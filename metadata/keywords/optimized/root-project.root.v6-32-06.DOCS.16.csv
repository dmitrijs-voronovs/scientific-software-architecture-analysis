quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,filename,wiki,url,total_similar,target_keywords,target_matched_words
Modifiability,"sing fitted chi2 values). The initial parameter values can be set directly in the input model function object.; However, for setting parameter bounds and step sizes to values different than the automatically computed ones, one needs to use the `ROOT::Fit::ParameterSetting` class.; This example code will set the lower/upper bounds for the first parameter and a lower bound for the second parameter. ``` {.cpp}; fitter.SetFunction( fitFunction, false);; fitter.Config().ParSettings(0).SetLimits(0,1.E6);; fitter.Config().ParSettings(2).SetLowerLimit(0);; ```. Note that a `ROOT::Fit::ParameterSettings` objects exists for each fit parameter and it created by the `ROOT::Fit::FitConfig` class, after the model function has been set in the Fitter.; Only when the function is set, the number of parameter is known and; automatically the `FitConfig` creates the corresponding `ParameterSetting` objects. When fitting, different minimizer can be used. The can be implemented in different libraries and loaded ar run time by the plug-in manager system of ROOT.; Each different minimizer (e.g. *Minuit, Minuit2, Fumili,* etc.) consists of a different implementation of the `ROOT::Math::Minimizer` interface.; Within the same minimizer, thus within the same class implementing the `Minimizer` interface, different algorithms can exist.; For example in the case of Minuit, we have *Migrad, Simplex* or *Minimize*. The minimizer and its corresponding algorithm, when available,; can be set by using the function `FitConfig::SetMinimizer(""minimizerName"")` or by using directly the `ROOT:Math::MinimizerOptions` class. If the requested minimizer is not available in ROOT, the default one is used. The default minimizer type and algorithm can be specified by using the; static function `ROOT::Math::MinimizerOptions::SetDefaultMinimizer(""minimizerName"")`. ### Minimizer Libraries and Algorithms. The list of available minimizer libraries currently available in ROOT, with their corresponding available algorithms ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:39842,plug-in,plug-in,39842,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['plug-in'],['plug-in']
Modifiability,"sing variables instead of values:. .. code-block:: gas. ; CHECK: mov r[[#REG_OFFSET:]], 0x[[#%X,FIELD_OFFSET:12]]; ; CHECK-NEXT: load r[[#]], [r[[#REG_BASE:]], r[[#REG_OFFSET]]]. which would match:. .. code-block:: gas. mov r4, 0xC; load r6, [r5, r4]. The ``--enable-var-scope`` option has the same effect on numeric variables as; on string variables. Important note: In its current implementation, an expression cannot use a; numeric variable defined earlier in the same CHECK directive. FileCheck Pseudo Numeric Variables; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Sometimes there's a need to verify output that contains line numbers of the; match file, e.g. when testing compiler diagnostics. This introduces a certain; fragility of the match file structure, as ""``CHECK:``"" lines contain absolute; line numbers in the same file, which have to be updated whenever line numbers; change due to text addition or deletion. To support this case, FileCheck expressions understand the ``@LINE`` pseudo; numeric variable which evaluates to the line number of the CHECK pattern where; it is found. This way match patterns can be put near the relevant test lines and include; relative line number references, for example:. .. code-block:: c++. // CHECK: test.cpp:[[# @LINE + 4]]:6: error: expected ';' after top level declarator; // CHECK-NEXT: {{^int a}}; // CHECK-NEXT: {{^ \^}}; // CHECK-NEXT: {{^ ;}}; int a. To support legacy uses of ``@LINE`` as a special string variable,; :program:`FileCheck` also accepts the following uses of ``@LINE`` with string; substitution block syntax: ``[[@LINE]]``, ``[[@LINE+<offset>]]`` and; ``[[@LINE-<offset>]]`` without any spaces inside the brackets and where; ``offset`` is an integer. Matching Newline Characters; ~~~~~~~~~~~~~~~~~~~~~~~~~~~. To match newline characters in regular expressions the character class; ``[[:space:]]`` can be used. For example, the following pattern:. .. code-block:: c++. // CHECK: DW_AT_location [DW_FORM_sec_offset] ([[DLOC:0x[0-9a-f]+]])",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst:34073,variab,variable,34073,interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,1,['variab'],['variable']
Modifiability,"sint-1.pdf).; * [Introduction to symbolic execution](https://www.cs.umd.edu/~mwh/se-tutorial/symbolic-exec.pdf).; * [Static Program Analysis by Anders Møller and Michael I. Schwartzbach](https://cs.au.dk/~amoeller/spa/).; * [EXE: automatically generating inputs of death](https://css.csail.mit.edu/6.858/2020/readings/exe.pdf); (a paper that successfully applies symbolic execution to real-world; software). ## Data flow analysis. ### The purpose of data flow analysis. Data flow analysis is a static analysis technique that proves facts about a; program or its fragment. It can make conclusions about all paths through the; program, while taking control flow into account and scaling to large programs.; The basic idea is propagating facts about the program through the edges of the; control flow graph (CFG) until a fixpoint is reached. ### Sample problem and an ad-hoc solution. We would like to explain data flow analysis while discussing an example. Let's; imagine that we want to track possible values of an integer variable in our; program. Here is how a human could annotate the code:. ```c++; void Example(int n) {; int x = 0;; // x is {0}; if (n > 0) {; x = 5;; // x is {5}; } else {; x = 42;; // x is {42}; }; // x is {5; 42}; print(x);; }; ```. We use sets of integers to represent possible values of `x`. Local variables; have unambiguous values between statements, so we annotate program points; between statements with sets of possible values. Here is how we arrived at these annotations. Assigning a constant to `x` allows; us to make a conclusion that `x` can only have one value. When control flow from; the ""then"" and ""else"" branches joins, `x` can have either value. Abstract algebra provides a nice formalism that models this kind of structure,; namely, a lattice. A join-semilattice is a partially ordered set, in which every; two elements have a least upper bound (called a *join*). ```; join(a, b) ⩾ a and join(a, b) ⩾ b and join(x, x) = x; ```. For this problem we will use th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:2247,variab,variable,2247,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,1,['variab'],['variable']
Modifiability,"sion of PoD on CernVM-FS you can use; that one. Experiment-independent versions are available from the PH-SFT; cvmfs repository. Only if you have specific reasons while you want to use a customly built; PoD version, download the source code and compile it using the; installation instructions. Please note that [CMake](http://www.cmake.org/) and; [Boost](http://www.boost.org/) are required to build PoD. - After you have built PoD, install it with:. make install. - After installing PoD, run:. pod-server getbins. This has to be done only once and downloads the binary packages that; will be dynamically transferred to the worker nodes as binary; payload, and prevents us from installing PoD on each cluster node. It is important to do this step now, because in case PoD has been; installed in a directory where the user has no write privileges, as; in the case of system-wide installations, the user won't be able to; download those required packages in the PoD binary directory. > There is no need to ""configure"" PoD for your specific cluster: it is; > just enough to install it on your head node.; >; > PoD does not have any system-wide persistent daemon running or any; > system-wide configuration to be performed. Also, no part of PoD will; > be ever run as root.; >; > Do not worry about environment or software configuration at this time:; > there is no system configuration for that. All the environment for; > your software dependencies will be set via proper scripts from the PoD; > client.; >; > PoD client configuration and running is properly covered in the; > appropriate manual page. ### Firewall configuration. The head node only requires **TCP ports 22 (SSH) and 443 (HTTPS)** to accept; connections from the outside. Users will get an authentication ""token""; from port 443 and all PROOF traffic will be automatically tunneled in a; SSH connection on port 22 by PoD. In case you are not using the HTTPS+SSH token+authentication method, access to; the sole port 22 is all you need.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:6057,config,configure,6057,proof/doc/confman/ConfigProofPoD.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md,6,['config'],"['configuration', 'configure']"
Modifiability,"sion, Objective-C,; C++, and Objective-C++. The Block Type; ==============. Like function types, the :block-term:`Block type` is a pair consisting; of a result value type and a list of parameter types very similar to a; function type. Blocks are intended to be used much like functions with; the key distinction being that in addition to executable code they; also contain various variable bindings to automatic (stack) or managed; (heap) memory. The abstract declarator,. .. code-block:: c. int (^)(char, float). describes a reference to a Block that, when invoked, takes two; parameters, the first of type char and the second of type float, and; returns a value of type int. The Block referenced is of opaque data; that may reside in automatic (stack) memory, global memory, or heap; memory. Block Variable Declarations; ===========================. A :block-term:`variable with Block type` is declared using function; pointer style notation substituting ``^`` for ``*``. The following are; valid Block variable declarations:. .. code-block:: c. void (^blockReturningVoidWithVoidArgument)(void);; int (^blockReturningIntWithIntAndCharArguments)(int, char);; void (^arrayOfTenBlocksReturningVoidWithIntArgument[10])(int);. Variadic ``...`` arguments are supported. [variadic.c] A Block that; takes no arguments must specify void in the argument list [voidarg.c].; An empty parameter list does not represent, as K&R provide, an; unspecified argument list. Note: both gcc and clang support K&R style; as a convenience. A Block reference may be cast to a pointer of arbitrary type and vice; versa. [cast.c] A Block reference may not be dereferenced via the; pointer dereference operator ``*``, and thus a Block's size may not be; computed at compile time. [sizeof.c]. Block Literal Expressions; =========================. A :block-term:`Block literal expression` produces a reference to a; Block. It is introduced by the use of the ``^`` token as a unary; operator. .. code-block:: c. Block_literal_expr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst:1554,variab,variable,1554,interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,1,['variab'],['variable']
Modifiability,"sion; ^^^^^^^^^. ``MemorySSA`` in LLVM deliberately trades off precision for speed.; Let us think about memory variables as if they were disjoint partitions of the; memory (that is, if you have one variable, as above, it represents the entire; memory, and if you have multiple variables, each one represents some; disjoint portion of the memory). First, because alias analysis results conflict with each other, and; each result may be what an analysis wants (IE; TBAA may say no-alias, and something else may say must-alias), it is; not possible to partition the memory the way every optimization wants.; Second, some alias analysis results are not transitive (IE A noalias B,; and B noalias C, does not mean A noalias C), so it is not possible to; come up with a precise partitioning in all cases without variables to; represent every pair of possible aliases. Thus, partitioning; precisely may require introducing at least N^2 new virtual variables,; phi nodes, etc. Each of these variables may be clobbered at multiple def sites. To give an example, if you were to split up struct fields into; individual variables, all aliasing operations that may-def multiple struct; fields, will may-def more than one of them. This is pretty common (calls,; copies, field stores, etc). Experience with SSA forms for memory in other compilers has shown that; it is simply not possible to do this precisely, and in fact, doing it; precisely is not worth it, because now all the optimizations have to; walk tons and tons of virtual variables and phi nodes. So we partition. At the point at which you partition, again,; experience has shown us there is no point in partitioning to more than; one variable. It simply generates more IR, and optimizations still; have to query something to disambiguate further anyway. As a result, LLVM partitions to one variable. Precision in practice; ^^^^^^^^^^^^^^^^^^^^^. In practice, there are implementation details in LLVM that also affect the; results' precision provided by",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:17590,variab,variables,17590,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['variab'],['variables']
Modifiability,"sition, offset, size and font can be set interactively;. - the color, size, and offset of axis labels can be set similarly. In; addition, there is a check box for no exponent choice, and another; one for setting the same decimal part for all labels. ### TPadEditor. ![](pictures/030000D6.png). - It provides the following user interface:. - Fixed aspect ratio - can be set for pad resizing. - Edit - sets pad or canvas as editable. - Cross-hair - sets a cross hair on the pad. - TickX - set ticks along the X axis. - TickY - set ticks along the Y axis. - GridX - set a grid along the X axis. - GridY - set a grid along the Y axis. - The pad or canvas border size can be set if a sunken or a raised; border mode is. - selected; no border mode can be set too. ## Copy and Paste. You can make a copy of a canvas using `TCanvas::DrawClonePad`. This; method is unique to **`TCanvas`**. It clones the entire canvas to the; active pad. There is a more general method `TObject::DrawClone`, which; all objects descendent of **`TObject`**, specifically all graphic; objects inherit. Below are two examples, one to show the use of; `DrawClonePad` and the other to show the use of `DrawClone`. ### Using the GUI. In this example we will copy an entire canvas to a new one with; `DrawClonePad`. Run the script `draw2dopt.C`. ``` {.cpp}; root[] .x tutorials/hist/draw2dopt.C; ```. This creates a canvas with 2D histograms. To make a copy of the canvas; follow the steps:. - Right-click on it to bring up the context menu. - Select `DrawClonePad`. This copies the entire canvas and all its sub-pads to a new canvas. The; copied canvas is a deep clone, and all the objects on it are copies and; independent of the original objects. For instance, change the fill on; one of the original histograms, and the cloned histogram retains its; attributes. `DrawClonePad` will copy the canvas to the active pad; the; target does not have to be a canvas. It can also be a pad on a canvas. ![Different draw options](pictures/03",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:85997,inherit,inherit,85997,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['inherit'],['inherit']
Modifiability,"sitory. In order to remain connected to the main buildmaster (and thus notify; developers of failures), a builbot must:. * Be building a supported configuration. Builders for experimental backends; should generally be attached to staging buildmaster.; * Be able to keep up with new commits to the main branch, or at a minimum; recover to tip of tree within a couple of days of falling behind. Additionally, we encourage all bot owners to point their bots towards the; staging master during maintenance windows, instability troubleshooting, and; such. Roles & Expectations; ====================. Each buildbot has an owner who is the responsible party for addressing problems; which arise with said buildbot. We generally expect the bot owner to be; reasonably responsive. For some bots, the ownership responsibility is split between a ""resource owner""; who provides the underlying machine resource, and a ""configuration owner"" who; maintains the build configuration. Generally, operational responsibility lies; with the ""config owner"". We do expect ""resource owners"" - who are generally; the contact listed in a workers attributes - to proxy requests to the relevant; ""config owner"" in a timely manner. Most issues with a buildbot should be addressed directly with a bot owner; via email. Please CC `Galina Kistanova <mailto:gkistanova@gmail.com>`_. Steps To Add Builder To LLVM Buildbot; =====================================; Volunteers can provide their build machines to work as build workers to; public LLVM Buildbot. Here are the steps you can follow to do so:. #. Check the existing build configurations to make sure the one you are; interested in is not covered yet or gets built on your computer much; faster than on the existing one. We prefer faster builds so developers; will get feedback sooner after changes get committed. #. The computer you will be registering with the LLVM buildbot; infrastructure should have all dependencies installed and be able to; build your configuration succe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst:1894,config,config,1894,interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,1,['config'],['config']
Modifiability,"size and NULL value. The ``DW_ASPACE_LLVM_none`` address space is the default target architecture; address space used in DWARF operations that do not specify an address space. It; therefore has to map to the global address space so that the ``DW_OP_addr*`` and; related operations can refer to addresses in the program code. The ``DW_ASPACE_AMDGPU_generic`` address space allows location expressions to; specify the flat address space. If the address corresponds to an address in the; local address space, then it corresponds to the wavefront that is executing the; focused thread of execution. If the address corresponds to an address in the; private address space, then it corresponds to the lane that is executing the; focused thread of execution for languages that are implemented using a SIMD or; SIMT execution model. .. note::. CUDA-like languages such as HIP that do not have address spaces in the; language type system, but do allow variables to be allocated in different; address spaces, need to explicitly specify the ``DW_ASPACE_AMDGPU_generic``; address space in the DWARF expression operations as the default address space; is the global address space. The ``DW_ASPACE_AMDGPU_local`` address space allows location expressions to; specify the local address space corresponding to the wavefront that is executing; the focused thread of execution. The ``DW_ASPACE_AMDGPU_private_lane`` address space allows location expressions; to specify the private address space corresponding to the lane that is executing; the focused thread of execution for languages that are implemented using a SIMD; or SIMT execution model. The ``DW_ASPACE_AMDGPU_private_wave`` address space allows location expressions; to specify the unswizzled private address space corresponding to the wavefront; that is executing the focused thread of execution. The wavefront view of private; memory is the per wavefront unswizzled backing memory layout defined in; :ref:`amdgpu-address-spaces`, such that address 0 corres",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:95244,variab,variables,95244,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['variab'],['variables']
Modifiability,"sk. <vlen>:= number -> number of lanes; | x -> VLA (Vector Length Agnostic). <parameters>:= v -> vector; | l | l <number> -> linear; | R | R <number> -> linear with ref modifier; | L | L <number> -> linear with val modifier; | U | U <number> -> linear with uval modifier; | ls <pos> -> runtime linear; | Rs <pos> -> runtime linear with ref modifier; | Ls <pos> -> runtime linear with val modifier; | Us <pos> -> runtime linear with uval modifier; | u -> uniform. <scalar_name>:= name of the scalar function. <vector_redirection>:= optional, custom name of the vector function. ``preallocated(<ty>)``; This attribute is required on calls to ``llvm.call.preallocated.arg``; and cannot be used on any other call. See; :ref:`llvm.call.preallocated.arg<int_call_preallocated_arg>` for more; details. .. _glattrs:. Global Attributes; -----------------. Attributes may be set to communicate additional information about a global variable.; Unlike :ref:`function attributes <fnattrs>`, attributes on a global variable; are grouped into a single :ref:`attribute group <attrgrp>`. ``no_sanitize_address``; This attribute indicates that the global variable should not have; AddressSanitizer instrumentation applied to it, because it was annotated; with `__attribute__((no_sanitize(""address"")))`,; `__attribute__((disable_sanitizer_instrumentation))`, or included in the; `-fsanitize-ignorelist` file.; ``no_sanitize_hwaddress``; This attribute indicates that the global variable should not have; HWAddressSanitizer instrumentation applied to it, because it was annotated; with `__attribute__((no_sanitize(""hwaddress"")))`,; `__attribute__((disable_sanitizer_instrumentation))`, or included in the; `-fsanitize-ignorelist` file.; ``sanitize_memtag``; This attribute indicates that the global variable should have AArch64 memory; tags (MTE) instrumentation applied to it. This attribute causes the; suppression of certain optimisations, like GlobalMerge, as well as ensuring; extra directives are emitted in the ass",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:115071,variab,variable,115071,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variable']
Modifiability,"smgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring. A sample configuration file; ---------------------------. xpd.stagereqrepo /opt/aaf/var/proof/datasets; dsmgrd.purgenoopds true; dsmgrd.urlregex alien://(.*)$ /storage$1; dsmgrd.sle",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:5156,variab,variable,5156,proof/doc/confman/DatasetStager.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md,2,"['plugin', 'variab']","['plugin', 'variable']"
Modifiability,"so be improved by matching region kinds,; i.e. changing ``foo[0].a`` is unlikely to affect ``foo[i].b``, no matter what; ``i`` is. For more detail, read through ``RegionStoreManager::removeSubRegionBindings`` in; RegionStore.cpp. ObjCIvarRegions; ---------------. Objective-C instance variables require a bit of special handling. Like struct; fields, they are not base regions, and when their parent object region is; invalidated, all the instance variables must be invalidated as well. However,; they have no concrete compile-time offsets (in the modern, ""non-fragile""; runtime), and so cannot easily be represented as an offset from the start of; the object in the analyzer. Moreover, this means that invalidating a single; instance variable should *not* invalidate the rest of the object, since unlike; struct fields or array elements there is no way to perform pointer arithmetic; to access another instance variable. Consequently, although the base region of an ObjCIvarRegion is the entire; object, RegionStore offsets are computed from the start of the instance; variable. Thus it is not valid to assume that all bindings with non-symbolic; offsets start from the base region!. Region Invalidation; -------------------. Unlike binding invalidation, region invalidation occurs when the entire; contents of a region may have changed---say, because it has been passed to a; function the analyzer can model, like memcpy, or because its address has; escaped, usually as an argument to an opaque function call. In these cases we; need to throw away not just all bindings within the region itself, but within; its entire cluster, since neighboring regions may be accessed via pointer; arithmetic. Region invalidation typically does even more than this, however. Because it; usually represents the complete escape of a region from the analyzer's model,; its *contents* must also be transitively invalidated. (For example, if a region; ``p`` of type ``int **`` is invalidated, the contents of ``*p`` an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/RegionStore.rst:3466,variab,variable,3466,interpreter/llvm-project/clang/docs/analyzer/developer-docs/RegionStore.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/RegionStore.rst,1,['variab'],['variable']
Modifiability,"so overwrite the existing include path:. ``` {.cpp}; gSystem->SetIncludePath("" -I$HOME/mypackage/include ""); ```. The `$ROOTSYS/include` directory is automatically appended to the; include path, so you do not have to worry about including it. To add; library that should be used during linking of the shared library use; something like:. ``` {.cpp}; gSystem->AddLinkedLibs(""-L/my/path -lanylib"");; ```. This is especially useful for static libraries. For shared ones you; can also simply load them before trying to compile the script:. ``` {.cpp}; gSystem->Load(""mydir/mylib"");; ```. ACLiC uses the directive `fMakeSharedLibs` to create the shared; library. If loading the shared library fails, it tries to output a; list of missing symbols by creating an executable (on some platforms; like OSF, this does not HAVE to be an executable) containing the; script. It uses the directive `fMakeExe` to do so. For both; directives, before passing them to `TSystem::Exec()`, it expands the; variables `$SourceFiles`, `$SharedLib`, `$LibName`, `$IncludePath`,; `$LinkedLibs`, `$ExeName `and` $ObjectFiles`. See `SetMakeSharedLib()`; for more information on those variables. When the file being passed to; ACLiC is on a read only file system, ACLiC warns the user and creates; the library in a temporary directory:. ``` {.cpp}; root[] .L readonly/t.C++; Warning in <ACLiC>: /scratch/aclic/subs/./readonly is not writable!; Warning in <ACLiC>: Output will be written to /tmp; Info in <TUnixSystem::ACLiC>: creating shared library; /tmp//scratch/aclic/subs/./readonly/t_C.so; ```. To select the temporary directory ACLiC looks at `$TEMP`, `$TEMP_DIR`,; `$TEMPDIR`, `$TMP`, `$TMPDIR`, `$TMP_DIR `or uses `/tmp (`or `C:/)`.; Also, a new interface `TSystem::Get/SetBuildDir` is introduced; to let users select an alternative 'root' for building of the ACLiC; libraries. For `filename/full/path/name/macro.C`, the library is; created as `fBuildDir/full/path/name/macro_C.so.`. ### Dictionary Generation. You can dire",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Cling.md:17707,variab,variables,17707,documentation/users-guide/Cling.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Cling.md,1,['variab'],['variables']
Modifiability,"so remove parentheses enclosing the expression in a; ``return``/``co_return`` statement. .. code-block:: c++. class __declspec(dllimport) X {};; co_return 0;; return (a + b) - (c + d);. .. _RemoveSemicolon:. **RemoveSemicolon** (``Boolean``) :versionbadge:`clang-format 16` :ref:`¶ <RemoveSemicolon>`; Remove semicolons after the closing brace of a non-empty function. .. warning::. Setting this option to ``true`` could lead to incorrect code formatting; due to clang-format's lack of complete semantic information. As such,; extra care should be taken to review code changes made by this option. .. code-block:: c++. false: true:. int max(int a, int b) { int max(int a, int b) {; return a > b ? a : b; return a > b ? a : b;; }; }. .. _RequiresClausePosition:. **RequiresClausePosition** (``RequiresClausePositionStyle``) :versionbadge:`clang-format 15` :ref:`¶ <RequiresClausePosition>`; The position of the ``requires`` clause. Possible values:. * ``RCPS_OwnLine`` (in configuration: ``OwnLine``); Always put the ``requires`` clause on its own line. .. code-block:: c++. template <typename T>; requires C<T>; struct Foo {... template <typename T>; requires C<T>; void bar(T t) {... template <typename T>; void baz(T t); requires C<T>; {... * ``RCPS_WithPreceding`` (in configuration: ``WithPreceding``); Try to put the clause together with the preceding part of a declaration.; For class templates: stick to the template declaration.; For function templates: stick to the template declaration.; For function declaration followed by a requires clause: stick to the; parameter list. .. code-block:: c++. template <typename T> requires C<T>; struct Foo {... template <typename T> requires C<T>; void bar(T t) {... template <typename T>; void baz(T t) requires C<T>; {... * ``RCPS_WithFollowing`` (in configuration: ``WithFollowing``); Try to put the ``requires`` clause together with the class or function; declaration. .. code-block:: c++. template <typename T>; requires C<T> struct Foo {... templa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:104387,config,configuration,104387,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['config'],['configuration']
Modifiability,"so_local i32 @foo(i1 %cond, i32 %input) !dbg !12 {; entry:; br i1 %cond, label %truebr, label %falsebr. bb1:; %value = phi i32 [ %value1, %truebr ], [ %value2, %falsebr ]; br label %exit, !dbg !26. truebr:; call void @llvm.dbg.value(metadata i32 %input, metadata !30, metadata !DIExpression()), !dbg !24; call void @llvm.dbg.value(metadata i32 1, metadata !23, metadata !DIExpression()), !dbg !24; %value1 = add i32 %input, 1; br label %bb1. falsebr:; call void @llvm.dbg.value(metadata i32 %input, metadata !30, metadata !DIExpression()), !dbg !24; call void @llvm.dbg.value(metadata i32 2, metadata !23, metadata !DIExpression()), !dbg !24; %value2 = add i32 %input, 2; br label %bb1. exit:; ret i32 %value, !dbg !30; }. Here the difficulties are:. * The control flow is roughly the opposite of basic block order; * The value of the ``!23`` variable merges into ``%bb1``, but there is no PHI; node. As mentioned above, the ``llvm.dbg.value`` intrinsics essentially form an; imperative program embedded in the IR, with each intrinsic defining a variable; location. This *could* be converted to an SSA form by mem2reg, in the same way; that it uses use-def chains to identify control flow merges and insert phi; nodes for IR Values. However, because debug variable locations are defined for; every machine instruction, in effect every IR instruction uses every variable; location, which would lead to a large number of debugging intrinsics being; generated. Examining the example above, variable ``!30`` is assigned ``%input`` on both; conditional paths through the function, while ``!23`` is assigned differing; constant values on either path. Where control flow merges in ``%bb1`` we would; want ``!30`` to keep its location (``%input``), but ``!23`` to become undefined; as we cannot determine at runtime what value it should have in %bb1 without; inserting a PHI node. mem2reg does not insert the PHI node to avoid changing; codegen when debugging is enabled, and does not insert the other dbg.val",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:38362,variab,variable,38362,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['variab'],['variable']
Modifiability,"solute_word);; if (Opcode == X86::MOV64ri); rt = X86::reloc_absolute_dword; // FIXME: add X86II flag?; if (MO1.isGlobalAddress()) {; bool NeedStub = isa<Function>(MO1.getGlobal());; bool isLazy = gvNeedsLazyPtr(MO1.getGlobal());; emitGlobalAddress(MO1.getGlobal(), rt, MO1.getOffset(), 0,; NeedStub, isLazy);; } else if (MO1.isExternalSymbol()); emitExternalSymbolAddress(MO1.getSymbolName(), rt);; else if (MO1.isConstantPoolIndex()); emitConstPoolAddress(MO1.getIndex(), rt);; else if (MO1.isJumpTableIndex()); emitJumpTableAddress(MO1.getIndex(), rt);; }; }; break;. In the previous example, ``XXXCodeEmitter.cpp`` uses the variable ``rt``, which; is a ``RelocationType`` enum that may be used to relocate addresses (for; example, a global address with a PIC base offset). The ``RelocationType`` enum; for that target is defined in the short target-specific ``XXXRelocations.h``; file. The ``RelocationType`` is used by the ``relocate`` method defined in; ``XXXJITInfo.cpp`` to rewrite addresses for referenced global symbols. For example, ``X86Relocations.h`` specifies the following relocation types for; the X86 addresses. In all four cases, the relocated value is added to the; value already in memory. For ``reloc_pcrel_word`` and ``reloc_picrel_word``,; there is an additional initial adjustment. .. code-block:: c++. enum RelocationType {; reloc_pcrel_word = 0, // add reloc value after adjusting for the PC loc; reloc_picrel_word = 1, // add reloc value after adjusting for the PIC base; reloc_absolute_word = 2, // absolute relocation; no additional adjustment; reloc_absolute_dword = 3 // absolute relocation; no additional adjustment; };. Target JIT Info; ---------------. ``XXXJITInfo.cpp`` implements the JIT interfaces for target-specific; code-generation activities, such as emitting machine code and stubs. At; minimum, a target-specific version of ``XXXJITInfo`` implements the following:. * ``getLazyResolverFunction`` --- Initializes the JIT, gives the target a; function that is",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:81362,rewrite,rewrite,81362,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['rewrite'],['rewrite']
Modifiability,"some; later versions of ``gcov``. To use :program:`llvm-cov gcov`, you must first build an instrumented version; of your application that collects coverage data as it runs. Compile with the; ``-fprofile-arcs`` and ``-ftest-coverage`` options to add the; instrumentation. (Alternatively, you can use the ``--coverage`` option, which; includes both of those other options.). At the time you compile the instrumented code, a ``.gcno`` data file will be; generated for each object file. These ``.gcno`` files contain half of the; coverage data. The other half of the data comes from ``.gcda`` files that are; generated when you run the instrumented program, with a separate ``.gcda``; file for each object file. Each time you run the program, the execution counts; are summed into any existing ``.gcda`` files, so be sure to remove any old; files if you do not want their contents to be included. By default, the ``.gcda`` files are written into the same directory as the; object files, but you can override that by setting the ``GCOV_PREFIX`` and; ``GCOV_PREFIX_STRIP`` environment variables. The ``GCOV_PREFIX_STRIP``; variable specifies a number of directory components to be removed from the; start of the absolute path to the object file directory. After stripping those; directories, the prefix from the ``GCOV_PREFIX`` variable is added. These; environment variables allow you to run the instrumented program on a machine; where the original object file directories are not accessible, but you will; then need to copy the ``.gcda`` files back to the object file directories; where :program:`llvm-cov gcov` expects to find them. Once you have generated the coverage data files, run :program:`llvm-cov gcov`; for each main source file where you want to examine the coverage results. This; should be run from the same directory where you previously ran the; compiler. The results for the specified source file are written to a file named; by appending a ``.gcov`` suffix. A separate output file is als",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-cov.rst:2224,variab,variables,2224,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-cov.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-cov.rst,1,['variab'],['variables']
Modifiability,"source distribution. The copyright transfer is; necessary for us to be able to effectively defend the project in case of; litigation. You can send us a patch or a pull request with Github, provided that you follow these two simple rules:. Make sure you follow the Cling coding conventions in your code.; . Make sure you provide a set of tests for your feature/bug fix.; . Often it is useful to contact us first to discuss the code you want to develop or the bug you want to fix. Picking up an Idea . We maintain a set of ""ideas"" for talented scientists and developers to pick up. An ""idea"" can be a sketch of a development project, a functionality, a missing feature we would like to see in our tool.; A list that we propose is the following:. Ideas. Extending and improving the multiline input mode - The multiline mode has to figure out automatically whether the user's input is still incomplete. For example ""if (a < 0) {"" is not fully completed input. Cling should'n try to process the line but to be smart enough to understand that it should wait for continuation. Currently cling switches multiline mode only when there is trailing ""{"". It has to be extended to detect trailing +, unbalanced ',"" and so on. Implementing error recovery verifier - One of the most important parts in cling is the error recovery. The error recovery takes care of reverting clang's internal structures on error in the user input. For instance, user types int i; error_here;. int i should be reverted and the entire input should be invalidated. This is very complex because many implicit template instantiations could be triggered and so on. The idea of the future verifier is to serialize the AST with all the lookup structures (probably in pch or pcm), trigger an error causing a lot of things to happen in clang internally and serialize the new AST. The comparison with the old one must return perfect match. Enabling clang's static analyzer - coming soon. Enabling ObjectiveC/ObjectiveC++ support - coming soon. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/www/contribute.html:1714,extend,extended,1714,interpreter/cling/www/contribute.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/www/contribute.html,1,['extend'],['extended']
Modifiability,"span>; <span style='background-color:#4A789C'> </span><span style='background-color:#85C1F5'>printf(""Hello world!\n"")</span><span style='background-color:#4A789C'>; </span> <span class='c1'>// Unreachable region's counter is zero</span>; <span style='background-color:#4A789C'>}</span>; </pre>`. The zero counters allow the code coverage tool to display proper line execution; counts for the unreachable lines and highlight the unreachable code.; Without them, the tool would think that those lines and regions were still; executed, as it doesn't possess the frontend's knowledge. Note that branch regions are created to track branch conditions in the source; code and refer to two coverage mapping counters, one to track the number of; times the branch condition evaluated to ""true"", and one to track the number of; times the branch condition evaluated to ""false"". LLVM IR Representation; ======================. The coverage mapping data is stored in the LLVM IR using a global constant; structure variable called *__llvm_coverage_mapping* with the *IPSK_covmap*; section specifier (i.e. "".lcovmap$M"" on Windows and ""__llvm_covmap"" elsewhere). For example, let’s consider a C file and how it gets compiled to LLVM:. .. _coverage mapping sample:. .. code-block:: c. int foo() {; return 42;; }; int bar() {; return 13;; }. The coverage mapping variable generated by Clang has 2 fields:. * Coverage mapping header. * An optionally compressed list of filenames present in the translation unit. The variable has 8-byte alignment because ld64 cannot always pack symbols from; different object files tightly (the word-level alignment assumption is baked in; too deeply). .. code-block:: llvm. @__llvm_coverage_mapping = internal constant { { i32, i32, i32, i32 }, [32 x i8] }; {; { i32, i32, i32, i32 } ; Coverage map header; {; i32 0, ; Always 0. In prior versions, the number of affixed function records; i32 32, ; The length of the string that contains the encoded translation unit filenames; i32 0, ; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst:14123,variab,variable,14123,interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CoverageMappingFormat.rst,1,['variab'],['variable']
Modifiability,special member functions; Unknown. 1732; C++14; Defining types in conditions and range-based for statements; Unknown. 1733; CD6; Return type and value for operator= with ref-qualifier; Unknown. 1734; CD4; Nontrivial deleted copy functions; No. 1735; drafting; Out-of-range literals in user-defined-literals; Not resolved. 1736; CD4; Inheriting constructor templates in a local class; Clang 3.9. 1737; C++14; Type dependence of call to a member of the current instantiation; Unknown. 1738; C++14; Explicit instantiation/specialization of inheriting constructor templates; Unknown. 1739; C++14; Conversion of floating point to enumeration; Unknown. 1740; C++14; Disambiguation of noexcept; Unknown. 1741; C++14; odr-use of class object in lvalue-to-rvalue conversion; Unknown. 1742; CD5; using-declarations and scoped enumerators; Unknown. 1743; NAD; init-captures in nested lambdas; Unknown. 1744; CD4; Unordered initialization for variable template specializations; Unknown. 1745; NAD; thread_local constexpr variable; Unknown. 1746; C++14; Are volatile scalar types trivially copyable?; Unknown. 1747; C++14; Constant initialization of reference to function; Unknown. 1748; CD4; Placement new with a null pointer; Clang 3.7. 1749; NAD; Confusing definition for constant initializer; Unknown. 1750; CD4; “Argument” vs “parameter”; Unknown. 1751; CD4; Non-trivial operations vs non-trivial initialization; Unknown. 1752; CD4; Right-recursion in mem-initializer-list; Unknown. 1753; CD4; decltype-specifier in nested-name-specifier of destructor; Clang 11. 1754; NAD; Declaration of partial specialization of static data member template; Unknown. 1755; drafting; Out-of-class partial specializations of member templates; Not resolved. 1756; CD4; Direct-list-initialization of a non-class object; Clang 3.7. 1757; CD4; Const integral subobjects; Unknown. 1758; CD4; Explicit conversion in copy/move list initialization; Clang 3.7. 1759; C++14; UTF-8 code units in plain char; Unknown. 1760; C++14; Access,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html:118323,variab,variable,118323,interpreter/llvm-project/clang/www/cxx_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html,1,['variab'],['variable']
Modifiability,"specialization whose declaration is; instantiated in one module and whose definition is instantiated in another; module may end up with members associated with the wrong declaration of the; class, which can result in miscompiles in some cases.; - Fix crash on use of a variadic overloaded operator.; (`#42535 <https://github.com/llvm/llvm-project/issues/42535>`_); - Fix a hang on valid C code passing a function type as an argument to; ``typeof`` to form a function declaration.; (`#64713 <https://github.com/llvm/llvm-project/issues/64713>`_); - Clang now reports missing-field-initializers warning for missing designated; initializers in C++.; (`#56628 <https://github.com/llvm/llvm-project/issues/56628>`_); - Clang now respects ``-fwrapv`` and ``-ftrapv`` for ``__builtin_abs`` and; ``abs`` builtins.; (`#45129 <https://github.com/llvm/llvm-project/issues/45129>`_,; `#45794 <https://github.com/llvm/llvm-project/issues/45794>`_); - Fixed an issue where accesses to the local variables of a coroutine during; ``await_suspend`` could be misoptimized, including accesses to the awaiter; object itself.; (`#56301 <https://github.com/llvm/llvm-project/issues/56301>`_); The current solution may bring performance regressions if the awaiters have; non-static data members. See; `#64945 <https://github.com/llvm/llvm-project/issues/64945>`_ for details.; - Clang now prints unnamed members in diagnostic messages instead of giving an; empty ''. Fixes; (`#63759 <https://github.com/llvm/llvm-project/issues/63759>`_); - Fix crash in __builtin_strncmp and related builtins when the size value; exceeded the maximum value representable by int64_t. Fixes; (`#64876 <https://github.com/llvm/llvm-project/issues/64876>`_); - Fixed an assertion if a function has cleanups and fatal erors.; (`#48974 <https://github.com/llvm/llvm-project/issues/48974>`_); - Clang now emits an error if it is not possible to deduce array size for a; variable with incomplete array type.; (`#37257 <https://github.com/llvm/llvm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:34018,variab,variables,34018,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,1,['variab'],['variables']
Modifiability,specification of enum direct-list-initialization; Unknown. 2375; NAD; Multiple redeclarations of constexpr static data members; Unknown. 2376; CD5; Class template argument deduction with array declarator; Unknown. 2377; NAD; Explicit copy constructor vs function viability; Unknown. 2378; C++20; Inconsistent grammar for reference init-capture of pack; Unknown. 2379; CD5; Missing prohibition against constexpr in friend declaration; Unknown. 2380; CD5; capture-default makes too many references odr-usable; Unknown. 2381; CD5; Composite pointer type of pointers to plain and noexcept member functions; Unknown. 2382; CD5; Array allocation overhead for non-allocating placement new; Unknown. 2383; NAD; Variadic member functions of variadic class templates; Unknown. 2384; CD5; Conversion function templates and qualification conversions; Unknown. 2385; CD5; Lookup for conversion-function-ids; N/A. 2386; CD5; tuple_size requirements for structured binding; Clang 9. 2387; CD5; Linkage of const-qualified variable template; Clang 9. 2388; NAD; Applicability of contract-attribute-specifiers; Unknown. 2389; CD6; Agreement of deduced and explicitly-specified variable types; Unknown. 2390; CD5; Is the argument of __has_cpp_attribute macro-expanded?; Clang 14. 2391; dup; Additional template parameters following pack expansion; Unknown. 2392; C++23; new-expression size check and constant evaluation; Unknown. 2393; NAD; Pseudo-destructors and object lifetime; Unknown. 2394; CD5; Const-default-constructible for members; Clang 15. 2395; drafting; Parameters following a pack expansion; Not resolved. 2396; CD6; Lookup of names in complex conversion-type-ids; No. 2397; CD6; auto specifier for pointers and references to arrays; Clang 17. 2398; drafting; Template template parameter matching and deduction; Not resolved. 2399; CD5; Unclear referent of “expression” in assignment-expression; Unknown. 2400; CD5; Constexpr virtual functions and temporary objects; Unknown. 2401; drafting; Array decay ,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html:163137,variab,variable,163137,interpreter/llvm-project/clang/www/cxx_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html,1,['variab'],['variable']
Modifiability,"specify the underlying scalar type. The `GenVector` classes do not inherit from **`TObject`**, therefore; cannot be used as in the case of the physics vector classes in ROOT; collections. In addition, to optimize performances, no virtual destructors are; provided. In the following paragraphs, the main characteristics of; `GenVector` are described. A more detailed description of all the; `GenVector` classes is available also at; <http://seal.cern.ch/documents/mathlib/GenVector.pdf>. ### Main Characteristics. #### Optimal Runtime Performances. We try to minimize any overhead in the run-time performance. We have; deliberately avoided the use of any virtual function and even virtual; destructors in the classes. In addition, as much as possible functions; are defined as inline. For this reason, we have chosen to use template; classes to implement the `GenVector` concepts instead of abstract or; base classes and virtual functions. It is then recommended to avoid; using the `GenVector` classes polymorphically and developing classes; inheriting from them. #### Points and Vector Concept. Mathematically vectors and points are two distinct concepts. They have; different transformations, as vectors only rotate while points rotate; and translate. You can add two vectors but not two points and the; difference between two points is a vector. We then distinguish for the 3; dimensional case, between points and vectors, modeling them with; different classes:. - `ROOT::Math::`**`DisplacementVector2D`** and; `ROOT::Math::`**`DisplacementVector3D`** template classes describing; 2 and 3 component direction and magnitude vectors, not rooted at any; particular point;. - `ROOT::Math::`**`PositionVector2D`** and; `ROOT::Math::`**`PositionVector3D`** template classes modeling the; points in 2 and 3 dimensions. For the 4D space-time vectors, we use the same class to model them,; `ROOT::Math::`**`LorentzVector`**, since we have recognized a limited; need for modeling the functionality of a 4D po",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:69374,polymorphi,polymorphically,69374,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,2,"['inherit', 'polymorphi']","['inheriting', 'polymorphically']"
Modifiability,"splus11; C++11 support is available. cplusplus14; C++14 support is available. cplusplus17; C++17 support is available. cplusplus20; C++20 support is available. cplusplus23; C++23 support is available. c99; C99 support is available. c11; C11 support is available. c17; C17 support is available. c23; C23 support is available. freestanding; A freestanding environment is available. gnuinlineasm; GNU inline ASM is available. objc; Objective-C support is available. objc_arc; Objective-C Automatic Reference Counting (ARC) is available. opencl; OpenCL is available. tls; Thread local storage is available. *target feature*; A specific target feature (e.g., ``sse4``, ``avx``, ``neon``) is available. *platform/os*; A os/platform variant (e.g. ``freebsd``, ``win32``, ``windows``, ``linux``, ``ios``, ``macos``, ``iossimulator``) is available. *environment*; A environment variant (e.g. ``gnu``, ``gnueabi``, ``android``, ``msvc``) is available. **Example:** The ``std`` module can be extended to also include C++ and C++11 headers using a *requires-declaration*:. .. parsed-literal::. module std {; // C standard library... module vector {; requires cplusplus; header ""vector""; }. module type_traits {; requires cplusplus11; header ""type_traits""; }; }. Header declaration; ~~~~~~~~~~~~~~~~~~; A header declaration specifies that a particular header is associated with the enclosing module. .. parsed-literal::. *header-declaration*:; ``private``:sub:`opt` ``textual``:sub:`opt` ``header`` *string-literal* *header-attrs*:sub:`opt`; ``umbrella`` ``header`` *string-literal* *header-attrs*:sub:`opt`; ``exclude`` ``header`` *string-literal* *header-attrs*:sub:`opt`. *header-attrs*:; '{' *header-attr** '}'. *header-attr*:; ``size`` *integer-literal*; ``mtime`` *integer-literal*. A header declaration that does not contain ``exclude`` nor ``textual`` specifies a header that contributes to the enclosing module. Specifically, when the module is built, the named header will be parsed and its declarations ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:35184,extend,extended,35184,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['extend'],['extended']
Modifiability,"src/HistFactoryImpl.cxx; src/HistFactoryModelUtils.cxx; src/HistFactoryNavigation.cxx; src/HistRef.cxx; src/HistoToWorkspaceFactoryFast.cxx; src/JSONTool.cxx; src/LinInterpVar.cxx; src/MakeModelAndMeasurementsFast.cxx; src/Measurement.cxx; src/ParamHistFunc.cxx; src/PiecewiseInterpolation.cxx; src/PreprocessFunction.cxx; src/RooBarlowBeestonLL.cxx; src/Sample.cxx; src/Systematics.cxx; ${HISTFACTORY_XML_SOURCES}; DICTIONARY_OPTIONS; ""-writeEmptyRootPCM""; LIBRARIES; RooBatchCompute; ${HISTFACTORY_XML_LIBRARIES}; DEPENDENCIES; RooFit; RooFitCore; Tree; RIO; Hist; Matrix; MathCore; Graf; Gpad; RooStats; RooFitJSONInterface; ${EXTRA_DICT_OPTS}; ). # For recent clang, this can facilitate auto-vectorisation.; # In RooFit, the errno side effect is not needed, anyway:; if(""${CMAKE_CXX_COMPILER_ID}"" MATCHES ""Clang""); target_compile_options(HistFactory PUBLIC -fno-math-errno); endif(). # The hist2workspace executable uses the HistFactory::ConfigParser to read the; # XML model specification. The ConfigParser is only built when xml is ON, so we; # can't build hist2workspace without xml.; if(xml); ROOT_EXECUTABLE(hist2workspace hist2workspace.cxx LIBRARIES HistFactory). #---Createhist2workspaceCommandLineOptions------------------------------------------------------------------; generateHeader(hist2workspace; ${CMAKE_CURRENT_SOURCE_DIR}/src/hist2workspace-argparse.py; ${CMAKE_BINARY_DIR}/ginclude/hist2workspaceCommandLineOptionsHelp.h; ). target_compile_definitions(HistFactory PUBLIC HISTFACTORY_XML); endif(). if(MSVC); set(prepareHistFactory_script prepareHistFactory.bat); else(); set(prepareHistFactory_script prepareHistFactory); endif(); file(COPY config/${prepareHistFactory_script} DESTINATION ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}); install(FILES ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/${prepareHistFactory_script}; PERMISSIONS OWNER_EXECUTE OWNER_WRITE OWNER_READ; GROUP_EXECUTE GROUP_READ; WORLD_EXECUTE WORLD_READ; DESTINATION ${CMAKE_INSTALL_BINDIR}). ROOT_ADD_TEST_SUBDIRECTORY(test); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/histfactory/CMakeLists.txt:3457,config,config,3457,roofit/histfactory/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/histfactory/CMakeLists.txt,1,['config'],['config']
Modifiability,"ss Foo {; void f() { foo(); }; };; void f() {; foo();; }; void f() {}. * ``SFS_All`` (in configuration: ``All``); Merge all functions fitting on a single line. .. code-block:: c++. class Foo {; void f() { foo(); }; };; void f() { bar(); }. .. _AllowShortIfStatementsOnASingleLine:. **AllowShortIfStatementsOnASingleLine** (``ShortIfStyle``) :versionbadge:`clang-format 3.3` :ref:`¶ <AllowShortIfStatementsOnASingleLine>`; Dependent on the value, ``if (a) return;`` can be put on a single line. Possible values:. * ``SIS_Never`` (in configuration: ``Never``); Never put short ifs on the same line. .. code-block:: c++. if (a); return;. if (b); return;; else; return;. if (c); return;; else {; return;; }. * ``SIS_WithoutElse`` (in configuration: ``WithoutElse``); Put short ifs on the same line only if there is no else statement. .. code-block:: c++. if (a) return;. if (b); return;; else; return;. if (c); return;; else {; return;; }. * ``SIS_OnlyFirstIf`` (in configuration: ``OnlyFirstIf``); Put short ifs, but not else ifs nor else statements, on the same line. .. code-block:: c++. if (a) return;. if (b) return;; else if (b); return;; else; return;. if (c) return;; else {; return;; }. * ``SIS_AllIfsAndElse`` (in configuration: ``AllIfsAndElse``); Always put short ifs, else ifs and else statements on the same; line. .. code-block:: c++. if (a) return;. if (b) return;; else return;. if (c) return;; else {; return;; }. .. _AllowShortLambdasOnASingleLine:. **AllowShortLambdasOnASingleLine** (``ShortLambdaStyle``) :versionbadge:`clang-format 9` :ref:`¶ <AllowShortLambdasOnASingleLine>`; Dependent on the value, ``auto lambda []() { return 0; }`` can be put on a; single line. Possible values:. * ``SLS_None`` (in configuration: ``None``); Never merge lambdas into a single line. * ``SLS_Empty`` (in configuration: ``Empty``); Only merge empty lambdas. .. code-block:: c++. auto lambda = [](int a) {};; auto lambda2 = [](int a) {; return a;; };. * ``SLS_Inline`` (in configuration: ``Inline`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:30511,config,configuration,30511,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['config'],['configuration']
Modifiability,"ss from Chapter 2 it is; immediately optimized, compiled and linked for us by the IRTransformLayer,; IRCompileLayer and RTDyldObjectLinkingLayer respectively. This scheme, where all the; work to make a Module executable is done up front, is simple to understand and; its performance characteristics are easy to reason about. However, it will lead; to very high startup times if the amount of code to be compiled is large, and; may also do a lot of unnecessary compilation if only a few compiled functions; are ever called at runtime. A truly ""just-in-time"" compiler should allow us to; defer the compilation of any given function until the moment that function is; first called, improving launch times and eliminating redundant work. In fact,; the ORC APIs provide us with a layer to lazily compile LLVM IR:; *CompileOnDemandLayer*. The CompileOnDemandLayer class conforms to the layer interface described in; Chapter 2, but its addModule method behaves quite differently from the layers; we have seen so far: rather than doing any work up front, it just scans the; Modules being added and arranges for each function in them to be compiled the; first time it is called. To do this, the CompileOnDemandLayer creates two small; utilities for each function that it scans: a *stub* and a *compile; callback*. The stub is a pair of a function pointer (which will be pointed at; the function's implementation once the function has been compiled) and an; indirect jump through the pointer. By fixing the address of the indirect jump; for the lifetime of the program we can give the function a permanent ""effective; address"", one that can be safely used for indirection and function pointer; comparison even if the function's implementation is never compiled, or if it is; compiled more than once (due to, for example, recompiling the function at a; higher optimization level) and changes address. The second utility, the compile; callback, represents a re-entry point from the program into the compiler that;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT3.rst:1875,layers,layers,1875,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT3.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT3.rst,1,['layers'],['layers']
Modifiability,"ss: ""class"" `ClassID` [`TemplateArgList`] `RecordBody`; TemplateArgList: ""<"" `TemplateArgDecl` ("","" `TemplateArgDecl`)* "">""; TemplateArgDecl: `Type` `TokIdentifier` [""="" `Value`]. A class can be parameterized by a list of ""template arguments,"" whose values; can be used in the class's record body. These template arguments are; specified each time the class is inherited by another class or record. If a template argument is not assigned a default value with ``=``, it is; uninitialized (has the ""value"" ``?``) and must be specified in the template; argument list when the class is inherited (required argument). If an; argument is assigned a default value, then it need not be specified in the; argument list (optional argument). In the declaration, all required template; arguments must precede any optional arguments. The template argument default; values are evaluated from left to right. The :token:`RecordBody` is defined below. It can include a list of; parent classes from which the current class inherits, along with field; definitions and other statements. When a class ``C`` inherits from another; class ``D``, the fields of ``D`` are effectively merged into the fields of; ``C``. A given class can only be defined once. A ``class`` statement is; considered to define the class if *any* of the following are true (the; :token:`RecordBody` elements are described below). * The :token:`TemplateArgList` is present, or; * The :token:`ParentClassList` in the :token:`RecordBody` is present, or; * The :token:`Body` in the :token:`RecordBody` is present and not empty. You can declare an empty class by specifying an empty :token:`TemplateArgList`; and an empty :token:`RecordBody`. This can serve as a restricted form of; forward declaration. Note that records derived from a forward-declared; class will inherit no fields from it, because those records are built when; their declarations are parsed, and thus before the class is finally defined. .. _NAME:. Every class has an implicit templat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:22857,inherit,inherits,22857,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['inherit'],['inherits']
Modifiability,"ss; WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR} ); endif(). if(WIN32); configure_file(${CMAKE_CURRENT_SOURCE_DIR}/config.h.win.in ${UNR_UNTARDIR}/config.h); else(); #---Define special compiler settings for unurun-----------------------------------------------------; set(UNR_CC ${CMAKE_C_COMPILER}); if(ROOT_ARCHITECTURE MATCHES hpuxia64acc); set(UNR_CC ""${UNR_CC} +DD64 -Ae""); elseif(ROOT_ARCHITECTURE MATCHES linuxppc64gcc); set(UNR_CC ""${UNR_CC} -m64 -fPIC""); elseif(ROOT_ARCHITECTURE MATCHES linuxx8664gcc); set(UNR_CFLAGS ""-m64 -fPIC""); elseif(ROOT_ARCHITECTURE MATCHES linuxicc); set(UNR_CFLAGS ""-m32""); elseif(ROOT_ARCHITECTURE MATCHES linuxx8664icc); set(UNR_CFLAGS ""-m64""); elseif(ROOT_ARCHITECTURE MATCHES win32 OR ROOT_ARCHITECTURE MATCHES win64); set(UNR_CFLAGS ""-MD -G5 -GX""); endif(); if(CMAKE_OSX_SYSROOT); set(UNR_CFLAGS ""${UNR_CFLAGS} -isysroot ${CMAKE_OSX_SYSROOT}""); endif(). #---configure unuran (required for creating the config.h used by unuran source files)----------------; add_custom_command(OUTPUT ${UNR_UNTARDIR}/config.h; COMMAND GNUMAKE=make ./configure CC=${UNR_CC} CFLAGS=${UNR_CFLAGS} > /dev/null 2>& 1; WORKING_DIRECTORY ${UNR_UNTARDIR}); endif(). #---We need to disable some warnings-------------------------------------------------------------------; string(REPLACE -Wall """" CMAKE_C_FLAGS ""${CMAKE_C_FLAGS}""); if(${CMAKE_CXX_COMPILER_ID} MATCHES Clang); ROOT_ADD_C_FLAG(CMAKE_C_FLAGS -Wno-parentheses-equality); ROOT_ADD_C_FLAG(CMAKE_C_FLAGS -Wno-deprecated-non-prototype); endif(); if(${CMAKE_CXX_COMPILER_ID} MATCHES GNU); ROOT_ADD_C_FLAG(CMAKE_C_FLAGS -Wno-maybe-uninitialized); ROOT_ADD_C_FLAG(CMAKE_C_FLAGS -Wno-alloc-size-larger-than). endif(). set(unrsources ${UNR_UNTARDIR}/src/utils/*.c; ${UNR_UNTARDIR}/src/methods/*.c; ${UNR_UNTARDIR}/src/specfunct/*.c; ${UNR_UNTARDIR}/src/distr/*.c; ${UNR_UNTARDIR}/src/distributions/*.c; ${UNR_UNTARDIR}/src/parser/*.c; ${UNR_UNTARDIR}/src/tests/*.c; ${UNR_UNTARDIR}/src/uniform/*.c; ${UNR_UNTARDIR}/src/urng/*.c ); s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/unuran/CMakeLists.txt:2357,config,config,2357,math/unuran/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/unuran/CMakeLists.txt,1,['config'],['config']
Modifiability,"ssPlugins); + if (auto PassPlugin = PassPlugin::Load(PluginFN)); + PassPlugin->registerPassBuilderCallbacks(PB);; }. .. _OptionMarshalling:. Option Marshalling Infrastructure; ---------------------------------. The option marshalling infrastructure automates the parsing of the Clang; ``-cc1`` frontend command line arguments into ``CompilerInvocation`` and their; generation from ``CompilerInvocation``. The system replaces lots of repetitive; C++ code with simple, declarative tablegen annotations and it's being used for; the majority of the ``-cc1`` command line interface. This section provides an; overview of the system. **Note:** The marshalling infrastructure is not intended for driver-only; options. Only options of the ``-cc1`` frontend need to be marshalled to/from; ``CompilerInvocation`` instance. To read and modify contents of ``CompilerInvocation``, the marshalling system; uses key paths, which are declared in two steps. First, a tablegen definition; for the ``CompilerInvocation`` member is created by inheriting from; ``KeyPathAndMacro``:. .. code-block:: text. // Options.td. class LangOpts<string field> : KeyPathAndMacro<""LangOpts->"", field, ""LANG_""> {}; // CompilerInvocation member ^^^^^^^^^^; // OPTION_WITH_MARSHALLING prefix ^^^^^. The first argument to the parent class is the beginning of the key path that; references the ``CompilerInvocation`` member. This argument ends with ``->`` if; the member is a pointer type or with ``.`` if it's a value type. The child class; takes a single parameter ``field`` that is forwarded as the second argument to; the base class. The child class can then be used like so:; ``LangOpts<""IgnoreExceptions"">``, constructing a key path to the field; ``LangOpts->IgnoreExceptions``. The third argument passed to the parent class is; a string that the tablegen backend uses as a prefix to the; ``OPTION_WITH_MARSHALLING`` macro. Using the key path as a mix-in on an; ``Option`` instance instructs the backend to generate the following code",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:34847,inherit,inheriting,34847,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['inherit'],['inheriting']
Modifiability,"sses that this record derives from. * ``!fields``: an array of strings giving the names of all the variables; in this record that were defined with the ``field`` keyword. * ``!name``: a string giving the name of the record. This is always; identical to the key in the JSON root object corresponding to this; record's dictionary. (If the record is anonymous, the name is; arbitrary.). * ``!anonymous``: a boolean indicating whether the record's name was; specified by the TableGen input (if it is ``false``), or invented by; TableGen itself (if ``true``). For each variable defined in a record, the ``def`` object for that; record also has a key for the variable name. The corresponding value; is a translation into JSON of the variable's value, using the; conventions described below. Some TableGen data types are translated directly into the; corresponding JSON type:. * A completely undefined value (e.g. for a variable declared without; initializer in some superclass of this record, and never initialized; by the record itself or any other superclass) is emitted as the JSON; ``null`` value. * ``int`` and ``bit`` values are emitted as numbers. Note that; TableGen ``int`` values are capable of holding integers too large to; be exactly representable in IEEE double precision. The integer; literal in the JSON output will show the full exact integer value.; So if you need to retrieve large integers with full precision, you; should use a JSON reader capable of translating such literals back; into 64-bit integers without losing precision, such as Python's; standard ``json`` module. * ``string`` and ``code`` values are emitted as JSON strings. * ``list<T>`` values, for any element type ``T``, are emitted as JSON; arrays. Each element of the array is represented in turn using these; same conventions. * ``bits`` values are also emitted as arrays. A ``bits`` array is; ordered from least-significant bit to most-significant. So the; element with index ``i`` corresponds to the bit described as",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst:16981,variab,variable,16981,interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst,1,['variab'],['variable']
Modifiability,"ssion operations: ``DW_OP_aspace_bregx``,; ``DW_OP_form_aspace_address``, ``DW_OP_aspace_implicit_pointer``, and; ``DW_OP_xderef*``. * The CFI instructions: ``DW_CFA_def_aspace_cfa`` and; ``DW_CFA_def_aspace_cfa_sf``. .. note::. Currently, DWARF defines address class values as being target architecture; specific, and defines a DW_AT_address_class attribute. With the removal of; DW_AT_segment in DWARF 6, it is unclear how the address class is intended to; be used as the term is not used elsewhere. Should these be replaced by this; proposal's more complete address space? Or are they intended to represent; source language memory spaces such as in OpenCL?. .. _amdgpu-dwarf-memory-spaces:. A.2.14 Memory Spaces; ~~~~~~~~~~~~~~~~~~~~. .. note::. This is a new section after DWARF Version 5 section 2.12 Segmented Addresses. DWARF memory spaces are used for source languages that have the concept of; memory spaces. They are used in the ``DW_AT_LLVM_memory_space`` attribute for; pointer type, reference type, variable, formal parameter, and constant debugger; information entries. Each DWARF memory space is conceptually a separate source language memory space; with its own lifetime and aliasing rules. DWARF memory spaces are used to; specify the source language memory spaces that pointer type and reference type; values refer, and to specify the source language memory space in which variables; are allocated. Although DWARF memory space identifiers are source language specific,; ``DW_MSPACE_LLVM_none`` is a common memory space supported by all source; languages, and defined as the source language default memory space. The set of currently defined DWARF memory spaces, together with source language; mappings, is given in :ref:`amdgpu-dwarf-source-language-memory-spaces-table`. Vendor defined source language memory spaces may be defined using codes in the; range ``DW_MSPACE_LLVM_lo_user`` to ``DW_MSPACE_LLVM_hi_user``. .. table:: Source language memory spaces; :name: amdgpu-dwarf-sour",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:150561,variab,variable,150561,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['variab'],['variable']
Modifiability,"ssor of TTree has been upgraded to the version 1 of the binary format specification. Compared to the v0 format, the header is ~40% smaller and the footer ~100% smaller (after zstd compression). More details in PR [#8897](https://github.com/root-project/root/pull/8897).; RNTuple is still experimental and is scheduled to become production grade in 2024. Thus, we appreciate feedback and suggestions for improvement. If you have been trying RNTuple for a while, these are the other important changes that you will notice:. - Support for aligned friends (PR [#6979](https://github.com/root-project/root/pull/6979)). Refer to the `RNTupleReader::OpenFriends()` function.; - Cluster and page sizes in `RNTupleWriteOptions` now refer to their target size in bytes (as opposed to the number of entries). Defaults are 64 kB for the page size and 50 MB for the cluster size (PR [#8703](https://github.com/root-project/root/pull/8703)).; - Storing objects of user-defined classes via `TClass` now also includes members inherited from all the base classes (PR [#8552](https://github.com/root-project/root/pull/8552)).; - Support for RFields whose type is a typedef to some other type. ## RDataFrame. ### New features. - Add [`Redefine`](https://root.cern/doc/master/classROOT_1_1RDF_1_1RInterface.html#a4e882a949c8a1022a38ec6936c2ff29c) to the `RDataFrame` interface, which allows to overwrite the value of an existing column.; - Add [`Describe`](https://root.cern/doc/master/classROOT_1_1RDF_1_1RInterface.html#a53f3e3d81e041a804481df228fe0081c) to the `RDataFrame` interface, which allows to get useful information, e.g. the columns and their types.; - Add [`DescribeDataset`](https://root.cern/doc/master/classROOT_1_1RDF_1_1RInterface.html#a1bc5b86a2a834bb06711fb535451146d) to the `RDataFrame` interface, which allows to get information about the dataset (subset of the output of Describe()).; - Add [`DefinePerSample`](https://root.cern/doc/master/classROOT_1_1RDF_1_1RInterface.html#a29d77593e95c0f84e35",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md:6974,inherit,inherited,6974,README/ReleaseNotes/v626/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md,1,['inherit'],['inherited']
Modifiability,st common; alignment of ``&`` and ``*``.; Pointer and reference alignment styles are going to be updated according; to the preferences found in the file.; ``PointerAlignment`` is then used only as fallback. .. _DisableFormat:. **DisableFormat** (``Boolean``) :versionbadge:`clang-format 3.7` :ref:`¶ <DisableFormat>`; Disables formatting completely. .. _EmptyLineAfterAccessModifier:. **EmptyLineAfterAccessModifier** (``EmptyLineAfterAccessModifierStyle``) :versionbadge:`clang-format 13` :ref:`¶ <EmptyLineAfterAccessModifier>`; Defines when to put an empty line after access modifiers.; ``EmptyLineBeforeAccessModifier`` configuration handles the number of; empty lines between two access modifiers. Possible values:. * ``ELAAMS_Never`` (in configuration: ``Never``); Remove all empty lines after access modifiers. .. code-block:: c++. struct foo {; private:; int i;; protected:; int j;; /* comment */; public:; foo() {}; private:; protected:; };. * ``ELAAMS_Leave`` (in configuration: ``Leave``); Keep existing empty lines after access modifiers.; MaxEmptyLinesToKeep is applied instead. * ``ELAAMS_Always`` (in configuration: ``Always``); Always add empty line after access modifiers if there are none.; MaxEmptyLinesToKeep is applied also. .. code-block:: c++. struct foo {; private:. int i;; protected:. int j;; /* comment */; public:. foo() {}; private:. protected:. };. .. _EmptyLineBeforeAccessModifier:. **EmptyLineBeforeAccessModifier** (``EmptyLineBeforeAccessModifierStyle``) :versionbadge:`clang-format 12` :ref:`¶ <EmptyLineBeforeAccessModifier>`; Defines in which cases to put empty line before access modifiers. Possible values:. * ``ELBAMS_Never`` (in configuration: ``Never``); Remove all empty lines before access modifiers. .. code-block:: c++. struct foo {; private:; int i;; protected:; int j;; /* comment */; public:; foo() {}; private:; protected:; };. * ``ELBAMS_Leave`` (in configuration: ``Leave``); Keep existing empty lines before access modifiers. * ``ELBAMS_LogicalBl,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:61178,config,configuration,61178,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['config'],['configuration']
Modifiability,"st discovery*. In the :program:`lit` model, every test must exist inside some *test suite*.; :program:`lit` resolves the inputs specified on the command line to test suites; by searching upwards from the input path until it finds a :file:`lit.cfg` or; :file:`lit.site.cfg` file. These files serve as both a marker of test suites; and as configuration files which :program:`lit` loads in order to understand; how to find and run the tests inside the test suite. Once :program:`lit` has mapped the inputs into test suites it traverses the; list of inputs adding tests for individual files and recursively searching for; tests in directories. This behavior makes it easy to specify a subset of tests to run, while still; allowing the test suite configuration to control exactly how tests are; interpreted. In addition, :program:`lit` always identifies tests by the test; suite they are in, and their relative path inside the test suite. For; appropriately configured projects, this allows :program:`lit` to provide; convenient and flexible support for out-of-tree builds. .. _test-status-results:. TEST STATUS RESULTS; -------------------. Each test ultimately produces one of the following eight results:. **PASS**. The test succeeded. **FLAKYPASS**. The test succeeded after being re-run more than once. This only applies to; tests containing an ``ALLOW_RETRIES:`` annotation. **XFAIL**. The test failed, but that is expected. This is used for test formats which allow; specifying that a test does not currently work, but wish to leave it in the test; suite. **XPASS**. The test succeeded, but it was expected to fail. This is used for tests which; were specified as expected to fail, but are now succeeding (generally because; the feature they test was broken and has been fixed). **FAIL**. The test failed. **UNRESOLVED**. The test result could not be determined. For example, this occurs when the test; could not be run, the test itself is invalid, or the test was interrupted. **UNSUPPORTED**. The ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst:12198,config,configured,12198,interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,2,"['config', 'flexible']","['configured', 'flexible']"
Modifiability,"st has to be enclosed in a square brackets and is a; comma-separated list of integers.; * targetClass; - The field is obligatory and defines the name of the in-memory class that; this rule can be applied to.; * target; - A comma-separated list of target class data member names that this rule; is capable of calculating.; * embed; - This property tells the system if the rule should be written in the output; file is some objects of this class are serialized.; * include; - A list of header files that should be included in order to provide the; functionality used in the code snippet; the list is comma delimited.; * code; - An user specified code snippet. The user can assume that in the provided code snippet the following variables; will be defined:. The user provided code snippets have to consist of valid C++ code. The system can do; some preprocessing before wrapping the code into function calls and declare some variables to; facilitate the rule definitions. The user can expect the following variables being predeclared:. * newObj; - variable representing the target in-memory object, its type is that of the; target object; * oldObj; - in normal conversion rules, an object of TVirtualObject class representing the; input data, guaranteed to hold the data members declared in the source property; of the rule; * buffer; - in raw conversion rules, an object of TBuffer class holding the data member; declared in source property of the rule; * names of the data members of the target object declared in the target property of the; rule declared to be the appropriate type; * onfile.xxx; - in normal conversion rules, names of the variables of basic types declared; in the source property of the rule. #### The C++ API. The schema evolution C++ API consists of two classes: `ROOT::TSchemaRuleSet` and; `ROOT::TSchemaRule`. Objects of the TSchemaRule class represent the rules and their fields have exactly the same; meaning as the ones of rules specified in the dictionaries. `TSchemaRuleSet",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:81627,variab,variables,81627,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,1,['variab'],['variables']
Modifiability,"st, 123, DW_OP_stack_value)`` specifies an expression where; the entry value of ``reg`` is pushed onto the stack, and is added with 123.; Due to framework limitations ``N`` must be 1, in other words,; ``DW_OP_entry_value`` always refers to the value/address operand of the; instruction. Because ``DW_OP_LLVM_entry_value`` is defined in terms of registers, it is; usually used in MIR, but it is also allowed in LLVM IR when targeting a; :ref:`swiftasync <swiftasync>` argument. The operation is introduced by:. - ``LiveDebugValues`` pass, which applies it to function parameters that; are unmodified throughout the function. Support is limited to simple; register location descriptions, or as indirect locations (e.g.,; parameters passed-by-value to a callee via a pointer to a temporary copy; made in the caller).; - ``AsmPrinter`` pass when a call site parameter value; (``DW_AT_call_site_parameter_value``) is represented as entry value of; the parameter.; - ``CoroSplit`` pass, which may move variables from allocas into a; coroutine frame. If the coroutine frame is a; :ref:`swiftasync <swiftasync>` argument, the variable is described with; an ``DW_OP_LLVM_entry_value`` operation. - ``DW_OP_LLVM_arg, N`` is used in debug intrinsics that refer to more than one; value, such as one that calculates the sum of two registers. This is always; used in combination with an ordered list of values, such that; ``DW_OP_LLVM_arg, N`` refers to the ``N``\ :sup:`th` element in that list. For; example, ``!DIExpression(DW_OP_LLVM_arg, 0, DW_OP_LLVM_arg, 1, DW_OP_minus,; DW_OP_stack_value)`` used with the list ``(%reg1, %reg2)`` would evaluate to; ``%reg1 - reg2``. This list of values should be provided by the containing; intrinsic/instruction.; - ``DW_OP_breg`` (or ``DW_OP_bregx``) represents a content on the provided; signed offset of the specified register. The opcode is only generated by the; ``AsmPrinter`` pass to describe call site parameter value which requires an; expression over two regist",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:264482,variab,variables,264482,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variables']
Modifiability,"st://disk1' instead of 'host' only as; it was so far). These feature can be enabled by defining the rootrc; variable 'Packetizer.Partitions', e.g.;            Packetizer.Partitions  /disk1,/disk2,/disk3; Add to the output list the parameters used by the active packetizer. . In the PrintProgress function used to display a text progress; bar, show also the average reading rate in [k,M,G}bytes/s in addition; to the event processing rate. This is useful to have a feeling of the; rate when running of a remote machine in batch mode.; Add the possibility to control the resident and virtual; memory of a proofserv using 'ulimit', which has less limitations and; more flexibility than setrlimit.; Deactivate workers when the requested packages could not be enabled properly.; Add support for reconfiguring the group manager and the; {env,rootrc} settings. The related configuration files are checked for; changes during the regular checks done by the XrdProofdManager.; Add support for selective definition of env and rootrc; variables. Different values can be set for different users, groups, SVN; versions or ROOT versions.; Improve the diagnostic in case of exceptions. Information; about the event and file being processed at the moment the exception; was raised is sent to the client, e.g.;    0.5: caught exception triggered by signal '1' while; processing dset:'EventTree',; file:'http://root.cern.ch/files/data/event_3.root', event:1 - check; logs for possible stacktrace; The patch also fixes a problem with submergers observed when a worker; was stopped because above the memory limits: this worker was; established as merger but could not do the work, for obvious reasons,; freezing the session.; Add two new methods to TProof: ShowMissingFiles() to facilitate; the display of the list of missing files; and GetMissingFiles() to get; a TFileCollection (dataset) with the missing files for further; processing. Fixes. Fix a bug in error status transmission which avoid; session freezing in so",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:8567,variab,variables,8567,proof/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html,1,['variab'],['variables']
Modifiability,"st; argument, and just calls another function passing through the first argument and; all trailing arguments. CMake provides a module ``CMakeParseArguments`` which provides an implementation; of advanced argument parsing. We use this all over LLVM, and it is recommended; for any function that has complex argument-based behaviors or optional; arguments. CMake's official documentation for the module is in the; ``cmake-modules`` manpage, and is also available at the; `cmake-modules online documentation; <https://cmake.org/cmake/help/v3.4/module/CMakeParseArguments.html>`_. .. note::; As of CMake 3.5 the cmake_parse_arguments command has become a native command; and the CMakeParseArguments module is empty and only left around for; compatibility. Functions Vs Macros; -------------------. Functions and Macros look very similar in how they are used, but there is one; fundamental difference between the two. Functions have their own scope, and; macros don't. This means variables set in macros will bleed out into the calling; scope. That makes macros suitable for defining very small bits of functionality; only. The other difference between CMake functions and macros is how arguments are; passed. Arguments to macros are not set as variables, instead dereferences to; the parameters are resolved across the macro before executing it. This can; result in some unexpected behavior if using unreferenced variables. For example:. .. code-block:: cmake. macro(print_list my_list); foreach(var IN LISTS my_list); message(""${var}""); endforeach(); endmacro(). set(my_list a b c d); set(my_list_of_numbers 1 2 3 4); print_list(my_list_of_numbers); # prints:; # a; # b; # c; # d. Generally speaking this issue is uncommon because it requires using; non-dereferenced variables with names that overlap in the parent scope, but it; is important to be aware of because it can lead to subtle bugs. LLVM Project Wrappers; =====================. LLVM projects provide lots of wrappers around critical CMake bui",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:12169,variab,variables,12169,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst,1,['variab'],['variables']
Modifiability,"st; entered points. The previous algorithm was based on user coordinates. It is now; based on pixel to avoid the problem reported; [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=20343). ### TCanvas. When the first canvas created by ROOT was in batch mode, it was note possible to; come back in interactive mode for the next canvases. this problem was reported; [here](https://root.cern.ch/phpBB3/viewtopic.php?f=3&t=20354). ### Cocoa Backend. Sometimes the mouse cursor did not change back to the window manager arrow when; exiting a `TCanvas`. ### `freetype` library. Updates `builtin_freetype` to 2.6.1 (current upstream version), which can detect; `PPC64LE` machine. This was compiled and tested on `SLC6 + ICC + x86_64`,; `F21 + GCC + ppc64le`, `MacOSX 10.11.1 + Xcode 7.1` and `Windows (ROOT 5.34)`.; `$ROOTSYS/graf2d/freetype/src/README` was removed, because no issues were noticed; with `ICC` compiler and `-Wall -pedantic -ansi` flags.; Additionally `--with-png=no --with-bzip2=no` flags are passed to freetype; configuration script. Default values for these options are auto.; `freetype` finds `libpng` and `libbzip2` on the system and builds extra; modules. Then attempting to link against `freetype` one would need to link; `-lpng -lbzip2` explicitly otherwise linking will returns in undefined; references. Otherwise we would need to check for `libpng` and `libbzip2` on the system; and adjust `FREETYPE_LIBRARIES` to include `-lpng` and `-lbzip2`.; The current solution goes for the minimal configuration. The original request for; this update was posted [here](https://sft.its.cern.ch/jira/browse/ROOT-7631). ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Libraries. ### THttpServer. Support of POST HTTP requests. For example, ROOT objects can be send with POST request and used as arguments of; objects method execution in exe.bin and exe.json requests. Request and response HTTP headers are now directly accessible in THttpCallArg class",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:17991,config,configuration,17991,README/ReleaseNotes/v606/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md,1,['config'],['configuration']
Modifiability,"stage2 compiler; based on the settings in Apple-stage2.cmake. This pattern of using cache scripts to set complex settings, and specifically to; make later stage builds include cache scripts is common in our more advanced; build configurations. Multi-stage PGO; ===============. Profile-Guided Optimizations (PGO) is a really great way to optimize the code; clang generates. Our multi-stage PGO builds are a workflow for generating PGO; profiles that can be used to optimize clang. At a high level, the way PGO works is that you build an instrumented compiler,; then you run the instrumented compiler against sample source files. While the; instrumented compiler runs it will output a bunch of files containing; performance counters (.profraw files). After generating all the profraw files; you use llvm-profdata to merge the files into a single profdata file that you; can feed into the LLVM_PROFDATA_FILE option. Our PGO.cmake cache automates that whole process. You can use it for; configuration with CMake with the following command:. .. code-block:: console. $ cmake -G Ninja -C <path to source>/clang/cmake/caches/PGO.cmake \; <path to source>/llvm. There are several additional options that the cache file also accepts to modify; the build, particularly the PGO_INSTRUMENT_LTO option. Setting this option to; Thin or Full will enable ThinLTO or full LTO respectively, further enhancing; the performance gains from a PGO build by enabling interprocedural; optimizations. For example, to run a CMake configuration for a PGO build; that also enables ThinTLO, use the following command:. .. code-block:: console. $ cmake -G Ninja -C <path to source>/clang/cmake/caches/PGO.cmake \; -DPGO_INSTRUMENT_LTO=Thin \; <path to source>/llvm. By default, clang will generate profile data by compiling a simple; hello world program. You can also tell clang use an external; project for generating profile data that may be a better fit for your; use case. The project you specify must either be a lit test sui",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst:5444,config,configuration,5444,interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,1,['config'],['configuration']
Modifiability,"start``' intrinsic specifies that the contents of; a memory object will not change. Arguments:; """""""""""""""""""". The first argument is a constant integer representing the size of the; object, or -1 if it is variable sized. The second argument is a pointer; to the object. Semantics:; """""""""""""""""""". This intrinsic indicates that until an ``llvm.invariant.end`` that uses; the return value, the referenced memory location is constant and; unchanging. '``llvm.invariant.end``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. The memory object can belong to any address space. ::. declare void @llvm.invariant.end.p0(ptr <start>, i64 <size>, ptr nocapture <ptr>). Overview:; """""""""""""""""". The '``llvm.invariant.end``' intrinsic specifies that the contents of a; memory object are mutable. Arguments:; """""""""""""""""""". The first argument is the matching ``llvm.invariant.start`` intrinsic.; The second argument is a constant integer representing the size of the; object, or -1 if it is variable sized and the third argument is a; pointer to the object. Semantics:; """""""""""""""""""". This intrinsic indicates that the memory is mutable again. '``llvm.launder.invariant.group``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. The memory object can belong to any address; space. The returned pointer must belong to the same address space as the; argument. ::. declare ptr @llvm.launder.invariant.group.p0(ptr <ptr>). Overview:; """""""""""""""""". The '``llvm.launder.invariant.group``' intrinsic can be used when an invariant; established by ``invariant.group`` metadata no longer holds, to obtain a new; pointer value that carries fresh invariant group information. It is an; experimental intrinsic, which means that its semantics might change in the; future. Arguments:; """""""""""""""""""". The ``llvm.launder.invariant.group`` takes only one argument, which is a pointer; to the memory. Semantics:; """""""""""""""""""". Returns another point",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:864908,variab,variable,864908,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variable']
Modifiability,"static/global data lookup) for 32b Windows; * Fixed more linker problems with malloc on 64b Windows; * Consistency in buffer length calculations and c_int/c_uint handling on Windows; * Properly resolve overloaded functions with using of templates from bases; * Get templated constructor info from decl instead of name comparison; * Fixed a performance regression for free functions. 2019-04-04 : 1.4.7; ------------------. * Enable initializer_list conversion on Windows as well; * Improved mapping of operator() for indexing (e.g. for matrices); * Implicit conversion no longer uses global state to prevent recursion; * Improved overload reordering; * Fixes for templated constructors in namespaces. 2019-04-02 : 1.4.6; ------------------. * More transparent use of smart pointers such as shared_ptr; * Expose versioned std namespace through using on Mac; * Improved error handling and interface checking in cross-inheritance; * Argument of (const/non-const) ref types support in callbacks/cross-inheritance; * Do template argument resolution in order: reference, pointer, value; * Fix for return type deduction of resolved but uninstantiated templates; * Fix wrapper generation for defaulted arguments of private types; * Several linker fixes on 64b Windows. 2019-03-25 : 1.4.5; ------------------. * Allow templated free functions to be attached as methods to classes; * Allow cross-derivation from templated classes; * More support for 'using' declarations (methods and inner namespaces); * Fix overload resolution for ``std::set::rbegin()``/``rend()`` ``operator==``; * Fixes for bugs #61, #67; * Several pointer truncation fixes for 64b Windows; * Linker and lookup fixes for Windows. 2019-03-20 : 1.4.4; ------------------. * Support for 'using' of namespaces; * Improved support for alias templates; * Faster template lookup; * Have rootcling/genreflex respect compile-time flags (except for --std if; overridden by CLING_EXTRA_ARGS); * Utility to build dictionarys on Windows (32/64); * Name",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:21170,inherit,inheritance,21170,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,2,['inherit'],['inheritance']
Modifiability,"std::set <dss_set>`. A sorted vector; (where you don't delete duplicate entries) or some other approach is almost; always better. .. _ds_map:. Map-Like Containers (std::map, DenseMap, etc); ---------------------------------------------. Map-like containers are useful when you want to associate data to a key. As; usual, there are a lot of different ways to do this. :). .. _dss_sortedvectormap:. A sorted 'vector'; ^^^^^^^^^^^^^^^^^. If your usage pattern follows a strict insert-then-query approach, you can; trivially use the same approach as :ref:`sorted vectors for set-like containers; <dss_sortedvectorset>`. The only difference is that your query function (which; uses std::lower_bound to get efficient log(n) lookup) should only compare the; key, not both the key and value. This yields the same advantages as sorted; vectors for sets. .. _dss_stringmap:. llvm/ADT/StringMap.h; ^^^^^^^^^^^^^^^^^^^^. Strings are commonly used as keys in maps, and they are difficult to support; efficiently: they are variable length, inefficient to hash and compare when; long, expensive to copy, etc. StringMap is a specialized container designed to; cope with these issues. It supports mapping an arbitrary range of bytes to an; arbitrary other object. The StringMap implementation uses a quadratically-probed hash table, where the; buckets store a pointer to the heap allocated entries (and some other stuff).; The entries in the map must be heap allocated because the strings are variable; length. The string data (key) and the element object (value) are stored in the; same allocation with the string data immediately after the element object.; This container guarantees the ""``(char*)(&Value+1)``"" points to the key string; for a value. The StringMap is very fast for several reasons: quadratic probing is very cache; efficient for lookups, the hash value of strings in buckets is not recomputed; when looking up an element, StringMap rarely has to touch the memory for; unrelated objects when looking u",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:88570,variab,variable,88570,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['variab'],['variable']
Modifiability,"stdin. Platform-Specific Tests; -----------------------. Whenever adding tests that require the knowledge of a specific platform,; either related to code generated, specific output or back-end features,; you must make sure to isolate the features, so that buildbots that; run on different architectures (and don't even compile all back-ends),; don't fail. The first problem is to check for target-specific output, for example sizes; of structures, paths and architecture names, for example:. * Tests containing Windows paths will fail on Linux and vice-versa.; * Tests that check for ``x86_64`` somewhere in the text will fail anywhere else.; * Tests where the debug information calculates the size of types and structures. Also, if the test rely on any behaviour that is coded in any back-end, it must; go in its own directory. So, for instance, code generator tests for ARM go; into ``test/CodeGen/ARM`` and so on. Those directories contain a special; ``lit`` configuration file that ensure all tests in that directory will; only run if a specific back-end is compiled and available. For instance, on ``test/CodeGen/ARM``, the ``lit.local.cfg`` is:. .. code-block:: python. config.suffixes = ['.ll', '.c', '.cpp', '.test']; if not 'ARM' in config.root.targets:; config.unsupported = True. Other platform-specific tests are those that depend on a specific feature; of a specific sub-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you'",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:18183,config,configuration,18183,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,1,['config'],['configuration']
Modifiability,"stem-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ### List of VAF-specific variables. There are some special variables that need to be set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default one configured on your RMS; will be used. ### Remote environment configuration. All the PoD commands sent to the VAF master will live in the environment; loaded via using the following scripts. Similarly to the local environment, configuration is split in different files; to allow for a system-wide configuration, which has precedence over; user's configuration in the home directory. If a script cannot be found,; it will be silently skipped. - `<output_of_payload>`. - `common.before`. - `remote.before`. - `remote.conf`. - `common.after`. - `remote.after`. For an explanation on how to pass extra data to the workers sa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:3925,variab,variable,3925,proof/doc/confman/UsingVirtualAnalysisFacility.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md,2,"['config', 'variab']","['configuration', 'variable']"
Modifiability,"stent store to the same; address, the first store can be erased. This transformation is not allowed for a; pair of volatile stores. On the other hand, a non-volatile non-atomic load can; be moved across a volatile load freely, but not an Acquire load. This document is intended to provide a guide to anyone either writing a frontend; for LLVM or working on optimization passes for LLVM with a guide for how to deal; with instructions with special semantics in the presence of concurrency. This; is not intended to be a precise guide to the semantics; the details can get; extremely complicated and unreadable, and are not usually necessary. .. _Optimization outside atomic:. Optimization outside atomic; ===========================. The basic ``'load'`` and ``'store'`` allow a variety of optimizations, but can; lead to undefined results in a concurrent environment; see `NotAtomic`_. This; section specifically goes into the one optimizer restriction which applies in; concurrent environments, which gets a bit more of an extended description; because any optimization dealing with stores needs to be aware of it. From the optimizer's point of view, the rule is that if there are not any; instructions with atomic ordering involved, concurrency does not matter, with; one exception: if a variable might be visible to another thread or signal; handler, a store cannot be inserted along a path where it might not execute; otherwise. Take the following example:. .. code-block:: c. /* C code, for readability; run through clang -O2 -S -emit-llvm to get; equivalent IR */; int x;; void f(int* a) {; for (int i = 0; i < 100; i++) {; if (a[i]); x += 1;; }; }. The following is equivalent in non-concurrent situations:. .. code-block:: c. int x;; void f(int* a) {; int xtemp = x;; for (int i = 0; i < 100; i++) {; if (a[i]); xtemp += 1;; }; x = xtemp;; }. However, LLVM is not allowed to transform the former to the latter: it could; indirectly introduce undefined behavior if another thread can access ``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:2753,extend,extended,2753,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['extend'],['extended']
Modifiability,"ster; which is silent by default. Try this once then check the log file; ``<buildbot-worker-root-directory>/worker/twistd.log``. If your settings; are correct you will see a refused connection. This is good and expected,; as the credentials have not been established on both ends. Now stop the; worker and proceed to the next steps. #. Fill the buildbot-worker description and admin name/e-mail. Here is an; example of the buildbot-worker description::. Windows 7 x64; Core i7 (2.66GHz), 16GB of RAM. g++.exe (TDM-1 mingw32) 4.4.0; GNU Binutils 2.19.1; cmake version 2.8.4; Microsoft(R) 32-bit C/C++ Optimizing Compiler Version 16.00.40219.01 for 80x86. See `here <http://docs.buildbot.net/current/manual/installation/worker.html>`_; for which files to edit. #. Send a patch which adds your build worker and your builder to; `zorg <https://github.com/llvm/llvm-zorg>`_. Use the typical LLVM; `workflow <https://llvm.org/docs/Contributing.html#how-to-submit-a-patch>`_. * workers are added to ``buildbot/osuosl/master/config/workers.py``; * builders are added to ``buildbot/osuosl/master/config/builders.py``. Please make sure your builder name and its builddir are unique through the; file. All new builders should default to using the ""'collapseRequests': False""; configuration. This causes the builder to build each commit individually; and not merge build requests. To maximize quality of feedback to developers,; we *strongly prefer* builders to be configured not to collapse requests.; This flag should be removed only after all reasonable efforts have been; exhausted to improve build times such that the builder can keep up with; commit flow. It is possible to allow email addresses to unconditionally receive; notifications on build failure; for this you'll need to add an; ``InformativeMailNotifier`` to ``buildbot/osuosl/master/config/status.py``.; This is particularly useful for the staging buildmaster which is silent; otherwise. #. Send the buildbot-worker access name and the access pa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst:5334,config,config,5334,interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,1,['config'],['config']
Modifiability,"sters. `TargetInstrInfo::isLoadFromStackSlotPostFE` and; `TargetInstrInfo::isStoreToStackSlotPostFE` are needed to identify spill and; restore instructions. Each should return the destination or source register; respectively. `LiveDebugValues` will track the movement of a value from / to; the stack slot. In addition, any instruction that writes to a stack spill; should have a `MachineMemoryOperand` attached, so that `LiveDebugValues` can; recognise that a slot has been clobbered. ## Target-specific optimisation instrumentation. Optimisations come in two flavours: those that mutate a `MachineInstr` to make; it do something different, and those that create a new instruction to replace; the operation of the old. The former _must_ be instrumented -- the relevant question is whether any; register def in any operand will produce a different value, as a result of the; mutation. If the answer is yes, then there is a risk that a `DBG_INSTR_REF`; instruction referring to that operand will end up assigning the different; value to a variable, presenting the debugging developer with an unexpected; variable value. In such scenarios, call `MachineInstr::dropDebugNumber()` on the; mutated instruction to erase its instruction number. Any `DBG_INSTR_REF`; referring to it will produce an empty variable location instead, that appears; as ""optimised out"" in the debugger. For the latter flavour of optimisation, to increase coverage you should record; an instruction number substitution: a mapping from the old instruction number /; operand pair to new instruction number / operand pair. Consider if we replace; a three-address add instruction with a two-address add:. ```text; %2:gr32 = ADD32rr %0, %1, debug-instr-number 1; ```. becomes. ```text; %2:gr32 = ADD32rr %0(tied-def 0), %1, debug-instr-number 2; ```. With a substitution from ""instruction number 1 operand 0"" to ""instruction number; 2 operand 0"" recorded in the `MachineFunction`. In `LiveDebugValues`,; `DBG_INSTR_REF`s will be mapped ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md:6837,variab,variable,6837,interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrRefDebugInfo.md,2,['variab'],['variable']
Modifiability,"sting DWARF expressions can retain their; current semantic meaning. DWARF has implicit conversions that convert from a; value that represents an address in the default address space to a memory; location description. This can be extended to allow a default address space; memory location description to be implicitly converted back to its address; value. This allows all DWARF Version 5 expressions to retain their same meaning,; while enabling the ability to explicitly create memory location descriptions in; non-default address spaces and generalizing the power of composite location; descriptions to any kind of location description. For those familiar with the definition of location descriptions in DWARF Version; 5, the definitions in these extensions are presented differently, but does in; fact define the same concept with the same fundamental semantics. However, it; does so in a way that allows the concept to extend to support address spaces,; bit addressing, the ability for composite location descriptions to be composed; of any kind of location description, and the ability to support objects located; at multiple places. Collectively these changes expand the set of architectures; that can be supported and improves support for optimized code. Several approaches were considered, and the one presented, together with the; extensions it enables, appears to be the simplest and cleanest one that offers; the greatest improvement of DWARF's ability to support debugging optimized GPU; and non-GPU code. Examining the GDB debugger and LLVM compiler, it appears only; to require modest changes as they both already have to support general use of; location descriptions. It is anticipated that will also be the case for other; debuggers and compilers. GDB has been modified to evaluate DWARF Version 5 expressions with location; descriptions as stack entries and with implicit conversions. All GDB tests have; passed, except one that turned out to be an invalid test case by DWARF Version 5",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:6588,extend,extend,6588,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['extend'],['extend']
Modifiability,"stitution list, ``config.substitutions``. Each item in the list is a tuple; consisting of a pattern and its replacement, which lit applies using python's; ``re.sub`` function.; - To define substitutions within a single test file, lit supports the; ``DEFINE:`` and ``REDEFINE:`` directives, described in detail below. So that; they have no effect on other test files, these directives modify a copy of the; substitution list that is produced by lit configuration files. For example, the following directives can be inserted into a test file to define; ``%{cflags}`` and ``%{fcflags}`` substitutions with empty initial values, which; serve as the parameters of another newly defined ``%{check}`` substitution:. .. code-block:: llvm. ; DEFINE: %{cflags} =; ; DEFINE: %{fcflags} =. ; DEFINE: %{check} = \; ; DEFINE: %clang_cc1 -verify -fopenmp -fopenmp-version=51 %{cflags} \; ; DEFINE: -emit-llvm -o - %s | \; ; DEFINE: FileCheck %{fcflags} %s. Alternatively, the above substitutions can be defined in a lit configuration; file to be shared with other test files. Either way, the test file can then; specify directives like the following to redefine the parameter substitutions as; desired before each use of ``%{check}`` in a ``RUN:`` line:. .. code-block:: llvm. ; REDEFINE: %{cflags} = -triple x86_64-apple-darwin10.6.0 -fopenmp-simd; ; REDEFINE: %{fcflags} = -check-prefix=SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-unknown-linux-gnu -fopenmp-simd; ; REDEFINE: %{fcflags} = -check-prefix=SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-apple-darwin10.6.0; ; REDEFINE: %{fcflags} = -check-prefix=NO-SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-unknown-linux-gnu; ; REDEFINE: %{fcflags} = -check-prefix=NO-SIMD; ; RUN: %{check}. Besides providing initial values, the initial ``DEFINE:`` directives for the; parameter substitutions in the above example serve a second purpose: they; establish the substitution order so that both ``%{check}`` and its par",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:29799,config,configuration,29799,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,1,['config'],['configuration']
Modifiability,"stract target description interfaces:; .. _implement the target description:. Target-specific Implementation Notes; ====================================. This section of the document explains features or design decisions that are; specific to the code generator for a particular target. .. _tail call section:. Tail call optimization; ----------------------. Tail call optimization, callee reusing the stack of the caller, is currently; supported on x86/x86-64, PowerPC, AArch64, and WebAssembly. It is performed on; x86/x86-64, PowerPC, and AArch64 if:. * Caller and callee have the calling convention ``fastcc``, ``cc 10`` (GHC; calling convention), ``cc 11`` (HiPE calling convention), ``tailcc``, or; ``swifttailcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Option ``-tailcallopt`` is enabled or the calling convention is ``tailcc``. * Platform-specific constraints are met. x86/x86-64 constraints:. * No variable argument lists are used. * On x86-64 when generating GOT/PIC code only module-local calls (visibility =; hidden or protected) are supported. PowerPC constraints:. * No variable argument lists are used. * No byval parameters are used. * On ppc32/64 GOT/PIC only module-local calls (visibility = hidden or protected); are supported. WebAssembly constraints:. * No variable argument lists are used. * The 'tail-call' target attribute is enabled. * The caller and callee's return types must match. The caller cannot; be void unless the callee is, too. AArch64 constraints:. * No variable argument lists are used. Example:. Call as ``llc -tailcallopt test.ll``. .. code-block:: llvm. declare fastcc i32 @tailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4). define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {; %l1 = add i32 %in1, %in2; %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1); ret i32 %tmp; }. Implications of ``-tailcallopt``:. To support tail call op",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:86869,variab,variable,86869,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['variab'],['variable']
Modifiability,"string; is specified by *length*; if not specified, the rest of the string is; extracted. The *start* and *length* arguments must be integers. ``!tail(``\ *a*\ ``)``; This operator produces a new list with all the elements; of the list *a* except for the zeroth one. (See also ``!head``.). ``!tolower(``\ *a*\ ``)``; This operator converts a string input *a* to lower case. ``!toupper(``\ *a*\ ``)``; This operator converts a string input *a* to upper case. ``!xor(``\ *a*\ ``,`` *b*\ ``, ...)``; This operator does a bitwise EXCLUSIVE OR on *a*, *b*, etc., and produces; the result. A logical XOR can be performed if all the arguments are either; 0 or 1. Appendix B: Paste Operator Examples; ===================================. Here is an example illustrating the use of the paste operator in record names. .. code-block:: text. defvar suffix = ""_suffstring"";; defvar some_ints = [0, 1, 2, 3];. def name # suffix {; }. foreach i = [1, 2] in {; def rec # i {; }; }. The first ``def`` does not use the value of the ``suffix`` variable. The; second def does use the value of the ``i`` iterator variable, because it is not a; global name. The following records are produced. .. code-block:: text. def namesuffix {; }; def rec1 {; }; def rec2 {; }. Here is a second example illustrating the paste operator in field value expressions. .. code-block:: text. def test {; string strings = suffix # suffix;; list<int> integers = some_ints # [4, 5, 6];; }. The ``strings`` field expression uses ``suffix`` on both sides of the paste; operator. It is evaluated normally on the left hand side, but taken verbatim; on the right hand side. The ``integers`` field expression uses the value of; the ``some_ints`` variable and a literal list. The following record is; produced. .. code-block:: text. def test {; string strings = ""_suffstringsuffix"";; list<int> ints = [0, 1, 2, 3, 4, 5, 6];; }. Appendix C: Sample Record; =========================. One target machine supported by LLVM is the Intel x86. The following",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:74179,variab,variable,74179,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['variab'],['variable']
Modifiability,"strings that contain `}}` or `{{`, the; string-mode parser accepts opening delimiters of more than two curly braces,; like `{{{`. It then looks for a closing delimiter of equal ""width"" (i.e `}}}`).; For example:. .. code-block:: c++. // expected-note {{{evaluates to '{{2, 3, 4}} == {0, 3, 4}'}}}. The intent is to allow the delimeter to be wider than the longest `{` or `}`; brace sequence in the content, so that if your expected text contains `{{{`; (three braces) it may be delimited with `{{{{` (four braces), and so on. Regex matching mode may be selected by appending ``-re`` to the diagnostic type; and including regexes wrapped in double curly braces (`{{` and `}}`) in the; directive, such as:. .. code-block:: text. expected-error-re {{format specifies type 'wchar_t **' (aka '{{.+}}')}}. Examples matching error: ""variable has incomplete type 'struct s'"". .. code-block:: c++. // expected-error {{variable has incomplete type 'struct s'}}; // expected-error {{variable has incomplete type}}; // expected-error {{{variable has incomplete type}}}; // expected-error {{{{variable has incomplete type}}}}. // expected-error-re {{variable has type 'struct {{.}}'}}; // expected-error-re {{variable has type 'struct {{.*}}'}}; // expected-error-re {{variable has type 'struct {{(.*)}}'}}; // expected-error-re {{variable has type 'struct{{[[:space:]](.*)}}'}}. Feature Test Macros; ===================; Clang implements several ways to test whether a feature is supported or not.; Some of these feature tests are standardized, like ``__has_cpp_attribute`` or; ``__cpp_lambdas``, while others are Clang extensions, like ``__has_builtin``.; The common theme among all the various feature tests is that they are a utility; to tell users that we think a particular feature is complete. However,; completeness is a difficult property to define because features may still have; lingering bugs, may only work on some targets, etc. We use the following; criteria when deciding whether to expose a featur",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:162182,variab,variable,162182,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,4,['variab'],['variable']
Modifiability,"struction's memory access to go to; the specified segment. LLVM address space 0 is the default address space, which; includes the stack, and any unqualified memory accesses in a program. Address; spaces 1-255 are currently reserved for user-defined code. The GS-segment is; represented by address space 256, the FS-segment is represented by address space; 257, and the SS-segment is represented by address space 258. Other x86 segments; have yet to be allocated address space numbers. While these address spaces may seem similar to TLS via the ``thread_local``; keyword, and often use the same underlying hardware, there are some fundamental; differences. The ``thread_local`` keyword applies to global variables and specifies that they; are to be allocated in thread-local memory. There are no type qualifiers; involved, and these variables can be pointed to with normal pointers and; accessed with normal loads and stores. The ``thread_local`` keyword is; target-independent at the LLVM IR level (though LLVM doesn't yet have; implementations of it for some configurations). Special address spaces, in contrast, apply to static types. Every load and store; has a particular address space in its address operand type, and this is what; determines which address space is accessed. LLVM ignores these special address; space qualifiers on global variables, and does not provide a way to directly; allocate storage in them. At the LLVM IR level, the behavior of these special; address spaces depends in part on the underlying OS or runtime environment, and; they are specific to x86 (and LLVM doesn't yet handle them correctly in some; cases). Some operating systems and runtime environments use (or may in the future use); the FS/GS-segment registers for various low-level purposes, so care should be; taken when considering them. Instruction naming; ^^^^^^^^^^^^^^^^^^. An instruction name consists of the base name, a default operand size, and a; character per operand with an optional special size. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:92985,config,configurations,92985,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['config'],['configurations']
Modifiability,"strumented code simply won't be accounted for in reports. To compile code with Modified Condition/Decision Coverage (MC/DC) enabled,; pass ``-fcoverage-mcdc`` in addition to the clang options specified above.; MC/DC is an advanced form of code coverage most applicable in the embedded; space. Running the instrumented program; ================================. The next step is to run the instrumented program. When the program exits it; will write a **raw profile** to the path specified by the ``LLVM_PROFILE_FILE``; environment variable. If that variable does not exist, the profile is written; to ``default.profraw`` in the current directory of the program. If; ``LLVM_PROFILE_FILE`` contains a path to a non-existent directory, the missing; directory structure will be created. Additionally, the following special; **pattern strings** are rewritten:. * ""%p"" expands out to the process ID. * ""%h"" expands out to the hostname of the machine running the program. * ""%t"" expands out to the value of the ``TMPDIR`` environment variable. On; Darwin, this is typically set to a temporary scratch directory. * ""%Nm"" expands out to the instrumented binary's signature. When this pattern; is specified, the runtime creates a pool of N raw profiles which are used for; on-line profile merging. The runtime takes care of selecting a raw profile; from the pool, locking it, and updating it before the program exits. If N is; not specified (i.e the pattern is ""%m""), it's assumed that ``N = 1``. The; merge pool specifier can only occur once per filename pattern. * ""%c"" expands out to nothing, but enables a mode in which profile counter; updates are continuously synced to a file. This means that if the; instrumented program crashes, or is killed by a signal, perfect coverage; information can still be recovered. Continuous mode does not support value; profiling for PGO, and is only supported on Darwin at the moment. Support for; Linux may be mostly complete but requires testing, and support for Window",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst:2747,variab,variable,2747,interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,1,['variab'],['variable']
Modifiability,"sual C++ compatibility fixes. N: Patrick Jenkins; E: patjenk@wam.umd.edu; D: Nightly Tester. N: Tony(Yanjun) Jiang; E: jtony@ca.ibm.com; D: PowerPC Backend Developer; D: Improvements to the PPC backend and miscellaneous bug fixes. N: Dale Johannesen; E: dalej@apple.com; D: ARM constant islands improvements; D: Tail merging improvements; D: Rewrite X87 back end; D: Use APFloat for floating point constants widely throughout compiler; D: Implement X87 long double. N: Brad Jones; E: kungfoomaster@nondot.org; D: Support for packed types. N: Rod Kay; E: rkay@auroraux.org; D: Author of LLVM Ada bindings. N: Erich Keane; E: erich.keane@intel.com; D: A variety of Clang contributions including function multiversioning, regcall/vectorcall.; I: ErichKeane. N: Eric Kidd; W: http://randomhacks.net/; D: llvm-config script. N: Anton Korobeynikov; E: anton at korobeynikov dot info; D: Mingw32 fixes, cross-compiling support, stdcall/fastcall calling conv.; D: x86/linux PIC codegen, aliases, regparm/visibility attributes; D: Switch lowering refactoring. N: Sumant Kowshik; E: kowshik@uiuc.edu; D: Author of the original C backend. N: Benjamin Kramer; E: benny.kra@gmail.com; D: Miscellaneous bug fixes. N: Michael Kuperstein; E: mkuper@google.com; D: Loop Vectorizer. N: Sundeep Kushwaha; E: sundeepk@codeaurora.org; D: Implemented DFA-based target independent VLIW packetizer. N: Christopher Lamb; E: christopher.lamb@gmail.com; D: aligned load/store support, parts of noalias and restrict support; D: vreg subreg infrastructure, X86 codegen improvements based on subregs; D: address spaces. N: Jim Laskey; E: jlaskey@apple.com; D: Improvements to the PPC backend, instruction scheduling; D: Debug and Dwarf implementation; D: Auto upgrade mangler; D: llvm-gcc4 svn wrangler. N: Chris Lattner; E: sabre@nondot.org; W: http://nondot.org/~sabre/; D: Primary architect of LLVM. N: Tanya Lattner (Tanya Brethour); E: tonic@nondot.org; W: http://nondot.org/~tonic/; D: The initial llvm-ar tool, converted reg",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CREDITS.TXT:6520,refactor,refactoring,6520,interpreter/llvm-project/llvm/CREDITS.TXT,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CREDITS.TXT,1,['refactor'],['refactoring']
Modifiability,"submodules of this package expose their own `RDataFrame` objects. The only needed change in user code is to substitute `ROOT.RDataFrame` calls with such backend-specific `RDataFrame`s. For example:. ```python; import ROOT. # Point RDataFrame calls to the Spark specific RDataFrame; RDataFrame = ROOT.RDF.Experimental.Distributed.Spark.RDataFrame. # It still accepts the same constructor arguments as traditional RDataFrame; df = RDataFrame(""mytree"",""myfile.root""). # Continue the application with the traditional RDataFrame API; ```. The main goal of this package is to support running any RDataFrame application distributedly. Nonetheless, not all RDataFrame operations currently work with this package. The subset that is currently available is:. - AsNumpy; - Count; - Define; - Fill; - Filter; - Graph; - Histo[1,2,3]D; - Max; - Mean; - Min; - Profile[1,2,3]D; - Snapshot; - Sum. with support for more operations coming in the future. Any distributed RDataFrame backend inherits the dependencies of the underlying software needed to distribute the applications. The Spark backend for example has the following runtime dependencies (ROOT will build just fine without, but the feature will be unavailable without these packages):. - [pyspark](https://spark.apache.org/docs/latest/api/python/index.html), that in turn has its own set of dependencies:; - [Java](https://www.java.com/en/); - [py4j](https://www.py4j.org/). Tests for the Spark backend can be turned ON/OFF with the new build option `test_distrdf_pyspark` (OFF by default). ## Histogram Libraries. ## Math Libraries. - Update the definitions of the physical constants using the recommended 2018 values from NIST.; - Use also the new SI definition of base units from 2019, where the Planck constant, the Boltzmann constant, the elementary electric charge and the Avogadro constant are exact numerical values. See <https://en.wikipedia.org/wiki/2019_redefinition_of_the_SI_base_units>. Note that with this new definition the functions `TMat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:11530,inherit,inherits,11530,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['inherit'],['inherits']
Modifiability,"substitution list by default. In this case, a substitution must; have been inserted earlier in the substitution list than any substitution; appearing in its value in order for the latter to expand. (For greater; flexibility, you can enable multiple passes through the substitution list by; setting `recursiveExpansionLimit`_ in a lit configuration file.); - While lit configuration files can insert anywhere in the substitution list,; the insertion behavior of the ``DEFINE:`` and ``REDEFINE:`` directives is; specified below and is designed specifically for the use case presented in the; example above.; - Defining a substitution in terms of itself, whether directly or via other; substitutions, should be avoided. It usually produces an infinitely recursive; definition that cannot be fully expanded. It does *not* define the; substitution in terms of its previous value, even when using ``REDEFINE:``. The relationship between the ``DEFINE:`` and ``REDEFINE:`` directive is; analogous to the relationship between a variable declaration and variable; assignment in many programming languages:. - ``DEFINE: %{name} = value``. This directive assigns the specified value to a new substitution whose; pattern is ``%{name}``, or it reports an error if there is already a; substitution whose pattern contains ``%{name}`` because that could produce; confusing expansions (e.g., a lit configuration file might define a; substitution with the pattern ``%{name}\[0\]``). The new substitution is; inserted at the start of the substitution list so that it will expand first.; Thus, its value can contain any substitution previously defined, whether in; the same test file or in a lit configuration file, and both will expand. - ``REDEFINE: %{name} = value``. This directive assigns the specified value to an existing substitution whose; pattern is ``%{name}``, or it reports an error if there are no substitutions; with that pattern or if there are multiple substitutions whose patterns; contain ``%{name}``. T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:32451,variab,variable,32451,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,2,['variab'],['variable']
Modifiability,"substitution; Yes. 310; C99; Add non-corner case example of trigraphs; Yes. 311; C99; Definition of variably modified types; Yes. 312; C99; Meaning of ""known constant size""; Yes. 313; NAD; Incomplete arrays of VLAs; Yes. 314; NAD; Cross-translation-unit tagged type compatibility; Unknown. 315; C99; Implementation-defined bit-field types; Yes. 316; NAD; Unprototyped function types; Yes. 317; NAD; Function definitions with empty parentheses; Yes. 318; C99; (double)0.1f with FLT_EVAL_METHOD being 2; Unknown. 319; NAD; printf(""%a"", 1.0) and trailing zeros; N/A. 320; C99; Scope of variably modified type; Yes. 321; C99; Wide character code values for members of the basic character set; Yes. 322; C99; Problem with TC2 Change #67 (Add perror to the list defining byte input/output functions); N/A. 323; C99; Potential problems with TC2 #34, #35, and #36; N/A. 324; C99; Tokenization obscurities; Yes. 325; NAD; strerror(); N/A. 326; C99; asctime(); N/A. 327; C99; Italicize definition of variable length array type, add forward references; Yes. 328; C99; String literals in compound literal initialization. Partial; Clang properly implements the use of string literals in a compound; literal initializer, but fails to diagnose use of a variably-modified; type at file scope. DR339 (about variably-modified types) is marked as; a duplicate of DR328.; . 329; C99; Math functions and directed rounding; N/A. 330; C99; Externally visible exceptional conditions; N/A. 331; NAD; permit FE_DIVBYZERO when errno says EDOM; N/A. 332; C99; gets is generally unsafe; N/A. 333; C99; Missing Predefined Macro Name; Yes. 334; Open; Missing semantics of comparison macros; Not resolved. 335; NAD; _Bool bit-fields; Yes. 336; C99; What does TMP_MAX actually indicate?; N/A. 337; C99; stdio.h macro definition problems; N/A. 338; C99; C99 seems to exclude indeterminate value from being an uninitialized register; Yes. 339; Dup; Variably modified compound literal; Duplicate of 328. 340; C99; Composite types for var",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_dr_status.html:19919,variab,variable,19919,interpreter/llvm-project/clang/www/c_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_dr_status.html,1,['variab'],['variable']
Modifiability,"substream's contents will; be described in detail :ref:`below <dbi_substreams>`. The length of the entire; DBI Stream should equal ``64`` (the length of the header above) plus the value; of each of the following ``7`` fields. - **ModInfoSize** - The length of the :ref:`dbi_mod_info_substream`. - **SectionContributionSize** - The length of the :ref:`dbi_sec_contr_substream`. - **SectionMapSize** - The length of the :ref:`dbi_section_map_substream`. - **SourceInfoSize** - The length of the :ref:`dbi_file_info_substream`. - **TypeServerMapSize** - The length of the :ref:`dbi_type_server_map_substream`. - **OptionalDbgHeaderSize** - The length of the :ref:`dbi_optional_dbg_stream`. - **ECSubstreamSize** - The length of the :ref:`dbi_ec_substream`. .. _dbi_substreams:. Substreams; ==========. .. _dbi_mod_info_substream:. Module Info Substream; ^^^^^^^^^^^^^^^^^^^^^. Begins at offset ``0`` immediately after the :ref:`header <dbi_header>`. The; module info substream is an array of variable-length records, each one; describing a single module (e.g. object file) linked into the program. Each; record in the array has the format:. .. code-block:: c++. struct ModInfo {; uint32_t Unused1;; struct SectionContribEntry {; uint16_t Section;; char Padding1[2];; int32_t Offset;; int32_t Size;; uint32_t Characteristics;; uint16_t ModuleIndex;; char Padding2[2];; uint32_t DataCrc;; uint32_t RelocCrc;; } SectionContr;; uint16_t Flags;; uint16_t ModuleSymStream;; uint32_t SymByteSize;; uint32_t C11ByteSize;; uint32_t C13ByteSize;; uint16_t SourceFileCount;; char Padding[2];; uint32_t Unused2;; uint32_t SourceFileNameIndex;; uint32_t PdbFilePathNameIndex;; char ModuleName[];; char ObjFileName[];; };. - **SectionContr** - Describes the properties of the section in the final binary; which contain the code and data from this module. ``SectionContr.Characteristics`` corresponds to the ``Characteristics`` field; of the `IMAGE_SECTION_HEADER <https://msdn.microsoft.com/en-us/library/windows/desk",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst:5652,variab,variable-length,5652,interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst,1,['variab'],['variable-length']
Modifiability,"such as. .. code-block:: c. for (int i = 1; i < n; i+=1) { // original loop; A[i] = i;; B[i] = 2 + B[i];; C[i] = 3 + C[i - 1];; }. into the following code:. .. code-block:: c. if (rtc) {; for (int i = 1; i < n; i+=1) // coincident loop; A[i] = i;; for (int i = 1; i < n; i+=1) // coincident loop; B[i] = 2 + B[i];; for (int i = 1; i < n; i+=1) // sequential loop; C[i] = 3 + C[i - 1];; } else {; for (int i = 1; i < n; i+=1) { // fallback loop; A[i] = i;; B[i] = 2 + B[i];; C[i] = 3 + C[i - 1];; }; }. where ``rtc`` is a generated runtime check. ``llvm.loop.distribute.followup_coincident`` sets the loop attributes of; all loops without loop-carried dependencies (i.e. vectorizable loops).; There might be more than one such loops. If not defined, the loops will; inherit the original loop's attributes. ``llvm.loop.distribute.followup_sequential`` sets the loop attributes of the; loop with potentially unsafe dependencies. There should be at most one; such loop. If not defined, the loop will inherit the original loop's; attributes. ``llvm.loop.distribute.followup_fallback`` defines the loop attributes; for the fallback loop, which is a copy of the original loop for when; loop versioning is required. If undefined, the fallback loop inherits; all attributes from the original loop. Attributes defined in ``llvm.loop.distribute.followup_all`` are added to; all of the aforementioned output loops. It is recommended to add ``llvm.loop.disable_nonforced`` to; ``llvm.loop.distribute.followup_fallback``. This avoids that the; fallback version (which is likely never executed) is further optimized; which would increase the code size. Versioning LICM; ---------------. The pass hoists code out of loops that are only loop-invariant when; dynamic conditions apply. For instance, it transforms the loop. .. code-block:: c. for (int i = 0; i < n; i+=1) // original loop; A[i] = B[0];. into:. .. code-block:: c. if (rtc) {; auto b = B[0];; for (int i = 0; i < n; i+=1) // versioned loop; A[i] = b;; } e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:12103,inherit,inherit,12103,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst,1,['inherit'],['inherit']
Modifiability,"symbols whose definitions are external; that is, accessible from; other files. .. option:: --format=<format>, -f. Select an output format; *format* may be *sysv*, *posix*, *darwin*, *bsd* or; *just-symbols*.; The default is *bsd*. .. option:: --help, -h. Print a summary of command-line options and their meanings. .. option:: -j. Print just the symbol names. Alias for `--format=just-symbols``. .. option:: --line-numbers, -l. Use debugging information to print the filenames and line numbers where; symbols are defined. Undefined symbols have the location of their first; relocation printed instead. .. option:: -m. Use Darwin format. Alias for ``--format=darwin``. .. option:: --no-demangle. Don't demangle symbol names. This is the default. .. option:: --no-llvm-bc. Disable the LLVM bitcode reader. .. option:: --no-sort, -p. Show symbols in the order encountered. .. option:: --no-weak, -W. Don't print weak symbols. .. option:: --numeric-sort, -n, -v. Sort symbols by address. .. option:: --portability, -P. Use POSIX.2 output format. Alias for ``--format=posix``. .. option:: --print-armap. Print the archive symbol table, in addition to the symbols. .. option:: --print-file-name, -A, -o. Precede each symbol with the file it came from. .. option:: --print-size, -S. Show symbol size as well as address (not applicable for Mach-O). .. option:: --quiet. Suppress 'no symbols' diagnostic. .. option:: --radix=<RADIX>, -t. Specify the radix of the symbol address(es). Values accepted are *d* (decimal),; *x* (hexadecimal) and *o* (octal). .. option:: --reverse-sort, -r. Sort symbols in reverse order. .. option:: --size-sort. Sort symbols by size. .. option:: --special-syms. Do not filter special symbols from the output. .. option:: --undefined-only, -u. Print only undefined symbols. .. option:: --version, -V. Display the version of the :program:`llvm-nm` executable, then exit. Does not; stack with other commands. .. option:: @<FILE>. Read command-line options from response file `<FILE>",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst:5285,portab,portability,5285,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst,1,['portab'],['portability']
Modifiability,"t > 1) {; std::string simCountStr = std::to_string(static_cast<double>(_simCount));; ctx.addToCodeBody(resName + "" += "" + weightSumName + "" * std::log("" + simCountStr + "");\n"");; }; ... }; ```. > Source: - [RooNLLVarNew](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooNLLVarNew.cxx). The complexity of the `RooNLLVarNew::translate()` function in this example can; be attributed to the more complex scenarios/operations specific to the; computation of negative log-likelihood (NLL) values for probability density; functions (PDFs) in RooFit, especially for simultaneous fits (multiple; simultaneous PDFs being considered) and binned likelihoods (adding further; complexity). In this example, the `RooNLLVarNew::translate()` function generates code to; compute the Negative Log likelihood (NLL). We can see that the intermediate; result variable `resName` is added to the context so that it can be accessed; and used in the generated code. This variable is made available globally; (using `addToGlobalScope()`). If a weight sum is needed, then it creates a loop, and `weightSumName` is; accumulated with the weight variable. Otherwise, if there are multiple; simultaneous PDFs, then it adds a term to the result that scales with the; logarithm of the count of simultaneous PDFs. The rest of the function body; (including the loop scope with NLL computation) has omitted from this example; to keep it brief. Helper functions:. - `makeValidVarName()` helps get a valid name from the name of the respective; RooFit class. It then helps save it to the variable that represents the result; of this class (the squashed code/ C++ function that will be created). - `addToGlobalScope()` helps declare and initialize the results variable, so; that it can be available globally (throughout the function body). For local; variables, the `addToCodeBody()` function can be used to keep the variables in; the respective scope (for example, within a loop). - `beginLoop()` helps build the st",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md:16650,variab,variable,16650,roofit/doc/developers/roofit_ad.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md,1,['variab'],['variable']
Modifiability,"t CUs and so a ``buffer_inv sc0`` is required which will invalidate; the L1 cache. * A ``buffer_inv sc0`` is required to invalidate the L1 cache for coherence; between wavefronts executing in different work-groups as they may be; executing on different CUs. * Atomic read-modify-write instructions implicitly bypass the L1 cache.; Therefore, they do not use the sc0 bit for coherence and instead use it to; indicate if the instruction returns the original value being updated. They; do use sc1 to indicate system or agent scope coherence. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache. * The gfx942 can be configured as a number of smaller agents with each having; a single L2 shared by all CUs on the same agent, or as fewer (possibly one); larger agents with groups of CUs on each agent each sharing separate L2; caches.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel for its associated L2.; Therefore, the vector and scalar memory operations performed by wavefronts; executing with different L1 caches and the same L2 cache can be reordered; relative to each other.; * A ``s_waitcnt vmcnt(0)`` is required to ensure synchronization between; vector memory operations of different CUs. It ensures a previous vector; memory operation has completed before executing a subsequent vector memory; or LDS operation and so can be used to meet the requirements of acquire and; release.; * An L2 cache can be kept coherent with other L2 caches by using the MTYPE RW; (read-write) for memory local to the L2, and MTYPE NC (non-coherent) with; the PTE C-bit set for memory not local to the L2. * Any local memory cache",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:287317,config,configured,287317,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['config'],['configured']
Modifiability,"t Public Members of the ``Module`` class; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. * ``Module::Module(std::string name = """")``. Constructing a Module_ is easy. You can optionally provide a name for it; (probably based on the name of the translation unit). * | ``Module::iterator`` - Typedef for function list iterator; | ``Module::const_iterator`` - Typedef for const_iterator.; | ``begin()``, ``end()``, ``size()``, ``empty()``. These are forwarding methods that make it easy to access the contents of a; ``Module`` object's :ref:`Function <c_Function>` list. * ``Module::FunctionListType &getFunctionList()``. Returns the list of :ref:`Function <c_Function>`\ s. This is necessary to use; when you need to update the list or perform a complex action that doesn't have; a forwarding method. ----------------. * | ``Module::global_iterator`` - Typedef for global variable list iterator; | ``Module::const_global_iterator`` - Typedef for const_iterator.; | ``Module::insertGlobalVariable()`` - Inserts a global variable to the list.; | ``Module::removeGlobalVariable()`` - Removes a global variable from the list.; | ``Module::eraseGlobalVariable()`` - Removes a global variable from the list and deletes it.; | ``global_begin()``, ``global_end()``, ``global_size()``, ``global_empty()``. These are forwarding methods that make it easy to access the contents of a; ``Module`` object's GlobalVariable_ list. ----------------. * ``SymbolTable *getSymbolTable()``. Return a reference to the SymbolTable_ for this ``Module``. ----------------. * ``Function *getFunction(StringRef Name) const``. Look up the specified function in the ``Module`` SymbolTable_. If it does not; exist, return ``null``. * ``FunctionCallee getOrInsertFunction(const std::string &Name,; const FunctionType *T)``. Look up the specified function in the ``Module`` SymbolTable_. If; it does not exist, add an external declaration for the function and; return it. Note that the function signature already present may not; mat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:139124,variab,variable,139124,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['variab'],['variable']
Modifiability,"t ``dealloc`` is really far too late; for the object to be raising such objections. Somewhat more legitimately, an; object may have been pool-allocated and should not be deallocated with; ``free``; for now, this can only be supported with a ``dealloc``; implementation outside of ARC. Such an implementation must be very careful; to do all the other work that ``NSObject``'s ``dealloc`` would, which is; outside the scope of this document to describe. The instance variables for an ARC-compiled class will be destroyed at some; point after control enters the ``dealloc`` method for the root class of the; class. The ordering of the destruction of instance variables is unspecified,; both within a single class and between subclasses and superclasses. .. admonition:: Rationale. The traditional, non-ARC pattern for destroying instance variables is to; destroy them immediately before calling ``[super dealloc]``. Unfortunately,; message sends from the superclass are quite capable of reaching methods in; the subclass, and those methods may well read or write to those instance; variables. Making such message sends from dealloc is generally discouraged,; since the subclass may well rely on other invariants that were broken during; ``dealloc``, but it's not so inescapably dangerous that we felt comfortable; calling it undefined behavior. Therefore we chose to delay destroying the; instance variables to a point at which message sends are clearly disallowed:; the point at which the root class's deallocation routines take over. In most code, the difference is not observable. It can, however, be observed; if an instance variable holds a strong reference to an object whose; deallocation will trigger a side-effect which must be carefully ordered with; respect to the destruction of the super class. Such code violates the design; principle that semantically important behavior should be explicit. A simple; fix is to clear the instance variable manually during ``dealloc``; a more; holistic solu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:89349,variab,variables,89349,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['variab'],['variables']
Modifiability,"t and bayesian; confidence intervals as well as a function for combining several efficiencies.; Example of usage: Creating a TEfficiency object; ; If you start a new analysis, it is highly recommended to use the TEfficiency class; from the beginning. You can then use one of the constructors for fixed or; variable bin size and your desired dimension. These constructors append the; created TEfficiency object to the current directory. So it will be written; automatically to a file during the next TFile::Write; command.; Example 1: create a twodimensional TEfficiency object with 10; bins along X and 20 bins along Y:; ; TEfficiency* pEff = new TEfficiency(""eff"",""my efficiency;x;y;#epsilon"",10,0,10,20,-5,5);. You can fill the TEfficiency object by calling the Fill(Bool_t bPassed,Double_t x,Double_t y,Double_t z) method.; The boolean flag ""bPassed"" indicates whether the current event is a good; (both histograms are filled) or not (only fTotalHistogram is filled).; The variables x,y and z determine the bin which is filled. For lower; dimensions the z- or even the y-value may be omitted.; ; You can also set the number of passed or total events for a bin directly by using the SetPassedEvents or SetTotalEvents method.; If you already have two histograms filled with the number of passed and total; events, you will use the constructor TEfficiency(const TH1& passed,const TH1& total); to construct the TEfficiency object. The histograms ""passed"" and ""total"" have; to fullfill the conditions mentioned in CheckConsistency,; otherwise the construction will fail.; Example 2: Create TEfficiency from 2 existing histograms:; ; TEfficiency * pEff = 0;; if (TEfficiency::CheckConsistency(h_pass,h_total)); pEff = new TEfficiency(h_pass,h_total);; . The TEfficiency class provides various statistics option based on; frequentist or Bayesian statistics to compute; the confidence interval on the efficiencies. For each statistical; option a corresponding static function esists taking as parameters; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v528/index.html:9298,variab,variables,9298,hist/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v528/index.html,1,['variab'],['variables']
Modifiability,"t are declared ""weak""; in C source code.; ``common``; ""``common``"" linkage is most similar to ""``weak``"" linkage, but they; are used for tentative definitions in C, such as ""``int X;``"" at; global scope. Symbols with ""``common``"" linkage are merged in the; same way as ``weak symbols``, and they may not be deleted if; unreferenced. ``common`` symbols may not have an explicit section,; must have a zero initializer, and may not be marked; ':ref:`constant <globalvars>`'. Functions and aliases may not have; common linkage. .. _linkage_appending:. ``appending``; ""``appending``"" linkage may only be applied to global variables of; pointer to array type. When two global variables with appending; linkage are linked together, the two global arrays are appended; together. This is the LLVM, typesafe, equivalent of having the; system linker append together ""sections"" with identical names when; .o files are linked. Unfortunately this doesn't correspond to any feature in .o files, so it; can only be used for variables like ``llvm.global_ctors`` which llvm; interprets specially. ``extern_weak``; The semantics of this linkage follow the ELF object file model: the; symbol is weak until linked, if not linked, the symbol becomes null; instead of being an undefined reference.; ``linkonce_odr``, ``weak_odr``; Some languages allow differing globals to be merged, such as two; functions with different semantics. Other languages, such as; ``C++``, ensure that only equivalent globals are ever merged (the; ""one definition rule"" --- ""ODR""). Such languages can use the; ``linkonce_odr`` and ``weak_odr`` linkage types to indicate that the; global will only be merged with equivalent globals. These linkage; types are otherwise the same as their non-``odr`` versions.; ``external``; If none of the above identifiers are used, the global is externally; visible, meaning that it participates in linkage and can be used to; resolve external symbol references. It is illegal for a global variable or function *d",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:10568,variab,variables,10568,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variables']
Modifiability,"t arguments. - **Basic usage**: To use ``cppyy`` in Numba JITed code, simply import; ``cppyy.numba_ext``, after which further use is transparent and the same; as when otherwise using ``cppyy`` in Python.; Example:. .. code-block:: python. >>> import numba; >>> import cppyy; >>> import cppyy.numba_ext # enables numba to work with cppyy; >>> import math; >>> @numba.jit(nopython=True); ... def cpp_sqrt(x):; ... return cppyy.gbl.sqrt(x) # direct use, no extra setup required; >>> print(""Sqrt of 4: "", cpp_sqrt(4.0)); Sqrt of 4: 2.0; >>> print(""Sqrt of Pi: "", cpp_sqrt(math.pi)); Sqrt of Pi: 1.7724538509055159. - **Overload selection**: C++ overloads provide different implementations; for different argument types (not to be confused with Numba overloads,; which provide different implementations for the same argument types).; Unfortunately, mapping of Python types to C++ types is often not exact,; so a ""best match"" is chosen, similarly to what ``cppyy`` normally does.; However, the latter, being dynamic, is more flexible.; For example, best-match C++ integer type can be value dependent, whereas; in the Numba trace, it is by definition fixed at JIT time.; Example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... int mul(int x) { return x * 2; }; ... float mul(float x) { return x * 3; }; ... """"""); >>> @numba.jit(nopython=True); ... def oversel(a):; ... total = type(a[0])(0); ... for i in range(len(a)):; ... total += cppyy.gbl.mul(a[i]); ... return total. >>> a = np.array(range(10), dtype=np.float32); >>> print(""Array: "", a); Array: [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]; >>> print(""Overload selection output: "", oversel(a)); Overload selection output: 135.0; >>> a = np.array(range(10), dtype=np.int32); >>> print(""Array: "", a); Array: [0 1 2 3 4 5 6 7 8 9]; >>> print(""Overload selection output: "", oversel(a)); Overload selection output: 90. - **Template instantiation**: templates are instantiated as needed as part; of the overload selection.; The best match is done for the arguments p",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:4527,flexible,flexible,4527,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,1,['flexible'],['flexible']
Modifiability,"t be correctly set on; # first cmake run; include(config-ix). # By default, we target the host, but this can be overridden at CMake; # invocation time. Except on 64-bit AIX, where the system toolchain; # expect 32-bit objects by default.; if(""${LLVM_HOST_TRIPLE}"" MATCHES ""^powerpc64-ibm-aix""); string(REGEX REPLACE ""^powerpc64"" ""powerpc"" LLVM_DEFAULT_TARGET_TRIPLE_DEFAULT ""${LLVM_HOST_TRIPLE}""); else(); # Only set default triple when native target is enabled.; if (LLVM_NATIVE_TARGET); set(LLVM_DEFAULT_TARGET_TRIPLE_DEFAULT ""${LLVM_HOST_TRIPLE}""); endif(); endif(). set(LLVM_DEFAULT_TARGET_TRIPLE ""${LLVM_DEFAULT_TARGET_TRIPLE_DEFAULT}"" CACHE STRING; ""Default target for which LLVM will generate code."" ); message(STATUS ""LLVM default target triple: ${LLVM_DEFAULT_TARGET_TRIPLE}""). set(LLVM_TARGET_TRIPLE ""${LLVM_DEFAULT_TARGET_TRIPLE}""). if(WIN32 OR CYGWIN); if(BUILD_SHARED_LIBS OR LLVM_BUILD_LLVM_DYLIB); set(LLVM_ENABLE_PLUGINS_default ON); else(); set(LLVM_ENABLE_PLUGINS_default OFF); endif(); else(); set(LLVM_ENABLE_PLUGINS_default ${LLVM_ENABLE_PIC}); endif(); option(LLVM_ENABLE_PLUGINS ""Enable plugin support"" ${LLVM_ENABLE_PLUGINS_default}). set(LLVM_ENABLE_NEW_PASS_MANAGER TRUE CACHE BOOL; ""Enable the new pass manager by default.""); if(NOT LLVM_ENABLE_NEW_PASS_MANAGER); message(FATAL_ERROR ""Enabling the legacy pass manager on the cmake level is""; "" no longer supported.""); endif(). include(HandleLLVMOptions). ######. # Configure all of the various header file fragments LLVM uses which depend on; # configuration variables.; set(LLVM_ENUM_TARGETS """"); set(LLVM_ENUM_ASM_PRINTERS """"); set(LLVM_ENUM_ASM_PARSERS """"); set(LLVM_ENUM_DISASSEMBLERS """"); set(LLVM_ENUM_TARGETMCAS """"); set(LLVM_ENUM_EXEGESIS """"); foreach(t ${LLVM_TARGETS_TO_BUILD}); set( td ${LLVM_MAIN_SRC_DIR}/lib/Target/${t} ). # Make sure that any experimental targets were passed via; # LLVM_EXPERIMENTAL_TARGETS_TO_BUILD, not LLVM_TARGETS_TO_BUILD.; # We allow experimental targets that are not in LLVM_ALL_EXPER",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:38968,plugin,plugin,38968,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,1,['plugin'],['plugin']
Modifiability,"t command draws `fPx` for the range; between with conditions on `fBx` and `fBy`, the second command draws `fPx`; for the same conditions, but adds a weight using the result of the second; expression. 35. **`tree->Draw(""fVertex"",""fVertex>10"")`**. When using arrays in the selection and the expression, the selection is; applied to each element of the array. `if (fVertex[0]>10) fVertex[0]`. `if (fVertex[1]>10) fVertex[1]`. `if (fVertex[2]>10) fVertex[2]`. 36. **`tree->Draw(""fPx[600]"")`**. 37. **`tree->Draw(""fPx[600]"",""fNtrack > 600"")`**. When using a specific element for a variable length array the entries; with fewer elements are ignored. Thus these two commands are equivalent. 38. **`tree->Draw(""Nation"")`**. `Nation` is a `char*` branch. When drawing a `char*` it will plot an; alphanumeric histogram, of the different value of the string `Nation`.; The axis will have the `Nation` values. See ""Histograms"". 39. **`tree->Draw(""MyChar +0"")`**. If you want to plot a char\* variable as a byte rather than a string,; you can use the syntax above. 40. **`tree->Draw(""fTracks.fTriggerBits"")`**. `fTriggerBits` is a data member of **`TTrack`** of type **`TBits`**.; Objects of class **`TBits`** can be drawn directly. This command will; create a 1D histogram from 0 to `nbits` which is filled for each; non-null bit-number. 41. **`tree->Draw(""fMatrix-Alt$(fClosestDistance,0)"")`**. `Alt$(primary,alternate)` returns the value of ""`primary`"" if it is; available for the current iteration; otherwise return the value of; ""`alternate`"". Assuming that `fClosestDistance` is a smaller array than; `fMatrix`. This example will draw `fMatrix[i]+fClosestDistance[i]` for; `i` less than the size of `fClosestDistance`, and will draw; `fMatrix[i]+0` for the other value of `i`. 42. **`tree->Draw(""fClosestDistance:Iteration$"")`**. This example draws a 2D plot with, for all entries,; `fClosestDistance[i]:i` for each value of `i` between 0 and the size of; `fClosestDistance`. `Iterations$` is one of four spe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:90934,variab,variable,90934,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['variab'],['variable']
Modifiability,"t command line option can be passed directly to tools such; as opt, llc and lli. The syntax is as follows:. ::. <tool name> [other options] -opt-bisect-limit=<limit>. If a value of -1 is used the tool will perform all optimizations but a message; will be printed to stderr for each optimization that could be skipped; indicating the index value that is associated with that optimization. To skip; optimizations, pass the value of the last optimization to be performed as the; opt-bisect-limit. All optimizations with a higher index value will be skipped. In order to use the -opt-bisect-limit option with a driver that provides a; wrapper around the LLVM core library, an additional prefix option may be; required, as defined by the driver. For example, to use this option with; clang, the ""-mllvm"" prefix must be used. A typical clang invocation would look; like this:. ::. clang -O2 -mllvm -opt-bisect-limit=256 my_file.c. The -opt-bisect-limit option may also be applied to link-time optimizations by; using a prefix to indicate that this is a plug-in option for the linker. The; following syntax will set a bisect limit for LTO transformations:. ::. # When using lld, or ld64 (macOS); clang -flto -Wl,-mllvm,-opt-bisect-limit=256 my_file.o my_other_file.o; # When using Gold; clang -flto -Wl,-plugin-opt,-opt-bisect-limit=256 my_file.o my_other_file.o. LTO passes are run by a library instance invoked by the linker. Therefore any; passes run in the primary driver compilation phase are not affected by options; passed via '-Wl,-plugin-opt' and LTO passes are not affected by options; passed to the driver-invoked LLVM invocation via '-mllvm'. Passing ``-opt-bisect-print-ir-path=path/foo.ll`` will dump the IR to; ``path/foo.ll`` when -opt-bisect-limit starts skipping passes. Bisection Index Values; ======================. The granularity of the optimizations associated with a single index value is; variable. Depending on how the optimization pass has been instrumented the; value may be asso",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OptBisect.rst:2728,plug-in,plug-in,2728,interpreter/llvm-project/llvm/docs/OptBisect.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OptBisect.rst,1,['plug-in'],['plug-in']
Modifiability,"t could be skipped; indicating the index value that is associated with that optimization. To skip; optimizations, pass the value of the last optimization to be performed as the; opt-bisect-limit. All optimizations with a higher index value will be skipped. In order to use the -opt-bisect-limit option with a driver that provides a; wrapper around the LLVM core library, an additional prefix option may be; required, as defined by the driver. For example, to use this option with; clang, the ""-mllvm"" prefix must be used. A typical clang invocation would look; like this:. ::. clang -O2 -mllvm -opt-bisect-limit=256 my_file.c. The -opt-bisect-limit option may also be applied to link-time optimizations by; using a prefix to indicate that this is a plug-in option for the linker. The; following syntax will set a bisect limit for LTO transformations:. ::. # When using lld, or ld64 (macOS); clang -flto -Wl,-mllvm,-opt-bisect-limit=256 my_file.o my_other_file.o; # When using Gold; clang -flto -Wl,-plugin-opt,-opt-bisect-limit=256 my_file.o my_other_file.o. LTO passes are run by a library instance invoked by the linker. Therefore any; passes run in the primary driver compilation phase are not affected by options; passed via '-Wl,-plugin-opt' and LTO passes are not affected by options; passed to the driver-invoked LLVM invocation via '-mllvm'. Passing ``-opt-bisect-print-ir-path=path/foo.ll`` will dump the IR to; ``path/foo.ll`` when -opt-bisect-limit starts skipping passes. Bisection Index Values; ======================. The granularity of the optimizations associated with a single index value is; variable. Depending on how the optimization pass has been instrumented the; value may be associated with as much as all transformations that would have; been performed by an optimization pass on an IR unit for which it is invoked; (for instance, during a single call of runOnFunction for a FunctionPass) or as; little as a single transformation. The index values may also be nested so that;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OptBisect.rst:2978,plugin,plugin-opt,2978,interpreter/llvm-project/llvm/docs/OptBisect.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OptBisect.rst,1,['plugin'],['plugin-opt']
Modifiability,"t example:; # char* path = read_path();; # char* dir = dirname(path);; # // dir is tainted if path was tainted; - Name: dirname; SrcArgs: [0]; DstArgs: [-1]. Sinks:; # Sink functions; # If taint reaches any of the arguments specified, a warning is emitted. # Sink function; # int system(const char* command); #; # Result example:; # const char* command = read_command();; # system(command); // emit diagnostic if command is tainted; - Name: system; Args: [0]. In the example file above, the entries under the `Propagation` key implement the conceptual sources and propagations, and sinks have their dedicated `Sinks` key.; The user can define operations (function calls) where the tainted values should be cleansed by listing entries under the `Filters` key.; Filters model the sanitization of values done by the programmer, and providing these is key to avoiding false-positive findings. Configuration file syntax and semantics; _______________________________________. The configuration file should have valid `YAML <http://llvm.org/docs/YamlIO.html#introduction-to-yaml>`_ syntax. The configuration file can have the following top-level keys:; - Filters; - Propagations; - Sinks. Under the `Filters` key, the user can specify a list of operations that remove taint (see :ref:`clangsa-taint-filter-details` for details). Under the `Propagations` key, the user can specify a list of operations that introduce and propagate taint (see :ref:`clangsa-taint-propagation-details` for details).; The user can mark taint sources with a `SrcArgs` key in the `Propagation` key, while propagations have none.; The lack of the `SrcArgs` key means unconditional propagation, which is how sources are modeled.; The semantics of propagations are such, that if any of the source arguments are tainted (specified by indexes in `SrcArgs`) then all of the destination arguments (specified by indexes in `DstArgs`) also become tainted. Under the `Sinks` key, the user can specify a list of operations where the checker ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/user-docs/TaintAnalysisConfiguration.rst:4127,config,configuration,4127,interpreter/llvm-project/clang/docs/analyzer/user-docs/TaintAnalysisConfiguration.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/user-docs/TaintAnalysisConfiguration.rst,1,['config'],['configuration']
Modifiability,"t files. * ``llvm-symbolizer`` and ``llvm-addr2line`` now support addresses specified as symbol names. * ``llvm-objcopy`` now supports ``--gap-fill`` and ``--pad-to`` options, for; ELF input and binary output files only.; * ``llvm-objcopy`` now supports ``-O elf64-s390`` for SystemZ. * Supported parsing XCOFF auxiliary symbols in ``obj2yaml``. * ``llvm-ranlib`` now supports ``-X`` on AIX to specify the type of object file; ranlib should examine. * ``llvm-cxxfilt`` now supports ``--no-params``/``-p`` to skip function; parameters. * ``llvm-nm`` now supports ``--export-symbol`` to ignore the import symbol file.; * ``llvm-nm`` now supports the ``--line-numbers`` (``-l``) option to use; debugging information to print symbols' filenames and line numbers. * ``llvm-rc`` and ``llvm-windres`` now accept file path references in ``.rc`` files; concatenated from multiple string literals. * The ``llvm-windres`` option ``--preprocessor`` now resolves its argument; in the ``PATH`` environment variable as expected, and options passed with; ``--preprocessor-arg`` are placed before the input file as they should; be. * The ``llvm-windres`` option ``--preprocessor`` has been updated with the; breaking behaviour change from GNU windres from binutils 2.36, where; the whole argument is considered as one path, not considered as a; sequence of tool name and parameters. Changes to LLDB; ---------------------------------. * ``SBWatchpoint::GetHardwareIndex`` is deprecated and now returns -1; to indicate the index is unavailable.; * Methods in SBHostOS related to threads have had their implementations; removed. These methods will return a value indicating failure.; * ``SBType::FindDirectNestedType`` function is added. It's useful; for formatters to quickly find directly nested type when it's known; where to search for it, avoiding more expensive global search via; ``SBTarget::FindFirstType``.; * ``lldb-vscode`` was renamed to ``lldb-dap`` and and its installation; instructions have been updated ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst:15073,variab,variable,15073,interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,1,['variab'],['variable']
Modifiability,"t for use in C++ code, all of the module's headers will be treated as if they were contained within an implicit ``extern ""C""`` block. An import for a module with this attribute can appear within an ``extern ""C""`` block. No other restrictions are lifted, however: the module currently cannot be imported within an ``extern ""C""`` block in a namespace. The ``no_undeclared_includes`` attribute specifies that the module can only reach non-modular headers and headers from used modules. Since some headers could be present in more than one search path and map to different modules in each path, this mechanism helps clang to find the right header, i.e., prefer the one for the current module or in a submodule instead of the first usual match in the search paths. Modules can have a number of different kinds of members, each of which is described below:. .. parsed-literal::. *module-member*:; *requires-declaration*; *header-declaration*; *umbrella-dir-declaration*; *submodule-declaration*; *export-declaration*; *export-as-declaration*; *use-declaration*; *link-declaration*; *config-macros-declaration*; *conflict-declaration*. An extern module references a module defined by the *module-id* in a file given by the *string-literal*. The file can be referenced either by an absolute path or by a path relative to the current map file. Requires declaration; ~~~~~~~~~~~~~~~~~~~~; A *requires-declaration* specifies the requirements that an importing translation unit must satisfy to use the module. .. parsed-literal::. *requires-declaration*:; ``requires`` *feature-list*. *feature-list*:; *feature* (',' *feature*)*. *feature*:; ``!``:sub:`opt` *identifier*. The requirements clause allows specific modules or submodules to specify that they are only accessible with certain language dialects, platforms, environments and target specific features. The feature list is a set of identifiers, defined below. If any of the features is not available in a given translation unit, that translation unit sha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:32849,config,config-macros-declaration,32849,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['config'],['config-macros-declaration']
Modifiability,"t gettok() {; ...; if (IdentifierStr == ""for""); return tok_for;; if (IdentifierStr == ""in""); return tok_in;; if (IdentifierStr == ""binary""); return tok_binary;; if (IdentifierStr == ""unary""); return tok_unary;; return tok_identifier;. This just adds lexer support for the unary and binary keywords, like we; did in `previous chapters <LangImpl05.html#lexer-extensions-for-if-then-else>`_. One nice thing; about our current AST, is that we represent binary operators with full; generalisation by using their ASCII code as the opcode. For our extended; operators, we'll use this same representation, so we don't need any new; AST or parser support. On the other hand, we have to be able to represent the definitions of; these new operators, in the ""def binary\| 5"" part of the function; definition. In our grammar so far, the ""name"" for the function; definition is parsed as the ""prototype"" production and into the; ``PrototypeAST`` AST node. To represent our new user-defined operators; as prototypes, we have to extend the ``PrototypeAST`` AST node like; this:. .. code-block:: c++. /// PrototypeAST - This class represents the ""prototype"" for a function,; /// which captures its argument names as well as if it is an operator.; class PrototypeAST {; std::string Name;; std::vector<std::string> Args;; bool IsOperator;; unsigned Precedence; // Precedence if a binary op. public:; PrototypeAST(const std::string &Name, std::vector<std::string> Args,; bool IsOperator = false, unsigned Prec = 0); : Name(Name), Args(std::move(Args)), IsOperator(IsOperator),; Precedence(Prec) {}. Function *codegen();; const std::string &getName() const { return Name; }. bool isUnaryOp() const { return IsOperator && Args.size() == 1; }; bool isBinaryOp() const { return IsOperator && Args.size() == 2; }. char getOperatorName() const {; assert(isUnaryOp() || isBinaryOp());; return Name[Name.size() - 1];; }. unsigned getBinaryPrecedence() const { return Precedence; }; };. Basically, in addition to knowing a name for",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl06.rst:4595,extend,extend,4595,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl06.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl06.rst,1,['extend'],['extend']
Modifiability,"t has to be enclosed in a square brackets and is a; comma-separated list of integers.; * targetClass - The field is obligatory and defines the name of the in-memory class that; this rule can be applied to.; * target - A semicolon-separated list of target class data member names that this rule; is capable of calculating.; * embed - This property tells the system if the rule should be written in the output; file is some objects of this class are serialized.; * include - A list of header files that should be included in order to provide the func-; tionality used in the code snippet; the list is comma delimited.; * code - An user specified code snippet. The user can assume that in the provided code snippet the following variables; will be defined:. The user provided code snippets have to consist of valid C++ code. The system can do; some preprocessing before wrapping the code into function calls and declare some variables to; facilitate the rule definitions. The user can expect the following variables being predeclared:. * newObj - variable representing the target in-memory object, it’s type is that of the; target object; * oldObj - in normal conversion rules, an object of TVirtualObject class representing the; input data, guaranteed to hold the data members declared in the source property; of the rule; * buffer - in raw conversion rules, an object of TBuﬀer class holding the data member; declared in source property of the rule; * names of the data members of the target object declared in the target property of the; rule declared to be the appropriate type; * onfile.xxx - in normal conversion rules, names of the variables of basic types declared; in the source property of the rule. 3. The C++ API. The schema evolution C++ API consists of two classes: ROOT::TSchemaRuleSet and ROOT::TSchemaRule.; Objects of the TSchemaRule class represent the rules and their fields have exactly the same; meaning as the ones of rules specified in the dictionaries. TSchemaRuleSet objects; m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/DataModelEvolution.txt:5040,variab,variables,5040,io/doc/DataModelEvolution.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/DataModelEvolution.txt,1,['variab'],['variables']
Modifiability,"t in the name of directory in TChain::Add and TChain::AddFile (however in this case the root file must be ending .root.); Improve support for circular TTree friendship in LoadTree.; Insure that the in-memory tree (not attached to a file) are saved in their new style (i.e. each basket saved separately) and prevent the printing of the misleading error message:; Error in : Cannot create key without file ; Repaired TTreeSQL:; The existing code was not compatible with the change made in TTree to reduce the number of baskets in memory.; If the TreeFriend is entered via a TTree*, properly detect that it is in the same file and do not record the filename (since we will alway know where to find it.); Add "","" in the list of special characters replaced by ""_"" in the TTree::MakeClass; and TTree::MakeCode functions.; The fast cloning now explicitly rejects trying to merge TTrees with different split level; The fast cloning now supports the case where one of the branch in the output tree in; not present and also supports the case where branch are not the same order.; New bit flag kMapObject [mybranch->ResetBit(kMapObject)] to explicitly disable the; object registration during streaming within a branch (Use only if you are sure that there; is not a pointer pointing back to the nesting object within this branch). Fix tree->Draw(""s1.value"");; when the top level branch does not have a trailing dot; (and hence the real branch name is only 'value'). Fixed support for vector<bool> and vector<string> ; Added support for top level object that do not inherit from TObject _AND_ have a custom streamer (like std::string and TString);; Tree Viewer. In TParallelCoordVar the ""average marker"" for candle plots was not painted at; the right place in case of horizontal view.; Protection added in:; TParallelCoord::TParallelCoord(TTree* tree, Long64_t nentries); in case nentries > tree->GetEstimate(); in such case a warning is printed and fNentries is set to; tree->GetEstimate(); instead of nentries. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v522/index.html:1738,inherit,inherit,1738,tree/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v522/index.html,1,['inherit'],['inherit']
Modifiability,"t is important to create with the size of the data; 	ROOT::Fit::UnBinData data(n);; 	for (int i = 0; i < n; ++i); 		data.add(buffer[2*i+1]); // the buffer of 1D histogram contains nevt,x1,w1,x2,w2,......; ```. Instead in this example we will create a 2-dim `UnBinData` object with the contents from a ROOT `TTree`. ``` {.cpp}; TFile * file = TFile::Open(""hsimple.root"");; TTree *ntuple = 0; file->GetObject(""ntuple"",ntuple);; 	// select from the tree the data we want to use for fitting; 	// we use TTree::Draw for this; 	int nevt = ntuple->Draw(""px:py"","""",""goff"");; 	double * x = ntuple->GetV1();; 	double * y = ntuple->GetV2();; ROOT::Fit::UnBinData data(nevt, x, y );; ```. ### Creating the Fit model. In order to fit a data sets we need a model to describe our data, e.g. a probability density function describing our observed data or; an hypothetical function describing the relation between the independent variables **`X`** and the single dependent variable `Y`.; We can have an arbitrary number `k` of independent variables. For example, when fitting a `k`-dimensional histogram,; the independent variables **`X`** are the bin center coordinates and `Y` is the bin weight. The model function needs to be expressed as function of some unknown parameters. The fitting will find the best parameter value to describe; the observed data. We can use the ROOT **`TF1`** class, the parametric function class, to describe the model function. However the `ROOT::Fit::Fitter` class, to be independent of the ROOT *`Hist`* library,; takes as input a more general parametric function object, the interface (abstract) class `ROOT::Math::IParametricFunctionMultiDim`, which describe a generic one or multi-dimensional function; with parameters. This interface extends the abstract class `ROOT::Math::IBaseFunctionMultiDim`, with methods to set/retrieve parameter values and to evaluate the function given the; independent vector of values **`X`** and vector of parameters `P`.; More information about the dif",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:35544,variab,variables,35544,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['variab'],['variables']
Modifiability,"t jg, int jh, int ji);; . New statistical function: non-central chisquare probability; density function; ; double noncentral_chisquared_pdf(double x, double r, double lambda);; ; It is implemented using Bessel functions or hypergeometric function; ; New classes VavilovAccurate and VavilovFast,; derived from the abstract base class Vavilov,; provide pdf, cdf and quantile functions for the Vavilov distribution,; based on the algorithms of CERNLIB (G116 and G115, respectively).; The classes VavilovAccuratePdf,; VavilovAccurateCdf and VavilovAccurateQuantile; implement the IParametricFunctionOneDim interface; for easier use in fit problems. . Unuran. Use new version 1.7.2 ; Add new class TUnuranSampler implementing the; ROOT::Math::DistSampler interface for one dimensional; continuous and discrete distributions and for mult-dimensional ones; . Foam. Add new class TFoamSampler implementing the; ROOT::Math::DistSampler interface for generating random; numbers according to any one or multi-dim distributions using Foam.; ; All the TFoam options can be controlled via the; ROOT::Math::DistSamplerOptions class, which can be passed; as input to the virtual ROOT::Math::DistSampler::Init(..); function.; . GenVector. Add some missing copy constructor and assignment operators to; fix compilation issue observed with LLVM (Clang). Minuit. Fix a bug when using at the same time TMinuit or TFitter with; the new TMinuitMinimizer class. See bug 72909.; . Minuit2. Fix the returned error from the Minimizer class for fixed and; constant parameters. Now is set explicitly to zero.; ; Fix a problem in re-defining fixed parameters as variable; ones. Before it was not possible to release them.; ; Fix a problem in the number of function calls when running MnHesse; after minimizing. Now the number is incremented instead of being; reset.; . Genetic. Add a new Minimizer implementation based on the genetic; algorithm used in TMVA (plugin name ""Genetic""). See example programs in; math/genetic/test.; . ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v528/index.html:9965,variab,variable,9965,math/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v528/index.html,2,"['plugin', 'variab']","['plugin', 'variable']"
Modifiability,"t matching; multilib variant that has the given file.; This behaviour permits multilib variants with only a partial set of files.; This means a toolchain can be distributed with one base multilib variant; containing all system headers and includes, and more specialised multilib; variants containing only files that are different to those in the base variant. For example, a multilib variant could be compiled with ``-fno-exceptions``.; This option doesn't affect the content of header files, nor does it affect the; C libraries. Therefore if multilib layering is supported by the ToolChain; subclass and a suitable base multilib variant is present then the; ``-fno-exceptions`` multilib variant need only contain C++ libraries. It is the responsibility of layered multilib authors to ensure that headers and; libraries in each layer are complete enough to mask any incompatibilities. Stability; =========. Multilib via configuration file shall be considered an experimental feature; until LLVM 18, at which point ``-print-multi-flags-experimental``; should be renamed to ``-print-multi-flags``.; A toolchain can opt in to using this feature by including a ``multilib.yaml``; file in its distribution, once support for it is added in relevant ToolChain; subclasses.; Once stability is reached, flags emitted by ``-print-multi-flags``; should not be removed or changed, although new flags may be added. Restrictions; ============. Despite the name, multilib is used to locate both ``include`` and ``lib``; directories. Therefore it is important that consistent options are passed to; the Clang driver when both compiling and linking. Otherwise inconsistent; ``include`` and ``lib`` directories may be used, and the results will be; undefined. EXPERIMENTAL multilib.yaml; ==========================. The below example serves as a small of a possible multilib, and documents; the available options. For a more comprehensive example see; ``clang/test/Driver/baremetal-multilib.yaml`` in the ``llvm-project",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst:5551,config,configuration,5551,interpreter/llvm-project/clang/docs/Multilib.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst,1,['config'],['configuration']
Modifiability,"t of attributes is represented, with 0 representing the return value; attributes, 0xFFFFFFFF representing function attributes, and other values; representing 1-based function parameters. Each *attr* is itself represented as a variable number of values:. ``kind, key [, ...], [value [, ...]]``. Each attribute is either a well-known LLVM attribute (possibly with an integer; value associated with it), or an arbitrary string (possibly with an arbitrary; string value associated with it). The *kind* value is an integer code; distinguishing between these possibilities:. * code 0: well-known attribute; * code 1: well-known attribute with an integer value; * code 3: string attribute; * code 4: string attribute with a string value. For well-known attributes (code 0 or 1), the *key* value is an integer code; identifying the attribute. For attributes with an integer argument (code 1),; the *value* value indicates the argument. For string attributes (code 3 or 4), the *key* value is actually a variable; number of values representing the bytes of a null-terminated string. For; attributes with a string argument (code 4), the *value* value is similarly a; variable number of values representing the bytes of a null-terminated string. The integer codes are mapped to well-known attributes as follows. * code 1: ``align(<n>)``; * code 2: ``alwaysinline``; * code 3: ``byval``; * code 4: ``inlinehint``; * code 5: ``inreg``; * code 6: ``minsize``; * code 7: ``naked``; * code 8: ``nest``; * code 9: ``noalias``; * code 10: ``nobuiltin``; * code 11: ``nocapture``; * code 12: ``nodeduplicate``; * code 13: ``noimplicitfloat``; * code 14: ``noinline``; * code 15: ``nonlazybind``; * code 16: ``noredzone``; * code 17: ``noreturn``; * code 18: ``nounwind``; * code 19: ``optsize``; * code 20: ``readnone``; * code 21: ``readonly``; * code 22: ``returned``; * code 23: ``returns_twice``; * code 24: ``signext``; * code 25: ``alignstack(<n>)``; * code 26: ``ssp``; * code 27: ``sspreq``; * code 28: ``sspstr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:37572,variab,variable,37572,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,1,['variab'],['variable']
Modifiability,"t of flags. #### Schema Extension Record Frame. The schema extension record frame contains an additional schema description that is incremental; with respect to the schema contained in the header (see Section Header Envelope).; Specifically, it is a record frame with the following four fields; (identical to the last four fields in Header Envelope):. - List frame: list of field record frames; - List frame: list of column record frames; - List frame: list of alias column record frames; - List frame: list of extra type information. In general, a schema extension is optional, and thus this record frame might be empty.; The interpretation of the information contained therein should be identical; as if it was found directly at the end of the header.; This is necessary when fields have been added during writing. Note that the field IDs and physical column IDs given by the serialization order; should continue from the largest IDs found in the header. Note that is it possible to extend existing fields by additional column representations.; This means that columns of the extension header may point to fields of the regular header. #### Column Group Record Frame; The column group record frame is used to set IDs for certain subsets of column IDs.; Column groups are only used when there are sharded clusters.; Otherwise, the enclosing list frame in the footer envelope is empty and all clusters span all columns.; The purpose of column groups is to prevent repetition of column ID ranges in cluster summaries. The column group record frame consists of a list frame of 32bit integer items.; Every item denotes a column ID that is part of this particular column group.; The ID of the column group is given implicitly by the order of column groups. The frame hierarchy is as follows. - Column group outer list frame; |; |---- Column group 1 record frame; | |---- List frame of column IDs; | | |---- Column ID 1 [32bit integer]; | | |---- Column ID 2 [32bit integer]; | | | ...; |; |---- Column gro",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:29770,extend,extend,29770,tree/ntuple/v7/doc/BinaryFormatSpecification.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md,1,['extend'],['extend']
Modifiability,"t of scope at the end of; each loop iteration, so their value in one iteration is not available in; the next iteration. The following ``defvar`` will not work::. defvar i = !add(i, 1);. Variables can also be defined with ``defvar`` in a record body. See; `Defvar in a Record Body`_ for more details. ``foreach`` --- iterate over a sequence of statements; -----------------------------------------------------. The ``foreach`` statement iterates over a series of statements, varying a; variable over a sequence of values. .. productionlist::; Foreach: ""foreach"" `ForeachIterator` ""in"" ""{"" `Statement`* ""}""; :| ""foreach"" `ForeachIterator` ""in"" `Statement`; ForeachIterator: `TokIdentifier` ""="" (""{"" `RangeList` ""}"" | `RangePiece` | `Value`). The body of the ``foreach`` is a series of statements in braces or a; single statement with no braces. The statements are re-evaluated once for; each value in the range list, range piece, or single value. On each; iteration, the :token:`TokIdentifier` variable is set to the value and can; be used in the statements. The statement list establishes an inner scope. Variables local to a; ``foreach`` go out of scope at the end of each loop iteration, so their; values do not carry over from one iteration to the next. Foreach loops may; be nested. .. Note that the productions involving RangeList and RangePiece have precedence; over the more generic value parsing based on the first token. .. code-block:: text. foreach i = [0, 1, 2, 3] in {; def R#i : Register<...>;; def F#i : Register<...>;; }. This loop defines records named ``R0``, ``R1``, ``R2``, and ``R3``, along; with ``F0``, ``F1``, ``F2``, and ``F3``. ``dump`` --- print messages to stderr; -------------------------------------. A ``dump`` statement prints the input string to standard error; output. It is intended for debugging purpose. * At top level, the message is printed immediately. * Within a record/class/multiclass, `dump` gets evaluated at each; instantiation point of the containing re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:46278,variab,variable,46278,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['variab'],['variable']
Modifiability,"t optimizations in the middle-end. Rematerialization; of hoisted instructions to reduce register pressure is the responsibility of; the back-end, which has more accurate information about register pressure and; also handles other optimizations than LICM that increase live-ranges. This pass uses alias analysis for two purposes:. #. Moving loop invariant loads and calls out of loops. If we can determine; that a load or call inside of a loop never aliases anything stored to, we; can hoist it or sink it like any other instruction. #. Scalar Promotion of Memory. If there is a store instruction inside of the; loop, we try to move the store to happen AFTER the loop instead of inside of; the loop. This can only happen if a few conditions are true:. #. The pointer stored through is loop invariant.; #. There are no stores or loads in the loop which *may* alias the pointer.; There are no calls in the loop which mod/ref the pointer. If these conditions are true, we can promote the loads and stores in the; loop of the pointer to use a temporary alloca'd variable. We then use the; :ref:`mem2reg <passes-mem2reg>` functionality to construct the appropriate; SSA form for the variable. ``loop-deletion``: Delete dead loops; ------------------------------------. This file implements the Dead Loop Deletion Pass. This pass is responsible for; eliminating loops with non-infinite computable trip counts that have no side; effects or volatile instructions, and do not contribute to the computation of; the function's return value. .. _passes-loop-extract:. ``loop-extract``: Extract loops into new functions; --------------------------------------------------. A pass wrapper around the ``ExtractLoop()`` scalar transformation to extract; each top-level loop into its own new function. If the loop is the *only* loop; in a given function, it is not touched. This is a pass most useful for; debugging via bugpoint. ``loop-reduce``: Loop Strength Reduction; ----------------------------------------. This",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:25032,variab,variable,25032,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['variab'],['variable']
Modifiability,"t or back-end features,; you must make sure to isolate the features, so that buildbots that; run on different architectures (and don't even compile all back-ends),; don't fail. The first problem is to check for target-specific output, for example sizes; of structures, paths and architecture names, for example:. * Tests containing Windows paths will fail on Linux and vice-versa.; * Tests that check for ``x86_64`` somewhere in the text will fail anywhere else.; * Tests where the debug information calculates the size of types and structures. Also, if the test rely on any behaviour that is coded in any back-end, it must; go in its own directory. So, for instance, code generator tests for ARM go; into ``test/CodeGen/ARM`` and so on. Those directories contain a special; ``lit`` configuration file that ensure all tests in that directory will; only run if a specific back-end is compiled and available. For instance, on ``test/CodeGen/ARM``, the ``lit.local.cfg`` is:. .. code-block:: python. config.suffixes = ['.ll', '.c', '.cpp', '.test']; if not 'ARM' in config.root.targets:; config.unsupported = True. Other platform-specific tests are those that depend on a specific feature; of a specific sub-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific File",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:18397,config,config,18397,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,1,['config'],['config']
Modifiability,"t parent class. As a special case, the name of a record can be passed as a template argument; to that record's parent classes. For example:. .. code-block:: text. class A <dag d> {; dag the_dag = d;; }. def rec1 : A<(ops rec1)>;. The DAG ``(ops rec1)`` is passed as a template argument to class ``A``. Notice; that the DAG includes ``rec1``, the record being defined. The steps taken to create a new record are somewhat complex. See `How; records are built`_. See `Examples: classes and records`_ for examples. Examples: classes and records; -----------------------------. Here is a simple TableGen file with one class and two record definitions. .. code-block:: text. class C {; bit V = true;; }. def X : C;; def Y : C {; let V = false;; string Greeting = ""Hello!"";; }. First, the abstract class ``C`` is defined. It has one field named ``V``; that is a bit initialized to true. Next, two records are defined, derived from class ``C``; that is, with ``C``; as their parent class. Thus they both inherit the ``V`` field. Record ``Y``; also defines another string field, ``Greeting``, which is initialized to; ``""Hello!""``. In addition, ``Y`` overrides the inherited ``V`` field,; setting it to false. A class is useful for isolating the common features of multiple records in; one place. A class can initialize common fields to default values, but; records inheriting from that class can override the defaults. TableGen supports the definition of parameterized classes as well as; nonparameterized ones. Parameterized classes specify a list of variable; declarations, which may optionally have defaults, that are bound when the; class is specified as a parent class of another class or record. .. code-block:: text. class FPFormat <bits<3> val> {; bits<3> Value = val;; }. def NotFP : FPFormat<0>;; def ZeroArgFP : FPFormat<1>;; def OneArgFP : FPFormat<2>;; def OneArgFPRW : FPFormat<3>;; def TwoArgFP : FPFormat<4>;; def CompareFP : FPFormat<5>;; def CondMovFP : FPFormat<6>;; def SpecialFP : FPForm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:29533,inherit,inherit,29533,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['inherit'],['inherit']
Modifiability,"t point inside the hierarchy; of nodes, after setting this point it is mandatory to call the; `‘Where am I?'` method:. ``` {.cpp}; gGeoManager->FindNode();; ```. In order to have more flexibility, there are in fact several alternative; ways of initializing a modeller state:. ``` {.cpp}; // Setting the point and finding the state in one step:; gGeoManager->FindNode(Double_t x,Double_t y,Double_t z);; gGeoManager->FindNode(Double_t *point[3]);; // Setting both initial point and direction and finding the state:; gGeoManager->InitTrack(Double_t x,Double_t y,Double_t z,; Double_t nx, Double_t ny, Double_t nz);; gGeoManager->InitTrack(Double_t *point[3],Double_t *dir[3]);; ```. Note that the current point coordinates can be changed and the state; re-initialized at any time. This represents the `‘Where am I?'`; geometrical query representing the basic navigation functionality; provided by the modeller. ### Checking the Current State. The current state and all variables related to this are essential during; tracking and have to be checked several times. Besides the current point; and direction, the following additional information can be retrieved; from **`TGeoManager`** interface:. - The `current path`. This represents a string containing the names; and copy numbers of all positioned objects in the current `branch`; written in the /folder/folder/.../folder/file fashion. The final node; pointed by the path is the deepest object containing the current; point and is representative for the current state. All intermediate; `folders` in the path are in fact also nodes ""touched"" by the; current point, but having some ""touched"" containment. The current; path can be retrieved only after the state was initialized and is; useful for getting an idea of the current point location. ``` {.cpp}; const char *path = gGeoManager->GetPath();; cout << ""Current path is: "" << path << endl;; /A_1/B_34/C_3/D_1; ```. - The `current node`***`, `***`volume` and `material`. In order to; take decisions ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:107287,variab,variables,107287,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['variab'],['variables']
Modifiability,"t portion. Unfortunately, such a matcher is impossible to write. Matchers contain; no logic for comparing two arbitrary AST nodes and determining whether; or not they are equal, so the best we can do is matching more than we; would like to allow, and punting extra comparisons to the callback. In any case, we can start building this sub-matcher. We can require that; the increment step be a unary increment like this:. .. code-block:: c++. hasIncrement(unaryOperator(hasOperatorName(""++""))). Specifying what is incremented introduces another quirk of Clang's AST:; Usages of variables are represented as ``DeclRefExpr``'s (""declaration; reference expressions"") because they are expressions which refer to; variable declarations. To find a ``unaryOperator`` that refers to a; specific declaration, we can simply add a second condition to it:. .. code-block:: c++. hasIncrement(unaryOperator(; hasOperatorName(""++""),; hasUnaryOperand(declRefExpr()))). Furthermore, we can restrict our matcher to only match if the; incremented variable is an integer:. .. code-block:: c++. hasIncrement(unaryOperator(; hasOperatorName(""++""),; hasUnaryOperand(declRefExpr(to(varDecl(hasType(isInteger()))))))). And the last step will be to attach an identifier to this variable, so; that we can retrieve it in the callback:. .. code-block:: c++. hasIncrement(unaryOperator(; hasOperatorName(""++""),; hasUnaryOperand(declRefExpr(to(; varDecl(hasType(isInteger())).bind(""incrementVariable"")))))). We can add this code to the definition of ``LoopMatcher`` and make sure; that our program, outfitted with the new matcher, only prints out loops; that declare a single variable initialized to zero and have an increment; step consisting of a unary increment of some variable. Now, we just need to add a matcher to check if the condition part of the; ``for`` loop compares a variable against the size of the array. There is; only one problem - we don't know which array we're iterating over; without looking at the body of the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersTutorial.rst:12452,variab,variable,12452,interpreter/llvm-project/clang/docs/LibASTMatchersTutorial.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersTutorial.rst,1,['variab'],['variable']
Modifiability,"t possible to specify that a particular one of the input; location descriptions is undefined. See the ``DW_OP_LLVM_undefined`` operation in; :ref:`amdgpu-dwarf-undefined-location-description-operations`. 2.6 Generalize Creation of Composite Location Descriptions; ----------------------------------------------------------. To allow composition of composite location descriptions, an explicit operation; that indicates the end of the definition of a composite location description is; required. This can be implied if the end of a DWARF expression is reached,; allowing current DWARF expressions to remain legal. See ``DW_OP_LLVM_piece_end`` in; :ref:`amdgpu-dwarf-composite-location-description-operations`. 2.7 Generalize DWARF Base Objects to Allow Any Location Description Kind; ------------------------------------------------------------------------. The number of registers and the cost of memory operations is much higher for; AMDGPU than a typical CPU. The compiler attempts to optimize whole variables and; arrays into registers. Currently DWARF only allows ``DW_OP_push_object_address`` and related operations; to work with a global memory location. To support AMDGPU optimized code it is; required to generalize DWARF to allow any location description to be used. This; allows registers, or composite location descriptions that may be a mixture of; memory, registers, or even implicit values. See ``DW_OP_push_object_address`` in; :ref:`amdgpu-dwarf-general-location-description-operations`. 2.8 General Support for Address Spaces; --------------------------------------. AMDGPU needs to be able to describe addresses that are in different kinds of; memory. Optimized code may need to describe a variable that resides in pieces; that are in different kinds of storage which may include parts of registers,; memory that is in a mixture of memory kinds, implicit values, or be undefined. DWARF has the concept of segment addresses. However, the segment cannot be; specified within a DWARF e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:16277,variab,variables,16277,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['variab'],['variables']
Modifiability,"t pushes a location description L with one memory location description SL; on the stack. SL specifies the memory location storage corresponding to the; target architecture default address space with a bit offset equal to A; scaled by 8 (the byte size). *If the DWARF is part of a code object, then A may need to be relocated. For; example, in the ELF code object format, A must be adjusted by the difference; between the ELF segment virtual address and the virtual address at which the; segment is loaded.*. 3. ``DW_OP_LLVM_form_aspace_address`` *New*. ``DW_OP_LLVM_form_aspace_address`` pops top two stack entries. The first; must be an integral type value that represents a target architecture; specific address space identifier AS. The second must be an integral type; value that represents an address A. The address size S is defined as the address bit size of the target; architecture specific address space that corresponds to AS. A is adjusted to S bits by zero extending if necessary, and then treating; the least significant S bits as an unsigned value A'. It pushes a location description L with one memory location description SL; on the stack. SL specifies the memory location storage LS that corresponds; to AS with a bit offset equal to A' scaled by 8 (the byte size). If AS is an address space that is specific to context elements, then LS; corresponds to the location storage associated with the current context. *For example, if AS is for per thread storage then LS is the location; storage for the current thread. For languages that are implemented using a; SIMT execution model, then if AS is for per lane storage then LS is the; location storage for the current lane of the current thread. Therefore, if L; is accessed by an operation, the location storage selected when the location; description was created is accessed, and not the location storage associated; with the current context of the access operation.*. The DWARF expression is ill-formed if AS is not one of the values ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:110681,extend,extending,110681,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['extend'],['extending']
Modifiability,"t static initializers. Instead of calling the ``*_file()`` APIs; described above, use the following to save the profile directly to a buffer; under your control:. * Forward-declare ``uint64_t __llvm_profile_get_size_for_buffer(void)`` and; call it to determine the size of the profile. You'll need to allocate a; buffer of this size. * Forward-declare ``int __llvm_profile_write_buffer(char *Buffer)`` and call it; to copy the current counters to ``Buffer``, which is expected to already be; allocated and big enough for the profile. * Optionally, forward-declare ``void __llvm_profile_reset_counters(void)`` and; call it to reset the counters before entering a specific section to be; profiled. This is only useful if there is some setup that should be excluded; from the profile. In C++ files, declare these as ``extern ""C""``. Collecting coverage reports for the llvm project; ================================================. To prepare a coverage report for llvm (and any of its sub-projects), add; ``-DLLVM_BUILD_INSTRUMENTED_COVERAGE=On`` to the cmake configuration. Raw; profiles will be written to ``$BUILD_DIR/profiles/``. To prepare an html; report, run ``llvm/utils/prepare-code-coverage-artifact.py``. To specify an alternate directory for raw profiles, use; ``-DLLVM_PROFILE_DATA_DIR``. To change the size of the profile merge pool, use; ``-DLLVM_PROFILE_MERGE_POOL_SIZE``. Drawbacks and limitations; =========================. * Prior to version 2.26, the GNU binutils BFD linker is not able link programs; compiled with ``-fcoverage-mapping`` in its ``--gc-sections`` mode. Possible; workarounds include disabling ``--gc-sections``, upgrading to a newer version; of BFD, or using the Gold linker. * Code coverage does not handle unpredictable changes in control flow or stack; unwinding in the presence of exceptions precisely. Consider the following; function:. .. code-block:: cpp. int f() {; may_throw();; return 0;; }. If the call to ``may_throw()`` propagates an exception into ``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst:18152,config,configuration,18152,interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,1,['config'],['configuration']
Modifiability,"t syntax tree (AST);; .dynamicExtensions - Turns on cling's dynamic extensions. This in turn enables the dynamic lookup and the late resolving of the identifier. With that option cling tries to heal the compile-time failed lookups at runtime;. Details; Command line. The interactive prompt supports an emacs-like command line editor, just like bash terminal, which makes it easy to integrate and use. Cling uses TextInput and doesn't depend on ncurses.; . Autocompletion should be coming soon!; ; #Include Declarations. Cling allows #include-s to be not only before the declarations. The includes could be mixed with other declarations. For example:; [cling]$ #include ""math.h""; [cling]$ sin(1); (double const) 8.414710e-01; [cling]$ #include ""stdio.h""; [cling]$ printf(""%f\n"", sin(1));; 0.841471. More statements could be combined using semicolon (;). This doesn't stay when the command is #include; The following example is invalid:[cling]$ #include ""math.h""; sin(1). The same rules are applicable for the other preprocessor directives (commands starting with # - such as #define); ; Variable Declarations. Cling allows statements to be entered onto the global scope. In order to be compiled and executed by the compiler these statements need to be wrapped into functions, which body contains the statement and afterwards to run the function. The semantics of the statements that declare variables is that variables should be accessed by other statements. If the statement that declare variable is wrapped into function the variables won't be accessible from outside anymore. In this case variables are extracted onto the global scope.; ; TODO: There should be dedicated entry for that in the docs; Builtins; Cling starts with very few builtins loaded. Users could extend the available builtins via extending the RuntimeUniverse.h, which is loaded at cling's startup.; . Copyright © Cling Team; . The ROOT Framework |; LLVM |; Clang |; Web Design. Page was modified on $Date$ in $Rev$ by $Author$. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/www/old/index.html:3869,variab,variables,3869,interpreter/cling/www/old/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/www/old/index.html,7,"['extend', 'variab']","['extend', 'extending', 'variable', 'variables']"
Modifiability,"t tablegen.; ```. <stdin>:1:1: error: Unexpected token at top level; This is not tablegen.; ^. Add some classes to get some output. ```tablegen; %reset; class Stuff {}; def thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def thing {	// Stuff; }. By default cells are connected. Meaning that we cache the code and magic directives from the previously run cells. This means that the next cell still sees the `Stuff` class. ```tablegen; def other_thing : Stuff {}; ```. ------------- Classes -----------------; class Stuff {; }; ------------- Defs -----------------; def other_thing {	// Stuff; }; def thing {	// Stuff; }. You can use the magic `%reset` to clear this cache and start fresh. ```tablegen; %reset; def other_thing : Stuff {}; ```. <stdin>:1:19: error: Couldn't find class 'Stuff'; def other_thing : Stuff {}; ^. You can also configure the default reset behaviour using the `%config` magic. ```tablegen; %config cellreset on; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; // The cache is reset here so this is an error.; def AThing: Thing {}; ```. <stdin>:2:13: error: Couldn't find class 'Thing'; def AThing: Thing {}; ^. The default value is `off`, meaning cells are connected. If you want to override the default for one cell only, use the `%reset` or `%noreset` magic. These always override the default. ```tablegen; class Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------. ```tablegen; %noreset; // This works because of the noreset above.; def AThing: Thing {}; ```. ------------- Classes -----------------; class Thing {; }; ------------- Defs -----------------; def AThing {	// Thing; }. ```tablegen; // This does not because we're not changing the default.; def AnotherThing: Thing {}; ```. <stdin>:2:19: error: Couldn't find class 'Thing'; def AnotherThing: Thin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md:1279,config,config,1279,interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/LLVM_TableGen.md,1,['config'],['config']
Modifiability,"t the activity on the nodes via syslog. .; New packetizer TPacketizerFile generating packets which contain a single; file path to be used in processing single files. Used, for example, in; tasks generating files. The files are specified into a TMap - named; 'PROOF_FilesToProcess' - containing the list of files to be generated; per host (the key is the host name, the value the TList of TObjString; (or TFileInfo) with the files names - or a TFileCollection: the output; of TFileCollection::GetFilesPerServer() can be directly passed as files; map). Workers are first assigned files belonging to; the list with host name matching the worker name. The map is; distributed to the master via the input list.Add support for; automatic setting of pointer data members to the relevant object in the; output list. The use of fOutputList->FindObject(""name"") in; TSelector::Terminate is not needed anymore for pointer data members,; e.g. histograms.; Add the possibility to define an external list of environment; variables to be transmitted to the master and workers. This is done via; the environment variable PROOF_ENVVARS. This addition allows to change; the variables wthout changing the macro or application running; TProof::Open.; Add the possibility to save the perfomance information shown; by the dialog into a small ntuple included in the output list. The; ntuple contains 5 floats (processing time, number of active workers,; event rate, MBytes read, number of effective sessions on the cluster); and it is filled each time the number of active workers changes or at; max 100 regular intervals at least 5 secs apart; in this way the ntuple; has at most O(100 entries + number of workers). To enable the saving of; the ntuple execute the following:;         proof->SetParameter(""PROOF_SaveProgressPerf"", ""yes"");; before running the query. The ntuple is called 'PROOF_ProgressPerfNtuple'.; Add support for worker autodiscovery in PROOF using the; Avahi/Bonjour technology. The new functionality is s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:2791,variab,variables,2791,proof/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html,1,['variab'],['variables']
Modifiability,"t the variable location is salvaged by folding; the GEPs effect into the DIExpression.; * The second GEP is also folded into the corresponding load. However, it is; insufficiently simple to be salvaged, and is emitted as a ``$noreg``; DBG_VALUE, indicating that the variable takes on an undefined location.; * The final dbg.value has its Value placed in virtual register ``%1``. Instruction Scheduling; ----------------------. A number of passes can reschedule instructions, notably instruction selection; and the pre-and-post RA machine schedulers. Instruction scheduling can; significantly change the nature of the program -- in the (very unlikely) worst; case the instruction sequence could be completely reversed. In such; circumstances LLVM follows the principle applied to optimizations, that it is; better for the debugger not to display any state than a misleading state.; Thus, whenever instructions are advanced in order of execution, any; corresponding DBG_VALUE is kept in its original position, and if an instruction; is delayed then the variable is given an undefined location for the duration; of the delay. To illustrate, consider this pseudo-MIR:. .. code-block:: text. %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; DBG_VALUE %7, $noreg, !5, !6. Imagine that the SUB32rr were moved forward to give us the following MIR:. .. code-block:: text. %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; DBG_VALUE %7, $noreg, !5, !6. In this circumstance LLVM would leave the MIR as shown above. Were we to move; the DBG_VALUE of virtual register %7 upwards with the SUB32rr, we ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:33316,variab,variable,33316,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['variab'],['variable']
Modifiability,"t to be promoted to a simple SSA value; instead of a memory location. .. _wellformed:. Well-Formedness; ---------------. It is important to note that this document describes 'well formed' LLVM; assembly language. There is a difference between what the parser accepts; and what is considered 'well formed'. For example, the following; instruction is syntactically okay, but not well formed:. .. code-block:: llvm. %x = add i32 1, %x. because the definition of ``%x`` does not dominate all of its uses. The; LLVM infrastructure provides a verification pass that may be used to; verify that an LLVM module is well formed. This pass is automatically; run by the parser after parsing input assembly and by the optimizer; before it outputs bitcode. The violations pointed out by the verifier; pass indicate bugs in transformation passes or input to the parser. .. _identifiers:. Identifiers; ===========. LLVM identifiers come in two basic types: global and local. Global; identifiers (functions, global variables) begin with the ``'@'``; character. Local identifiers (register names, types) begin with the; ``'%'`` character. Additionally, there are three different formats for; identifiers, for different purposes:. #. Named values are represented as a string of characters with their; prefix. For example, ``%foo``, ``@DivisionByZero``,; ``%a.really.long.identifier``. The actual regular expression used is; '``[%@][-a-zA-Z$._][-a-zA-Z$._0-9]*``'. Identifiers that require other; characters in their names can be surrounded with quotes. Special; characters may be escaped using ``""\xx""`` where ``xx`` is the ASCII; code for the character in hexadecimal. In this way, any character can; be used in a name value, even quotes themselves. The ``""\01""`` prefix; can be used on global values to suppress mangling.; #. Unnamed values are represented as an unsigned numeric value with; their prefix. For example, ``%12``, ``@2``, ``%44``.; #. Constants, which are described in the section Constants_ below. LLVM ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:2720,variab,variables,2720,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variables']
Modifiability,"t using a just-in-time compiler or an; interpreter. :program:`lli` is *not* an emulator. It will not execute IR of different architectures; and it can only interpret (or JIT-compile) for the host architecture. The JIT compiler takes the same arguments as other tools, like :program:`llc`,; but they don't necessarily work for the interpreter. If `filename` is not specified, then :program:`lli` reads the LLVM bitcode for the; program from standard input. The optional *args* specified on the command line are passed to the program as; arguments. GENERAL OPTIONS; ---------------. .. option:: -fake-argv0=executable. Override the ``argv[0]`` value passed into the executing program. .. option:: -force-interpreter={false,true}. If set to true, use the interpreter even if a just-in-time compiler is available; for this architecture. Defaults to false. .. option:: -help. Print a summary of command line options. .. option:: -load=pluginfilename. Causes :program:`lli` to load the plugin (shared object) named *pluginfilename* and use; it for optimization. .. option:: -stats. Print statistics from the code-generation passes. This is only meaningful for; the just-in-time compiler, at present. .. option:: -time-passes. Record the amount of time needed for each code-generation pass and print it to; standard error. .. option:: -version. Print out the version of :program:`lli` and exit without doing anything else. TARGET OPTIONS; --------------. .. option:: -mtriple=target triple. Override the target triple specified in the input bitcode file with the; specified string. This may result in a crash if you pick an; architecture which is not compatible with the current system. .. option:: -march=arch. Specify the architecture for which to generate assembly, overriding the target; encoded in the bitcode file. See the output of **llc -help** for a list of; valid architectures. By default this is inferred from the target triple or; autodetected to the current architecture. .. option:: -mcpu=cpu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst:1327,plugin,plugin,1327,interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,2,['plugin'],"['plugin', 'pluginfilename']"
Modifiability,"t visibility corresponds to ""external; linkage"" in the language.; ""``hidden``"" - Hidden style; Two declarations of an object with hidden visibility refer to the; same object if they are in the same shared object. Usually, hidden; visibility indicates that the symbol will not be placed into the; dynamic symbol table, so no other module (executable or shared; library) can reference it directly.; ""``protected``"" - Protected style; On ELF, protected visibility indicates that the symbol will be; placed in the dynamic symbol table, but that references within the; defining module will bind to the local symbol. That is, the symbol; cannot be overridden by another module. A symbol with ``internal`` or ``private`` linkage must have ``default``; visibility. .. _dllstorageclass:. DLL Storage Classes; -------------------. All Global Variables, Functions and Aliases can have one of the following; DLL storage class:. ``dllimport``; ""``dllimport``"" causes the compiler to reference a function or variable via; a global pointer to a pointer that is set up by the DLL exporting the; symbol. On Microsoft Windows targets, the pointer name is formed by; combining ``__imp_`` and the function or variable name.; ``dllexport``; On Microsoft Windows targets, ""``dllexport``"" causes the compiler to provide; a global pointer to a pointer in a DLL, so that it can be referenced with the; ``dllimport`` attribute. the pointer name is formed by combining ``__imp_``; and the function or variable name. On XCOFF targets, ``dllexport`` indicates; that the symbol will be made visible to other modules using ""exported""; visibility and thus placed by the linker in the loader section symbol table.; Since this storage class exists for defining a dll interface, the compiler,; assembler and linker know it is externally referenced and must refrain from; deleting the symbol. A symbol with ``internal`` or ``private`` linkage cannot have a DLL storage; class. .. _tls_model:. Thread Local Storage Models; ---------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:24602,variab,variable,24602,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variable']
Modifiability,"t way by; // default. If you build LLVM with RTTI this can be changed to a; // dynamic_cast for automatic error checking.; VariableExprAST *LHSE = static_cast<VariableExprAST*>(LHS.get());; if (!LHSE); return LogErrorV(""destination of '=' must be a variable"");. Unlike the rest of the binary operators, our assignment operator doesn't; follow the ""emit LHS, emit RHS, do computation"" model. As such, it is; handled as a special case before the other binary operators are handled.; The other strange thing is that it requires the LHS to be a variable. It; is invalid to have ""(x+1) = expr"" - only things like ""x = expr"" are; allowed. .. code-block:: c++. // Codegen the RHS.; Value *Val = RHS->codegen();; if (!Val); return nullptr;. // Look up the name.; Value *Variable = NamedValues[LHSE->getName()];; if (!Variable); return LogErrorV(""Unknown variable name"");. Builder->CreateStore(Val, Variable);; return Val;; }; ... Once we have the variable, codegen'ing the assignment is; straightforward: we emit the RHS of the assignment, create a store, and; return the computed value. Returning a value allows for chained; assignments like ""X = (Y = Z)"". Now that we have an assignment operator, we can mutate loop variables; and arguments. For example, we can now run code like this:. ::. # Function to print a double.; extern printd(x);. # Define ':' for sequencing: as a low-precedence operator that ignores operands; # and just returns the RHS.; def binary : 1 (x y) y;. def test(x); printd(x) :; x = 4 :; printd(x);. test(123);. When run, this example prints ""123"" and then ""4"", showing that we did; actually mutate the value! Okay, we have now officially implemented our; goal: getting this to work requires SSA construction in the general; case. However, to be really useful, we want the ability to define our; own local variables, let's add this next!. User-defined Local Variables; ============================. Adding var/in is just like any other extension we made to; Kaleidoscope: we extend t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:21938,variab,variable,21938,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['variab'],['variable']
Modifiability,"t which will be used to; discover and run tests in the test suite. Generally this will be a builtin test; format available from the *lit.formats* module. **test_source_root** The filesystem path to the test suite root. For out-of-dir; builds this is the directory that will be scanned for tests. **test_exec_root** For out-of-dir builds, the path to the test suite root inside; the object directory. This is where tests will be run and temporary output files; placed. **environment** A dictionary representing the environment to use when executing; tests in the suite. **standalone_tests** When true, mark a directory with tests expected to be run; standalone. Test discovery is disabled for that directory. *lit.suffixes* and; *lit.excludes* must be empty when this variable is true. **suffixes** For **lit** test formats which scan directories for tests, this; variable is a list of suffixes to identify test files. Used by: *ShTest*. **substitutions** For **lit** test formats which substitute variables into a test; script, the list of substitutions to perform. Used by: *ShTest*. **unsupported** Mark an unsupported directory, all tests within it will be; reported as unsupported. Used by: *ShTest*. **parent** The parent configuration, this is the config object for the directory; containing the test suite, or None. **root** The root configuration. This is the top-most :program:`lit` configuration in; the project. **pipefail** Normally a test using a shell pipe fails if any of the commands; on the pipe fail. If this is not desired, setting this variable to false; makes the test fail only if the last command in the pipe fails. **available_features** A set of features that can be used in `XFAIL`,; `REQUIRES`, and `UNSUPPORTED` directives. TEST DISCOVERY; ~~~~~~~~~~~~~~. Once test suites are located, :program:`lit` recursively traverses the source; directory (following *test_source_root*) looking for tests. When :program:`lit`; enters a sub-directory, it first checks to see if a neste",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst:16632,variab,variables,16632,interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,1,['variab'],['variables']
Modifiability,"t x> {; int Y = x;; int Yplus1 = !add(Y, 1);; int xplus1 = !add(x, 1);; }. let Y = 10 in {; def rec1 : C<5> {; }; }. def rec2 : C<5> {; let Y = 10;; }. In both cases, one where a top-level ``let`` is used to bind ``Y`` and one; where a local ``let`` does the same thing, the results are:. .. code-block:: text. def rec1 { // C; int Y = 10;; int Yplus1 = 11;; int xplus1 = 6;; }; def rec2 { // C; int Y = 10;; int Yplus1 = 11;; int xplus1 = 6;; }. ``Yplus1`` is 11 because the ``let Y`` is performed before the ``!add(Y,; 1)`` is resolved. Use this power wisely. Using Classes as Subroutines; ============================. As described in `Simple values`_, a class can be invoked in an expression; and passed template arguments. This causes TableGen to create a new anonymous; record inheriting from that class. As usual, the record receives all the; fields defined in the class. This feature can be employed as a simple subroutine facility. The class can; use the template arguments to define various variables and fields, which end; up in the anonymous record. Those fields can then be retrieved in the; expression invoking the class as follows. Assume that the field ``ret``; contains the final value of the subroutine. .. code-block:: text. int Result = ... CalcValue<arg>.ret ...;. The ``CalcValue`` class is invoked with the template argument ``arg``. It; calculates a value for the ``ret`` field, which is then retrieved at the; ""point of call"" in the initialization for the Result field. The anonymous; record created in this example serves no other purpose than to carry the; result value. Here is a practical example. The class ``isValidSize`` determines whether a; specified number of bytes represents a valid data size. The bit ``ret`` is; set appropriately. The field ``ValidSize`` obtains its initial value by; invoking ``isValidSize`` with the data size and retrieving the ``ret`` field; from the resulting anonymous record. .. code-block:: text. class isValidSize<int size> {; bit ret =",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:55409,variab,variables,55409,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['variab'],['variables']
Modifiability,"t {; int data;; struct LinkedList *next;; };. struct LinkedList * _Nullable getNext(struct LinkedList *l);. void updateNextData(struct LinkedList *list, int newData) {; struct LinkedList *next = getNext(list);; // Warning: Nullable pointer is dereferenced; next->data = 7;; }. .. _nullability-NullablePassedToNonnull:. nullability.NullablePassedToNonnull (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Warns when a nullable pointer is passed to a pointer which has a _Nonnull type. .. code-block:: objc. typedef struct Dummy { int val; } Dummy;; Dummy *_Nullable returnsNullable();; void takesNonnull(Dummy *_Nonnull);. void test() {; Dummy *p = returnsNullable();; takesNonnull(p); // warn; }. .. _nullability-NullableReturnedFromNonnull:. nullability.NullableReturnedFromNonnull (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Warns when a nullable pointer is returned from a function that has _Nonnull return type. .. _optin-checkers:. optin; ^^^^^. Checkers for portability, performance or coding style specific rules. .. _optin-core-EnumCastOutOfRange:. optin.core.EnumCastOutOfRange (C, C++); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for integer to enumeration casts that would produce a value with no; corresponding enumerator. This is not necessarily undefined behavior, but can; lead to nasty surprises, so projects may decide to use a coding standard that; disallows these ""unusual"" conversions. Note that no warnings are produced when the enum type (e.g. `std::byte`) has no; enumerators at all. .. code-block:: cpp. enum WidgetKind { A=1, B, C, X=99 };. void foo() {; WidgetKind c = static_cast<WidgetKind>(3); // OK; WidgetKind x = static_cast<WidgetKind>(99); // OK; WidgetKind d = static_cast<WidgetKind>(4); // warn; }. **Limitations**. This checker does not accept the coding pattern where an enum type is used to; store combinations of flag values:. .. code-block:: cpp. enum AnimalFlags; {; HasClaws = 1,; CanFly = 2,; EatsFish = 4,; Endangered = 8; };. AnimalFla",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:12839,portab,portability,12839,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['portab'],['portability']
Modifiability,"t(1.,2.,-3.);; ```. We are creating an object on the stack. A FORTRAN programmer may be; familiar with the idea; it is not unlike a local variable in a; function or subroutine. Although there are still a few old timers who; do not know it, FORTRAN is under no obligation to save local variables; once the function or subroutine returns unless the SAVE statement is; used. If not then it is likely that FORTRAN will place them on the; stack and they will ""pop off"" when the RETURN statement is reached. To; give an object more permanence it has to be placed on the heap. ``` {.cpp}; root[] .L Quad.cxx; root[] Quad *my_objptr = new Quad(1.,2.,-3.);; ```. The second line declares a pointer to `Quad` called `my_objptr`. From; the syntax point of view, this is just like all the other declarations; we have seen so far, i.e. this is a stack variable. The value of the; pointer is set equal to. ``` {.cpp}; new Quad(1.,2.,-3.);; ```. `new`, despite its looks, is an operator and creates an object or; variable of the type that comes next, `Quad` in this case, on the; heap. Just as with stack objects it has to be initialized by calling; its constructor. The syntax requires that the argument list follows the; type. This one statement has brought two items into existence, one on; the heap and one on the stack. The heap object will live until the; delete operator is applied to it. There is no FORTRAN parallel to a heap object; variables either come; or go as control passes in and out of a function or subroutine, or,; like a COMMON block variables, live for the lifetime of the program.; However, most people in HEP who use FORTRAN will have experience of a; memory manager and the act of creating a bank is a good equivalent of; a heap object. For those who know systems like ZEBRA, it will come as; a relief to learn that objects do not move, C++ does not garbage; collect, so there is never a danger that a pointer to an object; becomes invalid for that reason. However, having created an object",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/ALittleC++.md:9743,variab,variable,9743,documentation/users-guide/ALittleC++.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/ALittleC++.md,1,['variab'],['variable']
Modifiability,"t). All the relevant attributes can be read; from either the inline descriptor or the descriptor of the block. Array elements are identified by the ``Offset`` field of pointers,; pointing to past the inline descriptors for composites and before; the actual data in the case of primitive arrays. The ``Offset``; points to the offset where primitives can be read from. As an example,; ``a.c + 1`` would have the same base as ``a.c`` since it is an element; of ``a.c``, but its offset would point to ``&a.c[1]``. The; array-to-pointer decay operation adjusts a pointer to an array (where; the offset is equal to the base) to a pointer to the first element. ExternPointer; ~~~~~~~~~~~~~. Extern pointers can be derived, pointing into symbols which are not; readable from constexpr. An external pointer consists of a base; declaration, along with a path designating a subobject, similar to; the ``LValuePath`` of an APValue. Extern pointers can be converted; to block pointers if the underlying variable is defined after the; pointer is created, as is the case in the following example:. .. code-block:: c. extern const int a;; constexpr const int *p = &a;; const int a = 5;; static_assert(*p == 5, ""x"");. TargetPointer; ~~~~~~~~~~~~~. While null pointer arithmetic or integer-to-pointer conversion is; banned in constexpr, some expressions on target offsets must be folded,; replicating the behaviour of the ``offsetof`` builtin. Target pointers; are characterised by 3 offsets: a field offset, an array offset and a; base offset, along with a descriptor specifying the type the pointer is; supposed to refer to. Array indexing adjusts the array offset, while the; field offset is adjusted when a pointer to a member is created. Casting; an integer to a pointer sets the value of the base offset. As a special; case, null pointers are target pointers with all offsets set to 0. TypeInfoPointer; ~~~~~~~~~~~~~~~. ``TypeInfoPointer`` tracks two types: the type assigned to; ``std::type_info`` and the type w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ConstantInterpreter.rst:12898,variab,variable,12898,interpreter/llvm-project/clang/docs/ConstantInterpreter.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ConstantInterpreter.rst,1,['variab'],['variable']
Modifiability,"t); if(""${out}"" EQUAL 0); string(REPLACE ""BUILTINS_${name}_"" """" new_name ${variable_name}); if(new_name STREQUAL CACHE_FILES); foreach(cache IN LISTS ${variable_name}); list(APPEND ${name}_extra_args -C ${cache}); endforeach(); else(); string(REPLACE "";"" ""|"" new_value ""${${variable_name}}""); list(APPEND ${name}_extra_args ""-D${new_name}=${new_value}""); endif(); endif(); endforeach(). llvm_ExternalProject_Add(builtins-${name}; ${compiler_rt_path}/lib/builtins; DEPENDS ${ARG_DEPENDS}; CMAKE_ARGS -DLLVM_LIBRARY_OUTPUT_INTDIR=${LLVM_LIBRARY_DIR}; -DLLVM_RUNTIME_OUTPUT_INTDIR=${LLVM_TOOLS_BINARY_DIR}; -DLLVM_ENABLE_PER_TARGET_RUNTIME_DIR=ON; -DCMAKE_C_COMPILER_WORKS=ON; -DCMAKE_ASM_COMPILER_WORKS=ON; -DCOMPILER_RT_DEFAULT_TARGET_ONLY=ON; ${COMMON_CMAKE_ARGS}; ${${name}_extra_args}; USE_TOOLCHAIN; ${EXTRA_ARGS} ${ARG_EXTRA_ARGS}); endfunction(). # If compiler-rt is present we need to build the builtin libraries first. This; # is required because the other runtimes need the builtin libraries present; # before the just-built compiler can pass the configuration tests.; get_compiler_rt_path(compiler_rt_path); if(compiler_rt_path); if(NOT LLVM_BUILTIN_TARGETS); builtin_default_target(${compiler_rt_path}; DEPENDS clang-resource-headers); else(); if(""default"" IN_LIST LLVM_BUILTIN_TARGETS); builtin_default_target(${compiler_rt_path}; DEPENDS clang-resource-headers); list(REMOVE_ITEM LLVM_BUILTIN_TARGETS ""default""); else(); add_custom_target(builtins); add_custom_target(install-builtins); add_custom_target(install-builtins-stripped); endif(). foreach(target ${LLVM_BUILTIN_TARGETS}); check_apple_target(${target} builtin). builtin_register_target(${compiler_rt_path} ${target}; DEPENDS clang-resource-headers; CMAKE_ARGS -DLLVM_DEFAULT_TARGET_TRIPLE=${target}; EXTRA_ARGS TARGET_TRIPLE ${target}). add_dependencies(builtins builtins-${target}); add_dependencies(install-builtins install-builtins-${target}); add_dependencies(install-builtins-stripped install-builtins-${target}-stripped); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/runtimes/CMakeLists.txt:4827,config,configuration,4827,interpreter/llvm-project/llvm/runtimes/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/runtimes/CMakeLists.txt,1,['config'],['configuration']
Modifiability,"t);; void b(int volatile);; void c(volatile int);; void d(volatile int*);; void e(int volatile) {};; functionDecl(hasAnyParameter(hasType(isVolatileQualified()))); matches ""void b(int volatile)"", ""void c(volatile int)"" and; ""void e(int volatile) {}"". It does not match d as there; is no top-level volatile on the parameter type ""volatile int *"". Matcher<Stmt>equalsBoundNodestd::string ID; Matches if a node equals a previously bound node. Matches a node if it equals the node previously bound to ID. Given; class X { int a; int b; };; cxxRecordDecl(; has(fieldDecl(hasName(""a""), hasType(type().bind(""t"")))),; has(fieldDecl(hasName(""b""), hasType(type(equalsBoundNode(""t"")))))); matches the class X, as a and b have the same type. Note that when multiple matches are involved via forEach* matchers,; equalsBoundNodes acts as a filter.; For example:; compoundStmt(; forEachDescendant(varDecl().bind(""d"")),; forEachDescendant(declRefExpr(to(decl(equalsBoundNode(""d"")))))); will trigger a match for each combination of variable declaration; and reference to that variable declaration within a compound statement. Matcher<Stmt>equalsNodeconst Stmt* Other; Matches if a node equals another node. Stmt has pointer identity in the AST. Matcher<Stmt>isExpandedFromMacrostd::string MacroName; Matches statements that are (transitively) expanded from the named macro.; Does not match if only part of the statement is expanded from that macro or; if different parts of the statement are expanded from different; appearances of the macro. Matcher<Stmt>isExpansionInFileMatchingStringRef RegExp, Regex::RegexFlags Flags = NoFlags; Matches AST nodes that were expanded within files whose name is; partially matching a given regex. Example matches Y but not X; (matcher = cxxRecordDecl(isExpansionInFileMatching(""AST.*"")); #include ""ASTMatcher.h""; class X {};; ASTMatcher.h:; class Y {};. Usable as: Matcher<Decl>, Matcher<Stmt>, Matcher<TypeLoc>. If the matcher is used in clang-query, RegexFlags parameter; should ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html:115021,variab,variable,115021,interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,2,['variab'],['variable']
Modifiability,"t, for file types; not supported you will get a generic window showing some basic file info. The idea of QL is that file content can be shown without the heavy application; startup process. Generating a QL view of a ROOT file depends on the size of the; file, but generally it is a quick operation. Get the binary for the ROOTQL plugin from:. ftp://root.cern.ch/root/ROOTQL.tgz. To install the plugin, after untarring the above file, just drag the bundle; ROOTQL.qlgenerator to /Library/QuickLook (global, i.e. for all users on a; system) or to ~/Library/QuickLook (local, this user only) directory.; You may need to create that folder if it doesn't already exist. To build from source, get it from svn using:. svn co http://root.cern.ch/svn/root/trunk/misc/rootql rootql. Open the ROOTQL project in Xcode and click on ""Build"" (make sure the Active; Build Configuration is set the ""Release""). Copy the resulting; plugin from build/Release to the desired QuickLook directory. SpotLight plugin for MacOS X. This is a Spotlight plugin that allows ROOT files to be indexed by SL.; Once indexed SL can find ROOT files based on the names and titles of the; objects in the files. Spotlight is available on MacOS X since version 10.4 (Tiger). To use SL; select the SL icon on the top right of the menubar and type in a search text. Get the binary for the ROOTSL plugin from:. ftp://root.cern.ch/root/ROOTSL.tgz. To install the plugin, after untarring the above file, just drag the bundle; ROOTSL.mdimporter to /Library/Spotlight (global, i.e. for all users on a; system) or to ~/Library/Spotlight (local, this user only) directory.; You may need to create that folder if it doesn't already exist. To build from source, get it from svn using:. svn co http://root.cern.ch/svn/root/trunk/misc/rootsl rootsl. Open the ROOTSL project in Xcode and click on ""Build"" (make sure the Active; Build Configuration is set the ""Release""). Copy the resulting; plugin from build/Release to the desired QuickLook directory.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/misc/doc/v524/index.html:1361,plugin,plugin,1361,misc/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/misc/doc/v524/index.html,4,['plugin'],['plugin']
Modifiability,"t, given a number of other; changes and restrictions in ARC, is to provide a specialized tool to assist; users in that migration. Implementing these methods was banned because they are too integral to the; semantics of ARC; many tricks which worked tolerably under manual reference; counting will misbehave if ARC performs an ephemeral extra retain or two. If; absolutely required, it is still possible to implement them in non-ARC code,; for example in a category; the implementations must obey the :ref:`semantics; <arc.objects.retains>` laid out elsewhere in this document. .. _arc.misc.special_methods.dealloc:. ``dealloc``; ^^^^^^^^^^^. A program is ill-formed if it contains a message send or ``@selector``; expression for the selector ``dealloc``. .. admonition:: Rationale. There are no legitimate reasons to call ``dealloc`` directly. A class may provide a method definition for an instance method named; ``dealloc``. This method will be called after the final ``release`` of the; object but before it is deallocated or any of its instance variables are; destroyed. The superclass's implementation of ``dealloc`` will be called; automatically when the method returns. .. admonition:: Rationale. Even though ARC destroys instance variables automatically, there are still; legitimate reasons to write a ``dealloc`` method, such as freeing; non-retainable resources. Failing to call ``[super dealloc]`` in such a; method is nearly always a bug. Sometimes, the object is simply trying to; prevent itself from being destroyed, but ``dealloc`` is really far too late; for the object to be raising such objections. Somewhat more legitimately, an; object may have been pool-allocated and should not be deallocated with; ``free``; for now, this can only be supported with a ``dealloc``; implementation outside of ARC. Such an implementation must be very careful; to do all the other work that ``NSObject``'s ``dealloc`` would, which is; outside the scope of this document to describe. The instance va",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:87786,variab,variables,87786,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['variab'],['variables']
Modifiability,"t, it will emit globals to the section specified.; Additionally, the global can placed in a comdat if the target has the necessary; support. External declarations may have an explicit section specified. Section; information is retained in LLVM IR for targets that make use of this; information. Attaching section information to an external declaration is an; assertion that its definition is located in the specified section. If the; definition is located in a different section, the behavior is undefined. LLVM allows an explicit code model to be specified for globals. If the; target supports it, it will emit globals in the code model specified,; overriding the code model used to compile the translation unit.; The allowed values are ""tiny"", ""small"", ""kernel"", ""medium"", ""large"".; This may be extended in the future to specify global data layout that; doesn't cleanly fit into a specific code model. By default, global initializers are optimized by assuming that global; variables defined within the module are not modified from their; initial values before the start of the global initializer. This is; true even for variables potentially accessible from outside the; module, including those with external linkage or appearing in; ``@llvm.used`` or dllexported variables. This assumption may be suppressed; by marking the variable with ``externally_initialized``. An explicit alignment may be specified for a global, which must be a; power of 2. If not present, or if the alignment is set to zero, the; alignment of the global is set by the target to whatever it feels; convenient. If an explicit alignment is specified, the global is forced; to have exactly that alignment. Targets and optimizers are not allowed; to over-align the global if the global has an assigned section. In this; case, the extra alignment could be observable: for example, code could; assume that the globals are densely packed in their section and try to; iterate over them as an array, alignment padding would break thi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:33990,variab,variables,33990,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variables']
Modifiability,"t- or right-aligned to provide; equal detection of both underflows and overflows. Use after Free Detection; ------------------------. The guarded allocation pool also provides use-after-free detection. Whenever a; sampled allocation is deallocated, we map its guarded slot as inaccessible. Any; memory accesses after deallocation will thus trigger the crash handler, and we; can provide useful information about the source of the error. Please note that the use-after-free detection for a sampled allocation is; transient. To keep memory overhead fixed while still detecting bugs, deallocated; slots are randomly reused to guard future allocations. Usage; =====. GWP-ASan already ships by default in the; `Scudo Hardened Allocator <https://llvm.org/docs/ScudoHardenedAllocator.html>`_,; so building with ``-fsanitize=scudo`` is the quickest and easiest way to try out; GWP-ASan. Options; -------. GWP-ASan's configuration is managed by the supporting allocator. We provide a; generic configuration management library that is used by Scudo. It allows; several aspects of GWP-ASan to be configured through the following methods:. - When the GWP-ASan library is compiled, by setting; ``-DGWP_ASAN_DEFAULT_OPTIONS`` to the options string you want set by default.; If you're building GWP-ASan as part of a compiler-rt/LLVM build, add it during; cmake configure time (e.g. ``cmake ... -DGWP_ASAN_DEFAULT_OPTIONS=""...""``). If; you're building GWP-ASan outside of compiler-rt, simply ensure that you; specify ``-DGWP_ASAN_DEFAULT_OPTIONS=""...""`` when building; ``optional/options_parser.cpp``). - By defining a ``__gwp_asan_default_options`` function in one's program that; returns the options string to be parsed. Said function must have the following; prototype: ``extern ""C"" const char* __gwp_asan_default_options(void)``, with a; default visibility. This will override the compile time define;. - Depending on allocator support (Scudo has support for this mechanism): Through; an environment variable, co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst:5102,config,configuration,5102,interpreter/llvm-project/llvm/docs/GwpAsan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst,1,['config'],['configuration']
Modifiability,"t...). If you add `$URLTOSTAGE` and/or; `$TREENAME` in the *shell\_command*, they'll be substituted; respectively with the destination URL and the default ROOT tree name; in the file (as specified in the dataset staging request from ROOT). An example:. dsmgrd.stagecmd /path/to/afdsmgrd-xrd-stage-verify.sh ""$URLTOSTAGE"" ""$TREENAME"". Return value of the command is ignored: standard output is; considered, as explained here. Defaults to `/bin/false`. dsmgrd.cmdtimeoutsecs *secs*; : Timeout on staging command, expressed in seconds: after this; timeout, the command is considered failed and it is killed (in first; place with `SIGSTOP`, then if it is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; yo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:4753,plugin,plugin,4753,proof/doc/confman/DatasetStager.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md,1,['plugin'],['plugin']
Modifiability,"t.; Note: possibly an enhancement to ; core.NullDereference. struct S {int i;};. struct S* f();. void test() {; struct S *p = f();; if (p->i && p) {}; // warn; }. different.MultipleAccessors; (C++); Identical accessor bodies. Possibly a misprint. class A {; int i;; int j;; public:; int getI() { return i; }; int getJ() { return i; } // warn; };. class A {; int i;; int j;; public:; void setI(int& ii) { i = ii; }; void setJ(int& jj) { i = jj; } // warn; };. different.AccessorsForPublic; (C++); Accessors exist for a public class field. Should this field really be; public?. class A {; public:; int i; // warn; int getI() { return i; }; void setI(int& ii) { i = ii; }; };. different.LibFuncResultUnised; (C, C++); Calling a function ignoring its return value is of no use (create the list of; known system/library/API functions falling into this category). #include <vector>. void test() {; std::vector<int> v;; v.empty(); // warn; }. different.WrongVarForStmt; (C, C++); Wrong variable is possibly used in the loop/cond-expression of; the for statement. Did you mean; 'proper_variable_name'?. void test() {; int i = 0;; int j = 0;; for (i = 0; i < 3; j += 1); // warn; }. void test() {; int i = 0;; int j = 0;; for (int j = 0; i < 3; ++j); // warn; }. different.FloatingCompare; (C); Comparing floating point numbers may be not precise. #include <math.h>. double test() {; double b = sin(M_PI / 6.0);; if (b == 0.5) // warn; b = 0;; return b;; }. different.BitwiseOpBoolArg; (C, C++); Boolean value met at the left/right part of the bitwise &; or | operator.; Did you mean && (||) ?. int f();. void test() {; bool b = true;; if (b & f()) {} // warn; }. different.LabelInsideSwitch; (C); Possibly a misprint: label found inside a switch(); statement. void test(int c) {; switch(c){; case 1:; c += 1; break;; defalt: // warn (did you mean 'default'?); c -= 1; break;; }; }. different.IdenticalCondIfIf; (C); The conditions of two subsequent if statements are; identical. int test(int c) {; if (c > 5);",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html:21280,variab,variable,21280,interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,1,['variab'],['variable']
Modifiability,"t/issues/7872)] - TExecutorCRTP::Map() should support void; * [[#7871](https://github.com/root-project/root/issues/7871)] - Usability of TExecutor::MapReduce; * [[#7845](https://github.com/root-project/root/issues/7845)] - Improve TMatrix reference documentation; * [[#7805](https://github.com/root-project/root/issues/7805)] - Inconsistent and unintuitive behaviour of TFormula::SetParNames and TFormula::SetParameters; * [[#7774](https://github.com/root-project/root/issues/7774)] - Unreasonably slow behaviour of CompileMacro; * [[#7699](https://github.com/root-project/root/issues/7699)] - [VecOps] Make free functions in VecOps better visible; * [[#7686](https://github.com/root-project/root/issues/7686)] - [PyROOT] Segfault when creating proxy to derived class with multiple overloads; * [[#7669](https://github.com/root-project/root/issues/7669)] - Inconsistent behaviour in wildcard import; * [[#7644](https://github.com/root-project/root/issues/7644)] - Provide in the cmake configuration the C++ standard which was used to compile ROOT; * [[#7627](https://github.com/root-project/root/issues/7627)] - Fix TMVA group links; * [[#7159](https://github.com/root-project/root/issues/7159)] - TNetXNGFile::Open fails with double slash (//) in path; * [[#7128](https://github.com/root-project/root/issues/7128)] - Cannot build ROOT if another ROOT at /usr/local; * [[#6900](https://github.com/root-project/root/issues/6900)] - mathmore: invalid roots for a quartic polynomial; * [[#6811](https://github.com/root-project/root/issues/6811)] - Bug displaying several 3D objects such as TGraph2D on the same canvas ; * [[#6755](https://github.com/root-project/root/issues/6755)] - Greek letter epsilon not rendered correctly using TLatex with OpenGL.CanvasPreferGL option, segmentation fault.; * [[#6753](https://github.com/root-project/root/issues/6753)] - CMake dependency on Python: use targets; * [[#6616](https://github.com/root-project/root/issues/6616)] - hadd writes files with unspecified co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:48921,config,configuration,48921,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['config'],['configuration']
Modifiability,"t/~ubuntu-toolchain-r/+archive/test; .. _ask ubuntu stack exchange:; https://askubuntu.com/questions/466651/how-do-i-use-the-latest-gcc-on-ubuntu/581497#58149; .. _github gist:; https://gist.github.com/application2000/73fd6f4bf1be6600a2cf9f56315a2d91. Easy steps for installing a specific version of GCC:. .. code-block:: console. % gcc_version=7.4.0; % wget https://ftp.gnu.org/gnu/gcc/gcc-${gcc_version}/gcc-${gcc_version}.tar.bz2; % wget https://ftp.gnu.org/gnu/gcc/gcc-${gcc_version}/gcc-${gcc_version}.tar.bz2.sig; % wget https://ftp.gnu.org/gnu/gnu-keyring.gpg; % signature_invalid=`gpg --verify --no-default-keyring --keyring ./gnu-keyring.gpg gcc-${gcc_version}.tar.bz2.sig`; % if [ $signature_invalid ]; then echo ""Invalid signature"" ; exit 1 ; fi; % tar -xvjf gcc-${gcc_version}.tar.bz2; % cd gcc-${gcc_version}; % ./contrib/download_prerequisites; % cd ..; % mkdir gcc-${gcc_version}-build; % cd gcc-${gcc_version}-build; % $PWD/../gcc-${gcc_version}/configure --prefix=$HOME/toolchains --enable-languages=c,c++; % make -j$(nproc); % make install. For more details, check out the excellent `GCC wiki entry`_, where I got most; of this information from. .. _GCC wiki entry:; https://gcc.gnu.org/wiki/InstallingGCC. Once you have a GCC toolchain, configure your build of LLVM to use the new; toolchain for your host compiler and C++ standard library. Because the new; version of libstdc++ is not on the system library search path, you need to pass; extra linker flags so that it can be found at link time (``-L``) and at runtime; (``-rpath``). If you are using CMake, this invocation should produce working; binaries:. .. code-block:: console. % mkdir build; % cd build; % CC=$HOME/toolchains/bin/gcc CXX=$HOME/toolchains/bin/g++ \; cmake .. -DCMAKE_CXX_LINK_FLAGS=""-Wl,-rpath,$HOME/toolchains/lib64 -L$HOME/toolchains/lib64"". If you fail to set rpath, most LLVM binaries will fail on startup with a message; from the loader similar to ``libstdc++.so.6: version `GLIBCXX_3.4.20' not; found``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:17668,config,configure,17668,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['config'],['configure']
Modifiability,"t2Bcc %bb.4, 0 /* CC:eq */, killed $cpsr. As these annotations are comments, they are ignored by the MI parser.; Comments can be added or customized by overriding InstrInfo's hook; ``createMIROperandComment()``. Debug-Info constructs; ---------------------. Most of the debugging information in a MIR file is to be found in the metadata; of the embedded module. Within a machine function, that metadata is referred to; by various constructs to describe source locations and variable locations. Source locations; ^^^^^^^^^^^^^^^^. Every MIR instruction may optionally have a trailing reference to a; ``DILocation`` metadata node, after all operands and symbols, but before; memory operands:. .. code-block:: text. $rbp = MOV64rr $rdi, debug-location !12. The source location attachment is synonymous with the ``!dbg`` metadata; attachment in LLVM-IR. The absence of a source location attachment will be; represented by an empty ``DebugLoc`` object in the machine instruction. Fixed variable locations; ^^^^^^^^^^^^^^^^^^^^^^^^. There are several ways of specifying variable locations. The simplest is; describing a variable that is permanently located on the stack. In the stack; or fixedStack attribute of the machine function, the variable, scope, and; any qualifying location modifier are provided:. .. code-block:: text. - { id: 0, name: offset.addr, offset: -24, size: 8, alignment: 8, stack-id: default,; 4 debug-info-variable: '!1', debug-info-expression: '!DIExpression()',; debug-info-location: '!2' }. Where:. - ``debug-info-variable`` identifies a DILocalVariable metadata node,. - ``debug-info-expression`` adds qualifiers to the variable location,. - ``debug-info-location`` identifies a DILocation metadata node. These metadata attributes correspond to the operands of a ``llvm.dbg.declare``; IR intrinsic, see the :ref:`source level debugging<format_common_intrinsics>`; documentation. Varying variable locations; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Variables that are not always on the stack o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MIRLangRef.rst:24495,variab,variable,24495,interpreter/llvm-project/llvm/docs/MIRLangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MIRLangRef.rst,1,['variab'],['variable']
Modifiability,"t: rootdev [at] root.cern.ch; File a bug; If there is something wrong please check our bug database here and submit the bug description if it doesn't exist; Open tasks; We have lots of ideas how to make cling better, but we don't have enough time for realizing them all. Here are tasks that are on our todo lists since a while, but we still cannot manage to get them done. They are not difficult to implement and excellent for getting to know cling. If you find something interesting, please go ahead and get your hands dirty!; The list is prioritized in descending order:; Extending and improving the multiline input mode - The multiline mode has to figure out automatically whether the user's input is still incomplete. For example ""if (a < 0) {"" is not fully completed input. Cling should'n try to process the line but to be smart enough to understand that it should wait for continuation. Currently cling switches multiline mode only when there is trailing ""{"". It has to be extended to detect trailing +, unbalanced ',"" and so on.; Implementing auto completion - Clang has good interface for autocompletion which proposes possible completion options considering the current input.; Implementing error recovery verifier - One of the most important parts in cling is the error recovery. The error recovery takes care of reverting clang's internal structures on error in the user input. For instance, user types int i; error_here;. int i should be reverted and the entire input should be invalidated. This is very complex because many implicit template instantiations could be triggered and so on. The idea of the future verifier is to serialize the AST with all the lookup structures (probably in pch or pcm), trigger an error causing a lot of things to happen in clang internally and serialize the new AST. The comparison with the old one must return perfect match.; Enabling clang's static analyzer - coming soon; Enabling ObjectiveC/ObjectiveC++ support - coming soon. Copyright © Cling Team; .",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/www/old/contact.html:1497,extend,extended,1497,interpreter/cling/www/old/contact.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/www/old/contact.html,1,['extend'],['extended']
Modifiability,"t; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ### List of VAF-specific variables. There are some special variables that need to be set in one of the above; configuration files. `$VafConf_LocalPodLocation`; : Full path to the PoD installation on the client. > The `$VafConf_LocalPodLocation` variable must be set before the; > `PoD_env.sh` script gets sourced, so set it either in; > `common.before`, `local.before` or `local.conf`. Since PoD is; > usually system-wide installed, its location is normally; > system-wide set in either the `local.conf` file by the system; > administrator. `$VafConf_RemotePodLocation`; : Full path to the PoD installation on the VAF master node. *Note: this variable should be set in the configuration files for; the local environment despite it refers to a software present on the; remote nodes.*. `$VafConf_PodRms` *(optional)*; : Name of the Resource Management System used for submitting PoD jobs.; Run `pod-submit -l` to see the possible values. If not set, defaults to `condor`. `$VafConf_PodQueue` *(optional)*; : Queue name where to submit PoD jobs. If no queue has been given, the default ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:3341,variab,variables,3341,proof/doc/confman/UsingVirtualAnalysisFacility.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md,2,"['config', 'variab']","['configuration', 'variables']"
Modifiability,"t>` testing tool. This test procedure uses ``RUN``; lines in the actual test case to determine how to run the test. See the; :doc:`TestingGuide` for more details. * LLVM contains an optional package called ``llvm-test``, which provides; benchmarks and programs that are known to compile with the Clang front; end. You can use these programs to test your code, gather statistical; information, and compare it to the current LLVM performance statistics. Currently, there is no way to hook your tests directly into the ``llvm/test``; testing harness. You will simply need to find a way to use the source; provided within that directory on your own. Typically, you will want to build your **lib** directory first followed by your; **tools** directory. Writing LLVM Style Makefiles; ============================. The LLVM build system provides a convenient way to build libraries and; executables. Most of your project Makefiles will only need to define a few; variables. Below is a list of the variables one can set and what they can; do:. Required Variables; ------------------. ``LEVEL``. This variable is the relative path from this ``Makefile`` to the top; directory of your project's source code. For example, if your source code; is in ``/tmp/src``, then the ``Makefile`` in ``/tmp/src/jump/high``; would set ``LEVEL`` to ``""../..""``. Variables for Building Subdirectories; -------------------------------------. ``DIRS``. This is a space separated list of subdirectories that should be built. They; will be built, one at a time, in the order specified. ``PARALLEL_DIRS``. This is a list of directories that can be built in parallel. These will be; built after the directories in DIRS have been built. ``OPTIONAL_DIRS``. This is a list of directories that can be built if they exist, but will not; cause an error if they do not exist. They are built serially in the order; in which they are listed. Variables for Building Libraries; --------------------------------. ``LIBRARYNAME``. This variable c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Projects.rst:4335,variab,variables,4335,interpreter/llvm-project/llvm/docs/Projects.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Projects.rst,1,['variab'],['variables']
Modifiability,tGen/PrototypeTestGen.cpp; libc/utils/LibcTableGenUtil/APIIndexer.cpp; libc/utils/LibcTableGenUtil/APIIndexer.h; libc/utils/MPFRWrapper/check_mpfr.cpp; libc/utils/MPFRWrapper/MPFRUtils.cpp; libc/utils/MPFRWrapper/MPFRUtils.h; libc/utils/testutils/ExecuteFunction.h; libc/utils/testutils/ExecuteFunctionUnix.cpp; libc/utils/testutils/FDReader.h; libc/utils/testutils/FDReaderUnix.cpp; libc/utils/testutils/RandUtils.cpp; libc/utils/testutils/RandUtils.h; libc/utils/testutils/StreamWrapper.h; libc/utils/testutils/Timer.cpp; libc/utils/testutils/Timer.h; libc/utils/tools/WrapperGen/Main.cpp; libc/utils/UnitTest/FPExceptMatcher.cpp; libc/utils/UnitTest/FPExceptMatcher.h; libc/utils/UnitTest/FPMatcher.cpp; libc/utils/UnitTest/FPMatcher.h; libc/utils/UnitTest/FuchsiaTest.h; libc/utils/UnitTest/LibcTest.cpp; libc/utils/UnitTest/LibcTestMain.cpp; libc/utils/UnitTest/MemoryMatcher.cpp; libc/utils/UnitTest/MemoryMatcher.h; libc/utils/UnitTest/PlatformDefs.h; libc/utils/UnitTest/Test.h; libclc/generic/include/config.h; libclc/generic/include/clc/as_type.h; libclc/generic/include/clc/clcfunc.h; libclc/generic/include/clc/async/async_work_group_copy.h; libclc/generic/include/clc/async/async_work_group_strided_copy.h; libclc/generic/include/clc/async/prefetch.h; libclc/generic/include/clc/async/wait_group_events.h; libclc/generic/include/clc/atomic/atomic_add.h; libclc/generic/include/clc/atomic/atomic_and.h; libclc/generic/include/clc/atomic/atomic_max.h; libclc/generic/include/clc/atomic/atomic_min.h; libclc/generic/include/clc/atomic/atomic_or.h; libclc/generic/include/clc/atomic/atomic_sub.h; libclc/generic/include/clc/atomic/atomic_xor.h; libclc/generic/include/clc/cl_khr_global_int32_base_atomics/atom_add.h; libclc/generic/include/clc/cl_khr_global_int32_base_atomics/atom_dec.h; libclc/generic/include/clc/cl_khr_global_int32_base_atomics/atom_inc.h; libclc/generic/include/clc/cl_khr_global_int32_base_atomics/atom_sub.h; libclc/generic/include/clc/cl_khr_global_int32_base_atomics,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:149576,config,config,149576,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['config'],['config']
Modifiability,"tHub teams. This `mapping <https://github.com/llvm/llvm-project/blob/main/.github/new-prs-labeler.yml>`_; indicates which team is associated with a particular paths in the repository. You can also subscribe to the ""commits"" mailing list for a subproject you're interested in,; such as `llvm-commits; <http://lists.llvm.org/mailman/listinfo/llvm-commits>`_, `cfe-commits; <http://lists.llvm.org/mailman/listinfo/cfe-commits>`_, or `lldb-commits; <http://lists.llvm.org/mailman/listinfo/lldb-commits>`_. Missing features and bugs are tracked through our `GitHub issue tracker <https://github.com/llvm/llvm-project/issues>`_; and assigned labels. We recommend that active developers monitor incoming issues.; You can subscribe for notification for specific components by joining; one of the `issue-subscribers-* <https://github.com/orgs/llvm/teams?query=issue-subscribers>`_; teams.; You may also subscribe to the `llvm-bugs; <http://lists.llvm.org/mailman/listinfo/llvm-bugs>`_ email list to keep track; of bugs and enhancements occurring in the entire project. We really appreciate people; who are proactive at catching incoming bugs in their components and dealing with them; promptly. Please be aware that all public LLVM mailing lists and discourse forums are public and archived, and; that notices of confidentiality or non-disclosure cannot be respected. .. _patch:; .. _one-off patches:. Making and Submitting a Patch; -----------------------------. When making a patch for review, the goal is to make it as easy for the reviewer; to read it as possible. As such, we recommend that you:. #. Make your patch against git main, not a branch, and not an old version; of LLVM. This makes it easy to apply the patch. For information on how to; clone from git, please see the :ref:`Getting Started Guide; <checkout>`. #. Similarly, patches should be submitted soon after they are generated. Old; patches may not apply correctly if the underlying code changes between the; time the patch was created and ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:3349,enhance,enhancements,3349,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['enhance'],['enhancements']
Modifiability,"tKind x = static_cast<WidgetKind>(99); // OK; WidgetKind d = static_cast<WidgetKind>(4); // warn; }. **Limitations**. This checker does not accept the coding pattern where an enum type is used to; store combinations of flag values:. .. code-block:: cpp. enum AnimalFlags; {; HasClaws = 1,; CanFly = 2,; EatsFish = 4,; Endangered = 8; };. AnimalFlags operator|(AnimalFlags a, AnimalFlags b); {; return static_cast<AnimalFlags>(static_cast<int>(a) | static_cast<int>(b));; }. auto flags = HasClaws | CanFly;. Projects that use this pattern should not enable this optin checker. .. _optin-cplusplus-UninitializedObject:. optin.cplusplus.UninitializedObject (C++); """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". This checker reports uninitialized fields in objects created after a constructor; call. It doesn't only find direct uninitialized fields, but rather makes a deep; inspection of the object, analyzing all of its fields' subfields.; The checker regards inherited fields as direct fields, so one will receive; warnings for uninitialized inherited data members as well. .. code-block:: cpp. // With Pedantic and CheckPointeeInitialization set to true. struct A {; struct B {; int x; // note: uninitialized field 'this->b.x'; // note: uninitialized field 'this->bptr->x'; int y; // note: uninitialized field 'this->b.y'; // note: uninitialized field 'this->bptr->y'; };; int *iptr; // note: uninitialized pointer 'this->iptr'; B b;; B *bptr;; char *cptr; // note: uninitialized pointee 'this->cptr'. A (B *bptr, char *cptr) : bptr(bptr), cptr(cptr) {}; };. void f() {; A::B b;; char c;; A a(&b, &c); // warning: 6 uninitialized fields; // after the constructor call; }. // With Pedantic set to false and; // CheckPointeeInitialization set to true; // (every field is uninitialized). struct A {; struct B {; int x;; int y;; };; int *iptr;; B b;; B *bptr;; char *cptr;. A (B *bptr, char *cptr) : bptr(bptr), cptr(cptr) {}; };. void f() {; A::B b;; char c;; A a(&b, &c); // no warning; }. // With Pedantic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:14467,inherit,inherited,14467,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,2,['inherit'],['inherited']
Modifiability,"tProp``. The ``info`` field is only used if the kind; is ``UniformRetVal`` (indicates the uniform return value), or; ``UniqueRetVal`` (holds the return value associated with the unique vtable; (0 or 1)). The ``byte`` and ``bit`` fields are only used if the target does; not support the use of absolute symbols to store constants. .. _intrinsicglobalvariables:. Intrinsic Global Variables; ==========================. LLVM has a number of ""magic"" global variables that contain data that; affect code generation or other IR semantics. These are documented here.; All globals of this sort should have a section specified as; ""``llvm.metadata``"". This section and all globals that start with; ""``llvm.``"" are reserved for use by LLVM. .. _gv_llvmused:. The '``llvm.used``' Global Variable; -----------------------------------. The ``@llvm.used`` global is an array which has; :ref:`appending linkage <linkage_appending>`. This array contains a list of; pointers to named global variables, functions and aliases which may optionally; have a pointer cast formed of bitcast or getelementptr. For example, a legal; use of it is:. .. code-block:: llvm. @X = global i8 4; @Y = global i32 123. @llvm.used = appending global [2 x ptr] [; ptr @X,; ptr @Y; ], section ""llvm.metadata"". If a symbol appears in the ``@llvm.used`` list, then the compiler, assembler,; and linker are required to treat the symbol as if there is a reference to the; symbol that it cannot see (which is why they have to be named). For example, if; a variable has internal linkage and no references other than that from the; ``@llvm.used`` list, it cannot be deleted. This is commonly used to represent; references from inline asms and other things the compiler cannot ""see"", and; corresponds to ""``attribute((used))``"" in GNU C. On some targets, the code generator must emit a directive to the; assembler or object file to prevent the assembler and linker from; removing the symbol. .. _gv_llvmcompilerused:. The '``llvm.compiler.used``' G",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:351013,variab,variables,351013,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variables']
Modifiability,"tStyle``) :versionbadge:`clang-format 14` :ref:`¶ <QualifierAlignment>`; Different ways to arrange specifiers and qualifiers (e.g. const/volatile). .. warning::. Setting ``QualifierAlignment`` to something other than ``Leave``, COULD; lead to incorrect code formatting due to incorrect decisions made due to; clang-formats lack of complete semantic information.; As such extra care should be taken to review code changes made by the use; of this option. Possible values:. * ``QAS_Leave`` (in configuration: ``Leave``); Don't change specifiers/qualifiers to either Left or Right alignment; (default). .. code-block:: c++. int const a;; const int *a;. * ``QAS_Left`` (in configuration: ``Left``); Change specifiers/qualifiers to be left-aligned. .. code-block:: c++. const int a;; const int *a;. * ``QAS_Right`` (in configuration: ``Right``); Change specifiers/qualifiers to be right-aligned. .. code-block:: c++. int const a;; int const *a;. * ``QAS_Custom`` (in configuration: ``Custom``); Change specifiers/qualifiers to be aligned based on ``QualifierOrder``.; With:. .. code-block:: yaml. QualifierOrder: ['inline', 'static', 'type', 'const']. .. code-block:: c++. int const a;; int const *a;. .. _QualifierOrder:. **QualifierOrder** (``List of Strings``) :versionbadge:`clang-format 14` :ref:`¶ <QualifierOrder>`; The order in which the qualifiers appear.; Order is an array that can contain any of the following:. * const; * inline; * static; * friend; * constexpr; * volatile; * restrict; * type. .. note::. it MUST contain 'type'. Items to the left of 'type' will be placed to the left of the type and; aligned in the order supplied. Items to the right of 'type' will be; placed to the right of the type and aligned in the order supplied. .. code-block:: yaml. QualifierOrder: ['inline', 'static', 'type', 'const', 'volatile' ]. .. _RawStringFormats:. **RawStringFormats** (``List of RawStringFormats``) :versionbadge:`clang-format 6` :ref:`¶ <RawStringFormats>`; Defines hints for detecting su",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:97469,config,configuration,97469,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['config'],['configuration']
Modifiability,"tValue(; @""LocalizedString"", nil, [[NSBundle alloc] init], nil,@""""); // warn; }. .. _optin-osx-cocoa-localizability-NonLocalizedStringChecker:. optin.osx.cocoa.localizability.NonLocalizedStringChecker (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Warns about uses of non-localized NSStrings passed to UI methods expecting localized NSStrings. .. code-block:: objc. NSString *alarmText =; NSLocalizedString(@""Enabled"", @""Indicates alarm is turned on"");; if (!isEnabled) {; alarmText = @""Disabled"";; }; UILabel *alarmStateLabel = [[UILabel alloc] init];. // Warning: User-facing text should use localized string macro; [alarmStateLabel setText:alarmText];. .. _optin-performance-GCDAntipattern:. optin.performance.GCDAntipattern; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for performance anti-patterns when using Grand Central Dispatch. .. _optin-performance-Padding:. optin.performance.Padding; """"""""""""""""""""""""""""""""""""""""""""""""""; Check for excessively padded structs. .. _optin-portability-UnixAPI:. optin.portability.UnixAPI; """"""""""""""""""""""""""""""""""""""""""""""""""; Finds implementation-defined behavior in UNIX/Posix functions. .. _security-checkers:. security; ^^^^^^^^. Security related checkers. .. _security-cert-env-InvalidPtr:. security.cert.env.InvalidPtr; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". Corresponds to SEI CERT Rules `ENV31-C <https://wiki.sei.cmu.edu/confluence/display/c/ENV31-C.+Do+not+rely+on+an+environment+pointer+following+an+operation+that+may+invalidate+it>`_ and `ENV34-C <https://wiki.sei.cmu.edu/confluence/display/c/ENV34-C.+Do+not+store+pointers+returned+by+certain+functions>`_. * **ENV31-C**:; Rule is about the possible problem with ``main`` function's third argument, environment pointer,; ""envp"". When environment array is modified using some modification function; such as ``putenv``, ``setenv`` or others, It may happen that memory is reallocated,; however ""envp"" is not updated to reflect the changes and points to old memory; region. * **ENV34-C**:; Some funct",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:19608,portab,portability-UnixAPI,19608,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['portab'],['portability-UnixAPI']
Modifiability,"t_block_inside_block_async_leak() {; int x = 123;; void (^inner)(void) = ^void(void) {; int y = x;; ++y;; };; void (^outer)(void) = ^void(void) {; int z = x;; ++z;; inner();; };; return outer; // warn: address of stack-allocated block is captured by a; // returned block; }. alpha.core.TestAfterDivZero; (C, C++, ObjC); Check for division by variable that is later compared against 0.; Either the comparison is useless or there is division by zero. void test(int x) {; var = 77 / x;; if (x == 0) { } // warn; }. C++ Alpha Checkers. Name, DescriptionExample. alpha.cplusplus.ArrayDelete; (C++); Reports destructions of arrays of polymorphic objects that are destructed as; their base class. Base *create() {; Base *x = new Derived[10]; // note: Casting from 'Derived' to 'Base' here; return x;; }. void sink(Base *x) {; delete[] x; // warn: Deleting an array of 'Derived' objects as their base class 'Base' undefined; }. alpha.cplusplus.DeleteWithNonVirtualDtor; (C++); Reports destructions of polymorphic objects with a non-virtual destructor in; their base class. NonVirtual *create() {; NonVirtual *x = new NVDerived(); // note: Casting from 'NVDerived' to; // 'NonVirtual' here; return x;; }. void sink(NonVirtual *x) {; delete x; // warn: destruction of a polymorphic object with no virtual; // destructor; }. alpha.cplusplus.InvalidatedIterator; (C++); Check for use of invalidated iterators. void bad_copy_assign_operator_list1(std::list &L1,; const std::list &L2) {; auto i0 = L1.cbegin();; L1 = L2;; *i0; // warn: invalidated iterator accessed; }. alpha.cplusplus.IteratorRange; (C++); Check for iterators used outside their valid ranges. void simple_bad_end(const std::vector &v) {; auto i = v.end();; *i; // warn: iterator accessed outside of its range; }. alpha.cplusplus.MismatchedIterator; (C++); Check for use of iterators of different containers where iterators of the same; container are expected. void bad_insert3(std::vector &v1, std::vector &v2) {; v2.insert(v1.cbegin(), v2.cbegin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/alpha_checks.html:4764,polymorphi,polymorphic,4764,interpreter/llvm-project/clang/www/analyzer/alpha_checks.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/alpha_checks.html,1,['polymorphi'],['polymorphic']
Modifiability,"t_t field = 20; // field in kilogauss; enum Evect {kX,kY,kZ,kPX,kPY,kPZ,kPP};; vout[kPP] = vect[kPP];. Float_t h4 = field*2.99792e-4;; Float_t rho = -h4/vect[kPP];; Float_t tet = rho*step;; Float_t tsint = tet*tet/6;; Float_t sintt = 1 - tsint;; Float_t sint = tet*sintt;; Float_t cos1t = tet/2;; Float_t f1 = step*sintt;; Float_t f2 = step*cos1t;; Float_t f3 = step*tsint*vect[kPZ];; Float_t f4 = -tet*cos1t;; Float_t f5 = sint;; Float_t f6 = tet*cos1t*vect[kPZ];. vout[kX] = vect[kX] + (f1*vect[kPX] - f2*vect[kPY]);; vout[kY] = vect[kY] + (f1*vect[kPY] + f2*vect[kPX]);; vout[kZ] = vect[kZ] + (f1*vect[kPZ] + f3);; vout[kPX] = vect[kPX] + (f4*vect[kPX] - f5*vect[kPY]);; vout[kPY] = vect[kPY] + (f4*vect[kPY] + f5*vect[kPX]);; vout[kPZ] = vect[kPZ] + (f4*vect[kPZ] + f6);; }; ```. ### Writing the Tree. ``` {.cpp}; void tree2w() {; // write tree2 example; //create a Tree file tree2.root; TFile f(""tree2.root"",""recreate"");. //create the file, the Tree; TTree t2(""t2"",""a Tree with data from a fake Geant3"");; // declare a variable of the C structure type; Gctrak_t gstep;. // add the branches for a subset of gstep; t2.Branch(""vect"",gstep.vect,""vect[7]/F"");; t2.Branch(""getot"",&gstep.getot,""getot/F"");; t2.Branch(""gekin"",&gstep.gekin,""gekin/F"");; t2.Branch(""nmec"",&gstep.nmec,""nmec/I"");; t2.Branch(""lmec"",gstep.lmec,""lmec[nmec]/I"");; t2.Branch(""destep"",&gstep.destep,""destep/F"");; t2.Branch(""pid"",&gstep.pid,""pid/I"");. //Initialize particle parameters at first point; Float_t px,py,pz,p,charge=0;; Float_t vout[7];; Float_t mass = 0.137;; Bool_t newParticle = kTRUE;; gstep.step = 0.1;; gstep.destep = 0;; gstep.nmec = 0;; gstep.pid = 0;. //transport particles; for (Int_t i=0; i<10000; i++) {; //generate a new particle if necessary (Geant3 emulation); if (newParticle) {; px = gRandom->Gaus(0,.02);; py = gRandom->Gaus(0,.02);; pz = gRandom->Gaus(0,.02);; p = TMath::Sqrt(px*px+py*py+pz*pz);; charge = 1;; if (gRandom->Rndm() < 0.5) charge = -1;; gstep.pid += 1;; gstep.vect[0] = 0;; gstep.vect[1",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:45673,variab,variable,45673,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['variab'],['variable']
Modifiability,"ta file will be; generated for each object file. These ``.gcno`` files contain half of the; coverage data. The other half of the data comes from ``.gcda`` files that are; generated when you run the instrumented program, with a separate ``.gcda``; file for each object file. Each time you run the program, the execution counts; are summed into any existing ``.gcda`` files, so be sure to remove any old; files if you do not want their contents to be included. By default, the ``.gcda`` files are written into the same directory as the; object files, but you can override that by setting the ``GCOV_PREFIX`` and; ``GCOV_PREFIX_STRIP`` environment variables. The ``GCOV_PREFIX_STRIP``; variable specifies a number of directory components to be removed from the; start of the absolute path to the object file directory. After stripping those; directories, the prefix from the ``GCOV_PREFIX`` variable is added. These; environment variables allow you to run the instrumented program on a machine; where the original object file directories are not accessible, but you will; then need to copy the ``.gcda`` files back to the object file directories; where :program:`llvm-cov gcov` expects to find them. Once you have generated the coverage data files, run :program:`llvm-cov gcov`; for each main source file where you want to examine the coverage results. This; should be run from the same directory where you previously ran the; compiler. The results for the specified source file are written to a file named; by appending a ``.gcov`` suffix. A separate output file is also created for; each file included by the main source file, also with a ``.gcov`` suffix added. The basic content of an ``.gcov`` output file is a copy of the source file with; an execution count and line number prepended to every line. The execution; count is shown as ``-`` if a line does not contain any executable code. If; a line contains code but that code was never executed, the count is displayed; as ``#####``. OPTIONS; ^^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-cov.rst:2505,variab,variables,2505,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-cov.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-cov.rst,1,['variab'],['variables']
Modifiability,"ta; resides. *Target architecture specific DWARF address spaces may correspond to hardware; supported facilities such as memory utilizing base address registers, scratchpad; memory, and memory with special interleaving. The size of addresses in these; address spaces may vary. Their access and allocation may be hardware managed; with each thread or group of threads having access to independent storage. For; these reasons they may have properties that do not allow them to be viewed as; part of the unified global virtual address space accessible by all threads.*. *It is target architecture specific whether multiple DWARF address spaces are; supported and how source language memory spaces map to target architecture; specific DWARF address spaces. A target architecture may map multiple source; language memory spaces to the same target architecture specific DWARF address; class. Optimization may determine that variable lifetime and access pattern; allows them to be allocated in faster scratchpad memory represented by a; different DWARF address space than the default for the source language memory; space.*. Although DWARF address space identifiers are target architecture specific,; ``DW_ASPACE_LLVM_none`` is a common address space supported by all target; architectures, and defined as the target architecture default address space. DWARF address space identifiers are used by:. * The ``DW_AT_LLVM_address_space`` attribute. * The DWARF expression operations: ``DW_OP_aspace_bregx``,; ``DW_OP_form_aspace_address``, ``DW_OP_aspace_implicit_pointer``, and; ``DW_OP_xderef*``. * The CFI instructions: ``DW_CFA_def_aspace_cfa`` and; ``DW_CFA_def_aspace_cfa_sf``. .. note::. Currently, DWARF defines address class values as being target architecture; specific, and defines a DW_AT_address_class attribute. With the removal of; DW_AT_segment in DWARF 6, it is unclear how the address class is intended to; be used as the term is not used elsewhere. Should these be replaced by this; proposal'",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:149012,variab,variable,149012,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['variab'],['variable']
Modifiability,"tack. But this is not attractive as if the attribute is for a variable that; happens to end with a non-singleton stack, it will not simply put a; location description on the stack. Presumably the intent of using; ``DW_OP_call*`` on a variable or formal parameter debugger information; entry is to push just one location description on the stack. That; location description may have more than one single location description. The previous rule for ``exprloc`` also has the same problem, as normally; a variable or formal parameter location expression may leave multiple; entries on the stack and only return the top entry. GDB implements ``DW_OP_call*`` by always executing E on the same stack.; If the location list has multiple matching entries, it simply picks the; first one and ignores the rest. This seems fundamentally at odds with; the desire to support multiple places for variables. So, it feels like ``DW_OP_call*`` should both support pushing a location; description on the stack for a variable or formal parameter, and also; support being able to execute an operation expression on the same stack.; Being able to specify a different operation expression for different; program locations seems a desirable feature to retain. A solution to that is to have a distinct ``DW_AT_LLVM_proc`` attribute; for the ``DW_TAG_dwarf_procedure`` debugging information entry. Then the; ``DW_AT_location`` attribute expression is always executed separately; and pushes a location description (that may have multiple single; location descriptions), and the ``DW_AT_LLVM_proc`` attribute expression; is always executed on the same stack and can leave anything on the; stack. The ``DW_AT_LLVM_proc`` attribute could have the new classes; ``exprproc``, ``loclistproc``, and ``loclistsptrproc`` to indicate that; the expression is executed on the same stack. ``exprproc`` is the same; encoding as ``exprloc``. ``loclistproc`` and ``loclistsptrproc`` are the; same encoding as their non-\ ``proc`` counterparts,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:77776,variab,variable,77776,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['variab'],['variable']
Modifiability,"tadata !13), !dbg !14; ; [debug line = 2:7] [debug variable = X]. The first intrinsic ``%llvm.dbg.declare`` encodes debugging information for the; variable ``X``. The metadata ``!dbg !14`` attached to the intrinsic provides; scope information for the variable ``X``. .. code-block:: text. !14 = !DILocation(line: 2, column: 9, scope: !4); !4 = distinct !DISubprogram(name: ""foo"", scope: !1, file: !1, line: 1, type: !5,; isLocal: false, isDefinition: true, scopeLine: 1,; isOptimized: false, retainedNodes: !2). Here ``!14`` is metadata providing `location information; <LangRef.html#dilocation>`_. In this example, scope is encoded by ``!4``, a; `subprogram descriptor <LangRef.html#disubprogram>`_. This way the location; information attached to the intrinsics indicates that the variable ``X`` is; declared at line number 2 at a function level scope in function ``foo``. Now lets take another example. .. code-block:: llvm. call void @llvm.dbg.declare(metadata i32* %Z, metadata !17, metadata !13), !dbg !19; ; [debug line = 5:9] [debug variable = Z]. The third intrinsic ``%llvm.dbg.declare`` encodes debugging information for; variable ``Z``. The metadata ``!dbg !19`` attached to the intrinsic provides; scope information for the variable ``Z``. .. code-block:: text. !18 = distinct !DILexicalBlock(scope: !4, file: !1, line: 4, column: 5); !19 = !DILocation(line: 5, column: 11, scope: !18). Here ``!19`` indicates that ``Z`` is declared at line number 5 and column; number 11 inside of lexical scope ``!18``. The lexical scope itself resides; inside of subprogram ``!4`` described above. The scope information attached with each instruction provides a straightforward; way to find instructions covered by a scope. Object lifetime in optimized code; =================================. In the example above, every variable assignment uniquely corresponds to a; memory store to the variable's position on the stack. However in heavily; optimized code LLVM promotes most variables into SSA values,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:17111,variab,variable,17111,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['variab'],['variable']
Modifiability,"tag is deprecated and it; will be ignored. Instead, add `<ParamSetting Const=""True""> myparam </ParamSetting>` to your top-level XML's `<Measurement>` entry. This deprecation implied that the constant parameter flag in the; `RooStats:HistFactory::NormFactor` class had no effect as well. To avoid; ambiguity in the future, the possibility to set and retrieve this flag with; `NormFactor::SetConst()` and `NormFactor::GetConst()` was removed, as well as the; `Sample::AddNormFactor(std::string Name, double Val, double Low, double High, bool Const)`; overload. Also, the aforementioned deprecation warning is not printed anymore. ### Removal of `RooAbsMinimizerFcn` and `RooMinimizerFcn` from the public interface. The `RooAbsMinimizerFcn` class and its implementation `RooMinimizerFcn` were removed from the public interface.; These classes are implementation details of the RooMinimizer and should not be used in your code.; In the unlikely case that this causes any problem for you, please open a GitHub issue requesting to extend the RooMinimizer by the needed functionality. ### Vectorize `RooAbsBinning` interface for bin index lookups. The `RooAbsBinning` interface for bin index lookups was changed to enable vectorized implementations.; Instead of having the override `RooAbsBinning::binNumber()`, the binning implementations now have to override the `RooAbsBinning::binNumbers()` function to evaluate the bin indices of multiple values in one function call. ### Disable relative and absolute epsilon in `RooAbsRealLValue::inRange()`. So far, the `RooAbsRealLValue::inRange()` function used the following; undocumented convention to check whether a value `x` is in the range with; limits `a` and `b`: test if `[x - eps * x, x + eps * x]` overlaps with `[a, b]`, where the; parameter `eps` is defined as `max(epsRel * x, epsAbs)`. The values of the relative and absolute epsilons were inconsistent among the overloads:. * [RooAbsRealLValue::inRange(const char* rangeName)](https://root.cern.ch/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md:24526,extend,extend,24526,README/ReleaseNotes/v628/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md,1,['extend'],['extend']
Modifiability,"tains the type and function data for an individual translation unit; (read: one file of source code). So the first thing we need to do is; construct one for our fib.ks file. DWARF Emission Setup; ====================. Similar to the ``IRBuilder`` class we have a; `DIBuilder <https://llvm.org/doxygen/classllvm_1_1DIBuilder.html>`_ class; that helps in constructing debug metadata for an LLVM IR file. It; corresponds 1:1 similarly to ``IRBuilder`` and LLVM IR, but with nicer names.; Using it does require that you be more familiar with DWARF terminology than; you needed to be with ``IRBuilder`` and ``Instruction`` names, but if you; read through the general documentation on the; `Metadata Format <https://llvm.org/docs/SourceLevelDebugging.html>`_ it; should be a little more clear. We'll be using this class to construct all; of our IR level descriptions. Construction for it takes a module so we; need to construct it shortly after we construct our module. We've left it; as a global static variable to make it a bit easier to use. Next we're going to create a small container to cache some of our frequent; data. The first will be our compile unit, but we'll also write a bit of; code for our one type since we won't have to worry about multiple typed; expressions:. .. code-block:: c++. static std::unique_ptr<DIBuilder> DBuilder;. struct DebugInfo {; DICompileUnit *TheCU;; DIType *DblTy;. DIType *getDoubleTy();; } KSDbgInfo;. DIType *DebugInfo::getDoubleTy() {; if (DblTy); return DblTy;. DblTy = DBuilder->createBasicType(""double"", 64, dwarf::DW_ATE_float);; return DblTy;; }. And then later on in ``main`` when we're constructing our module:. .. code-block:: c++. DBuilder = std::make_unique<DIBuilder>(*TheModule);. KSDbgInfo.TheCU = DBuilder->createCompileUnit(; dwarf::DW_LANG_C, DBuilder->createFile(""fib.ks"", "".""),; ""Kaleidoscope Compiler"", false, """", 0);. There are a couple of things to note here. First, while we're producing a; compile unit for a language called Kaleidoscope we",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst:6651,variab,variable,6651,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst,1,['variab'],['variable']
Modifiability,"takes a non-l-value (const-ref, move, or by-value) vector as; a parameter, another sequence can be used and cppyy will automatically; generate a temporary.; Typically, this will be faster than coding up such a temporary on the Python; side, but if the same sequence is used multiple times, creating a temporary; once and re-using it will be the most efficient approach.o. .. code-block:: python. >>> cppyy.cppdef(""""""; ... int sumit1(const std::vector<int>& data) {; ... return std::accumulate(data.begin(), data.end(), 0);; ... }; ... int sumit2(std::vector<int> data) {; ... return std::accumulate(data.begin(), data.end(), 0);; ... }; ... int sumit3(const std::vector<int>&& data) {; ... return std::accumulate(data.begin(), data.end(), 0);; ... }""""""); ...; True; >>> cppyy.gbl.sumit1(range(5)); 10; >>> cppyy.gbl.sumit2(range(6)); 16; >>> cppyy.gbl.sumit3(range(7)); 21; >>>. The temporary vector is created using the vector constructor taking an; ``std::initializer_list``, which is more flexible than constructing a; temporary vector and filling it: it allows the data in the container to be; implicitly converted (e.g. from ``int`` to ``double`` type, or from; pointer to derived to pointer to base class).; As a consequence, however, with STL containers being allowed where Python; containers are, this in turn means that you can pass e.g. an; ``std::vector<int>`` (or ``std::list<int>``) where a ``std::vector<double>``; is expected and a temporary is allowed:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... double sumit4(const std::vector<double>& data) {; ... return std::accumulate(data.begin(), data.end(), 0);; ... }""""""); ...; True; >>> cppyy.gbl.sumit4(vector[int](range(7))); 21.0; >>>. Normal overload resolution rules continue to apply, however, thus if an; overload were available that takes an ``const std::vector<int>&``, it would; be preferred. When templates are involved, overload resolution is stricter, to ensure that; a better matching instantiation is preferred over an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:5126,flexible,flexible,5126,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,1,['flexible'],['flexible']
Modifiability,"takes a value to trunc, and a type to trunc; it to. Both types must be of :ref:`integer <t_integer>` types, or vectors; of the same number of integers. The bit size of the ``value`` must be; larger than the bit size of the destination type, ``ty2``. Equal sized; types are not allowed. Semantics:; """""""""""""""""""". The '``trunc``' instruction truncates the high order bits in ``value``; and converts the remaining bits to ``ty2``. Since the source size must; be larger than the destination size, ``trunc`` cannot be a *no-op cast*.; It will always truncate bits. Example:; """""""""""""""". .. code-block:: llvm. %X = trunc i32 257 to i8 ; yields i8:1; %Y = trunc i32 123 to i1 ; yields i1:true; %Z = trunc i32 122 to i1 ; yields i1:false; %W = trunc <2 x i16> <i16 8, i16 7> to <2 x i8> ; yields <i8 8, i8 7>. .. _i_zext:. '``zext .. to``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = zext <ty> <value> to <ty2> ; yields ty2. Overview:; """""""""""""""""". The '``zext``' instruction zero extends its operand to type ``ty2``. The ``nneg`` (non-negative) flag, if present, specifies that the operand is; non-negative. This property may be used by optimization passes to later; convert the ``zext`` into a ``sext``. Arguments:; """""""""""""""""""". The '``zext``' instruction takes a value to cast, and a type to cast it; to. Both types must be of :ref:`integer <t_integer>` types, or vectors of; the same number of integers. The bit size of the ``value`` must be; smaller than the bit size of the destination type, ``ty2``. Semantics:; """""""""""""""""""". The ``zext`` fills the high order bits of the ``value`` with zero bits; until it reaches the size of the destination type, ``ty2``. When zero extending from i1, the result will always be either 0 or 1. If the ``nneg`` flag is set, and the ``zext`` argument is negative, the result; is a poison value. Example:; """""""""""""""". .. code-block:: llvm. %X = zext i32 257 to i64 ; yields i64:257; %Y = zext i1 true to i32 ; yields i32:1; %Z = zext <2 x i16> <i16 8",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:443343,extend,extends,443343,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['extend'],['extends']
Modifiability,"tance and; class methods, respectively). As with identifiers, selectors are represented by numeric values within the AST; file. A separate index maps these numeric selector values to the offset of the; selector within the on-disk hash table, and will be used when de-serializing an; Objective-C method declaration (or other Objective-C construct) that refers to; the selector. AST Reader Integration Points; -----------------------------. The ""lazy"" deserialization behavior of AST files requires their integration; into several completely different submodules of Clang. For example, lazily; deserializing the declarations during name lookup requires that the name-lookup; routines be able to query the AST file to find entities stored there. For each Clang data structure that requires direct interaction with the AST; reader logic, there is an abstract class that provides the interface between; the two modules. The ``ASTReader`` class, which handles the loading of an AST; file, inherits from all of these abstract classes to provide lazy; deserialization of Clang's data structures. ``ASTReader`` implements the; following abstract classes:. ``ExternalSLocEntrySource``; This abstract interface is associated with the ``SourceManager`` class, and; is used whenever the :ref:`source manager <pchinternals-sourcemgr>` needs to; load the details of a file, buffer, or macro instantiation. ``IdentifierInfoLookup``; This abstract interface is associated with the ``IdentifierTable`` class, and; is used whenever the program source refers to an identifier that has not yet; been seen. In this case, the AST reader searches for this identifier within; its :ref:`identifier table <pchinternals-ident-table>` to load any top-level; declarations or macros associated with that identifier. ``ExternalASTSource``; This abstract interface is associated with the ``ASTContext`` class, and is; used whenever the abstract syntax tree nodes need to loaded from the AST; file. It provides the ability to de-serial",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst:22046,inherit,inherits,22046,interpreter/llvm-project/clang/docs/PCHInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst,1,['inherit'],['inherits']
Modifiability,target.h; openmp/libomptarget/include/omptargetplugin.h; openmp/libomptarget/include/rtl.h; openmp/libomptarget/include/SourceInfo.h; openmp/libomptarget/plugins/amdgpu/dynamic_hsa/hsa.cpp; openmp/libomptarget/plugins/amdgpu/dynamic_hsa/hsa.h; openmp/libomptarget/plugins/amdgpu/impl/get_elf_mach_gfx_name.cpp; openmp/libomptarget/plugins/amdgpu/impl/get_elf_mach_gfx_name.h; openmp/libomptarget/plugins/amdgpu/impl/hsa_api.h; openmp/libomptarget/plugins/amdgpu/impl/impl.cpp; openmp/libomptarget/plugins/amdgpu/impl/impl_runtime.h; openmp/libomptarget/plugins/amdgpu/impl/internal.h; openmp/libomptarget/plugins/amdgpu/impl/interop_hsa.cpp; openmp/libomptarget/plugins/amdgpu/impl/msgpack.cpp; openmp/libomptarget/plugins/amdgpu/impl/msgpack.h; openmp/libomptarget/plugins/amdgpu/impl/rt.h; openmp/libomptarget/plugins/amdgpu/src/print_tracing.h; openmp/libomptarget/plugins/common/elf_common/elf_common.cpp; openmp/libomptarget/plugins/common/elf_common/elf_common.h; openmp/libomptarget/plugins/common/MemoryManager/MemoryManager.h; openmp/libomptarget/plugins/cuda/dynamic_cuda/cuda.cpp; openmp/libomptarget/plugins/cuda/dynamic_cuda/cuda.h; openmp/libomptarget/plugins/generic-elf-64bit/src/rtl.cpp; openmp/libomptarget/plugins/remote/include/Utils.h; openmp/libomptarget/plugins/remote/server/OffloadingServer.cpp; openmp/libomptarget/plugins/remote/server/Server.cpp; openmp/libomptarget/plugins/remote/server/Server.h; openmp/libomptarget/plugins/remote/src/Client.cpp; openmp/libomptarget/plugins/remote/src/Client.h; openmp/libomptarget/plugins/ve/src/rtl.cpp; openmp/libomptarget/src/api.cpp; openmp/libomptarget/src/interface.cpp; openmp/libomptarget/src/interop.cpp; openmp/libomptarget/src/omptarget.cpp; openmp/libomptarget/src/private.h; openmp/libomptarget/src/rtl.cpp; openmp/libomptarget/tools/deviceinfo/llvm-omp-device-info.cpp; openmp/runtime/doc/doxygen/libomp_interface.h; openmp/runtime/src/extractExternal.cpp; openmp/runtime/src/kmp.h; openmp/runtime/src/kmp_affinity.h; op,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:407682,plugin,plugins,407682,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['plugin'],['plugins']
Modifiability,"targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target will install the LLVM testing; tools as the public tools. This can be changed well by setting; *LLVM_INSTALL_TOOLCHAIN_ONLY* to ``On``. The LLVM tools are intended for; development and testing of LLVM, and should only be included in distributions; that support LLVM development. When building with *LLVM_DISTRIBUTION_COMPONENTS* the build system also; generates a ``distribution`` target which builds all the components specified in; the list. This is a convenience build target to allow building just the; distributed pieces without needing to build all configured targets. .. _Multi-distribution configurations:. Multi-distribution configurations; ---------------------------------. The ``install-distribution`` target described above is for building a single; distribution. LLVM's build system also supports building multiple distributions,; which can be used to e.g. have one distribution containing just tools and; another for libraries (to enable development). These are configured by setting; the *LLVM_DISTRIBUTIONS* variable to hold a list of all distribution names; (which conventionally start with an uppercase letter, e.g. ""Development""), and; then setting the *LLVM_<distribution>_DISTRIBUTION_COMPONENTS* variable to the; list of targets for that distribution. For each distribution, the build system; generates an ``install-${distribution}-distribution`` target, where; ``${distribution}`` is the name of the distribution in lowercase, to install; that distribution. Each distribution creates its own set of CMake exports, and the target to; install the CMake exports for a particu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:4179,config,configurations,4179,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,1,['config'],['configurations']
Modifiability,"tart of the global initializer. This is; true even for variables potentially accessible from outside the; module, including those with external linkage or appearing in; ``@llvm.used`` or dllexported variables. This assumption may be suppressed; by marking the variable with ``externally_initialized``. An explicit alignment may be specified for a global, which must be a; power of 2. If not present, or if the alignment is set to zero, the; alignment of the global is set by the target to whatever it feels; convenient. If an explicit alignment is specified, the global is forced; to have exactly that alignment. Targets and optimizers are not allowed; to over-align the global if the global has an assigned section. In this; case, the extra alignment could be observable: for example, code could; assume that the globals are densely packed in their section and try to; iterate over them as an array, alignment padding would break this; iteration. For TLS variables, the module flag ``MaxTLSAlign``, if present,; limits the alignment to the given value. Optimizers are not allowed to; impose a stronger alignment on these variables. The maximum alignment; is ``1 << 32``. For global variable declarations, as well as definitions that may be; replaced at link time (``linkonce``, ``weak``, ``extern_weak`` and ``common``; linkage types), the allocation size and alignment of the definition it resolves; to must be greater than or equal to that of the declaration or replaceable; definition, otherwise the behavior is undefined. Globals can also have a :ref:`DLL storage class <dllstorageclass>`,; an optional :ref:`runtime preemption specifier <runtime_preemption_model>`,; an optional :ref:`global attributes <glattrs>` and; an optional list of attached :ref:`metadata <metadata>`. Variables and aliases can have a; :ref:`Thread Local Storage Model <tls_model>`. Globals cannot be or contain :ref:`Scalable vectors <t_vector>` because their; size is unknown at compile time. They are allowed in struc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:35038,variab,variables,35038,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variables']
Modifiability,"task. ## TTree Libraries. ## RNTuple; ROOT's experimental successor of TTree has seen a large number of updates during the last few months. Specifically, v6.30 includes the following changes:. - Support for custom ROOT I/O rules that target transient members of a user-defined class (see PR [#11944](https://github.com/root-project/root/pull/11944)). If a rule only targets transient members and it was working in TTree, it should work unmodified in RNTuple. - Improved support for user-defined classes that behave as a collection. Specifically, RNTuple now relies on the iterator interface defined in `TVirtualCollectionProxy` (see PR [#12380](https://github.com/root-project/root/pull/12380) for details).; Note that associative collections are not yet supported. - Support for new field types: `std::bitset<N>`, `std::unique_ptr<T>`, `std::set<T>`, `Double32_t`, scoped and unscoped enums with dictionary. - Full support for late model extension, which allows the RNTuple model to be extended after a `RNTupleWriter` has been created from the initial model (see PR [#12376](https://github.com/root-project/root/pull/12376)).; New top-level fields can be created at any time during the writing process.; On read-back, zero-initialized values are read for entries before the field was first seen.; The example below illustrates the use of this feature.; ```; auto model = RNTupleModel::Create();; auto fieldPt = model->MakeField<float>(""pt"", 42.0);; auto ntuple = RNTupleWriter::Recreate(std::move(model), ""myNTuple"", ""out.ntuple"");; ntuple->Fill();. auto modelUpdater = ntuple->CreateModelUpdater();; modelUpdater->BeginUpdate();; std::array<double, 2> fieldArray;; modelUpdater->AddField<std::array<double, 2>>(""array"", &fieldArray);; modelUpdater->CommitUpdate();. // After this point, entries will have a new field of type `std::array<double, 2>`; ntuple->Fill();; ```. - Support for alternative column representations (Split / Zigzag encoding). These encodings allow for better compression and ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md:6991,extend,extended,6991,README/ReleaseNotes/v630/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md,1,['extend'],['extended']
Modifiability,"tated precondition), or by inlining some but not all; of a deep implementation of a function. c++-stdlib-inlining; ^^^^^^^^^^^^^^^^^^^. This option controls whether functions from the C++ standard library, including; methods of the container classes in the Standard Template Library, should be; considered for inlining. ``-analyzer-config c++-stdlib-inlining=[true | false]``. Currently, C++ standard library functions are considered for inlining by; default. The standard library functions and the STL in particular are used ubiquitously; enough that our tolerance for false positives is even lower here. A false; positive due to poor modeling of the STL leads to a poor user experience, since; most users would not be comfortable adding assertions to system headers in order; to silence analyzer warnings. c++-container-inlining; ^^^^^^^^^^^^^^^^^^^^^^. This option controls whether constructors and destructors of ""container"" types; should be considered for inlining. ``-analyzer-config c++-container-inlining=[true | false]``. Currently, these constructors and destructors are NOT considered for inlining; by default. The current implementation of this setting checks whether a type has a member; named 'iterator' or a member named 'begin'; these names are idiomatic in C++,; with the latter specified in the C++11 standard. The analyzer currently does a; fairly poor job of modeling certain data structure invariants of container-like; objects. For example, these three expressions should be equivalent:. .. code-block:: cpp. std::distance(c.begin(), c.end()) == 0; c.begin() == c.end(); c.empty(). Many of these issues are avoided if containers always have unknown, symbolic; state, which is what happens when their constructors are treated as opaque.; In the future, we may decide specific containers are ""safe"" to model through; inlining, or choose to model them directly using checkers instead. Basics of Implementation; ------------------------. The low-level mechanism of inlining a functi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst:4071,config,config,4071,interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst,1,['config'],['config']
Modifiability,"tatement (excluding comments).; The pragma is active within the scope of the compound statement. When ``pragma clang fp eval_method(source)`` is enabled, the section of code; governed by the pragma behaves as though the command-line option; ``-ffp-eval-method=source`` is enabled. Rounds intermediate results to; source-defined precision. When ``pragma clang fp eval_method(double)`` is enabled, the section of code; governed by the pragma behaves as though the command-line option; ``-ffp-eval-method=double`` is enabled. Rounds intermediate results to; ``double`` precision. When ``pragma clang fp eval_method(extended)`` is enabled, the section of code; governed by the pragma behaves as though the command-line option; ``-ffp-eval-method=extended`` is enabled. Rounds intermediate results to; target-dependent ``long double`` precision. In Win32 programming, for instance,; the long double data type maps to the double, 64-bit precision data type. The full syntax this pragma supports is; ``#pragma clang fp eval_method(source|double|extended)``. .. code-block:: c++. for(...) {; // The compiler will use long double as the floating-point evaluation; // method.; #pragma clang fp eval_method(extended); a = b[i] * c[i] + e;; }. Note: ``math.h`` defines the typedefs ``float_t`` and ``double_t`` based on the active; evaluation method at the point where the header is included, not where the; typedefs are used. Because of this, it is unwise to combine these typedefs with; ``#pragma clang fp eval_method``. To catch obvious bugs, Clang will emit an; error for any references to these typedefs within the scope of this pragma;; however, this is not a fool-proof protection, and programmers must take care. The ``#pragma float_control`` pragma allows precise floating-point; semantics and floating-point exception behavior to be specified; for a section of the source code. This pragma can only appear at file or; namespace scope, within a language linkage specification or at the start of a; compou",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:174187,extend,extended,174187,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['extend'],['extended']
Modifiability,"tatementsOnASingleLine:. **AllowShortIfStatementsOnASingleLine** (``ShortIfStyle``) :versionbadge:`clang-format 3.3` :ref:`¶ <AllowShortIfStatementsOnASingleLine>`; Dependent on the value, ``if (a) return;`` can be put on a single line. Possible values:. * ``SIS_Never`` (in configuration: ``Never``); Never put short ifs on the same line. .. code-block:: c++. if (a); return;. if (b); return;; else; return;. if (c); return;; else {; return;; }. * ``SIS_WithoutElse`` (in configuration: ``WithoutElse``); Put short ifs on the same line only if there is no else statement. .. code-block:: c++. if (a) return;. if (b); return;; else; return;. if (c); return;; else {; return;; }. * ``SIS_OnlyFirstIf`` (in configuration: ``OnlyFirstIf``); Put short ifs, but not else ifs nor else statements, on the same line. .. code-block:: c++. if (a) return;. if (b) return;; else if (b); return;; else; return;. if (c) return;; else {; return;; }. * ``SIS_AllIfsAndElse`` (in configuration: ``AllIfsAndElse``); Always put short ifs, else ifs and else statements on the same; line. .. code-block:: c++. if (a) return;. if (b) return;; else return;. if (c) return;; else {; return;; }. .. _AllowShortLambdasOnASingleLine:. **AllowShortLambdasOnASingleLine** (``ShortLambdaStyle``) :versionbadge:`clang-format 9` :ref:`¶ <AllowShortLambdasOnASingleLine>`; Dependent on the value, ``auto lambda []() { return 0; }`` can be put on a; single line. Possible values:. * ``SLS_None`` (in configuration: ``None``); Never merge lambdas into a single line. * ``SLS_Empty`` (in configuration: ``Empty``); Only merge empty lambdas. .. code-block:: c++. auto lambda = [](int a) {};; auto lambda2 = [](int a) {; return a;; };. * ``SLS_Inline`` (in configuration: ``Inline``); Merge lambda into a single line if the lambda is argument of a function. .. code-block:: c++. auto lambda = [](int x, int y) {; return x < y;; };; sort(a.begin(), a.end(), [](int x, int y) { return x < y; });. * ``SLS_All`` (in configuration: ``All``); M",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:30769,config,configuration,30769,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['config'],['configuration']
Modifiability,"tatic storage duration.; It includes the variable declared at namespace scope and those declared; with ""static"" and ""extern"" storage class specifiers. void f() {; int x;; static int y;; thread_local int z;; }; int a;; static int b;; extern int c;; varDecl(hasStaticStorageDuration()); matches the function declaration y, a, b and c. Matcher<VarDecl>hasThreadStorageDuration; Matches a variable declaration that has thread storage duration. Example matches z, but not x, z, or a.; (matcher = varDecl(hasThreadStorageDuration()); void f() {; int x;; static int y;; thread_local int z;; }; int a;. Matcher<VarDecl>isConstexpr; Matches constexpr variable and function declarations,; and if constexpr. Given:; constexpr int foo = 42;; constexpr int bar();; void baz() { if constexpr(1 > 0) {} }; varDecl(isConstexpr()); matches the declaration of foo.; functionDecl(isConstexpr()); matches the declaration of bar.; ifStmt(isConstexpr()); matches the if statement in baz. Matcher<VarDecl>isConstinit; Matches constinit variable declarations. Given:; constinit int foo = 42;; constinit const char* bar = ""bar"";; int baz = 42;; [[clang::require_constant_initialization]] int xyz = 42;; varDecl(isConstinit()); matches the declaration of `foo` and `bar`, but not `baz` and `xyz`. Matcher<VarDecl>isDefinition; Matches if a declaration has a body attached. Example matches A, va, fa; class A {};; class B; // Doesn't match, as it has no body.; int va;; extern int vb; // Doesn't match, as it doesn't define the variable.; void fa() {}; void fb(); // Doesn't match, as it has no body.; @interface X; - (void)ma; // Doesn't match, interface is declaration.; @end; @implementation X; - (void)ma {}; @end. Usable as: Matcher<TagDecl>, Matcher<VarDecl>, Matcher<FunctionDecl>,; Matcher<ObjCMethodDecl>. Matcher<VarDecl>isExceptionVariable; Matches a variable declaration that is an exception variable from; a C++ catch block, or an Objective-C statement. Example matches x (matcher = varDecl(isExceptionVariable());",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html:125908,variab,variable,125908,interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,1,['variab'],['variable']
Modifiability,"tay alive.; ```. ### Define infinity as `std::numeric_limits<double>::infinity()`. RooFit has its internal representation of infinity in `RooNumber::infinity()`, which was `1e30` before. Now, it is defined as `std::numeric_limits<double>::infinity()`, to be consistent with the C++ standard library and other code. This change also affects the `RooNumber::isInfinite()` function. ### Remove `add(row, weight, weightError)` from RooAbsData interface. It was not good to have this signature in RooAbsData, because the; implementations in the two derived classes RooDataHist and RooDataSet were; inconsistent. The RooDataSet indeed took the weight error as the third argument, but; the RooDataHist version instead took the sum of weights squared, which; is equivalent to the squared weight error. Therefore, the virtual `RooAbsData::add(row, weight, weightError)` function was removed. ### Removal of `RooMomentMorphND` class. The `RooMomentMorphND` and `RooMomentMorphFuncND` were almost exactly the same,; only that one inherited from `RooAbsPdf` and the other from `RooAbsReal`. Thanks to the `RooWrapperPdf`, this code duplication in the RooFit implementation can now be avoided.; Instead of using the removed `RooMomentMorphND` (which is the pdf), you now need to use the `RooMomentMorphFuncND`,; change its behavior to exactly match the formter `RooMomentMorphND`, and then wrap it into a pdf object:. ```C++; RooMomentMorphFuncND func{<constructor args you previously passed to RooMomentMorphFunc>};. func.setPdfMode(); // change behavior to be exactly like the former RooMomentMorphND. // Pass the selfNormalized=true` flag to the wrapper because the; RooMomentMorphFuncND already normalizes itself in pdf mode.; RooWrapperPdf pdf{""pdf_name"", ""pdf_name"", func, /*selfNormalized=*/true};; ```. ### Removal of several internal classes from the public RooFit interface. Several RooFit classes of which the headers are publicly exposed in the interface were only meant as implementation details of ot",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md:13902,inherit,inherited,13902,README/ReleaseNotes/v630/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md,1,['inherit'],['inherited']
Modifiability,"tched as it is deduced to int& by reference collapsing rules. Matcher<Type>recordTypeMatcher<RecordType>...; Matches record types (e.g. structs, classes). Given; class C {};; struct S {};. C c;; S s;. recordType() matches the type of the variable declarations of both c; and s. Matcher<Type>referenceTypeMatcher<ReferenceType>...; Matches both lvalue and rvalue reference types. Given; int *a;; int &b = *a;; int &&c = 1;; auto &d = b;; auto &&e = c;; auto &&f = 2;; int g = 5;. referenceType() matches the types of b, c, d, e, and f. Matcher<Type>substTemplateTypeParmTypeMatcher<SubstTemplateTypeParmType>...; Matches types that represent the result of substituting a type for a; template type parameter. Given; template <typename T>; void F(T t) {; int i = 1 + t;; }. substTemplateTypeParmType() matches the type of 't' but not '1'. Matcher<Type>tagTypeMatcher<TagType>...; Matches tag types (record and enum types). Given; enum E {};; class C {};. E e;; C c;. tagType() matches the type of the variable declarations of both e; and c. Matcher<Type>templateSpecializationTypeMatcher<TemplateSpecializationType>...; Matches template specialization types. Given; template <typename T>; class C { };. template class C<int>; // A; C<char> var; // B. templateSpecializationType() matches the type of the explicit; instantiation in A and the type of the variable declaration in B. Matcher<Type>templateTypeParmTypeMatcher<TemplateTypeParmType>...; Matches template type parameter types. Example matches T, but not int.; (matcher = templateTypeParmType()); template <typename T> void f(int i);. Matcher<Type>typeMatcher<Type>...; Matches Types in the clang AST. Matcher<Type>typedefTypeMatcher<TypedefType>...; Matches typedef types. Given; typedef int X;; typedefType(); matches ""typedef int X"". Matcher<Type>unaryTransformTypeMatcher<UnaryTransformType>...; Matches types nodes representing unary type transformations. Given:; typedef __underlying_type(T) type;; unaryTransformType(); matches ""__underly",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html:51860,variab,variable,51860,interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,1,['variab'],['variable']
Modifiability,"tcher<CXXRecordDecl>. Matcher<VarDecl>isExternC; Matches extern ""C"" function or variable declarations. Given:; extern ""C"" void f() {}; extern ""C"" { void g() {} }; void h() {}; extern ""C"" int x = 1;; extern ""C"" int y = 2;; int z = 3;; functionDecl(isExternC()); matches the declaration of f and g, but not the declaration of h.; varDecl(isExternC()); matches the declaration of x and y, but not the declaration of z. Matcher<VarDecl>isInitCapture; Matches a variable serving as the implicit variable for a lambda init-; capture. Example matches x (matcher = varDecl(isInitCapture())); auto f = [x=3]() { return x; };. Matcher<VarDecl>isInline; Matches functions, variables and namespace declarations that are marked with; the inline keyword. Given; inline void f();; void g();; namespace n {; inline namespace m {}; }; inline int Foo = 5;; functionDecl(isInline()) will match ::f().; namespaceDecl(isInline()) will match n::m.; varDecl(isInline()) will match Foo;. Matcher<VarDecl>isStaticLocal; Matches a static variable with local scope. Example matches y (matcher = varDecl(isStaticLocal())); void f() {; int x;; static int y;; }; static int z;. Matcher<VarDecl>isStaticStorageClass; Matches variable/function declarations that have ""static"" storage; class specifier (""static"" keyword) written in the source. Given:; static void f() {}; static int i = 0;; extern int j;; int k;; functionDecl(isStaticStorageClass()); matches the function declaration f.; varDecl(isStaticStorageClass()); matches the variable declaration i. Matcher<VarDecl>isTemplateInstantiation; Matches template instantiations of function, class, or static; member variable template instantiations. Given; template <typename T> class X {}; class A {}; X<A> x;; or; template <typename T> class X {}; class A {}; template class X<A>;; or; template <typename T> class X {}; class A {}; extern template class X<A>;; cxxRecordDecl(hasName(""::X""), isTemplateInstantiation()); matches the template instantiation of X<A>. But given; templ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html:128337,variab,variable,128337,interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,1,['variab'],['variable']
Modifiability,"tches if the type location of a node matches the inner matcher. Examples:; int x;; declaratorDecl(hasTypeLoc(loc(asString(""int"")))); matches int x. auto x = int(3);; cxxTemporaryObjectExpr(hasTypeLoc(loc(asString(""int"")))); matches int(3). struct Foo { Foo(int, int); };; auto x = Foo(1, 2);; cxxFunctionalCastExpr(hasTypeLoc(loc(asString(""struct Foo"")))); matches Foo(1, 2). Usable as: Matcher<BlockDecl>, Matcher<CXXBaseSpecifier>,; Matcher<CXXCtorInitializer>, Matcher<CXXFunctionalCastExpr>,; Matcher<CXXNewExpr>, Matcher<CXXTemporaryObjectExpr>,; Matcher<CXXUnresolvedConstructExpr>,; Matcher<ClassTemplateSpecializationDecl>, Matcher<CompoundLiteralExpr>,; Matcher<DeclaratorDecl>, Matcher<ExplicitCastExpr>,; Matcher<ObjCPropertyDecl>, Matcher<TemplateArgumentLoc>,; Matcher<TypedefNameDecl>. Matcher<CXXBaseSpecifier>hasTypeMatcher<Decl> InnerMatcher; Overloaded to match the declaration of the expression's or value; declaration's type. In case of a value declaration (for example a variable declaration),; this resolves one layer of indirection. For example, in the value; declaration ""X x;"", cxxRecordDecl(hasName(""X"")) matches the declaration of; X, while varDecl(hasType(cxxRecordDecl(hasName(""X"")))) matches the; declaration of x. Example matches x (matcher = expr(hasType(cxxRecordDecl(hasName(""X""))))); and z (matcher = varDecl(hasType(cxxRecordDecl(hasName(""X""))))); and friend class X (matcher = friendDecl(hasType(""X"")); and public virtual X (matcher = cxxBaseSpecifier(hasType(; cxxRecordDecl(hasName(""X"")))); class X {};; void y(X &x) { x; X z; }; class Y { friend class X; };; class Z : public virtual X {};. Example matches class Derived; (matcher = cxxRecordDecl(hasAnyBase(hasType(cxxRecordDecl(hasName(""Base"")))))); class Base {};; class Derived : Base {};. Usable as: Matcher<Expr>, Matcher<FriendDecl>, Matcher<ValueDecl>,; Matcher<CXXBaseSpecifier>. Matcher<CXXBaseSpecifier>hasTypeMatcher<QualType> InnerMatcher; Matches if the expression's or declaration's type matches",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html:145654,variab,variable,145654,interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,1,['variab'],['variable']
Modifiability,"tcode format. It takes a program; in LLVM bitcode format and executes it using a just-in-time compiler or an; interpreter. :program:`lli` is *not* an emulator. It will not execute IR of different architectures; and it can only interpret (or JIT-compile) for the host architecture. The JIT compiler takes the same arguments as other tools, like :program:`llc`,; but they don't necessarily work for the interpreter. If `filename` is not specified, then :program:`lli` reads the LLVM bitcode for the; program from standard input. The optional *args* specified on the command line are passed to the program as; arguments. GENERAL OPTIONS; ---------------. .. option:: -fake-argv0=executable. Override the ``argv[0]`` value passed into the executing program. .. option:: -force-interpreter={false,true}. If set to true, use the interpreter even if a just-in-time compiler is available; for this architecture. Defaults to false. .. option:: -help. Print a summary of command line options. .. option:: -load=pluginfilename. Causes :program:`lli` to load the plugin (shared object) named *pluginfilename* and use; it for optimization. .. option:: -stats. Print statistics from the code-generation passes. This is only meaningful for; the just-in-time compiler, at present. .. option:: -time-passes. Record the amount of time needed for each code-generation pass and print it to; standard error. .. option:: -version. Print out the version of :program:`lli` and exit without doing anything else. TARGET OPTIONS; --------------. .. option:: -mtriple=target triple. Override the target triple specified in the input bitcode file with the; specified string. This may result in a crash if you pick an; architecture which is not compatible with the current system. .. option:: -march=arch. Specify the architecture for which to generate assembly, overriding the target; encoded in the bitcode file. See the output of **llc -help** for a list of; valid architectures. By default this is inferred from the target trip",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst:1277,plugin,pluginfilename,1277,interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lli.rst,1,['plugin'],['pluginfilename']
Modifiability,"te of 538. 328; CD1; Missing requirement that class member types be complete; Yes. 329; CD1; Evaluation of friends of templates; Clang 3.5. 330; CD4; Qualification conversions and pointers to arrays of pointers; Clang 7. 331; CD1; Allowed copy constructor signatures; Clang 11. 332; CD3; cv-qualified void parameter types; Duplicate of 577. 333; NAD; Ambiguous use of ""declaration"" in disambiguation section; Yes. 334; NAD; Is a comma-expression dependent if its first operand is?; Yes. 335; CD1; Allowing export on template members of nontemplate classes; No. 336; CD1; Explicit specialization examples are still incorrect; Yes. 337; CD1; Attempt to create array of abtract type should cause deduction to fail; Yes. 338; CD6; Enumerator name with linkage used as class name in other translation unit; Unknown. 339; CD1; Overload resolution in operand of sizeof in constant expression; Clang 2.8. 340; NAD; Unclear wording in disambiguation section; Yes. 341; C++11; extern ""C"" namespace member function versus global variable; Superseded by 1708. 342; CD3; Terminology: ""indirection"" versus ""dereference""; N/A. 343; C++17; Make template optional in contexts that require a type; No. 344; CD3; Naming destructors; Duplicate of 1435. 345; CD1; Misleading comment on example in templates chapter; Yes. 346; NAD; Typo in 15.4; N/A. 347; NAD; Use of derived class name in defining base class nested class; Yes. 348; CD1; delete and user-written deallocation functions; N/A. 349; CD1; Template argument deduction for conversion functions and qualification conversions; No. 350; open; signed char underlying representation for objects; Not resolved. 351; CD1; Sequence point error: unspecified or undefined?; N/A. 352; CD1; Nondeduced contexts; Clang 2.8. 353; CD1; Is deallocation routine called if destructor throws exception in delete?; Unknown. 354; CD1; Null as nontype template argument; Yes (C++11 onwards). 355; C++11; Global-scope :: in nested-name-specifier; Yes. 356; NAD; Wording of behavior of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html:22814,variab,variable,22814,interpreter/llvm-project/clang/www/cxx_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html,1,['variab'],['variable']
Modifiability,"te the address space; of the called function. If it is not specified, the program address space; from the :ref:`datalayout string<langref_datalayout>` will be used.; #. '``ty``': the type of the call instruction itself which is also the; type of the return value. Functions that return no value are marked; ``void``.; #. '``fnty``': shall be the signature of the function being invoked. The; argument types must match the types implied by this signature. This; type can be omitted if the function is not varargs.; #. '``fnptrval``': An LLVM value containing a pointer to a function to; be invoked. In most cases, this is a direct function invocation, but; indirect ``invoke``'s are just as possible, calling an arbitrary pointer; to function value.; #. '``function args``': argument list whose types match the function; signature argument types and parameter attributes. All arguments must; be of :ref:`first class <t_firstclass>` type. If the function signature; indicates the function accepts a variable number of arguments, the; extra arguments can be specified.; #. '``normal label``': the label reached when the called function; executes a '``ret``' instruction.; #. '``exception label``': the label reached when a callee returns via; the :ref:`resume <i_resume>` instruction or other exception handling; mechanism.; #. The optional :ref:`function attributes <fnattrs>` list.; #. The optional :ref:`operand bundles <opbundles>` list. Semantics:; """""""""""""""""""". This instruction is designed to operate as a standard '``call``'; instruction in most regards. The primary difference is that it; establishes an association with a label, which is used by the runtime; library to unwind the stack. This instruction is used in languages with destructors to ensure that; proper cleanup is performed in the case of either a ``longjmp`` or a; thrown exception. Additionally, this is important for implementation of; '``catch``' clauses in high-level languages that support them. For the purposes of the SSA for",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:364263,variab,variable,364263,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variable']
Modifiability,"te`` constructor takes; an integer argument, that by default is 42. `Cross-inheritance`; -------------------. Python classes that derive from C++ classes can override virtual methods as; long as those methods are declared on class instantiation (adding methods to; the Python class after the fact will not provide overrides on the C++ side,; only on the Python side).; Example:. .. code-block:: python. >>> from cppyy.gbl import Abstract, call_abstract_method; >>> class PyConcrete(Abstract):; ... def abstract_method(self):; ... return ""Hello, Python World!\n""; ... def concrete_method(self):; ... pass; ...; >>> pc = PyConcrete(); >>> call_abstract_method(pc); Hello, Python World!; >>>. Note that it is not necessary to provide a constructor (``__init__``), but; if you do, you *must* call the base class constructor through the ``super``; mechanism. `Multiple cross-inheritance`; ----------------------------. Python requires that any multiple inheritance (also in pure Python) has an; unambiguous method resolution order (mro), including for classes and thus; also for meta-classes.; In Python2, it was possible to resolve any mro conflicts automatically, but; meta-classes in Python3, although syntactically richer, have functionally; become far more limited.; In particular, the mro is checked in the builtin class builder, instead of; in the meta-class of the meta-class (which in Python3 is the builtin ``type``; rather than the meta-class itself as in Python2, another limitation, and; which actually checks the mro a second time for no reason).; The upshot is that a helper is required (``cppyy.multi``) to resolve the mro; to support Python3.; The helper is written to also work in Python2.; Example:. .. code-block:: python. >>> class PyConcrete(cppyy.multi(cppyy.gbl.Abstract1, cppyy.gbl.Abstract2)):; ... def abstract_method1(self):; ... return ""first message""; ... def abstract_method2(self):; ... return ""second message""; ...; >>> pc = PyConcrete(); >>> cppyy.gbl.call_abstract_metho",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:5424,inherit,inheritance,5424,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,1,['inherit'],['inheritance']
Modifiability,"tead of ```TObject::Hash``` during insertion operation to record in the object whether the Hash/RecursiveRemove setup is done properly (as explain above). It this is not the case ```TObject::HasInconsistentHash()``` will return true. This can then be used to select, in RecursiveRemove, whether the call to Hash can be trusted or if one needs to do a linear search (as was done in v6.10 and earlier).; - In TClass::GetMissingDictionaries activate the search through the base classes.; - Added a TStatusBitsChecker to avoid Status Bits overlap in class hierarchy deriving from TObject (and resolved a handful of conflicts).; - Introduced support for type safe range-for-loop for ROOT collection. The typical use is:. ```; for(auto bcl : TRangeDynCast<TBaseClass>( * cl->GetListOfBases() )) {; if (!bcl) continue;; ... use bcl as a TBaseClass*; }; for(auto bcl : TRangeDynCast<TBaseClass>( cl->GetListOfBases() )) {; if (!bcl) continue;; ... use bcl as a TBaseClass*; }; ```; - ClassDefInline has been enhanced even for some compiled class (without a dictionary). ClassDefInline can still not be used for class template instance using Double32_t or Float16_t as a template parameter or for class or class template that do not have a public default constructor.; - ROOT's backport of `std::string_view` has been updated to follow what's available in C++17, notably its `to_string` member function has been removed. ### Thread safety. Resolved the race conditions inherent to the use of the RecursiveRemove mechanism. - Introduced ```ROOT::TReentrantRWLock```, an implementation of a reentrant read-write lock with a configurable internal mutex/lock and a condition variable to synchronize readers and writers when necessary. The implementation allows a single reader to take the write lock without releasing the reader lock. It also allows the writer to take a read lock. In other word, the lock is re-entrant for both reading and writing. The implementation tries to make faster the scenario when reade",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md:3870,enhance,enhanced,3870,README/ReleaseNotes/v612/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v612/index.md,1,['enhance'],['enhanced']
Modifiability,"tectors; or not. The heuristic used will enable protectors for functions with:. - Character arrays larger than ``ssp-buffer-size`` (default 8).; - Aggregates containing character arrays larger than ``ssp-buffer-size``.; - Calls to alloca() with variable sizes or constant sizes greater than; ``ssp-buffer-size``. Variables that are identified as requiring a protector will be arranged; on the stack such that they are adjacent to the stack protector guard. If a function with an ``ssp`` attribute is inlined into a calling function,; the attribute is not carried over to the calling function. ``sspstrong``; This attribute indicates that the function should emit a stack smashing; protector. This attribute causes a strong heuristic to be used when; determining if a function needs stack protectors. The strong heuristic; will enable protectors for functions with:. - Arrays of any size and type; - Aggregates containing an array of any size and type.; - Calls to alloca().; - Local variables that have had their address taken. Variables that are identified as requiring a protector will be arranged; on the stack such that they are adjacent to the stack protector guard.; The specific layout rules are:. #. Large arrays and structures containing large arrays; (``>= ssp-buffer-size``) are closest to the stack protector.; #. Small arrays and structures containing small arrays; (``< ssp-buffer-size``) are 2nd closest to the protector.; #. Variables that have had their address taken are 3rd closest to the; protector. This overrides the ``ssp`` function attribute. If a function with an ``sspstrong`` attribute is inlined into a calling; function which has an ``ssp`` attribute, the calling function's attribute; will be upgraded to ``sspstrong``. ``sspreq``; This attribute indicates that the function should *always* emit a stack; smashing protector. This overrides the ``ssp`` and ``sspstrong`` function; attributes. Variables that are identified as requiring a protector will be arranged; on th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:103968,variab,variables,103968,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variables']
Modifiability,"tecture specific DWARF mappings. .. _amdgpu-dwarf-register-identifier:. Register Identifier; -------------------. This section defines the AMDGPU target architecture register numbers used in; DWARF operation expressions (see DWARF Version 5 section 2.5 and; :ref:`amdgpu-dwarf-operation-expressions`) and Call Frame Information; instructions (see DWARF Version 5 section 6.4 and; :ref:`amdgpu-dwarf-call-frame-information`). A single code object can contain code for kernels that have different wavefront; sizes. The vector registers and some scalar registers are based on the wavefront; size. AMDGPU defines distinct DWARF registers for each wavefront size. This; simplifies the consumer of the DWARF so that each register has a fixed size,; rather than being dynamic according to the wavefront size mode. Similarly,; distinct DWARF registers are defined for those registers that vary in size; according to the process address size. This allows a consumer to treat a; specific AMDGPU processor as a single architecture regardless of how it is; configured at run time. The compiler explicitly specifies the DWARF registers; that match the mode in which the code it is generating will be executed. DWARF registers are encoded as numbers, which are mapped to architecture; registers. The mapping for AMDGPU is defined in; :ref:`amdgpu-dwarf-register-mapping-table`. All AMDGPU targets use the same; mapping. .. table:: AMDGPU DWARF Register Mapping; :name: amdgpu-dwarf-register-mapping-table. ============== ================= ======== ==================================; DWARF Register AMDGPU Register Bit Size Description; ============== ================= ======== ==================================; 0 PC_32 32 Program Counter (PC) when; executing in a 32-bit process; address space. Used in the CFI to; describe the PC of the calling; frame.; 1 EXEC_MASK_32 32 Execution Mask Register when; executing in wavefront 32 mode.; 2-15 *Reserved* *Reserved for highly accessed; registers using DWARF shortc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:86516,config,configured,86516,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['config'],['configured']
Modifiability,"ted algorithms allow the level to be; set to any value from 1 to 9. The higher the level, the larger the; compression factors will be (smaller compressed data size). The; tradeoff is that for higher levels more CPU time is used for; compression and possibly more memory. The ZLIB algorithm takes less; CPU time during compression than the LZMA algorithm, but the LZMA; algorithm usually delivers higher compression factors. The header file core/zip/inc/Compression.h declares the function; ""CompressionSettings"" and the enumeration for the algorithms.; Currently the following selections can be made for the algorithm:; kZLIB (1), kLZMA (2), kOldCompressionAlgo (3), and kUseGlobalSetting; (0). The last option refers to an older interface used to control the; algorithm that is maintained for backward compatibility. The following; function is defined in core/zip/inc/Bits.h and it set the global; variable. R__SetZipMode(int algorithm);. If the algorithm is set to kUseGlobalSetting (0), the global variable; controls the algorithm for compression operations. This is the; default and the default value for the global variable is kZLIB. gDirectory; gDirectory is now a thread local!. The value of gDirectory and gFile are now all accessed via a static function of their respective class. The access is made transparent via a CPP macro. Note: Whenever a thread has an associated TThread object, the value of gDirectory is now thread local, i.e. all modifications direct or indirect of gDirectory will not be seen by the other thread. In particular this means that several I/O operations (including TDirectory::Write) are thread safe (as long as all the required TClass and TStreamerInfo has been previously setup).; Note: This model does not support sharing TFile amongst threads (i.e. a TFile must be accessed from exactly one thread). This means that whenever a TFile's control is passed from a thread to another, the code must explicitly reset gDirectory to another value or there is a risk for t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v532/index.html:2774,variab,variable,2774,io/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v532/index.html,1,['variab'],['variable']
Modifiability,"ted alignment, plus 1. .. _PARAMATTR_GROUP_BLOCK:. PARAMATTR_GROUP_BLOCK Contents; ------------------------------. The ``PARAMATTR_GROUP_BLOCK`` block (id 10) contains a table of entries; describing the attribute groups present in the module. These entries can be; referenced within ``PARAMATTR_CODE_ENTRY`` entries. .. _PARAMATTR_GRP_CODE_ENTRY:. PARAMATTR_GRP_CODE_ENTRY Record; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``[ENTRY, grpid, paramidx, attr0, attr1, ...]``. The ``ENTRY`` record (code 3) contains *grpid* and *paramidx* values, followed; by a variable number of values describing a unique group of attributes. The; *grpid* value is a unique key for the attribute group, which can be referenced; within ``PARAMATTR_CODE_ENTRY`` entries. The *paramidx* value indicates which; set of attributes is represented, with 0 representing the return value; attributes, 0xFFFFFFFF representing function attributes, and other values; representing 1-based function parameters. Each *attr* is itself represented as a variable number of values:. ``kind, key [, ...], [value [, ...]]``. Each attribute is either a well-known LLVM attribute (possibly with an integer; value associated with it), or an arbitrary string (possibly with an arbitrary; string value associated with it). The *kind* value is an integer code; distinguishing between these possibilities:. * code 0: well-known attribute; * code 1: well-known attribute with an integer value; * code 3: string attribute; * code 4: string attribute with a string value. For well-known attributes (code 0 or 1), the *key* value is an integer code; identifying the attribute. For attributes with an integer argument (code 1),; the *value* value indicates the argument. For string attributes (code 3 or 4), the *key* value is actually a variable; number of values representing the bytes of a null-terminated string. For; attributes with a string argument (code 4), the *value* value is similarly a; variable number of values representing the bytes of a null-term",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:36803,variab,variable,36803,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,1,['variab'],['variable']
Modifiability,"ted data is passed to a system call; }. Unfortunately, the checker cannot discover automatically that the programmer; have performed data sanitation, so it still emits the warning. One can get rid of this superfluous warning by telling by specifying the; sanitation functions in the taint configuration file (see; :doc:`user-docs/TaintAnalysisConfiguration`). .. code-block:: YAML. Filters:; - Name: sanitizeFileName; Args: [0]. The clang invocation to pass the configuration file location:. .. code-block:: bash. clang --analyze -Xclang -analyzer-config -Xclang alpha.security.taint.TaintPropagation:Config=`pwd`/taint_config.yml ... If you are validating your inputs instead of sanitizing them, or don't want to; mention each sanitizing function in our configuration,; you can use a more generic approach. Introduce a generic no-op `csa_mark_sanitized(..)` function to; tell the Clang Static Analyzer; that the variable is safe to be used on that analysis path. .. code-block:: c. // Marking sanitized variables safe.; // No vulnerability anymore, no warning. // User csa_mark_sanitize function is for the analyzer only; #ifdef __clang_analyzer__; void csa_mark_sanitized(const void *);; #endif. int main(int argc, char** argv) {; char cmd[2048] = ""/bin/cat "";; char filename[1024];; printf(""Filename:"");; scanf ("" %1023[^\n]"", filename);; if (access(filename,F_OK)){// Verifying user input; printf(""File does not exist\n"");; return -1;; }; #ifdef __clang_analyzer__; csa_mark_sanitized(filename); // Indicating to CSA that filename variable is safe to be used after this point; #endif; strcat(cmd, filename);; system(cmd); // No warning; }. Similarly to the previous example, you need to; define a `Filter` function in a `YAML` configuration file; and add the `csa_mark_sanitized` function. .. code-block:: YAML. Filters:; - Name: csa_mark_sanitized; Args: [0]. Then calling `csa_mark_sanitized(X)` will tell the analyzer that `X` is safe to; be used after this point, because its contents are veri",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:68965,variab,variables,68965,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['variab'],['variables']
Modifiability,"ted in the FORTRAN programming language. A; C++ version is also available, MINUIT2, as well as Fumili [@Fumili] an; algorithm optimised for fitting. The; minimisation algorithms can be selected using the static functions of; the `ROOT::Math::MinimizerOptions` class. Steering options for the; minimiser, such as the convergence tolerance or the maximum number of; function calls, can also be set using the methods of this class. All; currently implemented minimisers are documented in the reference; documentation of ROOT: have a look for example to the; `ROOT::Math::Minimizer` class documentation.; \newpage; The complication level of the code below is intentionally a little; higher than in the previous examples. The graphical output of the macro; is shown in Figure [6.1](#f61):. ``` {.cpp .numberLines}; @ROOT_INCLUDE_FILE macros/macro8.C; ```. Some step by step explanation is at this point necessary:. - Lines *1-3*: A simple function to ease the make-up of lines.; Remember that the class `TF1` inherits from `TAttLine`. - Lines *5-7* : Definition of a customised function, namely a Gaussian; (the ""signal"") plus a parabolic function, the ""background"". - Lines *10-12*: Some make-up for the Canvas. In particular we want; that the parameters of the fit appear very clearly and nicely on the; plot. - Lines *20-25*: Define and initialise an instance of `TF1`. - Lines *27-31*: Define and fill a histogram. - Lines *33-38*: For convenience, the same function as for the; generation of the pseudo-data is used in the fit; hence, we need to; reset the function parameters. This part of the code is very; important for each fit procedure, as it sets the initial values of; the fit. - Line *41*: A very simple command, well known by now: fit the; function to the histogram. - Lines *42-46*: Retrieve the output from the fit. Here, we simply; print the fit result and access and print the covariance matrix of; the parameters. - Lines *54-end*: Plot the pseudo-data, the fitted function and the; sig",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/functions_and_parameter_estimation.md:2709,inherit,inherits,2709,documentation/primer/functions_and_parameter_estimation.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/functions_and_parameter_estimation.md,1,['inherit'],['inherits']
Modifiability,"ted notes. For full documentation, consult the CMake; manual, or execute ``cmake --help-variable VARIABLE_NAME``. **CMAKE_CXX_STANDARD**:STRING; Sets the C++ standard to conform to when building LLVM. Possible values are; 17 and 20. LLVM Requires C++ 17 or higher. This defaults to 17. **CMAKE_INSTALL_BINDIR**:PATH; The path to install executables, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""bin"". **CMAKE_INSTALL_INCLUDEDIR**:PATH; The path to install header files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""include"". **CMAKE_INSTALL_DOCDIR**:PATH; The path to install documentation, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/doc"". **CMAKE_INSTALL_MANDIR**:PATH; The path to install manpage files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/man"". .. _LLVM-related variables:. LLVM-related variables; -----------------------. These variables provide fine control over the build of LLVM and; enabled sub-projects. Nearly all of these variable names begin with; ``LLVM_``. **BUILD_SHARED_LIBS**:BOOL; Flag indicating if each LLVM component (e.g. Support) is built as a shared; library (ON) or as a static library (OFF). Its default value is OFF. On; Windows, shared libraries may be used when building with MinGW, including; mingw-w64, but not when building with the Microsoft toolchain. .. note:: BUILD_SHARED_LIBS is only recommended for use by LLVM developers.; If you want to build LLVM as a shared library, you should use the; ``LLVM_BUILD_LLVM_DYLIB`` option. **LLVM_ABI_BREAKING_CHECKS**:STRING; Used to decide if LLVM should be built with ABI breaking checks or; not. Allowed values are `WITH_ASSERTS` (default), `FORCE_ON` and; `FORCE_OFF`. `WITH_ASSERTS` turns on ABI breaking checks in an; assertion enabled build. `FORCE_ON` (`FORCE_OFF`) turns them on; (off) irrespective of whether normal (`NDEBUG`-based) assertions are; enabled or not. A version of LLVM built with ABI breaking checks; is not ABI compatible with a version buil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:11460,variab,variable,11460,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['variab'],['variable']
Modifiability,"ted projects. > 2. Design issues to consider (an initial list that we should continue; > to modify). Note that I'm not trying to suggest actual solutions here,; > but just various directions we can pursue:. Understood. :). > a. A single-assignment VM, which we've both already been thinking; > about. Yup, I think that this makes a lot of sense. I am still intrigued,; however, by the prospect of a minimally allocated VM representation... I; think that it could have definite advantages for certain applications; (think very small machines, like PDAs). I don't, however, think that our; initial implementations should focus on this. :). Here are some other auxiliary goals that I think we should consider:. 1. Primary goal: Support a high performance dynamic compilation; system. This means that we have an ""ideal"" division of labor between; the runtime and static compilers. Of course, the other goals of the; system somewhat reduce the importance of this point (f.e. portability; reduces performance, but hopefully not much); 2. Portability to different processors. Since we are most familiar with; x86 and solaris, I think that these two are excellent candidates when; we get that far...; 3. Support for all languages & styles of programming (general purpose; VM). This is the point that disallows java style bytecodes, where all; array refs are checked for bounds, etc...; 4. Support linking between different language families. For example, call; C functions directly from Java without using the nasty/slow/gross JNI; layer. This involves several subpoints:; A. Support for languages that require garbage collectors and integration; with languages that don't. As a base point, we could insist on; always using a conservative GC, but implement free as a noop, f.e. > b. A strongly-typed VM. One question is do we need the types to be; > explicitly declared or should they be inferred by the dynamic; > compiler?. B. This is kind of similar to another idea that I have: make OOP; constructs (virt",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt:3451,portab,portability,3451,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,1,['portab'],['portability']
Modifiability,"ted. The *start* and *length* arguments must be integers. ``!tail(``\ *a*\ ``)``; This operator produces a new list with all the elements; of the list *a* except for the zeroth one. (See also ``!head``.). ``!tolower(``\ *a*\ ``)``; This operator converts a string input *a* to lower case. ``!toupper(``\ *a*\ ``)``; This operator converts a string input *a* to upper case. ``!xor(``\ *a*\ ``,`` *b*\ ``, ...)``; This operator does a bitwise EXCLUSIVE OR on *a*, *b*, etc., and produces; the result. A logical XOR can be performed if all the arguments are either; 0 or 1. Appendix B: Paste Operator Examples; ===================================. Here is an example illustrating the use of the paste operator in record names. .. code-block:: text. defvar suffix = ""_suffstring"";; defvar some_ints = [0, 1, 2, 3];. def name # suffix {; }. foreach i = [1, 2] in {; def rec # i {; }; }. The first ``def`` does not use the value of the ``suffix`` variable. The; second def does use the value of the ``i`` iterator variable, because it is not a; global name. The following records are produced. .. code-block:: text. def namesuffix {; }; def rec1 {; }; def rec2 {; }. Here is a second example illustrating the paste operator in field value expressions. .. code-block:: text. def test {; string strings = suffix # suffix;; list<int> integers = some_ints # [4, 5, 6];; }. The ``strings`` field expression uses ``suffix`` on both sides of the paste; operator. It is evaluated normally on the left hand side, but taken verbatim; on the right hand side. The ``integers`` field expression uses the value of; the ``some_ints`` variable and a literal list. The following record is; produced. .. code-block:: text. def test {; string strings = ""_suffstringsuffix"";; list<int> ints = [0, 1, 2, 3, 4, 5, 6];; }. Appendix C: Sample Record; =========================. One target machine supported by LLVM is the Intel x86. The following output; from TableGen shows the record that is created to represent the 32-bit; regi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:74246,variab,variable,74246,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['variab'],['variable']
Modifiability,"teger()))))). After adding binds to the expressions we wished to capture and; extracting the identifier strings into variables, we have array-step-2; completed. Step 4: Retrieving Matched Nodes; ================================. So far, the matcher callback isn't very interesting: it just dumps the; loop's AST. At some point, we will need to make changes to the input; source code. Next, we'll work on using the nodes we bound in the; previous step. The ``MatchFinder::run()`` callback takes a; ``MatchFinder::MatchResult&`` as its parameter. We're most interested in; its ``Context`` and ``Nodes`` members. Clang uses the ``ASTContext``; class to represent contextual information about the AST, as the name; implies, though the most functionally important detail is that several; operations require an ``ASTContext*`` parameter. More immediately useful; is the set of matched nodes, and how we retrieve them. Since we bind three variables (identified by ConditionVarName,; InitVarName, and IncrementVarName), we can obtain the matched nodes by; using the ``getNodeAs()`` member function. In ``LoopConvert.cpp`` add. .. code-block:: c++. #include ""clang/AST/ASTContext.h"". Change ``LoopMatcher`` to. .. code-block:: c++. StatementMatcher LoopMatcher =; forStmt(hasLoopInit(declStmt(; hasSingleDecl(varDecl(hasInitializer(integerLiteral(equals(0)))); .bind(""initVarName"")))),; hasIncrement(unaryOperator(; hasOperatorName(""++""),; hasUnaryOperand(declRefExpr(; to(varDecl(hasType(isInteger())).bind(""incVarName"")))))),; hasCondition(binaryOperator(; hasOperatorName(""<""),; hasLHS(ignoringParenImpCasts(declRefExpr(; to(varDecl(hasType(isInteger())).bind(""condVarName""))))),; hasRHS(expr(hasType(isInteger())))))).bind(""forLoop"");. And change ``LoopPrinter::run`` to. .. code-block:: c++. void LoopPrinter::run(const MatchFinder::MatchResult &Result) {; ASTContext *Context = Result.Context;; const ForStmt *FS = Result.Nodes.getNodeAs<ForStmt>(""forLoop"");; // We do not want to convert header files!; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersTutorial.rst:16368,variab,variables,16368,interpreter/llvm-project/clang/docs/LibASTMatchersTutorial.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersTutorial.rst,1,['variab'],['variables']
Modifiability,"tegy`` and register it with the compiler:. .. code-block:: c++. // lib/MyGC/MyGC.cpp - Example LLVM GC plugin. #include ""llvm/CodeGen/GCStrategy.h""; #include ""llvm/CodeGen/GCMetadata.h""; #include ""llvm/Support/Compiler.h"". using namespace llvm;. namespace {; class LLVM_LIBRARY_VISIBILITY MyGC : public GCStrategy {; public:; MyGC() {}; };. GCRegistry::Add<MyGC>; X(""mygc"", ""My bespoke garbage collector."");; }. This boilerplate collector does nothing. More specifically:. * ``llvm.gcread`` calls are replaced with the corresponding ``load``; instruction. * ``llvm.gcwrite`` calls are replaced with the corresponding ``store``; instruction. * No safe points are added to the code. * The stack map is not compiled into the executable. Using the LLVM makefiles, this code; can be compiled as a plugin using a simple makefile:. .. code-block:: make. # lib/MyGC/Makefile. LEVEL := ../..; LIBRARYNAME = MyGC; LOADABLE_MODULE = 1. include $(LEVEL)/Makefile.common. Once the plugin is compiled, code using it may be compiled using ``llc; -load=MyGC.so`` (though MyGC.so may have some other platform-specific; extension):. ::. $ cat sample.ll; define void @f() gc ""mygc"" {; entry:; ret void; }; $ llvm-as < sample.ll | llc -load=MyGC.so. It is also possible to statically link the collector plugin into tools, such as; a language-specific compiler front-end. .. _collector-algos:. Overview of available features; ------------------------------. ``GCStrategy`` provides a range of features through which a plugin may do useful; work. Some of these are callbacks, some are algorithms that can be enabled,; disabled, or customized. This matrix summarizes the supported (and planned); features and correlates them with the collection techniques which typically; require them. .. |v| unicode:: 0x2714; :trim:. .. |x| unicode:: 0x2718; :trim:. +------------+------+--------+----------+-------+---------+-------------+----------+------------+; | Algorithm | Done | Shadow | refcount | mark- | copying | incremental ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:25343,plugin,plugin,25343,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['plugin'],['plugin']
Modifiability,"template pattern parameterized over the load upper immediate; instruction, add operation, the zero register, and register class.; Here the instantiation of MipsHiLoRelocs in MipsInstrInfo.td is used; to MIPS32 to compute addresses for the static relocation model. // lib/Target/Mips/MipsInstrInfo.td; multiclass MipsHiLoRelocs<Instruction Lui, Instruction Addiu,; Register ZeroReg, RegisterOperand GPROpnd> {; def : MipsPat<(MipsHi tglobaladdr:$in), (Lui tglobaladdr:$in)>;; ...; def : MipsPat<(MipsLo tglobaladdr:$in), (Addiu ZeroReg, tglobaladdr:$in)>;; ...; def : MipsPat<(add GPROpnd:$hi, (MipsLo tglobaladdr:$lo)),; (Addiu GPROpnd:$hi, tglobaladdr:$lo)>;; ...; }; defm : MipsHiLoRelocs<LUi, ADDiu, ZERO, GPR32Opnd>;. // lib/Target/Mips/Mips64InstrInfo.td; defm : MipsHiLoRelocs<LUi64, DADDiu, ZERO_64, GPR64Opnd>, SYM_32;. The instantiation in Mips64InstrInfo.td is used for MIPS64 in ILP32; mode, as guarded by the predicate ""SYM_32"" and also for a submode of; LP64 where symbols are assumed to be 32 bits wide. More details on how multiclasses in TableGen work can be found in the; section ""Multiclass definitions and instances"" in the document; ""TableGen Language Introduction"". 4. Instruction definitions are multiply defined to cover the different; register classes. In some cases, such as LW/LW64, this also accounts; for the difference in the results of instruction execution. On MIPS32,; ""lw"" loads a 32 bit value from memory. On MIPS64, ""lw"" loads a 32 bit; value from memory and sign extends the value to 64 bits. // lib/Target/Mips/MipsInstrInfo.td; def LUi : MMRel, LoadUpper<""lui"", GPR32Opnd, uimm16_relaxed>, LUI_FM;; // lib/Target/Mips/Mips64InstrInfo.td; def LUi64 : LoadUpper<""lui"", GPR64Opnd, uimm16_64_relaxed>, LUI_FM;. defines two names ""LUi"" and ""LUi64"" with two different register; classes, but with the same encoding---""LUI_FM"". These instructions load a; 16-bit immediate into bits 31-16 and clear the lower 15 bits. On MIPS64,; the result is sign-extended to 64 bits.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/Relocation.txt:3386,extend,extends,3386,interpreter/llvm-project/llvm/lib/Target/Mips/Relocation.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/Relocation.txt,2,['extend'],"['extended', 'extends']"
Modifiability,"ten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; print(c->name); // Unsafe read; } else {; kGlobalCustomer = c; // Pointer escape; }; // Unsafe read, Pointer escape; }; ```. ## Example: finding dead stores. Let's say we want to find redundant stores, because they indicate potential; bugs. ```c++; x = GetX();; x = GetY();; ```. The first store to `x` is never read, probably there is a bug. The implementation of dead store analysis is very similar to output parameter; analysis: we need to track stores and loads, and find stores that were never; read. [Liveness analysis](https://en.wikipedia.org/wiki/Live_variable_analysis) is a; generalization of this idea, which is often used to answer many related; questions, for example:. * finding dead stores,; * finding uninitialized variables,; * finding a good point to deallocate memory,; * finding out if it would be safe to move an object. ## Example: definitive initialization. Definitive initialization proves that variables are known to be initialized when; read. If we find a variable which is read when not initialized then we generate; a warning. ```c++; void Init() {; int x; // x is uninitialized; if (cond()) {; x = 10; // x is initialized; } else {; x = 20; // x is initialized; }; print(x); // x is initialized; }; ```. ```c++; void Uninit() {; int x; // x is uninitialized; if (cond()) {; x = 10; // x is initialized; }; print(x); // x is maybe uninitialized, x is being read, report a bug.; }; ```. For this purpose we can use lattice in a form of a mapping from variable; declarations to initialization states; each initialization state is represented; by the following lattice:. ![Lattice for definitive initialization analysis](DataFlowAnalysisIntroImages/DefinitiveInitializationLattice.svg). A lattice element could also capture the source locations of the branches that; lead us to the corresponding program point. Diagnostics would use this; information to show a sample buggy code path to the user. ##",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:20420,variab,variables,20420,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,1,['variab'],['variables']
Modifiability,"tended to be used outside of ROOT, including: `gROOTLocal` and related functions, `TSchemaHelper`, `TSchemaMatch`, `TSchemaType`, `RStl`, `ROOT::TROOTAllocator`, `TSchemaRuleProcessor`, `TStdBitsetHelper`, `TInitBehavior`, `TDefaultInitBehavior`, `DefineBehavior`, `THnBaseBrowsable`, `THnBaseBinIter`, `GenericShowMembers`, `TOperatorNewHelper` and `BranchProxy` implementations classes. Several definition where moved from the global or ROOT namespace to the ROOT::Details namespace as they are intended to be used in 'expert' level code and have a lower level of backward compatibility requirement. This includes `TCollectionProxyInfo`, `TSchemaRuleSet`. ## Interpreter. ROOT can now dump the context of STL collections, for instance `map<string,int>`. A few ROOT types print their content, too. Fixed the handling of the current directory in `#include` of system headers, avoid problem with local files named `new` or `vector`. Fixed the issue with the ROOT special variable where the objects were read from the file at each and every access by caching those object. See [ROOT-7830] for example. This release contains several bug fixes and improvements, notably in unloading and performance. > NOTE: The GCC 5 ABI is *not* supported yet, due to a lack of support in clang. ## I/O Libraries. ### hadd. We extended the `hadd` options to allow more control on the compression settings use for the; output file. In particular the new option -fk allows for a copy of the input; files with no decompressions/recompression of the TTree baskets even if they; do not match the requested compression setting. New options:. - `-ff` allows to force the compression setting to match the one from the first input; - `-fk[0-209]` allows to keep all the basket compressed as is and to compress the meta data with the given compression setting or the compression setting of the first input file.; - `-a` option append to existing file; - The verbosity level is now optional after -v. ### Command line utilities. We",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:6406,variab,variable,6406,README/ReleaseNotes/v606/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md,1,['variab'],['variable']
Modifiability,"tends C expression parsing to accommodate Block; reference declarations as it accommodates function pointer; declarations. Given:. .. code-block:: c. typedef int (*pointerToFunctionThatReturnsIntWithCharArg)(char);; pointerToFunctionThatReturnsIntWithCharArg functionPointer;; ^ pointerToFunctionThatReturnsIntWithCharArg (float x) { return functionPointer; }. and:. .. code-block:: c. ^ int ((*)(float x))(char) { return functionPointer; }. are equivalent expressions, as is:. .. code-block:: c. ^(float x) { return functionPointer; }. [returnfunctionptr.c]. The compound statement body establishes a new lexical scope within; that of its parent. Variables used within the scope of the compound; statement are bound to the Block in the normal manner with the; exception of those in automatic (stack) storage. Thus one may access; functions and global variables as one would expect, as well as static; local variables. [testme]. Local automatic (stack) variables referenced within the compound; statement of a Block are imported and captured by the Block as const; copies. The capture (binding) is performed at the time of the Block; literal expression evaluation. The compiler is not required to capture a variable if it can prove; that no references to the variable will actually be evaluated.; Programmers can force a variable to be captured by referencing it in a; statement at the beginning of the Block, like so:. .. code-block:: c. (void) foo;. This matters when capturing the variable has side-effects, as it can; in Objective-C or C++. The lifetime of variables declared in a Block is that of a function;; each activation frame contains a new copy of variables declared within; the local scope of the Block. Such variable declarations should be; allowed anywhere [testme] rather than only when C99 parsing is; requested, including for statements. [testme]. Block literal expressions may occur within Block literal expressions; (nest) and all variables captured by any nested blocks are impli",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst:4550,variab,variables,4550,interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,1,['variab'],['variables']
Modifiability,"ter LLVM versions can add support for multilib selection from more command; line options as needed. Extensible; ----------. It is likely that the configuration format will need to evolve in future to; adapt to new requirements.; Using a format like YAML that supports key-value pairs helps here as it's; trivial to add new keys alongside existing ones. Backwards compatibility; -----------------------. New versions of Clang should be able to use configuration written for earlier; Clang versions.; To avoid behaving in a way that may be subtly incorrect, Clang should be able; to detect if the configuration is too new and emit an error. Forwards compatibility; ----------------------. As an author of a multilib configuration, it should be possible to design the; configuration in such a way that it is likely to work well with future Clang; versions. For example, if a future version of Clang is likely to add support; for newer versions of an architecture and the architecture is known to be; designed for backwards compatibility then it should be possible to express; compatibility for such architecture versions in the multilib configuration. Not GNU spec files; ------------------. The GNU spec files standard is large and complex and there's little desire to; import that complexity to LLVM. It's also heavily oriented towards processing; command line argument strings which is hard to do correctly, hence the large; amount of logic dedicated to that task in the Clang driver. While compatibility; with GNU would bring benefits, the cost in this case is deemed too high. Avoid re-inventing feature detection in the configuration; ---------------------------------------------------------. A large amount of logic in the Clang driver is dedicated to inferring which; architectural features are available based on the given command line options.; It is neither desirable nor practical to repeat such logic in each multilib; configuration. Instead the configuration should be able to benefit from",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst:11582,config,configuration,11582,interpreter/llvm-project/clang/docs/Multilib.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst,1,['config'],['configuration']
Modifiability,"ter opening the file.; Add export of the envs ROOTPROOFCLIENT and ROOTPROOFLITE when; appropriate. These allow to steer building and/or enabling of PAR files; in PROOF-INF/BUILD.sh and/or PROOF-INF/SETUP.C, improving transparency; between normal ROOT and PROOF. The example PAR; 'tutorials/proof/event.par' has been modified to check the two; variables.; Fix a few issues in SQL PROOF monitoring: in; TSQLMonitoringWriter::SendParameters, drop ''' around field names in; the INSERT string; also use TString::Format(...) instead of Form(...); where relevant.  In TPerfStats: call 'proofgroup' instead of; 'group' the field with the PROOF group (interference with the 'group'; keyword in SQL); add new field 'querytag' VARCHAR(64) with the unique; query tag; in WriteQueryLog fill also the field 'totevents'; in; PacketEvent, add switch to control whether to send te information to; the monitoring system on per packet level (may be too much for SQL).; The switch is called fMonitorPerPacket and it is globally controlled by; the rootrc variable 'Proof.MonitorPerPacket' and at session level with; the parameter PROOF_MonitorPerPacket .; Improve treatment of the case when temporary files are asked to be; created on a shared file system not containing the sandboxes. This; case, which seems to be a rather common one, should be now fully; supported.; Correctly honour selector abort status settings; TSelector::kAbortProcess and TSelector::kAbortFile.; Improve reporting of the non-processed {files, events} in the final; 'MissingFiles' list.  ; Improved algorithm for TPacketizerUnit to fix issue with non; homogeneous machines.; Improve the way the information about log files is saved in case of; failures. The log paths for these failing now should be now correctly; saved and accessible via TProofLog.; Improve merging of histograms. Just use TH1::Add whne the axis are; equal; much faster than TH1::Merge. Fixes; ; In TDataSetManagerFile::NotifyUpdate fix handling of the case when; the global l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:4368,variab,variable,4368,proof/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html,1,['variab'],['variable']
Modifiability,"ter pool reads pages of _active_ columns.; For instance, if only certain fields are used (e.g., through an imposed model), only the pages of columns connected to those fields are read.; Columns can be dynamically added (e.g. during event iteration, a new field view is created in a reader).; The cluster pool reads ahead a limited number of clusters given by the _cluster bunch size_ option (default = 1).; The read-ahead uses vector reads.; For the file backend, it additionally coalesces close read requests and uses uring reads when available. The page source can be restricted to a certain entry range.; This allows for optimizing the page lists that are being read.; Additionally, it allows for optimizing the cluster pool to not read-ahead beyond the limits. #### Late model extension; Reading an RNTuple with an extended model is transparent -- i.e., no additional interface calls are required.; Internally, columns that were created as part of late model extension will have synthesized zero-initialized column ranges for the clusters that were already written before the model was extended.; In addition, pages made up of 0x00 bytes are synthesized for deferred columns in the clusters that were already (partially) filled before the model was extended. Storage Backends; ----------------. Support for storage backends is implemented through derived classes of `RPageSink` and `RPageSource`.; The `RPage{Sink,Source}File` class provides a storage backend for RNTuple data in ROOT files, local or remote.; The `RPage{Sink,Source}Daos` class provides a storage backend for RNTuple data in the DAOS object store. Every new storage backend needs to define; 1) The RNTuple embedding: how are RNTuple data blobs stored, e.g. in keys of ROOT files, or in objects of object stores; 2) The RNTuple anchor: the initial link to the location of the header and footer (cf. format specification); 3) A locator format: how are byte ranges addressed (e.g., through an offset in a file or an object ID). That",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:23267,extend,extended,23267,tree/ntuple/v7/doc/Architecture.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md,1,['extend'],['extended']
Modifiability,"ter; keys. Beware of non-deterministic sorting order of equal elements; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``std::sort`` uses a non-stable sorting algorithm in which the order of equal; elements is not guaranteed to be preserved. Thus using ``std::sort`` for a; container having equal elements may result in non-deterministic behavior.; To uncover such instances of non-determinism, LLVM has introduced a new; llvm::sort wrapper function. For an EXPENSIVE_CHECKS build this will randomly; shuffle the container before sorting. Default to using ``llvm::sort`` instead; of ``std::sort``. Style Issues; ============. The High-Level Issues; ---------------------. Self-contained Headers; ^^^^^^^^^^^^^^^^^^^^^^. Header files should be self-contained (compile on their own) and end in ``.h``.; Non-header files that are meant for inclusion should end in ``.inc`` and be; used sparingly. All header files should be self-contained. Users and refactoring tools should; not have to adhere to special conditions to include the header. Specifically, a; header should have header guards and include all other headers it needs. There are rare cases where a file designed to be included is not; self-contained. These are typically intended to be included at unusual; locations, such as the middle of another file. They might not use header; guards, and might not include their prerequisites. Name such files with the; .inc extension. Use sparingly, and prefer self-contained headers when possible. In general, a header should be implemented by one or more ``.cpp`` files. Each; of these ``.cpp`` files should include the header that defines their interface; first. This ensures that all of the dependences of the header have been; properly added to the header itself, and are not implicit. System headers; should be included after user headers for a translation unit. Library Layering; ^^^^^^^^^^^^^^^^. A directory of header files (for example ``include/llvm/Foo``) defines a; library (`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:29518,refactor,refactoring,29518,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['refactor'],['refactoring']
Modifiability,"ter; register banks have been selected.; The output operands are always ordered from lowest bits to highest:. .. code-block:: none. %bits_0_7:(s8), %bits_8_15:(s8),; %bits_16_23:(s8), %bits_24_31:(s8) = G_UNMERGE_VALUES %0:(s32). G_BSWAP; ^^^^^^^. Reverse the order of the bytes in a scalar. .. code-block:: none. %1:_(s32) = G_BSWAP %0:_(s32). G_BITREVERSE; ^^^^^^^^^^^^. Reverse the order of the bits in a scalar. .. code-block:: none. %1:_(s32) = G_BITREVERSE %0:_(s32). G_SBFX, G_UBFX; ^^^^^^^^^^^^^^. Extract a range of bits from a register. The source operands are registers as follows:. - Source; - The least-significant bit for the extraction; - The width of the extraction. The least-significant bit (lsb) and width operands are in the range:. ::. 0 <= lsb < lsb + width <= source bitwidth, where all values are unsigned. G_SBFX sign-extends the result, while G_UBFX zero-extends the result. .. code-block:: none. ; Extract 5 bits starting at bit 1 from %x and store them in %a.; ; Sign-extend the result.; ;; ; Example:; ; %x = 0...0000[10110]1 ---> %a = 1...111111[10110]; %lsb_one = G_CONSTANT i32 1; %width_five = G_CONSTANT i32 5; %a:_(s32) = G_SBFX %x, %lsb_one, %width_five. ; Extract 3 bits starting at bit 2 from %x and store them in %b. Zero-extend; ; the result.; ;; ; Example:; ; %x = 1...11111[100]11 ---> %b = 0...00000[100]; %lsb_two = G_CONSTANT i32 2; %width_three = G_CONSTANT i32 3; %b:_(s32) = G_UBFX %x, %lsb_two, %width_three. Integer Operations; -------------------. G_ADD, G_SUB, G_MUL, G_AND, G_OR, G_XOR, G_SDIV, G_UDIV, G_SREM, G_UREM; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These each perform their respective integer arithmetic on a scalar. .. code-block:: none. %dst:_(s32) = G_ADD %src0:_(s32), %src1:_(s32). The above example adds %src1 to %src0 and stores the result in %dst. G_SDIVREM, G_UDIVREM; ^^^^^^^^^^^^^^^^^^^^. Perform integer division and remainder thereby producing two results. .. code-block:: none. %div:_(s32), ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:5455,extend,extend,5455,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,1,['extend'],['extend']
Modifiability,"ternal; representation that can be generated into anything you want. Current usage of TableGen is to create huge include files with tables that you; can either include directly (if the output is in the language you're coding),; or be used in pre-processing via macros surrounding the include of the file. Direct output can be used if the backend already prints a table in C format; or if the output is just a list of strings (for error and warning messages).; Pre-processed output should be used if the same information needs to be used; in different contexts (like Instruction names), so your backend should print; a meta-information list that can be shaped into different compile-time formats. See :doc:`TableGen BackEnds <./BackEnds>` for a list of available; backends, and see the :doc:`TableGen Backend Developer's Guide <./BackGuide>`; for information on how to write and debug a new backend. Tools and Resources; ===================. In addition to this documentation, a list of tools and resources for TableGen; can be found in TableGen's; `README <https://github.com/llvm/llvm-project/blob/main/llvm/utils/TableGen/README.md>`_. TableGen Deficiencies; =====================. Despite being very generic, TableGen has some deficiencies that have been; pointed out numerous times. The common theme is that, while TableGen allows; you to build domain specific languages, the final languages that you create; lack the power of other DSLs, which in turn increase considerably the size; and complexity of TableGen files. At the same time, TableGen allows you to create virtually any meaning of; the basic concepts via custom-made backends, which can pervert the original; design and make it very hard for newcomers to understand the evil TableGen; file. There are some in favor of extending the semantics even more, but making sure; backends adhere to strict rules. Others are suggesting we should move to less,; more powerful DSLs designed with specific purposes, or even reusing existing; DSLs.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/index.rst:12616,extend,extending,12616,interpreter/llvm-project/llvm/docs/TableGen/index.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/index.rst,1,['extend'],['extending']
Modifiability,"ters of $\mbox{FCN}$ would be the; coefficients of the polynomials. Using objects for minimization from M ,; the user would request M to minimize the $\mbox{FCN}$ with respect; to the parameters, that is, find those values of the coefficients which; give the lowest value of chisquare. The user must therefore supply, in addition to the function to be; analyzed, via a set or sequence of M applications the instructions which; analysis is wanted. The instructions are coded in in the calling program; (main.cpp), which allows looping, conditional execution, and all the; other possibilities of , but not interactivity, since it must be; compiled before execution. ## Design aspects of M in ##. What M is:. - platform independent. - written in an object-oriented way using standard. - independent of any external package. The maintainability should be guaranteed with the choice of a modern; computer language. Choosing object-oriented technology M should profit; from an increased flexibility and functionality and make it also; extendable (recursiveness, new algorithms, new functionality). What M does not:. - histogramming. - data handling. - graphics. M is kept as a low-level package with optimal performance. The main usages of M are. - from a user's program (such as int main()...). - from a graphical data analysis tool such as HippoDraw@bib-HippoDraw. The most important goals of M in are. - its numerical accuracy (equivalent to its Fortran version). - its computational performance (equivalent to its Fortran version). For the design of the application programming interface (API) of M a; two-way strategy was imposed:. - a minimal required interface with minimum interaction with M objects; and with appropriate usage of the standard library (STL): the user's; implementation of the FCNBase class, initial parameter values and; uncertainties are provided by the to M user via std::vectors. - a rich interface which provides the user with more functionality; such as interaction with param",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:3828,extend,extendable,3828,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['extend'],['extendable']
Modifiability,"ters. The main design goals for the; PROOF system are:. *Transparency* : there should be as little difference as possible; between a local ROOT based analysis session and a remote parallel PROOF; session, both being interactive and giving the same results. *Scalability* : the basic architecture should not put any implicit; limitations on the number of computers that can be used in parallel. *Adaptability* : the system should be able to adapt itself to variations; in the remote environment (changing load on the cluster nodes, network; interruptions, etc.). Being an extension of the ROOT system, PROOF is designed to work on; objects in ROOT data stores, though, for the time being, it mainly; addresses the case of **`TTree`** based object collections. PROOF is primarily meant as an interactive alternative to batch systems; for Central Analysis Facilities and departmental workgroups (Tier-2's).; However, thanks to a multi-tier architecture allowing multiple levels of; masters, it can be easily adapted to wide range virtual clusters; distributed over geographically separated domains and heterogeneous; machines (GRIDs). While pure interactivity might not always be possible when performing a; complicated analysis on a very large data set, PROOF still tries to give; the user the interactive experience with something we call ""interactive; batch"". With ""interactive batch"" the user can start very long running; queries, disconnect the client and at any time, any location and from; any computer reconnect to the query to monitor its progress or retrieve; the results. This feature gives it a distinct advantage over purely; batch based solutions, that only provide an answer once all sub-jobs; have been finished. ![The Multi-tier structure of a PROOF cluster](pictures/03000200.png). Details about the PROOF system and the way to use it can be found at; <PROOFWiki> [^1]. The PROOF development is a joint effort between CERN and MIT. [^1]: http://root.cern.ch/twiki/bin/view/ROOT/PROOF; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PROOF.md:1257,adapt,adapted,1257,documentation/users-guide/PROOF.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PROOF.md,1,['adapt'],['adapted']
Modifiability,"ters; per element in the set (thus adding a large amount of per-element space; overhead). It offers guaranteed log(n) performance, which is not particularly; fast from a complexity standpoint (particularly if the elements of the set are; expensive to compare, like strings), and has extremely high constant factors for; lookup, insertion and removal. The advantages of std::set are that its iterators are stable (deleting or; inserting an element from the set does not affect iterators or pointers to other; elements) and that iteration over the set is guaranteed to be in sorted order.; If the elements in the set are large, then the relative overhead of the pointers; and malloc traffic is not a big deal, but if the elements of the set are small,; std::set is almost never a good choice. .. _dss_setvector:. llvm/ADT/SetVector.h; ^^^^^^^^^^^^^^^^^^^^. LLVM's ``SetVector<Type>`` is an adapter class that combines your choice of a; set-like container along with a :ref:`Sequential Container <ds_sequential>` The; important property that this provides is efficient insertion with uniquing; (duplicate elements are ignored) with iteration support. It implements this by; inserting elements into both a set-like container and the sequential container,; using the set-like container for uniquing and the sequential container for; iteration. The difference between SetVector and other sets is that the order of iteration; is guaranteed to match the order of insertion into the SetVector. This property; is really important for things like sets of pointers. Because pointer values; are non-deterministic (e.g. vary across runs of the program on different; machines), iterating over the pointers in the set will not be in a well-defined; order. The drawback of SetVector is that it requires twice as much space as a normal; set and has the sum of constant factors from the set-like container and the; sequential container that it uses. Use it **only** if you need to iterate over; the elements in a determi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:84329,adapt,adapter,84329,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['adapt'],['adapter']
Modifiability,"tes of a single section name string. There should be one; ``SECTIONNAME`` record for each section name referenced (e.g., in global; variable or function ``section`` attributes) within the module. These records; can be referenced by the 1-based index in the *section* fields of ``GLOBALVAR``; or ``FUNCTION`` records. MODULE_CODE_DEPLIB Record; ^^^^^^^^^^^^^^^^^^^^^^^^^. ``[DEPLIB, ...string...]``. The ``DEPLIB`` record (code 6) contains a variable number of values representing; the bytes of a single dependent library name string, one of the libraries; mentioned in a ``deplibs`` declaration. There should be one ``DEPLIB`` record; for each library name referenced. MODULE_CODE_GLOBALVAR Record; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``[GLOBALVAR, strtab offset, strtab size, pointer type, isconst, initid, linkage, alignment, section, visibility, threadlocal, unnamed_addr, externally_initialized, dllstorageclass, comdat, attributes, preemptionspecifier]``. The ``GLOBALVAR`` record (code 7) marks the declaration or definition of a; global variable. The operand fields are:. * *strtab offset*, *strtab size*: Specifies the name of the global variable.; See `STRTAB_BLOCK Contents`_. * *pointer type*: The type index of the pointer type used to point to this; global variable. * *isconst*: Non-zero if the variable is treated as constant within the module,; or zero if it is not. * *initid*: If non-zero, the value index of the initializer for this variable,; plus 1. .. _linkage type:. * *linkage*: An encoding of the linkage type for this variable:. * ``external``: code 0; * ``weak``: code 1; * ``appending``: code 2; * ``internal``: code 3; * ``linkonce``: code 4; * ``dllimport``: code 5; * ``dllexport``: code 6; * ``extern_weak``: code 7; * ``common``: code 8; * ``private``: code 9; * ``weak_odr``: code 10; * ``linkonce_odr``: code 11; * ``available_externally``: code 12; * deprecated : code 13; * deprecated : code 14. * alignment*: The logarithm base 2 of the variable's requested alignment, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:27298,variab,variable,27298,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,1,['variab'],['variable']
Modifiability,"tes required by the function to; record the number of test vectors executed for each boolean expression. Semantics:; """""""""""""""""""". This intrinsic represents basic MC/DC parameters initiating one or more MC/DC; instrumentation sequences in a function. It will cause the ``-instrprof`` pass; to generate the appropriate data structures and the code to instrument MC/DC; test vectors in a format that can be written out by a compiler runtime and; consumed via the ``llvm-profdata`` tool. '``llvm.instrprof.mcdc.condbitmap.update``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.instrprof.mcdc.condbitmap.update(ptr <name>, i64 <hash>,; i32 <condition-id>,; ptr <mcdc-temp-addr>,; i1 <bool-value>). Overview:; """""""""""""""""". The '``llvm.instrprof.mcdc.condbitmap.update``' intrinsic is used to track; MC/DC condition evaluation for each condition in a boolean expression. Arguments:; """""""""""""""""""". The first argument is a pointer to a global variable containing the; name of the entity being instrumented. This should generally be the; (mangled) function name for a set of counters. The second argument is a hash value that can be used by the consumer; of the profile data to detect changes to the instrumented source. The third argument is an ID of a condition to track. This value is used as a; bit index into the condition bitmap. The fourth argument is the address of the condition bitmap. The fifth argument is the boolean value representing the evaluation of the; condition (true or false). Semantics:; """""""""""""""""""". This intrinsic represents the update of a condition bitmap that is local to a; function and will cause the ``-instrprof`` pass to generate the code to; instrument the control flow around each condition in a boolean expression. The; ID of each condition corresponds to a bit index in the condition bitmap which; is set based on the evaluation of the condition. '``llvm.instrprof.mcdc.tvbitmap.update``' Intrinsic; ^^^^^^^^^^^^^^^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:533813,variab,variable,533813,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variable']
Modifiability,"tes with new values:; ```; // In a RooDataHist subclass:; _vars = externalCoordinates;; auto index = calcTreeIndex();. // Or from the outside:; auto index = dataHist.getIndex(externalCoordinates); // Side effect: Active bin is now `index`.; ```; coordinates are now passed into calcTreeIndex without side effects:; ```; // In a subclass:; auto index = calcTreeIndex(externalCoordinates, fast=<true/false>); // No side effect. // From the outside:; auto index = dataHist.getIndex(externalCoordinates); // No side effect; ```; This will allow for marking more functions const, or for lying less about const correctness. - RooDataHist now supports fits with RooFit's faster `BatchMode()`.; - Lower memory footprint. If weight errors are not needed, RooDataHist now allocates only 40% of the memory that the old implementation used. #### Fix bin volume correction logic in `RooDataHist::sum()`. The public member function `RooDataHist::sum()` has three overloads.; Two of these overloads accept a `sumSet` parameter to not sum over all variables.; These two overloads previously behaved inconsistently when the `correctForBinSize` or `inverseBinCor` flags were set.; If you use the `RooDataHist::sum()` function in you own classes, please check that it can still be used with its new logic.; The new and corrected bin correction behaviour is:. - `correctForBinSize`: multiply counts in each bin by the bin volume corresponding to the variables in `sumSet`; - `inverseBinCor`: divide counts in each bin by the bin volume corresponding to the variables *not* in `sumSet`. ### New fully parametrised Crystal Ball shape class. So far, the Crystal Ball distribution has been represented in RooFit only by the `RooCBShape` class, which has a Gaussian core and a single power-law tail on one side.; This release introduces [`RooCrystalBall`](https://root.cern/doc/v624/classRooCrystalBall.html), which implements some common generalizations of the Crystal Ball shape:. - symmetric or asymmetric power-law tails o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:23413,variab,variables,23413,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['variab'],['variables']
Modifiability,"test-suite Guide; ================. Quickstart; ----------. 1. The lit test runner is required to run the tests. You can either use one; from an LLVM build:. ```bash; % <path to llvm build>/bin/llvm-lit --version; lit 0.8.0dev; ```. An alternative is installing it as a python package in a python virtual; environment:. ```bash; % mkdir venv; % virtualenv venv; % . venv/bin/activate; % pip install svn+https://llvm.org/svn/llvm-project/llvm/trunk/utils/lit; % lit --version; lit 0.8.0dev; ```. 2. Check out the `test-suite` module with:. ```bash; % git clone https://github.com/llvm/llvm-test-suite.git test-suite; ```. 3. Create a build directory and use CMake to configure the suite. Use the; `CMAKE_C_COMPILER` option to specify the compiler to test. Use a cache file; to choose a typical build configuration:. ```bash; % mkdir test-suite-build; % cd test-suite-build; % cmake -DCMAKE_C_COMPILER=<path to llvm build>/bin/clang \; -C../test-suite/cmake/caches/O3.cmake \; ../test-suite; ```. **NOTE!** if you are using your built clang, and you want to build and run the; MicroBenchmarks/XRay microbenchmarks, you need to add `compiler-rt` to your; `LLVM_ENABLE_RUNTIMES` cmake flag. 4. Build the benchmarks:. ```text; % make; Scanning dependencies of target timeit-target; [ 0%] Building C object tools/CMakeFiles/timeit-target.dir/timeit.c.o; [ 0%] Linking C executable timeit-target; ...; ```. 5. Run the tests with lit:. ```text; % llvm-lit -v -j 1 -o results.json .; -- Testing: 474 tests, 1 threads --; PASS: test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test (1 of 474); ********** TEST 'test-suite :: MultiSource/Applications/ALAC/decode/alacconvert-decode.test' RESULTS **********; compile_time: 0.2192; exec_time: 0.0462; hash: ""59620e187c6ac38b36382685ccd2b63b""; size: 83348; **********; PASS: test-suite :: MultiSource/Applications/ALAC/encode/alacconvert-encode.test (2 of 474); ...; ```. 6. Show and compare result files (optional):. ```bash; # Make sure panda",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:666,config,configure,666,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,2,['config'],"['configuration', 'configure']"
Modifiability,"test.c -analyzer-display-progress; ANALYZE (Syntax): test.c foo; ANALYZE (Syntax): test.c bar; ANALYZE (Path, Inline_Regular): test.c bar; ANALYZE (Path, Inline_Regular): test.c foo; $ clang -cc1 -analyze -analyzer-checker=core test.c -analyzer-display-progress -analyze-function=foo; ANALYZE (Syntax): test.c foo; ANALYZE (Path, Inline_Regular): test.c foo. Note: a fully qualified function name has to be used when selecting; C++ functions and methods, Objective-C methods and blocks, e.g.:. $ clang -cc1 -analyze -analyzer-checker=core test.cc -analyze-function='foo(int)'. The fully qualified name can be found from the; -analyzer-display-progress output. The bug reporter mechanism removes path diagnostics inside intermediate; function calls that have returned by the time the bug was found and contain; no interesting pieces. Usually it is up to the checkers to produce more; interesting pieces by adding custom BugReporterVisitor objects.; However, you can disable path pruning while debugging with the; -analyzer-config prune-paths=false option. Visualizing the Analysis; To dump the AST, which often helps understanding how the program should; behave:. $ clang -cc1 -ast-dump test.c. To view/dump CFG use debug.ViewCFG or debug.DumpCFG; checkers:. $ clang -cc1 -analyze -analyzer-checker=debug.ViewCFG test.c. ExplodedGraph (the state graph explored by the analyzer) can be; visualized with another debug checker:. $ clang -cc1 -analyze -analyzer-checker=debug.ViewExplodedGraph test.c. Or, equivalently, with -analyzer-viz-egraph-graphviz; option, which does the same thing - dumps the exploded graph in graphviz; .dot format.; You can convert .dot files into other formats - in; particular, converting to .svg and viewing in your web; browser might be more comfortable than using a .dot viewer:. $ dot -Tsvg ExprEngine-501e2e.dot -o ExprEngine-501e2e.svg. The -trim-egraph option removes all paths except those; leading to bug reports from the exploded graph dump. This is useful; because",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html:20935,config,config,20935,interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html,1,['config'],['config']
Modifiability,"text.html>`_; inside Clang.; The ``Decl`` hierarchy is done very similarly to the example setup; demonstrated in this tutorial.; The key part is how to then incorporate ``DeclContext``: all that is needed; is in ``bool DeclContext::classof(const Decl *)``, which asks the question; ""Given a ``Decl``, how can I determine if it is-a ``DeclContext``?"".; It answers this with a simple switch over the set of ``Decl`` ""kinds"", and; returning true for ones that are known to be ``DeclContext``'s. .. TODO::. Touch on some of the more advanced features, like ``isa_impl`` and; ``simplify_type``. However, those two need reference documentation in; the form of doxygen comments as well. We need the doxygen so that we can; say ""for full details, see https://llvm.org/doxygen/..."". Rules of Thumb; ==============. #. The ``Kind`` enum should have one entry per concrete class, ordered; according to a preorder traversal of the inheritance tree.; #. The argument to ``classof`` should be a ``const Base *``, where ``Base``; is some ancestor in the inheritance hierarchy. The argument should; *never* be a derived class or the class itself: the template machinery; for ``isa<>`` already handles this case and optimizes it.; #. For each class in the hierarchy that has no children, implement a; ``classof`` that checks only against its ``Kind``.; #. For each class in the hierarchy that has children, implement a; ``classof`` that checks a range of the first child's ``Kind`` and the; last child's ``Kind``. RTTI for Open Class Hierarchies; ===============================. Sometimes it is not possible to know all types in a hierarchy ahead of time.; For example, in the shapes hierarchy described above the authors may have; wanted their code to work for user defined shapes too. To support use cases; that require open hierarchies LLVM provides the ``RTTIRoot`` and; ``RTTIExtends`` utilities. The ``RTTIRoot`` class describes an interface for performing RTTI checks. The; ``RTTIExtends`` class template provi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSetUpLLVMStyleRTTI.rst:12382,inherit,inheritance,12382,interpreter/llvm-project/llvm/docs/HowToSetUpLLVMStyleRTTI.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSetUpLLVMStyleRTTI.rst,1,['inherit'],['inheritance']
Modifiability,"th are optional. The ""selection of target"" behavior is defined as follows:. (1) If the user does not specify -triple, we default to the host triple.; (2) If the user specifies a -arch, that overrides the arch in the host or; specified triple. //===---------------------------------------------------------------------===//. verifyInputConstraint and verifyOutputConstraint should not return bool. Instead we should return something like:. enum VerifyConstraintResult {; Valid,. // Output only; OutputOperandConstraintLacksEqualsCharacter,; MatchingConstraintNotValidInOutputOperand,. // Input only; InputOperandConstraintContainsEqualsCharacter,; MatchingConstraintReferencesInvalidOperandNumber,. // Both; PercentConstraintUsedWithLastOperand; };. //===---------------------------------------------------------------------===//. Blocks should not capture variables that are only used in dead code. The rule that we came up with is that blocks are required to capture; variables if they're referenced in evaluated code, even if that code; doesn't actually rely on the value of the captured variable. For example, this requires a capture:; (void) var;; But this does not:; if (false) puts(var);. Summary of <rdar://problem/9851835>: if we implement this, we should; warn about non-POD variables that are referenced but not captured, but; only if the non-reachability is not due to macro or template; metaprogramming. //===---------------------------------------------------------------------===//. We can still apply a modified version of the constructor/destructor; delegation optimization in cases of virtual inheritance where:; - there is no function-try-block,; - the constructor signature is not variadic, and; - the parameter variables can safely be copied and repassed; to the base constructor because either; - they have not had their addresses taken by the vbase initializers or; - they were passed indirectly. //===---------------------------------------------------------------------===//; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/NOTES.txt:3283,variab,variables,3283,interpreter/llvm-project/clang/NOTES.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/NOTES.txt,3,"['inherit', 'variab']","['inheritance', 'variables']"
Modifiability,"th may be absolute or relative to the working directory. The ``.clang-format`` file uses YAML format:. .. code-block:: yaml. key1: value1; key2: value2; # A comment.; ... The configuration file can consist of several sections each having different; ``Language:`` parameter denoting the programming language this section of the; configuration is targeted at. See the description of the **Language** option; below for the list of supported languages. The first section may have no; language set, it will set the default style options for all languages.; Configuration sections for specific language will override options set in the; default section. When :program:`clang-format` formats a file, it auto-detects the language using; the file name. When formatting standard input or a file that doesn't have the; extension corresponding to its language, ``-assume-filename=`` option can be; used to override the file name :program:`clang-format` uses to detect the; language. An example of a configuration file for multiple languages:. .. code-block:: yaml. ---; # We'll use defaults from the LLVM style, but with 4 columns indentation.; BasedOnStyle: LLVM; IndentWidth: 4; ---; Language: Cpp; # Force pointers to the type for C++.; DerivePointerAlignment: false; PointerAlignment: Left; ---; Language: JavaScript; # Use 100 columns for JS.; ColumnLimit: 100; ---; Language: Proto; # Don't format .proto files.; DisableFormat: true; ---; Language: CSharp; # Use 100 columns for C#.; ColumnLimit: 100; ... An easy way to get a valid ``.clang-format`` file containing all configuration; options of a certain predefined style is:. .. code-block:: console. clang-format -style=llvm -dump-config > .clang-format. When specifying configuration in the ``-style=`` option, the same configuration; is applied for all input files. The format of the configuration is:. .. code-block:: console. -style='{key1: value1, key2: value2, ...}'. Disabling Formatting on a Piece of Code; =====================================",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:2791,config,configuration,2791,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['config'],['configuration']
Modifiability,"th, clang-format will format up to the end; of the file.; Can only be used with one input file.; --lines=<string> - <start line>:<end line> - format a range of; lines (both 1-based).; Multiple ranges can be formatted by specifying; several -lines arguments.; Can't be used with -offset and -length.; Can only be used with one input file.; -n - Alias for --dry-run; --offset=<uint> - Format a range starting at this byte offset.; Multiple ranges can be formatted by specifying; several -offset and -length pairs.; Can only be used with one input file.; --output-replacements-xml - Output replacements as XML.; --qualifier-alignment=<string> - If set, overrides the qualifier alignment style; determined by the QualifierAlignment style flag; --sort-includes - If set, overrides the include sorting behavior; determined by the SortIncludes style flag; --style=<string> - Set coding style. <string> can be:; 1. A preset: LLVM, GNU, Google, Chromium, Microsoft,; Mozilla, WebKit.; 2. 'file' to load style configuration from a; .clang-format file in one of the parent directories; of the source file (for stdin, see --assume-filename).; If no .clang-format file is found, falls back to; --fallback-style.; --style=file is the default.; 3. 'file:<format_file_path>' to explicitly specify; the configuration file.; 4. ""{key: value, ...}"" to set specific parameters, e.g.:; --style=""{BasedOnStyle: llvm, IndentWidth: 8}""; --verbose - If set, shows the list of processed files. Generic Options:. --help - Display available options (--help-hidden for more); --help-list - Display list of available options (--help-list-hidden for more); --version - Display the version of this program. .. END_FORMAT_HELP. When the desired code formatting style is different from the available options,; the style can be customized using the ``-style=""{key: value, ...}""`` option or; by putting your style configuration in the ``.clang-format`` or ``_clang-format``; file in your project's directory and using ``clang-format -sty",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst:3870,config,configuration,3870,interpreter/llvm-project/clang/docs/ClangFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst,1,['config'],['configuration']
Modifiability,"th::MinimizerOptions::SetDefaultMinimizer(""Minuit"");; ```. Alternatively, you can add this line to your `~/.rootrc` file:; ```; Root.Fitter: Minuit; ```. ### Behavior change of `TMath::AreEqualAbs()`. The `TMath::AreEqualAbs()` compares two numbers for equality within a certain absolute range.; So far, it would tell you that `inf != inf` if you define `inf` as `std::numeric_limits<double>::infinity()`, which is inconsistent with the regular `==` operator. This is unexpected, because one would expect that if two numbers are considered exactly equal, they would also be considered equal within any range.; Therefore, the behavior of `TMath::AreEqualAbs()` was changed to return always `true` if the `==` comparison would return `true`. ## RooFit Libraries. ### Changes in RooFormulaVar and RooGenericPdf. The TFormula-based RooFit classes `RooFormulaVar` and `RooGenericPdf` change a bit their behavior to be more consistent:. 1. No matter which variables you pass to the constructor, only the variables that the formula depends on are registered as value servers.; 2. Similarly, the `dependents()` method of RooFormulaVar and RooGenericPdf will only return the list of actual value servers. ### Removal of the RooGenFunction and RooMultiGenFunction classes. The `RooGenFunction` was only a lightweight adaptor that exports a RooAbsReal as a `ROOT::Math::IGenFunction`.; The same can be easily achieved with the generic `ROOT::Math::Functor1D`, so in the spirit of not duplicating interfaces, the `RooGenFunction` is removed in this release. Here is an example that shows how to replace it in the unlikely case you were using it:. ```C++; RooArgSet normSet{x}; // normalization set. // Old way 1: create a RooGenFunction:; RooGenFunction func1{pdf, x, {}, normSet};. // Old way 2: use `RooAbsReal::iGenFunction()`:; std::unique_ptr<ROOT::Math::IGenFunction> func2{; pdf.iGenFunction(x, normSet); };. // How to do it now:; RooFunctor functor{pdf, x, {}, normSet};; ROOT::Math::Functor1D func3{funct",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md:11347,variab,variables,11347,README/ReleaseNotes/v630/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v630/index.md,2,['variab'],['variables']
Modifiability,"than trying something a; little crazy or off the wall and seeing how it turns out. If you get; stuck or want to talk about it, please post on the `LLVM forums ; <https://discourse.llvm.org>`_: it has lots of people who are interested; in languages and are often willing to help out. Before we end this tutorial, I want to talk about some ""tips and tricks""; for generating LLVM IR. These are some of the more subtle things that; may not be obvious, but are very useful if you want to take advantage of; LLVM's capabilities. Properties of the LLVM IR; =========================. We have a couple of common questions about code in the LLVM IR form -; let's just get these out of the way right now, shall we?. Target Independence; -------------------. Kaleidoscope is an example of a ""portable language"": any program written; in Kaleidoscope will work the same way on any target that it runs on.; Many other languages have this property, e.g. lisp, java, haskell,; javascript, python, etc (note that while these languages are portable,; not all their libraries are). One nice aspect of LLVM is that it is often capable of preserving target; independence in the IR: you can take the LLVM IR for a; Kaleidoscope-compiled program and run it on any target that LLVM; supports, even emitting C code and compiling that on targets that LLVM; doesn't support natively. You can trivially tell that the Kaleidoscope; compiler generates target-independent code because it never queries for; any target-specific information when generating code. The fact that LLVM provides a compact, target-independent,; representation for code gets a lot of people excited. Unfortunately,; these people are usually thinking about C or a language from the C; family when they are asking questions about language portability. I say; ""unfortunately"", because there is really no way to make (fully general); C code portable, other than shipping the source code around (and of; course, C source code is not actually portable in general",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst:5888,portab,portable,5888,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst,1,['portab'],['portable']
Modifiability,"that information used to optimize the program. If the condition is violated; during execution, the behavior is undefined. The argument itself is never; evaluated, so any side effects of the expression will be discarded. Query for this feature with ``__has_builtin(__builtin_assume)``. .. _langext-__builtin_assume_separate_storage:. ``__builtin_assume_separate_storage``; -------------------------------------. ``__builtin_assume_separate_storage`` is used to provide the optimizer with the; knowledge that its two arguments point to separately allocated objects. **Syntax**:. .. code-block:: c++. __builtin_assume_separate_storage(const volatile void *, const volatile void *). **Example of Use**:. .. code-block:: c++. int foo(int *x, int *y) {; __builtin_assume_separate_storage(x, y);; *x = 0;; *y = 1;; // The optimizer may optimize this to return 0 without reloading from *x.; return *x;; }. **Description**:. The arguments to this function are assumed to point into separately allocated; storage (either different variable definitions or different dynamic storage; allocations). The optimizer may use this fact to aid in alias analysis. If the; arguments point into the same storage, the behavior is undefined. Note that the; definition of ""storage"" here refers to the outermost enclosing allocation of any; particular object (so for example, it's never correct to call this function; passing the addresses of fields in the same struct, elements of the same array,; etc.). Query for this feature with ``__has_builtin(__builtin_assume_separate_storage)``. ``__builtin_offsetof``; ----------------------. ``__builtin_offsetof`` is used to implement the ``offsetof`` macro, which; calculates the offset (in bytes) to a given member of the given type. **Syntax**:. .. code-block:: c++. __builtin_offsetof(type-name, member-designator). **Example of Use**:. .. code-block:: c++. struct S {; char c;; int i;; struct T {; float f[2];; } t;; };. const int offset_to_i = __builtin_offsetof(struct S, i)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:100255,variab,variable,100255,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['variab'],['variable']
Modifiability,"that it can show approximate Poisson errors for non-integer data. These approximate; errors are calculated from interpolation of the error bars of the nearest integers. NB: A weighted dataset; plotted with RooAbsData::plotOn() will be default show sum-of-weights-squared errors. Only; when Poisson error are forced through a DataError(RooAbsData::Poisson) argument these; approximate Poisson error bars are shown. Miscellaneous improvements other. The RooFit messagee service class RooMsgService has been augmented with a stack that; can store its configurate state information. A call to saveState() will save the; present configuration, which can be restored through a subsequent call to restoreState().; In addition to the method RooAbsArg::printCompactTree() which is mostly intende for; debugging, a new method RooAbsArg::printComponentTree() has been added that prints; the tree structure of a pdf in a more user-friendly content oriented way. The printing ; of the leaf nodes (the variables) is omitted in this method to keep the output compact. RooStats. This release contains significant bug fixes and it is strongly; recommended to update to this version if using older ones. . Major Changes in LimitCalculator and HypoTestCalculator classes: usage of ModelConfig class. The RooStats calculator interfaces have been changed to use the ModelConfig class.; All the setter methods with the parameter lists, pdf instances and name have been removed from the interfaces.; The SetWorkspace(RooWorkspace & ) has also been removed, while a SetModel(const ModelConfig &); function is introduced. Users are supposed to pass all the model information using the; ModelConfig class rather than via the; RooWorkspace or specifying directly the pdf and parameter; objects in the constructors. ; Setter methods using pdf instances and parameter lists are maintained in the derived classes, like the ProfileLikelihoodCalculator or the HybridCalculator, but those passing a string for the name of the pdf have",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:11217,variab,variables,11217,roofit/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html,1,['variab'],['variables']
Modifiability,"that we'll have a source file; with a simple program written in Kaleidoscope rather than the; interactive JIT. It does involve a limitation that we can only; have one ""top level"" command at a time to reduce the number of; changes necessary. Here's the sample program we'll be compiling:. .. code-block:: python. def fib(x); if x < 3 then; 1; else; fib(x-1)+fib(x-2);. fib(10). Why is this a hard problem?; ===========================. Debug information is a hard problem for a few different reasons - mostly; centered around optimized code. First, optimization makes keeping source; locations more difficult. In LLVM IR we keep the original source location; for each IR level instruction on the instruction. Optimization passes; should keep the source locations for newly created instructions, but merged; instructions only get to keep a single location - this can cause jumping; around when stepping through optimized programs. Secondly, optimization; can move variables in ways that are either optimized out, shared in memory; with other variables, or difficult to track. For the purposes of this; tutorial we're going to avoid optimization (as you'll see with one of the; next sets of patches). Ahead-of-Time Compilation Mode; ==============================. To highlight only the aspects of adding debug information to a source; language without needing to worry about the complexities of JIT debugging; we're going to make a few changes to Kaleidoscope to support compiling; the IR emitted by the front end into a simple standalone program that; you can execute, debug, and see results. First we make our anonymous function that contains our top level; statement be our ""main"":. .. code-block:: udiff. - auto Proto = std::make_unique<PrototypeAST>("""", std::vector<std::string>());; + auto Proto = std::make_unique<PrototypeAST>(""main"", std::vector<std::string>());. just with the simple change of giving it a name. Then we're going to remove the command line code wherever it exists:. .. code-blo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst:2189,variab,variables,2189,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst,2,['variab'],['variables']
Modifiability,"that when; thrown they pop stack frames until a catch clause is found. Objective-C Extensions; ======================. Objective-C extends the definition of a Block reference type to be; that also of id. A variable or expression of Block type may be; messaged or used as a parameter wherever an id may be. The converse is; also true. Block references may thus appear as properties and are; subject to the assign, retain, and copy attribute logic that is; reserved for objects. All Blocks are constructed to be Objective-C objects regardless of; whether the Objective-C runtime is operational in the program or; not. Blocks using automatic (stack) memory are objects and may be; messaged, although they may not be assigned into ``__weak`` locations; if garbage collection is enabled. Within a Block literal expression within a method definition; references to instance variables are also imported into the lexical; scope of the compound statement. These variables are implicitly; qualified as references from self, and so self is imported as a const; copy. The net effect is that instance variables can be mutated. The :block-term:`Block_copy` operator retains all objects held in; variables of automatic storage referenced within the Block expression; (or form strong references if running under garbage collection).; Object variables of ``__block`` storage type are assumed to hold; normal pointers with no provision for retain and release messages. Foundation defines (and supplies) ``-copy`` and ``-release`` methods for; Blocks. In the Objective-C and Objective-C++ languages, we allow the; ``__weak`` specifier for ``__block`` variables of object type. If; garbage collection is not enabled, this qualifier causes these; variables to be kept without retain messages being sent. This; knowingly leads to dangling pointers if the Block (or a copy) outlives; the lifetime of this object. In garbage collected environments, the ``__weak`` variable is set to; nil when the object it references is coll",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst:9492,variab,variables,9492,interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,1,['variab'],['variables']
Modifiability,"the C standard shall be either; non-trivial or illegal to copy, destroy, or default-initialize.; An implementation may provide additional types which have one or more; of these properties. An expression calls for a type to be copied if it:. - passes an argument of that type to a function call,; - defines a function which declares a parameter of that type,; - calls or defines a function which returns a value of that type,; - assigns to an l-value of that type, or; - converts an l-value of that type to an r-value. A program calls for a type to be destroyed if it:. - passes an argument of that type to a function call,; - defines a function which declares a parameter of that type,; - calls or defines a function which returns a value of that type,; - creates an object of automatic storage duration of that type,; - assigns to an l-value of that type, or; - converts an l-value of that type to an r-value. A program calls for a type to be default-initialized if it:. - declares a variable of that type without an initializer. An expression is ill-formed if calls for a type to be copied,; destroyed, or default-initialized and that type is illegal to; (respectively) copy, destroy, or default-initialize. A program is ill-formed if it contains a function type specifier; with a parameter or return type that is illegal to copy or; destroy. If a function type specifier would be ill-formed for this; reason except that the parameter or return type was incomplete at; that point in the translation unit, the program is ill-formed but; no diagnostic is required. A ``goto`` or ``switch`` is ill-formed if it jumps into the scope of; an object of automatic storage duration whose type is non-trivial to; destroy. C specifies that it is generally undefined behavior to access an l-value; if there is no object of that type at that location. Implementations; are often lenient about this, but non-trivial types generally require; it to be enforced more strictly. The following rules apply:. The *static",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:55839,variab,variable,55839,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['variab'],['variable']
Modifiability,"the Poisson log likelihood function; Improve calculation of derivative in x for fitted function. This fixes some problem observed when fitting using the error on the coordinates.; Fitter class: add new methods for calculating the error matrix after minimization, Fitter::CalculateHessErrors() and for calculating the Minos errors Fitter::CalculateMinosErrors; FitConfig: add in the configuration the possibility to select a sub-set of the parameters for calculating the Minos errors by using the method FitConfig::SetMinosErrors( listOfParameters ). If no list is passed, by default the Minos error will be computed on all parameters.; UnBinData class: add new constructor for creating a unbin data set passing a range to select the data and copy in the internal array; FitResult: the class now stores a map of the Minos error using as key the parameter index. If the Minos error has not been calculated for the parameter, FitResult::LowerError(i) and FitResult::UpperError(i) returns the parabolic error; ; Add a new class, MinimTransformFunction to perform a transformation of the function object to deal with limited and fixed variables.; This class uses the same transformation which are also used inside Minuit, a sin transformation for double bounded variables and a sqrt transformation for single bound variable defined in the class MinimizerVariableTransformation.; These classes can be used by minimizer which do not support internally the bounds (like the GSL minimizers).; . Add two new method in ROOT::Math::Minimizer class:; ; int Minimizer::CovMatrixStatus() : returning the status of the covariance matrix. Implemented by Minuit and Minuit2 and follows original Minuit code meaning: code = 0 (not calculated), 1 (approximated), 2 (matrix was made pos def) , 3 (accurate); ; bool Hesse(): to perform a full calculation of the Hessian matrix; . TMath. Fix a numerical problem in TMath::ErfcInverse for small input values. Now the normal quantile function is used for implementing it.; . ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v524/index.html:1744,variab,variables,1744,math/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v524/index.html,1,['variab'],['variables']
Modifiability,"the commands:. .. code-block:: bat. c:; cd \. You may install the llvm sources in other location than ``c:\llvm`` but do not; install into a path containing spaces (e.g. ``c:\Documents and Settings\...``); as it will fail. 10. Register the Microsoft Debug Interface Access (DIA) DLLs. .. code-block:: bat. regsvr32 ""%VSINSTALLDIR%\DIA SDK\bin\msdia140.dll""; regsvr32 ""%VSINSTALLDIR%\DIA SDK\bin\amd64\msdia140.dll"". The DIA library is required for LLVM PDB tests and; `LLDB development <https://lldb.llvm.org/resources/build.html>`_. 11. Install psutil and obtain LLVM source code:. .. code-block:: bat. pip install psutil; git clone https://github.com/llvm/llvm-project.git llvm. Instead of ``git clone`` you may download a compressed source distribution; from the `releases page <https://github.com/llvm/llvm-project/releases>`_.; Select the last link: ``Source code (zip)`` and unpack the downloaded file using; Windows Explorer built-in zip support or any other unzip tool. 12. Finally, configure LLVM using CMake:. .. code-block:: bat. cmake -S llvm\llvm -B build -DLLVM_ENABLE_PROJECTS=clang -DLLVM_TARGETS_TO_BUILD=X86 -Thost=x64; exit. ``LLVM_ENABLE_PROJECTS`` specifies any additional LLVM projects you want to; build while ``LLVM_TARGETS_TO_BUILD`` selects the compiler targets. If; ``LLVM_TARGETS_TO_BUILD`` is omitted by default all targets are built; slowing compilation and using more disk space.; See the :doc:`LLVM CMake guide <CMake>` for detailed information about; how to configure the LLVM build. The ``cmake`` command line tool is bundled with Visual Studio but its GUI is; not. You may install `CMake <http://www.cmake.org/>`_ to use its GUI to change; CMake variables or modify the above command line. * Once CMake is installed then the simplest way is to just start the; CMake GUI, select the directory where you have LLVM extracted to, and; the default options should all be fine. One option you may really; want to change, regardless of anything else, might be the; ``CMAKE_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst:4935,config,configure,4935,interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStartedVS.rst,1,['config'],['configure']
Modifiability,"the compiler driver; --------------------------. The Clang driver accepts the `-fplugin` option to load a plugin.; Clang plugins can receive arguments from the compiler driver command; line via the `fplugin-arg-<plugin name>-<argument>` option. Using this; method, the plugin name cannot contain dashes itself, but the argument; passed to the plugin can. .. code-block:: console. $ export BD=/path/to/build/directory; $ make -C $BD CallSuperAttr; $ clang++ -fplugin=$BD/lib/CallSuperAttr.so \; -fplugin-arg-call_super_plugin-help \; test.cpp. If your plugin name contains dashes, either rename the plugin or used the; cc1 command line options listed below. Using the cc1 command line; --------------------------. To run a plugin, the dynamic library containing the plugin registry must be; loaded via the `-load` command line option. This will load all plugins; that are registered, and you can select the plugins to run by specifying the; `-plugin` option. Additional parameters for the plugins can be passed with; `-plugin-arg-<plugin-name>`. Note that those options must reach clang's cc1 process. There are two; ways to do so:. * Directly call the parsing process by using the `-cc1` option; this; has the downside of not configuring the default header search paths, so; you'll need to specify the full system path configuration on the command; line.; * Use clang as usual, but prefix all arguments to the cc1 process with; `-Xclang`. For example, to run the ``print-function-names`` plugin over a source file in; clang, first build the plugin, and then call clang with the plugin from the; source tree:. .. code-block:: console. $ export BD=/path/to/build/directory; $ (cd $BD && make PrintFunctionNames ); $ clang++ -D_GNU_SOURCE -D_DEBUG -D__STDC_CONSTANT_MACROS \; -D__STDC_FORMAT_MACROS -D__STDC_LIMIT_MACROS -D_GNU_SOURCE \; -I$BD/tools/clang/include -Itools/clang/include -I$BD/include -Iinclude \; tools/clang/tools/clang-check/ClangCheck.cpp -fsyntax-only \; -Xclang -load -Xclang $BD/lib",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangPlugins.rst:5441,plugin,plugins,5441,interpreter/llvm-project/clang/docs/ClangPlugins.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangPlugins.rst,3,['plugin'],"['plugin-arg', 'plugin-name', 'plugins']"
Modifiability,"the default on Darwin. Note that Clang will; never emit type information for types that are not referenced at all by the; program. .. option:: -feliminate-unused-debug-types. By default, Clang does not emit type information for types that are defined; but not used in a program. To retain the debug info for these unused types,; the negation **-fno-eliminate-unused-debug-types** can be used. .. option:: -fexceptions. Allow exceptions to be thrown through Clang compiled stack frames (on many; targets, this will enable unwind information for functions that might have; an exception thrown through them). For most targets, this is enabled by; default for C++. .. option:: -ftrapv. Generate code to catch integer overflow errors. Signed integer overflow is; undefined in C. With this flag, extra code is generated to detect this and; abort when it happens. .. option:: -fvisibility. This flag sets the default visibility level. .. option:: -fcommon, -fno-common. This flag specifies that variables without initializers get common linkage.; It can be disabled with :option:`-fno-common`. .. option:: -ftls-model=<model>. Set the default thread-local storage (TLS) model to use for thread-local; variables. Valid values are: ""global-dynamic"", ""local-dynamic"",; ""initial-exec"" and ""local-exec"". The default is ""global-dynamic"". The default; model can be overridden with the tls_model attribute. The compiler will try; to choose a more efficient model if possible. .. option:: -flto, -flto=full, -flto=thin, -emit-llvm. Generate output files in LLVM formats, suitable for link time optimization.; When used with :option:`-S` this generates LLVM intermediate language; assembly files, otherwise this generates LLVM bitcode format object files; (which may be passed to the linker depending on the stage selection options). The default for :option:`-flto` is ""full"", in which the; LLVM bitcode is suitable for monolithic Link Time Optimization (LTO), where; the linker merges all such modules into a single ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:14499,variab,variables,14499,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,1,['variab'],['variables']
Modifiability,"the effects of the CPU frontend on architectures; that cache decoded instructions, but consumes a register for counting; iterations. If performing an analysis over many opcodes, it may be best to; instead use the `min` mode, which will run each other mode,; and produce the minimal measured result. .. option:: --num-repetitions=<Number of repetitions>. Specify the target number of executed instructions. Note that the actual; repetition count of the snippet will be `num-repetitions`/`snippet size`.; Higher values lead to more accurate measurements but lengthen the benchmark. .. option:: --loop-body-size=<Preferred loop body size>. Only effective for `-repetition-mode=[loop|min]`.; Instead of looping over the snippet directly, first duplicate it so that the; loop body contains at least this many instructions. This potentially results; in loop body being cached in the CPU Op Cache / Loop Cache, which allows to; which may have higher throughput than the CPU decoders. .. option:: --max-configs-per-opcode=<value>. Specify the maximum configurations that can be generated for each opcode.; By default this is `1`, meaning that we assume that a single measurement is; enough to characterize an opcode. This might not be true of all instructions:; for example, the performance characteristics of the LEA instruction on X86; depends on the value of assigned registers and immediates. Setting a value of; `-max-configs-per-opcode` larger than `1` allows `llvm-exegesis` to explore; more configurations to discover if some register or immediate assignments; lead to different performance characteristics. .. option:: --benchmarks-file=</path/to/file>. File to read (`analysis` mode) or write (`latency`/`uops`/`inverse_throughput`; modes) benchmark results. ""-"" uses stdin/stdout. .. option:: --analysis-clusters-output-file=</path/to/file>. If provided, write the analysis clusters as CSV to this file. ""-"" prints to; stdout. By default, this analysis is not run. .. option:: --analysis-inconsiste",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:13857,config,configs-per-opcode,13857,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,1,['config'],['configs-per-opcode']
Modifiability,"the elements in; *list*. To perform the filtering, TableGen binds the variable *var* to each; element and then evaluates the *predicate* expression, which presumably; refers to *var*. The predicate must; produce a boolean value (``bit``, ``bits``, or ``int``). The value is; interpreted as with ``!if``:; if the value is 0, the element is not included in the new list. If the value; is anything else, the element is included. ``!find(``\ *string1*\ ``,`` *string2*\ [``,`` *start*]\ ``)``; This operator searches for *string2* in *string1* and produces its; position. The starting position of the search may be specified by *start*,; which can range between 0 and the length of *string1*; the default is 0.; If the string is not found, the result is -1. ``!foldl(``\ *init*\ ``,`` *list*\ ``,`` *acc*\ ``,`` *var*\ ``,`` *expr*\ ``)``; This operator performs a left-fold over the items in *list*. The; variable *acc* acts as the accumulator and is initialized to *init*.; The variable *var* is bound to each element in the *list*. The; expression is evaluated for each element and presumably uses *acc* and; *var* to calculate the accumulated value, which ``!foldl`` stores back in; *acc*. The type of *acc* is the same as *init*; the type of *var* is the; same as the elements of *list*; *expr* must have the same type as *init*. The following example computes the total of the ``Number`` field in the; list of records in ``RecList``::. int x = !foldl(0, RecList, total, rec, !add(total, rec.Number));. If your goal is to filter the list and produce a new list that includes only; some of the elements, see ``!filter``. ``!foreach(``\ *var*\ ``,`` *sequence*\ ``,`` *expr*\ ``)``; This operator creates a new ``list``/``dag`` in which each element is a; function of the corresponding element in the *sequence* ``list``/``dag``.; To perform the function, TableGen binds the variable *var* to an element; and then evaluates the expression. The expression presumably refers; to the variable *var* and c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:64060,variab,variable,64060,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['variab'],['variable']
Modifiability,"the estimate for the compressed cluster size, it will be flushed, too.; The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise.; The following clusters use the average compression ratio of all so-far written clusters as an estimate.; See the notes below on a discussion of this approximation. Page Sizes; ==========. Pages contain consecutive elements of a certain column.; They are the unit of compression and of addressability on storage.; RNTuple puts a configurable maximum uncompressed size for pages.; This limit is by default set to 1 MiB.; When the limit is reached, a page will be flushed to disk. In addition, RNTuple maintains a memory budget for the combined allocated size of the pages that are currently filled.; By default, this limit is set to twice the compressed target cluster size when compression is used,; and to the cluster target size for uncompressed data.; Initially, and after flushing, all columns use small pages,; just big enough to hold the configurable minimum number of elements (64 by default).; Page sizes are doubled as more data is filled into them.; When a page reaches the maximum page size (see above), it is flushed.; When the overall page budget is reached,; pages larger than the page at hand are flushed before the page at hand is flushed.; For the parallel writer, every fill context maintains the page memory budget independently. Note that the total amount of memory consumed for writing is usually larger than the write page budget.; For instance, if buffered writing is used (the default), additional memory is required.; Use RNTupleModel::EstimateWriteMemoryUsage() for the total estimated memory use for writing. The default values are tuned for a total write memory of around 300 MB per writer resp. fill context.; In order to decrease the memory consumption,; users should decrease the target cluster size before tuning more intricate memory settings. Notes; =====. Approximation of the compressed clus",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md:2163,config,configurable,2163,tree/ntuple/v7/doc/tuning.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md,1,['config'],['configurable']
Modifiability,"the fields into columns. .. note::. As of clang-format 15 this option only applied to arrays with equal; number of columns per row. Possible values:. * ``AIAS_Left`` (in configuration: ``Left``); Align array column and left justify the columns e.g.:. .. code-block:: c++. struct test demo[] =; {; {56, 23, ""hello""},; {-1, 93463, ""world""},; {7, 5, ""!!"" }; };. * ``AIAS_Right`` (in configuration: ``Right``); Align array column and right justify the columns e.g.:. .. code-block:: c++. struct test demo[] =; {; {56, 23, ""hello""},; {-1, 93463, ""world""},; { 7, 5, ""!!""}; };. * ``AIAS_None`` (in configuration: ``None``); Don't align array initializer columns. .. _AlignConsecutiveAssignments:. **AlignConsecutiveAssignments** (``AlignConsecutiveStyle``) :versionbadge:`clang-format 3.8` :ref:`¶ <AlignConsecutiveAssignments>`; Style of aligning consecutive assignments. ``Consecutive`` will result in formattings like:. .. code-block:: c++. int a = 1;; int somelongname = 2;; double c = 3;. Nested configuration flags:. Alignment options. They can also be read as a whole for compatibility. The choices are:; - None; - Consecutive; - AcrossEmptyLines; - AcrossComments; - AcrossEmptyLinesAndComments. For example, to align across empty lines and not across comments, either; of these work. .. code-block:: c++. AlignConsecutiveMacros: AcrossEmptyLines. AlignConsecutiveMacros:; Enabled: true; AcrossEmptyLines: true; AcrossComments: false. * ``bool Enabled`` Whether aligning is enabled. .. code-block:: c++. #define SHORT_NAME 42; #define LONGER_NAME 0x007f; #define EVEN_LONGER_NAME (2); #define foo(x) (x * x); #define bar(y, z) (y + z). int a = 1;; int somelongname = 2;; double c = 3;. int aaaa : 1;; int b : 12;; int ccc : 8;. int aaaa = 12;; float b = 23;; std::string ccc;. * ``bool AcrossEmptyLines`` Whether to align across empty lines. .. code-block:: c++. true:; int a = 1;; int somelongname = 2;; double c = 3;. int d = 3;. false:; int a = 1;; int somelongname = 2;; double c = 3;. int d = 3;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:9475,config,configuration,9475,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['config'],['configuration']
Modifiability,"the last match). For example, clang emits; vtable globals in reverse order. Using ``CHECK-DAG:``, we can keep the checks; in the natural order:. .. code-block:: c++. // RUN: %clang_cc1 %s -emit-llvm -o - | FileCheck %s. struct Foo { virtual void method(); };; Foo f; // emit vtable; // CHECK-DAG: @_ZTV3Foo =. struct Bar { virtual void method(); };; Bar b;; // CHECK-DAG: @_ZTV3Bar =. ``CHECK-NOT:`` directives could be mixed with ``CHECK-DAG:`` directives to; exclude strings between the surrounding ``CHECK-DAG:`` directives. As a result,; the surrounding ``CHECK-DAG:`` directives cannot be reordered, i.e. all; occurrences matching ``CHECK-DAG:`` before ``CHECK-NOT:`` must not fall behind; occurrences matching ``CHECK-DAG:`` after ``CHECK-NOT:``. For example,. .. code-block:: llvm. ; CHECK-DAG: BEFORE; ; CHECK-NOT: NOT; ; CHECK-DAG: AFTER. This case will reject input strings where ``BEFORE`` occurs after ``AFTER``. With captured variables, ``CHECK-DAG:`` is able to match valid topological; orderings of a DAG with edges from the definition of a variable to its use.; It's useful, e.g., when your test cases need to match different output; sequences from the instruction scheduler. For example,. .. code-block:: llvm. ; CHECK-DAG: add [[REG1:r[0-9]+]], r1, r2; ; CHECK-DAG: add [[REG2:r[0-9]+]], r3, r4; ; CHECK: mul r5, [[REG1]], [[REG2]]. In this case, any order of that two ``add`` instructions will be allowed. If you are defining `and` using variables in the same ``CHECK-DAG:`` block,; be aware that the definition rule can match `after` its use. So, for instance, the code below will pass:. .. code-block:: text. ; CHECK-DAG: vmov.32 [[REG2:d[0-9]+]][0]; ; CHECK-DAG: vmov.32 [[REG2]][1]; vmov.32 d0[1]; vmov.32 d0[0]. While this other code, will not:. .. code-block:: text. ; CHECK-DAG: vmov.32 [[REG2:d[0-9]+]][0]; ; CHECK-DAG: vmov.32 [[REG2]][1]; vmov.32 d1[1]; vmov.32 d0[0]. While this can be very useful, it's also dangerous, because in the case of; register sequence, you mus",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst:19050,variab,variables,19050,interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,2,['variab'],"['variable', 'variables']"
Modifiability,"the left most base class. Schema Evolution. Fix schema evolution problem in TTree::Draw by extending support in; TStreamerInfo::ReadValueAux to 'converted' numerical types, (; see issue in ROOT forum). When reading more than one TStreamerInfo for the same versioned; class, we now use the highest possible class version as the current; version of the class. Practically, we update the class version; when reading new (higher versioned) StreamerInfo until the Class; is actually used (i.e. TClass::GetClassVersion is call directly; or indirectly). In particular, if a file has several StreamerInfos for the same; versioned class, we will use the highest version number as the; 'current' class version (as opposed to the lowest until now). For backward compatibility TStreamerInfo::BuildCheck compares the checksum of; the on-file StreamerInfo not only to the current value of the class checksum; but also to the checksum calculated using the older algorithms. This patch extends this test to also be done when comparing 2 on-file StreamerInfos. This removes spurrious warning message when loading 2 older files which; were written with 2 different version of the TClass CheckSum algorithm; (and the in-memory class's version is greater than both TStreamerInfos'; class version). Extend support of TStreamerInfo::ReadValueAux to 'converted' numerical types, hence solving TTree::Draw's schema evolution problem (see http://root.cern/phpBB2/viewtopic.php?t=6225). DirectoryAutoAdd; Use the new DirectoryAutoAdd facility for the classes:; TTree, TH1, TEventList, TEntryList, TGraph2D; (and hence their derived classes). The instances of those classes are now added automatically; to the current directory only when Constructe'd with arguments or Clone'd; and to the directory they are read from when their are stored; directly in a TKey. [Note: the default constructor never adds; the object to the current directory]. The directory auto add can still be disabled for instance; of TH1 and TGraph2D by sett",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v520/index.html:1918,extend,extends,1918,io/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v520/index.html,1,['extend'],['extends']
Modifiability,"the left panel in the browser. The browser shows several; folders under `//root`. New folders can be added and removed to/from a folder. ## Why Use Folders?. One reason to use folders is to reduce class dependencies and improve; modularity. Each set of data has a producer class and one or many; consumer classes. When using folders, the producer class places a; pointer to the data into a folder, and the consumer class retrieves a; reference to the folder. The consumer can access the objects in a folder by specifying the path; name of the folder. Here is an example of a folder's path name:. `//root/Event/Hits/TCP`. One does not have to specify the full path name. If the partial path; name is unique, it will find it; otherwise it will return the first; occurrence of the path. The first diagram shows a system without folders. The objects have; pointers to each other to access each other's data. Pointers are an; efficient way to share data between classes. However, a direct pointer; creates a direct coupling between classes. This design can become a very; tangled web of dependencies in a system with a large number of classes. ![](pictures/020000E2.jpg). In the second diagram, a reference to the data is in the folder and the; consumers refer to the folder rather than each other to access the data.; The naming and search service provided by the ROOT folders hierarchy; provides an alternative. It loosely couples the classes and greatly; enhances I/O operations. In this way, folders separate the data from the; algorithms and greatly improve the modularity of an application by; minimizing the class dependencies. ![](pictures/020000E3.jpg). In addition, the folder hierarchy creates a picture of the data; organization. This is useful when discussing data design issues or when; learning the data organization. The example below illustrates this; point. ## How to Use Folders. Using folders means to build a hierarchy of folders, posting the; reference to the data in the folder by t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FoldersTasks.md:1346,coupling,coupling,1346,documentation/users-guide/FoldersTasks.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FoldersTasks.md,1,['coupling'],['coupling']
Modifiability,"the list of browsable. This way,; it is visible in the browser on the top level. ``` {.cpp}; {; // Add the top folder of my hierary to //root; TFolder *aliroot=gROOT->GetRootFolder()->AddFolder(""aliroot"",; ""aliroot top level folders"");; // Add the hierarchy to the list of browsables; gROOT->GetListOfBrowsables()->Add(aliroot,""aliroot"");. // Create and add the constants folder; TFolder *constants=aliroot->AddFolder(""Constants"",; ""Detector constants"");. // Create and add the pdg folder to pdg; TFolder *pdg = constants->AddFolder(""DatabasePDG"",""PDG database"");. // Create and add the run folder; TFolder *run = aliroot->AddFolder(""Run"",""Run dependent folders"");. // Create and add the configuration folder to run; TFolder *configuration = run->AddFolder(""Configuration"",; ""Run configuration"");. // Create and add the run_mc folder; TFolder *run_mc = aliroot->AddFolder(""RunMC"",; ""MonteCarlo run dependent folders"");. // Create and add the configuration_mc folder to run_mc; TFolder *configuration_mc = run_mc->AddFolder(""Configuration"",; ""MonteCarlo run configuration"");; }; ```. ### Posting Data to a Folder (Producer). ![](pictures/030000E4.png). A **`TFolder`** can contain other folders as shown above or any; **`TObject`** descendents. In general, users will not post a single; object to a folder; they will store a collection or multiple collections; in a folder. For example, to add an array to a folder:. ``` {.cpp}; TObjArray *array;; run_mc->Add(array);; ```. ### Reading Data from a Folder (Consumer). One can search for a folder or an object in a folder using the; `TROOT::FindObjectAny` method. It analyzes the string passed as its; argument and searches in the hierarchy until it finds an object or; folder matching the name. With `FindObjectAny`, you can give the full; path name, or the name of the folder. If only the name of the folder is; given, it will return the first instance of that name. A string-based; search is time consuming. If the retrieved object is used frequently ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FoldersTasks.md:3905,config,configuration,3905,documentation/users-guide/FoldersTasks.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FoldersTasks.md,1,['config'],['configuration']
Modifiability,"the model is generated with `batchsize=1`.; The Keras parser supports now in addition to the Dense layer the Conv2D layer, several activation functions (Relu, Selu, Sigmoid, Softmax, Tanh, LeakyRelu) and these other layers: BatchNormalization, Reshape, Convatenate, Add, Subtract, Multiply.; Models with Dropout layers are supported in case the Dropout is used only during training and not inference. For model having operators not yet supported in the Keras parser it is then reccomended to convert the Keras model to `ONNX` using the python `tf2onnx` tool. #### SOFIE PyTorch Parser. If using PyTorch it is recommended to save the model directly in `ONNX` format instad of the native `.pt` format by using the `torch.onnx.export` function of PyTorch. The support for parsing directly `.pt` files is limited to the Gemm, Conv, Relu, Selu, Sigmoid and Transpose operators. #### SOFIE RDataFrame Integration. The SOFIE inference is now integrated with RDataFrame, where a model can be evaluated on the columns of an input `TTree` with `RDataFrame` using the adapter functor class `SofieFunctor`.; Examples of using SOFIE with `RDataFrame` are the new tutorials (in the `tutorials/tmva` directory) `TMVA_SOFIE_RDataFrame.C` or `TMVA_SOFIE_RDataFrame.py`. `TMVA_SOFIE_RDataFrame_JIT.C` is an example where the SOFIE model is generated and compiled at runtime using ROOT Cling and evaluated using RDataFrame. #### RSofieReader. `RSofieReader` is a new class, which takes as input a model file (in ONNX, Keras, PyTorch or ROOT format) and generates and compiles the C++ code for the inference at run time using the ROOT JITing capabilities of CLING. An example of using this class is the tutorial `TMVA_SOFIE_RSofieReader.C`. ### TMVA Pythonizations. New Pythonizations are available for TMVA allowing to replace the option string passed to several `TMVA` functions such as the `TMVA::Factory` constructor, the `DataLoader::PrepareTrainingAndTestTree` and `Factory::BookMethod` using Python function argume",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md:29311,adapt,adapter,29311,README/ReleaseNotes/v628/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md,1,['adapt'],['adapter']
Modifiability,"the output is serialized to :ref:`YAML <yamlremarks>`. .. option:: -pass-remarks-format=<format>. Specifies the output format of the serialized remarks. Supported formats:. * :ref:`yaml <yamlremarks>` (default); * :ref:`yaml-strtab <yamlstrtabremarks>`; * :ref:`bitstream <bitstreamremarks>`. ``Content configuration``. .. option:: -pass-remarks-filter=<regex>. Only passes whose name match the given (POSIX) regular expression will be; serialized to the final output. .. option:: -pass-remarks-with-hotness. With PGO, include profile count in optimization remarks. .. option:: -pass-remarks-hotness-threshold. The minimum profile count required for an optimization remark to be; emitted. Other tools that support remarks:. :program:`llvm-lto`. .. option:: -lto-pass-remarks-output=<filename>; .. option:: -lto-pass-remarks-filter=<regex>; .. option:: -lto-pass-remarks-format=<format>; .. option:: -lto-pass-remarks-with-hotness; .. option:: -lto-pass-remarks-hotness-threshold. :program:`gold-plugin` and :program:`lld`. .. option:: -opt-remarks-filename=<filename>; .. option:: -opt-remarks-filter=<regex>; .. option:: -opt-remarks-format=<format>; .. option:: -opt-remarks-with-hotness. Serialization modes; ===================. There are two modes available for serializing remarks:. ``Separate``. In this mode, the remarks and the metadata are serialized separately. The; client is responsible for parsing the metadata first, then use the metadata; to correctly parse the remarks. ``Standalone``. In this mode, the remarks and the metadata are serialized to the same; stream. The metadata will always come before the remarks. The compiler does not support emitting standalone remarks. This mode is; more suited for post-processing tools like linkers, that can merge the; remarks for one whole project. .. _yamlremarks:. YAML remarks; ============. A typical remark serialized to YAML looks like this:. .. code-block:: yaml. --- !<TYPE>; Pass: <pass>; Name: <name>; DebugLoc: { File: <file>, Line",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Remarks.rst:3650,plugin,plugin,3650,interpreter/llvm-project/llvm/docs/Remarks.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Remarks.rst,1,['plugin'],['plugin']
Modifiability,"the overloaded function:. // lib/Target/Mips/MipsISelLowering.h; SDValue getTargetNode(JumpTableSDNode *N, EVT Ty, SelectionDAG &DAG,; unsigned Flag) const;. 2. Generic address nodes are lowered to some combination of target; independent and machine specific SDNodes (for example:; MipsISD::{Highest, Higher, Hi, Lo}) depending upon relocation model,; ABI, and compilation options. The choice of specific instructions that are to be used is delegated; to ISel which in turn relies on TableGen patterns to choose subtarget; specific instructions. For example, in getAddrLocal, the pseudo-code; generated is:. (add (load (wrapper $gp, %got(sym)), %lo(sym)). where ""%lo"" represents an instance of an SDNode with opcode; ""MipsISD::Lo"", ""wrapper"" indicates one with opcode ""MipsISD::Wrapper"",; and ""%got"" the global table pointer ""getGlobalReg(...)"". The ""add"" is; ""ISD::ADD"", not a target dependent one. 3. A TableGen multiclass pattern ""MipsHiLoRelocs"" is used to define a; template pattern parameterized over the load upper immediate; instruction, add operation, the zero register, and register class.; Here the instantiation of MipsHiLoRelocs in MipsInstrInfo.td is used; to MIPS32 to compute addresses for the static relocation model. // lib/Target/Mips/MipsInstrInfo.td; multiclass MipsHiLoRelocs<Instruction Lui, Instruction Addiu,; Register ZeroReg, RegisterOperand GPROpnd> {; def : MipsPat<(MipsHi tglobaladdr:$in), (Lui tglobaladdr:$in)>;; ...; def : MipsPat<(MipsLo tglobaladdr:$in), (Addiu ZeroReg, tglobaladdr:$in)>;; ...; def : MipsPat<(add GPROpnd:$hi, (MipsLo tglobaladdr:$lo)),; (Addiu GPROpnd:$hi, tglobaladdr:$lo)>;; ...; }; defm : MipsHiLoRelocs<LUi, ADDiu, ZERO, GPR32Opnd>;. // lib/Target/Mips/Mips64InstrInfo.td; defm : MipsHiLoRelocs<LUi64, DADDiu, ZERO_64, GPR64Opnd>, SYM_32;. The instantiation in Mips64InstrInfo.td is used for MIPS64 in ILP32; mode, as guarded by the predicate ""SYM_32"" and also for a submode of; LP64 where symbols are assumed to be 32 bits wide. More details",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/Relocation.txt:1904,parameteriz,parameterized,1904,interpreter/llvm-project/llvm/lib/Target/Mips/Relocation.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/Relocation.txt,1,['parameteriz'],['parameterized']
Modifiability,"the parameter area is minimally 32 bytes (64 bytes in 64; bit mode.) Also note that since the parameter area is a fixed offset from the; top of the frame, that a callee can access its split arguments using fixed; offsets from the stack pointer (or base pointer.). Combining the information about the linkage, parameter areas and alignment. A; stack frame is minimally 64 bytes in 32 bit mode and 128 bytes in 64 bit mode. The *dynamic area* starts out as size zero. If a function uses dynamic alloca; then space is added to the stack, the linkage and parameter areas are shifted to; top of stack, and the new space is available immediately below the linkage and; parameter areas. The cost of shifting the linkage and parameter areas is minor; since only the link value needs to be copied. The link value can be easily; fetched by adding the original frame size to the base pointer. Note that; allocations in the dynamic space need to observe 16 byte alignment. The *locals area* is where the llvm compiler reserves space for local variables. The *saved registers area* is where the llvm compiler spills callee saved; registers on entry to the callee. Prolog/Epilog; ^^^^^^^^^^^^^. The llvm prolog and epilog are the same as described in the PowerPC ABI, with; the following exceptions. Callee saved registers are spilled after the frame is; created. This allows the llvm epilog/prolog support to be common with other; targets. The base pointer callee saved register r31 is saved in the TOC slot of; linkage area. This simplifies allocation of space for the base pointer and; makes it convenient to locate programmatically and during debugging. Dynamic Allocation; ^^^^^^^^^^^^^^^^^^. .. note::. TODO - More to come. The NVPTX backend; -----------------. The NVPTX code generator under lib/Target/NVPTX is an open-source version of; the NVIDIA NVPTX code generator for LLVM. It is contributed by NVIDIA and is; a port of the code generator used in the CUDA compiler (nvcc). It targets the; PTX 3.0/3.1 ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:100307,variab,variables,100307,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['variab'],['variables']
Modifiability,"the path to the test suite root inside; the object directory. This is where tests will be run and temporary output files; placed. **environment** A dictionary representing the environment to use when executing; tests in the suite. **standalone_tests** When true, mark a directory with tests expected to be run; standalone. Test discovery is disabled for that directory. *lit.suffixes* and; *lit.excludes* must be empty when this variable is true. **suffixes** For **lit** test formats which scan directories for tests, this; variable is a list of suffixes to identify test files. Used by: *ShTest*. **substitutions** For **lit** test formats which substitute variables into a test; script, the list of substitutions to perform. Used by: *ShTest*. **unsupported** Mark an unsupported directory, all tests within it will be; reported as unsupported. Used by: *ShTest*. **parent** The parent configuration, this is the config object for the directory; containing the test suite, or None. **root** The root configuration. This is the top-most :program:`lit` configuration in; the project. **pipefail** Normally a test using a shell pipe fails if any of the commands; on the pipe fail. If this is not desired, setting this variable to false; makes the test fail only if the last command in the pipe fails. **available_features** A set of features that can be used in `XFAIL`,; `REQUIRES`, and `UNSUPPORTED` directives. TEST DISCOVERY; ~~~~~~~~~~~~~~. Once test suites are located, :program:`lit` recursively traverses the source; directory (following *test_source_root*) looking for tests. When :program:`lit`; enters a sub-directory, it first checks to see if a nested test suite is; defined in that directory. If so, it loads that test suite recursively,; otherwise it instantiates a local test config for the directory (see; :ref:`local-configuration-files`). Tests are identified by the test suite they are contained within, and the; relative path inside that suite. Note that the relative path may not",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst:16976,config,configuration,16976,interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,1,['config'],['configuration']
Modifiability,"the resulting binary. Design; ======. Clang supports GCC's ``-print-multi-lib`` and ``-print-multi-directory``; options. These are described in; `GCC Developer Options <https://gcc.gnu.org/onlinedocs/gcc-12.2.0/gcc/Developer-Options.html>`_. There are two ways to configure multilib in Clang: hard-coded or via a; configuration file. Hard-coded Multilib; ===================. The available libraries can be hard-coded in Clang. Typically this is done; using the ``MultilibBuilder`` interface in; ``clang/include/clang/Driver/MultilibBuilder.h``.; There are many examples of this in ``lib/Driver/ToolChains/Gnu.cpp``.; The remainder of this document will not focus on this type of multilib. EXPERIMENTAL Multilib via configuration file; ============================================. Some Clang toolchains support loading multilib configuration from a; ``multilib.yaml`` configuration file. A ``multilib.yaml`` configuration file specifies which multilib variants are; available, their relative location, what compilation options were used to build; them, and the criteria by which they are selected. Multilib processing; ===================. Clang goes through the following steps to use multilib from a configuration; file:. #. Normalize command line options. Clang can accept the same; information via different options - for example,; ``--target=arm-none-eabi -march=armv7-m`` and; ``--target=armv7m-none-eabi`` are equivalent.; Clang normalizes the command line before passing them to the multilib system.; To see what flags are emitted for a given set of command line options, use; the ``-print-multi-flags-experimental`` command line option; along with the rest of the options you want to use.; #. Load ``multilib.yaml`` from sysroot.; #. Generate additional flags. ``multilib.yaml`` contains a ``Mappings`` section,; which specifies how to generate additional flags based on the flags derived; from command line options. Flags are matched using regular expressions.; These regular expressions s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst:2113,config,configuration,2113,interpreter/llvm-project/clang/docs/Multilib.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst,1,['config'],['configuration']
Modifiability,"the same information as produced; by the :program:`llvm-cov report` command, but presented in JSON or lcov; format rather than text. .. option:: -ignore-filename-regex=<PATTERN>. Skip source code files with file paths that match the given regular expression. .. option:: -skip-expansions. Skip exporting macro expansion coverage data. .. option:: -skip-functions. Skip exporting per-function coverage data. .. option:: -num-threads=N, -j=N. Use N threads to export coverage data. When N=0, llvm-cov auto-detects an; appropriate number of threads to use. This is the default. .. option:: -compilation-dir=<dir>. Directory used as a base for relative coverage mapping paths. Only applicable; when binaries have been compiled with one of `-fcoverage-prefix-map`; `-fcoverage-compilation-dir`, or `-ffile-compilation-dir`. .. option:: -debuginfod. Attempt to look up coverage mapping from objects using debuginfod. This is; attempted by default for binary IDs present in the profile but not provided on; the command line, so long as debuginfod is compiled in and configured via; DEBUGINFOD_URLS. .. option:: -debug-file-directory=<dir>. Provides a directory to search for objects corresponding to binary IDs in the; profile. .. option:: -check-binary-ids. Fail if an object file cannot be found for a binary ID present in the profile,; neither on the command line nor via binary ID lookup. CONVERT-FOR-TESTING COMMAND; ---------------------------. .. warning::; This command is for the LLVM developers who are working on ``llvm-cov`` only. SYNOPSIS; ^^^^^^^^. :program:`llvm-cov convert-for-testing` *BIN* -o *OUT*. DESCRIPTION; ^^^^^^^^^^^. The :program:`llvm-cov convert-for-testing` command serves the purpose of; testing `llvm-cov` itself. It can extract all code coverage data from the; binary *BIN* to the file *OUT*, thereby reducing the size of test files. The; output file typically bears the :program:`.covmapping` extension. The :program:`.covmapping` files can be read back by ``llvm-cov`` jus",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-cov.rst:18852,config,configured,18852,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-cov.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-cov.rst,1,['config'],['configured']
Modifiability,"the second argument). The exact code generated is specified by the Function's; selected :ref:`GC strategy <plugin>`. Read barriers are needed by fewer algorithms than write barriers, and may have a; greater performance impact since pointer reads are more frequent than writes. .. _plugin:. .. _builtin-gc-strategies:. Built In GC Strategies; ======================. LLVM includes built in support for several varieties of garbage collectors. The Shadow Stack GC; ----------------------. To use this collector strategy, mark your functions with:. .. code-block:: c++. F.setGC(""shadow-stack"");. Unlike many GC algorithms which rely on a cooperative code generator to compile; stack maps, this algorithm carefully maintains a linked list of stack roots; [:ref:`Henderson2002 <henderson02>`]. This so-called ""shadow stack"" mirrors the; machine stack. Maintaining this data structure is slower than using a stack map; compiled into the executable as constant data, but has a significant portability; advantage because it requires no special support from the target code generator,; and does not require tricky platform-specific code to crawl the machine stack. The tradeoff for this simplicity and portability is:. * High overhead per function call. * Not thread-safe. Still, it's an easy way to get started. After your compiler and runtime are up; and running, writing a :ref:`plugin <plugin>` will allow you to take advantage; of :ref:`more advanced GC features <collector-algos>` of LLVM in order to; improve performance. The shadow stack doesn't imply a memory allocation algorithm. A semispace; collector or building atop ``malloc`` are great places to start, and can be; implemented with very little code. When it comes time to collect, however, your runtime needs to traverse the stack; roots, and for this it needs to integrate with the shadow stack. Luckily, doing; so is very simple. (This code is heavily commented to help you understand the; data structure, but there are only 20 lines of meani",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:16512,portab,portability,16512,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['portab'],['portability']
Modifiability,"the set. The target-specific implementations of these classes is auto-generated from a; :doc:`TableGen/index` description of the register file. .. _TargetInstrInfo:. The ``TargetInstrInfo`` class; -----------------------------. The ``TargetInstrInfo`` class is used to describe the machine instructions; supported by the target. Descriptions define things like the mnemonic for; the opcode, the number of operands, the list of implicit register uses and defs,; whether the instruction has certain target-independent properties (accesses; memory, is commutable, etc), and holds any target-specific flags. The ``TargetFrameLowering`` class; ---------------------------------. The ``TargetFrameLowering`` class is used to provide information about the stack; frame layout of the target. It holds the direction of stack growth, the known; stack alignment on entry to each function, and the offset to the local area.; The offset to the local area is the offset from the stack pointer on function; entry to the first location where function data (local variables, spill; locations) can be stored. The ``TargetSubtarget`` class; -----------------------------. The ``TargetSubtarget`` class is used to provide information about the specific; chip set being targeted. A sub-target informs code generation of which; instructions are supported, instruction latencies and instruction execution; itinerary; i.e., which processing units are used, in what order, and for how; long. The ``TargetJITInfo`` class; ---------------------------. The ``TargetJITInfo`` class exposes an abstract interface used by the; Just-In-Time code generator to perform target-specific activities, such as; emitting stubs. If a ``TargetMachine`` supports JIT code generation, it should; provide one of these objects through the ``getJITInfo`` method. .. _code being generated:; .. _machine code representation:. Machine code description classes; ================================. At the high-level, LLVM code is translated to a machine ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:14366,variab,variables,14366,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['variab'],['variables']
Modifiability,"the size of the return type. When zero extending from i1,; the result will always be either 0 or 1. The conversion is performed on lane; positions below the explicit vector length and where the vector mask is true.; Masked-off lanes are ``poison``. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x i32> @llvm.vp.zext.v4i32.v4i16(<4 x i16> %a, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = zext <4 x i16> %a to <4 x i32>; %also.r = select <4 x i1> %mask, <4 x i32> %t, <4 x i32> poison. .. _int_vp_sext:. '``llvm.vp.sext.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x i32> @llvm.vp.sext.v16i32.v16i16 (<16 x i16> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x i32> @llvm.vp.sext.nxv4i32.nxv4i16 (<vscale x 4 x i16> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". The '``llvm.vp.sext``' intrinsic sign extends its first operand to the return; type. The operation has a mask and an explicit vector length parameter. Arguments:; """""""""""""""""""". The '``llvm.vp.sext``' intrinsic takes a value to cast as its first operand.; The return type is the type to cast the value to. Both types must be vectors of; :ref:`integer <t_integer>` type. The bit size of the value must be smaller than; the bit size of the return type. The second operand is the vector mask. The; return type, the value to cast, and the vector mask have the same number of; elements. The third operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.sext``' intrinsic performs a sign extension by copying the sign; bit (highest order bit) of the value until it reaches the size of the return; type. When sign extending from i1, the result will always be either -1 or 0.; The conversion is performed on lane positions below the explicit vector length; and where the vector mask is true. Masked-off lanes are ``poison`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:799714,extend,extends,799714,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['extend'],['extends']
Modifiability,"the sources of classes like **`TLine`** or **`TBox`**. Go and look at; their `ExecuteEvent` method! We can nevertheless give some reference to; the various actions that may be performed. For example, one often wants; to change the shape of the cursor when passing on top of an object. This; is done with the `SetCursor` method:. ``` {.cpp}; gPad->SetCursor(cursor); ```. The argument `cursor` is the type of cursor. It may be:. ``` {.cpp}; kBottomLeft, kBottomRight, kTopLeft,; kTopRight, kBottomSide, kLeftSide,; kTopSide, kRightSide, kMove,; kCross, kArrowHor, kArrowVer,; kHand, kRotate, kPointer,; kArrowRight, kCaret, kWatch; ```. They are defined in `TVirtualX.h` and again we hope the names are; self-explanatory. If not, try them by designing a small class. It may; derive from something already known like **`TLine`**. Note that the `ExecuteEvent()` functions may in turn; invoke such; functions for other objects, in case an object is drawn using other; objects. You can also exploit at best the virtues of inheritance. See; for example how the class **`TArrow`** (derived from **`TLine`**) use or; redefine the picking functions in its base class. The last comment is that mouse position is always given in pixel units; in all these standard functions. `px=0` and `py=0` corresponds to the; top-left corner of the canvas. Here, we have followed the standard; convention in windowing systems. Note that user coordinates in a canvas; (pad) have the origin at the bottom-left corner of the canvas (pad).; This is all explained in the paragraph ""The Coordinate Systems of a; Pad"". ## Graphical Containers: Canvas and Pad; \index{TPad}. We have talked a lot about canvases, which may be seen as windows. More; generally, a graphical entity that contains graphical objects is called; a Pad. A Canvas is a special kind of Pad. From now on, when we say; something about pads, this also applies to canvases. A pad (class; **`TPad`**) is a graphical container in the sense it contains other; graphica",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:12556,inherit,inheritance,12556,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['inherit'],['inheritance']
Modifiability,"the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any Python regular expression enclosed in ``{{ }}``, in which case the boolean; expression is satisfied if any feature matches the regular expression. Regular; expressions can appear inside an identifier, so for example ``he{{l+}}o`` would match; ``helo``, ``hello``, ``helllo``, and so on.; - The default target triple, preceded by the string ``target=`` (for example,; ``target=x86_64-pc-windows-msvc``). Typically regular expressions are used; to match parts of the triple (for example, ``target={{.*}}-windows{{.*}}``; to match any Windows target triple). | ``REQUIRES`` enables the test if all expressions are true.; | ``UNSUPPORTED`` disables the test if any expression is true.; | ``XFAIL`` expects the test to fail if any expression is true. As a special case, ``XFAIL: *`` is expected to fail everywhere. .. code-b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:20430,config,config,20430,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,1,['config'],['config']
Modifiability,"the tdf, skipped otherwise.; - The TLazyDS data source has been added. It allows to create a source starting from ResultProxies to vectors.; - `TDataFrameInterface<T>::Report` returns a `TCutflowReport` object which can be inspected programmatically.; - Add `Aggregate` action and implement `Reduce` in terms of it.; - Add support for a more general leafname syntax that includes pathnames with multiple dots, such as ""myBranch.mySubBranch.myLeaf"". This is available both for jitted expressions and for lists of column names.; - The CSV data source (TCsvDS) can now be constructed with a chunk size parameter, and as a result the CSV file will be read progressively, in chunks of the specified size. This can be used to prevent the whole CSV file from being read into memory at once, thus reducing the memory footprint of this data source.; - Add the `ROOT::Experimental::TAdoptAllocator<T>`, an allocator which allows to adopt existing memory. If memory is adopted, upon allocation a copy is performed in the new, potentially more extended, memory region.; - Add `ROOT::Experimental::VecOps::TVec<T>` a class which represents a contiguous array, inspired by Numpy arrays. `TVec` offer a convenient interface, almost identical to the one of `std::vector`. It can own or adopt its memory. As well as a set of tools which make analysis of collections easier, avoiding to loop over the individual elements of the collections. Basic arithmetic operations such as +,-,*,/,% between TVecs and scalars and TVecs are supported. Most popular math functions which act on TVecs are provided. Helpers to calculate basic quantities such as sum, mean, variance or standard deviation of TVecs are provided.; A powerful and concise syntax for expressing cuts is available:; ```; // mu_pts_tvec and mu_etas_tvec are two equally sized TVecs holding kinematic properties of muons; // a filter on muons pseudorapidities is applied considering a range in pseudo rapidity.; filtered_mu_pts_tvec = mu_pts_tvec[abs(mu_etas_t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:8394,extend,extended,8394,README/ReleaseNotes/v614/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md,1,['extend'],['extended']
Modifiability,"the tutorial [rf515_hfJSON](https://root.cern/doc/v626/rf515__hfJSON_8py.html). ### Creating RooFit datasets from RDataFrame; RooFit now contains two RDataFrame action helpers, `RooDataSetHelper` and `RooDataHistHelper`, which allow for creating RooFit datasets by booking an action:; ```c++; RooRealVar x(""x"", ""x"", -5., 5.);; RooRealVar y(""y"", ""y"", -50., 50.);; auto myDataSet = rdataframe.Book<double, double>(; RooDataSetHelper{""dataset"", // Name (directly forwarded to RooDataSet::RooDataSet()); ""Title of dataset"", // Title ( ~ "" ~ ); RooArgSet(x, y) }, // Variables to create in dataset; {""x"", ""y""} // Column names from RDataFrame; );; ```; For more details, consult the tutorial [rf408_RDataFrameToRooFit](https://root.cern/doc/v626/rf408__RDataFrameToRooFit_8C.html). ### Storing global observables in RooFit datasets. RooFit groups model variables into *observables* and *parameters*, depending on if their values are stored in the dataset.; For fits with parameter constraints, there is a third kind of variables, called *global observables*.; These represent the results of auxiliary measurements that constrain the nuisance parameters.; In the RooFit implementation, a likelihood is generally the sum of two terms:; * the likelihood of the data given the parameters, where the normalization set is the set of observables (implemented by `RooNLLVar`); * the constraint term, where the normalization set is the set of *global observables* (implemented by `RooConstraintSum`). Before this release, the global observable values were always taken from the model/pdf.; With this release, a mechanism is added to store a snapshot of global observables in any `RooDataSet` or `RooDataHist`.; For toy studies where the global observables assume a different values for each toy, the bookkeeping of the set of global observables and in particular their values is much easier with this change. Usage example for a model with global observables `g1` and `g2`:; ```C++; auto data = model.generate(x, 100",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md:26985,variab,variables,26985,README/ReleaseNotes/v626/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md,1,['variab'],['variables']
Modifiability,"the type table. TYPE_CODE_PPC_FP128 Record; ^^^^^^^^^^^^^^^^^^^^^^^^^^. ``[PPC_FP128]``. The ``PPC_FP128`` record (code 15) adds a ``ppc_fp128`` (128-bit floating point); type to the type table. TYPE_CODE_METADATA Record; ^^^^^^^^^^^^^^^^^^^^^^^^^. ``[METADATA]``. The ``METADATA`` record (code 16) adds a ``metadata`` type to the type table. TYPE_CODE_X86_MMX Record; ^^^^^^^^^^^^^^^^^^^^^^^^. ``[X86_MMX]``. The ``X86_MMX`` record (code 17) adds an ``x86_mmx`` type to the type table. TYPE_CODE_STRUCT_ANON Record; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``[STRUCT_ANON, ispacked, ...eltty...]``. The ``STRUCT_ANON`` record (code 18) adds a literal struct type to the type; table. The operand fields are. * *ispacked*: Non-zero if the type represents a packed structure. * *eltty*: Zero or more type indices representing the element types of the; structure. TYPE_CODE_STRUCT_NAME Record; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``[STRUCT_NAME, ...string...]``. The ``STRUCT_NAME`` record (code 19) contains a variable number of values; representing the bytes of a struct name. The next ``OPAQUE`` or; ``STRUCT_NAMED`` record will use this name. TYPE_CODE_STRUCT_NAMED Record; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``[STRUCT_NAMED, ispacked, ...eltty...]``. The ``STRUCT_NAMED`` record (code 20) adds an identified struct type to the; type table, with a name defined by a previously encountered ``STRUCT_NAME``; record. The operand fields are. * *ispacked*: Non-zero if the type represents a packed structure. * *eltty*: Zero or more type indices representing the element types of the; structure. TYPE_CODE_FUNCTION Record; ^^^^^^^^^^^^^^^^^^^^^^^^^. ``[FUNCTION, vararg, retty, ...paramty... ]``. The ``FUNCTION`` record (code 21) adds a function type to the type table. The; operand fields are. * *vararg*: Non-zero if the type represents a varargs function. * *retty*: The type index of the function's return type. * *paramty*: Zero or more type indices representing the parameter types of the; function. TYPE_CODE_X86_AMX ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:46206,variab,variable,46206,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,1,['variab'],['variable']
Modifiability,"the value. CMake refers to; this as ""variable evaluation"" in their documentation. Dereferences are performed; *before* the command being called receives the arguments. This means; dereferencing a list results in multiple separate arguments being passed to the; command. Variable dereferences can be nested and be used to model complex data. For; example:. .. code-block:: cmake. set(var_name var1); set(${var_name} foo) # same as ""set(var1 foo)""; set(${${var_name}}_var bar) # same as ""set(foo_var bar)"". Dereferencing an unset variable results in an empty expansion. It is a common; pattern in CMake to conditionally set variables knowing that it will be used in; code paths that the variable isn't set. There are examples of this throughout; the LLVM CMake build system. An example of variable empty expansion is:. .. code-block:: cmake. if(APPLE); set(extra_sources Apple.cpp); endif(); add_executable(HelloWorld HelloWorld.cpp ${extra_sources}). In this example the ``extra_sources`` variable is only defined if you're; targeting an Apple platform. For all other targets the ``extra_sources`` will be; evaluated as empty before add_executable is given its arguments. Lists; -----. In CMake lists are semi-colon delimited strings, and it is strongly advised that; you avoid using semi-colons in lists; it doesn't go smoothly. A few examples of; defining lists:. .. code-block:: cmake. # Creates a list with members a, b, c, and d; set(my_list a b c d); set(my_list ""a;b;c;d""). # Creates a string ""a b c d""; set(my_string ""a b c d""). Lists of Lists; --------------. One of the more complicated patterns in CMake is lists of lists. Because a list; cannot contain an element with a semi-colon to construct a list of lists you; make a list of variable names that refer to other lists. For example:. .. code-block:: cmake. set(list_of_lists a b c); set(a 1 2 3); set(b 4 5 6); set(c 7 8 9). With this layout you can iterate through the list of lists printing each value; with the following code:. .. cod",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:4042,variab,variable,4042,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst,1,['variab'],['variable']
Modifiability,"the; VecGeom main library and loaded using the ROOT plug-in mechanism. The main functionality provided by the new vecgeom module is to make a conversion ; in memory of all the shapes in a loaded TGeo geometry into a special adapter; shape TGeoVGShape, redirecting all navigation calls to the corresponding VecGeom ; solid. The library loading and geometry conversion can be done with a single call ; `TVirtualGeoConverter::Instance()->ConvertGeometry()`; . After the conversion is done, all existing TGeo functionality is available as for; a native geometry, only that most of the converted solids provide better navigation ; performance, despite the overhead introduced by the new adapter shape. Prerequisites: installation of VecGeom. ; The installation instructions are available at <http://geant.web.cern.ch/content/installation>; Due to the fact that VecGeom provides for the moment static libraries ; and depends on ROOT, is is advised to compile first ROOT without VecGeom support, ; then compile VecGeom against this ROOT version, then re-configure ROOT to enable ; VecGeom and Vc support, using the flags -Dvc=ON -Dvecgeom=on; ; This has been implemented by Mihaela Gheata <Mihaela.Gheata@cern.ch>. ## Database Libraries. * Fix `TPgSQLStatement::SetBinary` to actually handle binary data (previous limited to ascii). ## Networking Libraries. * When seeing too many requested ranges, Apache 2.4 now simply sends the whole file; (MaxRanges configuration parameter). TWebFile can handle this case now, but this can; trigger multiple transmissions of the full file. TWebFile warns when Apache reacts by; sending the full file. ## GUI Libraries. * A new `Browser.ExpandDirectories` option (the default is `yes`) has been added, allowing to prevent expanding the parent directory tree in the ROOT Browser (for example on nfs). ## Language Bindings. ### PyROOT. * Added a new configuration option to disable processing of the rootlogon[.py|C] macro in addition; ro the -n option in the command argu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:24415,config,configure,24415,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['config'],['configure']
Modifiability,"the; application. Backward compatibility is NOT guaranteed. Please; contact the authors if you require the reading of old text weight; files in TMVA 4.; ; ; Standard macros:; ; The structure of the standard macros has changed: macros are; still in the ""$ROOTSYS/tmva/test"" directory, but distinguished for; classification and regression examples:; ; TMVAClassification.C, TMVAClassificationApplication.C TMVARegression.C, TMVARegressionApplication.C; ; Classification and regression analysis (training) is analysed as; usual via standard macros that can be called from dedicated; GUIs.; ; ; Regression:. Not yet available for all MVA methods. It exists for:; PDE-RS, PDE-Foam, K-NN, LD, FDA, MLP, BDT for single targets; (1D), and MLP for multiple targets (nD).; ; Not all transformation of input variables are available; (only ""Norm"" so far). Regression requires specific evaluation tools:. ; During the training we provide a ranking of input; variables, using various criteria: correlations, transposed; correlation, correlation ratio, and ""mutual information"" between; input variables and regression target. (Correlation ratio and; mutual information implmentations provided by Moritz Backes,; Geneva U); ; After the training, the trained MVA methods are ranked wrt.; the deviations between regression target and estimate.; ; Macros plot various deviation and correlation quantities.; A new GUI (macros/TMVARegGui.C) collects these macros.; . Improvements of / new features for MVA methods . Linear Discriminant:; Re-implementation of ""Fisher"" method as general linear discriminant (""LD""),; which is also regression capable (so far: single-target only). PDEFoam:; PDE-Foam is a variation of the PDE-RS method using a self-adapting binning; method to divide the multi-dimensional variable space into a finite number; of hyper-rectangles (cells). The binning algorithm adjusts the size and; position of a predefined number of cells such that the variance of the; signal and background densities insid",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:1655,variab,variables,1655,tmva/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html,2,['variab'],['variables']
Modifiability,"the; argument with name ``a`` and ``a1`` will be assigned to the argument with; name ``b``. Required arguments can also be specified as named argument. Note that the argument can only be specified once regardless of the way (named; or positional) to specify and positional arguments should be put before named; arguments. .. productionlist::; Body: "";"" | ""{"" `BodyItem`* ""}""; BodyItem: (`Type` | ""code"") `TokIdentifier` [""="" `Value`] "";""; :| ""let"" `TokIdentifier` [""{"" `RangeList` ""}""] ""="" `Value` "";""; :| ""defvar"" `TokIdentifier` ""="" `Value` "";""; :| `Assert`. A field definition in the body specifies a field to be included in the class; or record. If no initial value is specified, then the field's value is; uninitialized. The type must be specified; TableGen will not infer it from; the value. The keyword ``code`` may be used to emphasize that the field; has a string value that is code. The ``let`` form is used to reset a field to a new value. This can be done; for fields defined directly in the body or fields inherited from parent; classes. A :token:`RangeList` can be specified to reset certain bits in a; ``bit<n>`` field. The ``defvar`` form defines a variable whose value can be used in other; value expressions within the body. The variable is not a field: it does not; become a field of the class or record being defined. Variables are provided; to hold temporary values while processing the body. See `Defvar in a Record; Body`_ for more details. When class ``C2`` inherits from class ``C1``, it acquires all the field; definitions of ``C1``. As those definitions are merged into class ``C2``, any; template arguments passed to ``C1`` by ``C2`` are substituted into the; definitions. In other words, the abstract record fields defined by ``C1`` are; expanded with the template arguments before being merged into ``C2``. .. _def:. ``def`` --- define a concrete record; ------------------------------------. A ``def`` statement defines a new concrete record. .. productionlist::; Def: ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:26583,inherit,inherited,26583,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['inherit'],['inherited']
Modifiability,"the; old and new rules and which projects each applies to. #. Refactor the starter project in two commits:. 1. Add or change the project's .clang-tidy to reflect the agreed rules.; (This is in a separate commit to enable the merging process described in; `Minimising cost of downstream merges`_).; Also update the project list on the policy page.; 2. Apply ``clang-tidy`` to the project's files, with only the; ``readability-identifier-naming`` rules enabled. ``clang-tidy`` will also; reformat the affected lines according to the rules in ``.clang-format``.; It is anticipated that this will be a good dog-fooding opportunity for; clang-tidy, and bugs should be fixed in the process, likely including:. * `readability-identifier-naming incorrectly fixes lambda capture; <https://bugs.llvm.org/show_bug.cgi?id=41119>`_.; * `readability-identifier-naming incorrectly fixes variables which; become keywords <https://bugs.llvm.org/show_bug.cgi?id=41120>`_.; * `readability-identifier-naming misses fixing member variables in; destructor <https://bugs.llvm.org/show_bug.cgi?id=41122>`_. #. Gather feedback and refine the process as appropriate. #. Apply the process to the following projects, with a suitable delay between; each (at least 4 weeks after the first change, at least 2 weeks subsequently); to allow gathering further feedback.; This list should exclude projects that must adhere to an externally defined; standard e.g. libcxx.; The list is roughly in chronological order of renaming.; Some items may not make sense to rename individually - it is expected that; this list will change following experimentation:. * TableGen; * llvm/tools; * clang-tools-extra; * clang; * ARM backend; * AArch64 backend; * AMDGPU backend; * ARC backend; * AVR backend; * BPF backend; * Hexagon backend; * Lanai backend; * MIPS backend; * NVPTX backend; * PowerPC backend; * RISC-V backend; * Sparc backend; * SystemZ backend; * WebAssembly backend; * X86 backend; * XCore backend; * libLTO; * Debug Information; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst:12055,variab,variables,12055,interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst,1,['variab'],['variables']
Modifiability,"the; typedef information in the program. If the type of the expression is literally; a ``PointerType``, we can return that, otherwise we have to dig through the; typedefs to find the pointer type. For example, if the subexpression had type; ""``foo*``"", we could return that type as the result. If the subexpression had; type ""``bar``"", we want to return ""``foo*``"" (note that we do *not* want; ""``int*``""). In order to provide all of this, ``Type`` has a; ``getAsPointerType()`` method that checks whether the type is structurally a; ``PointerType`` and, if so, returns the best one. If not, it returns a null; pointer. This structure is somewhat mystical, but after meditating on it, it will make; sense to you :). .. _QualType:. The ``QualType`` class; ----------------------. The ``QualType`` class is designed as a trivial value class that is small,; passed by-value and is efficient to query. The idea of ``QualType`` is that it; stores the type qualifiers (``const``, ``volatile``, ``restrict``, plus some; extended qualifiers required by language extensions) separately from the types; themselves. ``QualType`` is conceptually a pair of ""``Type*``"" and the bits; for these type qualifiers. By storing the type qualifiers as bits in the conceptual pair, it is extremely; efficient to get the set of qualifiers on a ``QualType`` (just return the field; of the pair), add a type qualifier (which is a trivial constant-time operation; that sets a bit), and remove one or more type qualifiers (just return a; ``QualType`` with the bitfield set to empty). Further, because the bits are stored outside of the type itself, we do not need; to create duplicates of types with different sets of qualifiers (i.e. there is; only a single heap allocated ""``int``"" type: ""``const int``"" and ""``volatile; const int``"" both point to the same heap allocated ""``int``"" type). This; reduces the heap size used to represent bits and also means we do not have to; consider qualifiers when uniquing types (:ref:`Type ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:66745,extend,extended,66745,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['extend'],['extended']
Modifiability,"them. The variable's type is used by CMake's UI tool to display; the right input field. A variable's type generally doesn't impact evaluation,; however CMake does have special handling for some variables such as PATH.; You can read more about the special handling in `CMake's set documentation; <https://cmake.org/cmake/help/v3.5/command/set.html#set-cache-entry>`_. Scope; -----. CMake inherently has a directory-based scoping. Setting a variable in a; CMakeLists file, will set the variable for that file, and all subdirectories.; Variables set in a CMake module that is included in a CMakeLists file will be; set in the scope they are included from, and all subdirectories. When a variable that is already set is set again in a subdirectory it overrides; the value in that scope and any deeper subdirectories. The CMake set command provides two scope-related options. PARENT_SCOPE sets a; variable into the parent scope, and not the current scope. The CACHE option sets; the variable in the CMakeCache, which results in it being set in all scopes. The; CACHE option will not set a variable that already exists in the CACHE unless the; FORCE option is specified. In addition to directory-based scope, CMake functions also have their own scope.; This means variables set inside functions do not bleed into the parent scope.; This is not true of macros, and it is for this reason LLVM prefers functions; over macros whenever reasonable. .. note::; Unlike C-based languages, CMake's loop and control flow blocks do not have; their own scopes. Control Flow; ============. CMake features the same basic control flow constructs you would expect in any; scripting language, but there are a few quirks because, as with everything in; CMake, control flow constructs are commands. If, ElseIf, Else; ----------------. .. note::; For the full documentation on the CMake if command go; `here <https://cmake.org/cmake/help/v3.4/command/if.html>`_. That resource is; far more complete. In general CMake if blocks ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:6781,variab,variable,6781,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst,1,['variab'],['variable']
Modifiability,"then run the instrumented compiler against the; perf training data:. .. code-block:: console. $ ninja stage2-instrumented-generate-profdata. If you let that run for a few hours or so, it will place a profdata file in your; build directory. This takes a really long time because it builds clang twice,; and you *must* have compiler-rt in your build tree. This process uses any source files under the perf-training directory as training; data as long as the source files are marked up with LIT-style RUN lines. After it finishes you can use :code:`find . -name clang.profdata` to find it, but it; should be at a path something like:. .. code-block:: console. <build dir>/tools/clang/stage2-instrumented-bins/utils/perf-training/clang.profdata. You can feed that file into the LLVM_PROFDATA_FILE option when you build your; optimized compiler. It may be necessary to build additional targets before running perf training, such as; builtins and runtime libraries. You can use the :code:`CLANG_PGO_TRAINING_DEPS` CMake; variable for that purpose:. .. code-block:: cmake. set(CLANG_PGO_TRAINING_DEPS builtins runtimes CACHE STRING """"). The PGO cache has a slightly different stage naming scheme than other; multi-stage builds. It generates three stages: stage1, stage2-instrumented, and; stage2. Both of the stage2 builds are built using the stage1 compiler. The PGO cache generates the following additional targets:. **stage2-instrumented**; Builds a stage1 compiler, runtime, and required tools (llvm-config,; llvm-profdata) then uses that compiler to build an instrumented stage2 compiler. **stage2-instrumented-generate-profdata**; Depends on stage2-instrumented and will use the instrumented compiler to; generate profdata based on the training files in clang/utils/perf-training. **stage2**; Depends on stage2-instrumented-generate-profdata and will use the stage1; compiler with the stage2 profdata to build a PGO-optimized compiler. **stage2-check-llvm**; Depends on stage2 and runs check-llvm using",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst:8504,variab,variable,8504,interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AdvancedBuilds.rst,1,['variab'],['variable']
Modifiability,"then we check the structural equivalency on those nodes.; The following pseudo-code demonstrates the basics of the import mechanism:. .. code-block:: cpp. // Pseudo-code(!) of import:; ErrorOrDecl Import(Decl *FromD) {; Decl *ToDecl = nullptr;; FoundDeclsList = Look up all Decls in the ""to"" Ctx with the same name of FromD;; for (auto FoundDecl : FoundDeclsList) {; if (StructurallyEquivalentDecls(FoundDecl, FromD)) {; ToDecl = FoundDecl;; Mark FromD as imported;; break;; } else {; Report ODR violation;; return error;; }; }; if (FoundDeclsList is empty) {; Import dependent declarations and types of ToDecl;; ToDecl = create a new AST node in ""to"" Ctx;; Mark FromD as imported;; }; return ToDecl;; }. Two AST nodes are *structurally equivalent* if they are. - builtin types and refer to the same type, e.g. ``int`` and ``int`` are structurally equivalent,; - function types and all their parameters have structurally equivalent types,; - record types and all their fields in order of their definition have the same identifier names and structurally equivalent types,; - variable or function declarations and they have the same identifier name and their types are structurally equivalent. We could extend the definition of structural equivalency to templates similarly. If A and B are AST nodes and *A depends on B*, then we say that A is a **dependant** of B and B is a **dependency** of A.; The words ""dependant"" and ""dependency"" are nouns in British English.; Unfortunately, in American English, the adjective ""dependent"" is used for both meanings.; In this document, with the ""dependent"" adjective we always address the dependencies, the B node in the example. API; ---. Let's create a tool which uses the ASTImporter class!; First, we build two ASTs from virtual files; the content of the virtual files are synthesized from string literals:. .. code-block:: cpp. std::unique_ptr<ASTUnit> ToUnit = buildASTFromCode(; """", ""to.cc""); // empty file; std::unique_ptr<ASTUnit> FromUnit = buildASTFrom",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTImporter.rst:4011,variab,variable,4011,interpreter/llvm-project/clang/docs/LibASTImporter.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTImporter.rst,1,['variab'],['variable']
Modifiability,"ther useful argument form is a named alternative style. We shall use this; style in our compiler to specify different debug levels that can be used.; Instead of each debug level being its own switch, we want to support the; following options, of which only one can be specified at a time:; ""``--debug-level=none``"", ""``--debug-level=quick``"",; ""``--debug-level=detailed``"". To do this, we use the exact same format as our; optimization level flags, but we also specify an option name. For this case,; the code looks like this:. .. code-block:: c++. enum DebugLev {; nodebuginfo, quick, detailed; };. // Enable Debug Options to be specified on the command line; cl::opt<DebugLev> DebugLevel(""debug_level"", cl::desc(""Set the debugging level:""),; cl::values(; clEnumValN(nodebuginfo, ""none"", ""disable debug information""),; clEnumVal(quick, ""enable quick debug information""),; clEnumVal(detailed, ""enable detailed debug information"")));. This definition defines an enumerated command line variable of type ""``enum; DebugLev``"", which works exactly the same way as before. The difference here is; just the interface exposed to the user of your program and the help output by; the ""``-help``"" option:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -debug_level - Set the debugging level:; =none - disable debug information; =quick - enable quick debug information; =detailed - enable detailed debug information; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. Again, the only structural difference between the debug level declaration and; the optimization level declaration is that the debug level declaration includes; an option name (``""debug_level""``), which automatically change",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:17881,variab,variable,17881,interpreter/llvm-project/llvm/docs/CommandLine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst,1,['variab'],['variable']
Modifiability,ther we're able to guarantee that an argument is safe or it's considered if not a bug then bug-prone. .. code-block:: cpp. RefCountable* provide_uncounted();; void consume(RefCountable*);. // In these cases we can't make sure callee won't directly or indirectly call `deref()` on the argument which could make it unsafe from such point until the end of the call. void foo1() {; consume(provide_uncounted()); // warn; }. void foo2() {; RefCountable* uncounted = provide_uncounted();; consume(uncounted); // warn; }. Although we are enforcing member variables to be ref-counted by `webkit.NoUncountedMemberChecker` any method of the same class still has unrestricted access to these. Since from a caller's perspective we can't guarantee a particular member won't get modified by callee (directly or indirectly) we don't consider values obtained from members safe. Note: It's likely this heuristic could be made more precise with fewer false positives - for example calls to free functions that don't have any parameter other than the pointer should be safe as the callee won't be able to tamper with the member unless it's a global variable. .. code-block:: cpp. struct Foo {; RefPtr<RefCountable> member;; void consume(RefCountable*) { /* ... */ }; void bugprone() {; consume(member.get()); // warn; }; };. The implementation of this rule is a heuristic - we define a whitelist of kinds of values that are considered safe to be passed as arguments. If we can't prove an argument is safe it's considered an error. Allowed kinds of arguments:. - values obtained from ref-counted objects (including temporaries as those survive the call too). .. code-block:: cpp. RefCountable* provide_uncounted();; void consume(RefCountable*);. void foo() {; RefPtr<RefCountable> rc = makeRef(provide_uncounted());; consume(rc.get()); // ok; consume(makeRef(provide_uncounted()).get()); // ok; }. - forwarding uncounted arguments from caller to callee. .. code-block:: cpp. void foo(RefCountable& a) {; bar(a); // ok; },MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:82589,variab,variable,82589,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['variab'],['variable']
Modifiability,"ther without knowing about each other, as long as there is someone around to set up a connection between them. ## Features of the ROOT implementation. * The ROOT implementation **does not require the** *moc* preprocessor and the `signal:` and `slot:` keywords in the class declaration. Signals and slots are normal class methods. * The class which corresponds to **Qt's** **QObject** is [TQObject](https://root.cern/doc/master/classTQObject.html). It reproduces the general features of the QObject class and has the `Connect()`, `Disconnect()` and `Emit()` methods. The [TQObject](https://root.cern/doc/master/classTQObject.html) class does not derive from any class which makes it possible to have multiple inheritance from [TObject](https://root.cern/doc/master/classTQObject.html) derived classes and [TQObject](https://root.cern/doc/master/classTQObject.html). * By placing the [`RQ_OBJECT()`](https://root.cern/doc/master/RQ__OBJECT_8h.html) macro inside a class body you can use signals and slots with classes not inheriting from [TQObject](https://root.cern/doc/master/classTQObject.html), like interpreted classes which can not derive from compiled classes. This makes it possible to apply the **Object Communication Mechanism** between compiled and interpreted classes in an interactive ROOT session. * The ROOT implementation allows to make connections to any object known to the ROOT C++ interpreter. The following line makes a connection between signal `Pressed()` from `button` and method/slot `Draw()` from object `hist` of class (compiled or interpreted) `TH1`. ``` {.cpp}; Connect(button, ""Pressed()"", ""TH1"", hist, ""Draw()"");; ```. To connect to a stand-alone function (compiled or interpreted) the arguments corresponding to the name of the class and receiving object should be zero. For example. ``` {.cpp}; Connect(button, ""Pressed()"", 0, 0, ""printInfo()"");; ```. * It is also possible to make a single connection from all objects of the same class. For example:. ``` {.cpp}; TQObje",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/SignalSlot.md:4363,inherit,inheriting,4363,documentation/users-guide/SignalSlot.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/SignalSlot.md,1,['inherit'],['inheriting']
Modifiability,"therwise; the meaning is purely conventional unless the property is synthesized. If a; property is synthesized, then the :arc-term:`associated instance variable` is; the instance variable which is named, possibly implicitly, by the; ``@synthesize`` declaration. If the associated instance variable already; exists, then its ownership qualification must equal the ownership of the; property; otherwise, the instance variable is created with that ownership; qualification. A property of retainable object pointer type which is synthesized without a; source of ownership has the ownership of its associated instance variable, if it; already exists; otherwise, :when-revised:`[beginning Apple 3.1, LLVM 3.1]`; :revision:`its ownership is implicitly` ``strong``. Prior to this revision, it; was ill-formed to synthesize such a property. .. admonition:: Rationale. Using ``strong`` by default is safe and consistent with the generic ARC rule; about :ref:`inferring ownership <arc.ownership.inference.variables>`. It is,; unfortunately, inconsistent with the non-ARC rule which states that such; properties are implicitly ``assign``. However, that rule is clearly; untenable in ARC, since it leads to default-unsafe code. The main merit to; banning the properties is to avoid confusion with non-ARC practice, which did; not ultimately strike us as sufficient to justify requiring extra syntax and; (more importantly) forcing novices to understand ownership rules just to; declare a property when the default is so reasonable. Changing the rule away; from non-ARC practice was acceptable because we had conservatively banned the; synthesis in order to give ourselves exactly this leeway. Applying ``__attribute__((NSObject))`` to a property not of retainable object; pointer type has the same behavior it does outside of ARC: it requires the; property type to be some sort of pointer and permits the use of modifiers other; than ``assign``. These modifiers only affect the synthesized getter and; setter; dir",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:36176,variab,variables,36176,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['variab'],['variables']
Modifiability,"these parts in detail. Link Box; On the top of the page you can find a list of links. The first line contains the current; ""location"", giving the home page, the module name, and the class name.; The second line links to generic pages, like ROOT's home page, the; Class Index, and the Class Hierarchy.; The last line allows you to jump to the sections of the current page and a colored; version of the class's header and source file. Info Box; There is a little info box, usually floating on the right side of the page; (update your browser if it's not). It shows the name of the class you are currently; looking at, which library you have to link against to get access to the class, and; which header file you have to #include. It also contains options that influence how; the list of members is displayed. you can show or hide non-public methods. If you; just want to use ROOT you should hide them - you cannot access protected or private; members anyway. And you can select whether member that are inherited from a base class; should be shown. Again, if you just want to use ROOT you should probably show them,; as you often want to use them whether they are defined in the current class or in one; of its base classes. Whatever you set these options to should be stored in a cookie,; so you will have the same setting next time you look at the class documentation. The two links in the bottom of the box get you to the top of the page and to this help; page. You can hide the info box by clicking on the little ""-"" in the top right corner; of the box, and show it again by clicking on the ""+"". List of Data and Function Members; The central part of a class are its members. Some are available to you; some; are hidden from you, because they are only meant to be used internally.; As an example, a class might allow you to set, access, and print its values, or store; them into a file.; Because methods should have reasonable names, often the method name itself is already; a hint on what it does.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/etc/html/HELP.html:4069,inherit,inherited,4069,etc/html/HELP.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/etc/html/HELP.html,1,['inherit'],['inherited']
Modifiability,"they can; do:. Required Variables; ------------------. ``LEVEL``. This variable is the relative path from this ``Makefile`` to the top; directory of your project's source code. For example, if your source code; is in ``/tmp/src``, then the ``Makefile`` in ``/tmp/src/jump/high``; would set ``LEVEL`` to ``""../..""``. Variables for Building Subdirectories; -------------------------------------. ``DIRS``. This is a space separated list of subdirectories that should be built. They; will be built, one at a time, in the order specified. ``PARALLEL_DIRS``. This is a list of directories that can be built in parallel. These will be; built after the directories in DIRS have been built. ``OPTIONAL_DIRS``. This is a list of directories that can be built if they exist, but will not; cause an error if they do not exist. They are built serially in the order; in which they are listed. Variables for Building Libraries; --------------------------------. ``LIBRARYNAME``. This variable contains the base name of the library that will be built. For; example, to build a library named ``libsample.a``, ``LIBRARYNAME`` should; be set to ``sample``. ``BUILD_ARCHIVE``. By default, a library is a ``.o`` file that is linked directly into a; program. To build an archive (also known as a static library), set the; ``BUILD_ARCHIVE`` variable. ``SHARED_LIBRARY``. If ``SHARED_LIBRARY`` is defined in your Makefile, a shared (or dynamic); library will be built. Variables for Building Programs; -------------------------------. ``TOOLNAME``. This variable contains the name of the program that will be built. For; example, to build an executable named ``sample``, ``TOOLNAME`` should be set; to ``sample``. ``USEDLIBS``. This variable holds a space separated list of libraries that should be; linked into the program. These libraries must be libraries that come from; your **lib** directory. The libraries must be specified without their; ``lib`` prefix. For example, to link ``libsample.a``, you would set; ``USEDLI",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Projects.rst:5336,variab,variable,5336,interpreter/llvm-project/llvm/docs/Projects.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Projects.rst,1,['variab'],['variable']
Modifiability,"thing needed is the; ability to process a text file and recognize what it says. The; traditional way to do this is to use a; ""`lexer <http://en.wikipedia.org/wiki/Lexical_analysis>`_"" (aka; 'scanner') to break the input up into ""tokens"". Each token returned by; the lexer includes a token code and potentially some metadata (e.g. the; numeric value of a number). First, we define the possibilities:. .. code-block:: c++. // The lexer returns tokens [0-255] if it is an unknown character, otherwise one; // of these for known things.; enum Token {; tok_eof = -1,. // commands; tok_def = -2,; tok_extern = -3,. // primary; tok_identifier = -4,; tok_number = -5,; };. static std::string IdentifierStr; // Filled in if tok_identifier; static double NumVal; // Filled in if tok_number. Each token returned by our lexer will either be one of the Token enum; values or it will be an 'unknown' character like '+', which is returned; as its ASCII value. If the current token is an identifier, the; ``IdentifierStr`` global variable holds the name of the identifier. If; the current token is a numeric literal (like 1.0), ``NumVal`` holds its; value. We use global variables for simplicity, but this is not the; best choice for a real language implementation :). The actual implementation of the lexer is a single function named; ``gettok``. The ``gettok`` function is called to return the next token; from standard input. Its definition starts as:. .. code-block:: c++. /// gettok - Return the next token from standard input.; static int gettok() {; static int LastChar = ' ';. // Skip any whitespace.; while (isspace(LastChar)); LastChar = getchar();. ``gettok`` works by calling the C ``getchar()`` function to read; characters one at a time from standard input. It eats them as it; recognizes them and stores the last character read, but not processed,; in LastChar. The first thing that it has to do is ignore whitespace; between tokens. This is accomplished with the loop above. The next thing ``gettok``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl01.rst:3008,variab,variable,3008,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl01.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl01.rst,1,['variab'],['variable']
Modifiability,"thinks that a pointer can be null is because the preceding code checked compared it against null. So if you are absolutely sure that it cannot be null, remove the preceding check and, preferably, add an assertion as well. For example, in the code segment above, it will be sufficient to remove the if (!b) check. . void usePointer(int *b);; int foo(int *b) {; usePointer(b);; return *b;; }; Q: How do I tell the static analyzer that I don't care about a specific dead store?; When the analyzer sees that a value stored into a variable is never used, it's going to produce a message similar to this one:; Value stored to 'x' is never read; You can use the (void)x; idiom to acknowledge that there is a dead store in your code but you do not want it to be reported in the future.; Q: How do I tell the static analyzer that I don't care about a specific unused instance variable in Objective C?; When the analyzer sees that a value stored into a variable is never used, it is going to produce a message similar to this one:; Instance variable 'commonName' in class 'HappyBird' is never used by the methods in its @implementation; You can add __attribute__((unused)) to the instance variable declaration to suppress the warning.; Q: How do I tell the static analyzer that I don't care about a specific unlocalized string?; When the analyzer sees that an unlocalized string is passed to a method that will present that string to the user, it is going to produce a message similar to this one:; User-facing text should use localized string macro. If your project deliberately uses unlocalized user-facing strings (for example, in a debugging UI that is never shown to users), you can suppress the analyzer warnings (and document your intent) with a function that just returns its input but is annotated to return a localized string:. __attribute__((annotate(""returns_localized_nsstring""))); static inline NSString *LocalizationNotNeeded(NSString *s) {; return s;; }. You can then call this function when cre",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/faq.html:2710,variab,variable,2710,interpreter/llvm-project/clang/www/analyzer/faq.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/faq.html,4,['variab'],['variable']
Modifiability,"this ""C"" example, the front end compiler (Clang) will generate three GEP; instructions for the three indices through ""P"" in the assignment statement. The; function argument ``P`` will be the second operand of each of these GEP; instructions. The third operand indexes through that pointer. The fourth; operand will be the field offset into the ``struct munger_struct`` type, for; either the ``f1`` or ``f2`` field. So, in LLVM assembly the ``munge`` function; looks like:. .. code-block:: llvm. define void @munge(ptr %P) {; entry:; %tmp = getelementptr %struct.munger_struct, ptr %P, i32 1, i32 0; %tmp1 = load i32, ptr %tmp; %tmp2 = getelementptr %struct.munger_struct, ptr %P, i32 2, i32 1; %tmp3 = load i32, ptr %tmp2; %tmp4 = add i32 %tmp3, %tmp1; %tmp5 = getelementptr %struct.munger_struct, ptr %P, i32 0, i32 0; store i32 %tmp4, ptr %tmp5; ret void; }. In each case the second operand is the pointer through which the GEP instruction; starts. The same is true whether the second operand is an argument, allocated; memory, or a global variable. To make this clear, let's consider a more obtuse example:. .. code-block:: text. @MyVar = external global i32; ...; %idx1 = getelementptr i32, ptr @MyVar, i64 0; %idx2 = getelementptr i32, ptr @MyVar, i64 1; %idx3 = getelementptr i32, ptr @MyVar, i64 2. These GEP instructions are simply making address computations from the base; address of ``MyVar``. They compute, as follows (using C syntax):. .. code-block:: c++. idx1 = (char*) &MyVar + 0; idx2 = (char*) &MyVar + 4; idx3 = (char*) &MyVar + 8. Since the type ``i32`` is known to be four bytes long, the indices 0, 1 and 2; translate into memory offsets of 0, 4, and 8, respectively. No memory is; accessed to make these computations because the address of ``@MyVar`` is passed; directly to the GEP instructions. The obtuse part of this example is in the cases of ``%idx2`` and ``%idx3``. They; result in the computation of addresses that point to memory past the end of the; ``@MyVar`` global, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:3683,variab,variable,3683,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['variab'],['variable']
Modifiability,"this flag is unnecessary if a HIP input file is already present in your program. For convenience, Clang also supports compiling and linking in a single step:. .. code-block:: shell. clang++ --offload-arch=gfx906 -xhip sample.cpp -o sample. In the above commands, ``gfx906`` is the GPU architecture that the code is being compiled for. The supported GPU; architectures can be found in the `AMDGPU Processor Table <https://llvm.org/docs/AMDGPUUsage.html#processors>`_.; Alternatively, you can use the ``amdgpu-arch`` tool that comes with Clang to list the GPU architecture on your system:. .. code-block:: shell. amdgpu-arch. You can use ``--offload-arch=native`` to automatically detect the GPU architectures on your system:. .. code-block:: shell. clang++ --offload-arch=native -xhip sample.cpp -o sample. Path Setting for Dependencies; =============================. Compiling a HIP program depends on the HIP runtime and device library. The paths to the HIP runtime and device libraries; can be specified either using compiler options or environment variables. The paths can also be set through the ROCm path; if they follow the ROCm installation directory structure. Order of Precedence for HIP Path; --------------------------------. 1. ``--hip-path`` compiler option; 2. ``HIP_PATH`` environment variable *(use with caution)*; 3. ``--rocm-path`` compiler option; 4. ``ROCM_PATH`` environment variable *(use with caution)*; 5. Default automatic detection (relative to Clang or at the default ROCm installation location). Order of Precedence for Device Library Path; -------------------------------------------. 1. ``--hip-device-lib-path`` compiler option; 2. ``HIP_DEVICE_LIB_PATH`` environment variable *(use with caution)*; 3. ``--rocm-path`` compiler option; 4. ``ROCM_PATH`` environment variable *(use with caution)*; 5. Default automatic detection (relative to Clang or at the default ROCm installation location). .. list-table::; :header-rows: 1. * - Compiler Option; - Environment Variabl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HIPSupport.rst:3820,variab,variables,3820,interpreter/llvm-project/clang/docs/HIPSupport.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HIPSupport.rst,1,['variab'],['variables']
Modifiability,"this in place, the first functionality change we want to make belongs to; variable references. In our new scheme, variables live on the stack, so; code generating a reference to them actually needs to produce a load; from the stack slot:. .. code-block:: c++. Value *VariableExprAST::codegen() {; // Look this variable up in the function.; AllocaInst *A = NamedValues[Name];; if (!A); return LogErrorV(""Unknown variable name"");. // Load the value.; return Builder->CreateLoad(A->getAllocatedType(), A, Name.c_str());; }. As you can see, this is pretty straightforward. Now we need to update; the things that define the variables to set up the alloca. We'll start; with ``ForExprAST::codegen()`` (see the `full code listing <#id1>`_ for; the unabridged code):. .. code-block:: c++. Function *TheFunction = Builder->GetInsertBlock()->getParent();. // Create an alloca for the variable in the entry block.; AllocaInst *Alloca = CreateEntryBlockAlloca(TheFunction, VarName);. // Emit the start code first, without 'variable' in scope.; Value *StartVal = Start->codegen();; if (!StartVal); return nullptr;. // Store the value into the alloca.; Builder->CreateStore(StartVal, Alloca);; ... // Compute the end condition.; Value *EndCond = End->codegen();; if (!EndCond); return nullptr;. // Reload, increment, and restore the alloca. This handles the case where; // the body of the loop mutates the variable.; Value *CurVar = Builder->CreateLoad(Alloca->getAllocatedType(), Alloca,; VarName.c_str());; Value *NextVar = Builder->CreateFAdd(CurVar, StepVal, ""nextvar"");; Builder->CreateStore(NextVar, Alloca);; ... This code is virtually identical to the code `before we allowed mutable; variables <LangImpl05.html#code-generation-for-the-for-loop>`_. The big difference is that we; no longer have to construct a PHI node, and we use load/store to access; the variable as needed. To support mutable argument variables, we need to also make allocas for; them. The code for this is also pretty simple:. .. code-b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:14643,variab,variable,14643,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['variab'],['variable']
Modifiability,"this is exceptionally abstruse. These examples are a; best-effort attempt. * A template argument of a ``class``, such as the use of ``Bar`` in::. class Foo <int Bar> {; int Baz = Bar;; }. * The implicit template argument ``NAME`` in a ``class`` or ``multiclass``; definition (see `NAME`_). * A field local to a ``class``, such as the use of ``Bar`` in::. class Foo {; int Bar = 5;; int Baz = Bar;; }. * The name of a record definition, such as the use of ``Bar`` in the; definition of ``Foo``::. def Bar : SomeClass {; int X = 5;; }. def Foo {; SomeClass Baz = Bar;; }. * A field local to a record definition, such as the use of ``Bar`` in::. def Foo {; int Bar = 5;; int Baz = Bar;; }. Fields inherited from the record's parent classes can be accessed the same way. * A template argument of a ``multiclass``, such as the use of ``Bar`` in::. multiclass Foo <int Bar> {; def : SomeClass<Bar>;; }. * A variable defined with the ``defvar`` or ``defset`` statements. * The iteration variable of a ``foreach``, such as the use of ``i`` in::. foreach i = 0...5 in; def Foo#i;. .. productionlist::; SimpleValue8: `ClassID` ""<"" `ArgValueList` "">"". This form creates a new anonymous record definition (as would be created by an; unnamed ``def`` inheriting from the given class with the given template; arguments; see `def`_) and the value is that record. A field of the record can be; obtained using a suffix; see `Suffixed Values`_. Invoking a class in this manner can provide a simple subroutine facility.; See `Using Classes as Subroutines`_ for more information. .. productionlist::; SimpleValue9: `BangOperator` [""<"" `Type` "">""] ""("" `ValueListNE` "")""; :| `CondOperator` ""("" `CondClause` ("","" `CondClause`)* "")""; CondClause: `Value` "":"" `Value`. The bang operators provide functions that are not available with the other; simple values. Except in the case of ``!cond``, a bang operator takes a list; of arguments enclosed in parentheses and performs some function on those; arguments, producing a value f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:17450,variab,variable,17450,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['variab'],['variable']
Modifiability,"this itself. #### Numerical Inaccuracies. It is possible that the apparent lack of positive-definiteness is due; to excessive round off errors in numerical calculations (in the user; function), or not enough precision. This is unlikely in general, but; becomes more likely if the number of free parameters is very large, or; if the parameters are badly scaled (not all of the same order of; magnitude), and correlations are large. In any case, whether the; non-positive-definiteness is real or only numerical is largely; irrelevant, since in both cases the error matrix will be unreliable; and the minimum suspicious. #### An Ill-posed Problem. For questions of parameter dependence, see the discussion above on; positive-definiteness. Possible other mathematical problems are the; following:. - Excessive numerical round off - be especially careful of; exponential and factorial functions which get big very quickly and; lose accuracy. - Starting too far from the solution - the function may have; unphysical local minima, especially at infinity in some variables. ## Minuit2 Package. `Minuit2` is a new object-oriented implementation, written in C++, of; the popular `MINUIT` minimization package. Compared with the; **`TMinuit`** class, which is a direct conversion from FORTRAN to C++,; `Minuit2` is a complete redesign and re-implementation of the package.; This new version provides all the functionality present in the old; FORTRAN version, with almost equivalent numerical accuracy and; computational performances.; Furthermore, it contains some fixes and small improvements and this new functionality:; * The possibility to set single side parameter limits; * the FUMILI algorithm (see the next paragraph ""FUMILI Minimization Package""),; which is an optimized method for least square and log; likelihood minimizations. Minuit2 has been originally developed by M.; Winkler and F. James in the SEAL project. More information can be found; on the [MINUIT Web Site](MINUIT Web Site) and in partic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:64578,variab,variables,64578,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['variab'],['variables']
Modifiability,"this optimizing; assumption and shift some amount of risk to the user. .. _arc.misc.enumeration:. Fast enumeration iteration variables; ------------------------------------. If a variable is declared in the condition of an Objective-C fast enumeration; loop, and the variable has no explicit ownership qualifier, then it is; implicitly :ref:`externally-retained <arc.misc.externally_retained>` so that; objects encountered during the enumeration are not actually retained and; released. .. admonition:: Rationale. This is an optimization made possible because fast enumeration loops promise; to keep the objects retained during enumeration, and the collection itself; cannot be synchronously modified. It can be overridden by explicitly; qualifying the variable with ``__strong``, which will make the variable; mutable again and cause the loop to retain the objects it encounters. .. _arc.misc.blocks:. Blocks; ------. The implicit ``const`` capture variables created when evaluating a block; literal expression have the same ownership semantics as the local variables; they capture. The capture is performed by reading from the captured variable; and initializing the capture variable with that value; the capture variable is; destroyed when the block literal is, i.e. at the end of the enclosing scope. The :ref:`inference <arc.ownership.inference>` rules apply equally to; ``__block`` variables, which is a shift in semantics from non-ARC, where; ``__block`` variables did not implicitly retain during capture. ``__block`` variables of retainable object owner type are moved off the stack; by initializing the heap copy with the result of moving from the stack copy. With the exception of retains done as part of initializing a ``__strong``; parameter variable or reading a ``__weak`` variable, whenever these semantics; call for retaining a value of block-pointer type, it has the effect of a; ``Block_copy``. The optimizer may remove such copies when it sees that the; result is used only as an a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:96224,variab,variables,96224,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,2,['variab'],['variables']
Modifiability,"thod. The **`TTree`** (`tree`) below has two; friends (`ft1` and `ft2`) and now has access to the variables; `a,b,c,i,j,k,l` and `m`. ![](pictures/02000101.jpg). The `AddFriend` method has two parameters, the first is the tree name; and the second is the name of the ROOT file where the friend tree is; saved. `AddFriend` automatically opens the friend file. If no file name; is given, the tree called `ft1` is assumed to be in the same file as the; original tree. ``` {.cpp}; tree.AddFriend(""ft1"",""friendfile1.root"");; ```. If the friend tree has the same name as the original tree, you can give; it an alias in the context of the friendship:. ``` {.cpp}; tree.AddFriend(""tree1 = tree"",""friendfile1.root"");; ```. Once the tree has friends, we can use `TTree::Draw` as if the friend's; variables were in the original tree. To specify which tree to use in the; `Draw` method, use the syntax:. ``` {.cpp}; <treeName>.<branchname>.<varname>; ```. If the `variablename` is enough to identify uniquely the variable, you; can leave out the tree and/or branch name. For example, these commands generate a 3-d scatter plot of variable; ""`var`"" in the **`TTree`** `tree` versus variable `v1 in `TTree ft1`; versus variable `v2` in **`TTree`** `ft2`. ``` {.cpp}; tree.AddFriend(""ft1"",""friendfile1.root"");; tree.AddFriend(""ft2"",""friendfile2.root"");; tree.Draw(""var:ft1.v1:ft2.v2"");; ```. ![](pictures/02000102.jpg)The picture illustrates the access of the tree; and its friends with a `Draw` command. When `AddFriend` is called, the ROOT file is automatically opened and; the friend tree (`ft1)` header is read into memory. The new friend; (`ft1`) is added to the list of friends of `tree`. The number of entries; in the friend must be equal or greater to the number of entries of the; original tree. If the friend tree has fewer entries, a warning is given; and the missing entries are not included in the histogram. Use `TTree::GetListOfFriends` to retrieve the list of friends from a; tree. When the tree is w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:54008,variab,variablename,54008,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,2,['variab'],"['variable', 'variablename']"
Modifiability,"thod; * New options `RX`and `RY` for TMultiGraph in order to draw reverse axis along X and Y.; * Combined with the option ""Z"" the option ""CJUST"" allows to draw the color palette; with axis labels justified on the color boundaries (implemented by Otto Schaile).; * The `TCanvas` Event Status Bar now displays the date and time when the mouse cursor; is moved over a time axis (implemented by Otto Schaile).; * Negative values were not painted with option ""TEXT"" for TH2Poly. ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Libraries. ## GUI Libraries. ## Montecarlo Libraries. ## PROOF Libraries. ## Language Bindings. ### Jupyter Notebook Integration; - When starting Jupyter server with `root --notebook arg1 arg2 ...`, extra arguments can be provided.; All these arguments delivered as is to jupyter executable and can be used for configuration.; Like server binding to specific host `root --notebook --ip=hostname`; - Remove `c.NotebookApp.ip = '*'` from default jupyter config. One has to provide ip address for server; binding using `root --notebook --ip=<hostaddr>` arguments; - Now Jupyter Notebooks will use JSROOT provided with ROOT installation. This allows to use notebooks; without internet connection (offline). ## JavaScript ROOT; - Provide monitoring capabilities for TGeoManager object. Now geomtry with some tracks can be displayed and; updated in web browser, using THttpServer monitoring capability like histogram objects. ## Tutorials; - Add the ""Legacy"" category collecting the old tutorials which do not represent any more best practices. ## Class Reference Guide; - Images in tutorials can now be displayed à JavaScript thanks to the (js) option; added next to the directive `\macro_image`; - As the tutorial `palettes.C` is often hit when searching the keyword `palette`; in the reference guide, a direct link from this example to the full list of; predefined palettes given in `TColor` has been added.; - Revisited the TSpectrum2 documen",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v620/index.md:6254,config,config,6254,README/ReleaseNotes/v620/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v620/index.md,1,['config'],['config']
Modifiability,"thods may well read or write to those instance; variables. Making such message sends from dealloc is generally discouraged,; since the subclass may well rely on other invariants that were broken during; ``dealloc``, but it's not so inescapably dangerous that we felt comfortable; calling it undefined behavior. Therefore we chose to delay destroying the; instance variables to a point at which message sends are clearly disallowed:; the point at which the root class's deallocation routines take over. In most code, the difference is not observable. It can, however, be observed; if an instance variable holds a strong reference to an object whose; deallocation will trigger a side-effect which must be carefully ordered with; respect to the destruction of the super class. Such code violates the design; principle that semantically important behavior should be explicit. A simple; fix is to clear the instance variable manually during ``dealloc``; a more; holistic solution is to move semantically important side-effects out of; ``dealloc`` and into a separate teardown phase which can rely on working with; well-formed objects. .. _arc.misc.autoreleasepool:. ``@autoreleasepool``; --------------------. To simplify the use of autorelease pools, and to bring them under the control; of the compiler, a new kind of statement is available in Objective-C. It is; written ``@autoreleasepool`` followed by a *compound-statement*, i.e. by a new; scope delimited by curly braces. Upon entry to this block, the current state; of the autorelease pool is captured. When the block is exited normally,; whether by fallthrough or directed control flow (such as ``return`` or; ``break``), the autorelease pool is restored to the saved state, releasing all; the objects in it. When the block is exited with an exception, the pool is not; drained. ``@autoreleasepool`` may be used in non-ARC translation units, with equivalent; semantics. A program is ill-formed if it refers to the ``NSAutoreleasePool`` class. .. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:90212,variab,variable,90212,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['variab'],['variable']
Modifiability,"tialized when; read. If we find a variable which is read when not initialized then we generate; a warning. ```c++; void Init() {; int x; // x is uninitialized; if (cond()) {; x = 10; // x is initialized; } else {; x = 20; // x is initialized; }; print(x); // x is initialized; }; ```. ```c++; void Uninit() {; int x; // x is uninitialized; if (cond()) {; x = 10; // x is initialized; }; print(x); // x is maybe uninitialized, x is being read, report a bug.; }; ```. For this purpose we can use lattice in a form of a mapping from variable; declarations to initialization states; each initialization state is represented; by the following lattice:. ![Lattice for definitive initialization analysis](DataFlowAnalysisIntroImages/DefinitiveInitializationLattice.svg). A lattice element could also capture the source locations of the branches that; lead us to the corresponding program point. Diagnostics would use this; information to show a sample buggy code path to the user. ## Example: refactoring raw pointers to `unique_ptr`. Modern idiomatic C++ uses smart pointers to express memory ownership, however in; pre-C++11 code one can often find raw pointers that own heap memory blocks. Imagine that we would like to refactor raw pointers that own memory to; `unique_ptr`. There are multiple ways to design a data flow analysis for this; problem; let's look at one way to do it. For example, we would like to refactor the following code that uses raw; pointers:. ```c++; void UniqueOwnership1() {; int *pi = new int;; if (...) {; Borrow(pi);; delete pi;; } else {; TakeOwnership(pi);; }; }; ```. into code that uses `unique_ptr`:. ```c++; void UniqueOwnership1() {; auto pi = std::make_unique<int>();; if (...) {; Borrow(pi.get());; } else {; TakeOwnership(pi.release());; }; }; ```. This problem can be solved with a lattice in form of map from value declarations; to pointer states:. ![Lattice that identifies candidates for unique_ptr refactoring](DataFlowAnalysisIntroImages/UniquePtrLattice.svg).",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:21435,refactor,refactoring,21435,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,1,['refactor'],['refactoring']
Modifiability,"tic C++ uses smart pointers to express memory ownership, however in; pre-C++11 code one can often find raw pointers that own heap memory blocks. Imagine that we would like to refactor raw pointers that own memory to; `unique_ptr`. There are multiple ways to design a data flow analysis for this; problem; let's look at one way to do it. For example, we would like to refactor the following code that uses raw; pointers:. ```c++; void UniqueOwnership1() {; int *pi = new int;; if (...) {; Borrow(pi);; delete pi;; } else {; TakeOwnership(pi);; }; }; ```. into code that uses `unique_ptr`:. ```c++; void UniqueOwnership1() {; auto pi = std::make_unique<int>();; if (...) {; Borrow(pi.get());; } else {; TakeOwnership(pi.release());; }; }; ```. This problem can be solved with a lattice in form of map from value declarations; to pointer states:. ![Lattice that identifies candidates for unique_ptr refactoring](DataFlowAnalysisIntroImages/UniquePtrLattice.svg). We can perform the refactoring if at the exit of a function `pi` is; `Compatible`. ```c++; void UniqueOwnership1() {; int *pi; // pi is Compatible; pi = new int; // pi is Defined; if (...) {; Borrow(pi); // pi is Defined; delete pi; // pi is Compatible; } else {; TakeOwnership(pi); // pi is Compatible; }; // pi is Compatible; }; ```. Let's look at an example where the raw pointer owns two different memory blocks:. ```c++; void UniqueOwnership2() {; int *pi = new int; // pi is Defined; Borrow(pi);; delete pi; // pi is Compatible; if (smth) {; pi = new int; // pi is Defined; Borrow(pi);; delete pi; // pi is Compatible; }; // pi is Compatible; }; ```. It can be refactored to use `unique_ptr` like this:. ```c++; void UniqueOwnership2() {; auto pi = make_unique<int>();; Borrow(pi);; if (smth) {; pi = make_unique<int>();; Borrow(pi);; }; }; ```. In the following example, the raw pointer is used to access the heap object; after the ownership has been transferred. ```c++; void UniqueOwnership3() {; int *pi = new int; // pi is Defined",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:22469,refactor,refactoring,22469,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,1,['refactor'],['refactoring']
Modifiability,"tic`` that is used as a unified way to keep track of what the LLVM; compiler is doing and how effective various optimizations are. It is useful to; see what optimizations are contributing to making a particular program run; faster. Often you may run your pass on some big program, and you're interested to see; how many times it makes a certain transformation. Although you can do this with; hand inspection, or some ad-hoc method, this is a real pain and not very useful; for big programs. Using the ``Statistic`` class makes it very easy to keep; track of this information, and the calculated information is presented in a; uniform manner with the rest of the passes being executed. There are many examples of ``Statistic`` uses, but the basics of using it are as; follows:. Define your statistic like this:. .. code-block:: c++. #define DEBUG_TYPE ""mypassname"" // This goes after any #includes.; STATISTIC(NumXForms, ""The # of times I did stuff"");. The ``STATISTIC`` macro defines a static variable, whose name is specified by; the first argument. The pass name is taken from the ``DEBUG_TYPE`` macro, and; the description is taken from the second argument. The variable defined; (""NumXForms"" in this case) acts like an unsigned integer. Whenever you make a transformation, bump the counter:. .. code-block:: c++. ++NumXForms; // I did stuff!. That's all you have to do. To get '``opt``' to print out the statistics; gathered, use the '``-stats``' option:. .. code-block:: none. $ opt -stats -mypassname < program.bc > /dev/null; ... statistics output ... Note that in order to use the '``-stats``' option, LLVM must be; compiled with assertions enabled. When running ``opt`` on a C file from the SPEC benchmark suite, it gives a; report that looks like this:. .. code-block:: none. 7646 bitcodewriter - Number of normal instructions; 725 bitcodewriter - Number of oversized instructions; 129996 bitcodewriter - Number of bitcode bytes written; 2817 raise - Number of insts DCEd or constprop'd; 321",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:47441,variab,variable,47441,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['variab'],['variable']
Modifiability,"ticle = kFALSE;; }; // fill the Tree with current step parameters; t2.Fill();. //transport particle in magnetic field (Geant3 emulation); helixStep(gstep.step, gstep.vect, vout);; //make one step; //apply energy loss; gstep.destep = gstep.step*gRandom->Gaus(0.0002,0.00001);; gstep.gekin -= gstep.destep;; gstep.getot = gstep.gekin + mass;; gstep.vect[6]= charge*TMath::Sqrt(gstep.getot*gstep.getot; - mass*mass);; gstep.vect[0] = vout[0];; gstep.vect[1] = vout[1];; gstep.vect[2] = vout[2];; gstep.vect[3] = vout[3];; gstep.vect[4] = vout[4];; gstep.vect[5] = vout[5];; gstep.nmec = (Int_t)(5*gRandom->Rndm());; for (Int_t l=0; l<gstep.nmec; l++) gstep.lmec[l] = l;; if (gstep.gekin < 0.001) newParticle = kTRUE;; if (TMath::Abs(gstep.vect[2]) > 30) newParticle = kTRUE;; }; //save the Tree header. The file will be automatically; // closed when going out of the function scope; t2.Write();; }; ```. #### Adding a Branch with a Fixed Length Array. At first, we create a tree and create branches for a subset of variables; in the C structure` Gctrak_t`. Then we add several types of branches.; The first branch reads seven floating-point values beginning at the; address of `'gstep.vect'`. You do not need to specify `&gstep.vect`,; because in C and C++ the array variable holds the address of the first; element. ``` {.cpp}; t2.Branch(""vect"",gstep.vect,""vect[7]/F"");; t2.Branch(""getot"",&gstep.getot,""getot/F"");; t2.Branch(""gekin"",&gstep.gekin,""gekin/F"");; ```. #### Adding a Branch with a Variable Length Array. The next two branches are dependent on each other. The first holds the; length of the variable length array and the second holds the variable; length array. The `lmec` branch reads `nmec` number of integers; beginning at the address `gstep.lmec`. ``` {.cpp}; t2.Branch(""nmec"",&gstep.nmec,""nmec/I"");; t2.Branch(""lmec"",gstep.lmec,""lmec[nmec]/I"");; ```. The variable `nmec` is a random number and is reset for each entry. ``` {.cpp}; gstep.nmec = (Int_t)(5*gRandom->Rndm());; ```. #### Filli",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:47871,variab,variables,47871,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['variab'],['variables']
Modifiability,"ties provided by git for Windows have been known to work.; Cygwin has worked in the past, but is not well tested.; If you don't already have the core utilies from some other source, get; gnuwin32 from ; http://getgnuwin32.sourceforge.net/. Check out LLVM and Clang:; ; git clone https://github.com/llvm/llvm-project.git. Note: Some Clang tests are sensitive to the line endings. Ensure; that checking out the files does not convert LF line endings to CR+LF. If; you're using git on Windows, make sure your core.autocrlf setting; is false. Run CMake to generate the Visual Studio solution and project files:; ; cd llvm-project; mkdir build (for building without polluting the source dir); cd build. If you are using Visual Studio 2019:; cmake -DLLVM_ENABLE_PROJECTS=clang -G ""Visual Studio 16 2019"" -A x64 -Thost=x64 ..\llvm; -Thost=x64 is required, since the 32-bit linker will run out of memory.; ; To generate x86 binaries instead of x64, pass -A Win32.; See the LLVM CMake guide for; more information on other configuration options for CMake.; The above, if successful, will have created an LLVM.sln file in the; build directory.; . Build Clang:; ; Open LLVM.sln in Visual Studio.; Build the ""clang"" project for just the compiler driver and front end, or; the ""ALL_BUILD"" project to build everything, including tools. Try it out (assuming you added llvm/debug/bin to your path). (See the; running examples from above.); See ; Hacking on clang - Testing using Visual Studio on Windows for information; on running regression tests on Windows. Using Ninja alongside Visual Studio; We recommend that developers who want the fastest incremental builds use the; Ninja build system. You can use the; generated Visual Studio project files to edit Clang source code and generate a; second build directory next to it for running the tests with these steps:. Check out clang and LLVM as described above; Open a developer command prompt with the appropriate environment.; ; If you open the start menu and sear",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/get_started.html:5005,config,configuration,5005,interpreter/llvm-project/clang/www/get_started.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/get_started.html,1,['config'],['configuration']
Modifiability,"tifier* (',' *identifier*)*. Each *identifier* in the *config-macro-list* specifies the name of a macro. The compiler is required to maintain different variants of the given module for differing definitions of any of the named macros. A *config-macros-declaration* shall only be present on a top-level module, i.e., a module that is not nested within an enclosing module. The ``exhaustive`` attribute specifies that the list of macros in the *config-macros-declaration* is exhaustive, meaning that no other macro definition is intended to have an effect on the API of that module. .. note::. The ``exhaustive`` attribute implies that any macro definitions; for macros not listed as configuration macros should be ignored; completely when building the module. As an optimization, the; compiler could reduce the number of unique module variants by not; considering these non-configuration macros. This optimization is not; yet implemented in Clang. A translation unit shall not import the same module under different definitions of the configuration macros. .. note::. Clang implements a weak form of this requirement: the definitions; used for configuration macros are fixed based on the definitions; provided by the command line. If an import occurs and the definition; of any configuration macro has changed, the compiler will produce a; warning (under the control of ``-Wconfig-macros``). **Example:** A logging library might provide different API (e.g., in the form of different definitions for a logging macro) based on the ``NDEBUG`` macro setting:. .. parsed-literal::. module MyLogger {; umbrella header ""MyLogger.h""; config_macros [exhaustive] NDEBUG; }. Conflict declarations; ~~~~~~~~~~~~~~~~~~~~~; A *conflict-declaration* describes a case where the presence of two different modules in the same translation unit is likely to cause a problem. For example, two modules may provide similar-but-incompatible functionality. .. parsed-literal::. *conflict-declaration*:; ``conflict`` *module-id*",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:47573,config,configuration,47573,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['config'],['configuration']
Modifiability,"tility to take a look at the LLVM assembly code:. .. code-block:: console. % llvm-dis < hello.bc | less. #. Compile the program to native assembly using the LLC code generator:. .. code-block:: console. % llc hello.bc -o hello.s. #. Assemble the native assembly language file into a program:. .. code-block:: console. % /opt/SUNWspro/bin/cc -xarch=v9 hello.s -o hello.native # On Solaris. % gcc hello.s -o hello.native # On others. #. Execute the native code program:. .. code-block:: console. % ./hello.native. Note that using clang to compile directly to native code (i.e. when the; ``-emit-llvm`` option is not present) does steps 6/7/8 for you. Common Problems; ===============. If you are having problems building or using LLVM, or if you have any other; general questions about LLVM, please consult the `Frequently Asked; Questions <FAQ.html>`_ page. If you are having problems with limited memory and build time, please try; building with ninja instead of make. Please consider configuring the; following options with cmake:. * -G Ninja; Setting this option will allow you to build with ninja instead of make.; Building with ninja significantly improves your build time, especially with; incremental builds, and improves your memory usage. * -DLLVM_USE_LINKER; Setting this option to lld will significantly reduce linking time for LLVM; executables on ELF-based platforms, such as Linux. If you are building LLVM; for the first time and lld is not available to you as a binary package, then; you may want to use the gold linker as a faster alternative to GNU ld. * -DCMAKE_BUILD_TYPE; Controls optimization level and debug information of the build. This setting; can affect RAM and disk usage, see :ref:`CMAKE_BUILD_TYPE <cmake_build_type>`; for more information. * -DLLVM_ENABLE_ASSERTIONS; This option defaults to ON for Debug builds and defaults to OFF for Release; builds. As mentioned in the previous option, using the Release build type and; enabling assertions may be a good alternative",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:44148,config,configuring,44148,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['config'],['configuring']
Modifiability,"time compiler that extends C++ for ease of use as an interpreter.; . ; .. list-table:: Demos, tutorials, Cling’s ecosystem:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Cling integration | CLion <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_; - 2022.2 Version; - CLion uses Cling to integrate the `Quick Documentation <https://www.jetbrains.com/help/clion/2022.2/viewing-inline-documentation.html>`_ popup by allowing you to view the value of the expressions evaluated at compile time.; * - `Interactive C++ for Data Science <https://www.youtube.com/watch?v=23E0S3miWB0&t=2716s>`_; - *Vassil Vassilev* 2021 CppCon (The C++ Conference); - In this video, the author discusses how Cling enables interactive C++ for Data Science projects. ; * - `Cling -- Beyond Just Interpreting C++ <https://blog.llvm.org/posts/2021-03-25-cling-beyond-just-interpreting-cpp/>`_; - *Vassil Vassilev* 2021 The LLVM Project Blog; - This blog page discusses how Cling enables template Instantiation on demand, language interoperability on demand, interpreter/compiler as a service, plugins extension.; * - `TinySpec-Cling <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_; - Noah Weninger 2020; - A tiny C++ live-coded overlap-add (re)synthesizer for Linux, which uses Cling to add REPL-like functionality for C++ code.; * - `Interactive C++ for Data Science <https://blog.llvm.org/posts/2020-12-21-interactive-cpp-for-data-science/>`_; - *Vassil Vassilev,* *David Lange,* *Simeon Ehrig,* *Sylvain Corlay* 2020 The LLVM Project Blog; - Cling enables eval-style programming for Data Science applications. Examples of ROOT and Xeus-Cling for data science are shown.; * - `Interactive C++ with Cling <https://blog.llvm.org/posts/2020-11-30-interactive-cpp-with-cling/>`_; - *Vassil Vassilev* 2020 The LLVM Project Blog; - This blog page briefly discusses the concept of interactive C++ by presenting Cling’s main features, such as wrapper functions, entity re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:2881,plugin,plugins,2881,interpreter/cling/docs/chapters/references.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst,1,['plugin'],['plugins']
Modifiability,"times and memory usage; during linking significantly. With a build machine with sufficient; parallelism, link times tend to dominate critical path of the build, and are; thus worth optimizing. Use CCache and NOT incremental builds; Using ccache materially improves average build times. Incremental builds; can be slightly faster, but introduce the risk of build corruption due to; e.g. state changes, etc... At this point, the recommendation is not to; use incremental builds and instead use ccache as the latter captures the; majority of the benefit with less risk of false positives. One of the non-obvious benefits of using ccache is that it makes the; builder less sensitive to which projects are being monitored vs built.; If a change triggers a build request, but doesn't change the build output; (e.g. doc changes, python utility changes, etc..), the build will entirely; hit in cache and the build request will complete in just the testing time. With multiple workers, it is tempting to try to configure a shared cache; between the workers. Experience to date indicates this is difficult to; well, and that having local per-worker caches gets most of the benefit; anyways. We don't currently recommend shared caches. CCache does depend on the builder hardware having sufficient IO to access; the cache with reasonable access times - i.e. a fast disk, or enough memory; for a RAM cache, etc.. For builders without, incremental may be your best; option, but is likely to require higher ongoing involvement from the; sponsor. Enable batch builds; As a last resort, you can configure your builder to batch build requests.; This makes the build failure notifications markedly less actionable, and; should only be done once all other reasonable measures have been taken. Leave it on the staging buildmaster; While most of this section has been biased towards builders intended for; the main buildmaster, it is worth highlighting that builders can run; indefinitely on the staging buildmaster. Such a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst:11855,config,configure,11855,interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,1,['config'],['configure']
Modifiability,"timization, callee reusing the stack of the caller, is currently; supported on x86/x86-64, PowerPC, AArch64, and WebAssembly. It is performed on; x86/x86-64, PowerPC, and AArch64 if:. * Caller and callee have the calling convention ``fastcc``, ``cc 10`` (GHC; calling convention), ``cc 11`` (HiPE calling convention), ``tailcc``, or; ``swifttailcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Option ``-tailcallopt`` is enabled or the calling convention is ``tailcc``. * Platform-specific constraints are met. x86/x86-64 constraints:. * No variable argument lists are used. * On x86-64 when generating GOT/PIC code only module-local calls (visibility =; hidden or protected) are supported. PowerPC constraints:. * No variable argument lists are used. * No byval parameters are used. * On ppc32/64 GOT/PIC only module-local calls (visibility = hidden or protected); are supported. WebAssembly constraints:. * No variable argument lists are used. * The 'tail-call' target attribute is enabled. * The caller and callee's return types must match. The caller cannot; be void unless the callee is, too. AArch64 constraints:. * No variable argument lists are used. Example:. Call as ``llc -tailcallopt test.ll``. .. code-block:: llvm. declare fastcc i32 @tailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4). define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {; %l1 = add i32 %in1, %in2; %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1); ret i32 %tmp; }. Implications of ``-tailcallopt``:. To support tail call optimization in situations where the callee has more; arguments than the caller a 'callee pops arguments' convention is used. This; currently causes each ``fastcc`` call that is not tail call optimized (because; one or more of above constraints are not met) to be followed by a readjustment; of the stack. So performance might be worse in such cases. Sibling call optimizat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:87240,variab,variable,87240,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['variab'],['variable']
Modifiability,"ting 1-based function parameters. Each *attr* is itself represented as a variable number of values:. ``kind, key [, ...], [value [, ...]]``. Each attribute is either a well-known LLVM attribute (possibly with an integer; value associated with it), or an arbitrary string (possibly with an arbitrary; string value associated with it). The *kind* value is an integer code; distinguishing between these possibilities:. * code 0: well-known attribute; * code 1: well-known attribute with an integer value; * code 3: string attribute; * code 4: string attribute with a string value. For well-known attributes (code 0 or 1), the *key* value is an integer code; identifying the attribute. For attributes with an integer argument (code 1),; the *value* value indicates the argument. For string attributes (code 3 or 4), the *key* value is actually a variable; number of values representing the bytes of a null-terminated string. For; attributes with a string argument (code 4), the *value* value is similarly a; variable number of values representing the bytes of a null-terminated string. The integer codes are mapped to well-known attributes as follows. * code 1: ``align(<n>)``; * code 2: ``alwaysinline``; * code 3: ``byval``; * code 4: ``inlinehint``; * code 5: ``inreg``; * code 6: ``minsize``; * code 7: ``naked``; * code 8: ``nest``; * code 9: ``noalias``; * code 10: ``nobuiltin``; * code 11: ``nocapture``; * code 12: ``nodeduplicate``; * code 13: ``noimplicitfloat``; * code 14: ``noinline``; * code 15: ``nonlazybind``; * code 16: ``noredzone``; * code 17: ``noreturn``; * code 18: ``nounwind``; * code 19: ``optsize``; * code 20: ``readnone``; * code 21: ``readonly``; * code 22: ``returned``; * code 23: ``returns_twice``; * code 24: ``signext``; * code 25: ``alignstack(<n>)``; * code 26: ``ssp``; * code 27: ``sspreq``; * code 28: ``sspstrong``; * code 29: ``sret``; * code 30: ``sanitize_address``; * code 31: ``sanitize_thread``; * code 32: ``sanitize_memory``; * code 33: ``uwtable``; * cod",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:37734,variab,variable,37734,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,1,['variab'],['variable']
Modifiability,"ting a minimal example. ``` {.cpp}; @ROOT_INCLUDE_FILE macros/write_ntuple_to_file.C; ```. This data written to this example n-tuple represents, in the statistical; sense, three independent variables (Potential or Voltage, Pressure and; Temperature), and one variable (Current) which depends on the others; according to very simple laws, and an additional Gaussian smearing. This; set of variables mimics a measurement of an electrical resistance while; varying pressure and temperature. Imagine your task now consists in finding the relations among the; variables -- of course without knowing the code used to generate them.; You will see that the possibilities of the `NTuple` class enable you to; perform this analysis task. Open the ROOT file (`cond_data.root`); written by the macro above in an interactive session and use a; `TBrowser` to interactively inspect it:. ``` {.cpp}; root[0] TBrowser b; ```; You find the columns of your n-tuple written as *leafs*. Simply clicking; on them you can obtain histograms of the variables!. Next, try the following commands at the shell prompt and in the; interactive ROOT shell, respectively:. ``` {.cpp}; > root conductivity_experiment.root; Attaching file conductivity_experiment.root as _file0...; root [0] cond_data->Draw(""Current:Potential""); ```. You just produced a correlation plot with one single line of code!. Try to extend the syntax typing for example. ``` {.cpp}; root [1] cond_data->Draw(""Current:Potential"",""Temperature<270""); ```. What do you obtain ?. Now try. ``` {.cpp}; root [2] cond_data->Draw(""Current/Potential:Temperature""); ```. It should have become clear from these examples how to navigate in such; a multi-dimensional space of variables and unveil relations between; variables using n-tuples. ### Reading N-tuples. For completeness, you find here a small macro to read the data back from; a ROOT n-tuple. ``` {.cpp}; @ROOT_INCLUDE_FILE macros/read_ntuple_from_file.C; ```. The macro shows the easiest way of accessing the co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md:3226,variab,variables,3226,documentation/primer/filio.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md,1,['variab'],['variables']
Modifiability,"ting the bytes of a single garbage collector name string. There should; be one ``GCNAME`` record for each garbage collector name referenced in function; ``gc`` attributes within the module. These records can be referenced by 1-based; index in the *gc* fields of ``FUNCTION`` records. .. _PARAMATTR_BLOCK:. PARAMATTR_BLOCK Contents; ------------------------. The ``PARAMATTR_BLOCK`` block (id 9) contains a table of entries describing the; attributes of function parameters. These entries are referenced by 1-based index; in the *paramattr* field of module block `FUNCTION`_ records, or within the; *attr* field of function block ``INST_INVOKE`` and ``INST_CALL`` records. Entries within ``PARAMATTR_BLOCK`` are constructed to ensure that each is unique; (i.e., no two indices represent equivalent attribute lists). .. _PARAMATTR_CODE_ENTRY:. PARAMATTR_CODE_ENTRY Record; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``[ENTRY, attrgrp0, attrgrp1, ...]``. The ``ENTRY`` record (code 2) contains a variable number of values describing a; unique set of function parameter attributes. Each *attrgrp* value is used as a; key with which to look up an entry in the attribute group table described; in the ``PARAMATTR_GROUP_BLOCK`` block. .. _PARAMATTR_CODE_ENTRY_OLD:. PARAMATTR_CODE_ENTRY_OLD Record; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::; This is a legacy encoding for attributes, produced by LLVM versions 3.2 and; earlier. It is guaranteed to be understood by the current LLVM version, as; specified in the :ref:`IR backwards compatibility` policy. ``[ENTRY, paramidx0, attr0, paramidx1, attr1...]``. The ``ENTRY`` record (code 1) contains an even number of values describing a; unique set of function parameter attributes. Each *paramidx* value indicates; which set of attributes is represented, with 0 representing the return value; attributes, 0xFFFFFFFF representing function attributes, and other values; representing 1-based function parameters. Each *attr* value is a bitmap with the; following interpretatio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:34181,variab,variable,34181,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,1,['variab'],['variable']
Modifiability,"ting will misbehave if ARC performs an ephemeral extra retain or two. If; absolutely required, it is still possible to implement them in non-ARC code,; for example in a category; the implementations must obey the :ref:`semantics; <arc.objects.retains>` laid out elsewhere in this document. .. _arc.misc.special_methods.dealloc:. ``dealloc``; ^^^^^^^^^^^. A program is ill-formed if it contains a message send or ``@selector``; expression for the selector ``dealloc``. .. admonition:: Rationale. There are no legitimate reasons to call ``dealloc`` directly. A class may provide a method definition for an instance method named; ``dealloc``. This method will be called after the final ``release`` of the; object but before it is deallocated or any of its instance variables are; destroyed. The superclass's implementation of ``dealloc`` will be called; automatically when the method returns. .. admonition:: Rationale. Even though ARC destroys instance variables automatically, there are still; legitimate reasons to write a ``dealloc`` method, such as freeing; non-retainable resources. Failing to call ``[super dealloc]`` in such a; method is nearly always a bug. Sometimes, the object is simply trying to; prevent itself from being destroyed, but ``dealloc`` is really far too late; for the object to be raising such objections. Somewhat more legitimately, an; object may have been pool-allocated and should not be deallocated with; ``free``; for now, this can only be supported with a ``dealloc``; implementation outside of ARC. Such an implementation must be very careful; to do all the other work that ``NSObject``'s ``dealloc`` would, which is; outside the scope of this document to describe. The instance variables for an ARC-compiled class will be destroyed at some; point after control enters the ``dealloc`` method for the root class of the; class. The ordering of the destruction of instance variables is unspecified,; both within a single class and between subclasses and superclasses. .. a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:87975,variab,variables,87975,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['variab'],['variables']
Modifiability,"ting"". Note that we can get more than 3 possible values even without a loop:. ```c++; void ExampleOfTopWithoutLoops(int n) {; int x = 0; // x is {0}; switch(n) {; case 0: x = 1; break; // x is {1}; case 1: x = 9; break; // x is {9}; case 2: x = 7; break; // x is {7}; default: x = 3; break; // x is {3}; }; // x is ⊤; }; ```. ### Uninitialized variables and ""bottom"" values. When `x` is declared but not initialized, it has no possible values. We; represent this fact symbolically as `⊥` (pronounced ""bottom""). ```c++; void ExampleOfBottom() {; int x; // x is ⊥; x = 42; // x is {42}; print(x);; }; ```. Note that using values read from uninitialized variables is undefined behaviour; in C++. Generally, compilers and static analysis tools can assume undefined; behavior does not happen. We must model uninitialized variables only when we are; implementing a checker that specifically is trying to find uninitialized reads.; In this example we show how to model uninitialized variables only to demonstrate; the concept of ""bottom"", and how it applies to possible value analysis. We; describe an analysis that finds uninitialized reads in a section below. ### A practical lattice that tracks sets of concrete values. Taking into account all corner cases covered above, we can put together a; lattice that we can use in practice to track possible values of integer; variables. This lattice represents sets of integers with 1, 2, or 3 elements, as; well as top and bottom. Here is a Hasse diagram for it:. ![Hasse diagram for a lattice of integer sets](DataFlowAnalysisIntroImages/IntegerSetsFiniteLattice.svg). ### Formalization. Let's consider a slightly more complex example, and think about how we can; compute the sets of possible values algorithmically. ```c++; void Example(int n) {; int x; // x is ⊥; if (n > 0) {; if (n == 42) {; x = 44; // x is {44}; } else {; x = 5; // x is {5}; }; print(x); // x is {44; 5}; } else {; x = n; // x is ⊤; }; print(x); // x is ⊤; }; ```. As humans, we understan",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:6382,variab,variables,6382,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,1,['variab'],['variables']
Modifiability,"ting: custom variable titles and units can be; assigned in ""AddVariable"" call. Introduced the inverse transformation InverseTransform for; the variable transformations into the framework. While this is; not necessary for classification, it is necessary for; regression. The inverse transformation of the normalization; transformation has been implemented. Started to extend the variable transformations to the; regression targets as well. MethodCuts now produces the 'optimal-cut' histograms needed; by macro mvaeffs.C. (macro 5a of TMVAGui.C); ; MsgLogger can be silenced in order to prevent excess output; during boosting. Third dataset type added centrally (Training, Validation; and Testing). The validation data is split off the original; training data set. Update of GUI and other Macros according to the new; features of PDF and the addition of MethodBoost.; ; Updates in TMVA 4.0.1. ""Spectator"" variables can be defined now which are computed; just as the input variables and which are written out into the; TestTree, but which don't participate in any MVA calculation; (useful for correlation studies).; ; New booking option ""IgnoreNegWeightsInTraining"" to test the; effect of events with negative weights on the training. This is; especially useful for methods, which do not properly deal with; such events. Note that this new option is not available for all; methods (a training interrupt is issued if not available). ; Bug fixes:. Fixed regression bug in VariableNormalizeTransform (Use; number of targets from Event instead of DataSet); ; Fixed Multitarget-Regression in PDEFoam, foam dimensions; were miscalculated. Added writing of targets to the weight files in regression; mode to fix problems in RegressionApplication. Added missing standard C++ header files missing to some; classes, which lead to compilation failures on some; architectures (thanks to Lucian Ancu, Nijmegen, for reporting; these). Added checks for unused options to Factory and; DataSetFactory configuration option",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:6141,variab,variables,6141,tmva/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html,2,['variab'],['variables']
Modifiability,"tion Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help message. CreateMVAPdfs No False − Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False − Events with negative weights are ignored in the training (but are included for testing and performance evaluation). nkNN No 20 − Number of k-nearest neighbors. BalanceDepth No 6 − Binary tree balance depth. ScaleFrac No 0.8 − Fraction of events used to compute variable width. SigmaFact No 1 − Scale factor for sigma in Gaussian kernel. Kernel No Gaus − Use polynomial (=Poln) or Gaussian (=Gaus) kernel. Trim No False − Use equal number of signal and background events. UseKernel No False − Use polynomial kernel weight. UseWeight No True − Use weight to count kNN events. UseLDA No False − Use local linear discriminant - experimental feature. Configuration options for MVA method :. Configuration options reference for MVA method: BDT. Option Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all even",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:10522,variab,variable,10522,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,1,['variab'],['variable']
Modifiability,"tion and issues a diagnostic if not.; * ``diagLangOpts``, which checks if the attribute is permitted for the current; language mode and issues a diagnostic if not.; * ``existsInTarget``, which checks if the attribute is permitted for the given; target. To see a working example of an attribute plugin, see `the Attribute.cpp example; <https://github.com/llvm/llvm-project/blob/main/clang/examples/Attribute/Attribute.cpp>`_. Putting it all together; =======================. Let's look at an example plugin that prints top-level function names. This; example is checked into the clang repository; please take a look at; the `latest version of PrintFunctionNames.cpp; <https://github.com/llvm/llvm-project/blob/main/clang/examples/PrintFunctionNames/PrintFunctionNames.cpp>`_. Running the plugin; ==================. Using the compiler driver; --------------------------. The Clang driver accepts the `-fplugin` option to load a plugin.; Clang plugins can receive arguments from the compiler driver command; line via the `fplugin-arg-<plugin name>-<argument>` option. Using this; method, the plugin name cannot contain dashes itself, but the argument; passed to the plugin can. .. code-block:: console. $ export BD=/path/to/build/directory; $ make -C $BD CallSuperAttr; $ clang++ -fplugin=$BD/lib/CallSuperAttr.so \; -fplugin-arg-call_super_plugin-help \; test.cpp. If your plugin name contains dashes, either rename the plugin or used the; cc1 command line options listed below. Using the cc1 command line; --------------------------. To run a plugin, the dynamic library containing the plugin registry must be; loaded via the `-load` command line option. This will load all plugins; that are registered, and you can select the plugins to run by specifying the; `-plugin` option. Additional parameters for the plugins can be passed with; `-plugin-arg-<plugin-name>`. Note that those options must reach clang's cc1 process. There are two; ways to do so:. * Directly call the parsing process by using th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangPlugins.rst:4574,plugin,plugins,4574,interpreter/llvm-project/clang/docs/ClangPlugins.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangPlugins.rst,2,['plugin'],"['plugin', 'plugins']"
Modifiability,"tion each sanitizing function in our configuration,; you can use a more generic approach. Introduce a generic no-op `csa_mark_sanitized(..)` function to; tell the Clang Static Analyzer; that the variable is safe to be used on that analysis path. .. code-block:: c. // Marking sanitized variables safe.; // No vulnerability anymore, no warning. // User csa_mark_sanitize function is for the analyzer only; #ifdef __clang_analyzer__; void csa_mark_sanitized(const void *);; #endif. int main(int argc, char** argv) {; char cmd[2048] = ""/bin/cat "";; char filename[1024];; printf(""Filename:"");; scanf ("" %1023[^\n]"", filename);; if (access(filename,F_OK)){// Verifying user input; printf(""File does not exist\n"");; return -1;; }; #ifdef __clang_analyzer__; csa_mark_sanitized(filename); // Indicating to CSA that filename variable is safe to be used after this point; #endif; strcat(cmd, filename);; system(cmd); // No warning; }. Similarly to the previous example, you need to; define a `Filter` function in a `YAML` configuration file; and add the `csa_mark_sanitized` function. .. code-block:: YAML. Filters:; - Name: csa_mark_sanitized; Args: [0]. Then calling `csa_mark_sanitized(X)` will tell the analyzer that `X` is safe to; be used after this point, because its contents are verified. It is the; responsibility of the programmer to ensure that this verification was indeed; correct. Please note that `csa_mark_sanitized` function is only declared and; used during Clang Static Analysis and skipped in (production) builds. Further examples of injection vulnerabilities this checker can find. .. code-block:: c. void test() {; char x = getchar(); // 'x' marked as tainted; system(&x); // warn: untrusted data is passed to a system call; }. // note: compiler internally checks if the second param to; // sprintf is a string literal or not.; // Use -Wno-format-security to suppress compiler warning.; void test() {; char s[10], buf[10];; fscanf(stdin, ""%s"", s); // 's' marked as tainted. sprintf(buf,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:69692,config,configuration,69692,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['config'],['configuration']
Modifiability,"tion file, this can be configured like; in the following yaml example. This will result in imports being; formatted as in the Java example below. .. code-block:: yaml. JavaImportGroups: ['com.example', 'com', 'org']. .. code-block:: java. import static com.example.function1;. import static com.test.function2;. import static org.example.function3;. import com.example.ClassA;; import com.example.Test;; import com.example.a.ClassB;. import com.test.ClassC;. import org.example.ClassD;. .. _JavaScriptQuotes:. **JavaScriptQuotes** (``JavaScriptQuoteStyle``) :versionbadge:`clang-format 3.9` :ref:`¶ <JavaScriptQuotes>`; The JavaScriptQuoteStyle to use for JavaScript strings. Possible values:. * ``JSQS_Leave`` (in configuration: ``Leave``); Leave string quotes as they are. .. code-block:: js. string1 = ""foo"";; string2 = 'bar';. * ``JSQS_Single`` (in configuration: ``Single``); Always use single quotes. .. code-block:: js. string1 = 'foo';; string2 = 'bar';. * ``JSQS_Double`` (in configuration: ``Double``); Always use double quotes. .. code-block:: js. string1 = ""foo"";; string2 = ""bar"";. .. _JavaScriptWrapImports:. **JavaScriptWrapImports** (``Boolean``) :versionbadge:`clang-format 3.9` :ref:`¶ <JavaScriptWrapImports>`; Whether to wrap JavaScript import/export statements. .. code-block:: js. true:; import {; VeryLongImportsAreAnnoying,; VeryLongImportsAreAnnoying,; VeryLongImportsAreAnnoying,; } from 'some/module.js'. false:; import {VeryLongImportsAreAnnoying, VeryLongImportsAreAnnoying, VeryLongImportsAreAnnoying,} from ""some/module.js"". .. _KeepEmptyLinesAtEOF:. **KeepEmptyLinesAtEOF** (``Boolean``) :versionbadge:`clang-format 17` :ref:`¶ <KeepEmptyLinesAtEOF>`; Keep empty lines (up to ``MaxEmptyLinesToKeep``) at end of file. .. _KeepEmptyLinesAtTheStartOfBlocks:. **KeepEmptyLinesAtTheStartOfBlocks** (``Boolean``) :versionbadge:`clang-format 3.7` :ref:`¶ <KeepEmptyLinesAtTheStartOfBlocks>`; If true, the empty line at the start of blocks is kept. .. code-block:: c++. true: ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:80919,config,configuration,80919,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['config'],['configuration']
Modifiability,"tion of the function is the definitive definition; within the program or whether it will be overridden by a stronger; definition. To enable inlining and other optimizations, use; ""``linkonce_odr``"" linkage.; ``weak``; ""``weak``"" linkage has the same merging semantics as ``linkonce``; linkage, except that unreferenced globals with ``weak`` linkage may; not be discarded. This is used for globals that are declared ""weak""; in C source code.; ``common``; ""``common``"" linkage is most similar to ""``weak``"" linkage, but they; are used for tentative definitions in C, such as ""``int X;``"" at; global scope. Symbols with ""``common``"" linkage are merged in the; same way as ``weak symbols``, and they may not be deleted if; unreferenced. ``common`` symbols may not have an explicit section,; must have a zero initializer, and may not be marked; ':ref:`constant <globalvars>`'. Functions and aliases may not have; common linkage. .. _linkage_appending:. ``appending``; ""``appending``"" linkage may only be applied to global variables of; pointer to array type. When two global variables with appending; linkage are linked together, the two global arrays are appended; together. This is the LLVM, typesafe, equivalent of having the; system linker append together ""sections"" with identical names when; .o files are linked. Unfortunately this doesn't correspond to any feature in .o files, so it; can only be used for variables like ``llvm.global_ctors`` which llvm; interprets specially. ``extern_weak``; The semantics of this linkage follow the ELF object file model: the; symbol is weak until linked, if not linked, the symbol becomes null; instead of being an undefined reference.; ``linkonce_odr``, ``weak_odr``; Some languages allow differing globals to be merged, such as two; functions with different semantics. Other languages, such as; ``C++``, ensure that only equivalent globals are ever merged (the; ""one definition rule"" --- ""ODR""). Such languages can use the; ``linkonce_odr`` and ``weak_odr`` l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:10177,variab,variables,10177,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variables']
Modifiability,"tion routine is the opposite of the initialization. When finalized,; an implementation's data can be cleared out through the; ``__xray_log_flushLog()`` function. For implementations that support in-memory; processing, these should register an iterator function to provide access to the; data via the ``__xray_log_set_buffer_iterator(...)`` which allows code calling; the ``__xray_log_process_buffers(...)`` function to deal with the data in; memory. All of this is better explained in the ``xray/xray_log_interface.h`` header. Basic Mode; ----------. XRay supports a basic logging mode which will trace the application's; execution, and periodically append to a single log. This mode can be; installed/enabled by setting ``xray_mode=xray-basic`` in the ``XRAY_OPTIONS``; environment variable. Combined with ``patch_premain=true`` this can allow for; tracing applications from start to end. Like all the other modes installed through ``__xray_log_select_mode(...)``, the; implementation can be configured through the ``__xray_log_init_mode(...)``; function, providing the mode string and the flag options. Basic-mode specific; defaults can be provided in the ``XRAY_BASIC_OPTIONS`` environment variable. Flight Data Recorder Mode; -------------------------. XRay supports a logging mode which allows the application to only capture a; fixed amount of memory's worth of events. Flight Data Recorder (FDR) mode works; very much like a plane's ""black box"" which keeps recording data to memory in a; fixed-size circular queue of buffers, and have the data available; programmatically until the buffers are finalized and flushed. To use FDR mode; on your application, you may set the ``xray_mode`` variable to ``xray-fdr`` in; the ``XRAY_OPTIONS`` environment variable. Additional options to the FDR mode; implementation can be provided in the ``XRAY_FDR_OPTIONS`` environment; variable. Programmatic configuration can be done by calling; ``__xray_log_init_mode(""xray-fdr"", <configuration string>)`` once it",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:8549,config,configured,8549,interpreter/llvm-project/llvm/docs/XRay.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst,1,['config'],['configured']
Modifiability,"tion tokens and https protocol,; this makes usage of webgui components in public networks more secure. ### Enabled WLCG Bearer Tokens support in RDavix. Bearer tokens are part of WLCG capability-based infrastructure with capability-based scheme which uses an infrastructure that describes what the bearer is allowed to do as opposed to who that bearer is. Token discovery procedure are developed according WLCG Bearer Token Discovery specification document (https://github.com/WLCG-AuthZ-WG/bearer-token-discovery/blob/master/specification.md). Short overview:. 1. If the `BEARER_TOKEN` environment variable is set, then the value is taken to be the token contents.; 2. If the `BEARER_TOKEN_FILE` environment variable is set, then its value is interpreted as a filename. The contents of the specified file are taken to be the token contents.; 3. If the `XDG_RUNTIME_DIR` environment variable is set, then take the token from the contents of `$XDG_RUNTIME_DIR/bt_u$ID`(this additional location is intended to provide improved security for shared login environments as `$XDG_RUNTIME_DIR` is defined to be user-specific as opposed to a system-wide directory.).; 4. Otherwise, take the token from `/tmp/bt_u$ID`. ## GUI Libraries. ### RBrowser improvements. - central factory methods to handle browsing, editing and drawing of different classes; - simple possibility to extend RBrowser on user-defined classes; - support of web-based geometry viewer; - better support of TTree drawing; - server-side handling of code editor and image viewer widgets; - rbrowser content is fully recovered when web-browser is reloaded; - load of widgets code only when really required (shorter startup time for RBrowser). ## Montecarlo Libraries. ## PROOF Libraries. ## Language Bindings. ## JavaScript ROOT. ### Major JSROOT update to version 6. - update all used libraries `d3.js`, `three.js`, `MathJax.js`, openui5; - change to Promise based interface for all async methods, remove call-back arguments; - change scripts",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:26449,variab,variable,26449,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['variab'],['variable']
Modifiability,"tion upon which; the user is focused, if any. The result of the evaluation is the location; description L of the *canonical frame address* (see; :ref:`amdgpu-dwarf-call-frame-information`) of the relevant call frame of; the subprogram instance that immediately lexically encloses the current call; frame's subprogram or entry point. The DWARF is ill-formed if L is not comprised of one memory location; description for one of the target architecture specific address spaces. In the context of supporting nested subroutines, the DW_AT_frame_base; attribute value obeys the following constraints:. 1. It computes a value that does not change during the life of the; subprogram, and. 2. The computed value is unique among instances of the same subroutine. *For typical DW_AT_frame_base use, this means that a recursive subroutine's; stack frame must have non-zero size.*. *If a debugger is attempting to resolve an up-level reference to a variable,; it uses the nesting structure of DWARF to determine which subroutine is the; lexical parent and the* ``DW_AT_static_link`` *value to identify the; appropriate active frame of the parent. It can then attempt to find the; reference within the context of the parent.*. .. note::. The following new attributes are added. 4. For languages that are implemented using a SIMT execution model, a; ``DW_TAG_subprogram``, ``DW_TAG_inlined_subroutine``, or; ``DW_TAG_entry_point`` debugger information entry may have a; ``DW_AT_LLVM_lanes`` attribute whose value is an integer constant that is; the number of source language threads of execution per target architecture; thread. *For example, a compiler may map source language threads of execution onto; lanes of a target architecture thread using a SIMT execution model.*. It is the static number of source language threads of execution per target; architecture thread. It is not the dynamic number of source language threads; of execution with which the target architecture thread was initiated, for; example, due",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:160911,variab,variable,160911,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['variab'],['variable']
Modifiability,"tion(generator); (std::normal_distribution<double>::result_type) -1.086818e+00; root [4] distribution(generator); (std::normal_distribution<double>::result_type) 6.842899e-01; ```; Impressive isn't it?. ## ROOT as function plotter ##; Using one of ROOT's powerful classes, here `TF1` [^2], will allow us to; display a function of one variable, *x*. Try the following:. ``` {.cpp}; root [11] TF1 f1(""f1"",""sin(x)/x"",0.,10.);; root [12] f1.Draw();; ```. `f1` is an instance of a TF1 class, the arguments are used; in the constructor; the first one of type string is a name to be entered; in the internal ROOT memory management system, the second string type; parameter defines the function, here `sin(x)/x`, and the two parameters; of type double define the range of the variable *x*. The `Draw()`; method, here without any parameters, displays the function in a window; which should pop up after you typed the above two lines. A slightly extended version of this example is the definition of a; function with parameters, called `[0]`, `[1]` and so on in the ROOT; formula syntax. We now need a way to assign values to these parameters;; this is achieved with the method; `SetParameter(<parameter_number>,<parameter_value>)` of class `TF1`.; Here is an example:. ``` {.cpp}; root [13] TF1 f2(""f2"",""[0]*sin([1]*x)/x"",0.,10.);; root [14] f2.SetParameter(0,1);; root [15] f2.SetParameter(1,1);; root [16] f2.Draw();; ```. Of course, this version shows the same results as the initial one. Try; playing with the parameters and plot the function again. The class `TF1`; has a large number of very useful methods, including integration and; differentiation. To make full use of this and other ROOT classes, visit; the documentation on the Internet under; <https://root.cern/doc/master/>. Formulae in ROOT; are evaluated using the class `TFormula`, so also look up the relevant; class documentation for examples, implemented functions and syntax. You should definitely download this guide to your own system to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/ROOT_as_calculator.md:3851,extend,extended,3851,documentation/primer/ROOT_as_calculator.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/ROOT_as_calculator.md,1,['extend'],['extended']
Modifiability,"tion, it is necessary for; regression. The inverse transformation of the normalization; transformation has been implemented. Started to extend the variable transformations to the; regression targets as well. MethodCuts now produces the 'optimal-cut' histograms needed; by macro mvaeffs.C. (macro 5a of TMVAGui.C); ; MsgLogger can be silenced in order to prevent excess output; during boosting. Third dataset type added centrally (Training, Validation; and Testing). The validation data is split off the original; training data set. Update of GUI and other Macros according to the new; features of PDF and the addition of MethodBoost.; ; Updates in TMVA 4.0.1. ""Spectator"" variables can be defined now which are computed; just as the input variables and which are written out into the; TestTree, but which don't participate in any MVA calculation; (useful for correlation studies).; ; New booking option ""IgnoreNegWeightsInTraining"" to test the; effect of events with negative weights on the training. This is; especially useful for methods, which do not properly deal with; such events. Note that this new option is not available for all; methods (a training interrupt is issued if not available). ; Bug fixes:. Fixed regression bug in VariableNormalizeTransform (Use; number of targets from Event instead of DataSet); ; Fixed Multitarget-Regression in PDEFoam, foam dimensions; were miscalculated. Added writing of targets to the weight files in regression; mode to fix problems in RegressionApplication. Added missing standard C++ header files missing to some; classes, which lead to compilation failures on some; architectures (thanks to Lucian Ancu, Nijmegen, for reporting; these). Added checks for unused options to Factory and; DataSetFactory configuration options interpretation. Will now; complain if wrong option labels are used. Fixed standard creation of correlation matrix plots. Fixed internal mapping problem giving a fatal error message; when destroying and recreating the Factory. ; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:7219,config,configuration,7219,tmva/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html,1,['config'],['configuration']
Modifiability,"tion, the ``Summary`` entry will look like:. .. code-block:: text. function: (module: ^0, flags: (linkage: external, notEligibleToImport: 0, live: 0, dsoLocal: 0), insts: 2[, FuncFlags]?[, Calls]?[, TypeIdInfo]?[, Params]?[, Refs]?. The ``module`` field includes the summary entry id for the module containing; this definition, and the ``flags`` field contains information such as; the linkage type, a flag indicating whether it is legal to import the; definition, whether it is globally live and whether the linker resolved it; to a local definition (the latter two are populated during the thin link).; The ``insts`` field contains the number of IR instructions in the function.; Finally, there are several optional fields: :ref:`FuncFlags<funcflags_summary>`,; :ref:`Calls<calls_summary>`, :ref:`TypeIdInfo<typeidinfo_summary>`,; :ref:`Params<params_summary>`, :ref:`Refs<refs_summary>`. .. _variable_summary:. Global Variable Summary; ^^^^^^^^^^^^^^^^^^^^^^^. If the global value is a variable, the ``Summary`` entry will look like:. .. code-block:: text. variable: (module: ^0, flags: (linkage: external, notEligibleToImport: 0, live: 0, dsoLocal: 0)[, Refs]?. The variable entry contains a subset of the fields in a; :ref:`function summary <function_summary>`, see the descriptions there. .. _alias_summary:. Alias Summary; ^^^^^^^^^^^^^. If the global value is an alias, the ``Summary`` entry will look like:. .. code-block:: text. alias: (module: ^0, flags: (linkage: external, notEligibleToImport: 0, live: 0, dsoLocal: 0), aliasee: ^2). The ``module`` and ``flags`` fields are as described for a; :ref:`function summary <function_summary>`. The ``aliasee`` field; contains a reference to the global value summary entry of the aliasee. .. _funcflags_summary:. Function Flags; ^^^^^^^^^^^^^^. The optional ``FuncFlags`` field looks like:. .. code-block:: text. funcFlags: (readNone: 0, readOnly: 0, noRecurse: 0, returnDoesNotAlias: 0, noInline: 0, alwaysInline: 0, noUnwind: 1, mayThrow: 0, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:342393,variab,variable,342393,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variable']
Modifiability,"tion-description-operations`) operation is added; to allow the address space of the address held in a register to be specified. Similarly, ``DW_OP_implicit_pointer`` treats its implicit pointer value as being; in the default address space. A ``DW_OP_LLVM_aspace_implicit_pointer``; (:ref:`amdgpu-dwarf-implicit-location-description-operations`) operation is; added to allow the address space to be specified. Almost all uses of addresses in DWARF are limited to defining location; descriptions, or to be dereferenced to read memory. The exception is; ``DW_CFA_val_offset`` which uses the address to set the value of a register. In; order to support address spaces, the CFA DWARF expression is defined to be a; memory location description. This allows it to specify an address space which is; used to convert the offset address back to an address in that address space. See; :ref:`amdgpu-dwarf-call-frame-information`. This approach of extending memory location descriptions to support address; spaces, allows all existing DWARF Version 5 expressions to have the identical; semantics. It allows the compiler to explicitly specify the address space it is; using. For example, a compiler could choose to access private memory in a; swizzled manner when mapping a source language thread to the lane of a wavefront; in a SIMT manner. Or a compiler could choose to access it in an unswizzled; manner if mapping the same language with the wavefront being the thread. It also allows the compiler to mix the address space it uses to access private; memory. For example, for SIMT it can still spill entire vector registers in an; unswizzled manner, while using a swizzled private memory for SIMT variable; access. This approach also allows memory location descriptions for different address; spaces to be combined using the regular ``DW_OP_*piece`` operations. Location descriptions are an abstraction of storage. They give freedom to the; consumer on how to implement them. They allow the address space to enc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:21858,extend,extending,21858,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['extend'],['extending']
Modifiability,"tion. ; * New Deep Neural Network. Three different versions are available, which can be selected with the 'Architecture' option. See also the tutorial`tmva/TMVAClassification.C` for using the new DNN.; * `Architecture=STANDARD` to select the earlier version.; * `Architecture=CPU` to select the newer version for CPU, but designed also for GPU and optimized for speed and with multi-class support. ; * `Architecture=GPU` to select the newer GPU version. Requires configuration of ROOT with CUDA or OpenCL enabled. ; * Support for Cross Validation (see tutorial `tmva/TMVACrossValidation` as an example).; * Support for Hyper-Parameter tuning for BDT and SVM methods.; * New Variable Importance algorithm independent of the MVA method.; * New Loss Function class for regression.; * Improvements in the SVM method: new kernel functions.; * New `ROCCurve` class. ; * New interface to Keras (PyKeras) available in the PyMVA library.; * Support for Jupyter notebooks; * Support for all the functionality available in GUI: preprocessing, variable correlations, classifier output.; * New classifier visualization for BDT, ANN and DNN.; * Interactive training for all methods. ## 2D Graphics Libraries. * In `TColor::SetPalette`, make sure the high quality palettes are defined; only once taking care of transparency. Also `CreateGradientColorTable` has been; simplified.; * New fast constructor for `TColor` avoiding to call `gROOT->GetColor()`. The; normal constructor generated a big slow down when creating a Palette with; `CreateGradientColorTable`.; * In `CreateGradientColorTable` we do not need anymore to compute the highest; color index.; * In `TGraphPainter`, when graphs are painted with lines, they are split into; chunks of length `fgMaxPointsPerLine`. This allows to paint line with an ""infinite""; number of points. In some case this ""chunks painting"" technic may create artefacts; at the chunk's boundaries. For instance when zooming deeply in a PDF file. To avoid; this effect it might be nec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:13631,variab,variable,13631,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['variab'],['variable']
Modifiability,"tion. A; retainable object pointer type is **weak-unavailable** if; is a pointer to an (optionally protocol-qualified) Objective-C class ``T`` where; ``T`` or one of its superclasses has the ``objc_arc_weak_reference_unavailable``; attribute. A program is ill-formed if it applies the ``__weak`` ownership; qualifier to a weak-unavailable type or if the value operand of a weak; assignment operation has a weak-unavailable type. .. _arc.ownership.restrictions.autoreleasing:. Storage duration of ``__autoreleasing`` objects; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. A program is ill-formed if it declares an ``__autoreleasing`` object of; non-automatic storage duration. A program is ill-formed if it captures an; ``__autoreleasing`` object in a block or, unless by reference, in a C++11; lambda. .. admonition:: Rationale. Autorelease pools are tied to the current thread and scope by their nature.; While it is possible to have temporary objects whose instance variables are; filled with autoreleased objects, there is no way that ARC can provide any; sort of safety guarantee there. It is undefined behavior if a non-null pointer is assigned to an; ``__autoreleasing`` object while an autorelease pool is in scope and then that; object is read after the autorelease pool's scope is left. .. _arc.ownership.restrictions.conversion.indirect:. Conversion of pointers to ownership-qualified types; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. A program is ill-formed if an expression of type ``T*`` is converted,; explicitly or implicitly, to the type ``U*``, where ``T`` and ``U`` have; different ownership qualification, unless:. * ``T`` is qualified with ``__strong``, ``__autoreleasing``, or; ``__unsafe_unretained``, and ``U`` is qualified with both ``const`` and; ``__unsafe_unretained``; or; * either ``T`` or ``U`` is ``cv void``, where ``cv`` is an optional sequence; of non-ownership qualifiers; or; * the conversion is requested with a ``reinterpret_cast`` in Objective-C++;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:43003,variab,variables,43003,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['variab'],['variables']
Modifiability,"tion. To fit a histogram with a predefined function, simply pass the name of; the function in the first parameter of `TH1::Fit`. For example,; this line fits histogram object `hist` with a Gaussian. ``` {.cpp}; root[] hist.Fit(""gaus"");; ```. The initial parameter values (and eventual limits) for pre-defined functions are set; automatically. For overriding the default limits values use the fit option `B`. The list of pre-defined functions that can be used with the `Fit` method is the following:. - ""`gaus`"" Gaussian function with 3 parameters:; `f(x) = p0*exp(-0.5*((x-p1)/p2)^2)`. - ""`expo`""An Exponential with 2 parameters: `f(x) = exp(p0+p1*x)`. - ""`pol`*`N`*"" A polynomial of degree *N*, where N is a number between 0 and 9:; `f(x) = p0 + p1*x + p2*x2 +...`. - ""`chebyshev`*`N`*"" A Chebyshev polynomial of degree *N*, where N is a number between 0 and 9:; `f(x) = p0 + p1*x + p2*(2*x2-1) +...`. - ""`landau`"" Landau function with mean and sigma. This function has; been adapted from the `CERNLIB` routine `G110 denlan` (see `TMath::Landau`). - ""`gausn`"" Normalized form of the gaussian function with 3 parameters; `f(x) = p0*exp(-0.5*((x-p1)/p2)^2)/(p2 *sqrt(2PI))`. ### Creating User-Defined Functions (TF1). You can create a **`TF1`** object and use it in the call the; `TH1::Fit`. The parameter in to the `Fit` method is the NAME of; the **`TF1`** object. There are three ways to create a **`TF1`**. - Using C++ expression using x with a fixed set of operators and; functions defined in **`TFormula`**. - Same as first one, with parameters. - Using a function that you have defined. This can be a free function or; a functor object or a particular member function of a class. #### Creating a TF1 with a Formula. Let's look at the first case. Here we call the **`TF1`** constructor; by giving it the formula: `sin(x)/x`. ``` {.cpp}; root[] TF1 *f1 = new TF1(""f1"",""sin(x)/x"",0,10); ```. You can also use a **`TF1`** object in the constructor of another; **`TF1`**. ``` {.cpp}; root[] TF1 *f2 ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:5361,adapt,adapted,5361,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['adapt'],['adapted']
Modifiability,"tion:: -show-region-summary. Show statistics for all regions. Defaults to true. .. option:: -show-branch-summary. Show statistics for all branch conditions. Defaults to true. .. option:: -show-mcdc-summary. Show MC/DC statistics. Defaults to false. .. option:: -show-functions. Show coverage summaries for each function. Defaults to false. .. option:: -show-instantiation-summary. Show statistics for all function instantiations. Defaults to false. .. option:: -ignore-filename-regex=<PATTERN>. Skip source code files with file paths that match the given regular expression. .. option:: -compilation-dir=<dir>. Directory used as a base for relative coverage mapping paths. Only applicable; when binaries have been compiled with one of `-fcoverage-prefix-map`; `-fcoverage-compilation-dir`, or `-ffile-compilation-dir`. .. option:: -debuginfod. Attempt to look up coverage mapping from objects using debuginfod. This is; attempted by default for binary IDs present in the profile but not provided on; the command line, so long as debuginfod is compiled in and configured via; DEBUGINFOD_URLS. .. option:: -debug-file-directory=<dir>. Provides a directory to search for objects corresponding to binary IDs in the; profile. .. option:: -check-binary-ids. Fail if an object file cannot be found for a binary ID present in the profile,; neither on the command line nor via binary ID lookup. .. program:: llvm-cov export. .. _llvm-cov-export:. EXPORT COMMAND; --------------. SYNOPSIS; ^^^^^^^^. :program:`llvm-cov export` [*options*] -instr-profile *PROFILE* [*BIN*] [*-object BIN*]... [*-sources*] [*SOURCE*]... DESCRIPTION; ^^^^^^^^^^^. The :program:`llvm-cov export` command exports coverage data of the binaries; *BIN*... using the profile data *PROFILE* in either JSON or lcov trace file; format. When exporting JSON, the regions, functions, branches, expansions, and; summaries of the coverage data will be exported. When exporting an lcov trace; file, the line-based coverage, branch coverage, and s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-cov.rst:15984,config,configured,15984,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-cov.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-cov.rst,1,['config'],['configured']
Modifiability,"tion; * Make the notebooks available in the [tutorials section of the class documentation](https://root.cern/doc/master/group__Tutorials.html). ## Build, Configuration and Testing Infrastructure; - `root-config` does not suppress deprecation warnings (-Wno-deprecated-declarations) anymore. This means compilers will now diagnose the use of deprecated interfaces in user code.; - Added new 'builtin_vc' option to bundle a version of Vc within ROOT.; The default is OFF, however if the Vc package is not found in the system the option is switched to; ON if the option 'vc' option is ON.; - Many improvements (provided by Mattias Ellert):; - Build RFIO using dpm libraries if castor libraries are not available; - Add missing glib header path in GFAL module for version > 2; - Search also for globus libraries wouthout the flavour in the name; - Add missing io/hdfs/CMakeLists.txt; - net/globusauth has no installed headers - remove ROOT_INSTALL_HEADERS(); - Add missing pieces to the cmake config that are built by configure: bin/pq2, bin/rootd, bin/xpdtest, initd and xinitd start-up scripts; - Only link to libgfortranbegin.a when it is provided by the compiler; - Don't remove -Wall without also removing -Werror=*; - Don't overwrite the initial value of CMAKE_Fortran_FLAGS. Inconsistent case variant of CMAKE_Fortran_FLAGS; - Use the same sonames in cmake as in configure; - Allow building for ppc64 as well as ppc64le; - Add build instructions for 32 bit ARM; - Add build instructions for System Z (s390 and s390x); - Make sure that the roots wrapper can be executed; - Move gl2ps.h to its own subdir; - Added new 'builtin-unuran' option (provided by Mattias Ellert); - Added new 'builtin-gl2ps' option (provided by Mattias Ellert); - Added new 'macos_native' option (only for MacOS) to disable looking for binaries, libraires and headers for dependent; packages at locations other than native MacOS installations. Needed when wanting to ignore packages from Fink, Brew or Ports.; - Added new 'c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:29012,config,config,29012,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,2,['config'],"['config', 'configure']"
Modifiability,"tion; files are loaded first. The command line option ``--config=`` can be used to specify explicit; configuration files in a Clang invocation. If the option is used multiple times,; all specified files are loaded, in order. For example:. ::. clang --config=/home/user/cfgs/testing.txt; clang --config=debug.cfg --config=runtimes.cfg. If the provided argument contains a directory separator, it is considered as; a file path, and options are read from that file. Otherwise the argument is; treated as a file name and is searched for sequentially in the directories:. - user directory,; - system directory,; - the directory where Clang executable resides. Both user and system directories for configuration files are specified during; clang build using CMake parameters, ``CLANG_CONFIG_FILE_USER_DIR`` and; ``CLANG_CONFIG_FILE_SYSTEM_DIR`` respectively. The first file found is used.; It is an error if the required file cannot be found. The default configuration files are searched for in the same directories; following the rules described in the next paragraphs. Loading default; configuration files can be disabled entirely via passing; the ``--no-default-config`` flag. First, the algorithm searches for a configuration file named; ``<triple>-<driver>.cfg`` where `triple` is the triple for the target being; built for, and `driver` is the name of the currently used driver. The algorithm; first attempts to use the canonical name for the driver used, then falls back; to the one found in the executable name. The following canonical driver names are used:. - ``clang`` for the ``gcc`` driver (used to compile C programs); - ``clang++`` for the ``gxx`` driver (used to compile C++ programs); - ``clang-cpp`` for the ``cpp`` driver (pure preprocessor); - ``clang-cl`` for the ``cl`` driver; - ``flang`` for the ``flang`` driver; - ``clang-dxc`` for the ``dxc`` driver. For example, when calling ``x86_64-pc-linux-gnu-clang-g++``,; the driver will first attempt to use the configuration file named:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:31955,config,configuration,31955,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['config'],['configuration']
Modifiability,"tionThatReturnsIntWithCharArg functionPointer;; ^ pointerToFunctionThatReturnsIntWithCharArg (float x) { return functionPointer; }. and:. .. code-block:: c. ^ int ((*)(float x))(char) { return functionPointer; }. are equivalent expressions, as is:. .. code-block:: c. ^(float x) { return functionPointer; }. [returnfunctionptr.c]. The compound statement body establishes a new lexical scope within; that of its parent. Variables used within the scope of the compound; statement are bound to the Block in the normal manner with the; exception of those in automatic (stack) storage. Thus one may access; functions and global variables as one would expect, as well as static; local variables. [testme]. Local automatic (stack) variables referenced within the compound; statement of a Block are imported and captured by the Block as const; copies. The capture (binding) is performed at the time of the Block; literal expression evaluation. The compiler is not required to capture a variable if it can prove; that no references to the variable will actually be evaluated.; Programmers can force a variable to be captured by referencing it in a; statement at the beginning of the Block, like so:. .. code-block:: c. (void) foo;. This matters when capturing the variable has side-effects, as it can; in Objective-C or C++. The lifetime of variables declared in a Block is that of a function;; each activation frame contains a new copy of variables declared within; the local scope of the Block. Such variable declarations should be; allowed anywhere [testme] rather than only when C99 parsing is; requested, including for statements. [testme]. Block literal expressions may occur within Block literal expressions; (nest) and all variables captured by any nested blocks are implicitly; also captured in the scopes of their enclosing Blocks. A Block literal expression may be used as the initialization value for; Block variables at global or local static scope. The Invoke Operator; ===================. Block",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst:4804,variab,variable,4804,interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,2,['variab'],['variable']
Modifiability,"tional CMake options (i.e. -DCMAKE_INSTALL_PREFIX=<install path>)]; <path to llvm>. Options specified on the command line will override options in the cache files. The following cache files exist. Apple-stage1; ------------. The Apple stage1 cache configures a two stage build similar to how Apple builds; the clang shipped with Xcode. The build files generated from this invocation has; a target named ""stage2"" which performs an LTO build of clang. The Apple-stage2 cache can be used directly to match the build settings Apple; uses in shipping builds without doing a full bootstrap build. PGO; ---. The PGO CMake cache can be used to generate a multi-stage instrumented compiler.; You can configure your build directory with the following invocation of CMake:. cmake -G <generator> -C <path_to_clang>/cmake/caches/PGO.cmake <source dir>. After configuration the following additional targets will be generated:. stage2-instrumented:; Builds a stage1 x86 compiler, runtime, and required tools (llvm-config,; llvm-profdata) then uses that compiler to build an instrumented stage2 compiler. stage2-instrumented-generate-profdata:; Depends on ""stage2-instrumented"" and will use the instrumented compiler to; generate profdata based on the training files in <clang>/utils/perf-training. stage2:; Depends on ""stage2-instrumented-generate-profdata"" and will use the stage1; compiler with the stage2 profdata to build a PGO-optimized compiler. stage2-check-llvm:; Depends on stage2 and runs check-llvm using the stage3 compiler. stage2-check-clang:; Depends on stage2 and runs check-clang using the stage3 compiler. stage2-check-all:; Depends on stage2 and runs check-all using the stage3 compiler. stage2-test-suite:; Depends on stage2 and runs the test-suite using the stage3 compiler (requires; in-tree test-suite). 3-stage; -------. This cache file can be used to generate a 3-stage clang build. You can configure; using the following CMake command:. cmake -C <path to clang>/cmake/caches/3-stage.cmake ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/cmake/caches/README.txt:1277,config,config,1277,interpreter/llvm-project/clang/cmake/caches/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/cmake/caches/README.txt,1,['config'],['config']
Modifiability,"tions of a; :ref:`lexical block <DILexicalBlock>`. The ``file:`` field can be changed to; indicate textual inclusion, or the ``discriminator:`` field can be used to; discriminate between control flow within a single block in the source language. .. code-block:: text. !0 = !DILexicalBlock(scope: !3, file: !4, line: 7, column: 35); !1 = !DILexicalBlockFile(scope: !0, file: !4, discriminator: 0); !2 = !DILexicalBlockFile(scope: !0, file: !4, discriminator: 1). .. _DILocation:. DILocation; """""""""""""""""""". ``DILocation`` nodes represent source debug locations. The ``scope:`` field is; mandatory, and points at an :ref:`DILexicalBlockFile`, an; :ref:`DILexicalBlock`, or an :ref:`DISubprogram`. .. code-block:: text. !0 = !DILocation(line: 2900, column: 42, scope: !1, inlinedAt: !2). .. _DILocalVariable:. DILocalVariable; """""""""""""""""""""""""""""". ``DILocalVariable`` nodes represent local variables in the source language. If; the ``arg:`` field is set to non-zero, then this variable is a subprogram; parameter, and it will be included in the ``retainedNodes:`` field of its; :ref:`DISubprogram`. .. code-block:: text. !0 = !DILocalVariable(name: ""this"", arg: 1, scope: !3, file: !2, line: 7,; type: !3, flags: DIFlagArtificial); !1 = !DILocalVariable(name: ""x"", arg: 2, scope: !4, file: !2, line: 7,; type: !3); !2 = !DILocalVariable(name: ""y"", scope: !5, file: !2, line: 7, type: !3). .. _DIExpression:. DIExpression; """""""""""""""""""""""". ``DIExpression`` nodes represent expressions that are inspired by the DWARF; expression language. They are used in :ref:`debug intrinsics<dbg_intrinsics>`; (such as ``llvm.dbg.declare`` and ``llvm.dbg.value``) to describe how the; referenced LLVM variable relates to the source language variable. Debug; intrinsics are interpreted left-to-right: start by pushing the value/address; operand of the intrinsic onto a stack, then repeatedly push and evaluate; opcodes from the DIExpression until the final variable description is produced. The current supported opcode vocabulary",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:260445,variab,variable,260445,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variable']
Modifiability,"tions"");. StringMap<cl::Option*> &Map = cl::getRegisteredOptions();. //Unhide useful option and put it in a different category; assert(Map.count(""print-all-options"") > 0);; Map[""print-all-options""]->setHiddenFlag(cl::NotHidden);; Map[""print-all-options""]->setCategory(AnotherCategory);. //Hide an option we don't want to see; assert(Map.count(""enable-no-infs-fp-math"") > 0);; Map[""enable-no-infs-fp-math""]->setHiddenFlag(cl::Hidden);. //Change --version to --show-version; assert(Map.count(""version"") > 0);; Map[""version""]->setArgStr(""show-version"");. //Change --help description; assert(Map.count(""help"") > 0);; Map[""help""]->setDescription(""Shows help"");. cl::ParseCommandLineOptions(argc, argv, ""This is a small program to demo the LLVM CommandLine API"");; ...; }. .. _cl::ParseCommandLineOptions:. The ``cl::ParseCommandLineOptions`` function; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::ParseCommandLineOptions`` function is designed to be called directly; from ``main``, and is used to fill in the values of all of the command line; option variables once ``argc`` and ``argv`` are available. The ``cl::ParseCommandLineOptions`` function requires two parameters (``argc``; and ``argv``), but may also take an optional third parameter which holds; `additional extra text`_ to emit when the ``-help`` option is invoked. The ``cl::SetVersionPrinter`` function; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``cl::SetVersionPrinter`` function is designed to be called directly from; ``main`` and *before* ``cl::ParseCommandLineOptions``. Its use is optional. It; simply arranges for a function to be called in response to the ``--version``; option instead of having the ``CommandLine`` library print out the usual version; string for LLVM. This is useful for programs that are not part of LLVM but wish; to use the ``CommandLine`` facilities. Such programs should just define a small; function that takes no arguments and returns ``void`` and that prints out; whatever version information i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:53203,variab,variables,53203,interpreter/llvm-project/llvm/docs/CommandLine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst,1,['variab'],['variables']
Modifiability,"tiple times or widened; according to selected VF. :VPValue:; The base of VPlan's def-use relations class hierarchy. When instantiated, it; models a constant or a live-in Value in VPlan. It has users, which are of type; VPUser, but no operands. :VPUser:; A VPUser represents an entity that uses a number of VPValues as operands.; VPUser is similar in some aspects to LLVM's User class. :VPDef:; A VPDef represents an entity that defines zero, one or multiple VPValues.; It is used to model the fact that recipes in VPlan can define multiple; VPValues. :VPInstruction:; A VPInstruction is both a VPRecipe and a VPUser. It models a single; VPlan-level instruction to be generated if the VPlan is executed, including; its opcode and possibly additional characteristics. It is the basis for; writing instruction-level analyses and optimizations in VPlan as creating,; replacing or moving VPInstructions record both def-use and scheduling; decisions. VPInstructions also extend LLVM IR's opcodes with idiomatic; operations that enrich the Vectorizer's semantics. :VPTransformState:; Stores information used for generating output IR, passed from; LoopVectorizationPlanner to its selected VPlan for execution, and used to pass; additional information down to VPBlocks and VPRecipes. The Planning Process and VPlan Roadmap; ======================================. Transforming the Loop Vectorizer to use VPlan follows a staged approach. First,; VPlan is used to record the final vectorization decisions, and to execute them:; the Hierarchical CFG models the planned control-flow, and Recipes capture; decisions taken inside basic-blocks. Next, VPlan will be used also as the basis; for taking these decisions, effectively turning them into a series of; VPlan-to-VPlan algorithms. Finally, VPlan will support the planning process; itself including cost-based analyses for making these decisions, to fully; support compositional and iterative decision making. Some decisions are local to an instruction in the l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:7768,extend,extend,7768,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,1,['extend'],['extend']
Modifiability,"tive first 4 letters of the corresponding class name; (e.g. ""`tubs`"" will match **`TGeoTubeSeg`**, ""`bbox`"" will match; **`TGeoBBox`**); - `nmed:` the medium number. This will create a special volume that will not be directly used in the; geometry, but whenever positioned will require a list of actual; parameters for the current shape that will be created in this process.; Such volumes having shape parameters known only when used have to be; positioned only with **`TGeoManager::Node()` method (see ‘Creating and; Positioning Volumes').**. Other case when shape parameterizations are quite useful is scaling; geometry structures. Imagine that we would like to enlarge/shrink a; detector structure on one or more axes. This happens quite often in real; life and is handled by ""fitting mother"" parameters. This is accomplished; by defining shapes with one or more invalid (negative) parameters. For; instance, defining a box having `dx=10.`, `dy=10.`, and `dz=-1` will not; generate an error but will be interpreted in a different way: A special; volume **`TGeoVolumeMulti`** will be created. Whenever positioned inside; a mother volume, this will create a normal **`TGeoVolume`** object; having as shape a box with `dz` fitting the corresponding `dz `of the; mother shape. Generally, this type of parameterization is used when; positioning volumes in containers having a matching shape, but it works; also for most reasonable combinations. \defgroup Tubes Tubes; \ingroup Shapes_classes; Tubes have Z as their symmetry axis. \defgroup Cones Cones; \ingroup Shapes_classes; Conical tube classes. \defgroup Trapezoids Trapezoids; \ingroup Shapes_classes; In general, we will call trapezoidal shapes having 8 vertices and up to; 6 trapezoid faces. Besides that, two of the opposite faces are parallel; to XY plane and are positioned at ` dZ`. Since general trapezoids are; seldom used in detector geometry descriptions, there are several; primitives implemented in the modeller for particular cases. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md:10339,parameteriz,parameterization,10339,geom/geom/doc/shapes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md,1,['parameteriz'],['parameterization']
Modifiability,"tl;libcxx;compiler-rt;openmp;llvm-libgcc""); set(LLVM_ENABLE_RUNTIMES """" CACHE STRING; ""Semicolon-separated list of runtimes to build, or \""all\"" (${LLVM_DEFAULT_RUNTIMES}). Supported runtimes are ${LLVM_SUPPORTED_RUNTIMES}.""); if(LLVM_ENABLE_RUNTIMES STREQUAL ""all""); set(LLVM_ENABLE_RUNTIMES ${LLVM_DEFAULT_RUNTIMES}); endif(); foreach(proj IN LISTS LLVM_ENABLE_RUNTIMES); if (NOT ""${proj}"" IN_LIST LLVM_SUPPORTED_RUNTIMES); message(FATAL_ERROR ""Runtime \""${proj}\"" is not a supported runtime. Supported runtimes are: ${LLVM_SUPPORTED_RUNTIMES}""); endif(); endforeach(). if (""libc"" IN_LIST LLVM_ENABLE_RUNTIMES); # To build the libc runtime, we need to be able to build few libc build; # tools from the ""libc"" project. So, we add it to the list of enabled; # projects.; if (NOT ""libc"" IN_LIST LLVM_ENABLE_PROJECTS); message(STATUS ""Enabling libc project to build libc build tools""); list(APPEND LLVM_ENABLE_PROJECTS ""libc""); endif(); endif(). # LLVM_ENABLE_PROJECTS_USED is `ON` if the user has ever used the; # `LLVM_ENABLE_PROJECTS` CMake cache variable. This exists for; # several reasons:; #; # * As an indicator that the `LLVM_ENABLE_PROJECTS` list is now the single; # source of truth for which projects to build. This means we will ignore user; # supplied `LLVM_TOOL_<project>_BUILD` CMake cache variables and overwrite; # them.; #; # * The case where the user previously had `LLVM_ENABLE_PROJECTS` set to a; # non-empty list but now the user wishes to disable building all other projects; # by setting `LLVM_ENABLE_PROJECTS` to an empty string. In that case we still; # need to set the `LLVM_TOOL_${upper_proj}_BUILD` variables so that we disable; # building all the projects that were previously enabled.; set(LLVM_ENABLE_PROJECTS_USED OFF CACHE BOOL """"); mark_as_advanced(LLVM_ENABLE_PROJECTS_USED). if (LLVM_ENABLE_PROJECTS_USED OR NOT LLVM_ENABLE_PROJECTS STREQUAL """"); set(LLVM_ENABLE_PROJECTS_USED ON CACHE BOOL """" FORCE); foreach(proj ${LLVM_KNOWN_PROJECTS} ${LLVM_EXTERNAL_PROJECTS})",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt:7945,variab,variable,7945,interpreter/llvm-project/llvm/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/CMakeLists.txt,1,['variab'],['variable']
Modifiability,"to *A : D.attrs()) for (auto *A : D.attrs()) {; handleAttr(A); handleAttr(A);; }; }. do vs. do {; --i; --i;; while (i); } while (i);. .. _InsertNewlineAtEOF:. **InsertNewlineAtEOF** (``Boolean``) :versionbadge:`clang-format 16` :ref:`¶ <InsertNewlineAtEOF>`; Insert a newline at end of file if missing. .. _InsertTrailingCommas:. **InsertTrailingCommas** (``TrailingCommaStyle``) :versionbadge:`clang-format 11` :ref:`¶ <InsertTrailingCommas>`; If set to ``TCS_Wrapped`` will insert trailing commas in container; literals (arrays and objects) that wrap across multiple lines.; It is currently only available for JavaScript; and disabled by default ``TCS_None``.; ``InsertTrailingCommas`` cannot be used together with ``BinPackArguments``; as inserting the comma disables bin-packing. .. code-block:: c++. TSC_Wrapped:; const someArray = [; aaaaaaaaaaaaaaaaaaaaaaaaaa,; aaaaaaaaaaaaaaaaaaaaaaaaaa,; aaaaaaaaaaaaaaaaaaaaaaaaaa,; // ^ inserted; ]. Possible values:. * ``TCS_None`` (in configuration: ``None``); Do not insert trailing commas. * ``TCS_Wrapped`` (in configuration: ``Wrapped``); Insert trailing commas in container literals that were wrapped over; multiple lines. Note that this is conceptually incompatible with; bin-packing, because the trailing comma is used as an indicator; that a container should be formatted one-per-line (i.e. not bin-packed).; So inserting a trailing comma counteracts bin-packing. .. _IntegerLiteralSeparator:. **IntegerLiteralSeparator** (``IntegerLiteralSeparatorStyle``) :versionbadge:`clang-format 16` :ref:`¶ <IntegerLiteralSeparator>`; Format integer literal separators (``'`` for C++ and ``_`` for C#, Java,; and JavaScript). Nested configuration flags:. Separator format of integer literals of different bases. If negative, remove separators. If ``0``, leave the literal as is. If; positive, insert separators between digits starting from the rightmost; digit. For example, the config below will leave separators in binary literals; alone, insert separat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:76758,config,configuration,76758,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['config'],['configuration']
Modifiability,"to 0xa0463443. Due to ``7`` being unequal to ``5 + 1`` and ``a0463443`` being unequal to; ``a0463440 + 7``. A numeric variable can also be defined to the result of a numeric expression,; in which case the numeric expression constraint is checked and if verified the; variable is assigned to the value. The unified syntax for both checking a; numeric expression and capturing its value into a numeric variable is thus; ``[[#%<fmtspec>,<NUMVAR>: <constraint> <expr>]]`` with each element as; described previously. One can use this syntax to make a testcase more; self-describing by using variables instead of values:. .. code-block:: gas. ; CHECK: mov r[[#REG_OFFSET:]], 0x[[#%X,FIELD_OFFSET:12]]; ; CHECK-NEXT: load r[[#]], [r[[#REG_BASE:]], r[[#REG_OFFSET]]]. which would match:. .. code-block:: gas. mov r4, 0xC; load r6, [r5, r4]. The ``--enable-var-scope`` option has the same effect on numeric variables as; on string variables. Important note: In its current implementation, an expression cannot use a; numeric variable defined earlier in the same CHECK directive. FileCheck Pseudo Numeric Variables; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Sometimes there's a need to verify output that contains line numbers of the; match file, e.g. when testing compiler diagnostics. This introduces a certain; fragility of the match file structure, as ""``CHECK:``"" lines contain absolute; line numbers in the same file, which have to be updated whenever line numbers; change due to text addition or deletion. To support this case, FileCheck expressions understand the ``@LINE`` pseudo; numeric variable which evaluates to the line number of the CHECK pattern where; it is found. This way match patterns can be put near the relevant test lines and include; relative line number references, for example:. .. code-block:: c++. // CHECK: test.cpp:[[# @LINE + 4]]:6: error: expected ';' after top level declarator; // CHECK-NEXT: {{^int a}}; // CHECK-NEXT: {{^ \^}}; // CHECK-NEXT: {{^ ;}}; int a. To support legacy us",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst:33507,variab,variable,33507,interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,1,['variab'],['variable']
Modifiability,"to a single line if the lambda is argument of a function. .. code-block:: c++. auto lambda = [](int x, int y) {; return x < y;; };; sort(a.begin(), a.end(), [](int x, int y) { return x < y; });. * ``SLS_All`` (in configuration: ``All``); Merge all lambdas fitting on a single line. .. code-block:: c++. auto lambda = [](int a) {};; auto lambda2 = [](int a) { return a; };. .. _AllowShortLoopsOnASingleLine:. **AllowShortLoopsOnASingleLine** (``Boolean``) :versionbadge:`clang-format 3.7` :ref:`¶ <AllowShortLoopsOnASingleLine>`; If ``true``, ``while (true) continue;`` can be put on a single; line. .. _AlwaysBreakAfterDefinitionReturnType:. **AlwaysBreakAfterDefinitionReturnType** (``DefinitionReturnTypeBreakingStyle``) :versionbadge:`clang-format 3.7` :ref:`¶ <AlwaysBreakAfterDefinitionReturnType>`; The function definition return type breaking style to use. This; option is **deprecated** and is retained for backwards compatibility. Possible values:. * ``DRTBS_None`` (in configuration: ``None``); Break after return type automatically.; ``PenaltyReturnTypeOnItsOwnLine`` is taken into account. * ``DRTBS_All`` (in configuration: ``All``); Always break after the return type. * ``DRTBS_TopLevel`` (in configuration: ``TopLevel``); Always break after the return types of top-level functions. .. _AlwaysBreakAfterReturnType:. **AlwaysBreakAfterReturnType** (``ReturnTypeBreakingStyle``) :versionbadge:`clang-format 3.8` :ref:`¶ <AlwaysBreakAfterReturnType>`; The function declaration return type breaking style to use. Possible values:. * ``RTBS_None`` (in configuration: ``None``); Break after return type automatically.; ``PenaltyReturnTypeOnItsOwnLine`` is taken into account. .. code-block:: c++. class A {; int f() { return 0; };; };; int f();; int f() { return 1; }. * ``RTBS_All`` (in configuration: ``All``); Always break after the return type. .. code-block:: c++. class A {; int; f() {; return 0;; };; };; int; f();; int; f() {; return 1;; }. * ``RTBS_TopLevel`` (in configuration: ``T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:32547,config,configuration,32547,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['config'],['configuration']
Modifiability,"to by the; AQL dispatch packet. The; kernarg memory is used to; pass arguments to the; kernel. * If the kernarg pointer in; the dispatch packet is NULL; then there are no kernel; arguments.; * If the kernarg pointer in; the dispatch packet is; not NULL and this value; is 0 then the kernarg; memory size is; unspecified.; * If the kernarg pointer in; the dispatch packet is; not NULL and this value; is not 0 then the value; specifies the kernarg; memory size in bytes. It; is recommended to provide; a value as it may be used; by CP to optimize making; the kernarg memory; visible to the kernel; code. 127:96 4 bytes Reserved, must be 0.; 191:128 8 bytes KERNEL_CODE_ENTRY_BYTE_OFFSET Byte offset (possibly; negative) from base; address of kernel; descriptor to kernel's; entry point instruction; which must be 256 byte; aligned.; 351:272 20 Reserved, must be 0.; bytes; 383:352 4 bytes COMPUTE_PGM_RSRC3 GFX6-GFX9; Reserved, must be 0.; GFX90A, GFX940; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx90a-table`.; GFX10-GFX11; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx10-gfx11-table`.; GFX12; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table`.; 415:384 4 bytes COMPUTE_PGM_RSRC1 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC1``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`.; 447:416 4 bytes COMPUTE_PGM_RSRC2 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC2``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc2-gfx6-gfx12-table`.; 458:448 7 bits *See separate bits below.* Enable the setup of the; SGPR user data registers; (see; :ref:`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:160333,config,configuration,160333,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['config'],['configuration']
Modifiability,"to call/access.; For now we will ignore this argument and use a standard optimization; pipeline. To do this we set up a FunctionPassManager, add some passes to it, run; it over every function in the module, and then return the mutated module. The; specific optimizations are the same ones used in `Chapter 4 <LangImpl04.html>`_; of the ""Implementing a language with LLVM"" tutorial series. Readers may visit; that chapter for a more in-depth discussion of these, and of IR optimization in; general. And that's it in terms of changes to KaleidoscopeJIT: When a module is added via; addModule the OptimizeLayer will call our optimizeModule function before passing; the transformed module on to the CompileLayer below. Of course, we could have; called optimizeModule directly in our addModule function and not gone to the; bother of using the IRTransformLayer, but doing so gives us another opportunity; to see how layers compose. It also provides a neat entry point to the *layer*; concept itself, because IRTransformLayer is one of the simplest layers that; can be implemented. .. code-block:: c++. // From IRTransformLayer.h:; class IRTransformLayer : public IRLayer {; public:; using TransformFunction = std::function<Expected<ThreadSafeModule>(; ThreadSafeModule, const MaterializationResponsibility &R)>;. IRTransformLayer(ExecutionSession &ES, IRLayer &BaseLayer,; TransformFunction Transform = identityTransform);. void setTransform(TransformFunction Transform) {; this->Transform = std::move(Transform);; }. static ThreadSafeModule; identityTransform(ThreadSafeModule TSM,; const MaterializationResponsibility &R) {; return TSM;; }. void emit(MaterializationResponsibility R, ThreadSafeModule TSM) override;. private:; IRLayer &BaseLayer;; TransformFunction Transform;; };. // From IRTransformLayer.cpp:. IRTransformLayer::IRTransformLayer(ExecutionSession &ES,; IRLayer &BaseLayer,; TransformFunction Transform); : IRLayer(ES), BaseLayer(BaseLayer), Transform(std::move(Transform)) {}. void IRTr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst:6421,layers,layers,6421,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,1,['layers'],['layers']
Modifiability,"to edit. #. Send a patch which adds your build worker and your builder to; `zorg <https://github.com/llvm/llvm-zorg>`_. Use the typical LLVM; `workflow <https://llvm.org/docs/Contributing.html#how-to-submit-a-patch>`_. * workers are added to ``buildbot/osuosl/master/config/workers.py``; * builders are added to ``buildbot/osuosl/master/config/builders.py``. Please make sure your builder name and its builddir are unique through the; file. All new builders should default to using the ""'collapseRequests': False""; configuration. This causes the builder to build each commit individually; and not merge build requests. To maximize quality of feedback to developers,; we *strongly prefer* builders to be configured not to collapse requests.; This flag should be removed only after all reasonable efforts have been; exhausted to improve build times such that the builder can keep up with; commit flow. It is possible to allow email addresses to unconditionally receive; notifications on build failure; for this you'll need to add an; ``InformativeMailNotifier`` to ``buildbot/osuosl/master/config/status.py``.; This is particularly useful for the staging buildmaster which is silent; otherwise. #. Send the buildbot-worker access name and the access password directly to; `Galina Kistanova <mailto:gkistanova@gmail.com>`_, and wait until she; lets you know that your changes are applied and buildmaster is; reconfigured. #. Make sure you can start the buildbot-worker and successfully connect; to the silent buildmaster. Then set up your buildbot-worker to start; automatically at the start up time. See the buildbot documentation; for help. You may want to restart your computer to see if it works. #. Check the status of your buildbot-worker on the `Waterfall Display (Staging); <http://lab.llvm.org/staging/#/waterfall>`_ to make sure it is; connected, and the `Workers Display (Staging); <http://lab.llvm.org/staging/#/workers>`_ to see if administrator; contact and worker information are correct. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst:6155,config,config,6155,interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,1,['config'],['config']
Modifiability,"to enable some very special treatments of the canvas operations.; We hope that this will become the default later. To compile ROOT, just do (for example on a debian Linux):. ```; ./configure linuxdeb2 --with-thread=/usr/lib/libpthread.so; gmake depend; gmake; ```. This configures and builds ROOT using `/usr/lib/libpthread.so` as the; `Pthread` library, and defines `R__THREAD`. This enables the thread specific treatment of *`gPad`*, and creates; `$ROOTSYS/lib/libThread.so.`. Note: The parameter linuxdeb2 has to be replaced with the appropriate; ROOT keyword for your platform. ### Classes. **`TThread`** class implements threads . The platform dependent; implementation is in the **`TThreadImp`** class and its descendant; classes (e.g. **`TPosixThread`** ). **`TMutex`** class implements `mutex` locks. A mutex is a mutually; exclusive lock. The platform dependent implementation is in the; **`TMutexImp`** class and its descendant classes (e.g.; **`TPosixMutex`**). **`TCondition`** class implements a condition variable. Use a condition; variable to signal threads. The platform dependent implementation is in; the **`TConditionImp`** and **`TPosixCondition`** classes . **`TSemaphore`** class implements a counting semaphore. Use a semaphore; to synchronize threads. The platform dependent implementation is in the; **`TMutexImp`** and **`TConditionImp`** classes. ### TThread for Pedestrians. To run a thread in ROOT, follow these steps:. 1. Initialization. Add these lines to your `rootlogon.C`:. ``` {.cpp}; {; ...; // The next line may be unnecessary on some platforms; gSystem->Load(""/usr/lib/libpthread.so"");; gSystem->Load(""$ROOTSYS/lib/libThread.so"");; ...; }; ```. This loads the library with the **`TThread`** class and the `pthread`; specific implementation file for `Posix` threads. 2. Coding. Define a function (e.g. `void* UserFun(void* UserArgs))` that should run; as a thread. The code for the examples is at the web site of the authors; (Jörn Adamczewski, Marc Hemberger). A",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md:3966,variab,variable,3966,documentation/users-guide/Threads.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md,1,['variab'],['variable']
Modifiability,"to expose the class as a new datatype of R, but it has to be alongside; the `ROOTR_MODULE(Module)` macro which allows you to create an internal R module and make the class wrapping; To do this you must use inside the `ROOTR_MODULE` braces the class `ROOT::R::class_<>` and specify; each constructor, attribute or method that the class to export has.; Then the macrodefinition `LOAD_ROOTR_MODULE(Module)` can load the module and the class in R's environment.; You can find a more clear instruction by looking at a example below in Functor section. ##DataFrames; DataFrame? is a very important datatype in R and in ROOTR we have a class to manipulate; dataframes called TRDataFrame, with a lot of very useful operators overloaded to work with TRDataFrame's objects; in a similar way that in the R environment but from c++ in ROOT.; Example:. Lets to create need data to play with dataframe features. ~~~{.cxx}; ////////////////////////; //creating variables//; ////////////////////////; TVectorD v1(3);; std::vector<Double_t> v2(3);; std::array<Int_t,3> v3{ {1,2,3} };; std::list<std::string> names;. //////////////////////; //assigning values//; //////////////////////; v1[0]=1;; v1[1]=2;; v1[2]=3;. v2[0]=0.101;; v2[1]=0.202;; v2[2]=0.303;. names.push_back(""v1"");; names.push_back(""v2"");; names.push_back(""v3"");. ROOT::R::TRInterface &r=ROOT::R::TRInterface::Instance();; ~~~; In R the dataframe have associate to every column a label, in ROOTR you can have the same label using the class ROOT::R::Label to create a TRDataFrame where you data; have a label associate. ~~~{.cxx}; /////////////////////////////////////////////////; //creating dataframe object with its labels//; /////////////////////////////////////////////////. ROOT::R::TRDataFrame df1(ROOT::R::Label[""var1""]=v1,ROOT::R::Label[""var2""]=v2,ROOT::R::Label[""var3""]=v3,ROOT::R::Label[""strings""]=names);. //////////////////////////////////////////////; //Passing dataframe to R's environment//; /////////////////////////////////////////////",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md:7874,variab,variables,7874,bindings/r/doc/users-guide/ROOTR_Users_Guide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md,1,['variab'],['variables']
Modifiability,"to other target; debug info formats such as STABS. It would also be reasonable to use debug information to feed profiling tools; for analysis of generated code, or, tools for reconstructing the original; source from generated code. .. _intro_debugopt:. Debug information and optimizations; -----------------------------------. An extremely high priority of LLVM debugging information is to make it interact; well with optimizations and analysis. In particular, the LLVM debug; information provides the following guarantees:. * LLVM debug information **always provides information to accurately read; the source-level state of the program**, regardless of which LLVM; optimizations have been run. :doc:`HowToUpdateDebugInfo` specifies how debug; info should be updated in various kinds of code transformations to avoid; breaking this guarantee, and how to preserve as much useful debug info as; possible. Note that some optimizations may impact the ability to modify the; current state of the program with a debugger, such as setting program; variables, or calling functions that have been deleted. * As desired, LLVM optimizations can be upgraded to be aware of debugging; information, allowing them to update the debugging information as they; perform aggressive optimizations. This means that, with effort, the LLVM; optimizers could optimize debug code just as well as non-debug code. * LLVM debug information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a pro",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:4386,variab,variables,4386,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['variab'],['variables']
Modifiability,"to prohibit ARC from observably extending the; lifetime of a retainable object, other than as specified in this; document. Together with the rule limiting the transformation of; releases, this rule requires ARC to eliminate retains and release; only in pairs. ARC's power to reorder the destruction of objects is critical to its; ability to do any optimization, for essentially the same reason that; it must retain the power to decrease the lifetime of an object.; Unfortunately, while it's generally poor style for the destruction; of objects to have arbitrary side-effects, it's certainly possible.; Hence the caveat. .. _arc.optimization.precise:. Precise lifetime semantics; --------------------------. In general, ARC maintains an invariant that a retainable object pointer held in; a ``__strong`` object will be retained for the full formal lifetime of the; object. Objects subject to this invariant have :arc-term:`precise lifetime; semantics`. By default, local variables of automatic storage duration do not have precise; lifetime semantics. Such objects are simply strong references which hold; values of retainable object pointer type, and these values are still fully; subject to the optimizations on values under local control. .. admonition:: Rationale. Applying these precise-lifetime semantics strictly would be prohibitive.; Many useful optimizations that might theoretically decrease the lifetime of; an object would be rendered impossible. Essentially, it promises too much. A local variable of retainable object owner type and automatic storage duration; may be annotated with the ``objc_precise_lifetime`` attribute to indicate that; it should be considered to be an object with precise lifetime semantics. .. admonition:: Rationale. Nonetheless, it is sometimes useful to be able to force an object to be; released at a precise time, even if that object does not appear to be used.; This is likely to be uncommon enough that the syntactic weight of explicitly; requesting these s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:83812,variab,variables,83812,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['variab'],['variables']
Modifiability,"to requirements on inexact floating-point exceptions; Unknown. 292; C99; Use of the word variable; Yes. 293; C99; Typo in Standard - double complex instead of complex in an example; Yes. 294; NAD; Technical question on C99 restrict keyword; Unknown. 295; C99; Incomplete types for function parameters; Yes. 296; C99; Is exp(INFINITY) overflow? A range error? A divide-by-zero exception? INFINITY without any errors?; N/A. 297; C99; May FE_* floating-point exception flags have bits in common?; N/A. 298; C99; Validity of constant in unsigned long long range. Partial; Clang defines the behavior in this situation by automatically using; long long or unsigned long long as the; underlying type of the constant; however, Clang fails to diagnose the; extension in C89 mode with such constants.; . 299; C99; Is cabs() a type-generic macro?; N/A. 300; NAD; Translation-time expresssion evaluation; Yes. 301; NAD; Meaning of FE_* macros in <fenv.h>; Yes. 302; C99; 6.10.2p5: Adding underscore to portable include file name character set; Yes. 303; C99; 6.10p2: Breaking up the very long sentence describing preprocessing directive; Yes. 304; C99; Clarifying illegal tokens in #if directives; Yes. 305; C99; 6.10.1p3: Clarifying handling of keywords in #if directives; Yes. 306; C99; 6.10.3p9: Clarifying that rescanning applies to object-like macros; Yes. 307; C99; 6.10.3p10: Clarifiying arguments vs. parameters; Yes. 308; C99; Clarify that source files et al. need not be ""files""; Yes. 309; C99; Clarifying trigraph substitution; Yes. 310; C99; Add non-corner case example of trigraphs; Yes. 311; C99; Definition of variably modified types; Yes. 312; C99; Meaning of ""known constant size""; Yes. 313; NAD; Incomplete arrays of VLAs; Yes. 314; NAD; Cross-translation-unit tagged type compatibility; Unknown. 315; C99; Implementation-defined bit-field types; Yes. 316; NAD; Unprototyped function types; Yes. 317; NAD; Function definitions with empty parentheses; Yes. 318; C99; (double)0.1f with FLT_EVAL_M",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_dr_status.html:18406,portab,portable,18406,interpreter/llvm-project/clang/www/c_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_dr_status.html,1,['portab'],['portable']
Modifiability,"to the constructor as ``const char*``. Note that declaring an option category and associating it with an option before; parsing options (e.g. statically) will change the output of ``-help`` from; uncategorized to categorized. If an option category is declared but not; associated with an option then it will be hidden from the output of ``-help``. .. _different parser:; .. _discussed previously:. Builtin parsers; ---------------. Parsers control how the string value taken from the command line is translated; into a typed value, suitable for use in a C++ program. By default, the; CommandLine library uses an instance of ``parser<type>`` if the command line; option specifies that it uses values of type '``type``'. Because of this,; custom option processing is specified with specializations of the '``parser``'; class. The CommandLine library provides the following builtin parser specializations,; which are sufficient for most applications. It can, however, also be extended to; work with new data types and new ways of interpreting the same data. See the; `Writing a Custom Parser`_ for more details on this type of library extension. .. _enums:; .. _cl::parser:. * The generic ``parser<t>`` parser can be used to map strings values to any data; type, through the use of the `cl::values`_ property, which specifies the; mapping information. The most common use of this parser is for parsing enum; values, which allows you to use the CommandLine library for all of the error; checking to make sure that only valid enum values are specified (as opposed to; accepting arbitrary strings). Despite this, however, the generic parser class; can be used for any data type. .. _boolean flags:; .. _bool parser:. * The **parser<bool> specialization** is used to convert boolean strings to a; boolean value. Currently accepted strings are ""``true``"", ""``TRUE``"",; ""``True``"", ""``1``"", ""``false``"", ""``FALSE``"", ""``False``"", and ""``0``"". * The **parser<boolOrDefault> specialization** is used for cases wh",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:59187,extend,extended,59187,interpreter/llvm-project/llvm/docs/CommandLine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst,1,['extend'],['extended']
Modifiability,"to the lambda signature. This is the default. .. code-block:: c++. someMethod(; [](SomeReallyLongLambdaSignatureArgument foo) {; return;; });. * ``LBI_OuterScope`` (in configuration: ``OuterScope``); For statements within block scope, align lambda body relative to the; indentation level of the outer scope the lambda signature resides in. .. code-block:: c++. someMethod(; [](SomeReallyLongLambdaSignatureArgument foo) {; return;; });. someMethod(someOtherMethod(; [](SomeReallyLongLambdaSignatureArgument foo) {; return;; }));. .. _Language:. **Language** (``LanguageKind``) :versionbadge:`clang-format 3.5` :ref:`¶ <Language>`; Language, this format style is targeted at. Possible values:. * ``LK_None`` (in configuration: ``None``); Do not use. * ``LK_Cpp`` (in configuration: ``Cpp``); Should be used for C, C++. * ``LK_CSharp`` (in configuration: ``CSharp``); Should be used for C#. * ``LK_Java`` (in configuration: ``Java``); Should be used for Java. * ``LK_JavaScript`` (in configuration: ``JavaScript``); Should be used for JavaScript. * ``LK_Json`` (in configuration: ``Json``); Should be used for JSON. * ``LK_ObjC`` (in configuration: ``ObjC``); Should be used for Objective-C, Objective-C++. * ``LK_Proto`` (in configuration: ``Proto``); Should be used for Protocol Buffers; (https://developers.google.com/protocol-buffers/). * ``LK_TableGen`` (in configuration: ``TableGen``); Should be used for TableGen code. * ``LK_TextProto`` (in configuration: ``TextProto``); Should be used for Protocol Buffer messages in text format; (https://developers.google.com/protocol-buffers/). * ``LK_Verilog`` (in configuration: ``Verilog``); Should be used for Verilog and SystemVerilog.; https://standards.ieee.org/ieee/1800/6700/; https://sci-hub.st/10.1109/IEEESTD.2018.8299595. .. _LineEnding:. **LineEnding** (``LineEndingStyle``) :versionbadge:`clang-format 16` :ref:`¶ <LineEnding>`; Line ending style (``\n`` or ``\r\n``) to use. Possible values:. * ``LE_LF`` (in configuration: ``LF``); Use ``\",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:83543,config,configuration,83543,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['config'],['configuration']
Modifiability,"to visualise the content of these entities at the prompt.; * When interpreting dereferences of invalid pointers, cling will now complain (throw, actually) instead of crash.; * Resolve memory hoarding in some case of looking up functions [ROOT-8145]. ## Parallelism. * Three methods have been added to manage implicit multi-threading in ROOT: `ROOT::EnableImplicitMT(numthreads)`, `ROOT::DisableImplicitMT` and `ROOT::IsImplicitMTEnabled`. They can be used to enable, disable and check the status of the global implicit multi-threading in ROOT, respectively.; * Even if the default reduce function specified in the invocation of the `MapReduce` method of `TProcessExecutor` returns a pointer to a `TObject`, the return value of `MapReduce` is properly casted to the type returned by the map function.; * Add a new class named `TThreadExecutor` implementing a MapReduce framework sharing `TProcessExecutor` interface and based in tbb.; * Add a new class named `TExecutor` defining the MapReduce interface for `TProcessExecutor` and `TThreadExecutor`, who inherit from it.; * Remove all `TPool` signatures accepting collections as an argument with the exception of std::vector and initializer_lists. ; * Extend `TThreadExecutor` functionality offering parallel reduction given a binary operator as a reduction function.; * Add a new class named `TThreadedObject` which helps making objects thread private and merging them.; * Add tutorials showing how to fill randomly histograms using the `TProcessExecutor` and `TThreadExecutor` classes.; * Add tutorial showing how to fill randomly histograms from multiple threads.; * Add the `ROOT::TSpinMutex` class, a spin mutex compliant with C++11 requirements.; * Add a new Implicit Multi-Threading (IMT) use case, incarnated in method `TTreeProcessor::Process`. `TTProcessor::Process` allows to process the entries of a TTree in parallel. The user provides a function that receives one parameter, a TTreeReader, that can be used to iterate over a subrange of e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:6425,inherit,inherit,6425,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['inherit'],['inherit']
Modifiability,"to/llvm/source. You can set a variable after the initial CMake invocation to change its; value. You can also undefine a variable:. .. code-block:: console. $ cmake -UVARIABLE path/to/llvm/source. Variables are stored in the CMake cache. This is a file named ``CMakeCache.txt``; stored at the root of your build directory that is generated by ``cmake``.; Editing it yourself is not recommended. Variables are listed in the CMake cache and later in this document with; the variable name and type separated by a colon. You can also specify the; variable and type on the CMake command line:. .. code-block:: console. $ cmake -DVARIABLE:TYPE=value path/to/llvm/source. Frequently-used CMake variables; -------------------------------. Here are some of the CMake variables that are used often, along with a; brief explanation. For full documentation, consult the CMake manual,; or execute ``cmake --help-variable VARIABLE_NAME``. See `Frequently; Used LLVM-related Variables`_ below for information about commonly; used variables that control features of LLVM and enabled subprojects. .. _cmake_build_type:. **CMAKE_BUILD_TYPE**:STRING; This configures the optimization level for ``make`` or ``ninja`` builds. Possible values:. =========================== ============= ========== ========== ==========================; Build Type Optimizations Debug Info Assertions Best suited for; =========================== ============= ========== ========== ==========================; **Release** For Speed No No Users of LLVM and Clang; **Debug** None Yes Yes Developers of LLVM; **RelWithDebInfo** For Speed Yes No Users that also need Debug; **MinSizeRel** For Size No No When disk space matters; =========================== ============= ========== ========== ==========================. * Optimizations make LLVM/Clang run faster, but can be an impediment for; step-by-step debugging.; * Builds with debug information can use a lot of RAM and disk space and is; usually slower to run. You can improve RAM usage ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:6877,variab,variables,6877,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['variab'],['variables']
Modifiability,"to; ``%reg1 - reg2``. This list of values should be provided by the containing; intrinsic/instruction.; - ``DW_OP_breg`` (or ``DW_OP_bregx``) represents a content on the provided; signed offset of the specified register. The opcode is only generated by the; ``AsmPrinter`` pass to describe call site parameter value which requires an; expression over two registers.; - ``DW_OP_push_object_address`` pushes the address of the object which can then; serve as a descriptor in subsequent calculation. This opcode can be used to; calculate bounds of fortran allocatable array which has array descriptors.; - ``DW_OP_over`` duplicates the entry currently second in the stack at the top; of the stack. This opcode can be used to calculate bounds of fortran assumed; rank array which has rank known at run time and current dimension number is; implicitly first element of the stack.; - ``DW_OP_LLVM_implicit_pointer`` It specifies the dereferenced value. It can; be used to represent pointer variables which are optimized out but the value; it points to is known. This operator is required as it is different than DWARF; operator DW_OP_implicit_pointer in representation and specification (number; and types of operands) and later can not be used as multiple level. .. code-block:: text. IR for ""*ptr = 4;""; --------------; call void @llvm.dbg.value(metadata i32 4, metadata !17, metadata !20); !17 = !DILocalVariable(name: ""ptr1"", scope: !12, file: !3, line: 5,; type: !18); !18 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !19, size: 64); !19 = !DIBasicType(name: ""int"", size: 32, encoding: DW_ATE_signed); !20 = !DIExpression(DW_OP_LLVM_implicit_pointer)). IR for ""**ptr = 4;""; --------------; call void @llvm.dbg.value(metadata i32 4, metadata !17, metadata !21); !17 = !DILocalVariable(name: ""ptr1"", scope: !12, file: !3, line: 5,; type: !18); !18 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !19, size: 64); !19 = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: !20, size: 64); !20 = ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:266109,variab,variables,266109,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variables']
Modifiability,"togram->GetBuffer();; 	// number of entry is first entry in the buffer; 	int n = buffer[0];; 	// when creating the data object it is important to create with the size of the data; 	ROOT::Fit::UnBinData data(n);; 	for (int i = 0; i < n; ++i); 		data.add(buffer[2*i+1]); // the buffer of 1D histogram contains nevt,x1,w1,x2,w2,......; ```. Instead in this example we will create a 2-dim `UnBinData` object with the contents from a ROOT `TTree`. ``` {.cpp}; TFile * file = TFile::Open(""hsimple.root"");; TTree *ntuple = 0; file->GetObject(""ntuple"",ntuple);; 	// select from the tree the data we want to use for fitting; 	// we use TTree::Draw for this; 	int nevt = ntuple->Draw(""px:py"","""",""goff"");; 	double * x = ntuple->GetV1();; 	double * y = ntuple->GetV2();; ROOT::Fit::UnBinData data(nevt, x, y );; ```. ### Creating the Fit model. In order to fit a data sets we need a model to describe our data, e.g. a probability density function describing our observed data or; an hypothetical function describing the relation between the independent variables **`X`** and the single dependent variable `Y`.; We can have an arbitrary number `k` of independent variables. For example, when fitting a `k`-dimensional histogram,; the independent variables **`X`** are the bin center coordinates and `Y` is the bin weight. The model function needs to be expressed as function of some unknown parameters. The fitting will find the best parameter value to describe; the observed data. We can use the ROOT **`TF1`** class, the parametric function class, to describe the model function. However the `ROOT::Fit::Fitter` class, to be independent of the ROOT *`Hist`* library,; takes as input a more general parametric function object, the interface (abstract) class `ROOT::Math::IParametricFunctionMultiDim`, which describe a generic one or multi-dimensional function; with parameters. This interface extends the abstract class `ROOT::Math::IBaseFunctionMultiDim`, with methods to set/retrieve parameter values and to ev",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:35435,variab,variables,35435,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,2,['variab'],"['variable', 'variables']"
Modifiability,"togram; a named 'Normalization Factor' (which can be fixed or allowed to float in a fit); several 'Overall Systematics' in normalization with:; 	 ; a name; +/- 1 sigma variations (eg. 1.05 and 0.95 for a 5% uncertainty); 	 ; several 'Histogram Systematics' in shape with:; 	 ; a name (which can be shared with the OverallSyst if correlated); +/- 1 sigma variational histograms; 	 . RooStats; ModelConfig. This class is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; Various fixes by and improvements to make it usable with all; the existing calculator.; ModelConfig contains now always a reference to an; external workspace who manages all the objects being part of the model (pdf's and parameter sets). The user needs then to; set always a workspace pointer before setting the various objects.; . General Improvements. ModelConfig is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; ProfileLikelihood::GetInterval now returns LikleihoodInterval in the interface to avoid unnecessary casting; FeldmanCousins::GetInterval now returns PointSetInterval in the interface to avoid unnecessary casting. Profile Likelihood . When running ProfileLikelihoodCalculator::GetHypoTest; the user does not need anymore to clone the null parameter set. It; is done now inside the calculator; LikelihoodInterval::LowerLimit (and UpperLimit); returns now a boolean flag with the status of the limit search.; In case of a failure in finding the upper/lower limit a value of; zero is returned instead of the min/max of the variable range; LikelihoodIntervalPlot fix drawing of horizontal green; line when limits are outside the variable range . HybridCalculator. New re-written class based on the TestStatSampler and; TestStatistic interfaces. The new class is designed to provide; consistent use of a ModelConfig, specifying the Pdf and Prior. ; The old class r",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:3654,config,configuration,3654,roofit/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html,1,['config'],['configuration']
Modifiability,"tomatic (stack) storage. Thus one may access; functions and global variables as one would expect, as well as static; local variables. [testme]. Local automatic (stack) variables referenced within the compound; statement of a Block are imported and captured by the Block as const; copies. The capture (binding) is performed at the time of the Block; literal expression evaluation. The compiler is not required to capture a variable if it can prove; that no references to the variable will actually be evaluated.; Programmers can force a variable to be captured by referencing it in a; statement at the beginning of the Block, like so:. .. code-block:: c. (void) foo;. This matters when capturing the variable has side-effects, as it can; in Objective-C or C++. The lifetime of variables declared in a Block is that of a function;; each activation frame contains a new copy of variables declared within; the local scope of the Block. Such variable declarations should be; allowed anywhere [testme] rather than only when C99 parsing is; requested, including for statements. [testme]. Block literal expressions may occur within Block literal expressions; (nest) and all variables captured by any nested blocks are implicitly; also captured in the scopes of their enclosing Blocks. A Block literal expression may be used as the initialization value for; Block variables at global or local static scope. The Invoke Operator; ===================. Blocks are :block-term:`invoked` using function call syntax with a; list of expression parameters of types corresponding to the; declaration and returning a result type also according to the; declaration. Given:. .. code-block:: c. int (^x)(char);; void (^z)(void);; int (^(*y))(char) = &x;. the following are all legal Block invocations:. .. code-block:: c. x('a');; (*y)('a');; (true ? x : *y)('a'). The Copy and Release Operations; ===============================. The compiler and runtime provide :block-term:`copy` and; :block-term:`release` operations for",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst:5319,variab,variable,5319,interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,1,['variab'],['variable']
Modifiability,"ton* - performs a fit taking different option settings via the; Fit Panel interface. *Reset* - sets the GUI elements and related fit settings to the; default ones. *Close* - closes the Fit panel window. ### Minimization Options. With this tab one can select specific options for minimization. These include. * The minimizer library ( *Minuit*, *Minuit2*, *Fumili*, *GSL*, *Genetics* ); * The method (algorithm) for minimization. For example for Minuit one can choose between (*Migrad*, *Simplex* or *Scan*); * Error definition; * Minimization tolerance; * Number of iterations/function calls; * Print Level: (*Default*, *Verbose* or *Quiet*). ## New ROOT::Fit classes. The fitting of the data objects in ROOT, histograms, graphs and tree is performed via some common classes,; which are defined in the `ROOT::Fit` namespace.; These classes can be classified in the following groups:. * User classes driving the fit: `ROOT::Fit::Fitter` for executing the fit, `ROOT::Fit::FitConfig` for configuring the fit,; 	`ROOT::Fit::ParameterSettings` to define the properties of the fit parameters (initial; 	values, bounds, etc..), `ROOT::Fit::FitResult` for storing the result of the fit.; * Data classes containing the data sets used in the fitting. These classes are the`ROOT::Fit::BinData`for describing bin data sets,; 	 thus data points containing both coordinates and a corresponding value/weight; 	 with optionally an error on the value or the coordinate and the `ROOT::Fit::UnBinData` for un-binned data sets,; 	 which consists only of a vector of coordinate values. The coordinate values can be; 	 one-dimensional (i.e. one entry per event) or multi-dimensional (N entries per event).; * Function classes defining the type of fit (the objective function used for fitting):; 	- `ROOT::Fit::Chi2FCN` for chi2 (least-square fits),; 	- `ROOT::Fit::PoissonLikelihoodFCN` for binned likelihood fits of histograms,; 	- `ROOT::Fit::LogLikelihoodFCN` for generic un-binned likelihood fits.; 	These classes are ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:26646,config,configuring,26646,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['config'],['configuring']
Modifiability,"tool and editor integrations. Standalone Tool; ===============. :program:`clang-format` is located in `clang/tools/clang-format` and can be used; to format C/C++/Java/JavaScript/JSON/Objective-C/Protobuf/C# code. .. START_FORMAT_HELP. .. code-block:: console. $ clang-format --help; OVERVIEW: A tool to format C/C++/Java/JavaScript/JSON/Objective-C/Protobuf/C# code. If no arguments are specified, it formats the code from standard input; and writes the result to the standard output.; If <file>s are given, it reformats the files. If -i is specified; together with <file>s, the files are edited in-place. Otherwise, the; result is written to the standard output. USAGE: clang-format [options] [@<file>] [<file> ...]. OPTIONS:. Clang-format options:. --Werror - If set, changes formatting warnings to errors; --Wno-error=<value> - If set don't error out on the specified warning type.; =unknown - If set, unknown format options are only warned about.; This can be used to enable formatting, even if the; configuration contains unknown (newer) options.; Use with caution, as this might lead to dramatically; differing format depending on an option being; supported or not.; --assume-filename=<string> - Set filename used to determine the language and to find; .clang-format file.; Only used when reading from stdin.; If this is not passed, the .clang-format file is searched; relative to the current working directory when reading stdin.; Unrecognized filenames are treated as C++.; supported:; CSharp: .cs; Java: .java; JavaScript: .mjs .js .ts; Json: .json; Objective-C: .m .mm; Proto: .proto .protodevel; TableGen: .td; TextProto: .textpb .pb.txt .textproto .asciipb; Verilog: .sv .svh .v .vh; --cursor=<uint> - The position of the cursor when invoking; clang-format from an editor integration; --dry-run - If set, do not actually make the formatting changes; --dump-config - Dump configuration options to stdout and exit.; Can be used with -style option.; --fallback-style=<string> - The name of th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst:1200,config,configuration,1200,interpreter/llvm-project/clang/docs/ClangFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst,1,['config'],['configuration']
Modifiability,"toolchains`` above) as GCC.; Clang will look within its own prefix for libstdc++ and use it if found. You; can also add an explicit prefix for Clang to look in for a GCC toolchain with; the ``--gcc-toolchain=/opt/my/gcc/prefix`` flag, passing it to both compile and; link commands when using your just-built-Clang to bootstrap. .. _Getting Started with LLVM:. Getting Started with LLVM; =========================. The remainder of this guide is meant to get you up and running with LLVM and to; give you some basic information about the LLVM environment. The later sections of this guide describe the `general layout`_ of the LLVM; source tree, a `simple example`_ using the LLVM tool chain, and `links`_ to find; more information about LLVM or to get help via e-mail. Terminology and Notation; ------------------------. Throughout this manual, the following names are used to denote paths specific to; the local system and working environment. *These are not environment variables; you need to set but just strings used in the rest of this document below*. In; any of the examples below, simply replace each of these names with the; appropriate pathname on your local system. All these paths are absolute:. ``SRC_ROOT``. This is the top level directory of the LLVM source tree. ``OBJ_ROOT``. This is the top level directory of the LLVM object tree (i.e. the tree where; object files and compiled programs will be placed. It can be the same as; SRC_ROOT). Unpacking the LLVM Archives; ---------------------------. If you have the LLVM distribution, you will need to unpack it before you can; begin to compile it. LLVM is distributed as a number of different; subprojects. Each one has its own download which is a TAR archive that is; compressed with the gzip program. The files are as follows, with *x.y* marking the version number:. ``llvm-x.y.tar.gz``. Source release for the LLVM libraries and tools. ``cfe-x.y.tar.gz``. Source release for the Clang frontend. .. _checkout:. Checkout LLVM from Git;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:20754,variab,variables,20754,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['variab'],['variables']
Modifiability,"tor as the current object when it evaluates its associated expression.*. The result is undefined if the location description is invalid (see; :ref:`amdgpu-dwarf-location-description`). *An initial stack*. This is a list of values or location descriptions that will be pushed on the; operation expression evaluation stack in the order provided before evaluation; of an operation expression starts. Some debugger information entries have attributes that evaluate their DWARF; expression value with initial stack entries. In all other cases the initial; stack is empty. The result is undefined if any location descriptions are invalid (see; :ref:`amdgpu-dwarf-location-description`). If the evaluation requires a context element that is not specified, then the; result of the evaluation is an error. *A DWARF expression for a location description may be able to be evaluated; without a thread, lane, call frame, program location, or architecture context.; For example, the location of a global variable may be able to be evaluated; without such context. If the expression evaluates with an error then it may; indicate the variable has been optimized and so requires more context.*. *The DWARF expression for call frame information (see*; :ref:`amdgpu-dwarf-call-frame-information`\ *) operations are restricted to; those that do not require the compilation unit context to be specified.*. The DWARF is ill-formed if all the ``address_size`` fields in the headers of all; the entries in the ``.debug_info``, ``.debug_addr``, ``.debug_line``,; ``.debug_rnglists``, ``.debug_rnglists.dwo``, ``.debug_loclists``, and; ``.debug_loclists.dwo`` sections corresponding to any given program location do; not match. .. _amdgpu-dwarf-expression-value:. A.2.5.2 DWARF Expression Value; ++++++++++++++++++++++++++++++. A value has a type and a literal value. It can represent a literal value of any; supported base type of the target architecture. The base type specifies the; size, encoding, and endianity of the lit",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:54365,variab,variable,54365,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['variab'],['variable']
Modifiability,"tor operations in a; target-independent manner. These instructions cover the element-access; and vector-specific operations needed to process vectors effectively.; While LLVM does directly support these vector operations, many; sophisticated algorithms will want to use target-specific intrinsics to; take full advantage of a specific target. .. _i_extractelement:. '``extractelement``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = extractelement <n x <ty>> <val>, <ty2> <idx> ; yields <ty>; <result> = extractelement <vscale x n x <ty>> <val>, <ty2> <idx> ; yields <ty>. Overview:; """""""""""""""""". The '``extractelement``' instruction extracts a single scalar element; from a vector at a specified index. Arguments:; """""""""""""""""""". The first operand of an '``extractelement``' instruction is a value of; :ref:`vector <t_vector>` type. The second operand is an index indicating; the position from which to extract the element. The index may be a; variable of any integer type, and will be treated as an unsigned integer. Semantics:; """""""""""""""""""". The result is a scalar of the same type as the element type of ``val``.; Its value is the value at position ``idx`` of ``val``. If ``idx``; exceeds the length of ``val`` for a fixed-length vector, the result is a; :ref:`poison value <poisonvalues>`. For a scalable vector, if the value; of ``idx`` exceeds the runtime length of the vector, the result is a; :ref:`poison value <poisonvalues>`. Example:; """""""""""""""". .. code-block:: text. <result> = extractelement <4 x i32> %vec, i32 0 ; yields i32. .. _i_insertelement:. '``insertelement``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = insertelement <n x <ty>> <val>, <ty> <elt>, <ty2> <idx> ; yields <n x <ty>>; <result> = insertelement <vscale x n x <ty>> <val>, <ty> <elt>, <ty2> <idx> ; yields <vscale x n x <ty>>. Overview:; """""""""""""""""". The '``insertelement``' instruction inserts a scalar element into a; vector at a specified index. Argumen",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:401493,variab,variable,401493,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variable']
Modifiability,"tor to the crossed shape; surface, given a starting local point and an ongoing direction. All the features above are globally managed by the modeller in order to; provide navigation functionality. In addition to those, shapes have also; to implement additional specific abstract methods:. - Computation of the minimal box bounding the shape, given that this; box have to be aligned with the local coordinates;; - Algorithms for dividing the shape along a given axis. The modeller currently provides a set of 20 basic shapes, which we will; call `primitives`. It also provides a special class allowing the; creation of shapes as a result of Boolean operations between primitives.; These are called `composite shapes` and the composition operation can be; recursive (combined composites). This allows the creation of a quite; large number of different shape topologies and combinations. You can; have a look and run the tutorial: geodemo.C. \image html geom_primitive_shapes.png Primitive Shapes - the general inheritance scheme. Shapes are named objects and all primitives have constructors like:. ~~~ {.cpp}; TGeoXXX(const char *name,<type> param1,<type> param2, ...);; TGeoXXX(<type> param1,<type> param2, ...);; ~~~. Naming shape primitive is mandatory only for the primitives used in; Boolean composites (see ""Composite Shapes""). For the sake of simplicity,; we will describe only the constructors in the second form. \anchor SHAPES01; ### Primitive Shapes. - Boxes: TGeoBBox class; - Parallelepiped: TGeoPara class; - Trapezoids: TGeoTrd1, TGeoTrd2 classes; - General Trapezoid: TGeoTrap class; - Twisted Trapezoid: TGeoGtra class; - Arbitrary 8 vertices shapes: TGeoArb8 class; - Tubes: TGeoTube class; - Tube Segments: TGeoTubeSeg class; - Cut Tubes: TGeoCtub class; - Elliptical Tubes: TGeoEltu class; - Hyperboloids: TGeoHype class; - Cones: TGeoCone class; - Cone Segments: TGeoConeSeg class; - Sphere: TGeoSphere class; - Torus: TGeoTorus class; - Paraboloid: TGeoParaboloid class; - Polyco",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md:1953,inherit,inheritance,1953,geom/geom/doc/shapes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/shapes.md,1,['inherit'],['inheritance']
Modifiability,"tor_length>); declare <vscale x 4 x i8> @llvm.vp.ptrtoint.nxv4i8.nxv4p0(<vscale x 4 x ptr> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x i64> @llvm.vp.ptrtoint.v16i64.v16p0(<256 x ptr> <op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". The '``llvm.vp.ptrtoint``' intrinsic converts its pointer to the integer return; type. The operation has a mask and an explicit vector length parameter. Arguments:; """""""""""""""""""". The '``llvm.vp.ptrtoint``' intrinsic takes a value to cast as its first operand; , which must be a vector of pointers, and a type to cast it to return type,; which must be a vector of :ref:`integer <t_integer>` type.; The second operand is the vector mask. The return type, the value to cast, and; the vector mask have the same number of elements.; The third operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.ptrtoint``' intrinsic converts value to return type by; interpreting the pointer value as an integer and either truncating or zero; extending that value to the size of the integer type.; If ``value`` is smaller than return type, then a zero extension is done. If; ``value`` is larger than return type, then a truncation is done. If they are; the same size, then nothing is done (*no-op cast*) other than a type; change.; The conversion is performed on lane positions below the explicit vector length; and where the vector mask is true. Masked-off lanes are ``poison``. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x i8> @llvm.vp.ptrtoint.v4i8.v4p0i32(<4 x ptr> %a, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = ptrtoint <4 x ptr> %a to <4 x i8>; %also.r = select <4 x i1> %mask, <4 x i8> %t, <4 x i8> poison. .. _int_vp_inttoptr:. '``llvm.vp.inttoptr.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x ptr> @llvm.vp.inttoptr.v16p0.v16i32 (<16 x i32> <op>,",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:814090,extend,extending,814090,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['extend'],['extending']
Modifiability,"tore instructions,; and it is carefully designed not to have (or need) an ""address-of""; operator. Notice how the type of the @G/@H global variables is actually; ""i32\*"" even though the variable is defined as ""i32"". What this means is; that @G defines *space* for an i32 in the global data area, but its; *name* actually refers to the address for that space. Stack variables; work the same way, except that instead of being declared with global; variable definitions, they are declared with the `LLVM alloca; instruction <../../LangRef.html#alloca-instruction>`_:. .. code-block:: llvm. define i32 @example() {; entry:; %X = alloca i32 ; type of %X is i32*.; ...; %tmp = load i32, i32* %X ; load the stack value %X from the stack.; %tmp2 = add i32 %tmp, 1 ; increment it; store i32 %tmp2, i32* %X ; store it back; ... This code shows an example of how you can declare and manipulate a stack; variable in the LLVM IR. Stack memory allocated with the alloca; instruction is fully general: you can pass the address of the stack slot; to functions, you can store it in other variables, etc. In our example; above, we could rewrite the example to use the alloca technique to avoid; using a PHI node:. .. code-block:: llvm. @G = weak global i32 0 ; type of @G is i32*; @H = weak global i32 0 ; type of @H is i32*. define i32 @test(i1 %Condition) {; entry:; %X = alloca i32 ; type of %X is i32*.; br i1 %Condition, label %cond_true, label %cond_false. cond_true:; %X.0 = load i32, i32* @G; store i32 %X.0, i32* %X ; Update X; br label %cond_next. cond_false:; %X.1 = load i32, i32* @H; store i32 %X.1, i32* %X ; Update X; br label %cond_next. cond_next:; %X.2 = load i32, i32* %X ; Read X; ret i32 %X.2; }. With this, we have discovered a way to handle arbitrary mutable; variables without the need to create Phi nodes at all:. #. Each mutable variable becomes a stack allocation.; #. Each read of the variable becomes a load from the stack.; #. Each update of the variable becomes a store to the stack.; #. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:5450,variab,variables,5450,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['variab'],['variables']
Modifiability,"tored objects are written sequentially. However,; in a TClonesArray, by default, each object is split one level deep into its base; class(es) and data members, and each of these members is written sequentially for; all objects in the array before the next member is written. This has two advantages:; 1. Greater compression can be achieved when similar data is consecutive.; 2. The object's data members can easily be split into different TTree branches; (TTrees are discussed below). ### TTree. A TTree is a highly specialized container class for efficient storage and retrieval of user data.; The use of TTrees is discussed in detail in the; [Trees chapter of the Root Manual](https://root.cern/manual/trees/). Here we discuss in particular how a TTree is stored in a ROOTIO file. A TTree object is split into one or more branches (class TBranch), each of which may have its own; (sub)branches, recursively to any depth. Each TBranch contains an array of zero or more leaves; (class TLeaf), each corresponding to a basic variable type or a class object that has not been split.; The TLeaf object does not actually contain variable values, only information about the variables.; The actual data on each branch is physically stored in basket objects (class TBasket). The user; can set the basket size on a per TBranch basis. The default basket size is 32000 bytes.; This should be viewed as an approximate number. There is one TTree data record per file for each tree in the file, corresponding to a TTree; class object. The TTree class object recursively contains TBranch objects, each of which; contains an array of TBasket objects to hold its data. However, the TTree data record does not necessarily contain the entire TTree object. For each; branch, exactly one TBasket object is contained in the TTree data record. If the data on a; given branch fits in one basket, then all the data for that branch will be in the TTree record; itself. Otherwise, there will be a separate TBasket data record fo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md:13874,variab,variable,13874,io/doc/TFile/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/TFile/README.md,1,['variab'],['variable']
Modifiability,"toring actions. The :doc:`LibTooling`; library provides several other APIs that are used when developing a; refactoring action. Refactoring engine can be used to implement local refactorings that are; initiated using a selection in an editor or an IDE. You can combine; :doc:`AST matchers<LibASTMatchers>` and the refactoring engine to implement; refactorings that don't lend themselves well to source selection and/or have to; query ASTs for some particular nodes. We assume basic knowledge about the Clang AST. See the :doc:`Introduction; to the Clang AST <IntroductionToTheClangAST>` if you want to learn more; about how the AST is structured. .. FIXME: create new refactoring action tutorial and link to the tutorial. Introduction; ------------. Clang's refactoring engine defines a set refactoring actions that implement; a number of different source transformations. The ``clang-refactor``; command-line tool can be used to perform these refactorings. Certain; refactorings are also available in other clients like text editors and IDEs. A refactoring action is a class that defines a list of related refactoring; operations (rules). These rules are grouped under a common umbrella - a single; ``clang-refactor`` command. In addition to rules, the refactoring action; provides the action's command name and description to ``clang-refactor``.; Each action must implement the ``RefactoringAction`` interface. Here's an; outline of a ``local-rename`` action:. .. code-block:: c++. class LocalRename final : public RefactoringAction {; public:; StringRef getCommand() const override { return ""local-rename""; }. StringRef getDescription() const override {; return ""Finds and renames symbols in code with no indexer support"";; }. RefactoringActionRules createActionRules() const override {; ...; }; };. Refactoring Action Rules; ------------------------. An individual refactoring action is responsible for creating the set of; grouped refactoring action rules that represent one refactoring operatio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/RefactoringEngine.rst:1248,refactor,refactorings,1248,interpreter/llvm-project/clang/docs/RefactoringEngine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/RefactoringEngine.rst,1,['refactor'],['refactorings']
Modifiability,"torings that are; initiated using a selection in an editor or an IDE. You can combine; :doc:`AST matchers<LibASTMatchers>` and the refactoring engine to implement; refactorings that don't lend themselves well to source selection and/or have to; query ASTs for some particular nodes. We assume basic knowledge about the Clang AST. See the :doc:`Introduction; to the Clang AST <IntroductionToTheClangAST>` if you want to learn more; about how the AST is structured. .. FIXME: create new refactoring action tutorial and link to the tutorial. Introduction; ------------. Clang's refactoring engine defines a set refactoring actions that implement; a number of different source transformations. The ``clang-refactor``; command-line tool can be used to perform these refactorings. Certain; refactorings are also available in other clients like text editors and IDEs. A refactoring action is a class that defines a list of related refactoring; operations (rules). These rules are grouped under a common umbrella - a single; ``clang-refactor`` command. In addition to rules, the refactoring action; provides the action's command name and description to ``clang-refactor``.; Each action must implement the ``RefactoringAction`` interface. Here's an; outline of a ``local-rename`` action:. .. code-block:: c++. class LocalRename final : public RefactoringAction {; public:; StringRef getCommand() const override { return ""local-rename""; }. StringRef getDescription() const override {; return ""Finds and renames symbols in code with no indexer support"";; }. RefactoringActionRules createActionRules() const override {; ...; }; };. Refactoring Action Rules; ------------------------. An individual refactoring action is responsible for creating the set of; grouped refactoring action rules that represent one refactoring operation.; Although the rules in one action may have a number of different implementations,; they should strive to produce a similar result. It should be easy for users to; identify which re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/RefactoringEngine.rst:1489,refactor,refactor,1489,interpreter/llvm-project/clang/docs/RefactoringEngine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/RefactoringEngine.rst,1,['refactor'],['refactor']
Modifiability,"tory. Note also that the first `$UID` is not escaped and; will be substituted *locally* with your user ID *on your client; machine*, while the second one has the dollar escaped (`\$UID`) and will; be substituted *remotely* with your user ID *on the remote node*. > It is worth noting that the remote environment scripts will be sent to; > the remote node using a secure connection (SSH), thus there is no; > concern in placing sensitive user data there. Installing the Virtual Analysis Facility client; -----------------------------------------------. ### Download the client from Git. The Virtual Analysis Facility client is available on; [GitHub](https://github.com/dberzano/virtual-analysis-facility):. ``` {.bash}; git clone git://github.com/dberzano/virtual-analysis-facility.git /dest/dir; ```. The client will be found in `/dest/dir/client/bin/vaf-enter`: it is; convenient to add it to the `$PATH` so that the users might simply start; it by typing `vaf-enter`. ### Install the experiment's configuration files system-wide. A system administrator might find convenient to install the experiment; environment scripts system-wide. Configuration scripts for LHC experiments are shipped with the VAF; client and can be found in; `/dest/dir/client/config-samples/<experiment_name>`. To make them used; by default by the VAF client, place them in the `/dest/dir/etc`; directory like this:. ``` {.bash}; rsync -a /dest/dir/client/config-samples/<experiment_name>/ /dest/dir/etc/; ```. Remember that the trailing slash in the source directory name has a; meaning in `rsync` and must not be omitted. > Remember that system-wide configuration files will always have; > precedence over user's configuration files, so *don't place there; > files that are supposed to be provided by the user!*. Entering the Virtual Analysis Facility environment; --------------------------------------------------. The Virtual Analysis Facility client is a wrapper around commands sent; to the remote host by means of PRO",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:7313,config,configuration,7313,proof/doc/confman/UsingVirtualAnalysisFacility.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md,1,['config'],['configuration']
Modifiability,"totypes will cause a compiler error unless it; has ``__counted_by`` annotation in its bracket. .. code-block:: c. void f1(int n, int arr[]); // error. void f3(int n, int arr[__counted_by(n)]); // ok. void f2(int n, int arr[n]); // ok, decays to int *__counted_by(n). void f4(int n, int *__counted_by(n) arr); // ok. void f5(int n, int *arr); // ok, but decays to int *__single,; // and cannot be used for pointer arithmetic. Array references; ^^^^^^^^^^^^^^^^. In C, similar to arrays on the function prototypes, a reference to array is; automatically promoted (or ""decayed"") to a pointer to its first element (e.g.,; ``&arr[0]``). In `-fbounds-safety`, array references are promoted to ``__bidi_indexable``; pointers which contain the upper and lower bounds of the array, with the; equivalent of ``&arr[0]`` serving as the lower bound and ``&arr[array_size]``; (or one past the last element) serving as the upper bound. This applies to all; types of arrays including constant-length arrays, variable-length arrays (VLAs),; and flexible array members annotated with `__counted_by`. In the following example, reference to ``vla`` promotes to ``int; *__bidi_indexable``, with ``&vla[n]`` as the upper bound and ``&vla[0]`` as the; lower bound. Then, it's copied to ``int *p``, which is implicitly ``int; *__bidi_indexable p``. Please note that value of ``n`` used to create the upper; bound is ``10``, not ``100``, in this case because ``10`` is the actual length; of ``vla``, the value of ``n`` at the time when the array is being allocated. .. code-block:: c. void foo(void) {; int n = 10;; int vla[n];; n = 100;; int *p = vla; // { .ptr: &vla[0], .upper: &vla[10], .lower: &vla[0] }; // it's `&vla[10]` because the value of `n` was 10 at the; // time when the array is actually allocated.; // ...; }. By promoting array references to ``__bidi_indexable``, all array accesses are; bounds checked in ``-fbounds-safety``, just as ``__bidi_indexable`` pointers; are. Maintaining correctness of bounds ann",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst:34133,variab,variable-length,34133,interpreter/llvm-project/clang/docs/BoundsSafety.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst,2,"['flexible', 'variab']","['flexible', 'variable-length']"
Modifiability,"toy data; and parameters used for evaluating the test statistic.; ProfileLikelihoodTestStatUsing the raw profile likelihood while reviewing the old algorithm used to provide robustness in situations with local minima.; New test statistic classes:; ; SimpleLikelihoodRatioTestStat : log L_1 / L_0; RatioOfProfiledLikelihoodsTestStat: log L(mu_1, hat(nu_1))/L(mu_0,hat(nu_0)); MaxLikelihoodEstimateTestStat: the MLE of a specified parameter. ToyMCSampler. New version of ToyMCSampler which can smear the nuisance; parameters according to their distributions for use with; HybridCalculator; Updated class structure: ToyMCSampler is a particular implementation of a TestStatSampler and runs with any TestStatistic. It returns the result in an instance of SamplingDistribution.; Supports Importance Sampling: Improves sampling the tails of a distribution by generating toys from a user supplied importance density and a reweighing procedure of the result.; Supports Adaptive Sampling: extends the run until a given number of toys is reached in the tail(s).; Parallelization using PROOF(-Lite) is supported. It is enabled by supplying a ProofConfig instance. BayesianCalculator. Improve the way the class performs the numerical integration to; find the interval and/or the posterior function.; In case of complex; numerical calculation add the method SetScanOfPosterior(nbins) for; scanning the posterior function in a givn number of nbins; Add possibility to compute lower/upper limits using the method; SetLeftSideTailFraction(fraction); Add possibility to compute shortest interval using; SetShortestInterval. MCMCCalculator. Various improvements including possibility to compute; lower/central/upper limits using; SetLeftSideTailFraction(fraction). New Tutorials. New Demos that take name for file, workspace, modelconfig, and data, then use the corresponding calculator tool. If the file is not specified it will read an file produced from running the HistFactory tutorial example. StandardProfileLikel",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:7858,extend,extends,7858,roofit/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html,1,['extend'],['extends']
Modifiability,"tpop.i256(i256 <src>); declare <2 x i32> @llvm.ctpop.v2i32(<2 x i32> <src>). Overview:; """""""""""""""""". The '``llvm.ctpop``' family of intrinsics counts the number of bits set; in a value. Arguments:; """""""""""""""""""". The only argument is the value to be counted. The argument may be of any; integer type, or a vector with integer elements. The return type must; match the argument type. Semantics:; """""""""""""""""""". The '``llvm.ctpop``' intrinsic counts the 1's in a variable, or within; each element of a vector. .. _int_ctlz:. '``llvm.ctlz.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.ctlz`` on any; integer bit width, or any vector whose elements are integers. Not all; targets support all bit widths or vector types, however. ::. declare i8 @llvm.ctlz.i8 (i8 <src>, i1 <is_zero_poison>); declare <2 x i37> @llvm.ctlz.v2i37(<2 x i37> <src>, i1 <is_zero_poison>). Overview:; """""""""""""""""". The '``llvm.ctlz``' family of intrinsic functions counts the number of; leading zeros in a variable. Arguments:; """""""""""""""""""". The first argument is the value to be counted. This argument may be of; any integer type, or a vector with integer element type. The return; type must match the first argument type. The second argument is a constant flag that indicates whether the intrinsic; returns a valid result if the first argument is zero. If the first; argument is zero and the second argument is true, the result is poison.; Historically some architectures did not provide a defined result for zero; values as efficiently, and many algorithms are now predicated on avoiding; zero-value inputs. Semantics:; """""""""""""""""""". The '``llvm.ctlz``' intrinsic counts the leading (most significant); zeros in a variable, or within each element of the vector. If; ``src == 0`` then the result is the size in bits of the type of ``src``; if ``is_zero_poison == 0`` and ``poison`` otherwise. For example,; ``llvm.ctlz(i32 2) = 30``. .. _int_cttz:. '``llvm.cttz.*``' Intrin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:593947,variab,variable,593947,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variable']
Modifiability,"tps://github.com/llvm/llvm-project/issues/45794>`_); - Fixed an issue where accesses to the local variables of a coroutine during; ``await_suspend`` could be misoptimized, including accesses to the awaiter; object itself.; (`#56301 <https://github.com/llvm/llvm-project/issues/56301>`_); The current solution may bring performance regressions if the awaiters have; non-static data members. See; `#64945 <https://github.com/llvm/llvm-project/issues/64945>`_ for details.; - Clang now prints unnamed members in diagnostic messages instead of giving an; empty ''. Fixes; (`#63759 <https://github.com/llvm/llvm-project/issues/63759>`_); - Fix crash in __builtin_strncmp and related builtins when the size value; exceeded the maximum value representable by int64_t. Fixes; (`#64876 <https://github.com/llvm/llvm-project/issues/64876>`_); - Fixed an assertion if a function has cleanups and fatal erors.; (`#48974 <https://github.com/llvm/llvm-project/issues/48974>`_); - Clang now emits an error if it is not possible to deduce array size for a; variable with incomplete array type.; (`#37257 <https://github.com/llvm/llvm-project/issues/37257>`_); - Clang's ``-Wunused-private-field`` no longer warns on fields whose type is; declared with ``[[maybe_unused]]``.; (`#61334 <https://github.com/llvm/llvm-project/issues/61334>`_); - For function multi-versioning using the ``target``, ``target_clones``, or; ``target_version`` attributes, remove comdat for internal linkage functions.; (`#65114 <https://github.com/llvm/llvm-project/issues/65114>`_); - Clang now reports ``-Wformat`` for bool value and char specifier confusion; in scanf. Fixes; (`#64987 <https://github.com/llvm/llvm-project/issues/64987>`_); - Support MSVC predefined macro expressions in constant expressions and in; local structs.; - Correctly parse non-ascii identifiers that appear immediately after a line splicing; (`#65156 <https://github.com/llvm/llvm-project/issues/65156>`_); - Clang no longer considers the loss of ``__unaligned",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:34961,variab,variable,34961,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,1,['variab'],['variable']
Modifiability,"tr, <8 x i1> %Mask). ; %Bptr should be increased on each iteration according to the number of '1' elements in the Mask.; %MaskI = bitcast <8 x i1> %Mask to i8; %MaskIPopcnt = call i8 @llvm.ctpop.i8(i8 %MaskI); %MaskI64 = zext i8 %MaskIPopcnt to i64; %BNextInd = add i64 %BInd, %MaskI64. Other targets may support this intrinsic differently, for example, by lowering it into a sequence of branches that guard scalar store operations. Memory Use Markers; ------------------. This class of intrinsics provides information about the; :ref:`lifetime of memory objects <objectlifetime>` and ranges where variables; are immutable. .. _int_lifestart:. '``llvm.lifetime.start``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.lifetime.start(i64 <size>, ptr nocapture <ptr>). Overview:; """""""""""""""""". The '``llvm.lifetime.start``' intrinsic specifies the start of a memory; object's lifetime. Arguments:; """""""""""""""""""". The first argument is a constant integer representing the size of the; object, or -1 if it is variable sized. The second argument is a pointer; to the object. Semantics:; """""""""""""""""""". If ``ptr`` is a stack-allocated object and it points to the first byte of; the object, the object is initially marked as dead.; ``ptr`` is conservatively considered as a non-stack-allocated object if; the stack coloring algorithm that is used in the optimization pipeline cannot; conclude that ``ptr`` is a stack-allocated object. After '``llvm.lifetime.start``', the stack object that ``ptr`` points is marked; as alive and has an uninitialized value.; The stack object is marked as dead when either; :ref:`llvm.lifetime.end <int_lifeend>` to the alloca is executed or the; function returns. After :ref:`llvm.lifetime.end <int_lifeend>` is called,; '``llvm.lifetime.start``' on the stack object can be called again.; The second '``llvm.lifetime.start``' call marks the object as alive, but it; does not change the address of the object. If ``ptr`` is a non-stack-allocat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:861423,variab,variable,861423,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variable']
Modifiability,tra/clangd/index/dex/Trigram.h; clang-tools-extra/clangd/index/dex/dexp/Dexp.cpp; clang-tools-extra/clangd/index/remote/Client.cpp; clang-tools-extra/clangd/index/remote/Client.h; clang-tools-extra/clangd/index/remote/marshalling/Marshalling.cpp; clang-tools-extra/clangd/index/remote/marshalling/Marshalling.h; clang-tools-extra/clangd/index/remote/monitor/Monitor.cpp; clang-tools-extra/clangd/index/remote/server/Server.cpp; clang-tools-extra/clangd/index/remote/unimplemented/UnimplementedClient.cpp; clang-tools-extra/clangd/indexer/IndexerMain.cpp; clang-tools-extra/clangd/refactor/InsertionPoint.cpp; clang-tools-extra/clangd/refactor/InsertionPoint.h; clang-tools-extra/clangd/refactor/Rename.h; clang-tools-extra/clangd/refactor/Tweak.cpp; clang-tools-extra/clangd/refactor/Tweak.h; clang-tools-extra/clangd/refactor/tweaks/AddUsing.cpp; clang-tools-extra/clangd/refactor/tweaks/AnnotateHighlightings.cpp; clang-tools-extra/clangd/refactor/tweaks/DefineInline.cpp; clang-tools-extra/clangd/refactor/tweaks/DefineOutline.cpp; clang-tools-extra/clangd/refactor/tweaks/DumpAST.cpp; clang-tools-extra/clangd/refactor/tweaks/ExpandMacro.cpp; clang-tools-extra/clangd/refactor/tweaks/ExtractFunction.cpp; clang-tools-extra/clangd/refactor/tweaks/ObjCLocalizeStringLiteral.cpp; clang-tools-extra/clangd/refactor/tweaks/RemoveUsingNamespace.cpp; clang-tools-extra/clangd/refactor/tweaks/SwapIfBranches.cpp; clang-tools-extra/clangd/support/Cancellation.cpp; clang-tools-extra/clangd/support/Cancellation.h; clang-tools-extra/clangd/support/Context.cpp; clang-tools-extra/clangd/support/Context.h; clang-tools-extra/clangd/support/FileCache.cpp; clang-tools-extra/clangd/support/FileCache.h; clang-tools-extra/clangd/support/Function.h; clang-tools-extra/clangd/support/Logger.cpp; clang-tools-extra/clangd/support/Markup.cpp; clang-tools-extra/clangd/support/Markup.h; clang-tools-extra/clangd/support/MemoryTree.cpp; clang-tools-extra/clangd/support/MemoryTree.h; clang-tools-extra/clangd/support/,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:80445,refactor,refactor,80445,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['refactor'],['refactor']
Modifiability,"trap``, and ``strict``.; The default value is ``ignore``. Details:. * ``ignore`` The compiler assumes that the exception status flags will not be read and that floating point exceptions will be masked.; * ``maytrap`` The compiler avoids transformations that may raise exceptions that would not have been raised by the original code. Constant folding performed by the compiler is exempt from this option.; * ``strict`` The compiler ensures that all transformations strictly preserve the floating point exception semantics of the original code. .. option:: -ffp-eval-method=<value>. Specify the floating-point evaluation method for intermediate results within; a single expression of the code. Valid values are: ``source``, ``double``, and ``extended``.; For 64-bit targets, the default value is ``source``. For 32-bit x86 targets; however, in the case of NETBSD 6.99.26 and under, the default value is; ``double``; in the case of NETBSD greater than 6.99.26, with NoSSE, the; default value is ``extended``, with SSE the default value is ``source``.; Details:. * ``source`` The compiler uses the floating-point type declared in the source program as the evaluation method.; * ``double`` The compiler uses ``double`` as the floating-point evaluation method for all float expressions of type that is narrower than ``double``.; * ``extended`` The compiler uses ``long double`` as the floating-point evaluation method for all float expressions of type that is narrower than ``long double``. .. option:: -f[no-]protect-parens. This option pertains to floating-point types, complex types with; floating-point components, and vectors of these types. Some arithmetic; expression transformations that are mathematically correct and permissible; according to the C and C++ language standards may be incorrect when dealing; with floating-point types, such as reassociation and distribution. Further,; the optimizer may ignore parentheses when computing arithmetic expressions; in circumstances where the parenthesi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:64530,extend,extended,64530,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['extend'],['extended']
Modifiability,"tries will be created that describe where the; artificial variables are allocated at any given program location. The compiler; may allocate them to registers or spill them to memory. The DWARF procedures for each region use the values of the saved execution mask; artificial variables to only update the lanes that are active on entry to the; region. All other lanes retain the value of the enclosing region where they were; last active. If they were not active on entry to the subprogram, then will have; the undefined location description. Other structured control flow regions can be handled similarly. For example,; loops would set the divergent program location for the region at the end of the; loop. Any lanes active will be in the loop, and any lanes not active must have; exited the loop. An ``IF/THEN/ELSEIF/ELSEIF/...`` region can be treated as a nest of; ``IF/THEN/ELSE`` regions. The DWARF procedures can use the active lane artificial variable described in; :ref:`amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane` rather than the actual; ``EXEC`` mask in order to support whole or quad wavefront mode. .. _amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane:. ``DW_AT_LLVM_active_lane``; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ``DW_AT_LLVM_active_lane`` attribute on a subprogram debugger information; entry is used to specify the lanes that are conceptually active for a SIMT; thread. The execution mask may be modified to implement whole or quad wavefront mode; operations. For example, all lanes may need to temporarily be made active to; execute a whole wavefront operation. Such regions would save the ``EXEC`` mask,; update it to enable the necessary lanes, perform the operations, and then; restore the ``EXEC`` mask from the saved value. While executing the whole; wavefront region, the conceptual execution mask is the saved value, not the; ``EXEC`` value. This is handled by defining an artificial variable for the active lane mask. The; active lane mask artificial variable would be the actual ``EX",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:109031,variab,variable,109031,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['variab'],['variable']
Modifiability,"trinsic indicates which function to return the; frame pointer for. Zero indicates the calling function, one indicates; its caller, etc. The argument is **required** to be a constant integer; value. Semantics:; """""""""""""""""""". The '``llvm.frameaddress``' intrinsic either returns a pointer; indicating the frame address of the specified call frame, or zero if it; cannot be identified. The value returned by this intrinsic is likely to; be incorrect or 0 for arguments other than zero, so it should only be; used for debugging purposes. Note that calling this intrinsic does not prevent function inlining or; other aggressive transformations, so the value returned may not be that; of the obvious source-language caller. '``llvm.swift.async.context.addr``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare ptr @llvm.swift.async.context.addr(). Overview:; """""""""""""""""". The '``llvm.swift.async.context.addr``' intrinsic returns a pointer to; the part of the extended frame record containing the asynchronous; context of a Swift execution. Semantics:; """""""""""""""""""". If the caller has a ``swiftasync`` parameter, that argument will initially; be stored at the returned address. If not, it will be initialized to null. '``llvm.localescape``' and '``llvm.localrecover``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.localescape(...); declare ptr @llvm.localrecover(ptr %func, ptr %fp, i32 %idx). Overview:; """""""""""""""""". The '``llvm.localescape``' intrinsic escapes offsets of a collection of static; allocas, and the '``llvm.localrecover``' intrinsic applies those offsets to a; live frame pointer to recover the address of the allocation. The offset is; computed during frame layout of the caller of ``llvm.localescape``. Arguments:; """""""""""""""""""". All arguments to '``llvm.localescape``' must be pointers to static allocas or; casts of static allocas. Each function can only call '``llvm.local",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:512921,extend,extended,512921,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['extend'],['extended']
Modifiability,"trinsic is used to implement coverage; instrumentation. Arguments:; """"""""""""""""""""; The arguments are the same as the first four arguments of; '``llvm.instrprof.increment``'. Semantics:; """"""""""""""""""""; Similar to the '``llvm.instrprof.increment``' intrinsic, but it stores zero to; the profiling variable to signify that the function has been covered. We store; zero because this is more efficient on some targets. '``llvm.instrprof.value.profile``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.instrprof.value.profile(ptr <name>, i64 <hash>,; i64 <value>, i32 <value_kind>,; i32 <index>). Overview:; """""""""""""""""". The '``llvm.instrprof.value.profile``' intrinsic can be emitted by a; frontend for use with instrumentation based profiling. This will be; lowered by the ``-instrprof`` pass to find out the target values,; instrumented expressions take in a program at runtime. Arguments:; """""""""""""""""""". The first argument is a pointer to a global variable containing the; name of the entity being instrumented. ``name`` should generally be the; (mangled) function name for a set of counters. The second argument is a hash value that can be used by the consumer; of the profile data to detect changes to the instrumented source. It; is an error if ``hash`` differs between two instances of; ``llvm.instrprof.*`` that refer to the same name. The third argument is the value of the expression being profiled. The profiled; expression's value should be representable as an unsigned 64-bit value. The; fourth argument represents the kind of value profiling that is being done. The; supported value profiling kinds are enumerated through the; ``InstrProfValueKind`` type declared in the; ``<include/llvm/ProfileData/InstrProf.h>`` header file. The last argument is the; index of the instrumented expression within ``name``. It should be >= 0. Semantics:; """""""""""""""""""". This intrinsic represents the point where a call to a runtime routine; should be inserted for v",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:530834,variab,variable,530834,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variable']
Modifiability,"trtoint>` on constants.; ``inttoptr (CST to TYPE)``; Perform the :ref:`inttoptr operation <i_inttoptr>` on constants.; This one is *really* dangerous!; ``bitcast (CST to TYPE)``; Convert a constant, CST, to another TYPE.; The constraints of the operands are the same as those for the; :ref:`bitcast instruction <i_bitcast>`.; ``addrspacecast (CST to TYPE)``; Convert a constant pointer or constant vector of pointer, CST, to another; TYPE in a different address space. The constraints of the operands are the; same as those for the :ref:`addrspacecast instruction <i_addrspacecast>`.; ``getelementptr (TY, CSTPTR, IDX0, IDX1, ...)``, ``getelementptr inbounds (TY, CSTPTR, IDX0, IDX1, ...)``; Perform the :ref:`getelementptr operation <i_getelementptr>` on; constants. As with the :ref:`getelementptr <i_getelementptr>`; instruction, the index list may have one or more indexes, which are; required to make sense for the type of ""pointer to TY"". These indexes; may be implicitly sign-extended or truncated to match the index size; of CSTPTR's address space.; ``icmp COND (VAL1, VAL2)``; Perform the :ref:`icmp operation <i_icmp>` on constants.; ``fcmp COND (VAL1, VAL2)``; Perform the :ref:`fcmp operation <i_fcmp>` on constants.; ``extractelement (VAL, IDX)``; Perform the :ref:`extractelement operation <i_extractelement>` on; constants.; ``insertelement (VAL, ELT, IDX)``; Perform the :ref:`insertelement operation <i_insertelement>` on; constants.; ``shufflevector (VEC1, VEC2, IDXMASK)``; Perform the :ref:`shufflevector operation <i_shufflevector>` on; constants.; ``add (LHS, RHS)``; Perform an addition on constants.; ``sub (LHS, RHS)``; Perform a subtraction on constants.; ``mul (LHS, RHS)``; Perform a multiplication on constants.; ``shl (LHS, RHS)``; Perform a left shift on constants.; ``xor (LHS, RHS)``; Perform a bitwise xor on constants. Other Values; ============. .. _inlineasmexprs:. Inline Assembler Expressions; ----------------------------. LLVM supports inline assembler expres",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:204674,extend,extended,204674,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['extend'],['extended']
Modifiability,"truction (``%MyStruct``) which is ``ptr``. #. The first index, ``i64 0`` is required to step over the global variable; ``%MyStruct``. Since the second argument to the GEP instruction must always; be a value of pointer type, the first index steps through that pointer. A; value of 0 means 0 elements offset from that pointer. #. The second index, ``i32 1`` selects the second field of the structure (the; ``i32``). What is dereferenced by GEP?; ----------------------------. Quick answer: nothing. The GetElementPtr instruction dereferences nothing. That is, it doesn't access; memory in any way. That's what the Load and Store instructions are for. GEP is; only involved in the computation of addresses. For example, consider this:. .. code-block:: text. @MyVar = external global { i32, ptr }; ...; %idx = getelementptr { i32, ptr }, ptr @MyVar, i64 0, i32 1; %arr = load ptr, ptr %idx; %idx = getelementptr [40 x i32], ptr %arr, i64 0, i64 17. In this example, we have a global variable, ``@MyVar``, which is a pointer to; a structure containing a pointer. Let's assume that this inner pointer points; to an array of type ``[40 x i32]``. The above IR will first compute the address; of the inner pointer, then load the pointer, and then compute the address of; the 18th array element. This cannot be expressed in a single GEP instruction, because it requires; a memory dereference in between. However, the following example would work; fine:. .. code-block:: text. @MyVar = external global { i32, [40 x i32 ] }; ...; %idx = getelementptr { i32, [40 x i32] }, ptr @MyVar, i64 0, i32 1, i64 17. In this case, the structure does not contain a pointer and the GEP instruction; can index through the global variable, into the second field of the structure; and access the 18th ``i32`` in the array there. Why don't GEP x,0,0,1 and GEP x,1 alias?; ----------------------------------------. Quick Answer: They compute different address locations. If you look at the first indices in these GEP instructions y",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:6815,variab,variable,6815,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['variab'],['variable']
Modifiability,"tructor initializers before the colon and after the commas. .. code-block:: c++. Constructor(); : initializer1(),; initializer2(). * ``BCIS_BeforeComma`` (in configuration: ``BeforeComma``); Break constructor initializers before the colon and commas, and align; the commas with the colon. .. code-block:: c++. Constructor(); : initializer1(); , initializer2(). * ``BCIS_AfterColon`` (in configuration: ``AfterColon``); Break constructor initializers after the colon and commas. .. code-block:: c++. Constructor() :; initializer1(),; initializer2(). .. _BreakInheritanceList:. **BreakInheritanceList** (``BreakInheritanceListStyle``) :versionbadge:`clang-format 7` :ref:`¶ <BreakInheritanceList>`; The inheritance list style to use. Possible values:. * ``BILS_BeforeColon`` (in configuration: ``BeforeColon``); Break inheritance list before the colon and after the commas. .. code-block:: c++. class Foo; : Base1,; Base2; {};. * ``BILS_BeforeComma`` (in configuration: ``BeforeComma``); Break inheritance list before the colon and commas, and align; the commas with the colon. .. code-block:: c++. class Foo; : Base1; , Base2; {};. * ``BILS_AfterColon`` (in configuration: ``AfterColon``); Break inheritance list after the colon and commas. .. code-block:: c++. class Foo :; Base1,; Base2; {};. * ``BILS_AfterComma`` (in configuration: ``AfterComma``); Break inheritance list only after the commas. .. code-block:: c++. class Foo : Base1,; Base2; {};. .. _BreakStringLiterals:. **BreakStringLiterals** (``Boolean``) :versionbadge:`clang-format 3.9` :ref:`¶ <BreakStringLiterals>`; Allow breaking string literals when formatting. In C, C++, and Objective-C:. .. code-block:: c++. true:; const char* x = ""veryVeryVeryVeryVeryVe""; ""ryVeryVeryVeryVeryVery""; ""VeryLongString"";. false:; const char* x =; ""veryVeryVeryVeryVeryVeryVeryVeryVeryVeryVeryVeryLongString"";. In C# and Java:. .. code-block:: c++. true:; string x = ""veryVeryVeryVeryVeryVe"" +; ""ryVeryVeryVeryVeryVery"" +; ""VeryLongString"";. false:; s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:55345,config,configuration,55345,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,2,"['config', 'inherit']","['configuration', 'inheritance']"
Modifiability,"tructor' until the C++ compilers properly support the official move constructor notation. Implementing a move constructor avoid having to delete and reconstruct resource during a std::vector resize and avoid the double delete induced by using the default copy constructor. MakeProject now adds dictionaries for auto_ptr. MakeProject no longer request the dictionary for std::pair instances that already have been loaded. Misc. TFile::Open now does variable expansion so that you can include the protocol in the variable (for example: export H1=""http://root.cern/files/h1""; ...; TFile::Open(""$H1/dstarmb.root"");; Added warning if the file does contain any StreamerInfo objects and was written with a different version of ROOT.; Implemented polymorphism for Emulated object (still not supporting polymorphism of Emulated Object inheriting from compiled class). See the Core/Meta section for details.; Add support for streaming auto_ptr when generating their dictionary via rootcint; Enable the use of the I/O customization rules on data members that are either a variable size array or a fixed size array. For example:. #pragma read sourceClass = ""ACache"" targetClass = ""ACache"" version = ""[8]"" \; source = ""Int_t *fArray; Int_t fN;"" \; target = ""fArray"" \; code = ""{ fArray = new Char_t[onfile.fN]; Char_t* gtc=fArray; Int_t* gti=onfile.fArray; \; for(Int_t i=0; i<onfile.fN; i++) *(gtc+i) = *(gti+i)+10; }""; #pragma read sourceClass = ""ACache"" targetClass = ""ACache"" version = ""[8]"" \; source = ""float fValues[3]"" \; target = ""fValues"" \; code = ""{ for(Int_t i=0; i<3; i++) fValues[i] = 1+onfile.fValues[i]; }"". Allow the seamless schema evolution from map<a,b> to vector<pair<a,b> >.; Avoid dropping information when reading a long written on a 64 bits platforms; and being read into a long long on a 32 bits platform (previously the higher; bits were lost due to passing through a 32 bits temporary long).; Migrate the functionality of TStreamerInfo::TagFile to a new interface TBuffer::TagStreamer",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html:9809,variab,variable,9809,io/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html,1,['variab'],['variable']
Modifiability,"tructor; and destructor that initializes and destroys the global iostream objects; before they could possibly be used in the file. The code that you see in the; ``.ll`` file corresponds to the constructor and destructor registration code. If you would like to make it easier to *understand* the LLVM code generated; by the compiler in the demo page, consider using ``printf()`` instead of; ``iostream``\s to print values. Where did all of my code go??; -----------------------------; If you are using the LLVM demo page, you may often wonder what happened to; all of the code that you typed in. Remember that the demo script is running; the code through the LLVM optimizers, so if your code doesn't actually do; anything useful, it might all be deleted. To prevent this, make sure that the code is actually needed. For example, if; you are computing some expression, return the value from the function instead; of leaving it in a local variable. If you really want to constrain the; optimizer, you can read from and assign to ``volatile`` global variables. What is this ""``undef``"" thing that shows up in my code?; --------------------------------------------------------; ``undef`` is the LLVM way of representing a value that is not defined. You; can get these if you do not initialize a variable before you use it. For; example, the C function:. .. code-block:: c. int X() { int i; return i; }. Is compiled to ""``ret i32 undef``"" because ""``i``"" never has a value specified; for it. Why does instcombine + simplifycfg turn a call to a function with a mismatched calling convention into ""unreachable""? Why not make the verifier reject it?; ----------------------------------------------------------------------------------------------------------------------------------------------------------; This is a common problem run into by authors of front-ends that are using; custom calling conventions: you need to make sure to set the right calling; convention on both the function and on each call to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst:8583,variab,variables,8583,interpreter/llvm-project/llvm/docs/FAQ.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FAQ.rst,1,['variab'],['variables']
Modifiability,"tructs. They are used (optionally) in :ref:`DICompositeType` and; :ref:`DISubprogram` ``templateParams:`` fields. .. code-block:: text. !0 = !DITemplateTypeParameter(name: ""Ty"", type: !1). DITemplateValueParameter; """""""""""""""""""""""""""""""""""""""""""""""". ``DITemplateValueParameter`` nodes represent value parameters to generic source; language constructs. ``tag:`` defaults to ``DW_TAG_template_value_parameter``,; but if specified can also be set to ``DW_TAG_GNU_template_template_param`` or; ``DW_TAG_GNU_template_param_pack``. They are used (optionally) in; :ref:`DICompositeType` and :ref:`DISubprogram` ``templateParams:`` fields. .. code-block:: text. !0 = !DITemplateValueParameter(name: ""Ty"", type: !1, value: i32 7). DINamespace; """""""""""""""""""""". ``DINamespace`` nodes represent namespaces in the source language. .. code-block:: text. !0 = !DINamespace(name: ""myawesomeproject"", scope: !1, file: !2, line: 7). .. _DIGlobalVariable:. DIGlobalVariable; """""""""""""""""""""""""""""""". ``DIGlobalVariable`` nodes represent global variables in the source language. .. code-block:: text. @foo = global i32, !dbg !0; !0 = !DIGlobalVariableExpression(var: !1, expr: !DIExpression()); !1 = !DIGlobalVariable(name: ""foo"", linkageName: ""foo"", scope: !2,; file: !3, line: 7, type: !4, isLocal: true,; isDefinition: false, declaration: !5). DIGlobalVariableExpression; """""""""""""""""""""""""""""""""""""""""""""""""""". ``DIGlobalVariableExpression`` nodes tie a :ref:`DIGlobalVariable` together; with a :ref:`DIExpression`. .. code-block:: text. @lower = global i32, !dbg !0; @upper = global i32, !dbg !1; !0 = !DIGlobalVariableExpression(; var: !2,; expr: !DIExpression(DW_OP_LLVM_fragment, 0, 32); ); !1 = !DIGlobalVariableExpression(; var: !2,; expr: !DIExpression(DW_OP_LLVM_fragment, 32, 32); ); !2 = !DIGlobalVariable(name: ""split64"", linkageName: ""split64"", scope: !3,; file: !4, line: 8, type: !5, declaration: !6). All global variable expressions should be referenced by the `globals:` field of; a :ref:`compile unit <DICompileUnit>`. .. _DISubpr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:256453,variab,variables,256453,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variables']
Modifiability,"true is a required pass. For example:. .. code-block:: c++. class HelloWorldPass : public PassInfoMixin<HelloWorldPass> {; public:; PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);. static bool isRequired() { return true; }; };. A required pass is a pass that may not be skipped. An example of a required; pass is ``AlwaysInlinerPass``, which must always be run to preserve; ``alwaysinline`` semantics. Pass managers are required since they may contain; other required passes. An example of how a pass can be skipped is the ``optnone`` function; attribute, which specifies that optimizations should not be run on the; function. Required passes will still be run on ``optnone`` functions. For more implementation details, see; ``PassInstrumentation::runBeforePass()``. Registering passes as plugins; -----------------------------. LLVM provides a mechanism to register pass plugins within various tools like; ``clang`` or ``opt``. A pass plugin can add passes to default optimization; pipelines or to be manually run via tools like ``opt``. For more information,; see :doc:`NewPassManager`. Create a CMake project at the root of the repo alongside; other projects. This project must contain the following minimal; ``CMakeLists.txt``:. .. code-block:: cmake. add_llvm_pass_plugin(MyPassName source.cpp). See the definition of ``add_llvm_pass_plugin`` for more CMake details. The pass must provide at least one of two entry points for the new pass manager,; one for static registration and one for dynamically loaded plugins:. - ``llvm::PassPluginLibraryInfo get##Name##PluginInfo();``; - ``extern ""C"" ::llvm::PassPluginLibraryInfo llvmGetPassPluginInfo() LLVM_ATTRIBUTE_WEAK;``. Pass plugins are compiled and linked dynamically by default. Setting; ``LLVM_${NAME}_LINK_INTO_TOOLS`` to ``ON`` turns the project into a statically; linked extension. For an in-tree example, see ``llvm/examples/Bye/``. To make ``PassBuilder`` aware of statically linked pass plugins:. .. code-block:: c++. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:7472,plugin,plugin,7472,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,1,['plugin'],['plugin']
Modifiability,"try:str = ?, int XEntry:val1 = ?> { // XBase; string Str = XEntry:str;; bits<8> Val1 = { !cast<bits<8>>(XEntry:val1){7}, ... };; bit Val3 = 1;; }; ...; ------------- Defs -----------------; def ATable {	// GenericTable; string FilterClass = ""AEntry"";; string CppTypeName = ""AEntry"";; list<string> Fields = [""Str"", ""Val1"", ""Val2""];; list<string> PrimaryKey = [""Val1"", ""Val2""];; string PrimaryKeyName = ""lookupATableByValues"";; bit PrimaryKeyEarlyOut = 0;; }; ...; def anonymous_0 {	// AEntry; string Str = ""Bob"";; bits<8> Val1 = { 0, 0, 0, 0, 0, 1, 0, 1 };; bits<10> Val2 = { 0, 0, 0, 0, 0, 0, 0, 0, 1, 1 };; }. Classes are shown with their template arguments, parent classes (following; ``//``), and fields. Records are shown with their parent classes and; fields. Note that anonymous records are named ``anonymous_0``,; ``anonymous_1``, etc. The ``PrintDetailedRecords`` Backend; ------------------------------------. The TableGen command option ``--print-detailed-records`` invokes a backend; that prints all the global variables, classes, and records defined in the; source files. The format of the output is *not* guaranteed to be constant; over time. The output looks like this. .. code-block:: text. DETAILED RECORDS for file llvm-project\llvm\lib\target\arc\arc.td. -------------------- Global Variables (5) --------------------. AMDGPUBufferIntrinsics = [int_amdgcn_buffer_load_format, ...; AMDGPUImageDimAtomicIntrinsics = [int_amdgcn_image_atomic_swap_1d, ...; ...; -------------------- Classes (758) --------------------. AMDGPUBufferLoad |IntrinsicsAMDGPU.td:879|; Template args:; LLVMType AMDGPUBufferLoad:data_ty = llvm_any_ty |IntrinsicsAMDGPU.td:879|; Superclasses: (SDPatternOperator) Intrinsic AMDGPURsrcIntrinsic; Fields:; list<SDNodeProperty> Properties = [SDNPMemOperand] |Intrinsics.td:348|; string LLVMName = """" |Intrinsics.td:343|; ...; -------------------- Records (12303) --------------------. AMDGPUSample_lz_o |IntrinsicsAMDGPU.td:560|; Defm sequence: |IntrinsicsAMDGPU.td:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/BackGuide.rst:26656,variab,variables,26656,interpreter/llvm-project/llvm/docs/TableGen/BackGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/BackGuide.rst,1,['variab'],['variables']
Modifiability,"ts are verified. It is the; responsibility of the programmer to ensure that this verification was indeed; correct. Please note that `csa_mark_sanitized` function is only declared and; used during Clang Static Analysis and skipped in (production) builds. Further examples of injection vulnerabilities this checker can find. .. code-block:: c. void test() {; char x = getchar(); // 'x' marked as tainted; system(&x); // warn: untrusted data is passed to a system call; }. // note: compiler internally checks if the second param to; // sprintf is a string literal or not.; // Use -Wno-format-security to suppress compiler warning.; void test() {; char s[10], buf[10];; fscanf(stdin, ""%s"", s); // 's' marked as tainted. sprintf(buf, s); // warn: untrusted data used as a format string; }. void test() {; size_t ts;; scanf(""%zd"", &ts); // 'ts' marked as tainted; int *p = (int *)malloc(ts * sizeof(int));; // warn: untrusted data used as buffer size; }. There are built-in sources, propagations and sinks even if no external taint; configuration is provided. Default sources:; ``_IO_getc``, ``fdopen``, ``fopen``, ``freopen``, ``get_current_dir_name``,; ``getch``, ``getchar``, ``getchar_unlocked``, ``getwd``, ``getcwd``,; ``getgroups``, ``gethostname``, ``getlogin``, ``getlogin_r``, ``getnameinfo``,; ``gets``, ``gets_s``, ``getseuserbyname``, ``readlink``, ``readlinkat``,; ``scanf``, ``scanf_s``, ``socket``, ``wgetch``. Default propagations rules:; ``atoi``, ``atol``, ``atoll``, ``basename``, ``dirname``, ``fgetc``,; ``fgetln``, ``fgets``, ``fnmatch``, ``fread``, ``fscanf``, ``fscanf_s``,; ``index``, ``inflate``, ``isalnum``, ``isalpha``, ``isascii``, ``isblank``,; ``iscntrl``, ``isdigit``, ``isgraph``, ``islower``, ``isprint``, ``ispunct``,; ``isspace``, ``isupper``, ``isxdigit``, ``memchr``, ``memrchr``, ``sscanf``,; ``getc``, ``getc_unlocked``, ``getdelim``, ``getline``, ``getw``, ``memcmp``,; ``memcpy``, ``memmem``, ``memmove``, ``mbtowc``, ``pread``, ``qsort``,; ``qsort_r``, ``rawmemc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:70978,config,configuration,70978,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['config'],['configuration']
Modifiability,"ts automatically, but; meta-classes in Python3, although syntactically richer, have functionally; become far more limited.; In particular, the mro is checked in the builtin class builder, instead of; in the meta-class of the meta-class (which in Python3 is the builtin ``type``; rather than the meta-class itself as in Python2, another limitation, and; which actually checks the mro a second time for no reason).; The upshot is that a helper is required (``cppyy.multi``) to resolve the mro; to support Python3.; The helper is written to also work in Python2.; Example:. .. code-block:: python. >>> class PyConcrete(cppyy.multi(cppyy.gbl.Abstract1, cppyy.gbl.Abstract2)):; ... def abstract_method1(self):; ... return ""first message""; ... def abstract_method2(self):; ... return ""second message""; ...; >>> pc = PyConcrete(); >>> cppyy.gbl.call_abstract_method1(pc); first message; >>> cppyy.gbl/call_abstract_method2(pc); second message; >>>. Contrary to multiple inheritance in Python, in C++ there are no two separate; instances representing the base classes.; Thus, a single ``__init__`` call needs to construct and initialize all bases,; rather than calling ``__init__`` on each base independently.; To support this syntax, the arguments to each base class should be grouped; together in a tuple.; If there are no arguments, provide an empty tuple (or omit them altogether,; if these arguments apply to the right-most base(s)). .. _sec-methods-label:. `Methods`; ---------. C++ methods are represented as Python ones: these are first-class objects and; can be bound to an instance.; If a method is virtual in C++, the proper concrete method is called, whether; or not the concrete class is bound.; Similarly, if all classes are bound, the normal Python rules apply:. .. code-block:: python. >>> c.abstract_method(); called Concrete::abstract_method; >>> c.concrete_method(); called Concrete::concrete_method; >>> m = c.abstract_method; >>> m(); called Concrete::abstract_method; >>>. `Data members`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:6582,inherit,inheritance,6582,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,1,['inherit'],['inheritance']
Modifiability,"ts name. Note that it is possible that there is a; variable of the same name in the outer scope. It would be easy to make; this an error (emit an error and return null if there is already an; entry for VarName) but we choose to allow shadowing of variables. In; order to handle this correctly, we remember the Value that we are; potentially shadowing in ``OldVal`` (which will be null if there is no; shadowed variable). Once the loop variable is set into the symbol table, the code; recursively codegen's the body. This allows the body to use the loop; variable: any references to it will naturally find it in the symbol; table. .. code-block:: c++. // Emit the step value.; Value *StepVal = nullptr;; if (Step) {; StepVal = Step->codegen();; if (!StepVal); return nullptr;; } else {; // If not specified, use 1.0.; StepVal = ConstantFP::get(*TheContext, APFloat(1.0));; }. Value *NextVar = Builder->CreateFAdd(Variable, StepVal, ""nextvar"");. Now that the body is emitted, we compute the next value of the iteration; variable by adding the step value, or 1.0 if it isn't present.; '``NextVar``' will be the value of the loop variable on the next; iteration of the loop. .. code-block:: c++. // Compute the end condition.; Value *EndCond = End->codegen();; if (!EndCond); return nullptr;. // Convert condition to a bool by comparing non-equal to 0.0.; EndCond = Builder->CreateFCmpONE(; EndCond, ConstantFP::get(*TheContext, APFloat(0.0)), ""loopcond"");. Finally, we evaluate the exit value of the loop, to determine whether; the loop should exit. This mirrors the condition evaluation for the; if/then/else statement. .. code-block:: c++. // Create the ""after loop"" block and insert it.; BasicBlock *LoopEndBB = Builder->GetInsertBlock();; BasicBlock *AfterBB =; BasicBlock::Create(*TheContext, ""afterloop"", TheFunction);. // Insert the conditional branch into the end of LoopEndBB.; Builder->CreateCondBr(EndCond, LoopBB, AfterBB);. // Any new code will be inserted in AfterBB.; Builder->SetInsertPoi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl05.rst:24170,variab,variable,24170,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl05.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl05.rst,1,['variab'],['variable']
Modifiability,"ts second and third; operands, if they agree in classification, or else the other if one is known; retain-agnostic. If the cast operand is known retained, the conversion is treated as a; ``__bridge_transfer`` cast. If the cast operand is known unretained or known; retain-agnostic, the conversion is treated as a ``__bridge`` cast. .. admonition:: Rationale. Bridging casts are annoying. Absent the ability to completely automate the; management of CF objects, however, we are left with relatively poor attempts; to reduce the need for a glut of explicit bridges. Hence these rules. We've so far consciously refrained from implicitly turning retained CF; results from function calls into ``__bridge_transfer`` casts. The worry is; that some code patterns --- for example, creating a CF value, assigning it; to an ObjC-typed local, and then calling ``CFRelease`` when done --- are a; bit too likely to be accidentally accepted, leading to mysterious behavior. For loads from ``const`` global variables of :ref:`C retainable pointer type; <arc.misc.c-retainable>`, it is reasonable to assume that global system; constants were initialized with true constants (e.g. string literals), but; user constants might have been initialized with something dynamically; allocated, using a global initializer. .. _arc.objects.restrictions.conversion-exception-contextual:. Conversion from retainable object pointer type in certain contexts; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. :when-revised:`[beginning Apple 4.0, LLVM 3.1]`. If an expression of retainable object pointer type is explicitly cast to a; :ref:`C retainable pointer type <arc.misc.c-retainable>`, the program is; ill-formed as discussed above unless the result is immediately used:. * to initialize a parameter in an Objective-C message send where the parameter; is not marked with the ``cf_consumed`` attribute, or; * to initialize a parameter in a direct call to an; :ref:`audited <arc.misc.c-retainable.audit>` funct",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:28798,variab,variables,28798,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['variab'],['variables']
Modifiability,"ts to ``%u``. For example:. .. code-block:: llvm. ; CHECK: mov r[[#REG:]], 0x[[#%.8X,ADDR:]]. would match ``mov r5, 0x0000FEFE`` and set ``REG`` to the value ``5`` and; ``ADDR`` to the value ``0xFEFE``. Note that due to the precision it would fail; to match ``mov r5, 0xFEFE``. As a result of the numeric variable definition being optional, it is possible; to only check that a numeric value is present in a given format. This can be; useful when the value itself is not useful, for instance:. .. code-block:: gas. ; CHECK-NOT: mov r0, r[[#]]. to check that a value is synthesized rather than moved around. The syntax of a numeric substitution is; ``[[#%<fmtspec>, <constraint> <expr>]]`` where:. * ``<fmtspec>`` is the same format specifier as for defining a variable but; in this context indicating how a numeric expression value should be matched; against. If absent, both components of the format specifier are inferred from; the matching format of the numeric variable(s) used by the expression; constraint if any, and defaults to ``%u`` if no numeric variable is used,; denoting that the value should be unsigned with no leading zeros. In case of; conflict between format specifiers of several numeric variables, the; conversion specifier becomes mandatory but the precision specifier remains; optional. * ``<constraint>`` is the constraint describing how the value to match must; relate to the value of the numeric expression. The only currently accepted; constraint is ``==`` for an exact match and is the default if; ``<constraint>`` is not provided. No matching constraint must be specified; when the ``<expr>`` is empty. * ``<expr>`` is an expression. An expression is in turn recursively defined; as:. * a numeric operand, or; * an expression followed by an operator and a numeric operand. A numeric operand is a previously defined numeric variable, an integer; literal, or a function. Spaces are accepted before, after and between any of; these elements. Numeric operands have 64-bit pre",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst:30271,variab,variable,30271,interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,2,['variab'],['variable']
Modifiability,"ts:. ``` {.bash}; CVMFS_HTTP_PROXY=http://your-proxy-server.domain.ch:3128,DIRECT; CVMFS_REPOSITORIES=your-experiment.cern.ch,sft.cern.ch; CVMFS_QUOTA_LIMIT=50000; ```. You need to properly specify your closest HTTP caching proxy:; separate many of them via commas. The last fallback value, `DIRECT`,; tells cvmfs to connect directly without using any proxy at all. Among the list of repositories (comma-separated), always specify; `sft.cern.ch` and the one containing the software to your experiment; (e.g., `cms.cern.ch`). The quota limit is, in Megabytes, the amount of local disk space to; use as cache. - Check the configuration and repositories with:. # cvmfs_config chksetup; OK; # cvmfs_config probe; Probing /cvmfs/cms.cern.ch... OK; Probing /cvmfs/sft.cern.ch... OK. > You might need special configurations for some custom software; > repositories! Special cases are not covered in this guide. ### Firewall configuration. [PROOF on Demand](http://pod.gsi.de/) is very flexible in handling; various cases of network topologies. The best solution would be to allow; all TCP communications between the cluster machines. No other incoming communication is required from the outside. Configuration steps for the head node only; ------------------------------------------. ### Setup HTTPS+SSH (sshcertauth) authentication. > Latest recommended sshcertauth version is 0.8.5.; >; > [Download](https://github.com/dberzano/sshcertauth/archive/v0.8.5.zip); > and [read the; > instructions](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth). If you want your users to connect to the PROOF cluster using their Grid; user certificate and private key you might be interested in installing; sshcertauth. Please refer to the [installation; guide](http://newton.ph.unito.it/~berzano/w/doku.php?id=proof:sshcertauth); for further information. ### PROOF on Demand. > Latest recommended PROOF on Demand version is 3.12.; >; > **On CernVM-FS:** `/cvmfs/sft.cern.ch/lcg/external/PoD/3.12`; >; > *",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md:3743,flexible,flexible,3743,proof/doc/confman/ConfigProofPoD.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/ConfigProofPoD.md,1,['flexible'],['flexible']
Modifiability,"ts::; :local:. Introduction; ============. This document describes the CommandLine argument processing library. It will; show you how to use it, and what it can do. The CommandLine library uses a; declarative approach to specifying the command line options that your program; takes. By default, these options declarations implicitly hold the value parsed; for the option declared (of course this `can be changed`_). Although there are a **lot** of command line argument parsing libraries out; there in many different languages, none of them fit well with what I needed. By; looking at the features and problems of other libraries, I designed the; CommandLine library to have the following features:. #. Speed: The CommandLine library is very quick and uses little resources. The; parsing time of the library is directly proportional to the number of; arguments parsed, not the number of options recognized. Additionally,; command line argument values are captured transparently into user defined; global variables, which can be accessed like any other variable (and with the; same performance). #. Type Safe: As a user of CommandLine, you don't have to worry about; remembering the type of arguments that you want (is it an int? a string? a; bool? an enum?) and keep casting it around. Not only does this help prevent; error prone constructs, it also leads to dramatically cleaner source code. #. No subclasses required: To use CommandLine, you instantiate variables that; correspond to the arguments that you would like to capture, you don't; subclass a parser. This means that you don't have to write **any**; boilerplate code. #. Globally accessible: Libraries can specify command line arguments that are; automatically enabled in any tool that links to the library. This is; possible because the application doesn't have to keep a list of arguments to; pass to the parser. This also makes supporting `dynamically loaded options`_; trivial. #. Cleaner: CommandLine supports enum and other types di",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:1109,variab,variables,1109,interpreter/llvm-project/llvm/docs/CommandLine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst,2,['variab'],"['variable', 'variables']"
Modifiability,"ts:; implementing support for user-defined binary operators and adding unary; operators. User-defined Binary Operators; =============================. Adding support for user-defined binary operators is pretty simple with; our current framework. We'll first add support for the unary/binary; keywords:. .. code-block:: c++. enum Token {; ...; // operators; tok_binary = -11,; tok_unary = -12; };; ...; static int gettok() {; ...; if (IdentifierStr == ""for""); return tok_for;; if (IdentifierStr == ""in""); return tok_in;; if (IdentifierStr == ""binary""); return tok_binary;; if (IdentifierStr == ""unary""); return tok_unary;; return tok_identifier;. This just adds lexer support for the unary and binary keywords, like we; did in `previous chapters <LangImpl05.html#lexer-extensions-for-if-then-else>`_. One nice thing; about our current AST, is that we represent binary operators with full; generalisation by using their ASCII code as the opcode. For our extended; operators, we'll use this same representation, so we don't need any new; AST or parser support. On the other hand, we have to be able to represent the definitions of; these new operators, in the ""def binary\| 5"" part of the function; definition. In our grammar so far, the ""name"" for the function; definition is parsed as the ""prototype"" production and into the; ``PrototypeAST`` AST node. To represent our new user-defined operators; as prototypes, we have to extend the ``PrototypeAST`` AST node like; this:. .. code-block:: c++. /// PrototypeAST - This class represents the ""prototype"" for a function,; /// which captures its argument names as well as if it is an operator.; class PrototypeAST {; std::string Name;; std::vector<std::string> Args;; bool IsOperator;; unsigned Precedence; // Precedence if a binary op. public:; PrototypeAST(const std::string &Name, std::vector<std::string> Args,; bool IsOperator = false, unsigned Prec = 0); : Name(Name), Args(std::move(Args)), IsOperator(IsOperator),; Precedence(Prec) {}. Function *c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl06.rst:4124,extend,extended,4124,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl06.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl06.rst,1,['extend'],['extended']
Modifiability,"ts; * [[ROOT-10231](https://its.cern.ch/jira/browse/ROOT-10231)] - TMatrixD(a,TMatrixD::kInvMult,b) requires b.GetNcols() = a.GetNcols(); * [[ROOT-10320](https://its.cern.ch/jira/browse/ROOT-10320)] - ROOT/meta does not support anonymous unions/structs; * [[ROOT-10425](https://its.cern.ch/jira/browse/ROOT-10425)] - Missing symbols not reported as missing anymore; * [[ROOT-10546](https://its.cern.ch/jira/browse/ROOT-10546)] - RDataFrame cannot be interrupted from PyROOT; * [[ROOT-10593](https://its.cern.ch/jira/browse/ROOT-10593)] - Segmentation fault when calling a not-yet-defined function from ROOT interpreter; * [[ROOT-10607](https://its.cern.ch/jira/browse/ROOT-10607)] - Several ROOT 7 tests fail when assertions are enabled; * [[ROOT-10613](https://its.cern.ch/jira/browse/ROOT-10613)] - Configuration does not fail when fail-on-missing is ON and cudnn is not found; * [[ROOT-10621](https://its.cern.ch/jira/browse/ROOT-10621)] - Segfault if TFile is used with TRint in teardown; * [[ROOT-10705](https://its.cern.ch/jira/browse/ROOT-10705)] - The ""x"" and ""x0"" options in THnBase::PrintEntries misbehave; * [[ROOT-10789](https://its.cern.ch/jira/browse/ROOT-10789)] - some cppyy examples do not work under ROOT; * [[ROOT-10827](https://its.cern.ch/jira/browse/ROOT-10827)] - Missing contribution of extended term in the error Correction for extended weighted likelihood fits ; * [[ROOT-10859](https://its.cern.ch/jira/browse/ROOT-10859)] - std.make_shared[T] does not work on macOS; * [[ROOT-10866](https://its.cern.ch/jira/browse/ROOT-10866)] - Numerical instabilities when calculating the derivatives for the asymptotically correct erros; * [[ROOT-10958](https://its.cern.ch/jira/browse/ROOT-10958)] - jupyter notebook does not render geometries with new pyroot; * [[ROOT-10977](https://its.cern.ch/jira/browse/ROOT-10977)] - Exit code 0 with failing C++ notebook in nbconvert; * [[ROOT-11006](https://its.cern.ch/jira/browse/ROOT-11006)] - [TTreeReader] Crash when reading array branch",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:55534,extend,extended,55534,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,2,['extend'],['extended']
Modifiability,"ts<8> Opcode = { 0, 0, 0, 0, 0, 0, 0, 1 };; Format Form = MRMDestReg;; bits<7> FormBits = { 0, 1, 0, 1, 0, 0, 0 };; ImmType ImmT = NoImm;; bit ForceDisassemble = 0;; OperandSize OpSize = OpSize32;; bits<2> OpSizeBits = { 1, 0 };; AddressSize AdSize = AdSizeX;; bits<2> AdSizeBits = { 0, 0 };; Prefix OpPrefix = NoPrfx;; bits<3> OpPrefixBits = { 0, 0, 0 };; Map OpMap = OB;; bits<3> OpMapBits = { 0, 0, 0 };; bit hasREX_WPrefix = 0;; FPFormat FPForm = NotFP;; bit hasLockPrefix = 0;; Domain ExeDomain = GenericDomain;; bit hasREPPrefix = 0;; Encoding OpEnc = EncNormal;; bits<2> OpEncBits = { 0, 0 };; bit HasVEX_W = 0;; bit IgnoresVEX_W = 0;; bit EVEX_W1_VEX_W0 = 0;; bit hasVEX_4V = 0;; bit hasVEX_L = 0;; bit ignoresVEX_L = 0;; bit hasEVEX_K = 0;; bit hasEVEX_Z = 0;; bit hasEVEX_L2 = 0;; bit hasEVEX_B = 0;; bits<3> CD8_Form = { 0, 0, 0 };; int CD8_EltSize = 0;; bit hasEVEX_RC = 0;; bit hasNoTrackPrefix = 0;; bits<7> VectSize = { 0, 0, 1, 0, 0, 0, 0 };; bits<7> CD8_Scale = { 0, 0, 0, 0, 0, 0, 0 };; string FoldGenRegForm = ?;; string EVEX2VEXOverride = ?;; bit isMemoryFoldable = 1;; bit notEVEX2VEXConvertible = 0;; }. On the first line of the record, you can see that the ``ADD32rr`` record; inherited from eight classes. Although the inheritance hierarchy is complex,; using parent classes is much simpler than specifying the 109 individual; fields for each instruction. Here is the code fragment used to define ``ADD32rr`` and multiple other; ``ADD`` instructions:. .. code-block:: text. defm ADD : ArithBinOp_RF<0x00, 0x02, 0x04, ""add"", MRM0r, MRM0m,; X86add_flag, add, 1, 1, 1>;. The ``defm`` statement tells TableGen that ``ArithBinOp_RF`` is a; multiclass, which contains multiple concrete record definitions that inherit; from ``BinOpRR_RF``. That class, in turn, inherits from ``BinOpRR``, which; inherits from ``ITy`` and ``Sched``, and so forth. The fields are inherited; from all the parent classes; for example, ``IsIndirectBranch`` is inherited; from the ``Instruction`` class.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:78724,inherit,inherited,78724,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,7,['inherit'],"['inherit', 'inheritance', 'inherited', 'inherits']"
Modifiability,"ts`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Infor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:5728,variab,variable,5728,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,1,['variab'],['variable']
Modifiability,"tten to file. For a detailed description of the interface, the user should look at the; root reference guide at: <http://root.cern.ch/root/Reference.html>. ## Overview of Matrix Classes. The figure below shows an overview of the classes available in the; linear algebra library,` libMatrix.so`. At the center is the base class; **`TMatrixDBase`** from which three different matrix classes,; **`TMatrixD`**, **`TMatrixDSym`** and **`TMatrixDFSparse`** derive. The; user can define customized matrix operations through the classes; **`TElementActionD`** and **`TElementsPosActionD`**. ![Overview of matrix classes](pictures/0300012D.png). Reference to different views of the matrix can be created through the; classes on the right-hand side, see ""Matrix Views"". These references; provide a natural connection to vectors. Matrix decompositions (used in equation solving and matrix inversion); are available through the classes on the left-hand side (see ""Matrix; Decompositions""). They inherit from the **`TDecompBase`** class. The; Eigen Analysis is performed through the classes at the top, see ""Matrix; Eigen Analysis"". In both cases, only some matrix types can be analyzed.; For instance, **`TDecompChol`** will only accept symmetric matrices as; defined **`TMatrixDSym`**. The assignment operator behaves somewhat; different than of most other classes. The following lines will result in; an error:. ``` {.cpp}; TMatrixD a(3,4);; TMatrixD b(5,6);; b = a;; ```. It required to first resize matrix b to the shape of `a`. ``` {.cpp}; TMatrixD a(3,4);; TMatrixD b(5,6);; b.ResizeTo(a);; b = a;; ```. ## Matrix Properties. A matrix has five properties, which are all set in the constructor:. - `precision` - float or double. In the first case you will use the; **`TMatrixF`** class family, in the latter case the **`TMatrixD`**; one;. - `type` - general (**`TMatrixD`**), symmetric (**`TMatrixDSym`**) or; sparse (**`TMatrixDSparse`**);. - `size` - number of rows and columns;. - `index` - range start of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md:2272,inherit,inherit,2272,documentation/users-guide/LinearAlgebra.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md,1,['inherit'],['inherit']
Modifiability,"ttps://clang.llvm.org/doxygen/classclang_1_1Decl.html>`_ vs.; `DeclContext <https://clang.llvm.org/doxygen/classclang_1_1DeclContext.html>`_; inside Clang.; The ``Decl`` hierarchy is done very similarly to the example setup; demonstrated in this tutorial.; The key part is how to then incorporate ``DeclContext``: all that is needed; is in ``bool DeclContext::classof(const Decl *)``, which asks the question; ""Given a ``Decl``, how can I determine if it is-a ``DeclContext``?"".; It answers this with a simple switch over the set of ``Decl`` ""kinds"", and; returning true for ones that are known to be ``DeclContext``'s. .. TODO::. Touch on some of the more advanced features, like ``isa_impl`` and; ``simplify_type``. However, those two need reference documentation in; the form of doxygen comments as well. We need the doxygen so that we can; say ""for full details, see https://llvm.org/doxygen/..."". Rules of Thumb; ==============. #. The ``Kind`` enum should have one entry per concrete class, ordered; according to a preorder traversal of the inheritance tree.; #. The argument to ``classof`` should be a ``const Base *``, where ``Base``; is some ancestor in the inheritance hierarchy. The argument should; *never* be a derived class or the class itself: the template machinery; for ``isa<>`` already handles this case and optimizes it.; #. For each class in the hierarchy that has no children, implement a; ``classof`` that checks only against its ``Kind``.; #. For each class in the hierarchy that has children, implement a; ``classof`` that checks a range of the first child's ``Kind`` and the; last child's ``Kind``. RTTI for Open Class Hierarchies; ===============================. Sometimes it is not possible to know all types in a hierarchy ahead of time.; For example, in the shapes hierarchy described above the authors may have; wanted their code to work for user defined shapes too. To support use cases; that require open hierarchies LLVM provides the ``RTTIRoot`` and; ``RTTIExtends",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSetUpLLVMStyleRTTI.rst:12262,inherit,inheritance,12262,interpreter/llvm-project/llvm/docs/HowToSetUpLLVMStyleRTTI.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSetUpLLVMStyleRTTI.rst,1,['inherit'],['inheritance']
Modifiability,"ttps://github.com/root-project/root/blob/master/roofit/roofitcore/inc/RooFit/Detail/MathFuncs.h). So now that the `doFoo()` function exists in the `MathFuncs` namespace, we; need to comment out its original function definition in the RooFoo class and; also add the namespace `MathFuncs` to wherever `doFoo()` it is referenced; (and also define input parameters for it). ``` {.cpp}; class RooFoo : public RooAbsReal {; ...; // int doFoo() { return a* b + a + b; }. double evaluate() override {; ...; return MathFuncs::doFoo(a, b);; };; ```. Next, create the translate function. Most translate functions include a; `buildCall()` function, that includes the fully qualified name (including; 'MathFuncs') of the function to be called along with the input parameters; as they appear in the function (a,b in the following example). Also, each `translate()` function requires the `addResult()` function. It will; add whatever is represented on the right-hand side to the result (saved in; the `res` variable in the following example) of this class, which can then be; propagated in the rest of the compute graph. ``` {.cpp}; void translate(RooFit::Detail::RooFit::Detail::CodeSquashContext &ctx) const override {; std::string res = ctx.buildCall(""MathFuncs::doFoo"", a, b);; ctx.addResult(this, res);; }. ```. #### When to add the buildCallToAnalyticIntegral() function. Besides creating the `translate()` function, the; `buildCallToAnalyticIntegral()` function also needs to be added when; `analyticalIntegral()` is found in your class. Depending on the code, you can; call one or more integral functions using the `code` parameter. Our RooFoo; example above only contains one integral function (`integralFoo()`). Similar to `doFoo()`, comment out `integralFoo()' in the original file and; move it to 'MathFuncs.h'. As with `doFoo()`. add the relevant inputs (a,b) as parameters, instead of; just class members. ``` {.cpp}; ///// The MathFuncs.h file; int integralFoo(int a, int b) { return /* whatever */;};",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md:22089,variab,variable,22089,roofit/doc/developers/roofit_ad.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md,1,['variab'],['variable']
Modifiability,"ttribute; P0189R1; Clang 3.9. ; P1771R1 (DR); Clang 9. [[maybe_unused]] attribute; P0212R1; Clang 3.9. Aggregate initialization of classes with base classes; P0017R1; Clang 3.9. constexpr lambda expressions; P0170R1; Clang 5. Differing begin and end types in range-based for; P0184R0; Clang 3.9. Lambda capture of *this; P0018R3; Clang 3.9. Direct-list-initialization of enums; P0138R2; Clang 3.9. Hexadecimal floating-point literals; P0245R1; Yes. Using attribute namespaces without repetition; P0028R4; Clang 3.9. Dynamic memory allocation for over-aligned data; P0035R4; Clang 4. Template argument deduction for class templates; P0091R3; Clang 5. ; P0512R0. P0620R0 (DR); Clang 7. P0702R1 (DR); Clang 6. Non-type template parameters with auto type; P0127R2; Clang 4. Guaranteed copy elision; P0135R1; Clang 4. Stricter expression evaluation order; P0145R3; Clang 4 (9). P0400R0. Requirement to ignore unknown attributes; P0283R2; Yes. constexpr if-statements; P0292R2; Clang 3.9. Inline variables; P0386R2; Clang 3.9. Structured bindings; P0217R3; Clang 4. P0961R1 (DR); Clang 8. P0969R0 (DR); Clang 8. Separate variable and condition for if and switch; P0305R1; Clang 3.9. Matching template template parameters to compatible arguments; P0522R0; Partial (10). Removing deprecated dynamic exception specifications; P0003R5; Clang 4. Pack expansions in using-declarations; P0195R2; Clang 4. (8): This is a backwards-incompatible change that is applied to; all language versions that allow type deduction from auto; (per the request of the C++ committee).; In Clang 3.7, a warning is emitted for all cases that would change meaning. (9): Under the MS ABI, function parameters are destroyed from; left to right in the callee. As a result, function parameters in calls to; operator<<, operator>>, operator->*,; operator&&, operator||, and operator,; functions using expression syntax are no longer guaranteed to be destroyed in; reverse construction order in that ABI.; This is not fully supported duri",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_status.html:11816,variab,variables,11816,interpreter/llvm-project/clang/www/cxx_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_status.html,1,['variab'],['variables']
Modifiability,"turn sizeof(p);; // warn: sizeof(ptr) can produce an unexpected result; }. alpha.core.StackAddressAsyncEscape; (C); Check that addresses to stack memory do not escape the function that involves; dispatch_after or dispatch_async. This checker is; a part of core.StackAddressEscape, but is; temporarily disabled until some; false positives are fixed. dispatch_block_t test_block_inside_block_async_leak() {; int x = 123;; void (^inner)(void) = ^void(void) {; int y = x;; ++y;; };; void (^outer)(void) = ^void(void) {; int z = x;; ++z;; inner();; };; return outer; // warn: address of stack-allocated block is captured by a; // returned block; }. alpha.core.TestAfterDivZero; (C, C++, ObjC); Check for division by variable that is later compared against 0.; Either the comparison is useless or there is division by zero. void test(int x) {; var = 77 / x;; if (x == 0) { } // warn; }. C++ Alpha Checkers. Name, DescriptionExample. alpha.cplusplus.ArrayDelete; (C++); Reports destructions of arrays of polymorphic objects that are destructed as; their base class. Base *create() {; Base *x = new Derived[10]; // note: Casting from 'Derived' to 'Base' here; return x;; }. void sink(Base *x) {; delete[] x; // warn: Deleting an array of 'Derived' objects as their base class 'Base' undefined; }. alpha.cplusplus.DeleteWithNonVirtualDtor; (C++); Reports destructions of polymorphic objects with a non-virtual destructor in; their base class. NonVirtual *create() {; NonVirtual *x = new NVDerived(); // note: Casting from 'NVDerived' to; // 'NonVirtual' here; return x;; }. void sink(NonVirtual *x) {; delete x; // warn: destruction of a polymorphic object with no virtual; // destructor; }. alpha.cplusplus.InvalidatedIterator; (C++); Check for use of invalidated iterators. void bad_copy_assign_operator_list1(std::list &L1,; const std::list &L2) {; auto i0 = L1.cbegin();; L1 = L2;; *i0; // warn: invalidated iterator accessed; }. alpha.cplusplus.IteratorRange; (C++); Check for iterators used outside their",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/alpha_checks.html:4399,polymorphi,polymorphic,4399,interpreter/llvm-project/clang/www/analyzer/alpha_checks.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/alpha_checks.html,1,['polymorphi'],['polymorphic']
Modifiability,"turn true;; return a.bam < b.bam;; });. To take best advantage of this formatting, if you are designing an API which; accepts a continuation or single callable argument (be it a function object, or; a ``std::function``), it should be the last argument if at all possible. If there are multiple multi-line lambdas in a statement, or additional; parameters after the lambda, indent the block two spaces from the indent of the; ``[]``:. .. code-block:: c++. dyn_switch(V->stripPointerCasts(),; [] (PHINode *PN) {; // process phis...; },; [] (SelectInst *SI) {; // process selects...; },; [] (LoadInst *LI) {; // process loads...; },; [] (AllocaInst *AI) {; // process allocas...; });. Braced Initializer Lists; """""""""""""""""""""""""""""""""""""""""""""""". Starting from C++11, there are significantly more uses of braced lists to; perform initialization. For example, they can be used to construct aggregate; temporaries in expressions. They now have a natural way of ending up nested; within each other and within function calls in order to build up aggregates; (such as option structs) from local variables. The historically common formatting of braced initialization of aggregate; variables does not mix cleanly with deep nesting, general expression contexts,; function arguments, and lambdas. We suggest new code use a simple rule for; formatting braced initialization lists: act as-if the braces were parentheses; in a function call. The formatting rules exactly match those already well; understood for formatting nested function calls. Examples:. .. code-block:: c++. foo({a, b, c}, {1, 2, 3});. llvm::Constant *Mask[] = {; llvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 0),; llvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 1),; llvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 2)};. This formatting scheme also makes it particularly easy to get predictable,; consistent, and automatic formatting with tools like `Clang Format`_. .. _Clang Format: https://clang.llv",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:20464,variab,variables,20464,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['variab'],['variables']
Modifiability,"tutions are not defined in the proper order, some will remain in the; ``RUN:`` line unexpanded. For example, the following directives refer to; ``%{inner}`` within ``%{outer}`` but do not define ``%{inner}`` until after; ``%{outer}``:. .. code-block:: llvm. ; By default, this definition order does not enable full expansion. ; DEFINE: %{outer} = %{inner}; ; DEFINE: %{inner} = expanded. ; RUN: echo '%{outer}'. ``DEFINE:`` inserts substitutions at the start of the substitution list, so; ``%{inner}`` expands first but has no effect because the original ``RUN:`` line; does not contain ``%{inner}``. Next, ``%{outer}`` expands, and the output of; the ``echo`` command becomes:. .. code-block:: shell. %{inner}. Of course, one way to fix this simple case is to reverse the definitions of; ``%{outer}`` and ``%{inner}``. However, if a test has a complex set of; substitutions that can all reference each other, there might not exist a; sufficient substitution order. To address such use cases, lit configuration files support; ``config.recursiveExpansionLimit``, which can be set to a non-negative integer; to specify the maximum number of passes through the substitution list. Thus, in; the above example, setting the limit to 2 would cause lit to make a second pass; that expands ``%{inner}`` in the ``RUN:`` line, and the output from the ``echo``; command when then be:. .. code-block:: shell. expanded. To improve performance, lit will stop making passes when it notices the ``RUN:``; line has stopped changing. In the above example, setting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit to 1 will thus cause lit to report an error instead of; producing incorrect output. Options; -------. The llvm lit configuration allows to customize some things with user options:. ``llc``, ``opt``, ...; Substitute the respective llvm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:36839,config,configuration,36839,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,2,['config'],"['config', 'configuration']"
Modifiability,"tutorial describes recursive descent; parsing and operator precedence parsing.; - `Chapter #3: Code generation to LLVM IR <LangImpl03.html>`_ - with; the AST ready, we show how easy it is to generate LLVM IR, and show; a simple way to incorporate LLVM into your project.; - `Chapter #4: Adding JIT and Optimizer Support <LangImpl04.html>`_ -; One great thing about LLVM is its support for JIT compilation, so; we'll dive right into it and show you the 3 lines it takes to add JIT; support. Later chapters show how to generate .o files.; - `Chapter #5: Extending the Language: Control Flow <LangImpl05.html>`_ - With; the basic language up and running, we show how to extend; it with control flow operations ('if' statement and a 'for' loop). This; gives us a chance to talk about SSA construction and control; flow.; - `Chapter #6: Extending the Language: User-defined Operators; <LangImpl06.html>`_ - This chapter extends the language to let; users define arbitrary unary and binary operators - with assignable; precedence! This allows us to build a significant piece of the; ""language"" as library routines.; - `Chapter #7: Extending the Language: Mutable Variables; <LangImpl07.html>`_ - This chapter talks about adding user-defined local; variables along with an assignment operator. This shows how easy it is; to construct SSA form in LLVM: LLVM does *not* require your front-end; to construct SSA form in order to use it!; - `Chapter #8: Compiling to Object Files <LangImpl08.html>`_ - This; chapter explains how to take LLVM IR and compile it down to object; files, like a static compiler does.; - `Chapter #9: Debug Information <LangImpl09.html>`_ - A real language; needs to support debuggers, so we; add debug information that allows setting breakpoints in Kaleidoscope; functions, print out argument variables, and call functions!; - `Chapter #10: Conclusion and other tidbits <LangImpl10.html>`_ - This; chapter wraps up the series by discussing ways to extend the language; and includes p",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/index.rst:2972,extend,extends,2972,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/index.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/index.rst,1,['extend'],['extends']
Modifiability,"two; nodes: between the *templated* and the *described* node. There may be various; other kinds of cycles in the AST especially in case of declarations. .. _structural-eq:. Structural Equivalency; ^^^^^^^^^^^^^^^^^^^^^^. Importing one AST node copies that node into the destination ``ASTContext``. To; copy one node means that we create a new node in the ""to"" context then we set; its properties to be equal to the properties of the source node. Before the; copy, we make sure that the source node is not *structurally equivalent* to any; existing node in the destination context. If it happens to be equivalent then; we skip the copy. The informal definition of structural equivalency is the following:; Two nodes are **structurally equivalent** if they are. - builtin types and refer to the same type, e.g. ``int`` and ``int`` are; structurally equivalent,; - function types and all their parameters have structurally equivalent types,; - record types and all their fields in order of their definition have the same; identifier names and structurally equivalent types,; - variable or function declarations and they have the same identifier name and; their types are structurally equivalent. In C, two types are structurally equivalent if they are *compatible types*. For; a formal definition of *compatible types*, please refer to 6.2.7/1 in the C11; standard. However, there is no definition for *compatible types* in the C++; standard. Still, we extend the definition of structural equivalency to; templates and their instantiations similarly: besides checking the previously; mentioned properties, we have to check for equivalent template; parameters/arguments, etc. The structural equivalent check can be and is used independently from the; ASTImporter, e.g. the ``clang::Sema`` class uses it also. The equivalence of nodes may depend on the equivalency of other pairs of nodes.; Thus, the check is implemented as a parallel graph traversal. We traverse; through the nodes of both graphs at the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:92196,variab,variable,92196,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['variab'],['variable']
Modifiability,"ty, e.g. lisp, java, haskell,; javascript, python, etc (note that while these languages are portable,; not all their libraries are). One nice aspect of LLVM is that it is often capable of preserving target; independence in the IR: you can take the LLVM IR for a; Kaleidoscope-compiled program and run it on any target that LLVM; supports, even emitting C code and compiling that on targets that LLVM; doesn't support natively. You can trivially tell that the Kaleidoscope; compiler generates target-independent code because it never queries for; any target-specific information when generating code. The fact that LLVM provides a compact, target-independent,; representation for code gets a lot of people excited. Unfortunately,; these people are usually thinking about C or a language from the C; family when they are asking questions about language portability. I say; ""unfortunately"", because there is really no way to make (fully general); C code portable, other than shipping the source code around (and of; course, C source code is not actually portable in general either - ever; port a really old application from 32- to 64-bits?). The problem with C (again, in its full generality) is that it is heavily; laden with target specific assumptions. As one simple example, the; preprocessor often destructively removes target-independence from the; code when it processes the input text:. .. code-block:: c. #ifdef __i386__; int X = 1;; #else; int X = 42;; #endif. While it is possible to engineer more and more complex solutions to; problems like this, it cannot be solved in full generality in a way that; is better than shipping the actual source code. That said, there are interesting subsets of C that can be made portable.; If you are willing to fix primitive types to a fixed size (say int =; 32-bits, and long = 64-bits), don't care about ABI compatibility with; existing binaries, and are willing to give up some other minor features,; you can have portable code. This can make sense for s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst:6747,portab,portable,6747,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl10.rst,2,['portab'],['portable']
Modifiability,"tyExcessCharacter>`; The penalty for each character outside of the column limit. .. _PenaltyIndentedWhitespace:. **PenaltyIndentedWhitespace** (``Unsigned``) :versionbadge:`clang-format 12` :ref:`¶ <PenaltyIndentedWhitespace>`; Penalty for each character of whitespace indentation; (counted relative to leading non-whitespace column). .. _PenaltyReturnTypeOnItsOwnLine:. **PenaltyReturnTypeOnItsOwnLine** (``Unsigned``) :versionbadge:`clang-format 3.7` :ref:`¶ <PenaltyReturnTypeOnItsOwnLine>`; Penalty for putting the return type of a function onto its own line. .. _PointerAlignment:. **PointerAlignment** (``PointerAlignmentStyle``) :versionbadge:`clang-format 3.7` :ref:`¶ <PointerAlignment>`; Pointer and reference alignment style. Possible values:. * ``PAS_Left`` (in configuration: ``Left``); Align pointer to the left. .. code-block:: c++. int* a;. * ``PAS_Right`` (in configuration: ``Right``); Align pointer to the right. .. code-block:: c++. int *a;. * ``PAS_Middle`` (in configuration: ``Middle``); Align pointer in the middle. .. code-block:: c++. int * a;. .. _QualifierAlignment:. **QualifierAlignment** (``QualifierAlignmentStyle``) :versionbadge:`clang-format 14` :ref:`¶ <QualifierAlignment>`; Different ways to arrange specifiers and qualifiers (e.g. const/volatile). .. warning::. Setting ``QualifierAlignment`` to something other than ``Leave``, COULD; lead to incorrect code formatting due to incorrect decisions made due to; clang-formats lack of complete semantic information.; As such extra care should be taken to review code changes made by the use; of this option. Possible values:. * ``QAS_Leave`` (in configuration: ``Leave``); Don't change specifiers/qualifiers to either Left or Right alignment; (default). .. code-block:: c++. int const a;; const int *a;. * ``QAS_Left`` (in configuration: ``Left``); Change specifiers/qualifiers to be left-aligned. .. code-block:: c++. const int a;; const int *a;. * ``QAS_Right`` (in configuration: ``Right``); Change specifiers/qu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:96351,config,configuration,96351,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['config'],['configuration']
Modifiability,"tyle.py script to update this file. .. raw:: html. <style type=""text/css"">; .versionbadge { background-color: #1c913d; height: 20px; display: inline-block; min-width: 120px; text-align: center; border-radius: 5px; color: #FFFFFF; font-family: ""Verdana,Geneva,DejaVu Sans,sans-serif""; }; </style>. .. role:: versionbadge. ==========================; Clang-Format Style Options; ==========================. :doc:`ClangFormatStyleOptions` describes configurable formatting style options; supported by :doc:`LibFormat` and :doc:`ClangFormat`. When using :program:`clang-format` command line utility or; ``clang::format::reformat(...)`` functions from code, one can either use one of; the predefined styles (LLVM, Google, Chromium, Mozilla, WebKit, Microsoft) or; create a custom style by configuring specific style options. Configuring Style with clang-format; ===================================. :program:`clang-format` supports two ways to provide custom style options:; directly specify style configuration in the ``-style=`` command line option or; use ``-style=file`` and put style configuration in the ``.clang-format`` or; ``_clang-format`` file in the project directory. When using ``-style=file``, :program:`clang-format` for each input file will; try to find the ``.clang-format`` file located in the closest parent directory; of the input file. When the standard input is used, the search is started from; the current directory. When using ``-style=file:<format_file_path>``, :program:`clang-format` for; each input file will use the format file located at `<format_file_path>`.; The path may be absolute or relative to the working directory. The ``.clang-format`` file uses YAML format:. .. code-block:: yaml. key1: value1; key2: value2; # A comment.; ... The configuration file can consist of several sections each having different; ``Language:`` parameter denoting the programming language this section of the; configuration is targeted at. See the description of the **Language** option; b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:1203,config,configuration,1203,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,2,['config'],['configuration']
Modifiability,"type are assumed to hold; normal pointers with no provision for retain and release messages. Foundation defines (and supplies) ``-copy`` and ``-release`` methods for; Blocks. In the Objective-C and Objective-C++ languages, we allow the; ``__weak`` specifier for ``__block`` variables of object type. If; garbage collection is not enabled, this qualifier causes these; variables to be kept without retain messages being sent. This; knowingly leads to dangling pointers if the Block (or a copy) outlives; the lifetime of this object. In garbage collected environments, the ``__weak`` variable is set to; nil when the object it references is collected, as long as the; ``__block`` variable resides in the heap (either by default or via; ``Block_copy()``). The initial Apple implementation does in fact; start ``__block`` variables on the stack and migrate them to the heap; only as a result of a ``Block_copy()`` operation. It is a runtime error to attempt to assign a reference to a; stack-based Block into any storage marked ``__weak``, including; ``__weak`` ``__block`` variables. C++ Extensions; ==============. Block literal expressions within functions are extended to allow const; use of C++ objects, pointers, or references held in automatic storage. As usual, within the block, references to captured variables become; const-qualified, as if they were references to members of a const; object. Note that this does not change the type of a variable of; reference type. For example, given a class Foo:. .. code-block:: c. Foo foo;; Foo &fooRef = foo;; Foo *fooPtr = &foo;. A Block that referenced these variables would import the variables as; const variations:. .. code-block:: c. const Foo block_foo = foo;; Foo &block_fooRef = fooRef;; Foo *const block_fooPtr = fooPtr;. Captured variables are copied into the Block at the instant of; evaluating the Block literal expression. They are also copied when; calling ``Block_copy()`` on a Block allocated on the stack. In both; cases, they are copie",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst:10967,variab,variables,10967,interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,1,['variab'],['variables']
Modifiability,"type of binding called a ""Default"" binding. These are used to provide values to; all the elements of an aggregate type (struct or array) without having to; explicitly specify a binding for each individual element. When there is no Direct binding for a particular region, the store manager; looks at each super-region in turn to see if there is a Default binding. If so,; this value is used as the value of the original region. The search ends when; the base region is reached, at which point the RegionStore will pick an; appropriate default value for the region (usually a symbolic value, but; sometimes zero, for static data, or ""uninitialized"", for stack variables). .. code-block:: cpp. int manyInts[10];; manyInts[1] = 42; // Creates a Direct binding for manyInts[1].; print(manyInts[1]); // Retrieves the Direct binding for manyInts[1];; print(manyInts[0]); // There is no Direct binding for manyInts[0].; // Is there a Default binding for the entire array?; // There is not, but it is a stack variable, so we use; // ""uninitialized"" as the default value (and emit a; // diagnostic!). NOTE: The fact that bindings are stored as a base region plus an offset limits; the Default Binding strategy, because in C aggregates can contain other; aggregates. In the current implementation of RegionStore, there is no way to; distinguish a Default binding for an entire aggregate from a Default binding; for the sub-aggregate at offset 0. Lazy Bindings (LazyCompoundVal); -------------------------------. RegionStore implements an optimization for copying aggregates (structs and; arrays) called ""lazy bindings"", implemented using a special SVal called; LazyCompoundVal. When the store is asked for the ""binding"" for an entire; aggregate (i.e. for an lvalue-to-rvalue conversion), it returns a; LazyCompoundVal instead. When this value is then stored into a variable, it is; bound as a Default value. This makes copying arrays and structs much cheaper; than if they had required memberwise access. Under ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/RegionStore.rst:6102,variab,variable,6102,interpreter/llvm-project/clang/docs/analyzer/developer-docs/RegionStore.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/RegionStore.rst,1,['variab'],['variable']
Modifiability,"type"" boils down to a; function with the right name) everything falls into place. The final piece of code we are missing, is a bit of top-level magic:. .. code-block:: c++. Function *FunctionAST::codegen() {; // Transfer ownership of the prototype to the FunctionProtos map, but keep a; // reference to it for use below.; auto &P = *Proto;; FunctionProtos[Proto->getName()] = std::move(Proto);; Function *TheFunction = getFunction(P.getName());; if (!TheFunction); return nullptr;. // If this is an operator, install it.; if (P.isBinaryOp()); BinopPrecedence[P.getOperatorName()] = P.getBinaryPrecedence();. // Create a new basic block to start insertion into.; BasicBlock *BB = BasicBlock::Create(*TheContext, ""entry"", TheFunction);; ... Basically, before codegening a function, if it is a user-defined; operator, we register it in the precedence table. This allows the binary; operator parsing logic we already have in place to handle it. Since we; are working on a fully-general operator precedence parser, this is all; we need to do to ""extend the grammar"". Now we have useful user-defined binary operators. This builds a lot on; the previous framework we built for other operators. Adding unary; operators is a bit more challenging, because we don't have any framework; for it yet - let's see what it takes. User-defined Unary Operators; ============================. Since we don't currently support unary operators in the Kaleidoscope; language, we'll need to add everything to support them. Above, we added; simple support for the 'unary' keyword to the lexer. In addition to; that, we need an AST node:. .. code-block:: c++. /// UnaryExprAST - Expression class for a unary operator.; class UnaryExprAST : public ExprAST {; char Opcode;; std::unique_ptr<ExprAST> Operand;. public:; UnaryExprAST(char Opcode, std::unique_ptr<ExprAST> Operand); : Opcode(Opcode), Operand(std::move(Operand)) {}. Value *codegen() override;; };. This AST node is very simple and obvious by now. It directly mirrors",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl06.rst:10050,extend,extend,10050,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl06.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl06.rst,1,['extend'],['extend']
Modifiability,"types out of the way,; lets get a little wild and crazy. Lets say that we want our optimizer to accept; a **list** of optimizations to perform, allowing duplicates. For example, we; might want to run: ""``compiler -dce -instsimplify -inline -dce -strip``"". In this; case, the order of the arguments and the number of appearances is very; important. This is what the ""``cl::list``"" template is for. First, start by; defining an enum of the optimizations that you would like to perform:. .. code-block:: c++. enum Opts {; // 'inline' is a C++ keyword, so name it 'inlining'; dce, instsimplify, inlining, strip; };. Then define your ""``cl::list``"" variable:. .. code-block:: c++. cl::list<Opts> OptimizationList(cl::desc(""Available Optimizations:""),; cl::values(; clEnumVal(dce , ""Dead Code Elimination""),; clEnumVal(instsimplify , ""Instruction Simplification""),; clEnumValN(inlining, ""inline"", ""Procedure Integration""),; clEnumVal(strip , ""Strip Symbols"")));. This defines a variable that is conceptually of the type; ""``std::vector<enum Opts>``"". Thus, you can access it with standard vector; methods:. .. code-block:: c++. for (unsigned i = 0; i != OptimizationList.size(); ++i); switch (OptimizationList[i]); ... ... to iterate through the list of options specified. Note that the ""``cl::list``"" template is completely general and may be used with; any data types or other arguments that you can use with the ""``cl::opt``""; template. One especially useful way to use a list is to capture all of the; positional arguments together if there may be more than one specified. In the; case of a linker, for example, the linker takes several '``.o``' files, and; needs to capture them into a list. This is naturally specified as:. .. code-block:: c++. ...; cl::list<std::string> InputFilenames(cl::Positional, cl::desc(""<Input files>""), cl::OneOrMore);; ... This variable works just like a ""``vector<string>``"" object. As such, accessing; the list is simple, just like above. In this example, we used the; `",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:20148,variab,variable,20148,interpreter/llvm-project/llvm/docs/CommandLine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst,1,['variab'],['variable']
Modifiability,"typical data analysis; programs limited by the I/O speed (for example the latencies implied by; reading data from a hard drive). It is therefore expected that this; limitation cannot be eliminated with the usage of any parallel analysis; toolkit. ### Optimisation Regarding N-tuples ###. ROOT automatically applies compression algorithms on n-tuples to reduce; the memory consumption. A value that is in most cases the same will; consume only small space on your disk (but it has to be decompressed on; reading). Nevertheless, you should think about the design of your; n-tuples and your analyses as soon as the processing time exceeds some; minutes. - Try to keep your n-tuples simple and use appropriate variable types.; If your measurement has only a limited precision, it is needless to; store it with double precision. - Experimental conditions that do not change with every single; measurement should be stored in a separate tree. Although the; compression can handle redundant values, the processing time; increase with every variable that has to be filled. - The function `SetCacheSize(long)` specifies the size of the cache; for reading a `TTree` object from a file. The default value is 30MB.; A manual increase may help in certain situations. Please note that; the caching mechanism can cover only one `TTree` object per `TFile`; object. - You can select the branches to be covered by the caching algorithm; with `AddBranchToCache` and deactivate unneeded branches with; `SetBranchStatus`. This mechanism can result in a significant; speed-up for simple operations on trees with many branches. - You can measure the performance easily with `TTreePerfStats`. The; ROOT documentation on this class also includes an introductory; example. For example, `TTreePerfStats` can show you that it is; beneficial to store meta data and payload data separately, i.e.; write the meta data tree in a bulk to a file at the end of your job; instead of writing both trees interleaved. [^6]: The usage of `f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md:14018,variab,variable,14018,documentation/primer/filio.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md,1,['variab'],['variable']
Modifiability,"u find bugs. They typically slow; down LLVM and Clang when enabled, but can be useful during development.; You can manually set :ref:`LLVM_ENABLE_ASSERTIONS <llvm_enable_assertions>`; to override the default from `CMAKE_BUILD_TYPE`. If you are using an IDE such as Visual Studio or Xcode, you should use; the IDE settings to set the build type. **CMAKE_INSTALL_PREFIX**:PATH; Path where LLVM will be installed when the ""install"" target is built. **CMAKE_{C,CXX}_FLAGS**:STRING; Extra flags to use when compiling C and C++ source files respectively. **CMAKE_{C,CXX}_COMPILER**:STRING; Specify the C and C++ compilers to use. If you have multiple; compilers installed, CMake might not default to the one you wish to; use. .. _Frequently Used LLVM-related variables:. Frequently Used LLVM-related variables; --------------------------------------. The default configuration may not match your requirements. Here are; LLVM variables that are frequently used to control that. The full; description is in `LLVM-related variables`_ below. **LLVM_ENABLE_PROJECTS**:STRING; Control which projects are enabled. For example you may want to work on clang; or lldb by specifying ``-DLLVM_ENABLE_PROJECTS=""clang;lldb""``. **LLVM_ENABLE_RUNTIMES**:STRING; Control which runtimes are enabled. For example you may want to work on; libc++ or libc++abi by specifying ``-DLLVM_ENABLE_RUNTIMES=""libcxx;libcxxabi""``. **LLVM_LIBDIR_SUFFIX**:STRING; Extra suffix to append to the directory where libraries are to be; installed. On a 64-bit architecture, one could use ``-DLLVM_LIBDIR_SUFFIX=64``; to install libraries to ``/usr/lib64``. **LLVM_PARALLEL_{COMPILE,LINK}_JOBS**:STRING; Building the llvm toolchain can use a lot of resources, particularly; linking. These options, when you use the Ninja generator, allow you; to restrict the parallelism. For example, to avoid OOMs or going; into swap, permit only one link job per 15GB of RAM available on a; 32GB machine, specify ``-G Ninja -DLLVM_PARALLEL_LINK_JOBS=2``. **LLVM",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:8997,variab,variables,8997,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['variab'],['variables']
Modifiability,"u're still; probably better off simply splitting the value into two separate operands, for; clarity. (e.g. see the description of the ``A`` constraint on X86, which,; despite existing only for use with this feature, is not really a good idea to; use). Indirect inputs and outputs; """""""""""""""""""""""""""""""""""""""""""""""""""""". Indirect output or input constraints can be specified by the ""``*``"" modifier; (which goes after the ""``=``"" in case of an output). This indicates that the asm; will write to or read from the contents of an *address* provided as an input; argument. (Note that in this way, indirect outputs act more like an *input* than; an output: just like an input, they consume an argument of the call expression,; rather than producing a return value. An indirect output constraint is an; ""output"" only in that the asm is expected to write to the contents of the input; memory location, instead of just read from it). This is most typically used for memory constraint, e.g. ""``=*m``"", to pass the; address of a variable as a value. It is also possible to use an indirect *register* constraint, but only on output; (e.g. ""``=*r``""). This will cause LLVM to allocate a register for an output; value normally, and then, separately emit a store to the address provided as; input, after the provided inline asm. (It's not clear what value this; functionality provides, compared to writing the store explicitly after the asm; statement, and it can only produce worse code, since it bypasses many; optimization passes. I would recommend not using it.). Call arguments for indirect constraints must have pointer type and must specify; the :ref:`elementtype <attr_elementtype>` attribute to indicate the pointer; element type. Clobber constraints; """""""""""""""""""""""""""""""""""""". A clobber constraint is indicated by a ""``~``"" prefix. A clobber does not; consume an input operand, nor generate an output. Clobbers cannot use any of the; general constraint code letters -- they may use only explicit register; constraints, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:216294,variab,variable,216294,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variable']
Modifiability,"uage-defined (commands implemented in C++ in CMake), defined; functions, and defined macros. The CMake distribution also contains a suite of; CMake modules that contain definitions for useful functionality. The example below is the full CMake build for building a C++ ""Hello World""; program. The example uses only CMake language-defined functions. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(HelloWorld); add_executable(HelloWorld HelloWorld.cpp). The CMake language provides control flow constructs in the form of foreach loops; and if blocks. To make the example above more complicated you could add an if; block to define ""APPLE"" when targeting Apple platforms:. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(HelloWorld); add_executable(HelloWorld HelloWorld.cpp); if(APPLE); target_compile_definitions(HelloWorld PUBLIC APPLE); endif(). Variables, Types, and Scope; ===========================. Dereferencing; -------------. In CMake variables are ""stringly"" typed. All variables are represented as; strings throughout evaluation. Wrapping a variable in ``${}`` dereferences it; and results in a literal substitution of the name for the value. CMake refers to; this as ""variable evaluation"" in their documentation. Dereferences are performed; *before* the command being called receives the arguments. This means; dereferencing a list results in multiple separate arguments being passed to the; command. Variable dereferences can be nested and be used to model complex data. For; example:. .. code-block:: cmake. set(var_name var1); set(${var_name} foo) # same as ""set(var1 foo)""; set(${${var_name}}_var bar) # same as ""set(foo_var bar)"". Dereferencing an unset variable results in an empty expansion. It is a common; pattern in CMake to conditionally set variables knowing that it will be used in; code paths that the variable isn't set. There are examples of this throughout; the LLVM CMake build system. An example of variable empty expansion ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:2855,variab,variables,2855,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst,1,['variab'],['variables']
Modifiability,"ualization, the resulting; RuntimeDefinition contains a Decl corresponding to the definition of the called; function, and RuntimeDefinition::mayHaveOtherDefinitions will return FALSE. In the case of dynamic dispatch where our information is not perfect, CallEvent; can make a guess, but RuntimeDefinition::mayHaveOtherDefinitions will return; TRUE. The RuntimeDefinition object will then also include a MemRegion; corresponding to the object being called (i.e., the ""receiver"" in Objective-C; parlance), which ExprEngine uses to decide whether or not the call should be; inlined. Inlining Dynamic Calls; ^^^^^^^^^^^^^^^^^^^^^^. The -analyzer-config ipa option has five different modes: none, basic-inlining,; inlining, dynamic, and dynamic-bifurcate. Under -analyzer-config ipa=dynamic,; all dynamic calls are inlined, whether we are certain or not that this will; actually be the definition used at runtime. Under -analyzer-config ipa=inlining,; only ""near-perfect"" devirtualized calls are inlined*, and other dynamic calls; are evaluated conservatively (as if no definition were available). * Currently, no Objective-C messages are not inlined under; -analyzer-config ipa=inlining, even if we are reasonably confident of the type; of the receiver. We plan to enable this once we have tested our heuristics; more thoroughly. The last option, -analyzer-config ipa=dynamic-bifurcate, behaves similarly to; ""dynamic"", but performs a conservative invalidation in the general virtual case; in *addition* to inlining. The details of this are discussed below. As stated above, -analyzer-config ipa=basic-inlining does not inline any C++; member functions or Objective-C method calls, even if they are non-virtual or; can be safely devirtualized. Bifurcation; ^^^^^^^^^^^. ExprEngine::BifurcateCall implements the ``-analyzer-config ipa=dynamic-bifurcate``; mode. When a call is made on an object with imprecise dynamic type information; (RuntimeDefinition::mayHaveOtherDefinitions() evaluates to TRUE), Exp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst:12092,config,config,12092,interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst,1,['config'],['config']
Modifiability,"ually 'this'), `in`; (string to add to the squashed code).; - Output: Adds the input string to the squashed code body. - **RooFit::Detail::CodeSquashContext::addToGlobalScope()**: Helps declare and; initialize the results variable, so that it can be available globally; (throughout the function body). - Input: `str` (the string to add to the global scope).; - Output: Adds the given string to the string block that will be emitted at; the top of the squashed function. - **RooFit::Detail::CodeSquashContext::assembleCode()**: combines the generated; code statements into the final code body of the squashed function. - Input: `returnExpr` (he string representation of what the squashed function; should return, usually the head node).; - Output: The final body of the function. - **RooFit::Detail::CodeSquashContext::beginLoop()**: The code squashing task; will automatically build a For loop around the indented statements that follow; this function. - Input: `in` (a pointer to the calling class, used to determine the loop; dependent variables).; - Output: A scope for iterating over vector observables. - **RooFit::Detail::CodeSquashContext::buildArg()**: helps convert RooFit; objects into arrays or other C++ representations for efficient computation. - Input: `in` (the list to convert to array).; - Output: Name of the array that stores the input list in the squashed code. - **RooFit::Detail::CodeSquashContext::buildCall()**: Creates a string; representation of the function to be called and its arguments. - Input: A function with name `funcname`, passing some arguments.; - Output: A string representation of the function to be called. - **RooFit::Detail::makeValidVarName()**: It helps fetch and save a valid name; from the name of the respective RooFit class. - Input: `in` (the input string).; - Output: A new string that is a valid variable name. - **RooFuncWrapper::buildCode()**: Generates the optimized code for evaluating; the function and its derivatives. - Input: `head` (starti",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md:36609,variab,variables,36609,roofit/doc/developers/roofit_ad.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md,1,['variab'],['variables']
Modifiability,"uaternion.h, TRobustEstimator.h, TRolke.h,; TRotation.h, TVector2.h, TVector3.h; ```. ## How to Find More Information. website The ROOT web site has up to date documentation. The ROOT; source code automatically generates this documentation, so each class; is explicitly documented on its own web page, which is always up to; date with the latest official release of ROOT. The ROOT Reference Guide web pages can be found at class index; reference guide <https://root.cern/doc/master/classes.html>. Each; page contains a class description, and an explanation of each method.; It shows the class inheritance tree and lets you jump to the parent; class page by clicking on the class name. If you want more details,; you can even see the source. There is a help page available in the; little box on the upper right hand side of each class documentation; page. You can see on the next page what a typical class documentation; web page looks like. The ROOT web site also contains in addition to; this Reference Guide, ""How To's"", a list of publications and example; applications. ### Class Reference Guide. The top of any class reference page lets you jump to different parts; of the documentation. The first line links to the class index and the; index for the current module (a group of classes, often a library).; The second line links to the ROOT homepage and the class overviews.; The third line links the source information - a HTML version of the; source and header file as well as the CVS (the source management; system used for the ROOT development) information of the files. The; last line links the different parts of the current pages. ![](pictures/03000006.png). ![Example of function documentation, with automatically generated LaTeX-like graphics](pictures/03000007.png). ![Inheritance tree, showing what the current class derives from, and which classes inherit from it](pictures/03000008.png). ![HTML version of the source file linking all types and most functions](pictures/03000009.png); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:25904,inherit,inherit,25904,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,1,['inherit'],['inherit']
Modifiability,"ubproject in a separate file, the; git repository contains all of the projects together. If you want to get a specific release (as opposed to the most recent revision),; you can check out a tag after cloning the repository. E.g., `git checkout; llvmorg-6.0.1` inside the ``llvm-project`` directory created by the above; command. Use `git tag -l` to list all of them. Sending patches; ^^^^^^^^^^^^^^^. See :ref:`Contributing <submit_patch>`. Bisecting commits; ^^^^^^^^^^^^^^^^^. See `Bisecting LLVM code <GitBisecting.html>`_ for how to use ``git bisect``; on LLVM. Reverting a change; ^^^^^^^^^^^^^^^^^^. When reverting changes using git, the default message will say ""This reverts; commit XYZ"". Leave this at the end of the commit message, but add some details; before it as to why the commit is being reverted. A brief explanation and/or; links to bots that demonstrate the problem are sufficient. Local LLVM Configuration; ------------------------. Once checked out repository, the LLVM suite source code must be configured; before being built. This process uses CMake. Unlinke the normal ``configure``; script, CMake generates the build files in whatever format you request as well; as various ``*.inc`` files, and ``llvm/include/llvm/Config/config.h.cmake``. Variables are passed to ``cmake`` on the command line using the format; ``-D<variable name>=<value>``. The following variables are some common options; used by people developing LLVM. +-------------------------+----------------------------------------------------+; | Variable | Purpose |; +=========================+====================================================+; | CMAKE_C_COMPILER | Tells ``cmake`` which C compiler to use. By |; | | default, this will be /usr/bin/cc. |; +-------------------------+----------------------------------------------------+; | CMAKE_CXX_COMPILER | Tells ``cmake`` which C++ compiler to use. By |; | | default, this will be /usr/bin/c++. |; +-------------------------+-----------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:23585,config,configured,23585,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['config'],['configured']
Modifiability,"uct.char_buffer. # With thew new cppyy, you get access to the lower level buffer instead of a; # Python string:; print(""struct.char_buffer : "", char_buffer). # However, you can turn the buffer into a string very easily with as_string():; print(""struct.char_buffer.as_string(): "", char_buffer.as_string()); ```; The output of this script with ROOT 6.32:; ```; struct.char_buffer : <cppyy.LowLevelView object at 0x74c7a2682fb0>; struct.char_buffer.as_string(): foo; ```. ### Deprecate the attribute pythonization of `TDirectory` in favor of item-getting syntax. The new recommended way to get objects from a `TFile` or any `TDirectory` in general is now via `__getitem__`:. ```python; tree = my_file[""my_tree""] # instead of my_file.my_tree; ```. This is more consistent with other Python collections (like dictionaries), makes sure that member functions can't be confused with branch names, and easily allows you to use string variables as keys. With the new dictionary-like syntax, you can also get objects with names that don't qualify as a Python variable. Here is a short demo:; ```python; import ROOT. with ROOT.TFile.Open(""my_file.root"", ""RECREATE"") as my_file:. # Populate the TFile with simple objects.; my_file.WriteObject(ROOT.std.string(""hello world""), ""my_string""); my_file.WriteObject(ROOT.vector[""int""]([1, 2, 3]), ""my vector""). print(my_file[""my_string""]) # new syntax; print(my_file.my_string) # old deprecated syntax. # With the dictionary syntax, you can also use names that don't qualify as; # a Python variable:; print(my_file[""my vector""]); # print(my_file.my vector) # the old syntax would not work here!; ```. The old pythonization with the `__getattr__` syntax still works, but emits a deprecation warning and will be removed from ROOT 6.34. ### Removal of Python 2 support. ROOT does no longer support Python 2. The minimum Python version necessary to use ROOT in a Python application is 3.8.; As a consequence, any reference to Python 2 in ROOT code was removed and certain co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:21695,variab,variable,21695,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['variab'],['variable']
Modifiability,ude/Mapping.h; openmp/libomptarget/DeviceRTL/include/State.h; openmp/libomptarget/DeviceRTL/include/Synchronization.h; openmp/libomptarget/DeviceRTL/include/Types.h; openmp/libomptarget/DeviceRTL/include/Utils.h; openmp/libomptarget/DeviceRTL/src/Configuration.cpp; openmp/libomptarget/DeviceRTL/src/Kernel.cpp; openmp/libomptarget/DeviceRTL/src/Misc.cpp; openmp/libomptarget/DeviceRTL/src/Parallelism.cpp; openmp/libomptarget/DeviceRTL/src/Reduction.cpp; openmp/libomptarget/DeviceRTL/src/State.cpp; openmp/libomptarget/DeviceRTL/src/Synchronization.cpp; openmp/libomptarget/DeviceRTL/src/Tasking.cpp; openmp/libomptarget/DeviceRTL/src/Utils.cpp; openmp/libomptarget/include/Debug.h; openmp/libomptarget/include/device.h; openmp/libomptarget/include/DeviceEnvironment.h; openmp/libomptarget/include/interop.h; openmp/libomptarget/include/omptarget.h; openmp/libomptarget/include/omptargetplugin.h; openmp/libomptarget/include/rtl.h; openmp/libomptarget/include/SourceInfo.h; openmp/libomptarget/plugins/amdgpu/dynamic_hsa/hsa.cpp; openmp/libomptarget/plugins/amdgpu/dynamic_hsa/hsa.h; openmp/libomptarget/plugins/amdgpu/impl/get_elf_mach_gfx_name.cpp; openmp/libomptarget/plugins/amdgpu/impl/get_elf_mach_gfx_name.h; openmp/libomptarget/plugins/amdgpu/impl/hsa_api.h; openmp/libomptarget/plugins/amdgpu/impl/impl.cpp; openmp/libomptarget/plugins/amdgpu/impl/impl_runtime.h; openmp/libomptarget/plugins/amdgpu/impl/internal.h; openmp/libomptarget/plugins/amdgpu/impl/interop_hsa.cpp; openmp/libomptarget/plugins/amdgpu/impl/msgpack.cpp; openmp/libomptarget/plugins/amdgpu/impl/msgpack.h; openmp/libomptarget/plugins/amdgpu/impl/rt.h; openmp/libomptarget/plugins/amdgpu/src/print_tracing.h; openmp/libomptarget/plugins/common/elf_common/elf_common.cpp; openmp/libomptarget/plugins/common/elf_common/elf_common.h; openmp/libomptarget/plugins/common/MemoryManager/MemoryManager.h; openmp/libomptarget/plugins/cuda/dynamic_cuda/cuda.cpp; openmp/libomptarget/plugins/cuda/dynamic_cuda/cuda.h; openmp/libom,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:406846,plugin,plugins,406846,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['plugin'],['plugins']
Modifiability,"ue and; initial uncertainty. ### add(...) ###. The method MnUserParameters::add(...) is overloaded for three kind of; parameters:. - add(const char\*, double, double) for adding a free variable; parameter. - add(const char\*, double, double, double, double) for adding a; variable parameter with limits (lower and upper). - add(const char\*, double) for adding a constant parameter. When adding parameters, M assigns indices to each parameter which will; be the same as in the std::vector$<$double$>$ in the; FCNBase::operator(). That means the first parameter the user adds gets; index 0, the second index 1, and so on. When calculating the function; value inside FCN, M will call FCNBase::operator() with the elements at; their positions. ### setValue(...) ###. [api:setvalue] setValue(unsigned int parno, double value) or; setValue(const char\* name, double value) set the value of parameter; $\mbox{parno}$ or with name $\mbox{name}$ to; $\mbox{ value}$. The parameter in question may be variable, fixed,; or constant, but must be defined. ### setError(...) ###. [api:seterror] setError(unsigned int parno, double error) or; setError(const char\* name, double error) set the error (sigma) of; parameter $\mbox{parno}$ or with name $\mbox{name}$ to; $\mbox{value}$. ### fix(...) ###. [api:fix] fix(unsigned int parno) or fix(const char\* name) fixes; parameter $\mbox{parno}$ or with name $\mbox{name}$. ### release(...) ###. [api:release] release(unsigned int parno) or release(const char\* name); releases a previously fixed parameter $\mbox{parno}$ or with name; $\mbox{name}$. ### setLimits(...) ###. [api:setlimits] setLimits(unsigned int n, double low, double up) or; setLimits(const char\* name, double low, double up) sets the lower and; upper bound of parameter $\mbox{n}$ or with name $\mbox{name}$. However, if $\mbox{low}$ is equal to $\mbox{up}$, an error; condition results. ### setUpperLimit(...) ###. [api:setupperlimits] setUpperLimit(unsigned int n, double up) or; setUpperLimit(c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:54401,variab,variable,54401,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['variab'],['variable']
Modifiability,"ueeze out all parameters that are not variable. - Transform all variable parameters with limits, so that the; transformed parameter can vary without limits. (See the next section; for details concerning this transformation.) Because this; transformation is non-linear, it is recommended to avoid putting; limits on parameters where they are not needed. As an example, suppose that the user has defined the following; parameters:. - Parameter 0, constant. - Parameter 1, freely variable. - Parameter 2, variable with limits. - Parameter 3, constant. - Parameter 4, freely variable. Then the internal parameter list would be as follows:. - Internal parameter 0 = external parameter 1. - Internal parameter 1 = external parameter 2, transformed; appropriately. - Internal parameter 2 = external parameter 4. In the above example, M considers that the number of external parameters; is 5, and the number of internal parameters is 3. This is the number; which determines, for example, the size of the error matrix of the; parameters, since only variable parameters have errors. An important feature of M is that parameters are allowed to change types; during the M minimization and analysis of a $\mbox{FCN}$ function.; Several applications in M have methods available to make variable; parameters fixed and vice-versa; to impose, change, or remove limits; from variable parameters; and even to define completely new parameters; at any time during a run. In addition, some M applications (notably the; $\mbox{MINOS}$ error analysis) cause one or more variable parameters; to be temporarily fixed during the calculation. Therefore, the; correspondence between external and internal parameter lists is in; general a dynamic one, and the number of internal parameters is not; necessarily constant. For more details about parameter interaction see [api:parameters]. ### The transformation for parameters with limits ###. [intro:limits]. For variable parameters with double sided limits $a$ (lower) and $b$; (u",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:7272,variab,variable,7272,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['variab'],['variable']
Modifiability,"ues are `⊤`"" is; understood as ""at this program point `x` can have any value because we have too; much information, or the information is conflicting"". Note that we can get more than 3 possible values even without a loop:. ```c++; void ExampleOfTopWithoutLoops(int n) {; int x = 0; // x is {0}; switch(n) {; case 0: x = 1; break; // x is {1}; case 1: x = 9; break; // x is {9}; case 2: x = 7; break; // x is {7}; default: x = 3; break; // x is {3}; }; // x is ⊤; }; ```. ### Uninitialized variables and ""bottom"" values. When `x` is declared but not initialized, it has no possible values. We; represent this fact symbolically as `⊥` (pronounced ""bottom""). ```c++; void ExampleOfBottom() {; int x; // x is ⊥; x = 42; // x is {42}; print(x);; }; ```. Note that using values read from uninitialized variables is undefined behaviour; in C++. Generally, compilers and static analysis tools can assume undefined; behavior does not happen. We must model uninitialized variables only when we are; implementing a checker that specifically is trying to find uninitialized reads.; In this example we show how to model uninitialized variables only to demonstrate; the concept of ""bottom"", and how it applies to possible value analysis. We; describe an analysis that finds uninitialized reads in a section below. ### A practical lattice that tracks sets of concrete values. Taking into account all corner cases covered above, we can put together a; lattice that we can use in practice to track possible values of integer; variables. This lattice represents sets of integers with 1, 2, or 3 elements, as; well as top and bottom. Here is a Hasse diagram for it:. ![Hasse diagram for a lattice of integer sets](DataFlowAnalysisIntroImages/IntegerSetsFiniteLattice.svg). ### Formalization. Let's consider a slightly more complex example, and think about how we can; compute the sets of possible values algorithmically. ```c++; void Example(int n) {; int x; // x is ⊥; if (n > 0) {; if (n == 42) {; x = 44; // x is {44",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:6222,variab,variables,6222,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,1,['variab'],['variables']
Modifiability,"ugger to form stack traces, show information about local variables, etc. This section of the documentation first describes the representation aspects; common to any source-language. :ref:`ccxx_frontend` describes the data layout; conventions used by the C and C++ front-ends. Debug information descriptors are `specialized metadata nodes; <LangRef.html#specialized-metadata>`_, first-class subclasses of ``Metadata``. .. _format_common_intrinsics:. Debugger intrinsic functions; ----------------------------. LLVM uses several intrinsic functions (name prefixed with ""``llvm.dbg``"") to; track source local variables through optimization and code generation. ``llvm.dbg.declare``; ^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.dbg.declare(metadata, metadata, metadata). This intrinsic provides information about a local element (e.g., variable).; The first argument is metadata holding the address of variable, typically a; static alloca in the function entry block. The second argument is a; `local variable <LangRef.html#dilocalvariable>`_ containing a description of; the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.declare` intrinsic describes the; *address* of a source variable. .. code-block:: text. %i.addr = alloca i32, align 4; call void @llvm.dbg.declare(metadata i32* %i.addr, metadata !1,; metadata !DIExpression()), !dbg !2; !1 = !DILocalVariable(name: ""i"", ...) ; int i; !2 = !DILocation(...); ...; %buffer = alloca [256 x i8], align 8; ; The address of i is buffer+64.; call void @llvm.dbg.declare(metadata [256 x i8]* %buffer, metadata !3,; metadata !DIExpression(DW_OP_plus, 64)), !dbg !4; !3 = !DILocalVariable(name: ""i"", ...) ; int i; !4 = !DILocation(...). A frontend should generate exactly one call to ``llvm.dbg.declare`` at the point; of declaration of a source variable. Optimization passes that fully promote the; variable from memory to SSA values will replace this call with possibly multiple; calls to `llvm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:8744,variab,variable,8744,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['variab'],['variable']
Modifiability,"uild your program with; ``-fsanitize=cfi -fno-sanitize=cfi-nvcall,cfi-icall``; to use all schemes except for non-virtual member function call and indirect call; checking. Remember that you have to provide ``-flto`` or ``-flto=thin`` if at; least one CFI scheme is enabled. Trapping and Diagnostics; ========================. By default, CFI will abort the program immediately upon detecting a control; flow integrity violation. You can use the :ref:`-fno-sanitize-trap=; <controlling-code-generation>` flag to cause CFI to print a diagnostic; similar to the one below before the program aborts. .. code-block:: console. bad-cast.cpp:109:7: runtime error: control flow integrity check for type 'B' failed during base-to-derived cast (vtable address 0x000000425a50); 0x000000425a50: note: vtable is of type 'A'; 00 00 00 00 f0 f1 41 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 20 5a 42 00; ^. If diagnostics are enabled, you can also configure CFI to continue program; execution instead of aborting by using the :ref:`-fsanitize-recover=; <controlling-code-generation>` flag. Forward-Edge CFI for Virtual Calls; ==================================. This scheme checks that virtual calls take place using a vptr of the correct; dynamic type; that is, the dynamic type of the called object must be a; derived class of the static type of the object used to make the call.; This CFI scheme can be enabled on its own using ``-fsanitize=cfi-vcall``. For this scheme to work, all translation units containing the definition; of a virtual member function (whether inline or not), other than members; of :ref:`ignored <cfi-ignorelist>` types or types with public :doc:`LTO; visibility <LTOVisibility>`, must be compiled with ``-flto`` or ``-flto=thin``; enabled and be statically linked into the program. Performance; -----------. A performance overhead of less than 1% has been measured by running the; Dromaeo benchmark suite against an instrumented version of the Chromium; web browser. Anot",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrity.rst:3909,config,configure,3909,interpreter/llvm-project/clang/docs/ControlFlowIntegrity.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ControlFlowIntegrity.rst,1,['config'],['configure']
Modifiability,"uilder->GetInsertBlock()->getParent();. // Create an alloca for the variable in the entry block.; AllocaInst *Alloca = CreateEntryBlockAlloca(TheFunction, VarName);. // Emit the start code first, without 'variable' in scope.; Value *StartVal = Start->codegen();; if (!StartVal); return nullptr;. // Store the value into the alloca.; Builder->CreateStore(StartVal, Alloca);; ... // Compute the end condition.; Value *EndCond = End->codegen();; if (!EndCond); return nullptr;. // Reload, increment, and restore the alloca. This handles the case where; // the body of the loop mutates the variable.; Value *CurVar = Builder->CreateLoad(Alloca->getAllocatedType(), Alloca,; VarName.c_str());; Value *NextVar = Builder->CreateFAdd(CurVar, StepVal, ""nextvar"");; Builder->CreateStore(NextVar, Alloca);; ... This code is virtually identical to the code `before we allowed mutable; variables <LangImpl05.html#code-generation-for-the-for-loop>`_. The big difference is that we; no longer have to construct a PHI node, and we use load/store to access; the variable as needed. To support mutable argument variables, we need to also make allocas for; them. The code for this is also pretty simple:. .. code-block:: c++. Function *FunctionAST::codegen() {; ...; Builder->SetInsertPoint(BB);. // Record the function arguments in the NamedValues map.; NamedValues.clear();; for (auto &Arg : TheFunction->args()) {; // Create an alloca for this variable.; AllocaInst *Alloca = CreateEntryBlockAlloca(TheFunction, Arg.getName());. // Store the initial value into the alloca.; Builder->CreateStore(&Arg, Alloca);. // Add arguments to variable symbol table.; NamedValues[std::string(Arg.getName())] = Alloca;; }. if (Value *RetVal = Body->codegen()) {; ... For each argument, we make an alloca, store the input value to the; function into the alloca, and register the alloca as the memory location; for the argument. This method gets invoked by ``FunctionAST::codegen()``; right after it sets up the entry block for the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:15483,variab,variable,15483,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['variab'],['variable']
Modifiability,"uilder.cpp``. C/C++ source file information; -----------------------------. ``llvm::Instruction`` provides easy access to metadata attached with an; instruction. One can extract line number information encoded in LLVM IR using; ``Instruction::getDebugLoc()`` and ``DILocation::getLine()``. .. code-block:: c++. if (DILocation *Loc = I->getDebugLoc()) { // Here I is an LLVM instruction; unsigned Line = Loc->getLine();; StringRef File = Loc->getFilename();; StringRef Dir = Loc->getDirectory();; bool ImplicitCode = Loc->isImplicitCode();; }. When the flag ImplicitCode is true then it means that the Instruction has been; added by the front-end but doesn't correspond to source code written by the user. For example. .. code-block:: c++. if (MyBoolean) {; MyObject MO;; ...; }. At the end of the scope the MyObject's destructor is called but it isn't written; explicitly. This information is useful to avoid to have counters on brackets when; making code coverage. C/C++ global variable information; ---------------------------------. Given an integer global variable declared as follows:. .. code-block:: c. _Alignas(8) int MyGlobal = 100;. a C/C++ front-end would generate the following descriptors:. .. code-block:: text. ;;; ;; Define the global itself.; ;;; @MyGlobal = global i32 100, align 8, !dbg !0. ;;; ;; List of debug info of globals; ;;; !llvm.dbg.cu = !{!1}. ;; Some unrelated metadata.; !llvm.module.flags = !{!6, !7}; !llvm.ident = !{!8}. ;; Define the global variable itself; !0 = distinct !DIGlobalVariable(name: ""MyGlobal"", scope: !1, file: !2, line: 1, type: !5, isLocal: false, isDefinition: true, align: 64). ;; Define the compile unit.; !1 = distinct !DICompileUnit(language: DW_LANG_C99, file: !2,; producer: ""clang version 4.0.0"",; isOptimized: false, runtimeVersion: 0, emissionKind: FullDebug,; enums: !3, globals: !4). ;;; ;; Define the file; ;;; !2 = !DIFile(filename: ""/dev/stdin"",; directory: ""/Users/dexonsmith/data/llvm/debug-info""). ;; An empty array.; !3 = !{}. ;;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:42529,variab,variable,42529,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['variab'],['variable']
Modifiability,"uires the language definition to guarantee that; optimizations based on the 'constantness' are valid for the translation; units that do not include the definition. As SSA values, global variables define pointer values that are in scope; (i.e. they dominate) all basic blocks in the program. Global variables; always define a pointer to their ""content"" type because they describe a; region of memory, and all memory objects in LLVM are accessed through; pointers. Global variables can be marked with ``unnamed_addr`` which indicates; that the address is not significant, only the content. Constants marked; like this can be merged with other constants if they have the same; initializer. Note that a constant with significant address *can* be; merged with a ``unnamed_addr`` constant, the result being a constant; whose address is significant. If the ``local_unnamed_addr`` attribute is given, the address is known to; not be significant within the module. A global variable may be declared to reside in a target-specific; numbered address space. For targets that support them, address spaces; may affect how optimizations are performed and/or what target; instructions are used to access the variable. The default address space; is zero. The address space qualifier must precede any other attributes. LLVM allows an explicit section to be specified for globals. If the; target supports it, it will emit globals to the section specified.; Additionally, the global can placed in a comdat if the target has the necessary; support. External declarations may have an explicit section specified. Section; information is retained in LLVM IR for targets that make use of this; information. Attaching section information to an external declaration is an; assertion that its definition is located in the specified section. If the; definition is located in a different section, the behavior is undefined. LLVM allows an explicit code model to be specified for globals. If the; target supports it, it will emit g",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:32593,variab,variable,32593,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variable']
Modifiability,"uish them from local variables.; This is consistent with [LLDB]_. The ``m_`` prefix is consistent with [WebKit]_. A variation is for member variables to be prefixed with ``m``; [IvanovicDistinguish]_ [BeylsDistinguish]_. This is consistent with [Mozilla]_. Another option is for member variables to be suffixed with ``_`` which is; consistent with [Google]_ and similar to [Python]_. Opposed by; [ParzyszekDistinguish]_. Reducing the number of acronyms; ===============================. While switching coding standard will make it easier to use non-acronym names for; new code, it doesn't improve the existing large body of code that uses acronyms; extensively to the detriment of its readability. Further, it is natural and; generally encouraged that new code be written in the style of the surrounding; code. Therefore it is likely that much newly written code will also use; acronyms despite what the coding standard says, much as it is today. As well as changing the case of variable names, they could also be expanded to; their non-acronym form e.g. ``Triple T`` → ``Triple triple``. There is support for expanding many acronyms [CarruthAcronym]_ [PicusAcronym]_; but there is a preference that expanding acronyms be deferred; [ParzyszekAcronym]_ [CarruthAcronym]_. The consensus within the community seems to be that at least some acronyms are; valuable [ParzyszekAcronym]_ [LattnerAcronym]_. The most commonly cited acronym; is ``TLI`` however that is used to refer to both ``TargetLowering`` and; ``TargetLibraryInfo`` [GreeneDistinguish]_. The following is a list of acronyms considered sufficiently useful that the; benefit of using them outweighs the cost of learning them. Acronyms that are; either not on the list or are used to refer to a different type should be; expanded. ============================ =============; Class name Variable name; ============================ =============; DeterministicFiniteAutomaton dfa; DominatorTree dt; LoopInfo li; MachineFunction mf; MachineInst",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst:5153,variab,variable,5153,interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst,1,['variab'],['variable']
Modifiability,"ul for algorithms that need very fast clear/find/insert/erase; and fast iteration over small sets. It is not intended for building composite; data structures. .. _dss_sparsemultiset:. llvm/ADT/SparseMultiSet.h; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. SparseMultiSet adds multiset behavior to SparseSet, while retaining SparseSet's; desirable attributes. Like SparseSet, it typically uses a lot of memory, but; provides operations that are almost as fast as a vector. Typical keys are; physical registers, virtual registers, or numbered basic blocks. SparseMultiSet is useful for algorithms that need very fast; clear/find/insert/erase of the entire collection, and iteration over sets of; elements sharing a key. It is often a more efficient choice than using composite; data structures (e.g. vector-of-vectors, map-of-vectors). It is not intended for; building composite data structures. .. _dss_FoldingSet:. llvm/ADT/FoldingSet.h; ^^^^^^^^^^^^^^^^^^^^^. FoldingSet is an aggregate class that is really good at uniquing; expensive-to-create or polymorphic objects. It is a combination of a chained; hash table with intrusive links (uniqued objects are required to inherit from; FoldingSetNode) that uses :ref:`SmallVector <dss_smallvector>` as part of its ID; process. Consider a case where you want to implement a ""getOrCreateFoo"" method for a; complex object (for example, a node in the code generator). The client has a; description of **what** it wants to generate (it knows the opcode and all the; operands), but we don't want to 'new' a node, then try inserting it into a set; only to find out it already exists, at which point we would have to delete it; and return the node that already exists. To support this style of client, FoldingSet perform a query with a; FoldingSetNodeID (which wraps SmallVector) that can be used to describe the; element that we want to query for. The query either returns the element; matching the ID or it returns an opaque ID that indicates where insertion should; take p",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:81827,polymorphi,polymorphic,81827,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['polymorphi'],['polymorphic']
Modifiability,"ular symbol. This type; of rule is typically used to implement an interactive renaming action that; allows users to specify which occurrences should be renamed during the; refactoring. Subclasses that choose to implement this rule have to implement; the ``findSymbolOccurrences`` member function. The following set of quick checks might help if you are unsure about the type; of rule you should use:. #. If you would like to transform the source in one translation unit and if; you don't need any cross-TU information, then the; ``SourceChangeRefactoringRule`` should work for you. #. If you would like to implement a rename-like operation with potential; interactive components, then ``FindSymbolOccurrencesRefactoringRule`` might; work for you. How to Create a Rule; ^^^^^^^^^^^^^^^^^^^^. Once you determine which type of rule is suitable for your needs you can; implement the refactoring by subclassing the rule and implementing its; interface. The subclass should have a constructor that takes the inputs that; are needed to perform the refactoring. For example, if you want to implement a; rule that simply deletes a selection, you should create a subclass of; ``SourceChangeRefactoringRule`` with a constructor that accepts the selection; range:. .. code-block:: c++. class DeleteSelectedRange final : public SourceChangeRefactoringRule {; public:; DeleteSelection(SourceRange Selection) : Selection(Selection) {}. Expected<AtomicChanges>; createSourceReplacements(RefactoringRuleContext &Context) override {; AtomicChange Replacement(Context.getSources(), Selection.getBegin());; Replacement.replace(Context.getSource,; CharSourceRange::getCharRange(Selection), """");; return { Replacement };; }; private:; SourceRange Selection;; };. The rule's subclass can then be added to the list of refactoring action's; rules for a particular action using the ``createRefactoringActionRule``; function. For example, the class that's shown above can be added to the; list of action rules using the followi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/RefactoringEngine.rst:5252,refactor,refactoring,5252,interpreter/llvm-project/clang/docs/RefactoringEngine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/RefactoringEngine.rst,1,['refactor'],['refactoring']
Modifiability,"ulating.; * embed; - This property tells the system if the rule should be written in the output; file is some objects of this class are serialized.; * include; - A list of header files that should be included in order to provide the; functionality used in the code snippet; the list is comma delimited.; * code; - An user specified code snippet. The user can assume that in the provided code snippet the following variables; will be defined:. The user provided code snippets have to consist of valid C++ code. The system can do; some preprocessing before wrapping the code into function calls and declare some variables to; facilitate the rule definitions. The user can expect the following variables being predeclared:. * newObj; - variable representing the target in-memory object, its type is that of the; target object; * oldObj; - in normal conversion rules, an object of TVirtualObject class representing the; input data, guaranteed to hold the data members declared in the source property; of the rule; * buffer; - in raw conversion rules, an object of TBuffer class holding the data member; declared in source property of the rule; * names of the data members of the target object declared in the target property of the; rule declared to be the appropriate type; * onfile.xxx; - in normal conversion rules, names of the variables of basic types declared; in the source property of the rule. #### The C++ API. The schema evolution C++ API consists of two classes: `ROOT::TSchemaRuleSet` and; `ROOT::TSchemaRule`. Objects of the TSchemaRule class represent the rules and their fields have exactly the same; meaning as the ones of rules specified in the dictionaries. `TSchemaRuleSet` objects; manage the sets of rules and ensure their consistency. There can be no conflicting; rules in the rule sets. The rule sets are owned by the `TClass` objects corresponding to the; target classes defined in the rules and can be accessed using `TClass::{Get|Adopt}SchemaRules`. ### Manual Schema Evolution",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:81669,variab,variable,81669,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,1,['variab'],['variable']
Modifiability,"uld set ``LEVEL`` to ``""../..""``. Variables for Building Subdirectories; -------------------------------------. ``DIRS``. This is a space separated list of subdirectories that should be built. They; will be built, one at a time, in the order specified. ``PARALLEL_DIRS``. This is a list of directories that can be built in parallel. These will be; built after the directories in DIRS have been built. ``OPTIONAL_DIRS``. This is a list of directories that can be built if they exist, but will not; cause an error if they do not exist. They are built serially in the order; in which they are listed. Variables for Building Libraries; --------------------------------. ``LIBRARYNAME``. This variable contains the base name of the library that will be built. For; example, to build a library named ``libsample.a``, ``LIBRARYNAME`` should; be set to ``sample``. ``BUILD_ARCHIVE``. By default, a library is a ``.o`` file that is linked directly into a; program. To build an archive (also known as a static library), set the; ``BUILD_ARCHIVE`` variable. ``SHARED_LIBRARY``. If ``SHARED_LIBRARY`` is defined in your Makefile, a shared (or dynamic); library will be built. Variables for Building Programs; -------------------------------. ``TOOLNAME``. This variable contains the name of the program that will be built. For; example, to build an executable named ``sample``, ``TOOLNAME`` should be set; to ``sample``. ``USEDLIBS``. This variable holds a space separated list of libraries that should be; linked into the program. These libraries must be libraries that come from; your **lib** directory. The libraries must be specified without their; ``lib`` prefix. For example, to link ``libsample.a``, you would set; ``USEDLIBS`` to ``sample.a``. Note that this works only for statically linked libraries. ``LLVMLIBS``. This variable holds a space separated list of libraries that should be; linked into the program. These libraries must be LLVM libraries. The; libraries must be specified without their ``li",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Projects.rst:5685,variab,variable,5685,interpreter/llvm-project/llvm/docs/Projects.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Projects.rst,1,['variab'],['variable']
Modifiability,"ule will not be compiled until they are first; called. LLLazyJIT aims to provide a replacement of LLVM's original (pre-MCJIT); JIT API. LLJIT and LLLazyJIT instances can be created using their respective builder; classes: LLJITBuilder and LLazyJITBuilder. For example, assuming you have a; module ``M`` loaded on a ThreadSafeContext ``Ctx``:. .. code-block:: c++. // Try to detect the host arch and construct an LLJIT instance.; auto JIT = LLJITBuilder().create();. // If we could not construct an instance, return an error.; if (!JIT); return JIT.takeError();. // Add the module.; if (auto Err = JIT->addIRModule(TheadSafeModule(std::move(M), Ctx))); return Err;. // Look up the JIT'd code entry point.; auto EntrySym = JIT->lookup(""entry"");; if (!EntrySym); return EntrySym.takeError();. // Cast the entry point address to a function pointer.; auto *Entry = EntrySym.getAddress().toPtr<void(*)()>();. // Call into JIT'd code.; Entry();. The builder classes provide a number of configuration options that can be; specified before the JIT instance is constructed. For example:. .. code-block:: c++. // Build an LLLazyJIT instance that uses four worker threads for compilation,; // and jumps to a specific error handler (rather than null) on lazy compile; // failures. void handleLazyCompileFailure() {; // JIT'd code will jump here if lazy compilation fails, giving us an; // opportunity to exit or throw an exception into JIT'd code.; throw JITFailed();; }. auto JIT = LLLazyJITBuilder(); .setNumCompileThreads(4); .setLazyCompileFailureAddr(; ExecutorAddr::fromPtr(&handleLazyCompileFailure)); .create();. // ... For users wanting to get started with LLJIT a minimal example program can be; found at ``llvm/examples/HowToUseLLJIT``. Design Overview; ===============. ORC's JIT program model aims to emulate the linking and symbol resolution; rules used by the static and dynamic linkers. This allows ORC to JIT; arbitrary LLVM IR, including IR produced by an ordinary static compiler (e.g.; clang) t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst:5393,config,configuration,5393,interpreter/llvm-project/llvm/docs/ORCv2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst,1,['config'],['configuration']
Modifiability,"ule.h <https://github.com/llvm/llvm-project/blob/main/clang/include/clang/Tooling/Transformer/RewriteRule.h>`_. Using a RewriteRule as a clang-tidy check; -----------------------------------------. Transformer supports executing a rewrite rule as a; `clang-tidy <https://clang.llvm.org/extra/clang-tidy/>`_ check, with the class; ``clang::tidy::utils::TransformerClangTidyCheck``. It is designed to require; minimal code in the definition. For example, given a rule; ``MyCheckAsRewriteRule``, one can define a tidy check as follows:. .. code-block:: c++. class MyCheck : public TransformerClangTidyCheck {; public:; MyCheck(StringRef Name, ClangTidyContext *Context); 	 : TransformerClangTidyCheck(MyCheckAsRewriteRule, Name, Context) {}; };. ``TransformerClangTidyCheck`` implements the virtual ``registerMatchers`` and; ``check`` methods based on your rule specification, so you don't need to implement; them yourself. If the rule needs to be configured based on the language options; and/or the clang-tidy configuration, it can be expressed as a function taking; these as parameters and (optionally) returning a ``RewriteRule``. This would be; useful, for example, for our method-renaming rule, which is parameterized by the; original name and the target. For details, see; `clang-tools-extra/clang-tidy/utils/TransformerClangTidyCheck.h <https://github.com/llvm/llvm-project/blob/main/clang-tools-extra/clang-tidy/utils/TransformerClangTidyCheck.h>`_. Related Reading; ---------------. A good place to start understanding the clang AST and its matchers is with the; introductions on clang's site:. * :doc:`Introduction to the Clang AST <IntroductionToTheClangAST>`; * :doc:`Matching the Clang AST <LibASTMatchers>`; * `AST Matcher Reference <https://clang.llvm.org/docs/LibASTMatchersReference.html>`_. .. rubric:: Footnotes. .. [#f1] Technically, it binds it to the string ""str"", to which our; variable ``s`` is bound. But, the choice of that id string is; irrelevant, so elide the difference.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangTransformerTutorial.rst:17132,config,configured,17132,interpreter/llvm-project/clang/docs/ClangTransformerTutorial.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangTransformerTutorial.rst,4,"['config', 'parameteriz', 'variab']","['configuration', 'configured', 'parameterized', 'variable']"
Modifiability,ull pointer constant?; Yes. 457; CD1; Wording nit on use of const variables in constant expressions; Yes. 458; C++11; Hiding of member template parameters by other members; Clang 11. 459; NAD; Hiding of template parameters by base class members; Unknown. 460; CD1; Can a using-declaration name a namespace?; Yes. 461; NAD; Make asm conditionally-supported; N/A. 462; CD3; Lifetime of temporaries bound to comma expressions; Unknown. 463; CD1; reinterpret_cast<T*>(0); N/A. 464; CD1; Wording nit on lifetime of temporaries to which references are bound; N/A. 465; NAD; May constructors of global objects call exit()?; N/A. 466; CD1; cv-qualifiers on pseudo-destructor type; No. 467; NAD; Jump past initialization of local static variable; Yes. 468; CD1; Allow ::template outside of templates; Yes (C++11 onwards). 469; NAD; Const template specializations and reference arguments; No. 470; CD1; Instantiation of members of an explicitly-instantiated class template; Yes. 471; NAD; Conflicting inherited access specifications; Clang 2.8. 472; drafting; Casting across protected inheritance; Not resolved. 473; NAD; Block-scope declarations of allocator functions; Unknown. 474; CD1; Block-scope extern declarations in namespace members; Clang 3.4. 475; C++11; When is std::uncaught_exception() true? (take 2); Unknown. 476; CD5; Determining the buffer size for placement new; Unknown. 477; CD1; Can virtual appear in a friend declaration?; Clang 3.5. 478; NAD; May a function parameter be an array of an abstract class type?; Yes. 479; CD1; Copy elision in exception handling; Clang 2.8. 480; CD1; Is a base of a virtual base also virtual?; Yes. 481; CD2; Scope of template parameters; Clang 2.8. 482; CD3; Qualified declarators in redeclarations; Clang 3.5. 483; CD3; Normative requirements on integral ranges; Yes. 484; CD1; Can a base-specifier name a cv-qualified class type?; Yes. 485; CD1; What is a “name”?; Yes. 486; CD1; Invalid return types and template argument deduction; Yes. 487; NAD; Oper,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html:32202,inherit,inherited,32202,interpreter/llvm-project/clang/www/cxx_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html,1,['inherit'],['inherited']
Modifiability,"ult constructor doesn't touch global state; but only initializes the object to various default values.; But if, say, we're making an array of strings,; depending on the implementation you might have to allocate a new buffer; for each string, and in this case default-binding won't cut it.; We might want to come up with an auxiliary analysis in order to perform; widening of these simple loops more precisely.; . Handle constructors that can be elided due to Named Return Value Optimization (NRVO); Local variables which are returned by values on all return statements; may be stored directly at the address for the return value,; eliding the copy or move constructor call.; Such variables can be identified using the AST call VarDecl::isNRVOVariable.; . Handle constructors of lambda captures; Variables which are captured by value into a lambda require a call to; a copy constructor.; This call is not currently modeled.; . Handle constructors for default arguments; Default arguments in C++ are recomputed at every call,; and are therefore local, and not static, variables.; See tests cases in handle_constructors_for_default_arguments.cpp.; . Default arguments are annoying because the initializer expression is; evaluated at the call site but doesn't syntactically belong to the; caller's AST; instead it belongs to the ParmVarDecl for the default; parameter. This can lead to situations when the same expression has to; carry different values simultaneously -; when multiple instances of the same function are evaluated as part of the; same full-expression without specifying the default arguments.; Even simply calling the function twice (not necessarily within the; same full-expression) may lead to program points agglutinating because; it's the same expression. There are some nasty test cases already; in temporaries.cpp (struct DefaultParam and so on). I recommend adding a; new LocationContext kind specifically to deal with this problem. It'll; also help you figure out the construction ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/open_projects.html:4563,variab,variables,4563,interpreter/llvm-project/clang/www/analyzer/open_projects.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/open_projects.html,1,['variab'],['variables']
Modifiability,"ult in ``*23``; mode, and as an extension in ``*17`` and earlier modes.; - ``[[]]`` attributes are supported by default in ``*23`` mode, and as an; extension in ``*17`` and earlier modes. GCC extensions not implemented yet; ----------------------------------. clang tries to be compatible with gcc as much as possible, but some gcc; extensions are not implemented yet:. - clang does not support decimal floating point types (``_Decimal32`` and; friends) yet.; - clang does not support nested functions; this is a complex feature; which is infrequently used, so it is unlikely to be implemented; anytime soon. In C++11 it can be emulated by assigning lambda; functions to local variables, e.g:. .. code-block:: cpp. auto const local_function = [&](int parameter) {; // Do something; };; ...; local_function(1);. - clang only supports global register variables when the register specified; is non-allocatable (e.g. the stack pointer). Support for general global; register variables is unlikely to be implemented soon because it requires; additional LLVM backend support.; - clang does not support static initialization of flexible array; members. This appears to be a rarely used extension, but could be; implemented pending user demand.; - clang does not support; ``__builtin_va_arg_pack``/``__builtin_va_arg_pack_len``. This is; used rarely, but in some potentially interesting places, like the; glibc headers, so it may be implemented pending user demand. Note; that because clang pretends to be like GCC 4.2, and this extension; was introduced in 4.3, the glibc headers will not try to use this; extension with clang at the moment.; - clang does not support the gcc extension for forward-declaring; function parameters; this has not shown up in any real-world code; yet, though, so it might never be implemented. This is not a complete list; if you find an unsupported extension; missing from this list, please send an e-mail to cfe-dev. This list; currently excludes C++; see :ref:`C++ Language Fe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:134039,variab,variables,134039,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['variab'],['variables']
Modifiability,"ult initializers in aggregate members is enabled. C++14 digit separators; ^^^^^^^^^^^^^^^^^^^^^^. Use ``__cpp_digit_separators`` to determine if support for digit separators; using single quotes (for instance, ``10'000``) is enabled. At this time, there; is no corresponding ``__has_feature`` name. C++14 generalized lambda capture; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Use ``__has_feature(cxx_init_captures)`` or; ``__has_extension(cxx_init_captures)`` to determine if support for; lambda captures with explicit initializers is enabled; (for instance, ``[n(0)] { return ++n; }``). C++14 generic lambdas; ^^^^^^^^^^^^^^^^^^^^^. Use ``__has_feature(cxx_generic_lambdas)`` or; ``__has_extension(cxx_generic_lambdas)`` to determine if support for generic; (polymorphic) lambdas is enabled; (for instance, ``[] (auto x) { return x + 1; }``). C++14 relaxed constexpr; ^^^^^^^^^^^^^^^^^^^^^^^. Use ``__has_feature(cxx_relaxed_constexpr)`` or; ``__has_extension(cxx_relaxed_constexpr)`` to determine if variable; declarations, local variable modification, and control flow constructs; are permitted in ``constexpr`` functions. C++14 return type deduction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Use ``__has_feature(cxx_return_type_deduction)`` or; ``__has_extension(cxx_return_type_deduction)`` to determine if support; for return type deduction for functions (using ``auto`` as a return type); is enabled. C++14 runtime-sized arrays; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Use ``__has_feature(cxx_runtime_array)`` or; ``__has_extension(cxx_runtime_array)`` to determine if support; for arrays of runtime bound (a restricted form of variable-length arrays); is enabled.; Clang's implementation of this feature is incomplete. C++14 variable templates; ^^^^^^^^^^^^^^^^^^^^^^^^. Use ``__has_feature(cxx_variable_templates)`` or; ``__has_extension(cxx_variable_templates)`` to determine if support for; templated variable declarations is enabled. C11; ---. The features listed below are part of the C11 standard. As a result, all thes",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:50363,variab,variable,50363,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,2,['variab'],['variable']
Modifiability,"ult type also according to the; declaration. Given:. .. code-block:: c. int (^x)(char);; void (^z)(void);; int (^(*y))(char) = &x;. the following are all legal Block invocations:. .. code-block:: c. x('a');; (*y)('a');; (true ? x : *y)('a'). The Copy and Release Operations; ===============================. The compiler and runtime provide :block-term:`copy` and; :block-term:`release` operations for Block references that create and,; in matched use, release allocated storage for referenced Blocks. The copy operation ``Block_copy()`` is styled as a function that takes; an arbitrary Block reference and returns a Block reference of the same; type. The release operation, ``Block_release()``, is styled as a; function that takes an arbitrary Block reference and, if dynamically; matched to a Block copy operation, allows recovery of the referenced; allocated memory. The ``__block`` Storage Qualifier; =================================. In addition to the new Block type we also introduce a new storage; qualifier, :block-term:`__block`, for local variables. [testme: a; __block declaration within a block literal] The ``__block`` storage; qualifier is mutually exclusive to the existing local storage; qualifiers auto, register, and static. [testme] Variables qualified by; ``__block`` act as if they were in allocated storage and this storage; is automatically recovered after last use of said variable. An; implementation may choose an optimization where the storage is; initially automatic and only ""moved"" to allocated (heap) storage upon; a Block_copy of a referencing Block. Such variables may be mutated as; normal variables are. In the case where a ``__block`` variable is a Block one must assume; that the ``__block`` variable resides in allocated storage and as such; is assumed to reference a Block that is also in allocated storage; (that it is the result of a ``Block_copy`` operation). Despite this; there is no provision to do a ``Block_copy`` or a ``Block_release`` if; an impleme",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst:7033,variab,variables,7033,interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,1,['variab'],['variables']
Modifiability,"umPdf changed from sum of coefficients to sum of coefficients*integrals of input functions.; New PDF RooNonCentralChiSquare which is useful for asymptotic analysis of likelihood ratio tests -- like expected significance and error bands.; Ability to ""seal"" data in RooNLLVar, so that an experiment can publish likleihood functions without exposing the data necessary to evaluate the likelihood function. HistFactory. The ROOT release ships with a script prepareHistFactory and a binary hist2workspace in the $ROOTSYS/bin directories.; prepareHistFactory prepares a working area. It creates a results/, data/, and config/ directory. It also copies the HistFactorySchema.dtd and example XML files into the config/ directory. Additionally, it copies a root file into the data/ directory for use with the examples. Usage: hist2workspace input.xml; HistFactorySchema.dtd: This file is located in $ROOTSYS/etc/ specifies the XML schema. It is typically placed in the config/ direc-tory of a working area together with the top-level XML file and the individual channel XML files. The user should not modify this file. The HistFactorySchema.dtd is commented to specify exactly the meaning of the various options. Top-Level XML File. see for example $ROOTSYS/tutorials/histfactory/example.xml; This file is edited by the user. It specifies; ; A top level 'Combination' that is composed of:; 	; several 'Channels', which are described in separate XML files.; 	 several 'Measurements' (corresponding to a full fit of the model) each of which specifies; 	 ; a name for this measurement to be used in tables and files; what is the luminosity associated to the measurement in picobarns; which bins of the histogram should be used; what is the relative uncertainty on the luminosity; what is (are) the parameter(s) of interest that will be measured; which parameters should be fixed/floating (eg. nuisance parameters); which type of constraints are desired; 		; Gaussian by default ; 		 Gamma, LogNormal, and Uniform",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:1094,config,config,1094,roofit/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html,1,['config'],['config']
Modifiability,"ument explains features or design decisions that are; specific to the code generator for a particular target. .. _tail call section:. Tail call optimization; ----------------------. Tail call optimization, callee reusing the stack of the caller, is currently; supported on x86/x86-64, PowerPC, AArch64, and WebAssembly. It is performed on; x86/x86-64, PowerPC, and AArch64 if:. * Caller and callee have the calling convention ``fastcc``, ``cc 10`` (GHC; calling convention), ``cc 11`` (HiPE calling convention), ``tailcc``, or; ``swifttailcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Option ``-tailcallopt`` is enabled or the calling convention is ``tailcc``. * Platform-specific constraints are met. x86/x86-64 constraints:. * No variable argument lists are used. * On x86-64 when generating GOT/PIC code only module-local calls (visibility =; hidden or protected) are supported. PowerPC constraints:. * No variable argument lists are used. * No byval parameters are used. * On ppc32/64 GOT/PIC only module-local calls (visibility = hidden or protected); are supported. WebAssembly constraints:. * No variable argument lists are used. * The 'tail-call' target attribute is enabled. * The caller and callee's return types must match. The caller cannot; be void unless the callee is, too. AArch64 constraints:. * No variable argument lists are used. Example:. Call as ``llc -tailcallopt test.ll``. .. code-block:: llvm. declare fastcc i32 @tailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4). define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {; %l1 = add i32 %in1, %in2; %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1); ret i32 %tmp; }. Implications of ``-tailcallopt``:. To support tail call optimization in situations where the callee has more; arguments than the caller a 'callee pops arguments' convention is used. This; currently causes each ``fastcc`` call that is n",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:87046,variab,variable,87046,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['variab'],['variable']
Modifiability,"uments on the top of the stack (their normal place for; non-tail call optimized calls) that source from the callers arguments; or that source from a virtual register (also possibly sourcing from; callers arguments).; This is done to prevent overwriting of parameters (see example; below) that might be used later. example: . int callee(int32, int64); ; int caller(int32 arg1, int32 arg2) { ; int64 local = arg2 * 2; ; return callee(arg2, (int64)local); ; }. [arg1] [!arg2 no longer valid since we moved local onto it]; [arg2] -> [(int64); [RETADDR] local ]. Moving arg1 onto the stack slot of callee function would overwrite; arg2 of the caller. Possible optimizations:. - Analyse the actual parameters of the callee to see which would; overwrite a caller parameter which is used by the callee and only; push them onto the top of the stack. int callee (int32 arg1, int32 arg2);; int caller (int32 arg1, int32 arg2) {; return callee(arg1,arg2);; }. Here we don't need to write any variables to the top of the stack; since they don't overwrite each other. int callee (int32 arg1, int32 arg2);; int caller (int32 arg1, int32 arg2) {; return callee(arg2,arg1);; }. Here we need to push the arguments because they overwrite each; other. //===---------------------------------------------------------------------===//. main (); {; int i = 0;; unsigned long int z = 0;. do {; z -= 0x00004000;; i++;; if (i > 0x00040000); abort ();; } while (z > 0);; exit (0);; }. gcc compiles this to:. _main:; 	subl	$28, %esp; 	xorl	%eax, %eax; 	jmp	L2; L3:; 	cmpl	$262144, %eax; 	je	L10; L2:; 	addl	$1, %eax; 	cmpl	$262145, %eax; 	jne	L3; 	call	L_abort$stub; L10:; 	movl	$0, (%esp); 	call	L_exit$stub. llvm:. _main:; 	subl	$12, %esp; 	movl	$1, %eax; 	movl	$16384, %ecx; LBB1_1:	# bb; 	cmpl	$262145, %eax; 	jge	LBB1_4	# cond_true; LBB1_2:	# cond_next; 	incl	%eax; 	addl	$4294950912, %ecx; 	cmpl	$16384, %ecx; 	jne	LBB1_1	# bb; LBB1_3:	# bb11; 	xorl	%eax, %eax; 	addl	$12, %esp; 	ret; LBB1_4:	# cond_true; 	call	L_abort$stu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:19053,variab,variables,19053,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,1,['variab'],['variables']
Modifiability,"uments.; * If the kernarg pointer in; the dispatch packet is; not NULL and this value; is 0 then the kernarg; memory size is; unspecified.; * If the kernarg pointer in; the dispatch packet is; not NULL and this value; is not 0 then the value; specifies the kernarg; memory size in bytes. It; is recommended to provide; a value as it may be used; by CP to optimize making; the kernarg memory; visible to the kernel; code. 127:96 4 bytes Reserved, must be 0.; 191:128 8 bytes KERNEL_CODE_ENTRY_BYTE_OFFSET Byte offset (possibly; negative) from base; address of kernel; descriptor to kernel's; entry point instruction; which must be 256 byte; aligned.; 351:272 20 Reserved, must be 0.; bytes; 383:352 4 bytes COMPUTE_PGM_RSRC3 GFX6-GFX9; Reserved, must be 0.; GFX90A, GFX940; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx90a-table`.; GFX10-GFX11; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx10-gfx11-table`.; GFX12; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table`.; 415:384 4 bytes COMPUTE_PGM_RSRC1 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC1``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`.; 447:416 4 bytes COMPUTE_PGM_RSRC2 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC2``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc2-gfx6-gfx12-table`.; 458:448 7 bits *See separate bits below.* Enable the setup of the; SGPR user data registers; (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). The total number of SGPR; user data registers; requested must not exceed; 16 and match value in; ``compute_pgm_rsrc2.user_sgpr.user_sgp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:160514,config,configuration,160514,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['config'],['configuration']
Modifiability,"umes; exist are `source files <LangRef.html#difile>`_, and `program objects; <LangRef.html#diglobalvariable>`_. These abstract objects are used by a; debugger to form stack traces, show information about local variables, etc. This section of the documentation first describes the representation aspects; common to any source-language. :ref:`ccxx_frontend` describes the data layout; conventions used by the C and C++ front-ends. Debug information descriptors are `specialized metadata nodes; <LangRef.html#specialized-metadata>`_, first-class subclasses of ``Metadata``. .. _format_common_intrinsics:. Debugger intrinsic functions; ----------------------------. LLVM uses several intrinsic functions (name prefixed with ""``llvm.dbg``"") to; track source local variables through optimization and code generation. ``llvm.dbg.declare``; ^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.dbg.declare(metadata, metadata, metadata). This intrinsic provides information about a local element (e.g., variable).; The first argument is metadata holding the address of variable, typically a; static alloca in the function entry block. The second argument is a; `local variable <LangRef.html#dilocalvariable>`_ containing a description of; the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.declare` intrinsic describes the; *address* of a source variable. .. code-block:: text. %i.addr = alloca i32, align 4; call void @llvm.dbg.declare(metadata i32* %i.addr, metadata !1,; metadata !DIExpression()), !dbg !2; !1 = !DILocalVariable(name: ""i"", ...) ; int i; !2 = !DILocation(...); ...; %buffer = alloca [256 x i8], align 8; ; The address of i is buffer+64.; call void @llvm.dbg.declare(metadata [256 x i8]* %buffer, metadata !3,; metadata !DIExpression(DW_OP_plus, 64)), !dbg !4; !3 = !DILocalVariable(name: ""i"", ...) ; int i; !4 = !DILocation(...). A frontend should generate exactly one call to ``llvm.dbg.declare`` at the point; of declaration of a sour",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:8579,variab,variable,8579,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['variab'],['variable']
Modifiability,"uncname, Int_t ndiv=510,; Option_t* chopt, Double_t gridlength=0); ```. In such a way, it is possible to obtain exponential evolution of the; tick marks position, or even decreasing. In fact, anything you like. ### Orientation of Tick Marks on Axis. Tick marks are normally drawn on the positive side of the axis, however,; if `xmin = xmax`, then negative. - `chopt = '+': ` tick marks are drawn on Positive side. (Default). - `chopt = '-': ` tick marks are drawn on the negative side. - `chopt = '+-':` tick marks are drawn on both sides of the axis. - `chopt = ‘U': ` unlabeled axis, default is labeled. ### Labels. #### Position. Labels are normally drawn on side opposite to tick marks. However,; `chopt = '='`: on Equal side. The function `TAxis::CenterLabels()` sets; the bit `kCenterLabels` and it is visible from **`TAxis`** context menu.; It centers the bin labels and it makes sense only when the number of; bins is equal to the number of tick marks. The class responsible for; drawing the axis **`TGaxis`** inherits this property. #### Orientation. Labels are normally drawn parallel to the axis. However, if; `xmin = xmax`, then they are drawn orthogonal, and if `ymin=ymax` they; are drawn parallel. #### Labels for Exponents. By default, an exponent of the form 10\^N is used when the label values; are either all very small or very large. One can disable the exponent by; calling:. ``` {.cpp}; TAxis::SetNoExponent(kTRUE); ```. Note that this option is implicitly selected if the number of digits to; draw a label is less than the `fgMaxDigits` global member. If the; property `SetNoExponent` was set in **`TAxis`** (via; `TAxis::SetNoExponent)`, the **`TGaxis`** will inherit this property.; **`TGaxis`** is the class responsible for drawing the axis. The method; `SetNoExponent` is also available from the axis context menu. ![Y-axis with and without exponent labels](pictures/030000C7.png). #### Number of Digits in Labels. `TGaxis::fgMaxDigits` is the maximum number of digits permi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:55391,inherit,inherits,55391,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['inherit'],['inherits']
Modifiability,"unction generates code to; compute the Negative Log likelihood (NLL). We can see that the intermediate; result variable `resName` is added to the context so that it can be accessed; and used in the generated code. This variable is made available globally; (using `addToGlobalScope()`). If a weight sum is needed, then it creates a loop, and `weightSumName` is; accumulated with the weight variable. Otherwise, if there are multiple; simultaneous PDFs, then it adds a term to the result that scales with the; logarithm of the count of simultaneous PDFs. The rest of the function body; (including the loop scope with NLL computation) has omitted from this example; to keep it brief. Helper functions:. - `makeValidVarName()` helps get a valid name from the name of the respective; RooFit class. It then helps save it to the variable that represents the result; of this class (the squashed code/ C++ function that will be created). - `addToGlobalScope()` helps declare and initialize the results variable, so; that it can be available globally (throughout the function body). For local; variables, the `addToCodeBody()` function can be used to keep the variables in; the respective scope (for example, within a loop). - `beginLoop()` helps build the start and the end of a For loop for your; class. Simply place this function in the scope and place the contents of the; `For` loop below this statement. The code squashing task will automatically; build a loop around the statements that follow it. There's no need to worry; about the index of these loops, because they get propagated. For example, if; you want to iterate over a vector of RooFit objects using a loop, you don't; have to think about indexing them properly because the `beginLoop()` function; takes care of that. Simply call this function, place your function call in a; scope and after the scope ends, the loop will also end. - `addToCodeBody()` helps add things to the body of the C++ function that; you're creating. It takes whatever s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md:17424,variab,variable,17424,roofit/doc/developers/roofit_ad.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md,1,['variab'],['variable']
Modifiability,"unction value, the; expected distance to the minimum and the number of function calls. ### operator$<<$(std::ostream&, const MnUserParameters&) ###. Prints out the MnUserParameters. ### operator$<<$(std::ostream&, const MnUserCovariance&) ###. Prints out the MnUserCovariance. ### operator$<<$(std::ostream&, const MnGlobalCorrelationCoeff&) ###. Prints out the MnGlobalCorrelationCoeff. ### operator$<<$(std::ostream&, const MnUserParameterState&) ###. Prints out the whole MnUserParameterState: MnUserParameters,; MnUserCovariance and MnGlobalCorrelationCoeff. ### operator$<<$(std::ostream&, const MinosError&) ###. Prints out the MinosError of a given parameter. ### operator$<<$(std::ostream&, const ContoursErros&) ###. Prints out the MinosError of the two parameters and plots a line printer; graphic of the contours on the output terminal. # How to get the right answer from M #. The goal of M — to be able to minimize and analyze parameter errors for; all possible user functions with any number of variable parameters — is; of course impossible to realise, even in principle, in a finite amount; of time. In practice, some assumptions must be made about the behaviour; of the function in order to avoid evaluating it at all possible points.; In this chapter we give some hints on how the user can help M to make; the right assumptions. ## Which minimizer to use ##. One of the historically interesting advantages of M is that it was; probably the first minimization program to offer the user a choice of; several minimization algorithms. This could be taken as a reflection of; the fact that none of the algorithms known at that time were good enough; to be universal, so users were encouraged to find the one that worked; best for them. Since then, algorithms have improved considerably, but M; still offers several, mostly so that old users will not feel cheated,; but also to help the occasional user who does manage to defeat the best; algorithms. M currently offers four applications wh",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md:59715,variab,variable,59715,documentation/minuit2/Minuit2.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/minuit2/Minuit2.md,1,['variab'],['variable']
Modifiability,"unction. For implementations that support in-memory; processing, these should register an iterator function to provide access to the; data via the ``__xray_log_set_buffer_iterator(...)`` which allows code calling; the ``__xray_log_process_buffers(...)`` function to deal with the data in; memory. All of this is better explained in the ``xray/xray_log_interface.h`` header. Basic Mode; ----------. XRay supports a basic logging mode which will trace the application's; execution, and periodically append to a single log. This mode can be; installed/enabled by setting ``xray_mode=xray-basic`` in the ``XRAY_OPTIONS``; environment variable. Combined with ``patch_premain=true`` this can allow for; tracing applications from start to end. Like all the other modes installed through ``__xray_log_select_mode(...)``, the; implementation can be configured through the ``__xray_log_init_mode(...)``; function, providing the mode string and the flag options. Basic-mode specific; defaults can be provided in the ``XRAY_BASIC_OPTIONS`` environment variable. Flight Data Recorder Mode; -------------------------. XRay supports a logging mode which allows the application to only capture a; fixed amount of memory's worth of events. Flight Data Recorder (FDR) mode works; very much like a plane's ""black box"" which keeps recording data to memory in a; fixed-size circular queue of buffers, and have the data available; programmatically until the buffers are finalized and flushed. To use FDR mode; on your application, you may set the ``xray_mode`` variable to ``xray-fdr`` in; the ``XRAY_OPTIONS`` environment variable. Additional options to the FDR mode; implementation can be provided in the ``XRAY_FDR_OPTIONS`` environment; variable. Programmatic configuration can be done by calling; ``__xray_log_init_mode(""xray-fdr"", <configuration string>)`` once it has been; selected/installed. When the buffers are flushed to disk, the result is a binary trace format; described by `XRay FDR format <XRayFDRFormat.h",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:8749,variab,variable,8749,interpreter/llvm-project/llvm/docs/XRay.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst,1,['variab'],['variable']
Modifiability,"und parameters and bound parameters. It could also affected Fumili2. Furthermore, a wrong sign for the correlation matrix could also have been obtained in some cases with bound parameters.; ; Use a tolerance of 0.01 instead of 0.05 in MnContours. The value of 0.01 is the same used in Minos. This is sufficient to get good quality contours.; Improve also the debug in MnContour. Add printing of points as info messages; Remove some un-necessary assert() when defining the minimization parameters.; Fix a bug in MnHesse to return the information if the matrix was made pos def. In addition change in MinimumError the condition that when the matrix was made pos def the status of the error is still considered valid and not invalid as before. This makes also the function minimum valid when a matrix was decleared pos def.; Improvements in the Minuit2Minimizer class:; . implement the new methods defined in the base class: Hess() using MnHess and CovMatrixStatus();; ; improve the switch-off of the info message according to the print level;; ; define the variables passed with zero step-size as constant (as is done in F77 Minuit); . Fix a problem in building the parallel version of Minuit2. The parallel version is built if the environment variables USE_PARALLEL_MINUIT2 and USE_OPENMP are set before compiling Minuit2 on a compiler which supports openMP (for example gcc version >= 4.2); ; Add, thanks to Alfio Lazzaro, support for running Minuit2 using multi-process by using MPI. A new class MPIProcess deals with starting and terminating the MPI process. Each process calculates independently the derivatives for a given set of parameters.; A Minuit2 library with MPI support can be built by defining before compilation the environment variables USE_PARALLEL_MINUIT2 and USE_MPI. Unuran; Add constructor of Tunuran distributions using function objects defined using the mathcore interfaces:. TUnuranContDist (const ROOT::Math::IGenFunction & pdf, const ROOT::Math::IGenFunction * dpdf, bool isLo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v524/index.html:7130,variab,variables,7130,math/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v524/index.html,1,['variab'],['variables']
Modifiability,"uned by; `root-config --libs`. These commands are commonly used in `Makefiles`.; Using `root-config` instead of enumerating the libraries by hand; allows you to link them in a platform independent way. Also, if ROOT; library names change you will not need to change your Makefile. A batch program that does not have a graphic display, which creates,; fills, and saves histograms and trees, only needs to link the core; libraries (`libCore`, `libRIO`), `libHist` and `libTree`.; If ROOT needs access to other libraries, it loads them dynamically.; For example, if the **`TreeViewer`** is used, `libTreePlayer` and all; libraries `libTreePlayer` depends on are loaded also. The dependent; libraries are shown in the ROOT reference guide's library dependency; graph. The difference between reference guide `libHist` and; `libHistPainter` is that the former needs to be explicitly linked and; the latter will be loaded automatically at runtime when ROOT needs it,; by means of the Plugin Manager. plugin manager. In the Figure 1-2, the libraries represented by green boxes outside of; the core are loaded via the plugin manager plugin manager or; equivalent techniques, while the white ones are not. Of course, if one; wants to access a plugin library directly, it has to be explicitly; linked. An example of a plugin library is `libMinuit`. To create and; fill histograms you need to link `libHist.so`. If the code has a call; to fit the histogram, the ""fitter"" will dynamically load libMinuit if; it is not yet loaded. #### Plugins: Runtime Library Dependencies for Linking. plugin manager The Plugin Manager **`TPluginManager`** allows; postponing library dependencies to runtime: a plugin library will only; be loaded when it is needed. Non-plugins will need to be linked, and; are thus loaded at start-up. Plugins are defined by a base class (e.g.; **`TFile`**) that will be implemented in a plugin, a tag used to; identify the plugin (e.g. `^rfio:` as part of the protocol string),; the plugin clas",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:18394,plugin,plugin,18394,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,1,['plugin'],['plugin']
Modifiability,"unix-StdCLibraryFunctions`. The ``ModelPOSIX`` option of that; checker affects the set of checked functions. **Parameters**. The ``AllowErrnoReadOutsideConditionExpressions`` option allows read of the; errno value if the value is not used in a condition (in ``if`` statements,; loops, conditional expressions, ``switch`` statements). For example ``errno``; can be stored into a variable without getting a warning by the checker. .. code-block:: c. int unsafe_errno_read(int sock, void *data, int data_size) {; if (send(sock, data, data_size, 0) != data_size) {; int err = errno;; // warning if 'AllowErrnoReadOutsideConditionExpressions' is false; // no warning if 'AllowErrnoReadOutsideConditionExpressions' is true; }; return 1;; }. Default value of this option is ``true``. This allows save of the errno value; for possible later error handling. **Limitations**. - Only the very first usage of ``errno`` is checked after an affected function; call. Value of ``errno`` is not followed when it is stored into a variable; or returned from a function.; - Documentation of function ``lseek`` is not clear about what happens if the; function returns different value than the expected file position but not -1.; To avoid possible false-positives ``errno`` is allowed to be used in this; case. .. _unix-Malloc:. unix.Malloc (C); """"""""""""""""""""""""""""""; Check for memory leaks, double free, and use-after-free problems. Traces memory managed by malloc()/free(). .. literalinclude:: checkers/unix_malloc_example.c; :language: c. .. _unix-MallocSizeof:. unix.MallocSizeof (C); """"""""""""""""""""""""""""""""""""""""""; Check for dubious ``malloc`` arguments involving ``sizeof``. .. code-block:: c. void test() {; long *p = malloc(sizeof(short));; // warn: result is converted to 'long *', which is; // incompatible with operand type 'short'; free(p);; }. .. _unix-MismatchedDeallocator:. unix.MismatchedDeallocator (C, C++); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for mismatched deallocators. .. literalinclude:: checkers/mismatch",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:28385,variab,variable,28385,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['variab'],['variable']
Modifiability,"untime by the compiler, and they're easy to integrate into your build; environment. Canonical examples of when to use Clang Plugins:. * special lint-style warnings or errors for your project; * creating additional build artifacts from a single compile step. Use Clang Plugins when you...:. * need your tool to rerun if any of the dependencies change; * want your tool to make or break a build; * need full control over the Clang AST. Do not use Clang Plugins when you...:. * want to run tools outside of your build environment; * want full control on how Clang is set up, including mapping of in-memory; virtual files; * need to run over a specific subset of files in your project which is not; necessarily related to any changes which would trigger rebuilds. LibTooling; ----------. :doc:`LibTooling <LibTooling>` is a C++ interface aimed at writing standalone; tools, as well as integrating into services that run clang tools. Canonical; examples of when to use LibTooling:. * a simple syntax checker; * refactoring tools. Use LibTooling when you...:. * want to run tools over a single file, or a specific subset of files,; independently of the build system; * want full control over the Clang AST; * want to share code with Clang Plugins. Do not use LibTooling when you...:. * want to run as part of the build triggered by dependency changes; * want a stable interface so you don't need to change your code when the AST API; changes; * want high level abstractions like cursors and code completion out of the box; * do not want to write your tools in C++. :doc:`Clang tools <ClangTools>` are a collection of specific developer tools; built on top of the LibTooling infrastructure as part of the Clang project.; They are targeted at automating and improving core development activities of; C/C++ developers. Examples of tools we are building or planning as part of the Clang project:. * Syntax checking (:program:`clang-check`); * Automatic fixing of compile errors (:program:`clang-fixit`); * Auto",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Tooling.rst:2323,refactor,refactoring,2323,interpreter/llvm-project/clang/docs/Tooling.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Tooling.rst,1,['refactor'],['refactoring']
Modifiability,"untime provide :block-term:`copy` and; :block-term:`release` operations for Block references that create and,; in matched use, release allocated storage for referenced Blocks. The copy operation ``Block_copy()`` is styled as a function that takes; an arbitrary Block reference and returns a Block reference of the same; type. The release operation, ``Block_release()``, is styled as a; function that takes an arbitrary Block reference and, if dynamically; matched to a Block copy operation, allows recovery of the referenced; allocated memory. The ``__block`` Storage Qualifier; =================================. In addition to the new Block type we also introduce a new storage; qualifier, :block-term:`__block`, for local variables. [testme: a; __block declaration within a block literal] The ``__block`` storage; qualifier is mutually exclusive to the existing local storage; qualifiers auto, register, and static. [testme] Variables qualified by; ``__block`` act as if they were in allocated storage and this storage; is automatically recovered after last use of said variable. An; implementation may choose an optimization where the storage is; initially automatic and only ""moved"" to allocated (heap) storage upon; a Block_copy of a referencing Block. Such variables may be mutated as; normal variables are. In the case where a ``__block`` variable is a Block one must assume; that the ``__block`` variable resides in allocated storage and as such; is assumed to reference a Block that is also in allocated storage; (that it is the result of a ``Block_copy`` operation). Despite this; there is no provision to do a ``Block_copy`` or a ``Block_release`` if; an implementation provides initial automatic storage for Blocks. This; is due to the inherent race condition of potentially several threads; trying to update the shared variable and the need for synchronization; around disposing of older values and copying new ones. Such; synchronization is beyond the scope of this language specificat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst:7381,variab,variable,7381,interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,1,['variab'],['variable']
Modifiability,"upper bound of dimension i.; DW_OP_lit<n> ! sizeof(dim); DW_OP_mul; DW_OP_lit<n> ! offsetof(dim); DW_OP_plus; DW_OP_push_object_address; DW_OP_swap; DW_OP_offset; DW_OP_lit<n> ! offset of upperbound in dim; DW_OP_offset; DW_OP_deref); DW_AT_byte_stride(expression=; ! Looks up the byte stride of dimension i.; ...; ! (analogous to DW_AT_upper_bound); ); ----------------------------------------------------------------------------. .. note::. This example suggests that ``DW_AT_lower_bound`` and ``DW_AT_upper_bound``; evaluate an exprloc with an initial stack containing the rank value. The; attribute definition should be updated to state this. D.2.6 Ada Example; +++++++++++++++++. Figure D.20: Ada example: DWARF description. .. code::; :number-lines:. ----------------------------------------------------------------------------; 11$: DW_TAG_variable; DW_AT_name(""M""); DW_AT_type(reference to INTEGER); 12$: DW_TAG_array_type; ! No name, default (Ada) order, default stride; DW_AT_type(reference to INTEGER); 13$: DW_TAG_subrange_type; DW_AT_type(reference to INTEGER); DW_AT_lower_bound(constant 1); DW_AT_upper_bound(reference to variable M at 11$); 14$: DW_TAG_variable; DW_AT_name(""VEC1""); DW_AT_type(reference to array type at 12$); ...; 21$: DW_TAG_subrange_type; DW_AT_name(""TEENY""); DW_AT_type(reference to INTEGER); DW_AT_lower_bound(constant 1); DW_AT_upper_bound(constant 100); ...; 26$: DW_TAG_structure_type; DW_AT_name(""REC2""); 27$: DW_TAG_member; DW_AT_name(""N""); DW_AT_type(reference to subtype TEENY at 21$); DW_AT_data_member_location(constant 0); 28$: DW_TAG_array_type; ! No name, default (Ada) order, default stride; ! Default data location; DW_AT_type(reference to INTEGER); 29$: DW_TAG_subrange_type; DW_AT_type(reference to subrange TEENY at 21$); DW_AT_lower_bound(constant 1); DW_AT_upper_bound(reference to member N at 27$); 30$: DW_TAG_member; DW_AT_name(""VEC2""); DW_AT_type(reference to array ""subtype"" at 28$); DW_AT_data_member_location(machine=; DW_OP_lit<n> ! wh",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:232820,variab,variable,232820,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['variab'],['variable']
Modifiability,"upport atomic; scopes, then they will behave exactly as the standard GNU atomic builtins. Low-level ARM exclusive memory builtins; ---------------------------------------. Clang provides overloaded builtins giving direct access to the three key ARM; instructions for implementing atomic operations. .. code-block:: c. T __builtin_arm_ldrex(const volatile T *addr);; T __builtin_arm_ldaex(const volatile T *addr);; int __builtin_arm_strex(T val, volatile T *addr);; int __builtin_arm_stlex(T val, volatile T *addr);; void __builtin_arm_clrex(void);. The types ``T`` currently supported are:. * Integer types with width at most 64 bits (or 128 bits on AArch64).; * Floating-point types; * Pointer types. Note that the compiler does not guarantee it will not insert stores which clear; the exclusive monitor in between an ``ldrex`` type operation and its paired; ``strex``. In practice this is only usually a risk when the extra store is on; the same cache line as the variable being modified and Clang will only insert; stack stores on its own, so it is best not to use these operations on variables; with automatic storage duration. Also, loads and stores may be implicit in code written between the ``ldrex`` and; ``strex``. Clang will not necessarily mitigate the effects of these either, so; care should be exercised. For these reasons the higher level atomic primitives should be preferred where; possible. Non-temporal load/store builtins; --------------------------------. Clang provides overloaded builtins allowing generation of non-temporal memory; accesses. .. code-block:: c. T __builtin_nontemporal_load(T *addr);; void __builtin_nontemporal_store(T value, T *addr);. The types ``T`` currently supported are:. * Integer types.; * Floating-point types.; * Vector types. Note that the compiler does not guarantee that non-temporal loads or stores; will be used. C++ Coroutines support builtins; --------------------------------. .. warning::; This is a work in progress. Compatibility across ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:144287,variab,variable,144287,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,2,['variab'],"['variable', 'variables']"
Modifiability,"upport; for the ``decltype(auto)`` placeholder type is enabled. C++14 default initializers for aggregates; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Use ``__has_feature(cxx_aggregate_nsdmi)`` or; ``__has_extension(cxx_aggregate_nsdmi)`` to determine if support; for default initializers in aggregate members is enabled. C++14 digit separators; ^^^^^^^^^^^^^^^^^^^^^^. Use ``__cpp_digit_separators`` to determine if support for digit separators; using single quotes (for instance, ``10'000``) is enabled. At this time, there; is no corresponding ``__has_feature`` name. C++14 generalized lambda capture; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Use ``__has_feature(cxx_init_captures)`` or; ``__has_extension(cxx_init_captures)`` to determine if support for; lambda captures with explicit initializers is enabled; (for instance, ``[n(0)] { return ++n; }``). C++14 generic lambdas; ^^^^^^^^^^^^^^^^^^^^^. Use ``__has_feature(cxx_generic_lambdas)`` or; ``__has_extension(cxx_generic_lambdas)`` to determine if support for generic; (polymorphic) lambdas is enabled; (for instance, ``[] (auto x) { return x + 1; }``). C++14 relaxed constexpr; ^^^^^^^^^^^^^^^^^^^^^^^. Use ``__has_feature(cxx_relaxed_constexpr)`` or; ``__has_extension(cxx_relaxed_constexpr)`` to determine if variable; declarations, local variable modification, and control flow constructs; are permitted in ``constexpr`` functions. C++14 return type deduction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Use ``__has_feature(cxx_return_type_deduction)`` or; ``__has_extension(cxx_return_type_deduction)`` to determine if support; for return type deduction for functions (using ``auto`` as a return type); is enabled. C++14 runtime-sized arrays; ^^^^^^^^^^^^^^^^^^^^^^^^^^. Use ``__has_feature(cxx_runtime_array)`` or; ``__has_extension(cxx_runtime_array)`` to determine if support; for arrays of runtime bound (a restricted form of variable-length arrays); is enabled.; Clang's implementation of this feature is incomplete. C++14 variable templates; ^^^^^^^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:50121,polymorphi,polymorphic,50121,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['polymorphi'],['polymorphic']
Modifiability,"upports processing an `RNTuple` dataset.; * In distributed `RDataFrame`, the `initialize` function useful to run initialization code at the beginning of every task; on a worker will now run only in the worker processes. Previously, it was also run eagerly at the point of calling, that; is in the main user process. This is done to better separate the user driver environment and the worker environments. If; necessary, the function passed to `initialize` can be called directly by the user in the main application to reproduce; the same effect as before.; * Some internal details of the `RDataFrame` implementation were reworked to decrease memory usage and runtime of programs; with very deep computation graphs (more than O(10K) nodes in the same branch). Preliminary tests indicate between 30%; and a factor 2.5 in memory decrease. This improvement is transparent for `RDataFrame` users. ## Graphics backends; The ROOT release 6.32 brings a lot of impressive enhancements to the Web Graphics package, greatly surpassing the features and capabilities of version 6.30. ; This update provides users with a more robust Web Graphics. * The JSROOT version has been updated to v7.7. ## 2D Graphics Libraries. - TMultiGraph: Add the objects from the list of functions in legend produce by TLegend.; - Implement the IsInside method for TEllipse, TCrown and TDiamond. Also, a new graphics example `inside.C` has been added.; - Two new methods in TColor: `ListColors()` and `GetColorByname()`.; - Make sure the option `L` draws closed polygon for `TH2Poly`.; - Use Tex Gyre fonts for sans serif (similar to Helvetica) .; - The new method `TPad::ModifiedUpdate` is short cut to call `Modified()` and `Update()` in a single call. On Mac with Cocoa, it performs an additional ProcessEvents().; - Improve `SetTextSize` error: show code and values.; - Very long text string generated a wrong SVG file.; - Fix the option `SAME` works for `TGraph2D`.; - Implement the title for the palette of a `TH3`.; - Fix typo ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:16353,enhance,enhancements,16353,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['enhance'],['enhancements']
Modifiability,"uration options, please see the; :doc:`user-docs/TaintAnalysisConfiguration`. For an example see; :ref:`clangsa-taint-configuration-example`. **Configuration**. * `Config` Specifies the name of the YAML configuration file. The user can; define their own taint sources and sinks. **Related Guidelines**. * `CWE Data Neutralization Issues; <https://cwe.mitre.org/data/definitions/137.html>`_; * `SEI Cert STR02-C. Sanitize data passed to complex subsystems; <https://wiki.sei.cmu.edu/confluence/display/c/STR02-C.+Sanitize+data+passed+to+complex+subsystems>`_; * `SEI Cert ENV33-C. Do not call system(); <https://wiki.sei.cmu.edu/confluence/pages/viewpage.action?pageId=87152177>`_; * `ENV03-C. Sanitize the environment when invoking external programs; <https://wiki.sei.cmu.edu/confluence/display/c/ENV03-C.+Sanitize+the+environment+when+invoking+external+programs>`_. **Limitations**. * The taintedness property is not propagated through function calls which are; unknown (or too complex) to the analyzer, unless there is a specific; propagation rule built-in to the checker or given in the YAML configuration; file. This causes potential true positive findings to be lost. alpha.unix; ^^^^^^^^^^. .. _alpha-unix-BlockInCriticalSection:. alpha.unix.BlockInCriticalSection (C); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for calls to blocking functions inside a critical section.; Applies to: ``lock, unlock, sleep, getc, fgets, read, recv, pthread_mutex_lock,``; `` pthread_mutex_unlock, mtx_lock, mtx_timedlock, mtx_trylock, mtx_unlock, lock_guard, unique_lock``. .. code-block:: c. void test() {; std::mutex m;; m.lock();; sleep(3); // warn: a blocking function sleep is called inside a critical; // section; m.unlock();; }. .. _alpha-unix-Chroot:. alpha.unix.Chroot (C); """"""""""""""""""""""""""""""""""""""""""; Check improper use of chroot. .. code-block:: c. void f();. void test() {; chroot(""/usr/local"");; f(); // warn: no call of chdir(""/"") immediately after chroot; }. .. _alpha-unix-PthreadLock:. alpha.uni",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:74368,config,configuration,74368,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['config'],['configuration']
Modifiability,"urce -> llvm-tblgen -> JSON -> Python -> results; ```. The backend here is ported from one of several in ""SQLGen"" which was written by Min-Yih Hsu.; * SQLGen C++ sources - https://github.com/mshockwave/SQLGen; * LLVM dev presentation - https://www.youtube.com/watch?v=UP-LBRbvI_U. I encourage you to use those resources to supplement this notebook. ## Compiling TableGen. Unlike the other tutorial notebooks we are not using the TableGen kernel. This is an iPython notebook and we're going to run `llvm-tblgen` as a subprocess. First let's find it, in the same way the TableGen kernel does. ```python; import os; import shutil. def find_tblgen():; path = os.environ.get(""LLVM_TBLGEN_EXECUTABLE""); if path is not None and os.path.isfile(path) and os.access(path, os.X_OK):; return path; else:; path = shutil.which(""llvm-tblgen""); if path is None:; raise OSError(""llvm-tblgen not found""); return path; ; _ = find_tblgen(); ```. If the above cell raises an exception, either put `llvm-tblgen` on your `PATH` or point to it using the `LLVM_TBLGEN_EXECUTABLE` environment variable. Alternatively, edit the code to use whatever path you want. Then we need to compile some TableGen by passing it to `llvm-tblgen`'s stdin. We will be using the option `--dump-json` and returning the JSON as a Python dictionary if the compilation succeeds. If it fails, we raise an exception. ```python; import subprocess; import tempfile; import json. def run_tblgen(src):; # Passing to stdin requires a file like object.; with tempfile.TemporaryFile(""w+"") as f:; f.write(src); f.seek(0); got = subprocess.run(; [find_tblgen(), ""--dump-json""],; stdin=f,; stderr=subprocess.PIPE,; stdout=subprocess.PIPE,; universal_newlines=True,; ); ; if got.stderr:; raise RuntimeError(""llvm-tblgen failed with stderr: "" + got.stderr); ; return json.loads(got.stdout); ; print(json.dumps(run_tblgen(""class Foo {}""), indent=4)); ```. {; ""!instanceof"": {; ""Foo"": []; },; ""!tablegen_json_version"": 1; }. ## Structure of a SQL Query. This backe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md:1584,variab,variable,1584,interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/utils/TableGen/jupyter/sql_query_backend.md,1,['variab'],['variable']
Modifiability,"ure above, can be viewed by selecting the; menu entry Colors in the View canvas menu. The user may define other; colors. To do this, one has to build a new **`TColor`**:. ``` {.cpp}; TColor(Int_t color,Float_t r,Float_t g,Float_t b,const char* name); ```. One has to give the color number and the three Red, Green, Blue values,; each being defined from 0 (min) to 1(max). An optional name may be; given. When built, this color is automatically added to the existing; list of colors. If the color number already exists, one has to extract; it from the list and redefine the RGB values. This may be done for; example with:. ``` {.cpp}; root[] color=(TColor*)(gROOT->GetListOfColors()->At(index_color)); root[] color->SetRGB(r,g,b); ```. Where `r`, `g` and `b` go from 0 to 1 and `index_color` is the color; number you wish to change. ![](pictures/030000D4.png) The user interface for changing the fill; color and style looks like shown in this picture. It takes place in the; editor frame anytime the selected object inherits the class; **`TAttFill`**. #### Color Palette (for Histograms). Defining one color at a time may be tedious. The histogram classes (see; Draw Options) use the color palette. For example, `TH1::Draw(""col"")`; draws a 2-D histogram with cells represented by a box filled with a; color `CI` function of the cell content. If the cell content is `N`, the; color `CI` used will be the color number in `colors[N]`. If the maximum; cell content is `>ncolors`, all cell contents are scaled to `ncolors`.; The current color palette does not have a class or global object of its; own. It is defined in the current style as an array of color numbers.; The current palette can be changed with:. ``` {.cpp}; TStyle::SetPalette(Int_t ncolors,Int_t*color_indexes).; ```. By default, or if `ncolors <= 0`, a default palette (see above) of 50; colors is defined. The colors defined in this palette are good for; coloring pads, labels, and other graphic objects. If `ncolors > 0` and; `colors = 0",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:81288,inherit,inherits,81288,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['inherit'],['inherits']
Modifiability,"ures it into the; string variable ``REGISTER``. The second line verifies that whatever is in; ``REGISTER`` occurs later in the file after an ""``andw``"". :program:`FileCheck`; string substitution blocks are always contained in ``[[ ]]`` pairs, and string; variable names can be formed with the regex ``[a-zA-Z_][a-zA-Z0-9_]*``. If a; colon follows the name, then it is a definition of the variable; otherwise, it; is a substitution. :program:`FileCheck` variables can be defined multiple times, and substitutions; always get the latest value. Variables can also be substituted later on the; same line they were defined on. For example:. .. code-block:: llvm. ; CHECK: op [[REG:r[0-9]+]], [[REG]]. Can be useful if you want the operands of ``op`` to be the same register,; and don't care exactly which register it is. If ``--enable-var-scope`` is in effect, variables with names that; start with ``$`` are considered to be global. All others variables are; local. All local variables get undefined at the beginning of each; CHECK-LABEL block. Global variables are not affected by CHECK-LABEL.; This makes it easier to ensure that individual tests are not affected; by variables set in preceding tests. FileCheck Numeric Substitution Blocks; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. :program:`FileCheck` also supports numeric substitution blocks that allow; defining numeric variables and checking for numeric values that satisfy a; numeric expression constraint based on those variables via a numeric; substitution. This allows ``CHECK:`` directives to verify a numeric relation; between two numbers, such as the need for consecutive registers to be used. The syntax to capture a numeric value is; ``[[#%<fmtspec>,<NUMVAR>:]]`` where:. * ``%<fmtspec>,`` is an optional format specifier to indicate what number; format to match and the minimum number of digits to expect. * ``<NUMVAR>:`` is an optional definition of variable ``<NUMVAR>`` from the; captured value. The syntax of ``<fmtspec>`` is: ``#.<prec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst:27629,variab,variables,27629,interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,1,['variab'],['variables']
Modifiability,"urn 1;; else return 0; }; ULong_t Hash() const { return num; }; };; ```. ## The TIter Generic Iterator. As stated above, the **`TIterator`** class is abstract; it is not; possible to create **`TIterator`** objects. However, it should be; possible to write generic code to process all members of a collection so; there is a need for a generic iterator object. A **`TIter`** object acts; as generic iterator. It provides the same `Next()` and `Reset()` methods; as **`TIterator`** although it has no idea how to support them! It works; as follows:. - To create a **`TIter`** object its constructor must be passed an; object that inherits from **`TCollection`**. The **`TIter`**; constructor calls the `MakeIterator()` method of this collection to; get the appropriate iterator object that inherits from; **`TIterator`**. - The `Next()` and `Reset()` methods of **`TIter`** simply call the; `Next()` and `Reset()` methods of the iterator object. Therefore, **`TIter`** simply acts as a wrapper for an object of a; concrete class inheriting from **`TIterator`**. To see this working in practice, consider the **`TObjArray`**; collection. Its associated iterator is **`TObjArrayIter`**. Suppose; `myarray` is a pointer to a **`TObjArray`** that contains `MyClass`; objects, i.e. ``` {.cpp}; TObjArray *myarray;; ```. To create a **`TIter`** object called `myiter`:. ``` {.cpp}; TIter myiter(myarray);; ```. ![](pictures/020001A4.jpg). As shown in the diagram, this results in several methods being called:. - The **`TIter`** constructor is passed a **`TObjArray`**. - **`TIter`** asks embedded **`TCollection`** to make an iterator. - **`TCollection`** asks **`TObjArray`** to make an iterator. - **`TObjArray`** returns a **`TObjArrayIter`**. Now define a pointer for `MyClass` objects and set it to each member of; the **`TObjArray`**:. ``` {.cpp}; MyClass *myobject;; while ((myobject = (MyClass *)myiter.Next())) {; // process myobject; }; ```. The heart of this is the `myiter.Next()` expression whic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/CollectionClasses.md:11270,inherit,inheriting,11270,documentation/users-guide/CollectionClasses.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/CollectionClasses.md,1,['inherit'],['inheriting']
Modifiability,"urn x; // warn; }. // C++; void test() {; int a = 2;. while (a > 1); a--;. if (a > 1); a++; // warn; }. // Objective-C; void test(id x) {; return;; [x retain]; // warn; }. alpha.fuchsia; ^^^^^^^^^^^^^. .. _alpha-fuchsia-lock:. alpha.fuchsia.Lock; """"""""""""""""""""""""""""""""""""; Similarly to :ref:`alpha.unix.PthreadLock <alpha-unix-PthreadLock>`, checks for; the locking/unlocking of fuchsia mutexes. .. code-block:: cpp. spin_lock_t mtx1;. void bad1(void); {; spin_lock(&mtx1);; spin_lock(&mtx1);	// warn: This lock has already been acquired; }. alpha.llvm; ^^^^^^^^^^. .. _alpha-llvm-Conventions:. alpha.llvm.Conventions; """""""""""""""""""""""""""""""""""""""""""". Check code for LLVM codebase conventions:. * A StringRef should not be bound to a temporary std::string whose lifetime is shorter than the StringRef's.; * Clang AST nodes should not have fields that can allocate memory. alpha.osx; ^^^^^^^^^. .. _alpha-osx-cocoa-DirectIvarAssignment:. alpha.osx.cocoa.DirectIvarAssignment (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for direct assignments to instance variables. .. code-block:: objc. @interface MyClass : NSObject {}; @property (readonly) id A;; - (void) foo;; @end. @implementation MyClass; - (void) foo {; _A = 0; // warn; }; @end. .. _alpha-osx-cocoa-DirectIvarAssignmentForAnnotatedFunctions:. alpha.osx.cocoa.DirectIvarAssignmentForAnnotatedFunctions (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for direct assignments to instance variables in; the methods annotated with ``objc_no_direct_instance_variable_assignment``. .. code-block:: objc. @interface MyClass : NSObject {}; @property (readonly) id A;; - (void) fAnnotated __attribute__((; annotate(""objc_no_direct_instance_variable_assignment"")));; - (void) fNotAnnotated;; @end. @implementation MyClass; - (void) fAnnotated {; _A = 0; // warn; }; - (void) fNotAnnotated {; _A = 0; // no warn; }; @end. .. _alpha-osx-cocoa-InstanceVariableInvalidation:. alpha.osx.cocoa.InstanceVariableInvalidation (ObjC);",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:57235,variab,variables,57235,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['variab'],['variables']
Modifiability,"urrounding context. .. code-block:: c++. namespace N {; enum E {; E1,; E2,; };. class C {; public:; C();; };. bool baz(int i) {; try {; do {; switch (i) {; case 1: {; foobar();; break;; }; default: {; break;; }; }; } while (--i);; return true;; } catch (...) {; handleError();; return false;; }; }. void foo(bool b) {; if (b) {; baz(2);; } else {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_Linux`` (in configuration: ``Linux``); Like ``Attach``, but break before braces on function, namespace and; class definitions. .. code-block:: c++. namespace N; {; enum E {; E1,; E2,; };. class C; {; public:; C();; };. bool baz(int i); {; try {; do {; switch (i) {; case 1: {; foobar();; break;; }; default: {; break;; }; }; } while (--i);; return true;; } catch (...) {; handleError();; return false;; }; }. void foo(bool b); {; if (b) {; baz(2);; } else {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_Mozilla`` (in configuration: ``Mozilla``); Like ``Attach``, but break before braces on enum, function, and record; definitions. .. code-block:: c++. namespace N {; enum E; {; E1,; E2,; };. class C; {; public:; C();; };. bool baz(int i); {; try {; do {; switch (i) {; case 1: {; foobar();; break;; }; default: {; break;; }; }; } while (--i);; return true;; } catch (...) {; handleError();; return false;; }; }. void foo(bool b); {; if (b) {; baz(2);; } else {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_Stroustrup`` (in configuration: ``Stroustrup``); Like ``Attach``, but break before function definitions, ``catch``, and; ``else``. .. code-block:: c++. namespace N {; enum E {; E1,; E2,; };. class C {; public:; C();; };. bool baz(int i); {; try {; do {; switch (i) {; case 1: {; foobar();; break;; }; default: {; break;; }; }; } while (--i);; return true;; }; catch (...) {; handleError();; return false;; }; }. void foo(bool b); {; if (b) {; baz(2);; }; else {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_All",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:48741,config,configuration,48741,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['config'],['configuration']
Modifiability,"use complexities in SSA; construction, consider this extremely simple C example:. .. code-block:: c. int G, H;; int test(_Bool Condition) {; int X;; if (Condition); X = G;; else; X = H;; return X;; }. In this case, we have the variable ""X"", whose value depends on the path; executed in the program. Because there are two different possible values; for X before the return instruction, a PHI node is inserted to merge the; two values. The LLVM IR that we want for this example looks like this:. .. code-block:: llvm. @G = weak global i32 0 ; type of @G is i32*; @H = weak global i32 0 ; type of @H is i32*. define i32 @test(i1 %Condition) {; entry:; br i1 %Condition, label %cond_true, label %cond_false. cond_true:; %X.0 = load i32, i32* @G; br label %cond_next. cond_false:; %X.1 = load i32, i32* @H; br label %cond_next. cond_next:; %X.2 = phi i32 [ %X.1, %cond_false ], [ %X.0, %cond_true ]; ret i32 %X.2; }. In this example, the loads from the G and H global variables are; explicit in the LLVM IR, and they live in the then/else branches of the; if statement (cond\_true/cond\_false). In order to merge the incoming; values, the X.2 phi node in the cond\_next block selects the right value; to use based on where control flow is coming from: if control flow comes; from the cond\_false block, X.2 gets the value of X.1. Alternatively, if; control flow comes from cond\_true, it gets the value of X.0. The intent; of this chapter is not to explain the details of SSA form. For more; information, see one of the many `online; references <http://en.wikipedia.org/wiki/Static_single_assignment_form>`_. The question for this article is ""who places the phi nodes when lowering; assignments to mutable variables?"". The issue here is that LLVM; *requires* that its IR be in SSA form: there is no ""non-ssa"" mode for; it. However, SSA construction requires non-trivial algorithms and data; structures, so it is inconvenient and wasteful for every front-end to; have to reproduce this logic. Memory in LLV",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:2461,variab,variables,2461,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['variab'],['variables']
Modifiability,"use in the replacement of a ``s@@@`` command in sed; %{/T:regex_replacement} %/T but escaped for use in the replacement of a ``s@@@`` command in sed; %:s On Windows, %/s but a ``:`` is removed if its the second character.; Otherwise, %s but with a single leading ``/`` removed.; %:S On Windows, %/S but a ``:`` is removed if its the second character.; Otherwise, %S but with a single leading ``/`` removed.; %:p On Windows, %/p but a ``:`` is removed if its the second character.; Otherwise, %p but with a single leading ``/`` removed.; %:t On Windows, %/t but a ``:`` is removed if its the second character.; Otherwise, %t but with a single leading ``/`` removed.; %:T On Windows, %/T but a ``:`` is removed if its the second character.; Otherwise, %T but with a single leading ``/`` removed.; ======================= ==============. Other substitutions are provided that are variations on this base set and; further substitution patterns can be defined by each test module. See the; modules :ref:`local-configuration-files`. More detailed information on substitutions can be found in the; :doc:`../TestingGuide`. TEST RUN OUTPUT FORMAT; ~~~~~~~~~~~~~~~~~~~~~~. The :program:`lit` output for a test run conforms to the following schema, in; both short and verbose modes (although in short mode no PASS lines will be; shown). This schema has been chosen to be relatively easy to reliably parse by; a machine (for example in buildbot log scraping), and for other tools to; generate. Each test result is expected to appear on a line that matches:. .. code-block:: none. <result code>: <test name> (<progress info>). where ``<result-code>`` is a standard test result such as PASS, FAIL, XFAIL,; XPASS, UNRESOLVED, or UNSUPPORTED. The performance result codes of IMPROVED and; REGRESSED are also allowed. The ``<test name>`` field can consist of an arbitrary string containing no; newline. The ``<progress info>`` field can be used to report progress information such; as (1/300) or can be empty, but even",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst:22047,config,configuration-files,22047,interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,1,['config'],['configuration-files']
Modifiability,"use the syntax above. 40. **`tree->Draw(""fTracks.fTriggerBits"")`**. `fTriggerBits` is a data member of **`TTrack`** of type **`TBits`**.; Objects of class **`TBits`** can be drawn directly. This command will; create a 1D histogram from 0 to `nbits` which is filled for each; non-null bit-number. 41. **`tree->Draw(""fMatrix-Alt$(fClosestDistance,0)"")`**. `Alt$(primary,alternate)` returns the value of ""`primary`"" if it is; available for the current iteration; otherwise return the value of; ""`alternate`"". Assuming that `fClosestDistance` is a smaller array than; `fMatrix`. This example will draw `fMatrix[i]+fClosestDistance[i]` for; `i` less than the size of `fClosestDistance`, and will draw; `fMatrix[i]+0` for the other value of `i`. 42. **`tree->Draw(""fClosestDistance:Iteration$"")`**. This example draws a 2D plot with, for all entries,; `fClosestDistance[i]:i` for each value of `i` between 0 and the size of; `fClosestDistance`. `Iterations$` is one of four special variables; giving some indications of the state of the loops implied by the; formula:. `Entry$ :` return the current entry number (`TTree::GetReadEntry()`). `Entries$ :` return the total number of entries (`TTree::GetEntries()`). `Length$ :` return the total number of element of this formula for; this entry. `Iteration$:` return the current iteration over this formula for this; entry (i.e. varies from 0 to `Length$`). 43. **`tree->Draw(""fLastTrack.GetPx():fLastTrack.fPx"");`**. **`TRef`** and **`TRefArray`** are automatically deferenced and this; shows the value of the `fPx` of the track referenced by `fLastTrack`. To; access the **`TRef`** object itself use the '`@`' notation (see next; example). This auto dereferencing can be extended (via an implementation; of **`TVirtualRefProxy`**) to any reference type. 44. **`tree->Scan(""((Track*)(fLastTrack@.GetObject())).GetPx()"","""","""");`**. Will cast the return value of `GetObject()` (which happens to be; **`TObject*`** in this case) before requesting the `GetPx()` m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:91960,variab,variables,91960,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['variab'],['variables']
Modifiability,"used to setup a sort of ROOTmarks in stressProof .; Several improvements in the test program 'stressProof'; and in the tutorials under 'tutorials/proof'; Avoid; contacting the DNS when initializing TProofMgr as base class of; TProofMgrLite: it is not needed and it may introduce long startup; delays.; Make TProof::LogViewer("""") start the viewer for; a Lite session, in parallel to whats happen for TProof::Open("""").; Several; improvements in the handling of wild cards in the dataset manager; for; example, issuing a GetDataSet(...) on a dataset URI containign wild; cards will return a grand dataset sum of all the datasets matching the; URI.; Add options to get a list of all dataset registered names; from ScanDataSets (option kList; the result is a TMap of {TObjString,; TObjString} with the second TObjString empty).Improved version of the PQ2 scripts; the scripts now invoke a dedicated ROOT application (named pq2) available under $ROOTSYS/bin .Add; support for recursive reading of group config files via the 'include; sub-file' directive. This allows to have a common part and, for; example, customize differently the quotas.Fix an issue with TTreeFriends. New tutorial showing how to use friends in PROOF.Package; management: add support for arguments in the SETUP function: it is; possible now to pass a string or a list of objects. The; TProof::EnablePackage interface has been extended to support this.Optimize; the validation step in the case not all the entries are required. The; validation step is stopped as soon as the requested number of events is; reached. If the parameter ""PROOF_ValidateByFile"" is set to 1, the; number of files is exactly what needed; otherwise the number of files; may exceed the number of files needed by (Number_Of_Workers - 1) .; New directive 'xpd.datadir' to better control the user data directories and their permission settings. In TPacketizerUnit, add the possibility to exactly share the number of cycles between the workers.; See the parameter PROO",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:5451,config,config,5451,proof/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html,1,['config'],['config']
Modifiability,"used with -offset and -length.; Can only be used with one input file.; -n - Alias for --dry-run; --offset=<uint> - Format a range starting at this byte offset.; Multiple ranges can be formatted by specifying; several -offset and -length pairs.; Can only be used with one input file.; --output-replacements-xml - Output replacements as XML.; --qualifier-alignment=<string> - If set, overrides the qualifier alignment style; determined by the QualifierAlignment style flag; --sort-includes - If set, overrides the include sorting behavior; determined by the SortIncludes style flag; --style=<string> - Set coding style. <string> can be:; 1. A preset: LLVM, GNU, Google, Chromium, Microsoft,; Mozilla, WebKit.; 2. 'file' to load style configuration from a; .clang-format file in one of the parent directories; of the source file (for stdin, see --assume-filename).; If no .clang-format file is found, falls back to; --fallback-style.; --style=file is the default.; 3. 'file:<format_file_path>' to explicitly specify; the configuration file.; 4. ""{key: value, ...}"" to set specific parameters, e.g.:; --style=""{BasedOnStyle: llvm, IndentWidth: 8}""; --verbose - If set, shows the list of processed files. Generic Options:. --help - Display available options (--help-hidden for more); --help-list - Display list of available options (--help-list-hidden for more); --version - Display the version of this program. .. END_FORMAT_HELP. When the desired code formatting style is different from the available options,; the style can be customized using the ``-style=""{key: value, ...}""`` option or; by putting your style configuration in the ``.clang-format`` or ``_clang-format``; file in your project's directory and using ``clang-format -style=file``. An easy way to create the ``.clang-format`` file is:. .. code-block:: console. clang-format -style=llvm -dump-config > .clang-format. Available style options are described in :doc:`ClangFormatStyleOptions`. .clang-format-ignore; ====================. You ca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst:4156,config,configuration,4156,interpreter/llvm-project/clang/docs/ClangFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormat.rst,1,['config'],['configuration']
Modifiability,"used. .. _legalize types:; .. _Legalize SelectionDAG Types:; .. _Legalize SelectionDAG Ops:. SelectionDAG LegalizeTypes Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Legalize phase is in charge of converting a DAG to only use the types that; are natively supported by the target. There are two main ways of converting values of unsupported scalar types to; values of supported types: converting small types to larger types (""promoting""),; and breaking up large integer types into smaller ones (""expanding""). For; example, a target might require that all f32 values are promoted to f64 and that; all i1/i8/i16 values are promoted to i32. The same target might require that; all i64 values be expanded into pairs of i32 values. These changes can insert; sign and zero extensions as needed to make sure that the final code has the same; behavior as the input. There are two main ways of converting values of unsupported vector types to; value of supported types: splitting vector types, multiple times if necessary,; until a legal type is found, and extending vector types by adding elements to; the end to round them out to legal types (""widening""). If a vector gets split; all the way down to single-element parts with no supported vector type being; found, the elements are converted to scalars (""scalarizing""). A target implementation tells the legalizer which types are supported (and which; register class to use for them) by calling the ``addRegisterClass`` method in; its ``TargetLowering`` constructor. .. _legalize operations:; .. _Legalizer:. SelectionDAG Legalize Phase; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Legalize phase is in charge of converting a DAG to only use the operations; that are natively supported by the target. Targets often have weird constraints, such as not supporting every operation on; every supported datatype (e.g. X86 does not support byte conditional moves and; PowerPC does not support sign-extending loads from a 16-bit memory location).; Legalize takes care of this by",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:41832,extend,extending,41832,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['extend'],['extending']
Modifiability,"using standard above-presented algorithm. ![Part of original noisy spectrum and Markov spectrum for window=3](figures/image066.png). The form of the generalized peak searching function is as follows:. ```{.cpp}; Int_t Search1General(float *spectrum,; int size,; float sigma,; int threshold,; bool markov,; int aver_window);; ```. This function searches for peaks in the source spectrum. The number of found; peaks and their positions are written into the structure pointed by the; `one_dim_peak` structure pointer. Function parameters:. - **`spectrum`**: pointer to the vector of the source spectrum. This source spectrum is replaced by the new spectrum calculated using Markov chains method.; - **`size`**: length of the source spectrum; - **`sigma`**: sigma of searched peaks; - **`threshold`**: threshold value for peaks selection; - **`markov`**: logical variable. If it is set to `true`, then the source spectrum is first replaced by the new spectrum calculated using Markov chains method; - **`aver_window`**: averaging window used in the calculation of Markov spectrum, applies only if the `markov` variable was set to `true`. The methods of peak searching are sensitive to the `sigma`. Usually the; `sigma` value is known beforehand. It also changes only slightly with the; energy. We have investigated as well the robustness of the proposed; algorithms to the spectrum with the peaks with `sigma` changing from 1 to; 10 (see Figure 3.6). ![Robustness of the proposed algorithms to the spectrum with the peaks with sigma changing from 1 to 10](figures/image068.png). We applied peak searching algorithm based on Markov approach. We changed; `sigma` in the interval from 1 to 10. The spectra for averaging windows 3,; 5, 10 are shown in Figure 3.7. ![Spectra for averaging windows 3, 5, 10](figures/image070.png). When we applied peak searching function to the Markov spectrum averaged; with the `window=10`, we obtained correct estimate of all 10 peak; positions for `sigma=2,3,4,5,6,7,8`. It ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md:20239,variab,variable,20239,documentation/spectrum/Spectrum.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/spectrum/Spectrum.md,1,['variab'],['variable']
Modifiability,"usly saved in a variable using the `addResult()` function). - `addResult()` It may include a function call, an expression, or something; more complicated. For a specific class, it will add whatever is represented on; the right-hand side to the result of that class, which can then be propagated; in the rest of the compute graph. \note For each `translate()` function, it is important to call `addResult()` since this is what enables the squashing to happen. **translate() Example 2:** Following is a code snippet from `RooGaussian.cxx`; *after* it has AD support. ``` {.cpp}; void RooGaussian::translate(RooFit::Detail::RooFit::Detail::CodeSquashContext &ctx) const; {; ctx.addResult(this, ctx.buildCall(""RooFit::Detail::MathFuncs::gaussianEvaluate"", x, mean, sigma));; }; ```. Here we can see that the `RooGaussian::translate()` function constructs a; function call using the `buildCall()` method. It specifies the fully qualified; name of the `gaussianEvaluate` function (which is now part of the; `MathFuncs` file), and includes the x, mean, and sigma variables as; arguments to this function call. Helper Function:. - `buildCall()` helps build a function call. Requires the fully qualified name; (`RooFit::Detail::MathFuncs::gaussianEvaluate`) of the function. When; this external `buildCall()` function is called, internally, the `getResult()`; function is called on the input RooFit objects (e.g., x, mean, sigma). That's; the only way to propagate these upwards into the compute graph. **translate() Example 3:** A more complicated example of a `translate()`; function can be seen here:. ``` {.cpp}; void RooNLLVarNew::translate(RooFit::Detail::RooFit::Detail::CodeSquashContext &ctx) const; {; std::string weightSumName = ctx.makeValidVarName(GetName()) + ""WeightSum"";; std::string resName = ctx.makeValidVarName(GetName()) + ""Result"";; ctx.addResult(this, resName);; ctx.addToGlobalScope(""double "" + weightSumName + "" = 0.0;\n"");; ctx.addToGlobalScope(""double "" + resName + "" = 0.0;\n"");. co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md:14522,variab,variables,14522,roofit/doc/developers/roofit_ad.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_ad.md,1,['variab'],['variables']
Modifiability,"ust cycle in less than 15 minutes to have a hope of being; useful. However, those commits are not uniformly distributed. They; tend to cluster strongly during US working hours. Looking at a couple; of recent (Nov 2021) working days, we routinely see ~10 commits per; hour during peek times, with occasional spikes as high as ~15 commits; per hour. Thus, as a rule of thumb, we should plan for our builder to; complete ~10-15 builds an hour. Resource Appropriately; At 10-15 builds per hour, we need to complete a new build on average every; 4 to 6 minutes. For anything except the fastest of hardware/build configs,; this is going to be well beyond the ability of a single machine. In buildbot; terms, we likely going to need multiple workers to build requests in parallel; under a single builder configuration. For some rough back of the envelope; numbers, if your build config takes e.g. 30 minutes, you will need something; on the order of 5-8 workers. If your build config takes ~2 hours, you'll; need something on the order of 20-30 workers. The rest of this section; focuses on how to reduce cycle times. Restrict what you build and test; Think hard about why you're setting up a bot, and restrict your build; configuration as much as you can. Basic functionality is probably; already covered by other bots, and you don't need to duplicate that; testing. You only need to be building and testing the *unique* parts; of the configuration. (e.g. For a multi-stage clang builder, you probably; don't need to be enabling every target or building all the various utilities.). It can sometimes be worthwhile splitting a single builder into two or more,; if you have multiple distinct purposes for the same builder. As an example,; if you want to both a) confirm that all of LLVM builds with your host; compiler, and b) want to do a multi-stage clang build on your target, you; may be better off with two separate bots. Splitting increases resource; consumption, but makes it easy for each bot to keep ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst:9214,config,config,9214,interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToAddABuilder.rst,1,['config'],['config']
Modifiability,"ust like any other binary operator, but handle; it internally (instead of allowing the user to define it). The first; step is to set a precedence:. .. code-block:: c++. int main() {; // Install standard binary operators.; // 1 is lowest precedence.; BinopPrecedence['='] = 2;; BinopPrecedence['<'] = 10;; BinopPrecedence['+'] = 20;; BinopPrecedence['-'] = 20;. Now that the parser knows the precedence of the binary operator, it; takes care of all the parsing and AST generation. We just need to; implement codegen for the assignment operator. This looks like:. .. code-block:: c++. Value *BinaryExprAST::codegen() {; // Special case '=' because we don't want to emit the LHS as an expression.; if (Op == '=') {; // This assume we're building without RTTI because LLVM builds that way by; // default. If you build LLVM with RTTI this can be changed to a; // dynamic_cast for automatic error checking.; VariableExprAST *LHSE = static_cast<VariableExprAST*>(LHS.get());; if (!LHSE); return LogErrorV(""destination of '=' must be a variable"");. Unlike the rest of the binary operators, our assignment operator doesn't; follow the ""emit LHS, emit RHS, do computation"" model. As such, it is; handled as a special case before the other binary operators are handled.; The other strange thing is that it requires the LHS to be a variable. It; is invalid to have ""(x+1) = expr"" - only things like ""x = expr"" are; allowed. .. code-block:: c++. // Codegen the RHS.; Value *Val = RHS->codegen();; if (!Val); return nullptr;. // Look up the name.; Value *Variable = NamedValues[LHSE->getName()];; if (!Variable); return LogErrorV(""Unknown variable name"");. Builder->CreateStore(Val, Variable);; return Val;; }; ... Once we have the variable, codegen'ing the assignment is; straightforward: we emit the RHS of the assignment, create a store, and; return the computed value. Returning a value allows for chained; assignments like ""X = (Y = Z)"". Now that we have an assignment operator, we can mutate loop variables; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:21248,variab,variable,21248,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['variab'],['variable']
Modifiability,"ust returns the RHS.; def binary : 1 (x y) y;. # Recursive fib, we could do this before.; def fib(x); if (x < 3) then; 1; else; fib(x-1)+fib(x-2);. # Iterative fib.; def fibi(x); var a = 1, b = 1, c in; (for i = 3, i < x in; c = a + b :; a = b :; b = c) :; b;. # Call it.; fibi(10);. In order to mutate variables, we have to change our existing variables; to use the ""alloca trick"". Once we have that, we'll add our new; operator, then extend Kaleidoscope to support new variable definitions. Adjusting Existing Variables for Mutation; =========================================. The symbol table in Kaleidoscope is managed at code generation time by; the '``NamedValues``' map. This map currently keeps track of the LLVM; ""Value\*"" that holds the double value for the named variable. In order; to support mutation, we need to change this slightly, so that; ``NamedValues`` holds the *memory location* of the variable in question.; Note that this change is a refactoring: it changes the structure of the; code, but does not (by itself) change the behavior of the compiler. All; of these changes are isolated in the Kaleidoscope code generator. At this point in Kaleidoscope's development, it only supports variables; for two things: incoming arguments to functions and the induction; variable of 'for' loops. For consistency, we'll allow mutation of these; variables in addition to other user-defined variables. This means that; these will both need memory locations. To start our transformation of Kaleidoscope, we'll change the; ``NamedValues`` map so that it maps to AllocaInst\* instead of Value\*. Once; we do this, the C++ compiler will tell us what parts of the code we need; to update:. .. code-block:: c++. static std::map<std::string, AllocaInst*> NamedValues;. Also, since we will need to create these allocas, we'll use a helper; function that ensures that the allocas are created in the entry block of; the function:. .. code-block:: c++. /// CreateEntryBlockAlloca - Create an alloca ins",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:11943,refactor,refactoring,11943,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['refactor'],['refactoring']
Modifiability,"usted by existing Security Group members to keep communications embargoed while still active. Nomination process; ------------------. Anyone who feels they meet these criteria can nominate themselves, or may be nominated by a third party such as an existing LLVM Security Group member. The nomination should state whether the nominee is nominated as an individual, researcher, or as a vendor contact. It should clearly describe the grounds for nomination. For the moment, nominations are generally proposed, discussed, and voted on using Phabricator. An `example nomination is available here`_. The use of Phabricator helps keep membership discussions open, transparent, and easily accessible to LLVM developers in many ways. If, for any reason, a fully-world-readable nomination seems inappropriate, you may `open a new issue`_, and a discussion can be had about the best way to approach nomination, given the constraints that individuals are under. Our recommended method of nomination may change as our `Discussion Medium`_ story evolves over time. Choosing new members; --------------------. If a nomination for LLVM Security Group membership is supported by a majority of existing LLVM Security Group members, then it carries within five business days unless an existing member of the Security Group objects. If an objection is raised, the LLVM Security Group members should discuss the matter and try to come to consensus; failing this, the nomination will succeed only by a two-thirds supermajority vote of the LLVM Security Group. Accepting membership; --------------------. Before new LLVM Security Group membership is finalized, the successful nominee should accept membership and agree to abide by this security policy, particularly `Privileges and Responsibilities of LLVM Security Group Members`_ below. Keeping Membership Current; --------------------------. * At least every six months, the LLVM Security Group applies the above criteria. The membership list is pruned accordingly.; * A",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:5996,evolve,evolves,5996,interpreter/llvm-project/llvm/docs/Security.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst,1,['evolve'],['evolves']
Modifiability,"ut does not match ""int *a"". Matcher<Type>parenTypeMatcher<ParenType>...; Matches ParenType nodes. Given; int (*ptr_to_array)[4];; int *array_of_ptrs[4];. varDecl(hasType(pointsTo(parenType()))) matches ptr_to_array but not; array_of_ptrs. Matcher<Type>pointerTypeMatcher<PointerType>...; Matches pointer types, but does not match Objective-C object pointer; types. Given; int *a;; int &b = *a;; int c = 5;. @interface Foo; @end; Foo *f;; pointerType(); matches ""int *a"", but does not match ""Foo *f"". Matcher<Type>rValueReferenceTypeMatcher<RValueReferenceType>...; Matches rvalue reference types. Given:; int *a;; int &b = *a;; int &&c = 1;; auto &d = b;; auto &&e = c;; auto &&f = 2;; int g = 5;. rValueReferenceType() matches the types of c and f. e is not; matched as it is deduced to int& by reference collapsing rules. Matcher<Type>recordTypeMatcher<RecordType>...; Matches record types (e.g. structs, classes). Given; class C {};; struct S {};. C c;; S s;. recordType() matches the type of the variable declarations of both c; and s. Matcher<Type>referenceTypeMatcher<ReferenceType>...; Matches both lvalue and rvalue reference types. Given; int *a;; int &b = *a;; int &&c = 1;; auto &d = b;; auto &&e = c;; auto &&f = 2;; int g = 5;. referenceType() matches the types of b, c, d, e, and f. Matcher<Type>substTemplateTypeParmTypeMatcher<SubstTemplateTypeParmType>...; Matches types that represent the result of substituting a type for a; template type parameter. Given; template <typename T>; void F(T t) {; int i = 1 + t;; }. substTemplateTypeParmType() matches the type of 't' but not '1'. Matcher<Type>tagTypeMatcher<TagType>...; Matches tag types (record and enum types). Given; enum E {};; class C {};. E e;; C c;. tagType() matches the type of the variable declarations of both e; and c. Matcher<Type>templateSpecializationTypeMatcher<TemplateSpecializationType>...; Matches template specialization types. Given; template <typename T>; class C { };. template class C<int>; // A; C<char> va",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html:51100,variab,variable,51100,interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,1,['variab'],['variable']
Modifiability,"ut(StringRef Scalar, void *Ctxt,; MyStringType &Value) {; Value.Str = Scalar.str();; return StringRef();; }; };. Mappings; ========. To be translated to or from a YAML mapping for your type T you must specialize; llvm::yaml::MappingTraits on T and implement the ""void mapping(IO &io, T&)""; method. If your native data structures use pointers to a class everywhere,; you can specialize on the class pointer. Examples:. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. // Example of struct Foo which is used by value; template <>; struct MappingTraits<Foo> {; static void mapping(IO &io, Foo &foo) {; io.mapOptional(""size"", foo.size);; ...; }; };. // Example of struct Bar which is natively always a pointer; template <>; struct MappingTraits<Bar*> {; static void mapping(IO &io, Bar *&bar) {; io.mapOptional(""size"", bar->size);; ...; }; };. There are circumstances where we want to allow the entire mapping to be; read as an enumeration. For example, say some configuration option; started as an enumeration. Then it got more complex so it is now a; mapping. But it is necessary to support the old configuration files.; In that case, add a function ``enumInput`` like for; ``ScalarEnumerationTraits::enumeration``. Examples:. .. code-block:: c++. struct FooBarEnum {; int Foo;; int Bar;; bool operator==(const FooBarEnum &R) const {; return Foo == R.Foo && Bar == R.Bar;; }; };. template <> struct MappingTraits<FooBarEnum> {; static void enumInput(IO &io, FooBarEnum &Val) {; io.enumCase(Val, ""OnlyFoo"", FooBarEnum({1, 0}));; io.enumCase(Val, ""OnlyBar"", FooBarEnum({0, 1}));; }; static void mapping(IO &io, FooBarEnum &Val) {; io.mapOptional(""Foo"", Val.Foo);; io.mapOptional(""Bar"", Val.Bar);; }; };. No Normalization; ----------------. The ``mapping()`` method is responsible, if needed, for normalizing and; denormalizing. In a simple case where the native data structure requires no; normalization, the mapping method just uses mapOptional() or mapRequired() to; bind th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:15763,config,configuration,15763,interpreter/llvm-project/llvm/docs/YamlIO.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst,1,['config'],['configuration']
Modifiability,"ute different code depending on; whether SafeStack is enabled. The macro ``__has_feature(safe_stack)`` can; be used for this purpose. .. code-block:: c. #if __has_feature(safe_stack); // code that builds only under SafeStack; #endif. ``__attribute__((no_sanitize(""safe-stack"")))``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Use ``__attribute__((no_sanitize(""safe-stack"")))`` on a function declaration; to specify that the safe stack instrumentation should not be applied to that; function, even if enabled globally (see ``-fsanitize=safe-stack`` flag). This; attribute may be required for functions that make assumptions about the; exact layout of their stack frames. All local variables in functions with this attribute will be stored on the safe; stack. The safe stack remains unprotected against memory errors when accessing; these variables, so extra care must be taken to manually ensure that all such; accesses are safe. Furthermore, the addresses of such local variables should; never be stored on the heap, as it would leak the location of the SafeStack. ``__builtin___get_unsafe_stack_ptr()``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. This builtin function returns current unsafe stack pointer of the current; thread. ``__builtin___get_unsafe_stack_bottom()``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. This builtin function returns a pointer to the bottom of the unsafe stack of the; current thread. ``__builtin___get_unsafe_stack_top()``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. This builtin function returns a pointer to the top of the unsafe stack of the; current thread. ``__builtin___get_unsafe_stack_start()``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Deprecated: This builtin function is an alias for; ``__builtin___get_unsafe_stack_bottom()``. Design; ======. Please refer to the `Code-Pointer Integrity <https://dslab.epfl.ch/research/cpi/>`__; project page for more information about the design of the SafeStack and its; related technologies. setjmp and exception handling;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SafeStack.rst:7294,variab,variables,7294,interpreter/llvm-project/clang/docs/SafeStack.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SafeStack.rst,1,['variab'],['variables']
Modifiability,"ute lifetime information for virtual registers (which are in SSA; form) and only has to track physical registers within a block. Before register; allocation, LLVM can assume that physical registers are only live within a; single basic block. This allows it to do a single, local analysis to resolve; physical register lifetimes within each basic block. If a physical register is; not register allocatable (e.g., a stack pointer or condition codes), it is not; tracked. Physical registers may be live in to or out of a function. Live in values are; typically arguments in registers. Live out values are typically return values in; registers. Live in values are marked as such, and are given a dummy ""defining""; instruction during live intervals analysis. If the last basic block of a; function is a ``return``, then it's marked as using all live out values in the; function. ``PHI`` nodes need to be handled specially, because the calculation of the live; variable information from a depth first traversal of the CFG of the function; won't guarantee that a virtual register used by the ``PHI`` node is defined; before it's used. When a ``PHI`` node is encountered, only the definition is; handled, because the uses will be handled in other basic blocks. For each ``PHI`` node of the current basic block, we simulate an assignment at; the end of the current basic block and traverse the successor basic blocks. If a; successor basic block has a ``PHI`` node and one of the ``PHI`` node's operands; is coming from the current basic block, then the variable is marked as *alive*; within the current basic block and all of its predecessor basic blocks, until; the basic block with the defining instruction is encountered. Live Intervals Analysis; ^^^^^^^^^^^^^^^^^^^^^^^. We now have the information available to perform the live intervals analysis and; build the live intervals themselves. We start off by numbering the basic blocks; and machine instructions. We then handle the ""live-in"" values. These a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:56372,variab,variable,56372,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['variab'],['variable']
Modifiability,"uted over several; processors and you can specify which entries to send to each processor.; With `MakeClass` the user has control over the event loop, with; `MakeSelector `the tree is in control of the event loop. ## Simple Analysis Using TTree::Draw. We will use the tree in `cernstaff.root` that was made by the macro in; `$ROOTSYS/tutorials/tree/staff.C`. First, open the file and lists its contents. ``` {.cpp}; root[] TFile f (""cernstaff.root""); root[] f.ls(); TFile** cernstaff.root; TFile* cernstaff.root; KEY: TTree T;1 staff data from ascii file; ```. We can see the **`TTree `**""`T`"" in the file. We will use it to; experiment with the **`TTree::Draw`** method, so let's create a pointer to it:. ``` {.cpp}; root[] TTree *MyTree = T; ```. Cling allows us to get simply the object by using it. Here we define a; pointer to a **`TTree`** object and assign it the value of ""`T`"", the; **`TTree`** in the file. Cling looks for an object named ""`T`"" in the; current ROOT file and returns it (this assumes that ""T"" has not; previously been used to declare a variable or function). In contrast, in compiled code, you can use:. ``` {.cpp}; TTree *MyTree;f.GetObject(""T"",MyTree);; ```. To show the different `Draw` options, we create a canvas with four; sub-pads. We will use one sub-pad for each `Draw` command. ``` {.cpp}; root[] TCanvas *myCanvas = new TCanvas(); root[] myCanvas->Divide(2,2); ```. We activate the first pad with the `TCanvas::cd` statement:. ``` {.cpp}; root[] myCanvas->cd(1); ```. We then draw the variable `Cost`:. ``` {.cpp}; root[] MyTree->Draw(""C; ```. As you can see, the last call `TTree::Draw` has only one parameter. It; is a string containing the leaf name. A histogram is automatically; created as a result of a `TTree::Draw`. The style of the histogram is; inherited from the **`TTree`** attributes and the current style; (***`gStyle`***) is ignored. The **`TTree`** gets its attributes from; the current **`TStyle`** at the time it was created. You can call the; m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:69406,variab,variable,69406,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['variab'],['variable']
Modifiability,"uto.; `freetype` finds `libpng` and `libbzip2` on the system and builds extra; modules. Then attempting to link against `freetype` one would need to link; `-lpng -lbzip2` explicitly otherwise linking will returns in undefined; references. Otherwise we would need to check for `libpng` and `libbzip2` on the system; and adjust `FREETYPE_LIBRARIES` to include `-lpng` and `-lbzip2`.; The current solution goes for the minimal configuration. The original request for; this update was posted [here](https://sft.its.cern.ch/jira/browse/ROOT-7631). ## 3D Graphics Libraries. ## Geometry Libraries. ## Database Libraries. ## Networking Libraries. ### THttpServer. Support of POST HTTP requests. For example, ROOT objects can be send with POST request and used as arguments of; objects method execution in exe.bin and exe.json requests. Request and response HTTP headers are now directly accessible in THttpCallArg class. When command is registered with THttpServer::RegisterCommand() method,; one could configure additional arguments which should be submitted when; command is executed with cmd.json requests. Introduce restriction rules for objects access with THttpServer::Restrict() method.; Up to now general read-only flag was applied - either; everything read-only or everything is fully accessible.; Now one could restrict access to different parts of; objects hierarchy or even fully 'hide' them from the client.; Restriction based on user account name, which is applied; when htdigest authentication is configured.; One also able to allow execution of selected methods. Implement multi.bin and multi.json requests.; One could request many items with single HTTP request.; Let optimize communication between server and client. With *SNIFF* tag in ClassDef() comments one could expose different properties,; which than exposed by the TRootSniffer to the client with h.json requests.; Such possibility ease implementation of client-side code for custom classes. Allow to bind http port with loopback ad",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md:19047,config,configure,19047,README/ReleaseNotes/v606/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v606/index.md,1,['config'],['configure']
Modifiability,"utomaticStorageDuration()); void f() {; int x;; static int y;; thread_local int z;; }; int a;. Matcher<VarDecl>hasGlobalStorage; Matches a variable declaration that does not have local storage. Example matches y and z (matcher = varDecl(hasGlobalStorage()); void f() {; int x;; static int y;; }; int z;. Matcher<VarDecl>hasLocalStorage; Matches a variable declaration that has function scope and is a; non-static local variable. Example matches x (matcher = varDecl(hasLocalStorage()); void f() {; int x;; static int y;; }; int z;. Matcher<VarDecl>hasStaticStorageDuration; Matches a variable declaration that has static storage duration.; It includes the variable declared at namespace scope and those declared; with ""static"" and ""extern"" storage class specifiers. void f() {; int x;; static int y;; thread_local int z;; }; int a;; static int b;; extern int c;; varDecl(hasStaticStorageDuration()); matches the function declaration y, a, b and c. Matcher<VarDecl>hasThreadStorageDuration; Matches a variable declaration that has thread storage duration. Example matches z, but not x, z, or a.; (matcher = varDecl(hasThreadStorageDuration()); void f() {; int x;; static int y;; thread_local int z;; }; int a;. Matcher<VarDecl>isConstexpr; Matches constexpr variable and function declarations,; and if constexpr. Given:; constexpr int foo = 42;; constexpr int bar();; void baz() { if constexpr(1 > 0) {} }; varDecl(isConstexpr()); matches the declaration of foo.; functionDecl(isConstexpr()); matches the declaration of bar.; ifStmt(isConstexpr()); matches the if statement in baz. Matcher<VarDecl>isConstinit; Matches constinit variable declarations. Given:; constinit int foo = 42;; constinit const char* bar = ""bar"";; int baz = 42;; [[clang::require_constant_initialization]] int xyz = 42;; varDecl(isConstinit()); matches the declaration of `foo` and `bar`, but not `baz` and `xyz`. Matcher<VarDecl>isDefinition; Matches if a declaration has a body attached. Example matches A, va, fa; class A {};;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html:125280,variab,variable,125280,interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,1,['variab'],['variable']
Modifiability,"utomatically configures ssh tunnel between local and remote nodes, one the remote node; unix socket with strict 0700 mode is used. When ROOT running on remote node wants to display; new web widget, script will automatically start web browser on local node with appropriate URL,; accessing widget via configured ssh tunnel. ## Montecarlo Libraries. ## PROOF Libraries. ## Language Bindings. ## JavaScript ROOT. - Major JSROOT upgrade to version 7, using ES6 modules and classes. ## Tutorials. - Several new tutorials have been added in both C++ and Python in the `tutorial/tmva` directory.; Tutorials like `TMVA_Higgs_Classification.py` shows the new pythonizations available in TMVA and; new `TMVA_SOFIE_...` tutorials show th eusage of SOFIE in both C++ or Python. ## Class Reference Guide. ## Build, Configuration and Testing Infrastructure. - Building external applications that use ROOT oftentimes fail if there is a mismatch in the C++ standard between ROOT and the application. As of v6.28, suchs builds will issue a warning if the C++ standard does not match ROOT's, i.e. if there is a mismatch in the value of the `__cplusplus` preprocessor macro w.r.t. when ROOT was configured. ## PyROOT. - A `.rootlogon.py` file will be searched both in the current working directory and in the user's home directory. This; file is the Python equivalent of `rootlogon.C` and can be used to tweak ROOT settings when using PyROOT.; - A new pythonization for `TFile` now enables its usage as a Python context manager:; ```python; from ROOT import TFile; with TFile(""file1.root"", ""recreate"") as outfile:; hout = ROOT.TH1F(...); outfile.WriteObject(hout, ""myhisto""); ```; - A new pythonization for `TDirectory::TContext` now enables its usage as a Python context manager:; ```python; with TDirectory.TContext():; # Open some file here; file = ROOT.TFile(...); # Retrieve contents from the file; histo = file.Get(""myhisto""); ; # After the 'with' statement, the current directory is restored to ROOT.gROOT; ```; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md:33592,config,configured,33592,README/ReleaseNotes/v628/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md,1,['config'],['configured']
Modifiability,"uzzer,; clang-objc-fuzzer, and clang-proto-fuzzer. All use libFuzzer to generate inputs; to clang via coverage-guided mutation. The three utilities differ, however, in how they structure inputs to Clang.; clang-fuzzer makes no attempt to generate valid C++ programs and is therefore; primarily useful for stressing the surface layers of Clang (i.e. lexer, parser). clang-objc-fuzzer is similar but for Objective-C: it makes no attempt to; generate a valid Objective-C program. clang-proto-fuzzer uses a protobuf class to describe a subset of the C++; language and then uses libprotobuf-mutator to mutate instantiations of that; class, producing valid C++ programs in the process. As a result,; clang-proto-fuzzer is better at stressing deeper layers of Clang and LLVM. Some of the fuzzers have example corpuses inside the corpus_examples directory. ===================================; Building clang-fuzzer; ===================================; Within your LLVM build directory, run CMake with the following variable; definitions:; - CMAKE_C_COMPILER=clang; - CMAKE_CXX_COMPILER=clang++; - LLVM_USE_SANITIZE_COVERAGE=YES; - LLVM_USE_SANITIZER=Address. Then build the clang-fuzzer target. Example:; cd $LLVM_SOURCE_DIR; mkdir build && cd build; cmake .. -GNinja -DCMAKE_C_COMPILER=clang -DCMAKE_CXX_COMPILER=clang++ \; -DLLVM_USE_SANITIZE_COVERAGE=YES -DLLVM_USE_SANITIZER=Address; ninja clang-fuzzer. ======================; Running clang-fuzzer; ======================; bin/clang-fuzzer CORPUS_DIR. ===================================; Building clang-objc-fuzzer; ===================================; Within your LLVM build directory, run CMake with the following variable; definitions:; - CMAKE_C_COMPILER=clang; - CMAKE_CXX_COMPILER=clang++; - LLVM_USE_SANITIZE_COVERAGE=YES; - LLVM_USE_SANITIZER=Address. Then build the clang-objc-fuzzer target. Example:; cd $LLVM_SOURCE_DIR; mkdir build && cd build; cmake .. -GNinja -DCMAKE_C_COMPILER=clang -DCMAKE_CXX_COMPILER=clang++ \; -DLLVM_USE_SANITIZE",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/clang-fuzzer/README.txt:1075,variab,variable,1075,interpreter/llvm-project/clang/tools/clang-fuzzer/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/tools/clang-fuzzer/README.txt,1,['variab'],['variable']
Modifiability,"v4i32``,; operate on a per-element basis and the element order is not affected. .. _int_ctpop:. '``llvm.ctpop.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use llvm.ctpop on any integer; bit width, or on any vector with integer elements. Not all targets; support all bit widths or vector types, however. ::. declare i8 @llvm.ctpop.i8(i8 <src>); declare i16 @llvm.ctpop.i16(i16 <src>); declare i32 @llvm.ctpop.i32(i32 <src>); declare i64 @llvm.ctpop.i64(i64 <src>); declare i256 @llvm.ctpop.i256(i256 <src>); declare <2 x i32> @llvm.ctpop.v2i32(<2 x i32> <src>). Overview:; """""""""""""""""". The '``llvm.ctpop``' family of intrinsics counts the number of bits set; in a value. Arguments:; """""""""""""""""""". The only argument is the value to be counted. The argument may be of any; integer type, or a vector with integer elements. The return type must; match the argument type. Semantics:; """""""""""""""""""". The '``llvm.ctpop``' intrinsic counts the 1's in a variable, or within; each element of a vector. .. _int_ctlz:. '``llvm.ctlz.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.ctlz`` on any; integer bit width, or any vector whose elements are integers. Not all; targets support all bit widths or vector types, however. ::. declare i8 @llvm.ctlz.i8 (i8 <src>, i1 <is_zero_poison>); declare <2 x i37> @llvm.ctlz.v2i37(<2 x i37> <src>, i1 <is_zero_poison>). Overview:; """""""""""""""""". The '``llvm.ctlz``' family of intrinsic functions counts the number of; leading zeros in a variable. Arguments:; """""""""""""""""""". The first argument is the value to be counted. This argument may be of; any integer type, or a vector with integer element type. The return; type must match the first argument type. The second argument is a constant flag that indicates whether the intrinsic; returns a valid result if the first argument is zero. If the first; argument is zero and the second argument is true, the result ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:593365,variab,variable,593365,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variable']
Modifiability,"vailable to JIT'd code), to dynamic code generation based on symbol; names, and even lazy compilation. One immediate benefit of the symbol resolution rule is that we can now extend; the language by writing arbitrary C++ code to implement operations. For example,; if we add:. .. code-block:: c++. #ifdef _WIN32; #define DLLEXPORT __declspec(dllexport); #else; #define DLLEXPORT; #endif. /// putchard - putchar that takes a double and returns 0.; extern ""C"" DLLEXPORT double putchard(double X) {; fputc((char)X, stderr);; return 0;; }. Note, that for Windows we need to actually export the functions because; the dynamic symbol loader will use ``GetProcAddress`` to find the symbols. Now we can produce simple output to the console by using things like:; ""``extern putchard(x); putchard(120);``"", which prints a lowercase 'x'; on the console (120 is the ASCII code for 'x'). Similar code could be; used to implement file I/O, console input, and many other capabilities; in Kaleidoscope. This completes the JIT and optimizer chapter of the Kaleidoscope; tutorial. At this point, we can compile a non-Turing-complete; programming language, optimize and JIT compile it in a user-driven way.; Next up we'll look into `extending the language with control flow; constructs <LangImpl05.html>`_, tackling some interesting LLVM IR issues; along the way. Full Code Listing; =================. Here is the complete code listing for our running example, enhanced with; the LLVM JIT and optimizer. To build this example, use:. .. code-block:: bash. # Compile; clang++ -g toy.cpp `llvm-config --cxxflags --ldflags --system-libs --libs core orcjit native` -O3 -o toy; # Run; ./toy. If you are compiling this on Linux, make sure to add the ""-rdynamic""; option as well. This makes sure that the external functions are resolved; properly at runtime. Here is the code:. .. literalinclude:: ../../../examples/Kaleidoscope/Chapter4/toy.cpp; :language: c++. `Next: Extending the language: control flow <LangImpl05.html>`_. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst:24826,extend,extending,24826,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,3,"['config', 'enhance', 'extend']","['config', 'enhanced', 'extending']"
Modifiability,"valid ``using`` is the last method; * Filter -fno-plt (coming from anaconda builds; not understood by Cling); * Fixed memory leak in generic base ``__str__``. 2021-01-05: 1.9.2; -----------------. * Added ``cppyy.types`` module for exposing cppyy builtin types; * Improve numpy integration with custom ``__array__`` methods; * Allow operator overload resolution mixing class and global methods; * Installation fixes for PyPy when using pip. 2020-11-23: 1.9.1; -----------------. * Fix custom installer in pip sdist. 2020-11-22: 1.9.0; -----------------. * In-tree build resolving build/install order for PyPy with pyproject.toml; * ``std::string`` not converterd to ``str`` on function returns; * Cover more use cases where C string memory can be managed; * Automatic memory management of converted python functions; * Added pyinstaller hooks (https://stackoverflow.com/questions/64406727); * Support for enums in pseudo-constructors of aggregates; * Fixes for overloaded/split-access protected members in cross-inheritance; * Support for deep, mixed, hierarchies for multi-cross-inheritance; * Added tp_iter method to low level views. 2020-11-06: 1.8.6; -----------------. * Fix preprocessor macro of CPyCppyy header for Windows/MSVC. 2020-10-31: 1.8.5; -----------------. * Fix leaks when using vector iterators on Py3/Linux. 2020-10-10: 1.8.4; -----------------. * ``std::string`` globals/data members no longer automatically converted to ``str``; * New methods for std::string to allow ``str`` interchangability; * Added a ``decode`` method to ``std::string``; * Add pythonized ``__contains__`` to ``std::set``; * Fix constructor generation for aggregates with static data; * Fix performance bug when using implicit conversions; * Fix memory overwrite when parsing during sorting of methods; * PyPy pip install again falls back to setup.py install. 2020-09-21: 1.8.3; -----------------. * Add initializer constructors for PODs and aggregates; * Use actual underlying type for enums, where possible",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:9332,inherit,inheritance,9332,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,2,['inherit'],['inheritance']
Modifiability,"valuates to '{{2, 3, 4}} == {0, 3, 4}'}}}. The intent is to allow the delimeter to be wider than the longest `{` or `}`; brace sequence in the content, so that if your expected text contains `{{{`; (three braces) it may be delimited with `{{{{` (four braces), and so on. Regex matching mode may be selected by appending ``-re`` to the diagnostic type; and including regexes wrapped in double curly braces (`{{` and `}}`) in the; directive, such as:. .. code-block:: text. expected-error-re {{format specifies type 'wchar_t **' (aka '{{.+}}')}}. Examples matching error: ""variable has incomplete type 'struct s'"". .. code-block:: c++. // expected-error {{variable has incomplete type 'struct s'}}; // expected-error {{variable has incomplete type}}; // expected-error {{{variable has incomplete type}}}; // expected-error {{{{variable has incomplete type}}}}. // expected-error-re {{variable has type 'struct {{.}}'}}; // expected-error-re {{variable has type 'struct {{.*}}'}}; // expected-error-re {{variable has type 'struct {{(.*)}}'}}; // expected-error-re {{variable has type 'struct{{[[:space:]](.*)}}'}}. Feature Test Macros; ===================; Clang implements several ways to test whether a feature is supported or not.; Some of these feature tests are standardized, like ``__has_cpp_attribute`` or; ``__cpp_lambdas``, while others are Clang extensions, like ``__has_builtin``.; The common theme among all the various feature tests is that they are a utility; to tell users that we think a particular feature is complete. However,; completeness is a difficult property to define because features may still have; lingering bugs, may only work on some targets, etc. We use the following; criteria when deciding whether to expose a feature test macro (or particular; result value for the feature test):. * Are there known issues where we reject valid code that should be accepted?; * Are there known issues where we accept invalid code that should be rejected?; * Are there known crashes, fail",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:162529,variab,variable,162529,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['variab'],['variable']
Modifiability,"value for the null and also for the alternate using the Asimov data set. In this; differs form the ProfileLikelihoodCalculator which computes only the p-values for the null hypothesis.; The Asimov data set is generated with the utility function AsymptoticCalculator::MakeAsimovData and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calculator in the HypoTestInverter class. It can then plugged in the HypoTestInverter for computing asymptotic CLs and CLs+b; limits. In this way the limits will be computed by just performing a fit for each test parameter value and without; generating any toys. . The class can be used via the StandardHypothesisTest.C tutorial passing a value of 2 for the; calculator type. . RooStats Utils. Add a utility function (from G. Petrucciani), RooStats::MakeNuisancePdf, which given a model configuration (or the global pdf and the; observables), factorizes from the model pdf the constraint probability density functions for the nuisance parameters; and builds a global nuisance pdf. This function can then be used in the HybridCalculator or in the BayesianCalculator; with the option ""TOYMC"".; . HypotestInverter and HypoTestInverterResult. Several improvements and bug fixes in merging results and in computing the observed and expected limits.; Provide support now for using the AsympoticCalculator. MCMCCalculator. Add now possibility to store in the chain only the parameter of interested via the method MCMCCalculator::SetChainParameters. This saves memory in case of models with a; large number of nuisance parameters. . Test Statistics classes. Make a more robust evaluation of the ProfileLikelihoodTestStat. Use RooMinimizer and give possibility to use; different minimizer, via ProfileLikelihoodTestStat::SetMinimizer. The print level of minimization can also be; controlled via ProfileLikelihoodTestStat::SetPrintLevel. Activate also the RooFit ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:8171,config,configuration,8171,roofit/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html,1,['config'],['configuration']
Modifiability,"value of `g`.; }. The requirement to annotate all pointers with explicit bounds information could; present a significant adoption burden. To tackle this issue, the model; incorporates the concept of a ""wide pointer"" (a.k.a. fat pointer) – a larger; pointer that carries bounds information alongside the pointer value. Utilizing; wide pointers can potentially reduce the adoption burden, as it contains bounds; information internally and eliminates the need for explicit bounds annotations.; However, wide pointers differ from standard C pointers in their data layout,; which may result in incompatibilities with the application binary interface; (ABI). Breaking the ABI complicates interoperability with external code that has; not adopted the same programming model. ``-fbounds-safety`` harmonizes the wide pointer and the bounds annotation; approaches to reduce the adoption burden while maintaining the ABI. In this; model, local variables of pointer type are implicitly treated as wide pointers,; allowing them to carry bounds information without requiring explicit bounds; annotations. Please note that this approach doesn't apply to function parameters; which are considered ABI-visible. As local variables are typically hidden from; the ABI, this approach has a marginal impact on it. In addition,; ``-fbounds-safety`` employs compile-time restrictions to prevent implicit wide; pointers from silently breaking the ABI (see `ABI implications of default bounds; annotations`_). Pointers associated with any other variables, including function; parameters, are treated as single object pointers (i.e., ``__single``), ensuring; that they always have the tightest bounds by default and offering a strong; bounds safety guarantee. By implementing default bounds annotations based on ABI visibility, a; considerable portion of C code can operate without modifications within this; programming model, reducing the adoption burden. The rest of the section will discuss individual bounds annotations an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst:5915,variab,variables,5915,interpreter/llvm-project/clang/docs/BoundsSafety.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafety.rst,1,['variab'],['variables']
Modifiability,"vant CMake Options; ======================. This section provides documentation of the CMake options that are intended to; help construct distributions. This is not an exhaustive list, and many; additional options are documented in the :doc:`CMake` page. Some key options; that are already documented include: *LLVM_TARGETS_TO_BUILD*, *LLVM_ENABLE_PROJECTS*,; *LLVM_ENABLE_RUNTIMES*, *LLVM_BUILD_LLVM_DYLIB*, and *LLVM_LINK_LLVM_DYLIB*. **LLVM_ENABLE_RUNTIMES**:STRING; When building a distribution that includes LLVM runtime projects (i.e. libcxx,; compiler-rt, libcxxabi, libunwind...), it is important to build those projects; with the just-built compiler. **LLVM_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of LLVM build system; components to install. All LLVM-based tools are components, as well as most; of the libraries and runtimes. Component names match the names of the build; system targets. **LLVM_DISTRIBUTIONS**:STRING; This variable can be set to a semi-colon separated list of distributions. See; the :ref:`Multi-distribution configurations` section above for details on this; and other CMake variables to configure multiple distributions. **LLVM_RUNTIME_DISTRIBUTION_COMPONENTS**:STRING; This variable can be set to a semi-colon separated list of runtime library; components. This is used in conjunction with *LLVM_ENABLE_RUNTIMES* to specify; components of runtime libraries that you want to include in your distribution.; Just like with *LLVM_DISTRIBUTION_COMPONENTS*, component names match the names; of the build system targets. **LLVM_DYLIB_COMPONENTS**:STRING; This variable can be set to a semi-colon separated name of LLVM library; components. LLVM library components are either library names with the LLVM; prefix removed (i.e. Support, Demangle...), LLVM target names, or special; purpose component names. The special purpose component names are:. #. ``all`` - All LLVM available component libraries; #. ``Native`` - The LLVM ta",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:11791,variab,variable,11791,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,1,['variab'],['variable']
Modifiability,"var/in. With this in place, we can define the parser pieces. The first thing we; do is add it as a primary expression:. .. code-block:: c++. /// primary; /// ::= identifierexpr; /// ::= numberexpr; /// ::= parenexpr; /// ::= ifexpr; /// ::= forexpr; /// ::= varexpr; static std::unique_ptr<ExprAST> ParsePrimary() {; switch (CurTok) {; default:; return LogError(""unknown token when expecting an expression"");; case tok_identifier:; return ParseIdentifierExpr();; case tok_number:; return ParseNumberExpr();; case '(':; return ParseParenExpr();; case tok_if:; return ParseIfExpr();; case tok_for:; return ParseForExpr();; case tok_var:; return ParseVarExpr();; }; }. Next we define ParseVarExpr:. .. code-block:: c++. /// varexpr ::= 'var' identifier ('=' expression)?; // (',' identifier ('=' expression)?)* 'in' expression; static std::unique_ptr<ExprAST> ParseVarExpr() {; getNextToken(); // eat the var. std::vector<std::pair<std::string, std::unique_ptr<ExprAST>>> VarNames;. // At least one variable name is required.; if (CurTok != tok_identifier); return LogError(""expected identifier after var"");. The first part of this code parses the list of identifier/expr pairs; into the local ``VarNames`` vector. .. code-block:: c++. while (true) {; std::string Name = IdentifierStr;; getNextToken(); // eat identifier. // Read the optional initializer.; std::unique_ptr<ExprAST> Init;; if (CurTok == '=') {; getNextToken(); // eat the '='. Init = ParseExpression();; if (!Init) return nullptr;; }. VarNames.push_back(std::make_pair(Name, std::move(Init)));. // End of var list, exit loop.; if (CurTok != ',') break;; getNextToken(); // eat the ','. if (CurTok != tok_identifier); return LogError(""expected identifier list after var"");; }. Once all the variables are parsed, we then parse the body and create the; AST node:. .. code-block:: c++. // At this point, we have to have 'in'.; if (CurTok != tok_in); return LogError(""expected 'in' keyword after 'var'"");; getNextToken(); // eat 'in'. auto Bod",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:25311,variab,variable,25311,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['variab'],['variable']
Modifiability,"variable is defined in the CMake configuration, we're; # skipping the download of the repository and use the passed directory.; if (DEFINED CLAD_SOURCE_DIR); list(APPEND _clad_extra_settings DOWNLOAD_COMMAND """"); list(APPEND _clad_extra_settings SOURCE_DIR ${CLAD_SOURCE_DIR}); endif(). #list(APPEND _clad_patches_list ""patch1.patch"" ""patch2.patch""); #set(_clad_patch_command; # ${CMAKE_COMMAND} -E copy_directory; # ${CMAKE_SOURCE_DIR}/interpreter/cling/tools/plugins/clad/patches <SOURCE_DIR>; # && git checkout <SOURCE_DIR>; # && git apply --ignore-space-change --ignore-whitespace ${_clad_patches_list}; # ). ExternalProject_Add(; clad; GIT_REPOSITORY https://github.com/vgvassilev/clad.git; GIT_TAG v1.7; UPDATE_COMMAND """"; PATCH_COMMAND ${_clad_patch_command}; CMAKE_ARGS -G ${CMAKE_GENERATOR}; -DCMAKE_BUILD_TYPE=${CMAKE_BUILD_TYPE}; -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER}; -DCMAKE_C_FLAGS=${CMAKE_C_FLAGS}; -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER}; -DCMAKE_CXX_FLAGS=${CLAD_CXX_FLAGS}; -DCMAKE_INSTALL_PREFIX=${clad_install_dir}/plugins; -DLLVM_DIR=${LLVM_BINARY_DIR}; -DCLANG_INCLUDE_DIRS=${CLANG_INCLUDE_DIRS}; ${_clad_extra_cmake_args}; # FIXME; # Building with 1 core is a temporary workaround for #16654 and has to be ; # there until the behaviour of the clad build on ubuntu 24.10 is understood.; # The performance penalty in the build is negligible.; BUILD_COMMAND ${CMAKE_COMMAND} --build . ${EXTRA_BUILD_ARGS} -j 1; INSTALL_COMMAND ${CMAKE_COMMAND} --build . ${EXTRA_BUILD_ARGS} -j 1 --target install; BUILD_BYPRODUCTS ${CLAD_BYPRODUCTS}; ${_clad_extra_settings}; # We need the target clangBasic to be built before building clad. However, we; # support building prebuilt clang and adding clangBasic breaks this case.; # Delegate the dependency resolution to the clingInterpreter target (which; # will always depend on clangBasic).; DEPENDS clingInterpreter; ). # Register cladPlugin, cladDifferentiator; foreach (lib cladPlugin cladDifferentiator); add_library(${lib} IMPORTED STATI",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/plugins/clad/CMakeLists.txt:3388,plugin,plugins,3388,interpreter/cling/tools/plugins/clad/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/plugins/clad/CMakeLists.txt,1,['plugin'],['plugins']
Modifiability,"variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help message. CreateMVAPdfs No False − Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False − Events with negative weights are ignored in the training (but are included for testing and performance evaluation). VolumeRangeMode No Adaptive Unscaled, MinMax, RMS, Adaptive, kNN Method to determine volume size. KernelEstimator No Box Box, Sphere, Teepee, Gauss, Sinc3, Sinc5, Sinc7, Sinc9, Sinc11, Lanczos2, Lanczos3, Lanczos5, Lanczos8, Trim Kernel estimation function. DeltaFrac No 3 − nEventsMin/Max for minmax and rms volume range. NEventsMin No 100 − nEventsMin for adaptive volume range. NEventsMax No 200 − nEventsMax for adaptive volume range. MaxVIterations No 150 − MaxVIterations for adaptive volume range. InitialScale No 0.99 − InitialScale for adaptive volume range. GaussSigma No 0.1 − Width (wrt volume size) of Gaussian kernel estimator. NormTree No False − Normalize binary search tree. Configuration options for MVA method :. Configuration options reference for MVA method: FDA. Option Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help mes",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:4783,adapt,adaptive,4783,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,1,['adapt'],['adaptive']
Modifiability,"variables mimics a measurement of an electrical resistance while; varying pressure and temperature. Imagine your task now consists in finding the relations among the; variables -- of course without knowing the code used to generate them.; You will see that the possibilities of the `NTuple` class enable you to; perform this analysis task. Open the ROOT file (`cond_data.root`); written by the macro above in an interactive session and use a; `TBrowser` to interactively inspect it:. ``` {.cpp}; root[0] TBrowser b; ```; You find the columns of your n-tuple written as *leafs*. Simply clicking; on them you can obtain histograms of the variables!. Next, try the following commands at the shell prompt and in the; interactive ROOT shell, respectively:. ``` {.cpp}; > root conductivity_experiment.root; Attaching file conductivity_experiment.root as _file0...; root [0] cond_data->Draw(""Current:Potential""); ```. You just produced a correlation plot with one single line of code!. Try to extend the syntax typing for example. ``` {.cpp}; root [1] cond_data->Draw(""Current:Potential"",""Temperature<270""); ```. What do you obtain ?. Now try. ``` {.cpp}; root [2] cond_data->Draw(""Current/Potential:Temperature""); ```. It should have become clear from these examples how to navigate in such; a multi-dimensional space of variables and unveil relations between; variables using n-tuples. ### Reading N-tuples. For completeness, you find here a small macro to read the data back from; a ROOT n-tuple. ``` {.cpp}; @ROOT_INCLUDE_FILE macros/read_ntuple_from_file.C; ```. The macro shows the easiest way of accessing the content of a n-tuple:; after loading the n-tuple, its branches are assigned to variables and; `GetEntry(long)` automatically fills them with the content for a; specific row. By doing so, the logic for reading the n-tuple and the; code to process it can be split and the source code remains clear. ### Storing Arbitrary N-tuples ###. It is also possible to write n-tuples of arbitrary type by",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md:3576,extend,extend,3576,documentation/primer/filio.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md,1,['extend'],['extend']
Modifiability,"vas = new TCanvas(""canvas"");; TH1F* histo = new TH1F(""histo"",""test 1"",10,0.,10.);; histo->SetFillColor(2);; histo->Fill(2.);; histo->Draw();; canvas->Print(""plots.pdf("",""Title:One bin filled"");; histo->Fill(4.);; histo->Draw();; canvas->Print(""plots.pdf"",""Title:Two bins filled"");; histo->Fill(6.);; histo->Draw();; canvas->Print(""plots.pdf"",""Title:Three bins filled"");; histo->Fill(8.);; histo->Draw();; canvas->Print(""plots.pdf"",""Title:Four bins filled"");; histo->Fill(8.);; histo->Draw();; canvas->Print(""plots.pdf)"",""Title:The fourth bin content is 2"");; }; ```. Each character string following the keyword ""Title:"" makes a new entry; in the table of contents. ## Create or Modify a Style. All objects that can be drawn in a pad inherit from one or more; attribute classes like **`TAttLine`**, **`TAttFill`**, **`TAttText`**,; **`TAttMarker`**. When objects are created, their default attributes are; taken from the current style. The current style is an object of the; class **`TStyle`** and can be referenced via the global variable; ***`gStyle`*** (in `TStyle.h`). See the class **`TStyle`** for a; complete list of the attributes that can be set in one style. ROOT provides several styles called:. - ""`Default`"" - the default style. - ""`Plain`"" - the simple style (black and white). - ""`Bold`"" - bolder lines. - ""`Video`"" - suitable for html output or screen viewing. The ""`Default`"" style is created by:. ``` {.cpp}; TStyle *default = new TStyle(""Default"",""Default Style"");; ```. The ""`Plain`"" style can be used if you want to get a ""conventional""; PostScript output or if you are working on a monochrome display. The; following example shows how to create it. ``` {.cpp}; TStyle *plain = new TStyle(""Plain"",; ""Plain Style(no colors/fill areas)"");; plain->SetCanvasBorderMode(0);; plain->SetPadBorderMode(0);; plain->SetPadColor(0);; plain->SetCanvasColor(0);; plain->SetTitleColor(0);; plain->SetStatColor(0);; ```. You can set the current style by:. ``` {.cpp}; gROOT->SetStyle(style_name);",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:101684,variab,variable,101684,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['variab'],['variable']
Modifiability,"vate:; protected:; };. * ``ELAAMS_Leave`` (in configuration: ``Leave``); Keep existing empty lines after access modifiers.; MaxEmptyLinesToKeep is applied instead. * ``ELAAMS_Always`` (in configuration: ``Always``); Always add empty line after access modifiers if there are none.; MaxEmptyLinesToKeep is applied also. .. code-block:: c++. struct foo {; private:. int i;; protected:. int j;; /* comment */; public:. foo() {}; private:. protected:. };. .. _EmptyLineBeforeAccessModifier:. **EmptyLineBeforeAccessModifier** (``EmptyLineBeforeAccessModifierStyle``) :versionbadge:`clang-format 12` :ref:`¶ <EmptyLineBeforeAccessModifier>`; Defines in which cases to put empty line before access modifiers. Possible values:. * ``ELBAMS_Never`` (in configuration: ``Never``); Remove all empty lines before access modifiers. .. code-block:: c++. struct foo {; private:; int i;; protected:; int j;; /* comment */; public:; foo() {}; private:; protected:; };. * ``ELBAMS_Leave`` (in configuration: ``Leave``); Keep existing empty lines before access modifiers. * ``ELBAMS_LogicalBlock`` (in configuration: ``LogicalBlock``); Add empty line only when access modifier starts a new logical block.; Logical block is a group of one or more member fields or functions. .. code-block:: c++. struct foo {; private:; int i;. protected:; int j;; /* comment */; public:; foo() {}. private:; protected:; };. * ``ELBAMS_Always`` (in configuration: ``Always``); Always add empty line before access modifiers unless access modifier; is at the start of struct or class definition. .. code-block:: c++. struct foo {; private:; int i;. protected:; int j;; /* comment */. public:; foo() {}. private:. protected:; };. .. _ExperimentalAutoDetectBinPacking:. **ExperimentalAutoDetectBinPacking** (``Boolean``) :versionbadge:`clang-format 3.7` :ref:`¶ <ExperimentalAutoDetectBinPacking>`; If ``true``, clang-format detects whether function calls and; definitions are formatted with one parameter per line. Each call can be bin-packed",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:62106,config,configuration,62106,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['config'],['configuration']
Modifiability,"ve 'xpd.putenv' in the; xrootd config file.Input dataIntroduce the; concept of 'input data': these are objects that are distributed in; optimal way to the workers, which are available via the input list, but; which are not saved in the TQueryResult object. These are meant for big; objects whic can create a big overload when distributed via the; standard input list (which should mostly be used for job control; parameters).  To add an input-data object just use; TProof::AddInputData(TObject *); if the input-data objects are in a; file you can use TProof::SetInputDataFile(const char *file); the final; set of input-data objects is assembled from the objects added via; AddInputData and those found in the file defined bySetInputDataFile.  . Improvements:. More; complete set of tests in test/stressProof . To run with PROOF-Lite pass; the argument 'lite' as master URL, e.g. './stressProof lite'.Possibility; to control on the client via rc variable the location of the sandbox,; package directory, cache and dataset directory (the latters two only; for PROOF-Lite); the variable names are 'Proof.Sandbox', ; 'Proof.PackageDir', 'Proof.CacheDir' and 'Proof.DataSetDir'. The default location of the sandbox has been changed from ""~/proof"" to ""~/.proof"" to avoid interferences with possible users' working areas.XrdProofd plug-in. Overall refactorization for easier; maintainance and improved solidity; Improved format of printout messages: all information; messages contain now the tag 'xpd-I' and all error messages the; tag 'xpd-E', so that they can easily be grepped out from the; log file.; . Log sending. Implement selective sending of logs from workers to master to avoid duplicating; too many text lines on the master log. Logs are now sent only after Exec, Print; requests and in case an error (level >= kError) occured. Of course, the full; logs can always be retrieved via TProofMgr::GetSessionLogs; . Log retrieval:. for 'grep' operations, use the system 'grep' command; via 'popen'; ins",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html:4093,variab,variable,4093,proof/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html,3,"['sandbox', 'variab']","['sandbox', 'variable']"
Modifiability,"ve a graphic display, which creates,; fills, and saves histograms and trees, only needs to link the core; libraries (`libCore`, `libRIO`), `libHist` and `libTree`.; If ROOT needs access to other libraries, it loads them dynamically.; For example, if the **`TreeViewer`** is used, `libTreePlayer` and all; libraries `libTreePlayer` depends on are loaded also. The dependent; libraries are shown in the ROOT reference guide's library dependency; graph. The difference between reference guide `libHist` and; `libHistPainter` is that the former needs to be explicitly linked and; the latter will be loaded automatically at runtime when ROOT needs it,; by means of the Plugin Manager. plugin manager. In the Figure 1-2, the libraries represented by green boxes outside of; the core are loaded via the plugin manager plugin manager or; equivalent techniques, while the white ones are not. Of course, if one; wants to access a plugin library directly, it has to be explicitly; linked. An example of a plugin library is `libMinuit`. To create and; fill histograms you need to link `libHist.so`. If the code has a call; to fit the histogram, the ""fitter"" will dynamically load libMinuit if; it is not yet loaded. #### Plugins: Runtime Library Dependencies for Linking. plugin manager The Plugin Manager **`TPluginManager`** allows; postponing library dependencies to runtime: a plugin library will only; be loaded when it is needed. Non-plugins will need to be linked, and; are thus loaded at start-up. Plugins are defined by a base class (e.g.; **`TFile`**) that will be implemented in a plugin, a tag used to; identify the plugin (e.g. `^rfio:` as part of the protocol string),; the plugin class of which an object will be created; (e.g. **`TRFIOFile`**), the library to be loaded (in short; `libRFIO.so` to RFIO), and the constructor to be called (e.g.; ""`TRFIOFile()`""). This can be specified in the `.rootrc` which already; contains many plugin definitions, or by calls to; `gROOT->GetPluginManager()->Add",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:18708,plugin,plugin,18708,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,1,['plugin'],['plugin']
Modifiability,"ve had their implementations; removed. These methods will return a value indicating failure.; * ``SBType::FindDirectNestedType`` function is added. It's useful; for formatters to quickly find directly nested type when it's known; where to search for it, avoiding more expensive global search via; ``SBTarget::FindFirstType``.; * ``lldb-vscode`` was renamed to ``lldb-dap`` and and its installation; instructions have been updated to reflect this. The underlying functionality; remains unchanged.; * The ``mte_ctrl`` register can now be read from AArch64 Linux core files.; * LLDB on AArch64 Linux now supports debugging the Scalable Matrix Extension; (SME) and Scalable Matrix Extension 2 (SME2) for both live processes and core; files. For details refer to the; `AArch64 Linux documentation <https://lldb.llvm.org/use/aarch64-linux.html>`_.; * LLDB now supports symbol and binary acquisition automatically using the; DEBUFINFOD protocol. The standard mechanism of specifying DEBUFINOD servers in; the ``DEBUGINFOD_URLS`` environment variable is used by default. In addition,; users can specify servers to request symbols from using the LLDB setting; ``plugin.symbol-locator.debuginfod.server_urls``, override or adding to the; environment variable. * When running on AArch64 Linux, ``lldb-server`` now provides register; field information for the following registers: ``cpsr``, ``fpcr``,; ``fpsr``, ``svcr`` and ``mte_ctrl``. ::. (lldb) register read cpsr; cpsr = 0x80001000; = (N = 1, Z = 0, C = 0, V = 0, SS = 0, IL = 0, <...>. This is only available when ``lldb`` is built with XML support.; Where possible the CPU's capabilities are used to decide which; fields are present, however this is not always possible or entirely; accurate. If in doubt, refer to the numerical value. * On Windows, LLDB can now read the thread names. Changes to Sanitizers; ---------------------; * HWASan now defaults to detecting use-after-scope bugs. * `SpecialCaseList <https://clang.llvm.org/docs/SanitizerSpecialC",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst:16686,variab,variable,16686,interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,1,['variab'],['variable']
Modifiability,"ve leeway to implement these functions; however they want. Since Clang supports an excellent set of native vector operations,; the Clang headers implement these interfaces in terms of the native vector; operations. In contrast, GCC implements these functions mostly as a 1-to-1 mapping to; builtin function calls, like __builtin_ia32_paddw128. These builtin; functions are an internal implementation detail of GCC, and are not portable to; the Intel compiler, the Microsoft compiler, or Clang. If you get build errors; mentioning these, the fix is simple: switch to the *mmintrin.h functions.; The same issue occurs for NEON and Altivec for the ARM and PowerPC; architectures respectively. For these, make sure to use the <arm_neon.h>; and <altivec.h> headers.; For x86 architectures this script should help with; the manual migration process. It will rewrite your source files in place to; use the APIs instead of builtin function calls. Just call it like this:. builtins.py *.c *.h. and it will rewrite all of the .c and .h files in the current directory to; use the API calls instead of calls like __builtin_ia32_paddw128. Lvalue casts. Old versions of GCC permit casting the left-hand side of an assignment to a; different type. Clang produces an error on similar code, e.g.,. lvalue.c:2:3: error: assignment to cast is illegal, lvalue casts are not supported; (int*)addr = val;; ^~~~~~~~~~ ~. To fix this problem, move the cast to the right-hand side. In this; example, one could use:. addr = (float *)val;. Jumps to within __block variable scope. Clang disallows jumps into the scope of a __block; variable. Variables marked with __block require special; runtime initialization. A jump into the scope of a __block; variable bypasses this initialization, leaving the variable's metadata; in an invalid state. Consider the following code fragment:. int fetch_object_state(struct MyObject *c) {; if (!c->active) goto error;. __block int result;; run_specially_somehow(^{ result = c->state; });; ret",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/compatibility.html:4866,rewrite,rewrite,4866,interpreter/llvm-project/clang/www/compatibility.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/compatibility.html,1,['rewrite'],['rewrite']
Modifiability,"vector operations; on X86 CPUs. These functions have names like _mm_xor_ps and; _mm256_addsub_pd. Compilers have leeway to implement these functions; however they want. Since Clang supports an excellent set of native vector operations,; the Clang headers implement these interfaces in terms of the native vector; operations. In contrast, GCC implements these functions mostly as a 1-to-1 mapping to; builtin function calls, like __builtin_ia32_paddw128. These builtin; functions are an internal implementation detail of GCC, and are not portable to; the Intel compiler, the Microsoft compiler, or Clang. If you get build errors; mentioning these, the fix is simple: switch to the *mmintrin.h functions.; The same issue occurs for NEON and Altivec for the ARM and PowerPC; architectures respectively. For these, make sure to use the <arm_neon.h>; and <altivec.h> headers.; For x86 architectures this script should help with; the manual migration process. It will rewrite your source files in place to; use the APIs instead of builtin function calls. Just call it like this:. builtins.py *.c *.h. and it will rewrite all of the .c and .h files in the current directory to; use the API calls instead of calls like __builtin_ia32_paddw128. Lvalue casts. Old versions of GCC permit casting the left-hand side of an assignment to a; different type. Clang produces an error on similar code, e.g.,. lvalue.c:2:3: error: assignment to cast is illegal, lvalue casts are not supported; (int*)addr = val;; ^~~~~~~~~~ ~. To fix this problem, move the cast to the right-hand side. In this; example, one could use:. addr = (float *)val;. Jumps to within __block variable scope. Clang disallows jumps into the scope of a __block; variable. Variables marked with __block require special; runtime initialization. A jump into the scope of a __block; variable bypasses this initialization, leaving the variable's metadata; in an invalid state. Consider the following code fragment:. int fetch_object_state(struct MyObject",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/compatibility.html:4721,rewrite,rewrite,4721,interpreter/llvm-project/clang/www/compatibility.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/compatibility.html,1,['rewrite'],['rewrite']
Modifiability,"ved by using; ``SpacesInParens`` with ``Custom`` and by setting all; ``SpacesInParensOptions`` to ``true`` except for ``InCStyleCasts`` and; ``InEmptyParentheses``. .. _SpacesInSquareBrackets:. **SpacesInSquareBrackets** (``Boolean``) :versionbadge:`clang-format 3.7` :ref:`¶ <SpacesInSquareBrackets>`; If ``true``, spaces will be inserted after ``[`` and before ``]``.; Lambdas without arguments or unspecified size array declarations will not; be affected. .. code-block:: c++. true: false:; int a[ 5 ]; vs. int a[5];; std::unique_ptr<int[]> foo() {} // Won't be affected. .. _Standard:. **Standard** (``LanguageStandard``) :versionbadge:`clang-format 3.7` :ref:`¶ <Standard>`; Parse and format C++ constructs compatible with this standard. .. code-block:: c++. c++03: latest:; vector<set<int> > x; vs. vector<set<int>> x;. Possible values:. * ``LS_Cpp03`` (in configuration: ``c++03``); Parse and format as C++03.; ``Cpp03`` is a deprecated alias for ``c++03``. * ``LS_Cpp11`` (in configuration: ``c++11``); Parse and format as C++11. * ``LS_Cpp14`` (in configuration: ``c++14``); Parse and format as C++14. * ``LS_Cpp17`` (in configuration: ``c++17``); Parse and format as C++17. * ``LS_Cpp20`` (in configuration: ``c++20``); Parse and format as C++20. * ``LS_Latest`` (in configuration: ``Latest``); Parse and format using the latest supported language version.; ``Cpp11`` is a deprecated alias for ``Latest``. * ``LS_Auto`` (in configuration: ``Auto``); Automatic detection based on the input. .. _StatementAttributeLikeMacros:. **StatementAttributeLikeMacros** (``List of Strings``) :versionbadge:`clang-format 12` :ref:`¶ <StatementAttributeLikeMacros>`; Macros which are ignored in front of a statement, as if they were an; attribute. So that they are not parsed as identifier, for example for Qts; emit. .. code-block:: c++. AlignConsecutiveDeclarations: true; StatementAttributeLikeMacros: []; unsigned char data = 'x';; emit signal(data); // This is parsed as variable declaration. AlignCo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:129268,config,configuration,129268,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['config'],['configuration']
Modifiability,"ved in ROOT 6.34:. * RooAbsTestStatistic; * RooAbsOptTestStatistic; * RooNLLVar; * RooChi2Var; * RooXYChi2Var. Please use the higher-level functions `RooAbsPdf::createNLL()` and `RooAbsPdf::createChi2()` if you want to create objects that represent test statistics. ### Change of RooParamHistFunc. The `RooParamHistFunc` didn't take any observable `RooRealVar` as constructor; argument. It assumes as observable the internal variables in the passed; RooDataHist. This means it was in most contexts unusable, because the input; can't be changed, other than loading a different bin in the dataset. Furthermore, there was actually a constructor that took a `RooAbsArg x`, but it; was simply ignored. To fix all these problems, the existing constructors were replaced by a new one; that takes the observable explicitly. Since the old constructors resulted in wrong computation graphs that caused; trouble with the new CPU evaluation backend, they had to be removed without; deprecation. Please adapt your code if necessary. ### Renaming of some RooFit classes. The `RooPower` was renamed to `RooPowerSum`, and `RooExpPoly` was renamed to `RooLegacyExpPoly`. This was a necessary change, because the names of these classes introduced in ROOT 6.28 collided with some classes in CMS combine, which were around already long before. Therefore, the classes had to be renamed to not cause any problems for CMS. In the unlikeliy case where you should have used these new classes for analysis already, please adapt your code to the new names and re-create your workspaces. ## RDataFrame. * The `RDataFrame` constructors that take in input one or more file names (or globs thereof) will now infer the format of the dataset, either `TTree` or `RNTuple`, that is stored in the first input file. When multiple files are specified, it is assumed that all other files contain a coherent dataset of the same format and with the same schema, exactly as it used to happen with `TChain`. This automatic inference further con",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:13869,adapt,adapt,13869,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['adapt'],['adapt']
Modifiability,"ved"" retaining; operations. Specifically, the object must be laid out such that the; Objective-C message send machinery can successfully send it the following; messages:. * ``retain``, taking no arguments and returning a pointer to the object.; * ``release``, taking no arguments and returning ``void``.; * ``autorelease``, taking no arguments and returning a pointer to the object. The behavior of these methods is constrained in the following ways. The term; :arc-term:`high-level semantics` is an intentionally vague term; the intent is; that programmers must implement these methods in a way such that the compiler,; modifying code in ways it deems safe according to these constraints, will not; violate their requirements. For example, if the user puts logging statements; in ``retain``, they should not be surprised if those statements are executed; more or less often depending on optimization settings. These constraints are; not exhaustive of the optimization opportunities: values held in local; variables are subject to additional restrictions, described later in this; document. It is undefined behavior if a computation history featuring a send of; ``retain`` followed by a send of ``release`` to the same object, with no; intervening ``release`` on that object, is not equivalent under the high-level; semantics to a computation history in which these sends are removed. Note that; this implies that these methods may not raise exceptions. It is undefined behavior if a computation history features any use whatsoever; of an object following the completion of a send of ``release`` that is not; preceded by a send of ``retain`` to the same object. The behavior of ``autorelease`` must be equivalent to sending ``release`` when; one of the autorelease pools currently in scope is popped. It may not throw an; exception. When the semantics call for performing one of these operations on a retainable; object pointer, if that pointer is ``null`` then the effect is a no-op. All of the sema",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:14006,variab,variables,14006,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['variab'],['variables']
Modifiability,"vel declaration includes; an option name (``""debug_level""``), which automatically changes how the library; processes the argument. The CommandLine library supports both forms so that you; can choose the form most appropriate for your application. .. _lists:. Parsing a list of options; -------------------------. Now that we have the standard run-of-the-mill argument types out of the way,; lets get a little wild and crazy. Lets say that we want our optimizer to accept; a **list** of optimizations to perform, allowing duplicates. For example, we; might want to run: ""``compiler -dce -instsimplify -inline -dce -strip``"". In this; case, the order of the arguments and the number of appearances is very; important. This is what the ""``cl::list``"" template is for. First, start by; defining an enum of the optimizations that you would like to perform:. .. code-block:: c++. enum Opts {; // 'inline' is a C++ keyword, so name it 'inlining'; dce, instsimplify, inlining, strip; };. Then define your ""``cl::list``"" variable:. .. code-block:: c++. cl::list<Opts> OptimizationList(cl::desc(""Available Optimizations:""),; cl::values(; clEnumVal(dce , ""Dead Code Elimination""),; clEnumVal(instsimplify , ""Instruction Simplification""),; clEnumValN(inlining, ""inline"", ""Procedure Integration""),; clEnumVal(strip , ""Strip Symbols"")));. This defines a variable that is conceptually of the type; ""``std::vector<enum Opts>``"". Thus, you can access it with standard vector; methods:. .. code-block:: c++. for (unsigned i = 0; i != OptimizationList.size(); ++i); switch (OptimizationList[i]); ... ... to iterate through the list of options specified. Note that the ""``cl::list``"" template is completely general and may be used with; any data types or other arguments that you can use with the ""``cl::opt``""; template. One especially useful way to use a list is to capture all of the; positional arguments together if there may be more than one specified. In the; case of a linker, for example, the linker takes severa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:19820,variab,variable,19820,interpreter/llvm-project/llvm/docs/CommandLine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst,1,['variab'],['variable']
Modifiability,"vely, define a ""myclass_selection.xml"" file::. <lcgdict>; <class name=""MyClass"" />; </lcgdict>. serving the same purpose as the Linkdef.h file above (in fact, ``rootcling``; accepts a ""selection.xml"" file in lieu of a ""Linkdef.h"").; For more tags, see the `selection file`_ documentation.; Commonly used are ``namespace``, ``function``, ``enum``, or ``variable``; instead of the ``class`` tag, and ``pattern`` instead of ``name`` with; wildcarding in the value string. Next, use ``genreflex`` to generate the dictionary (here:; ``MyClass_rflx.cxx``) and module files::. $ genreflex MyClass.h --selection=myclass_selection.xml -o MyClass_rflx.cxx. From here, compile and link the generated dictionary file with the project; and/or system specific options and libraries into a shared library, using; ``cling-config`` for the relevant cppyy compiler/linker flags.; (For work on MS Windows, this `helper script`_ may be useful.); To continue the example, assuming Linux::. $ g++ `cling-config --cppflags` -fPIC -O2 -shared MyClass_rflx.cxx -o MyClassDict.so. Instead of loading the header text into ``cling``, you can now load the; dictionary:. .. code-block:: python. >>> import cppyy; >>> cppyy.load_reflection_info('MyClassDict'); >>> cppyy.gbl.MyClass(42); <cppyy.gbl.MyClass object at 0x7ffb9f230950>; >>> print(_.get_int()); 42; >>>. and use the selected C++ entities as if the header was loaded. The dictionary shared library can be relocated, as long as it can be found; by the dynamic loader (e.g. through ``LD_LIBRARY_PATH``) and the header file; is fully embedded or still accessible (e.g. through a path added to; ``cppyy.add_include_path`` at run-time, or with ``-I`` to; ``rootcling``/``genreflex`` during build time).; When relocating the shared library, move the .pcm with it.; Once support for C++ modules is fully fleshed out, access to the header file; will no longer be needed. .. _`rootcling manual`: https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:7041,config,config,7041,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,1,['config'],['config']
Modifiability,"ven build ID, specified as a hexadecimal; string. The found object is handled as if it were an input filename. .. option:: -C, --demangle. Demangle symbol names in the output. .. option:: --debug-file-directory <path>. Provide a path to a directory with a `.build-id` subdirectory to search for; debug information for stripped binaries. Multiple instances of this argument; are searched in the order given. .. option:: --debuginfod, --no-debuginfod. Whether or not to try debuginfod lookups for debug binaries. Unless specified,; debuginfod is only enabled if libcurl was compiled in (``LLVM_ENABLE_CURL``); and at least one server URL was provided by the environment variable; ``DEBUGINFOD_URLS``. .. option:: --debug-vars=<format>. Print the locations (in registers or memory) of source-level variables; alongside disassembly. ``format`` may be ``unicode`` or ``ascii``, defaulting; to ``unicode`` if omitted. .. option:: --debug-vars-indent=<width>. Distance to indent the source-level variable display, relative to the start; of the disassembly. Defaults to 52 characters. .. option:: -j, --section=<section1[,section2,...]>. Perform commands on the specified sections only. For Mach-O use; `segment,section` to specify the section name. .. option:: -l, --line-numbers. When disassembling, display source line numbers. Implies; :option:`--disassemble`. .. option:: -M, --disassembler-options=<opt1[,opt2,...]>. Pass target-specific disassembler options. Available options:. * ``reg-names-std``: ARM only (default). Print in ARM 's instruction set documentation, with r13/r14/r15 replaced by sp/lr/pc.; * ``reg-names-raw``: ARM only. Use r followed by the register number.; * ``no-aliases``: AArch64 and RISC-V only. Print raw instruction mnemonic instead of pseudo instruction mnemonic.; * ``numeric``: RISC-V only. Print raw register names instead of ABI mnemonic. (e.g. print x1 instead of ra); * ``att``: x86 only (default). Print in the AT&T syntax.; * ``intel``: x86 only. Print in the intel ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst:4368,variab,variable,4368,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst,1,['variab'],['variable']
Modifiability,"ven precedence. The following; extensions are part of the clang-cl toolset:. - `/winsysroot:`. The `/winsysroot:` is used as an equivalent to `-sysroot` on Unix; environments. It allows the control of an alternate location to be treated; as a system root. When specified, it will be used as the root where the; `Windows Kits` is located. - `/winsdkversion:`; - `/winsdkdir:`. If `/winsysroot:` is not specified, the `/winsdkdir:` argument is consulted; as a location to identify where the Windows SDK is located. Contrary to; `/winsysroot:`, `/winsdkdir:` is expected to be the complete path rather; than a root to locate `Windows Kits`. The `/winsdkversion:` flag allows the user to specify a version identifier; for the SDK to prefer. When this is specified, no additional validation is; performed and this version is preferred. If the version is not specified,; the highest detected version number will be used. 2. Consult the environment. TODO: This is not yet implemented. This will consult the environment variables:. - `WindowsSdkDir`; - `UCRTVersion`. 3. Fallback to the registry. If no arguments are used to indicate where the SDK is present, and the; compiler is running on Windows, the registry is consulted to locate the; installation. The Visual C++ Toolset has a slightly more elaborate mechanism for detection. 1. Consult the command line. - `/winsysroot:`. The `/winsysroot:` is used as an equivalent to `-sysroot` on Unix; environments. It allows the control of an alternate location to be treated; as a system root. When specified, it will be used as the root where the; `VC` directory is located. - `/vctoolsdir:`; - `/vctoolsversion:`. If `/winsysroot:` is not specified, the `/vctoolsdir:` argument is consulted; as a location to identify where the Visual C++ Tools are located. If; `/vctoolsversion:` is specified, that version is preferred, otherwise, the; highest version detected is used. 2. Consult the environment. - `/external:[VARIABLE]`. This specifies a user identified",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:195041,variab,variables,195041,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['variab'],['variables']
Modifiability,"ven:; void Func();; void DeletedFunc() = delete;; functionDecl(isDeleted()); matches the declaration of DeletedFunc, but not Func. Matcher<FunctionDecl>isExplicitTemplateSpecialization; Matches explicit template specializations of function, class, or; static member variable template instantiations. Given; template<typename T> void A(T t) { }; template<> void A(int N) { }; functionDecl(isExplicitTemplateSpecialization()); matches the specialization A<int>(). Usable as: Matcher<FunctionDecl>, Matcher<VarDecl>, Matcher<CXXRecordDecl>. Matcher<FunctionDecl>isExternC; Matches extern ""C"" function or variable declarations. Given:; extern ""C"" void f() {}; extern ""C"" { void g() {} }; void h() {}; extern ""C"" int x = 1;; extern ""C"" int y = 2;; int z = 3;; functionDecl(isExternC()); matches the declaration of f and g, but not the declaration of h.; varDecl(isExternC()); matches the declaration of x and y, but not the declaration of z. Matcher<FunctionDecl>isInline; Matches functions, variables and namespace declarations that are marked with; the inline keyword. Given; inline void f();; void g();; namespace n {; inline namespace m {}; }; inline int Foo = 5;; functionDecl(isInline()) will match ::f().; namespaceDecl(isInline()) will match n::m.; varDecl(isInline()) will match Foo;. Matcher<FunctionDecl>isMain; Determines whether the function is ""main"", which is the entry point; into an executable program. Matcher<FunctionDecl>isNoReturn; Matches FunctionDecls that have a noreturn attribute. Given; void nope();; [[noreturn]] void a();; __attribute__((noreturn)) void b();; struct c { [[noreturn]] c(); };; functionDecl(isNoReturn()); matches all of those except; void nope();. Matcher<FunctionDecl>isNoThrow; Matches functions that have a non-throwing exception specification. Given:; void f();; void g() noexcept;; void h() throw();; void i() throw(int);; void j() noexcept(false);; functionDecl(isNoThrow()) and functionProtoType(isNoThrow()); match the declarations of g, and h, but not ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html:93064,variab,variables,93064,interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,1,['variab'],['variables']
Modifiability,"vent"" is a structure with one float and; three integers and one unsigned integer. You should not assume that the; compiler aligns the elements of a structure without gaps. To avoid; alignment problems, you need to use structures with same length members.; If your structure does not qualify, you need to create one branch for; each element of the structure. The leaf name is NOT used to pick the variable out of the structure, but; is only used as the name for the leaf. This means that the list of; variables needs to be in a structure in the order described in the third; parameter. This third parameter is a string describing the leaf list. Each leaf has; a name and a type separated by a ""/"" and it is separated from the next; leaf by a ""`:`"". ``` {.cpp}; <Variable>/<type>:<Variable>/<type>; ```. The example on the next line has two leafs: a floating-point number; called temp and an integer named `ntrack`. ``` {.cpp}; ""temp/F:ntrack/I:""; ```. The type can be omitted and if no type is given, the same type as the; previous variable is assumed. This leaf list has three integers called; `ntrack`, `nseg`, and `nvtex`. ``` {.cpp}; ""ntrack/I:nseg:nvtex""; ```. There is one more rule: when no type is given for the very first leaf,; it becomes a `float` (F). This leaf list has three floats called `temp`,; `mass`, and `px`. ``` {.cpp}; ""temp:mass:px""; ```. The symbols used for the type are:. - `C`: a character string terminated by the 0 character; - `B`: an 8 bit signed integer; - `b`: an 8 bit unsigned integer; - `S`: a 16 bit signed integer; - `s`: a 16 bit unsigned integer; - `I`: a 32 bit signed integer; - `i`: a 32 bit unsigned integer; - `L`: a 64 bit signed integer; - `l`: a 64 bit unsigned integer; - `G`: a long signed integer, stored as 64 bit; - `g`: a long unsigned integer, stored as 64 bit; - `F`: a 32 bit floating point; - `D`: a 64 bit floating point; - `O`: [the letter 'o', not a zero] a boolean (Bool\_t). The type is used for a byte count to decide how much space to a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:20778,variab,variable,20778,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['variab'],['variable']
Modifiability,"ver(""fastcgi:9000"");; ```. In fact, the FastCGI interface can run in parallel to http server. One can just call:. ```cpp; serv = new THttpServer(""http:8080"");; serv->CreateEngine(""fastcgi:9000"");; ```. One could specify a debug parameter to be able to adjust the FastCGI configuration on the web server:. ```cpp; serv->CreateEngine(""fastcgi:9000?debug=1"");; ```. By default 10 threads are used to process FastCGI requests. This number can be changed with ""thrds"" url parameter:. ```cpp; serv->CreateEngine(""fastcgi:9000?thrds=20"");; ```. If `thrds=0` parameter specified, the only thread will be use to received and process all requests. All user access will be ruled by the main web server. Authorized account names could be used to configure access restriction in THttpServer. ### Configure fastcgi with Apache2. Since Apache version 2.4 FastCGI is directly supported - there is no need to compile and install external modules any more.; One only need to enable `mod_proxy` and `mod_proxy_fcgi` modules and add following line to **Apache2** configuration file:. ```; ProxyPass ""/root.app/"" ""fcgi://localhost:9000/"" enablereuse=on; ```. More information can be found in [FastCGI proxy docu](https://httpd.apache.org/docs/2.4/mod/mod_proxy_fcgi.html).; After restarting apache server one should be able to open address: `http://apache_host_name/root.app/`.; There are many ways to configure user authentication in Apache. Example of digest auth for FastCGI server:. ```; <Location ""/root.app/"">; AuthType Digest; AuthName ""root""; AuthDigestDomain ""/root.app/"" ""root""; AuthDigestProvider file; AuthUserFile ""/srv/auth/auth.txt""; Require valid-user; </Location>; ```. ### Configure fastcgi with lighttpd. An example of configuration file for **lighttpd** server is:. ```; server.modules += ( ""mod_fastcgi"" ); fastcgi.server = (; ""/root.app"" =>; (( ""host"" => ""192.168.1.11"",; ""port"" => 9000,; ""check-local"" => ""disable"",; ""docroot"" => ""/""; )); ); ```. Be aware, that with *lighttpd* one should specify IP",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md:11293,config,configuration,11293,documentation/HttpServer/HttpServer.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/HttpServer/HttpServer.md,1,['config'],['configuration']
Modifiability,"ver; - ``clang-dxc`` for the ``dxc`` driver. For example, when calling ``x86_64-pc-linux-gnu-clang-g++``,; the driver will first attempt to use the configuration file named::. x86_64-pc-linux-gnu-clang++.cfg. If this file is not found, it will attempt to use the name found; in the executable instead::. x86_64-pc-linux-gnu-clang-g++.cfg. Note that options such as ``--driver-mode=``, ``--target=``, ``-m32`` affect; the search algorithm. For example, the aforementioned executable called with; ``-m32`` argument will instead search for::. i386-pc-linux-gnu-clang++.cfg. If none of the aforementioned files are found, the driver will instead search; for separate driver and target configuration files and attempt to load both.; The former is named ``<driver>.cfg`` while the latter is named; ``<triple>.cfg``. Similarly to the previous variants, the canonical driver name; will be preferred, and the compiler will fall back to the actual name. For example, ``x86_64-pc-linux-gnu-clang-g++`` will attempt to load two; configuration files named respectively::. clang++.cfg; x86_64-pc-linux-gnu.cfg. with fallback to trying::. clang-g++.cfg; x86_64-pc-linux-gnu.cfg. It is not an error if either of these files is not found. The configuration file consists of command-line options specified on one or; more lines. Lines composed of whitespace characters only are ignored as well as; lines in which the first non-blank character is ``#``. Long options may be split; between several lines by a trailing backslash. Here is example of a; configuration file:. ::. # Several options on line; -c --target=x86_64-unknown-linux-gnu. # Long option split between lines; -I/usr/lib/gcc/x86_64-linux-gnu/5.4.0/../../../../\; include/c++/5.4.0. # other config files may be included; @linux.options. Files included by ``@file`` directives in configuration files are resolved; relative to the including file. For example, if a configuration file; ``~/.llvm/target.cfg`` contains the directive ``@os/linux.opts``, the fil",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:33850,config,configuration,33850,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['config'],['configuration']
Modifiability,versions to non-class prvalues in reference initialization; Not resolved. 2109; CD4; Value dependence underspecified; Unknown. 2110; drafting; Overload resolution for base class conversion and reference/non-reference; Not resolved. 2111; NAD; Array temporaries in reference binding; Unknown. 2112; CD5; new auto{x}; Unknown. 2113; CD4; Incompete specification of types for declarators; Unknown. 2114; CD3; Missing description of incompatibility from aggregate NSDMIs; Unknown. 2115; drafting; Order of implicit destruction vs release of automatic storage; Not resolved. 2116; C++17; Direct or copy initialization for omitted aggregate initializers; Unknown. 2117; drafting; Explicit specializations and constexpr function templates; Not resolved. 2118; open; Stateful metaprogramming via friend injection; Not resolved. 2119; NAD; Disambiguation of multi-level covariant return type; Unknown. 2120; CD4; Array as first non-static data member in standard-layout class; Clang 7. 2121; CD6; More flexible lambda syntax; Unknown. 2122; CD4; Glvalues of void type; Unknown. 2123; open; Omitted constant initialization of local static variables; Not resolved. 2124; CD4; Signature of constructor template; Unknown. 2125; NAD; Copy elision and comma operator; Unknown. 2126; C++20; Lifetime-extended temporaries in constant expressions; Clang 12. 2127; drafting; Partial specialization and nullptr; Not resolved. 2128; drafting; Imprecise rule for reference member initializer; Not resolved. 2129; CD4; Non-object prvalues and constant expressions; Unknown. 2130; CD4; Over-aligned types in new-expressions; Unknown. 2131; drafting; Ambiguity with opaque-enum-declaration; Not resolved. 2132; NAD; Deprecated default generated copy constructors; Unknown. 2133; CD5; Converting std::nullptr_t to bool; Unknown. 2134; NAD; Objectless references to non-static member functions; Unknown. 2135; NAD; mem-initializers for virtual bases of abstract classes; Unknown. 2136; NAD; Argument-dependent lookup and initial,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html:144466,flexible,flexible,144466,interpreter/llvm-project/clang/www/cxx_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html,1,['flexible'],['flexible']
Modifiability,"verts automatically to an integer, which represents the status code of the fit. If the Fit method is used as before, there is a no visible change for the user.; When using the fit option ""S"", the TFitResultPtr will now contain a pointer to the new TFitResult class. It will behave as a smart pointer to TFitResult,; by using the -> operator the user can call the TFitResult methods or access directly the TFitResult object, by using the de-reference operator * or; TFitResultPtr::Get().; The TFitResult class derives from the ROOT::Math::FitResult, which contains all the result information from a fit and from TNamed. It provides then I/O capabilities for the FitResult object and convenience methods like Print(), Write(), GetCovarianceMatrix() and GetCorrelationMatrix() which return a TMatrixDSym object.; Example of usage:; ; TFitResult r = h->Fit(""myFunc"",""S"");; TMatrixDSym cov = r->GetCovarianceMatrix(); // to access the covariance matrix; Double_t chi2 = r->Chi2(); // to retrieve the fit chi2; Double_t par0 = r->Value(0); // retrieve the value for the parameter 0; Double_t err0 = r->Error(0); // retrieve the error for the parameter 0; r->Print(""V""); // print full information of fit including covariance matrix; r->Write(); // store the result in a file. FitPanel. Added predefined 2D Functions.; Addition of new minimization algorithms from the GSL library and foreseen the addition of; genetic minimizers when will be released.; Fixed up to three bugs from the previous release; Added the Update Button. This way the user can update the content of the fitpanel with all the new objects and functions created in the current ROOT session.; Changed the way the TF1s were being copied internally. Instead of using TObject::Clone, now it's using the TF1 copy constructor. new tutorial rebin.C; This tutorial illustrates how to:. create a variable binwidth histogram with a binning such; that the population per bin is about the same.; rebin a variable binwidth histogram into another one. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v526/index.html:6396,variab,variable,6396,hist/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v526/index.html,2,['variab'],['variable']
Modifiability,"via an attribute) default visibility from the; source, including RTTI.; * ``-mdefault-visibility-export-mapping=all``: set XCOFF exported visibility; for all entities with default visibility from any source. This gives a; export behavior similar to ELF platforms where all entities with default; visibility are exported. .. _spir-v:. SPIR-V support; --------------. Clang supports generation of SPIR-V conformant to `the OpenCL Environment; Specification; <https://www.khronos.org/registry/OpenCL/specs/3.0-unified/html/OpenCL_Env.html>`_. To generate SPIR-V binaries, Clang uses the external ``llvm-spirv`` tool from the; `SPIRV-LLVM-Translator repo; <https://github.com/KhronosGroup/SPIRV-LLVM-Translator>`_. Prior to the generation of SPIR-V binary with Clang, ``llvm-spirv``; should be built or installed. Please refer to `the following instructions; <https://github.com/KhronosGroup/SPIRV-LLVM-Translator#build-instructions>`_; for more details. Clang will expect the ``llvm-spirv`` executable to; be present in the ``PATH`` environment variable. Clang uses ``llvm-spirv``; with `the widely adopted assembly syntax package; <https://github.com/KhronosGroup/SPIRV-LLVM-Translator/#build-with-spirv-tools>`_. `The versioning; <https://github.com/KhronosGroup/SPIRV-LLVM-Translator/releases>`_ of; ``llvm-spirv`` is aligned with Clang major releases. The same applies to the; main development branch. It is therefore important to ensure the ``llvm-spirv``; version is in alignment with the Clang version. For troubleshooting purposes; ``llvm-spirv`` can be `tested in isolation; <https://github.com/KhronosGroup/SPIRV-LLVM-Translator#test-instructions>`_. Example usage for OpenCL kernel compilation:. .. code-block:: console. $ clang --target=spirv32 -c test.cl; $ clang --target=spirv64 -c test.cl. Both invocations of Clang will result in the generation of a SPIR-V binary file; `test.o` for 32 bit and 64 bit respectively. This file can be imported; by an OpenCL driver that support SPIR-V consu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:165995,variab,variable,165995,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['variab'],['variable']
Modifiability,"vides; <https://www.kernel.org/doc/Documentation/arm/kernel_user_helpers.txt>`_ a; function which on older CPUs contains a ""magically-restartable"" atomic sequence; (which looks atomic so long as there's only one CPU), and contains actual atomic; instructions on newer multicore models. This sort of functionality can typically; be provided on any architecture, if all CPUs which are missing atomic; compare-and-swap support are uniprocessor (no SMP). This is almost always the; case. The only common architecture without that property is SPARC -- SPARCV8 SMP; systems were common, yet it doesn't support any sort of compare-and-swap; operation. Some targets (like RISCV) support a ``+forced-atomics`` target feature, which; enables the use of lock-free atomics even if LLVM is not aware of any specific; OS support for them. In this case, the user is responsible for ensuring that; necessary ``__sync_*`` implementations are available. Code using; ``+forced-atomics`` is ABI-incompatible with code not using the feature, if; atomic variables cross the ABI boundary. In either of these cases, the Target in LLVM can claim support for atomics of an; appropriate size, and then implement some subset of the operations via libcalls; to a ``__sync_*`` function. Such functions *must* not use locks in their; implementation, because unlike the ``__atomic_*`` routines used by; AtomicExpandPass, these may be mixed-and-matched with native instructions by the; target lowering. Further, these routines do not need to be shared, as they are stateless. So,; there is no issue with having multiple copies included in one binary. Thus,; typically these routines are implemented by the statically-linked compiler; runtime support library. LLVM will emit a call to an appropriate ``__sync_*`` routine if the target; ISelLowering code has set the corresponding ``ATOMIC_CMPXCHG``, ``ATOMIC_SWAP``,; or ``ATOMIC_LOAD_*`` operation to ""Expand"", and if it has opted-into the; availability of those library functions vi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:28136,variab,variables,28136,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['variab'],['variables']
Modifiability,"view:. Overview; ________. Taint analysis works by checking for the occurrence of special operations during the symbolic execution of the program.; Taint analysis defines sources, sinks, and propagation rules. It identifies errors by detecting a flow of information that originates from a taint source, reaches a taint sink, and propagates through the program paths via propagation rules.; A source, sink, or an operation that propagates taint is mainly domain-specific knowledge, but there are some built-in defaults provided by :ref:`alpha-security-taint-TaintPropagation`.; It is possible to express that a statement sanitizes tainted values by providing a ``Filters`` section in the external configuration (see :ref:`clangsa-taint-configuration-example` and :ref:`clangsa-taint-filter-details`).; There are no default filters defined in the built-in settings.; The checker's documentation also specifies how to provide a custom taint configuration with command-line options. .. _clangsa-taint-configuration-example:. Example configuration file; __________________________. .. code-block:: yaml. # The entries that specify arguments use 0-based indexing when specifying; # input arguments, and -1 is used to denote the return value. Filters:; # Filter functions; # Taint is sanitized when tainted variables are pass arguments to filters. # Filter function; # void cleanse_first_arg(int* arg); #; # Result example:; # int x; // x is tainted; # cleanse_first_arg(&x); // x is not tainted after the call; - Name: cleanse_first_arg; Args: [0]. Propagations:; # Source functions; # The omission of SrcArgs key indicates unconditional taint propagation,; # which is conceptually what a source does. # Source function; # size_t fread(void *ptr, size_t size, size_t nmemb, FILE * stream); #; # Result example:; # FILE* f = fopen(""file.txt"");; # char buf[1024];; # size_t read = fread(buf, sizeof(buf[0]), sizeof(buf)/sizeof(buf[0]), f);; # // both read and buf are tainted; - Name: fread; DstArgs: [0, -1].",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/user-docs/TaintAnalysisConfiguration.rst:1939,config,configuration-example,1939,interpreter/llvm-project/clang/docs/analyzer/user-docs/TaintAnalysisConfiguration.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/user-docs/TaintAnalysisConfiguration.rst,1,['config'],['configuration-example']
Modifiability,"ving from the; class ``Instruction``. For each ``def`` record, the root object also has a key for the record; name. The corresponding value is a subsidiary object containing the; following fixed keys:. * ``!superclasses``: an array of strings giving the names of all the; classes that this record derives from. * ``!fields``: an array of strings giving the names of all the variables; in this record that were defined with the ``field`` keyword. * ``!name``: a string giving the name of the record. This is always; identical to the key in the JSON root object corresponding to this; record's dictionary. (If the record is anonymous, the name is; arbitrary.). * ``!anonymous``: a boolean indicating whether the record's name was; specified by the TableGen input (if it is ``false``), or invented by; TableGen itself (if ``true``). For each variable defined in a record, the ``def`` object for that; record also has a key for the variable name. The corresponding value; is a translation into JSON of the variable's value, using the; conventions described below. Some TableGen data types are translated directly into the; corresponding JSON type:. * A completely undefined value (e.g. for a variable declared without; initializer in some superclass of this record, and never initialized; by the record itself or any other superclass) is emitted as the JSON; ``null`` value. * ``int`` and ``bit`` values are emitted as numbers. Note that; TableGen ``int`` values are capable of holding integers too large to; be exactly representable in IEEE double precision. The integer; literal in the JSON output will show the full exact integer value.; So if you need to retrieve large integers with full precision, you; should use a JSON reader capable of translating such literals back; into 64-bit integers without losing precision, such as Python's; standard ``json`` module. * ``string`` and ``code`` values are emitted as JSON strings. * ``list<T>`` values, for any element type ``T``, are emitted as JSON; arra",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst:16795,variab,variable,16795,interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst,1,['variab'],['variable']
Modifiability,"ving<WhenToPreserveLocation>` and; :ref:`merging<WhenToMergeLocation>` debug locations do not apply. The API to; use is ``Instruction::dropLocation()``. The purpose of this rule is to prevent erratic or misleading single-stepping; behavior in situations in which an instruction has no clear, unambiguous; relationship to a source location. To handle an instruction without a location, the DWARF generator; defaults to allowing the last-set location after a label to cascade forward, or; to setting a line 0 location with viable scope information if no previous; location is available. See the discussion in the section about; :ref:`merging locations<WhenToMergeLocation>` for examples of when the rule for; dropping locations applies. Rules for updating debug values; ===============================. Deleting an IR-level Instruction; --------------------------------. When an ``Instruction`` is deleted, its debug uses change to ``undef``. This is; a loss of debug info: the value of one or more source variables becomes; unavailable, starting with the ``llvm.dbg.value(undef, ...)``. When there is no; way to reconstitute the value of the lost instruction, this is the best; possible outcome. However, it's often possible to do better:. * If the dying instruction can be RAUW'd, do so. The; ``Value::replaceAllUsesWith`` API transparently updates debug uses of the; dying instruction to point to the replacement value. * If the dying instruction cannot be RAUW'd, call ``llvm::salvageDebugInfo`` on; it. This makes a best-effort attempt to rewrite debug uses of the dying; instruction by describing its effect as a ``DIExpression``. * If one of the **operands** of a dying instruction would become trivially; dead, use ``llvm::replaceAllDbgUsesWith`` to rewrite the debug uses of that; operand. Consider the following example function:. .. code-block:: llvm. define i16 @foo(i16 %a) {; %b = sext i16 %a to i32; %c = and i32 %b, 15; call void @llvm.dbg.value(metadata i32 %c, ...); %d = trunc i32 %c ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst:6691,variab,variables,6691,interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToUpdateDebugInfo.rst,1,['variab'],['variables']
Modifiability,"vironment; r[""df2""]<<df2;; r<<""print(df2)"";; ~~~; Output. ~~~{.sh}; v1 v2 v3; 1 0.1 3 v1; 2 0.2 2 v2; 3 0.3 1 v3; ~~~. ~~~{.cxx}; ///////////////////////////////////////////; //Working with columns between dataframes//; ///////////////////////////////////////////. //passing values from column v3 of df2 to var1 of df1; df2[""v3""]>>df1[""var1""];; //updating df1 in R's environment; r[""df1""]<<df1;; r<<""print(df1)"";; ~~~. Output. ~~~{.sh}; var1 var2 var3 strings var4; 1 v1 0.101 1 v1 -1; 2 v2 0.202 2 v2 -2; 3 v3 0.303 3 v3 -3; ~~~. ## Plotting with R's graphical system.; ROOTR supports an eventloop for R's graphical system which allows plotting using the R functions to the; graphical system or generating images(ps, pdf png, etc).; You can find a demo in Interpolation below in examples section. ## Interactive Mode; The interactive mode lets you get the R's command line within ROOT's command line to run R code with tab completion support.; The variables created in the interactive mode can be passed to ROOT with TRObjectProxy and the method ParseEval?.; To initialize the interactive mode just call Interactive() method and type "".q"" to exit from R's prompt and to go to the ROOT's prompt again. ~~~{.cxx}; [omazapa] [tuxhome] [~]$ root -l; root [0] #include<TRInterface.h>; root [1] ROOT::R::TRInterface &r=ROOT::R::TRInterface::Instance();; root [2] r.Interactive(); [r]:a=seq; seq seq_along seq.Date seq.default seq.int seq_len seq.POSIXt sequence; [r]:a=seq(1,5,0.5); [r]:.q; root [3] TVectorD v=r.ParseEval(""a"");; root [4] v.Print(). Vector (9) is as follows. | 1 |; ------------------; 0 |1; 1 |1.5; 2 |2; 3 |2.5; 4 |3; 5 |3.5; 6 |4; 7 |4.5; 8 |5. root [4]; ~~~. ## Examples; The examples can also be found in `$ROOTSYS/tutorials/r`. ## Creating a Functor; A functor is a class which wraps a function, very useful when states and properties; associated to that function are needed.; In this example I show how to give support to a custom class to be used in R's environment,; which at the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md:11233,variab,variables,11233,bindings/r/doc/users-guide/ROOTR_Users_Guide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md,1,['variab'],['variables']
Modifiability,"vm-profdata); set(PGO_OPT -DLLVM_PROFDATA=${LLVM_RUNTIME_OUTPUT_INTDIR}/llvm-profdata); endif(). if(LLVM_BUILD_INSTRUMENTED); add_dependencies(clang-bootstrap-deps generate-profdata); set(PGO_OPT -DLLVM_PROFDATA_FILE=${CMAKE_CURRENT_BINARY_DIR}/utils/perf-training/clang.profdata); # Use the current tools for LTO instead of the instrumented ones; list(APPEND _BOOTSTRAP_DEFAULT_PASSTHROUGH; CMAKE_CXX_COMPILER; CMAKE_C_COMPILER; CMAKE_ASM_COMPILER; CMAKE_AR; CMAKE_RANLIB; DARWIN_LTO_LIBRARY; DYLD_LIBRARY_PATH). set(COMPILER_OPTIONS); set(LTO_LIBRARY); set(LTO_AR); set(LTO_RANLIB); endif(). # Populate the passthrough variables; foreach(variableName ${CLANG_BOOTSTRAP_PASSTHROUGH} ${_BOOTSTRAP_DEFAULT_PASSTHROUGH}); if(DEFINED ${variableName}); if(""${${variableName}}"" STREQUAL """"); set(value """"); else(); string(REPLACE "";"" ""|"" value ""${${variableName}}""); endif(); list(APPEND PASSTHROUGH_VARIABLES; -D${variableName}=${value}); endif(); endforeach(). # Find all variables that start with BOOTSTRAP_ and populate a variable with; # them.; get_cmake_property(variableNames VARIABLES); foreach(variableName ${variableNames}); if(variableName MATCHES ""^BOOTSTRAP_""); string(SUBSTRING ${variableName} 10 -1 varName); string(REPLACE "";"" ""|"" value ""${${variableName}}""); list(APPEND PASSTHROUGH_VARIABLES; -D${varName}=${value}); endif(); if(${variableName} AND variableName MATCHES ""LLVM_EXTERNAL_.*_SOURCE_DIR""); list(APPEND PASSTHROUGH_VARIABLES; -D${variableName}=${${variableName}}); endif(); endforeach(). # Build arguments for native tool used in CMake.; set(build_configuration ""$<CONFIG>""); set(build_tool_args ""${LLVM_EXTERNAL_PROJECT_BUILD_TOOL_ARGS}""); if(NOT build_tool_args STREQUAL """"); string(PREPEND build_tool_args ""-- ""); separate_arguments(build_tool_args UNIX_COMMAND ""${build_tool_args}""); endif(). ExternalProject_Add(${NEXT_CLANG_STAGE}; DEPENDS clang-bootstrap-deps; PREFIX ${NEXT_CLANG_STAGE}; SOURCE_DIR ${CMAKE_SOURCE_DIR}; STAMP_DIR ${STAMP_DIR}; BINARY_DIR ${BINARY_DIR}",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt:27164,variab,variables,27164,interpreter/llvm-project/clang/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CMakeLists.txt,2,['variab'],"['variable', 'variables']"
Modifiability,"vm.dbg.assign`; intrinsics similarly to `llvm.dbg.declare` intrinsics. Clone the; `llvm.dbg.assign` intrinsics linked to the store, update the FragmentInfo in; the `ValueExpression`, and give the split stores (and cloned intrinsics) new; `DIAssignID` attachments each. In other words, treat the split stores as; separate assignments. For partial DSE (e.g. shortening a memset), we do the; same except that `llvm.dbg.assign` for the dead fragment gets an `Undef`; `Address`. **Promoting** allocas and store/loads: `llvm.dbg.assign` intrinsics implicitly; describe joined values in memory locations at CFG joins, but this is not; necessarily the case after promoting (or partially promoting) the; variable. Passes that promote variables are responsible for inserting; `llvm.dbg.assign` intrinsics after the resultant PHIs generated during; promotion. `mem2reg` already has to do this (with `llvm.dbg.value`) for; `llvm.dbg.declare`s. Where a store has no linked intrinsic, the store is; assumed to represent an assignment for variables stored at the destination; address. #### Debug intrinsic updates. **Moving** a debug intrinsic: avoid moving `llvm.dbg.assign` intrinsics where; possible, as they represent a source-level assignment, whose position in the; program should not be affected by optimization passes. **Deleting** a debug intrinsic: Nothing new to do. Just like for conventional; debug intrinsics, unless it is unreachable, it’s almost always incorrect to; delete a `llvm.dbg.assign` intrinsic. ### Lowering `llvm.dbg.assign` to MIR. To begin with only SelectionDAG ISel will be supported. `llvm.dbg.assign`; intrinsics are lowered to MIR `DBG_INSTR_REF` instructions. Before this happens; we need to decide where it is appropriate to use memory locations and where we; must use a non-memory location (or no location) for each variable. In order to; make those decisions we run a standard fixed-point dataflow analysis that makes; the choice at each instruction, iteratively joining the re",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:8373,variab,variables,8373,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md,1,['variab'],['variables']
Modifiability,"volatile compound operations; P2327R1; Clang 15. Support for #warning; P2437R1; Yes. Remove non-encodable wide character literals and multicharacter wide character literals; P2362R3; Clang 14. Labels at the end of compound statements; P2324R2; Clang 16. Delimited escape sequences; P2290R3; Clang 15. Named universal character escapes; P2071R2; Clang 15. Relaxing some constexpr restrictions; P2448R2. Clang 17 (Partial); 	 We do not support outside of defaulted special memeber functions the change that constexpr functions no; longer have to be constexpr compatible but rather support a less restricted requirements for constexpr; functions. Which include allowing non-literal types as return values and parameters, allow calling of; non-constexpr functions and constructors.; . Using unknown pointers and references in constant expressions; P2280R4 (DR); No. static operator(); P1169R4; Clang 16. Extended floating-point types and standard names; P1467R9; No. Class template argument deduction from inherited constructors; P2582R1; No. Portable assumptions; P1774R8; No. Support for UTF-8 as a portable source file encoding; P2295R6; Clang 15. char8_t Compatibility and Portability Fix; P2513R3; Clang 16. Relax requirements on wchar_t to match existing practices; P2460R2; Yes. Explicit lifetime management; P2590R2; No. static operator[]; P2589R1; Clang 16. Permitting static constexpr variables in constexpr functions; P2647R1; Clang 16. consteval needs to propagate up; P2564R3 (DR); Clang 17. Lifetime extension in range-based for loops; P2718R0; No. Referencing The Unicode Standard; P2736R2; Yes. C++20 implementation status; Clang has support for some of the features of the; ISO C++ 2020 standard.; You can use Clang in C++20 mode with the -std=c++20 option; (use -std=c++2a in Clang 9 and earlier). List of features and minimum Clang version with support. Language Feature; C++20 Proposal; Available in Clang?. Default member initializers for bit-fields; P0683R1; Clang 6. const&-qualifi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_status.html:4905,inherit,inherited,4905,interpreter/llvm-project/clang/www/cxx_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_status.html,1,['inherit'],['inherited']
Modifiability,"w is set to highlight as 'llvm', despite that we; have misc.highlighting_failure set?. .. code-block:: text. declare !callback !1 dso_local i32 @pthread_create(ptr, ptr, ptr, ptr). ...; !2 = !{i64 2, i64 3, i1 false}; !1 = !{!2}. Another example is shown below. The callback callee is the second argument of; the ``__kmpc_fork_call`` function (``i64 2``). The callee is given two unknown; values (each identified by a ``i64 -1``) and afterwards all; variadic arguments that are passed to the ``__kmpc_fork_call`` call (due to the; final ``i1 true``). .. FIXME why does the llvm-sphinx-docs builder give a highlighting; error if the below is set to highlight as 'llvm', despite that we; have misc.highlighting_failure set?. .. code-block:: text. declare !callback !0 dso_local void @__kmpc_fork_call(ptr, i32, ptr, ...). ...; !1 = !{i64 2, i64 -1, i64 -1, i1 true}; !0 = !{!1}. '``exclude``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^. ``exclude`` metadata may be attached to a global variable to signify that its; section should not be included in the final executable or shared library. This; option is only valid for global variables with an explicit section targeting ELF; or COFF. This is done using the ``SHF_EXCLUDE`` flag on ELF targets and the; ``IMAGE_SCN_LNK_REMOVE`` and ``IMAGE_SCN_MEM_DISCARDABLE`` flags for COFF; targets. Additionally, this metadata is only used as a flag, so the associated; node must be empty. The explicit section should not conflict with any other; sections that the user does not want removed after linking. .. code-block:: text. @object = private constant [1 x i8] c""\00"", section "".foo"" !exclude !0. ...; !0 = !{}. '``unpredictable``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. ``unpredictable`` metadata may be attached to any branch or switch; instruction. It can be used to express the unpredictability of control; flow. Similar to the llvm.expect intrinsic, it may be used to alter; optimizations related to compare and branch instructions. The metadata; is treated as a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:291430,variab,variable,291430,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variable']
Modifiability,"w option, *ValidationSize* has been added to the global options for `MethodDL`.; The same option is also available in the `PyKeras` method of `PyMVA`; - The fast tanh implementation from VDT is now used as activation function when training the network on CPU.; - Using `Cblas` from the GSL library is supported for CPU training when no other Blas libraries are found. However, it is strongly recommended, to use an optimized Blas implementation such as `libopenblas`, that is; available in cvmfs.; - Add several performance optimizations for both CPU and GPU versions of `MethodDL`. . ### Other New TMVA Features. - Add a new option to the `DataLoader` to switch off computation of correlation matrix. The new option is called *CalcCorrelations* and it should be used when a large number of input variables are; provided, otherwise TMVA will spend a long time in setting up the data set before training. ; ; - Build configuration:; - Add new cmake flags, `tmva-cpu` and `tmva-gpu`, which can be used to swicth on/off the CPU and GPU (based on CUDA) implementations of the TMVA Deep Learning module. `tmva-cpu` is enabled by; default if a Blas or CBlas library is found in the system. `tmva-gpu` is enabled when the cmake flag `cuda` is enabled and a compatible Cuda library is found. ; enabled if the corre; - Add possibility to independently configure building of optional pymva part of tmva with flag `-Dpymva=ON|OFF`. - New Cross Validation features:; - Add stratified splitting for cross validation.; - New plotting option in cross validation, average ROC curve. - Bugfixes:; - Fix bug in BDT training with imt=on; - Improved handling of large event numbers in cross validation using deterministic splitting. - Documentation:; - Update TMVA Users' guide. ## 2D Graphics Libraries. - Highlight mode is implemented for `TH1` and for `TGraph` classes. When; highlight mode is on, mouse movement over the bin will be represented; graphically. Histograms bins or graph points will be highlighted. Moreo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md:15448,config,configuration,15448,README/ReleaseNotes/v616/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v616/index.md,1,['config'],['configuration']
Modifiability,"w to pass a string or a list of objects. The; TProof::EnablePackage interface has been extended to support this.Optimize; the validation step in the case not all the entries are required. The; validation step is stopped as soon as the requested number of events is; reached. If the parameter ""PROOF_ValidateByFile"" is set to 1, the; number of files is exactly what needed; otherwise the number of files; may exceed the number of files needed by (Number_Of_Workers - 1) .; New directive 'xpd.datadir' to better control the user data directories and their permission settings. In TPacketizerUnit, add the possibility to exactly share the number of cycles between the workers.; See the parameter PROOF_PacketizerFixedNum.Implement; a timer to terminate idle sessions. The timeout value is controlled by; the variable ProofServ.IdleTimeout (value in seconds). This variable; can be set for all sessions in the xproofd config file via the 'xpd.putrc' directive.; Add the possibility to control the use of sub-mergers with; the ROOTrc variable Proof.SubMergers. It has the same meaning of the; parameter 'PROOF_UseMergers'. The capabilities of the latter have been; extended: now -1 means disable the use of submergers (before  negative values were ignored and there was no way for the user to disable the use of submergers). . Packetizer optimizations: improved worked distribution when; the number of files left to be processed is smaller than the number of; workers and at least one file has a number of events significantly; larger than the average; better apply the upper/lower limits on the; expected packet processing time.; Add the possibility to single-out disk partitions in the; packetizer; this works adding the beginning of a path in the name; defining a new TFileNode (e.g. 'host://disk1' instead of 'host' only as; it was so far). These feature can be enabled by defining the rootrc; variable 'Packetizer.Partitions', e.g.;            Packetizer.Partitions  /disk1,/disk2,/disk3; Add to the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:6787,variab,variable,6787,proof/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html,1,['variab'],['variable']
Modifiability,"w-tests. List all of the discovered tests and exit. EXIT STATUS; -----------. :program:`lit` will exit with an exit code of 1 if there are any FAIL or XPASS; results. Otherwise, it will exit with the status 0. Other exit codes are used; for non-test related failures (for example a user error or an internal program; error). .. _test-discovery:. TEST DISCOVERY; --------------. The inputs passed to :program:`lit` can be either individual tests, or entire; directories or hierarchies of tests to run. When :program:`lit` starts up, the; first thing it does is convert the inputs into a complete list of tests to run; as part of *test discovery*. In the :program:`lit` model, every test must exist inside some *test suite*.; :program:`lit` resolves the inputs specified on the command line to test suites; by searching upwards from the input path until it finds a :file:`lit.cfg` or; :file:`lit.site.cfg` file. These files serve as both a marker of test suites; and as configuration files which :program:`lit` loads in order to understand; how to find and run the tests inside the test suite. Once :program:`lit` has mapped the inputs into test suites it traverses the; list of inputs adding tests for individual files and recursively searching for; tests in directories. This behavior makes it easy to specify a subset of tests to run, while still; allowing the test suite configuration to control exactly how tests are; interpreted. In addition, :program:`lit` always identifies tests by the test; suite they are in, and their relative path inside the test suite. For; appropriately configured projects, this allows :program:`lit` to provide; convenient and flexible support for out-of-tree builds. .. _test-status-results:. TEST STATUS RESULTS; -------------------. Each test ultimately produces one of the following eight results:. **PASS**. The test succeeded. **FLAKYPASS**. The test succeeded after being re-run more than once. This only applies to; tests containing an ``ALLOW_RETRIES:`` annot",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst:11582,config,configuration,11582,interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,1,['config'],['configuration']
Modifiability,"wait await_counter{};; a++; // __int_32_0 is still 43 here!!; std::cout << a << ""\n"";; a++; // Why is __int_32_0 still 43 here?; std::cout << a << ""\n"";; }. When debugging step-by-step, the value of `__int_32_0` seemingly does not; change, despite being frequently incremented, and instead is always `43`.; While this might be surprising, this is a result of the optimizer recognizing; that it can eliminate most of the load/store operations. The above code gets; optimized to the equivalent of:. .. code-block:: c++. static task coro_task(int v) {; store v to __int_32_0 in the frame; co_await await_counter{};; a = load __int_32_0; std::cout << a+1 << ""\n"";; std::cout << a+2 << ""\n"";; std::cout << a+3 << ""\n"";; co_await await_counter{};; a = load __int_32_0; std::cout << a+4 << ""\n"";; std::cout << a+5 << ""\n"";; }. It should now be obvious why the value of `__int_32_0` remains unchanged; throughout the function. It is important to recognize that `__int_32_0`; does not directly correspond to `a`, but is instead a variable generated; to assist the compiler in code generation. The variables in an optimized; coroutine frame should not be thought of as directly representing the; variables in the C++ source. Get the suspended points; ========================. An important requirement for debugging coroutines is to understand suspended; points, which are where the coroutine is currently suspended and awaiting. For simple cases like the above, inspecting the value of the `__coro_index`; variable in the coroutine frame works well. However, it is not quite so simple in really complex situations. In these; cases, it is necessary to use the coroutine libraries to insert the; line-number. For example:. .. code-block:: c++. // For all the promise_type we want:; class promise_type {; ...; + unsigned line_number = 0xffffffff;; };. #include <source_location>. // For all the awaiter types we need:; class awaiter {; ...; template <typename Promise>; void await_suspend(std::coroutine_handle<Pr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DebuggingCoroutines.rst:10257,variab,variable,10257,interpreter/llvm-project/clang/docs/DebuggingCoroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DebuggingCoroutines.rst,1,['variab'],['variable']
Modifiability,"warn; log();; if (a > b); return a;; return b;; }. int maxClone(int x, int y) { // similar code here; log();; if (x > y); return x;; return y;; }. alpha.core; ^^^^^^^^^^. .. _alpha-core-BoolAssignment:. alpha.core.BoolAssignment (ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Warn about assigning non-{0,1} values to boolean variables. .. code-block:: objc. void test() {; BOOL b = -1; // warn; }. .. _alpha-core-C11Lock:. alpha.core.C11Lock; """"""""""""""""""""""""""""""""""""; Similarly to :ref:`alpha.unix.PthreadLock <alpha-unix-PthreadLock>`, checks for; the locking/unlocking of ``mtx_t`` mutexes. .. code-block:: cpp. mtx_t mtx1;. void bad1(void); {; mtx_lock(&mtx1);; mtx_lock(&mtx1); // warn: This lock has already been acquired; }. .. _alpha-core-CallAndMessageUnInitRefArg:. alpha.core.CallAndMessageUnInitRefArg (C,C++, ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for logical errors for function calls and Objective-C; message expressions (e.g., uninitialized arguments, null function pointers, and pointer to undefined variables). .. code-block:: c. void test(void) {; int t;; int &p = t;; int &s = p;; int &q = s;; foo(q); // warn; }. void test(void) {; int x;; foo(&x); // warn; }. .. _alpha-core-CastSize:. alpha.core.CastSize (C); """"""""""""""""""""""""""""""""""""""""""""""; Check when casting a malloc'ed type ``T``, whether the size is a multiple of the size of ``T``. .. code-block:: c. void test() {; int *x = (int *) malloc(11); // warn; }. .. _alpha-core-CastToStruct:. alpha.core.CastToStruct (C, C++); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Check for cast from non-struct pointer to struct pointer. .. code-block:: cpp. // C; struct s {};. void test(int *p) {; struct s *ps = (struct s *) p; // warn; }. // C++; class c {};. void test(int *p) {; c *pc = (c *) p; // warn; }. .. _alpha-core-Conversion:. alpha.core.Conversion (C, C++, ObjC); """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Loss of sign/precision in implicit conversions. .. code-block:: c. void test(unsigned U, signed S) {; if (S > 10) {; if ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:48025,variab,variables,48025,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['variab'],['variables']
Modifiability,"way, any character can; be used in a name value, even quotes themselves. The ``""\01""`` prefix; can be used on global values to suppress mangling.; #. Unnamed values are represented as an unsigned numeric value with; their prefix. For example, ``%12``, ``@2``, ``%44``.; #. Constants, which are described in the section Constants_ below. LLVM requires that values start with a prefix for two reasons: Compilers; don't need to worry about name clashes with reserved words, and the set; of reserved words may be expanded in the future without penalty.; Additionally, unnamed identifiers allow a compiler to quickly come up; with a temporary variable without having to avoid symbol table; conflicts. Reserved words in LLVM are very similar to reserved words in other; languages. There are keywords for different opcodes ('``add``',; '``bitcast``', '``ret``', etc...), for primitive type names ('``void``',; '``i32``', etc...), and others. These reserved words cannot conflict; with variable names, because none of them start with a prefix character; (``'%'`` or ``'@'``). Here is an example of LLVM code to multiply the integer variable; '``%X``' by 8:. The easy way:. .. code-block:: llvm. %result = mul i32 %X, 8. After strength reduction:. .. code-block:: llvm. %result = shl i32 %X, 3. And the hard way:. .. code-block:: llvm. %0 = add i32 %X, %X ; yields i32:%0; %1 = add i32 %0, %0 ; yields i32:%1; %result = add i32 %1, %1. This last way of multiplying ``%X`` by 8 illustrates several important; lexical features of LLVM:. #. Comments are delimited with a '``;``' and go until the end of line.; #. Unnamed temporaries are created when the result of a computation is; not assigned to a named value.; #. By default, unnamed temporaries are numbered sequentially (using a; per-function incrementing counter, starting with 0). However, when explicitly; specifying temporary numbers, it is allowed to skip over numbers. Note that basic blocks and unnamed function parameters are included in this; number",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:4359,variab,variable,4359,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variable']
Modifiability,"well as the; `>>` operator overloads, are implemented only if you use `ClassDef` and; `ClassImp`. See `$ROOTSYS/include/Rtypes.h` for the definition of; `ClassDef` and `ClassImp`. To exclude a data member from the `Streamer`,; add a `!` as the first character in the comments of the field:. ``` {.cpp}; Int_t fTempValue; //! temporary state value; ```. ### The LinkDef.h File. **Step 3:** The `LinkDef.h` file tells `rootcling` which classes should; be added to the dictionary. ``` {.cpp}; #ifdef __CLING__; #pragma link C++ class SClass;; #endif; ```. Three options can trail the class name:. - `-` : tells `rootcling` **not** to generate the `Streamer` method for; this class. This is necessary for those classes that need a; customized `Streamer` method. ``` {.cpp}; #pragma link C++ class SClass-; // no streamer; ```. - **`!`** : tells `rootcling` **not** to generate the; `operator>>(`**`TBuffer`** `&b,MyClass *&obj)` method for this; class. This is necessary to be able to write pointers to objects of; classes not inheriting from **`TObject`**. ``` {.cpp}; #pragma link C++ class SClass!; // no >> operator; // or; #pragma link C++ class SClass-!; // no streamer, no >> operator; ```. - **+** : in ROOT version 1 and 2 tells `rootcling` to generate a; `Streamer` with extra byte count information. This adds an integer; to each object in the output buffer, but it allows for powerful; error correction in case a `Streamer` method is out of sync with; data in the file. The `+` option is mutual exclusive with both the; `-` and `!` options. IMPORTANT NOTE: In ROOT Version 3 and later, a ""+"" after the class name; tells `rootcling` to use the new I/O system. The byte count check is; always added. The new I/O system has many advantages including support; automatic schema evolution, full support for STL collections and better; run-time performance. We strongly recommend using it. ``` {.cpp}; #pragma link C++ class SClass+; // add byte count; ```. For information on `Streamers` see ""Input/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/AddingaClass.md:21756,inherit,inheriting,21756,documentation/users-guide/AddingaClass.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/AddingaClass.md,1,['inherit'],['inheriting']
Modifiability,"which return a reference object and a pointer object respectively. ~~~{.cxx}; #include<TRInterface.h>; ROOT::R::TRInterface &r=ROOT::R::TRInterface::Instance();; ~~~. ## Running R code and passing/getting variables.; We have different ways to run R code and pass/obtain data to/from R environment: using the methods Execute(code) and; Eval(code). ~~~{.cxx}; #include<TRInterface.h>. //creating an instance; ROOT::R::TRInterface &r=ROOT::R::TRInterface::Instance();; //executing simple r commands with the operator <<; r<<""print('hello ROOTR')"";; r<<""vec=c(1,2,3)""<<""print(vec)"";. //executing R's code using the method Execute that doesn't return anything; r.Execute(""print('hello ROOTR')"");. //We execute the code using the method Eval which returns an instance of TRObjectProxy; //which can be converted to a ROOTR supported classes; std::vector<Int_t> v=r.Eval(""c(1,2,3)"");; std::cout<<v[0]<<"" ""<<v[1]<<"" ""<<v[2]<<std::endl;. std::vector<Double_t> vd(3);. //obtaining variables from R environment using the operators [] and >>; r[""seq(0,1,0.5)""]>>vd;; std::cout<<vd[0]<<"" ""<<vd[1]<<"" ""<<vd[2]<<std::endl;. std::vector<Int_t> v1(3);; v1[0]=0;; v1[1]=1;; v1[2]=2;. r[""v1""]<<v1;; r<<""print(v1)"";. TMatrixD m(2,2);. //Creating a matrix inside r environment and converting it into a TMatrixD; r<<""mat<-matrix(c(0.1,0.2,0.3,0.4),nrow=2)"";; r[""mat""]>>m;; m.Print();; ~~~; So, working with ROOTR is like working with flows of data to pass, obtain and process data. ## Passing functions from ROOT to R; You can pass functions from ROOT to R using the operators `<<` and `=` or using the class TRFunction, but the arguments and datatypes of the return value cannot be pointers. They must be ROOTR supported datatypes.; So instead of using `*Double_t` you must use `std::vector` and instead of `*Char_t` use TString or `std::string`. For this example we need to create a macro, so save it as fun.C. ~~~{.cxx}; #include<TRInterface.h>; #include<TMath.h>. Double_t myfun(Double_t x); {; return 2*cos(x);; }. Dou",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md:4534,variab,variables,4534,bindings/r/doc/users-guide/ROOTR_Users_Guide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md,1,['variab'],['variables']
Modifiability,"while `TRandom3` generates only 32 bit random numbers.; * `TRandomRanlux48` - 48 bit Ranlux generator. Note that `TRandom1` is a 24 bit generator. ; * Improve thread safety of `TMinuit` constructor [ROOT-8217]; * Vc has ben removed from the ROOT sources. If the option 'vc' is enabled, the package will be searched (by default),; alternatively the source tarfile can be downloded and build with the option 'builtin_vc'. ## TMVA Libraries. * New `DataLoader` class that allows flexibility in variable and dataset selection. ; * New Deep Neural Network. Three different versions are available, which can be selected with the 'Architecture' option. See also the tutorial`tmva/TMVAClassification.C` for using the new DNN.; * `Architecture=STANDARD` to select the earlier version.; * `Architecture=CPU` to select the newer version for CPU, but designed also for GPU and optimized for speed and with multi-class support. ; * `Architecture=GPU` to select the newer GPU version. Requires configuration of ROOT with CUDA or OpenCL enabled. ; * Support for Cross Validation (see tutorial `tmva/TMVACrossValidation` as an example).; * Support for Hyper-Parameter tuning for BDT and SVM methods.; * New Variable Importance algorithm independent of the MVA method.; * New Loss Function class for regression.; * Improvements in the SVM method: new kernel functions.; * New `ROCCurve` class. ; * New interface to Keras (PyKeras) available in the PyMVA library.; * Support for Jupyter notebooks; * Support for all the functionality available in GUI: preprocessing, variable correlations, classifier output.; * New classifier visualization for BDT, ANN and DNN.; * Interactive training for all methods. ## 2D Graphics Libraries. * In `TColor::SetPalette`, make sure the high quality palettes are defined; only once taking care of transparency. Also `CreateGradientColorTable` has been; simplified.; * New fast constructor for `TColor` avoiding to call `gROOT->GetColor()`. The; normal constructor generated a big slow",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:13062,config,configuration,13062,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['config'],['configuration']
Modifiability,"will cause the caller to gain the attribute. This is intended; to provide a maximally conservative model where the code in a function; annotated with this attribute will always (even after inlining) end up; hardened.; ``speculatable``; This function attribute indicates that the function does not have any; effects besides calculating its result and does not have undefined behavior.; Note that ``speculatable`` is not enough to conclude that along any; particular execution path the number of calls to this function will not be; externally observable. This attribute is only valid on functions; and declarations, not on individual call sites. If a function is; incorrectly marked as speculatable and really does exhibit; undefined behavior, the undefined behavior may be observed even; if the call site is dead code. ``ssp``; This attribute indicates that the function should emit a stack; smashing protector. It is in the form of a ""canary"" --- a random value; placed on the stack before the local variables that's checked upon; return from the function to see if it has been overwritten. A; heuristic is used to determine if a function needs stack protectors; or not. The heuristic used will enable protectors for functions with:. - Character arrays larger than ``ssp-buffer-size`` (default 8).; - Aggregates containing character arrays larger than ``ssp-buffer-size``.; - Calls to alloca() with variable sizes or constant sizes greater than; ``ssp-buffer-size``. Variables that are identified as requiring a protector will be arranged; on the stack such that they are adjacent to the stack protector guard. If a function with an ``ssp`` attribute is inlined into a calling function,; the attribute is not carried over to the calling function. ``sspstrong``; This attribute indicates that the function should emit a stack smashing; protector. This attribute causes a strong heuristic to be used when; determining if a function needs stack protectors. The strong heuristic; will enable protectors f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:102831,variab,variables,102831,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variables']
Modifiability,"will match only #1. Matcher<Decl>isInstantiated; Matches declarations that are template instantiations or are inside; template instantiations. Given; template<typename T> void A(T t) { T i; }; A(0);; A(0U);; functionDecl(isInstantiated()); matches 'A(int) {...};' and 'A(unsigned) {...}'. Matcher<Decl>isPrivate; Matches private C++ declarations and C++ base specifers that specify private; inheritance. Examples:; class C {; public: int a;; protected: int b;; private: int c; // fieldDecl(isPrivate()) matches 'c'; };. struct Base {};; struct Derived1 : private Base {}; // matches 'Base'; class Derived2 : Base {}; // matches 'Base'. Matcher<Decl>isProtected; Matches protected C++ declarations and C++ base specifers that specify; protected inheritance. Examples:; class C {; public: int a;; protected: int b; // fieldDecl(isProtected()) matches 'b'; private: int c;; };. class Base {};; class Derived : protected Base {}; // matches 'Base'. Matcher<Decl>isPublic; Matches public C++ declarations and C++ base specifers that specify public; inheritance. Examples:; class C {; public: int a; // fieldDecl(isPublic()) matches 'a'; protected: int b;; private: int c;; };. class Base {};; class Derived1 : public Base {}; // matches 'Base'; struct Derived2 : Base {}; // matches 'Base'. Matcher<DesignatedInitExpr>designatorCountIsunsigned N; Matches designated initializer expressions that contain; a specific number of designators. Example: Given; point ptarray[10] = { [2].y = 1.0, [0].x = 1.0 };; point ptarray2[10] = { [2].y = 1.0, [2].x = 0.0, [0].x = 1.0 };; designatorCountIs(2); matches '{ [2].y = 1.0, [0].x = 1.0 }',; but not '{ [2].y = 1.0, [2].x = 0.0, [0].x = 1.0 }'. Matcher<EnumDecl>isScoped; Matches C++11 scoped enum declaration. Example matches Y (matcher = enumDecl(isScoped())); enum X {};; enum class Y {};. Matcher<Expr>isInstantiationDependent; Matches expressions that are instantiation-dependent even if it is; neither type- nor value-dependent. In the following example, the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html:85257,inherit,inheritance,85257,interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,1,['inherit'],['inheritance']
Modifiability,"will not need to change your Makefile. A batch program that does not have a graphic display, which creates,; fills, and saves histograms and trees, only needs to link the core; libraries (`libCore`, `libRIO`), `libHist` and `libTree`.; If ROOT needs access to other libraries, it loads them dynamically.; For example, if the **`TreeViewer`** is used, `libTreePlayer` and all; libraries `libTreePlayer` depends on are loaded also. The dependent; libraries are shown in the ROOT reference guide's library dependency; graph. The difference between reference guide `libHist` and; `libHistPainter` is that the former needs to be explicitly linked and; the latter will be loaded automatically at runtime when ROOT needs it,; by means of the Plugin Manager. plugin manager. In the Figure 1-2, the libraries represented by green boxes outside of; the core are loaded via the plugin manager plugin manager or; equivalent techniques, while the white ones are not. Of course, if one; wants to access a plugin library directly, it has to be explicitly; linked. An example of a plugin library is `libMinuit`. To create and; fill histograms you need to link `libHist.so`. If the code has a call; to fit the histogram, the ""fitter"" will dynamically load libMinuit if; it is not yet loaded. #### Plugins: Runtime Library Dependencies for Linking. plugin manager The Plugin Manager **`TPluginManager`** allows; postponing library dependencies to runtime: a plugin library will only; be loaded when it is needed. Non-plugins will need to be linked, and; are thus loaded at start-up. Plugins are defined by a base class (e.g.; **`TFile`**) that will be implemented in a plugin, a tag used to; identify the plugin (e.g. `^rfio:` as part of the protocol string),; the plugin class of which an object will be created; (e.g. **`TRFIOFile`**), the library to be loaded (in short; `libRFIO.so` to RFIO), and the constructor to be called (e.g.; ""`TRFIOFile()`""). This can be specified in the `.rootrc` which already; contains m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:18634,plugin,plugin,18634,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,1,['plugin'],['plugin']
Modifiability,"wing descriptor for the trampoline function:. .. code-block:: text. !DISubprogram(name: ""sub1_.t0p"", linkageName: ""sub1_.t0p"", scope: !4, file: !4, type: !5, spFlags: DISPFlagLocalToUnit | DISPFlagDefinition, unit: !7, retainedNodes: !24, targetFuncName: ""sub1_""). The targetFuncName field is the name of the function that the trampoline; calls. This descriptor results in the following DWARF tag:. .. code-block:: text. DW_TAG_subprogram; ...; DW_AT_linkage_name	(""sub1_.t0p""); DW_AT_name	(""sub1_.t0p""); DW_AT_trampoline	(""sub1_""). Debugging information format; ============================. Debugging Information Extension for Objective C Properties; ----------------------------------------------------------. Introduction; ^^^^^^^^^^^^. Objective C provides a simpler way to declare and define accessor methods using; declared properties. The language provides features to declare a property and; to let compiler synthesize accessor methods. The debugger lets developer inspect Objective C interfaces and their instance; variables and class variables. However, the debugger does not know anything; about the properties defined in Objective C interfaces. The debugger consumes; information generated by compiler in DWARF format. The format does not support; encoding of Objective C properties. This proposal describes DWARF extensions to; encode Objective C properties, which the debugger can use to let developers; inspect Objective C properties. Proposal; ^^^^^^^^. Objective C properties exist separately from class members. A property can be; defined only by ""setter"" and ""getter"" selectors, and be calculated anew on each; access. Or a property can just be a direct access to some declared ivar.; Finally it can have an ivar ""automatically synthesized"" for it by the compiler,; in which case the property can be referred to in user code directly using the; standard C dereference syntax as well as through the property ""dot"" syntax, but; there is no entry in the ``@interface`` declaration co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:49537,variab,variables,49537,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,2,['variab'],['variables']
Modifiability,"with GCC 5.4.0] on linux2; >>>> import cppyy_compat, cppyy; >>>>. You may have to set ``LD_LIBRARY_PATH`` appropriately if you get an; ``EnvironmentError`` (it will indicate the needed directory). Note that your python interpreter (whether CPython or ``pypy-c``) may not have; been linked by the C++ compiler.; This can lead to problems during loading of C++ libraries and program shutdown.; In that case, re-linking is highly recommended. Very old versions of PyPy (5.6.0 and earlier) have a built-in ``cppyy`` based; on `Reflex`_, which is less feature-rich and no longer supported.; However, both the :doc:`distribution utilities <utilities>` and user-facing; Python codes are very backwards compatible, making migration straightforward. Precompiled header; ------------------. For performance reasons (reduced memory and CPU usage), a precompiled header; (PCH) of the system and compiler header files will be installed or, failing; that, generated on startup.; Obviously, this PCH is not portable and should not be part of any wheel. Some compiler features, such as AVX, OpenMP, fast math, etc. need to be; active during compilation of the PCH, as they depend both on compiler flags; and system headers (for intrinsics, or API calls).; You can control compiler flags through the ``EXTRA_CLING_ARGS`` envar and thus; what is active in the PCH.; In principle, you can also change the C++ language standard by setting the; appropriate flag on ``EXTRA_CLING_ARGS`` and rebuilding the PCH.; However, if done at this stage, that disables some automatic conversion for; C++ types that were introduced after C++11 (such as ``string_view`` and; ``optional``). If you want multiple PCHs living side-by-side, you can generate them; yourself (note that the given path must be absolute)::. >>> import cppyy_backend.loader as l; >>> l.set_cling_compile_options(True) # adds defaults to EXTRA_CLING_ARGS; >>> install_path = '/full/path/to/target/location/for/PCH'; >>> l.ensure_precompiled_header(install_path).",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:7727,portab,portable,7727,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,1,['portab'],['portable']
Modifiability,"with a maximum dimension depending on the; maximum number of parameters are now data members' arrays with a; dynamic dimension such that one can fit very large problems by; simply initializing the **`TMinuit`** constructor with the maximum; number of parameters. - The include file `Minuit.h` has been commented as much as possible; using existing comments in the code or the printed documentation. - The original `Minuit` subroutines are now member functions. - Constructors and destructor have been added. - Instead of passing the `FCN` function in the argument list, the; addresses of this function is stored as pointer in the data; members of the class. This is by far more elegant and flexible in; an interactive environment. The member function `SetFCN` can be; used to define this pointer. - The ROOT static function `Printf` is provided to replace all; format statements and to print on currently defined output file. - The functions `SetObjectFit/GetObjectFit` can be used inside the; `FCN` function to set/get a referenced object instead of using; global variables. - By default `fGraphicsMode` is true. When calling the `Minuit`; functions such as `mncont`, `mnscan`, or any `Minuit` command; invoking `mnplot`, `TMinuit::mnplot()` produces a **`TGraph`**; object pointed by `fPlot`. One can retrieve this object with; **`TMinuit`**`::GetPlot().` For example:. ``` {.cpp}; h->Fit(""gaus"");; gMinuit->Command(""SCAn 1"");; TGraph *gr = (TGraph*)gMinuit->GetPlot();; gr->SetMarkerStyle(21);; gr->Draw(""alp"");; ```. - To set `Minuit` in no graphics mode, call. ``` {.cpp}; gMinuit->SetGraphicsMode(kFALSE);; ```. ### Basic Concepts of Minuit. The `Minuit` package acts on a multi parameter FORTRAN function to; which one must give the generic name `FCN`. In the ROOT; implementation, the function `FCN` is defined via the `Minuit`; `SetFCN` member function when an histogram fitting is invoked. The; value of `FCN` will in general depend on one or more variable; parameters. ### The Transformati",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:54471,variab,variables,54471,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['variab'],['variables']
Modifiability,"with base classes; P0017R1; Clang 3.9. constexpr lambda expressions; P0170R1; Clang 5. Differing begin and end types in range-based for; P0184R0; Clang 3.9. Lambda capture of *this; P0018R3; Clang 3.9. Direct-list-initialization of enums; P0138R2; Clang 3.9. Hexadecimal floating-point literals; P0245R1; Yes. Using attribute namespaces without repetition; P0028R4; Clang 3.9. Dynamic memory allocation for over-aligned data; P0035R4; Clang 4. Template argument deduction for class templates; P0091R3; Clang 5. ; P0512R0. P0620R0 (DR); Clang 7. P0702R1 (DR); Clang 6. Non-type template parameters with auto type; P0127R2; Clang 4. Guaranteed copy elision; P0135R1; Clang 4. Stricter expression evaluation order; P0145R3; Clang 4 (9). P0400R0. Requirement to ignore unknown attributes; P0283R2; Yes. constexpr if-statements; P0292R2; Clang 3.9. Inline variables; P0386R2; Clang 3.9. Structured bindings; P0217R3; Clang 4. P0961R1 (DR); Clang 8. P0969R0 (DR); Clang 8. Separate variable and condition for if and switch; P0305R1; Clang 3.9. Matching template template parameters to compatible arguments; P0522R0; Partial (10). Removing deprecated dynamic exception specifications; P0003R5; Clang 4. Pack expansions in using-declarations; P0195R2; Clang 4. (8): This is a backwards-incompatible change that is applied to; all language versions that allow type deduction from auto; (per the request of the C++ committee).; In Clang 3.7, a warning is emitted for all cases that would change meaning. (9): Under the MS ABI, function parameters are destroyed from; left to right in the callee. As a result, function parameters in calls to; operator<<, operator>>, operator->*,; operator&&, operator||, and operator,; functions using expression syntax are no longer guaranteed to be destroyed in; reverse construction order in that ABI.; This is not fully supported during constant expression evaluation until Clang 12. (10): Despite being the resolution to a Defect Report, this; feature is disabled by defaul",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_status.html:11941,variab,variable,11941,interpreter/llvm-project/clang/www/cxx_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_status.html,1,['variab'],['variable']
Modifiability,"with bitcode files; is still supported. .. _`gold linker`: http://sourceware.org/binutils; .. _`GCC LTO`: http://gcc.gnu.org/wiki/LinkTimeOptimization; .. _`gold plugin interface`: http://gcc.gnu.org/wiki/whopr/driver. .. _lto-how-to-build:. How to build it; ===============. You need to have gold with plugin support and build the LLVMgold plugin.; The gold linker is installed as ld.gold. To see whether gold is the default; on your system, run ``/usr/bin/ld -v``. It will report ""GNU; gold"" or else ""GNU ld"" if not. If gold is already installed at; ``/usr/bin/ld.gold``, one option is to simply make that the default by; backing up your existing ``/usr/bin/ld`` and creating a symbolic link; with ``ln -s /usr/bin/ld.gold /usr/bin/ld``. Alternatively, you can build; with clang's ``-fuse-ld=gold`` or add ``-fuse-ld=gold`` to LDFLAGS, which will; cause the clang driver to invoke ``/usr/bin/ld.gold`` directly. If you have gold installed, check for plugin support by running; ``/usr/bin/ld.gold -plugin``. If it complains ""missing argument"" then; you have plugin support. If not, and you get an error such as ""unknown option"",; then you will either need to build gold or install a version with plugin; support. * Download, configure and build gold with plugin support:. .. code-block:: bash. $ git clone --depth 1 git://sourceware.org/git/binutils-gdb.git binutils; $ mkdir build; $ cd build; $ ../binutils/configure --enable-gold --enable-plugins --disable-werror; $ make all-gold. That should leave you with ``build/gold/ld-new`` which supports; the ``-plugin`` option. Running ``make`` will additionally build; ``build/binutils/ar`` and ``nm-new`` binaries supporting plugins. Once you're ready to switch to using gold, backup your existing; ``/usr/bin/ld`` then replace it with ``ld-new``. Alternatively, install; in ``/usr/bin/ld.gold`` and use ``-fuse-ld=gold`` as described earlier. Optionally, add ``--enable-gold=default`` to the above configure invocation; to automatically install the ne",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GoldPlugin.rst:1831,plugin,plugin,1831,interpreter/llvm-project/llvm/docs/GoldPlugin.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GoldPlugin.rst,1,['plugin'],['plugin']
Modifiability,"with certain types of Attributes.; (`#76521 <https://github.com/llvm/llvm-project/issues/76521>`_). Miscellaneous Bug Fixes; ^^^^^^^^^^^^^^^^^^^^^^^. Miscellaneous Clang Crashes Fixed; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; - Fixed a crash when parsing top-level ObjC blocks that aren't properly; terminated. Clang should now also recover better when an @end is missing; between blocks.; `Issue 64065 <https://github.com/llvm/llvm-project/issues/64065>`_; - Fixed a crash when check array access on zero-length element.; `Issue 64564 <https://github.com/llvm/llvm-project/issues/64564>`_; - Fixed a crash when an ObjC ivar has an invalid type. See; (`#68001 <https://github.com/llvm/llvm-project/pull/68001>`_); - Fixed a crash in C when redefined struct is another nested redefinition.; `Issue 41302 <https://github.com/llvm/llvm-project/issues/41302>`_; - Fixed a crash when ``-ast-dump=json`` was used for code using class; template deduction guides.; - Fixed a crash when a lambda marked as ``static`` referenced a captured; variable in an expression.; `Issue 74608 <https://github.com/llvm/llvm-project/issues/74608>`_; - Fixed a crash with modules and a ``constexpr`` destructor.; `Issue 68702 <https://github.com/llvm/llvm-project/issues/68702>`_. OpenACC Specific Changes; ------------------------; - OpenACC Implementation effort is beginning with semantic analysis and parsing; of OpenACC pragmas. The ``-fopenacc`` flag was added to enable these new,; albeit incomplete changes. The ``_OPENACC`` macro is currently defined to; ``1``, as support is too incomplete to update to a standards-required value.; - Added ``-fexperimental-openacc-macro-override``, a command line option to; permit overriding the ``_OPENACC`` macro to be any digit-only value specified; by the user, which permits testing the compiler against existing OpenACC; workloads in order to evaluate implementation progress. Target Specific Changes; -----------------------. AMDGPU Support; ^^^^^^^^^^^^^^; - Use pass-by-refere",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst:58247,variab,variable,58247,interpreter/llvm-project/clang/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ReleaseNotes.rst,1,['variab'],['variable']
Modifiability,"with constructor/destructors. The (1<<26) bit is set and; functions are generated. The block copy helper function should, for each of the variables of the type; mentioned above, call:. .. code-block:: c. _Block_object_assign(&dst->target, src->target, BLOCK_FIELD_<apropos>);. in the copy helper and:. .. code-block:: c. _Block_object_dispose(->target, BLOCK_FIELD_<apropos>);. in the dispose helper where ``<apropos>`` is:. .. code-block:: c. enum {; BLOCK_FIELD_IS_OBJECT = 3, // id, NSObject, __attribute__((NSObject)), block, ...; BLOCK_FIELD_IS_BLOCK = 7, // a block variable; BLOCK_FIELD_IS_BYREF = 8, // the on stack structure holding the __block variable. BLOCK_FIELD_IS_WEAK = 16, // declared __weak. BLOCK_BYREF_CALLER = 128, // called from byref copy/dispose helpers; };. and of course the constructors/destructors for ``const`` copied C++ objects. The ``block_byref`` data structure similarly requires copy/dispose helpers for; block variables, ``__attribute__((NSObject))`` variables, or C++ ``const``; copied objects with constructor/destructors, and again the (1<<26) bit is set; and functions are generated in the same manner. Under ObjC we allow ``__weak`` as an attribute on ``__block`` variables, and; this causes the addition of ``BLOCK_FIELD_IS_WEAK`` orred onto the; ``BLOCK_FIELD_IS_BYREF`` flag when copying the ``block_byref`` structure in the; ``Block`` copy helper, and onto the ``BLOCK_FIELD_<apropos>`` field within the; ``block_byref`` copy/dispose helper calls. The prototypes, and summary, of the helper functions are:. .. code-block:: c. /* Certain field types require runtime assistance when being copied to the; heap. The following function is used to copy fields of types: blocks,; pointers to byref structures, and objects (including; __attribute__((NSObject)) pointers. BLOCK_FIELD_IS_WEAK is orthogonal to; the other choices which are mutually exclusive. Only in a Block copy; helper will one see BLOCK_FIELD_IS_BYREF.; */; void _Block_object_assign(void *destAd",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst:28943,variab,variables,28943,interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst,2,['variab'],['variables']
Modifiability,"with the abstract and opaque ``SCEV`` class.; Given this analysis, trip counts of loops and other important properties can be; obtained. This analysis is primarily useful for induction variable substitution and; strength reduction. ``scev-aa``: ScalarEvolution-based Alias Analysis; -------------------------------------------------. Simple alias analysis implemented in terms of ``ScalarEvolution`` queries. This differs from traditional loop dependence analysis in that it tests for; dependencies within a single iteration of a loop, rather than dependencies; between different iterations. ``ScalarEvolution`` has a more complete understanding of pointer arithmetic; than ``BasicAliasAnalysis``' collection of ad-hoc analyses. ``stack-safety``: Stack Safety Analysis; ---------------------------------------. The ``StackSafety`` analysis can be used to determine if stack allocated; variables can be considered safe from memory access bugs. This analysis' primary purpose is to be used by sanitizers to avoid unnecessary; instrumentation of safe variables. Transform Passes; ================. This section describes the LLVM Transform Passes. ``adce``: Aggressive Dead Code Elimination; ------------------------------------------. ADCE aggressively tries to eliminate code. This pass is similar to :ref:`DCE; <passes-dce>` but it assumes that values are dead until proven otherwise. This; is similar to :ref:`SCCP <passes-sccp>`, except applied to the liveness of; values. ``always-inline``: Inliner for ``always_inline`` functions; ----------------------------------------------------------. A custom inliner that handles only functions that are marked as ""always; inline"". ``argpromotion``: Promote 'by reference' arguments to scalars; -------------------------------------------------------------. This pass promotes ""by reference"" arguments to be ""by value"" arguments. In; practice, this means looking for internal functions that have pointer; arguments. If it can prove, through the use of ali",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:11696,variab,variables,11696,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['variab'],['variables']
Modifiability,"with the pointer and the corresponding bounds fields.; Despite this difference in their representations, they are still pointers in; terms of types of operations that are allowed and their semantics. For instance,; a pointer dereference on a ``__bidi_indexable`` pointer will return the; dereferenced value same as plain C pointers, modulo the extra bounds checks; being performed before dereferencing the wide pointer. This means mapping the; wide pointers to struct types with equivalent layout won’t be sufficient. To; represent the wide pointers in Clang AST, we add an extra field in the; PointerType class to indicate the internal bounds of the pointer. This ensures; pointers of different representations are mapped to different canonical types; while they are still treated as pointers. In LLVM IR, wide pointers will be emitted as structs of equivalent; representations. Clang CodeGen will handle them as Aggregate in; ``TypeEvaluationKind (TEK)``. ``AggExprEmitter`` was extended to handle pointer; operations returning wide pointers. Alternatively, a new ``TEK`` and an; expression emitter dedicated to wide pointers could be introduced. Default bounds annotations; ==========================. The model may implicitly add ``__bidi_indexable`` or ``__single`` depending on; the context of the declaration that has the pointer type. ``__bidi_indexable``; implicitly adds to local variables, while ``__single`` implicitly adds to; pointer types specifying struct fields, function parameters, or global; variables. This means the parser may first create the pointer type without any; default pointer attribute and then recreate the type once the parser has the; declaration context and determined the default attribute accordingly. This also requires the parser to reset the type of the declaration with the; newly created type with the right default attribute. Promotion expression; ====================. A new expression will be introduced to represent the conversion from a pointer; with an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst:3272,extend,extended,3272,interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BoundsSafetyImplPlans.rst,1,['extend'],['extended']
Modifiability,"with the; location description of the object since the expression has to need it. A.6 Other Debugging Information; -------------------------------. .. note::. This section provides changes to existing debugger information entry; attributes. These would be incorporated into the corresponding DWARF Version 5; chapter 6 sections. A.6.1 Accelerated Access; ~~~~~~~~~~~~~~~~~~~~~~~~. .. _amdgpu-dwarf-lookup-by-name:. A.6.1.1 Lookup By Name; ++++++++++++++++++++++. A.6.1.1.1 Contents of the Name Index; ####################################. .. note::. The following provides changes to DWARF Version 5 section 6.1.1.1. The rule for debugger information entries included in the name index in the; optional ``.debug_names`` section is extended to also include named; ``DW_TAG_variable`` debugging information entries with a ``DW_AT_location``; attribute that includes a ``DW_OP_LLVM_form_aspace_address`` operation. The name index must contain an entry for each debugging information entry that; defines a named subprogram, label, variable, type, or namespace, subject to the; following rules:. * ``DW_TAG_variable`` debugging information entries with a ``DW_AT_location``; attribute that includes a ``DW_OP_addr``, ``DW_OP_LLVM_form_aspace_address``,; or ``DW_OP_form_tls_address`` operation are included; otherwise, they are; excluded. A.6.1.1.4 Data Representation of the Name Index; ###############################################. .. _amdgpu-dwarf-name-index-section-header:. A.6.1.1.4.1 Section Header; ^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. The following provides an addition to DWARF Version 5 section 6.1.1.4.1 item; 14 ``augmentation_string``. A null-terminated UTF-8 vendor specific augmentation string, which provides; additional information about the contents of this index. If provided, the; recommended format for augmentation string is:. | ``[``\ *vendor*\ ``:v``\ *X*\ ``.``\ *Y*\ [\ ``:``\ *options*\ ]\ ``]``\ *. Where *vendor* is the producer, ``vX.Y`` specifies the major X and minor ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:186412,variab,variable,186412,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['variab'],['variable']
Modifiability,wn. more precise aliasing rules via effective type; Unknown; Unknown. restricted pointers; N448; Unknown. variable length arrays; N683; Yes. flexible array members; Unknown; Yes. static and type qualifiers in parameter array declarators; Unknown; Yes. more precise aliasing rules via effective type; Unknown; Unknown. complex and imaginary support in <complex.h>. N620; Unknown. N638; Unknown. N657; Unknown. N694; Unknown. N809; Unknown. type-generic math macros in <tgmath.h>; N693; Yes. the long long int type; N601; Yes. increase minimum translation limits; N590; Unknown. additional floating-point characteristics in <float.h>; Unknown; Unknown. remove implicit int. N635; Yes. N692; Yes. N722; Yes. reliable integer division; N617; Yes. universal character names (\u and \U); Unknown; Yes. extended identifiers; N717; Unknown. hexadecimal floating-point constants; N308. Yes. compound literals; N716; Yes. designated initializers; N494; Yes. // comments; N644; Yes. extended integer types and library functions in <inttypes.h> and <stdint.h>; Unknown. Yes. remove implicit function declaration; N636; Yes. preprocessor arithmetic done in intmax_t/uintmax_t; N736; Yes. mixed declarations and code; N740; Yes. new block scopes for selection and iteration statements; Unknown; Unknown. integer constant type rules; N629; Yes. integer promotion rules; N725; Yes. macros with a variable number of arguments; N707; Yes. IEC 60559 support; Unknown; Unknown. trailing comma allowed in enum declaration; Unknown; Yes. inline functions; N741; Yes. boolean type in <stdbool.h>; N815; Yes. idempotent type qualifiers; N505; Yes. empty macro arguments; N570; Unknown. new structure type compatibility (tag compatibility); N522; Unknown. additional predefined macro names; Unknown; Unknown. _Pragma preprocessing operator; N634. Yes. standard pragmas. N631; Unknown. N696; Unknown. __func__ predefined identifier; N611; Yes. va_copy macro; N671; Yes. LIA compatibility annex; N792; No. remove deprecation of ,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_status.html:2550,extend,extended,2550,interpreter/llvm-project/clang/www/c_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_status.html,1,['extend'],['extended']
Modifiability,"write and; run a Clang Plugin. Introduction; ============. Clang Plugins run FrontendActions over code. See the :doc:`FrontendAction; tutorial <RAVFrontendAction>` on how to write a ``FrontendAction`` using the; ``RecursiveASTVisitor``. In this tutorial, we'll demonstrate how to write a; simple clang plugin. Writing a ``PluginASTAction``; =============================. The main difference from writing normal ``FrontendActions`` is that you can; handle plugin command line options. The ``PluginASTAction`` base class declares; a ``ParseArgs`` method which you have to implement in your plugin. .. code-block:: c++. bool ParseArgs(const CompilerInstance &CI,; const std::vector<std::string>& args) {; for (unsigned i = 0, e = args.size(); i != e; ++i) {; if (args[i] == ""-some-arg"") {; // Handle the command line argument.; }; }; return true;; }. Registering a plugin; ====================. A plugin is loaded from a dynamic library at runtime by the compiler. To; register a plugin in a library, use ``FrontendPluginRegistry::Add<>``:. .. code-block:: c++. static FrontendPluginRegistry::Add<MyPlugin> X(""my-plugin-name"", ""my plugin description"");. Defining pragmas; ================. Plugins can also define pragmas by declaring a ``PragmaHandler`` and; registering it using ``PragmaHandlerRegistry::Add<>``:. .. code-block:: c++. // Define a pragma handler for #pragma example_pragma; class ExamplePragmaHandler : public PragmaHandler {; public:; ExamplePragmaHandler() : PragmaHandler(""example_pragma"") { }; void HandlePragma(Preprocessor &PP, PragmaIntroducer Introducer,; Token &PragmaTok) {; // Handle the pragma; }; };. static PragmaHandlerRegistry::Add<ExamplePragmaHandler> Y(""example_pragma"",""example pragma description"");. Defining attributes; ===================. Plugins can define attributes by declaring a ``ParsedAttrInfo`` and registering; it using ``ParsedAttrInfoRegister::Add<>``:. .. code-block:: c++. class ExampleAttrInfo : public ParsedAttrInfo {; public:; ExampleAttrInfo(",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangPlugins.rst:1168,plugin,plugin,1168,interpreter/llvm-project/clang/docs/ClangPlugins.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangPlugins.rst,1,['plugin'],['plugin']
Modifiability,"write each other. int callee (int32 arg1, int32 arg2);; int caller (int32 arg1, int32 arg2) {; return callee(arg2,arg1);; }. Here we need to push the arguments because they overwrite each; other. //===---------------------------------------------------------------------===//. main (); {; int i = 0;; unsigned long int z = 0;. do {; z -= 0x00004000;; i++;; if (i > 0x00040000); abort ();; } while (z > 0);; exit (0);; }. gcc compiles this to:. _main:; 	subl	$28, %esp; 	xorl	%eax, %eax; 	jmp	L2; L3:; 	cmpl	$262144, %eax; 	je	L10; L2:; 	addl	$1, %eax; 	cmpl	$262145, %eax; 	jne	L3; 	call	L_abort$stub; L10:; 	movl	$0, (%esp); 	call	L_exit$stub. llvm:. _main:; 	subl	$12, %esp; 	movl	$1, %eax; 	movl	$16384, %ecx; LBB1_1:	# bb; 	cmpl	$262145, %eax; 	jge	LBB1_4	# cond_true; LBB1_2:	# cond_next; 	incl	%eax; 	addl	$4294950912, %ecx; 	cmpl	$16384, %ecx; 	jne	LBB1_1	# bb; LBB1_3:	# bb11; 	xorl	%eax, %eax; 	addl	$12, %esp; 	ret; LBB1_4:	# cond_true; 	call	L_abort$stub. 1. LSR should rewrite the first cmp with induction variable %ecx.; 2. DAG combiner should fold; leal 1(%eax), %edx; cmpl $262145, %edx; =>; cmpl $262144, %eax. //===---------------------------------------------------------------------===//. define i64 @test(double %X) {; 	%Y = fptosi double %X to i64; 	ret i64 %Y; }. compiles to:. _test:; 	subl	$20, %esp; 	movsd	24(%esp), %xmm0; 	movsd	%xmm0, 8(%esp); 	fldl	8(%esp); 	fisttpll	(%esp); 	movl	4(%esp), %edx; 	movl	(%esp), %eax; 	addl	$20, %esp; 	#FP_REG_KILL; 	ret. This should just fldl directly from the input stack slot. //===---------------------------------------------------------------------===//. This code:; int foo (int x) { return (x & 65535) | 255; }. Should compile into:. _foo:; movzwl 4(%esp), %eax; orl $255, %eax; ret. instead of:; _foo:; 	movl	$65280, %eax; 	andl	4(%esp), %eax; 	orl	$255, %eax; 	ret. //===---------------------------------------------------------------------===//. We're codegen'ing multiply of long longs inefficiently:. unsigned long long LLM(un",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:20090,rewrite,rewrite,20090,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,2,"['rewrite', 'variab']","['rewrite', 'variable']"
Modifiability,"writeback dirty L2 cache; lines if configured to have multiple L2 caches.; * To ensure coherence of local memory writes of CUs in different agents a; ``buffer_wbl2 sc1`` is required. It will writeback dirty L2 cache lines.; * To ensure coherence of local memory reads of CUs with different L1 caches; in the same agent a ``buffer_inv sc1`` is required. It does nothing if the; agent is configured to have a single L2, or will invalidate non-local L2; cache lines if configured to have multiple L2 caches.; * To ensure coherence of local memory reads of CUs in different agents a; ``buffer_inv sc0 sc1`` is required. It will invalidate non-local L2 cache; lines if configured to have multiple L2 caches. * PCIe access from the GPU to the CPU can be kept coherent by using the MTYPE; UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:290014,variab,variables,290014,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['variab'],['variables']
Modifiability,"ws how we use the LogError routines. When called, this function; expects that the current token is a '(' token, but after parsing the; subexpression, it is possible that there is no ')' waiting. For example,; if the user types in ""(4 x"" instead of ""(4)"", the parser should emit an; error. Because errors can occur, the parser needs a way to indicate that; they happened: in our parser, we return null on an error. 2) Another interesting aspect of this function is that it uses recursion; by calling ``ParseExpression`` (we will soon see that; ``ParseExpression`` can call ``ParseParenExpr``). This is powerful; because it allows us to handle recursive grammars, and keeps each; production very simple. Note that parentheses do not cause construction; of AST nodes themselves. While we could do it this way, the most; important role of parentheses are to guide the parser and provide; grouping. Once the parser constructs the AST, parentheses are not; needed. The next simple production is for handling variable references and; function calls:. .. code-block:: c++. /// identifierexpr; /// ::= identifier; /// ::= identifier '(' expression* ')'; static std::unique_ptr<ExprAST> ParseIdentifierExpr() {; std::string IdName = IdentifierStr;. getNextToken(); // eat identifier. if (CurTok != '(') // Simple variable ref.; return std::make_unique<VariableExprAST>(IdName);. // Call.; getNextToken(); // eat (; std::vector<std::unique_ptr<ExprAST>> Args;; if (CurTok != ')') {; while (true) {; if (auto Arg = ParseExpression()); Args.push_back(std::move(Arg));; else; return nullptr;. if (CurTok == ')'); break;. if (CurTok != ','); return LogError(""Expected ')' or ',' in argument list"");; getNextToken();; }; }. // Eat the ')'.; getNextToken();. return std::make_unique<CallExprAST>(IdName, std::move(Args));; }. This routine follows the same style as the other routines. (It expects; to be called if the current token is a ``tok_identifier`` token). It; also has recursion and error handling. One interes",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl02.rst:9547,variab,variable,9547,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl02.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl02.rst,1,['variab'],['variable']
Modifiability,"wser is reloaded; - load of widgets code only when really required (shorter startup time for RBrowser). ## Montecarlo Libraries. ## PROOF Libraries. ## Language Bindings. ## JavaScript ROOT. ### Major JSROOT update to version 6. - update all used libraries `d3.js`, `three.js`, `MathJax.js`, openui5; - change to Promise based interface for all async methods, remove call-back arguments; - change scripts names, core scripts name now `JSRoot.core.js`; - unify function/methods naming conventions, many changes in method names; - provide central code loader via `JSROOT.require`, supporting 4 different loading engines; - many nice features and many bug fixes; see JSROOT v6 release notes. ## Tutorials. ## Class Reference Guide. ## Build, Configuration and Testing Infrastructure. - a new cmake variable, `CMAKE_INSTALL_PYTHONDIR`, has been added: it allows customization of the installation directory of ROOT's python modules; - the developer build option `asserts` is introduced to enable/disable asserts via the `NDEBUG` C/CXX flag. Asserts are always enabled for `CMAKE_BUILD_TYPE=Debug` and `dev=ON`. The previous behavior of the builds set via the `CMAKE_BUILD_TYPE` variable has not changed.; - `CMAKE_CXX_STANDARD`, i.e. the C++ standard ROOT is built with, now defaults to the compiler default (or C++11 if the compiler default is older than that) rather than always defaulting to C++11. In turn this means that v6.24 is the first ROOT release for which ROOT's pre-compiled binaries are not compiled with C++11 but with the default standard in use by the default system compiler. On Ubuntu 20.04, for example, the v6.24 pre-compiled binaries are now compiled with C++14 rather than C++11 as it happened for previous ROOT versions. Also see [ROOT-10692](https://sft.its.cern.ch/jira/browse/ROOT-10692). The following builtins have been updated:. - VecCore 0.7.0. ## PyROOT. - Deprecate `TTree.AsMatrix` in this release and mark for removal in v6.26. Please use instead `RDataFrame.AsNumpy`.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:28335,variab,variable,28335,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['variab'],['variable']
Modifiability,"x -march=armv8+memtag`` to compilation flags. Implementation; ==============. See `HardwareAssistedAddressSanitizer`_ for a general overview of a; tag-based approach to memory safety. MemTagSanitizer follows a; similar implementation strategy, but with the tag storage (shadow); provided by the hardware. A quick overview of MTE hardware capabilities:. * Every 16 aligned bytes of memory can be assigned a 4-bit Allocation Tag.; * Every pointer can have a 4-bit Address Tag that is in its most significant byte.; * Most memory access instructions generate an exception if Address Tag != Allocation Tag.; * Special instructions are provided for fast tag manipulation. Stack instrumentation; =====================. Stack-based memory errors are detected by updating Allocation Tag for; each local variable to a random value at the start of its lifetime,; and resetting it to the stack pointer Address Tag at the end of; it. Unallocated stack space is expected to match the Address Tag of; SP; this allows to skip tagging of any variable when memory safety can; be statically proven. Allocating a truly random tag for each stack variable in a large; function may incur significant code size overhead, because it means; that each variable's address is an independent, non-rematerializable; value; thus a function with N local variables will have extra N live; values to keep through most of its life time. For this reason MemTagSanitizer generates at most one random tag per; function, called a ""base tag"". Other stack variables, if there are; any, are assigned tags at a fixed offset from the base. Please refer to `this document; <https://github.com/google/sanitizers/wiki/Stack-instrumentation-with-ARM-Memory-Tagging-Extension-(MTE)>`_; for more details about stack instrumentation. Heap tagging; ============. **Note:** this part is not implemented as of Oct 2019. MemTagSanitizer will use :doc:`ScudoHardenedAllocator`; with additional code to update memory tags when. * New memory is obtained from ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemTagSanitizer.rst:2158,variab,variable,2158,interpreter/llvm-project/llvm/docs/MemTagSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemTagSanitizer.rst,1,['variab'],['variable']
Modifiability,"x i32> @llvm.vp.sext.nxv4i32.nxv4i16 (<vscale x 4 x i16> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". The '``llvm.vp.sext``' intrinsic sign extends its first operand to the return; type. The operation has a mask and an explicit vector length parameter. Arguments:; """""""""""""""""""". The '``llvm.vp.sext``' intrinsic takes a value to cast as its first operand.; The return type is the type to cast the value to. Both types must be vectors of; :ref:`integer <t_integer>` type. The bit size of the value must be smaller than; the bit size of the return type. The second operand is the vector mask. The; return type, the value to cast, and the vector mask have the same number of; elements. The third operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.sext``' intrinsic performs a sign extension by copying the sign; bit (highest order bit) of the value until it reaches the size of the return; type. When sign extending from i1, the result will always be either -1 or 0.; The conversion is performed on lane positions below the explicit vector length; and where the vector mask is true. Masked-off lanes are ``poison``. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x i32> @llvm.vp.sext.v4i32.v4i16(<4 x i16> %a, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = sext <4 x i16> %a to <4 x i32>; %also.r = select <4 x i1> %mask, <4 x i32> %t, <4 x i32> poison. .. _int_vp_fptrunc:. '``llvm.vp.fptrunc.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.fptrunc.v16f32.v16f64 (<16 x double> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.trunc.nxv4f32.nxv4f64 (<vscale x 4 x double> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". The '``llvm.vp.fptrunc``' intrinsic truncates its first operand to the return; type. The oper",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:800519,extend,extending,800519,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['extend'],['extending']
Modifiability,"x i8]`` | Array of 4 8-bit integer values. |; +------------------+--------------------------------------+. Here are some examples of multidimensional arrays:. +-----------------------------+----------------------------------------------------------+; | ``[3 x [4 x i32]]`` | 3x4 array of 32-bit integer values. |; +-----------------------------+----------------------------------------------------------+; | ``[12 x [10 x float]]`` | 12x10 array of single precision floating-point values. |; +-----------------------------+----------------------------------------------------------+; | ``[2 x [3 x [4 x i16]]]`` | 2x3x4 array of 16-bit integer values. |; +-----------------------------+----------------------------------------------------------+. There is no restriction on indexing beyond the end of the array implied; by a static type (though there are restrictions on indexing beyond the; bounds of an allocated object in some cases). This means that; single-dimension 'variable sized array' addressing can be implemented in; LLVM with a zero length array type. An implementation of 'pascal style; arrays' in LLVM could use the type ""``{ i32, [0 x float]}``"", for; example. .. _t_struct:. Structure Type; """""""""""""""""""""""""""". :Overview:. The structure type is used to represent a collection of data members; together in memory. The elements of a structure may be any type that has; a size. Structures in memory are accessed using '``load``' and '``store``' by; getting a pointer to a field with the '``getelementptr``' instruction.; Structures in registers are accessed using the '``extractvalue``' and; '``insertvalue``' instructions. Structures may optionally be ""packed"" structures, which indicate that; the alignment of the struct is one byte, and that there is no padding; between the elements. In non-packed structs, padding between field types; is inserted as defined by the DataLayout string in the module, which is; required to match what the underlying code generator expects. Structures can e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:180978,variab,variable,180978,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variable']
Modifiability,"x is defined by the following BNF syntax:. .. code::. <target-id> ::== <processor> ( "":"" <target-feature> ( ""+"" | ""-"" ) )*. Where:. **processor**; Is a the target specific processor or any alternative processor name. **target-feature**; Is a target feature name that is supported by the processor. Each target; feature must appear at most once in a target ID and can have one of three; values:. *Any*; Specified by omitting the target feature from the target ID.; A code object compiled with a target ID specifying the default; value of a target feature can be loaded and executed on a processor; configured with the target feature on or off. *On*; Specified by ``+``, indicating the target feature is enabled. A code; object compiled with a target ID specifying a target feature on; can only be loaded on a processor configured with the target feature on. *Off*; specified by ``-``, indicating the target feature is disabled. A code; object compiled with a target ID specifying a target feature off; can only be loaded on a processor configured with the target feature off. .. _compatibility-target-id:. Compatibility Rules for Target ID; ---------------------------------. A code object compiled for a Target ID is considered compatible for a; target, if:. * Their processor is same.; * Their feature set is compatible as defined above. There are two forms of target ID:. *Non-Canonical Form*; The non-canonical form is used as the input to user commands to allow the user; greater convenience. It allows both the primary and alternative processor name; to be used and the target features may be specified in any order. *Canonical Form*; The canonical form is used for all generated output to allow greater; convenience for tools that consume the information. It is also used for; internal passing of information between tools. Only the primary and not; alternative processor name is used and the target features are specified in; alphabetic order. Command line tools convert non-canonical form to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst:12541,config,configured,12541,interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst,1,['config'],['configured']
Modifiability,"x is {3}; }; // x is ⊤; }; ```. ### Uninitialized variables and ""bottom"" values. When `x` is declared but not initialized, it has no possible values. We; represent this fact symbolically as `⊥` (pronounced ""bottom""). ```c++; void ExampleOfBottom() {; int x; // x is ⊥; x = 42; // x is {42}; print(x);; }; ```. Note that using values read from uninitialized variables is undefined behaviour; in C++. Generally, compilers and static analysis tools can assume undefined; behavior does not happen. We must model uninitialized variables only when we are; implementing a checker that specifically is trying to find uninitialized reads.; In this example we show how to model uninitialized variables only to demonstrate; the concept of ""bottom"", and how it applies to possible value analysis. We; describe an analysis that finds uninitialized reads in a section below. ### A practical lattice that tracks sets of concrete values. Taking into account all corner cases covered above, we can put together a; lattice that we can use in practice to track possible values of integer; variables. This lattice represents sets of integers with 1, 2, or 3 elements, as; well as top and bottom. Here is a Hasse diagram for it:. ![Hasse diagram for a lattice of integer sets](DataFlowAnalysisIntroImages/IntegerSetsFiniteLattice.svg). ### Formalization. Let's consider a slightly more complex example, and think about how we can; compute the sets of possible values algorithmically. ```c++; void Example(int n) {; int x; // x is ⊥; if (n > 0) {; if (n == 42) {; x = 44; // x is {44}; } else {; x = 5; // x is {5}; }; print(x); // x is {44; 5}; } else {; x = n; // x is ⊤; }; print(x); // x is ⊤; }; ```. As humans, we understand the control flow from the program text. We used our; understanding of control flow to find program points where two flows join.; Formally, control flow is represented by a CFG (control flow graph):. ![CFG for the code above](DataFlowAnalysisIntroImages/CFGExample.svg). We can compute sets of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:6770,variab,variables,6770,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,1,['variab'],['variables']
Modifiability,"x to append to the directory where libraries are to be; installed. On a 64-bit architecture, one could use ``-DLLVM_LIBDIR_SUFFIX=64``; to install libraries to ``/usr/lib64``. **LLVM_PARALLEL_{COMPILE,LINK}_JOBS**:STRING; Building the llvm toolchain can use a lot of resources, particularly; linking. These options, when you use the Ninja generator, allow you; to restrict the parallelism. For example, to avoid OOMs or going; into swap, permit only one link job per 15GB of RAM available on a; 32GB machine, specify ``-G Ninja -DLLVM_PARALLEL_LINK_JOBS=2``. **LLVM_TARGETS_TO_BUILD**:STRING; Control which targets are enabled. For example you may only need to enable; your native target with, for example, ``-DLLVM_TARGETS_TO_BUILD=X86``. .. _llvm_use_linker:. **LLVM_USE_LINKER**:STRING; Override the system's default linker. For instance use ``lld`` with; ``-DLLVM_USE_LINKER=lld``. Rarely-used CMake variables; ---------------------------. Here are some of the CMake variables that are rarely used, along with a brief; explanation and LLVM-related notes. For full documentation, consult the CMake; manual, or execute ``cmake --help-variable VARIABLE_NAME``. **CMAKE_CXX_STANDARD**:STRING; Sets the C++ standard to conform to when building LLVM. Possible values are; 17 and 20. LLVM Requires C++ 17 or higher. This defaults to 17. **CMAKE_INSTALL_BINDIR**:PATH; The path to install executables, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""bin"". **CMAKE_INSTALL_INCLUDEDIR**:PATH; The path to install header files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""include"". **CMAKE_INSTALL_DOCDIR**:PATH; The path to install documentation, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/doc"". **CMAKE_INSTALL_MANDIR**:PATH; The path to install manpage files, relative to the *CMAKE_INSTALL_PREFIX*.; Defaults to ""share/man"". .. _LLVM-related variables:. LLVM-related variables; -----------------------. These variables provide fine control over the build of LLVM and; ena",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:10391,variab,variables,10391,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['variab'],['variables']
Modifiability,"x was updated from 0.6.4 to 0.6.7 (support for OpenSSL 1.1, [ROOT-9353](https://sft.its.cern.ch/jira/browse/ROOT-9353)); - Vdt has been updated from 0.3.9 to 0.4.1 (includes new atan function); - XRootd has been updated from 4.6.1 to 4.8.2 (for GCC 8.x support); - Builtin TBB can now be used on Windows; - xxHash and LZ4 have been separated so that a system version of LZ4 can be used even if it does not include xxHash headers ([ROOT-9099](https://sft.its.cern.ch/jira/browse/ROOT-9099)); - In addition, several updates have been made to fix minor build system issues, such as not checking for external packages if their builtin is turned off, or checking for packages even when the respective option is disabled ([ROOT-8806](https://sft.its.cern.ch/jira/browse/ROOT-8806), [ROOT-9190](https://sft.its.cern.ch/jira/browse/ROOT-9190), [ROOT-9315](https://sft.its.cern.ch/jira/browse/ROOT-9315), [ROOT-9385](https://sft.its.cern.ch/jira/browse/ROOT-9385)).; - The `python3` option to CMake has been removed ([ROOT-9033](https://sft.its.cern.ch/jira/browse/ROOT-9033), [ROOT-9143](https://sft.its.cern.ch/jira/browse/ROOT-9143)). Python support is enabled by default. To configure ROOT to use specific Python versions, there is a new option called `python_version`. This is how to configure ROOT and Python for the common use cases:. * Use the default Python interpreter:; - `-Dpython=ON` (default); * Search only for Python 2.x or only 3.x:; - `-Dpython_version=2` or `-Dpython_version=3`; * Use a specific version of Python from `$PATH`:; - `-Dpython_version=2.7` or `-Dpython_version=3.5`; * Use a specific Python interpreter, whatever the version:; - `-DPYTHON_EXECUTABLE=/usr/local/bin/python`. Note: The use of `PYTHON_EXECUTABLE` requires the full path to the interpreter. ## Infrastructure and Testing. - Reduce time taken by tests which takes too long to run ({One,Two}SidedFrequentistUpperLimitWithBands.C); - Disable PyROOT SQL tutorials (the C++ counterparts are since several releases).; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md:19589,config,configure,19589,README/ReleaseNotes/v614/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v614/index.md,2,['config'],['configure']
Modifiability,"x) {; for (unsigned I = 0; I < 10; ++I) { BAR(I); }; }; int main() {; foo<int>(0);; foo<float>(0);; return 0;; }; EOF. Compiling with coverage enabled; ===============================. To compile code with coverage enabled, pass ``-fprofile-instr-generate; -fcoverage-mapping`` to the compiler:. .. code-block:: console. # Step 1: Compile with coverage enabled.; % clang++ -fprofile-instr-generate -fcoverage-mapping foo.cc -o foo. Note that linking together code with and without coverage instrumentation is; supported. Uninstrumented code simply won't be accounted for in reports. To compile code with Modified Condition/Decision Coverage (MC/DC) enabled,; pass ``-fcoverage-mcdc`` in addition to the clang options specified above.; MC/DC is an advanced form of code coverage most applicable in the embedded; space. Running the instrumented program; ================================. The next step is to run the instrumented program. When the program exits it; will write a **raw profile** to the path specified by the ``LLVM_PROFILE_FILE``; environment variable. If that variable does not exist, the profile is written; to ``default.profraw`` in the current directory of the program. If; ``LLVM_PROFILE_FILE`` contains a path to a non-existent directory, the missing; directory structure will be created. Additionally, the following special; **pattern strings** are rewritten:. * ""%p"" expands out to the process ID. * ""%h"" expands out to the hostname of the machine running the program. * ""%t"" expands out to the value of the ``TMPDIR`` environment variable. On; Darwin, this is typically set to a temporary scratch directory. * ""%Nm"" expands out to the instrumented binary's signature. When this pattern; is specified, the runtime creates a pool of N raw profiles which are used for; on-line profile merging. The runtime takes care of selecting a raw profile; from the pool, locking it, and updating it before the program exits. If N is; not specified (i.e the pattern is ""%m""), it's assumed that",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst:2251,variab,variable,2251,interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,1,['variab'],['variable']
Modifiability,"x,y,z);; h3->Fill(x,y,z,w);; ```. The `Fill` method computes the bin number corresponding to the given; x, y or z argument and increments this bin by the given weight. The; `Fill()` method returns the bin number for 1-D histograms or global; bin number for 2-D and 3-D histograms. If **`TH1`**`::Sumw2()` has; been called before filling, the sum of squares is also stored. One can; increment a bin number directly by calling; **`TH1`**`::AddBinContent()`, replace the existing content via; **`TH1`**`::SetBinContent()` , and access the bin content of a given; bin via **`TH1`**`::GetBinContent()` . ``` {.cpp}; Double_t binContent = h->GetBinContent(bin);; ```. ### Automatic Re-binning Option. By default, the number of bins is computed using the range of the; axis. You can change this to re-bin automatically by setting the; automatic re-binning option:. ``` {.cpp}; h->SetBit(TH1::kCanRebin);; ```; \index{histogram!rebin}. Once this is set, the `Fill()` method will automatically extend the; axis range to accommodate the new value specified in the `Fill()`; argument. The used method is to double the bin size until the new; value fits in the range, merging bins two by two. The; **`TTree`**`::Draw()` method extensively uses this automatic binning; option when drawing histograms of variables in **`TTree`** with an; unknown range. The automatic binning option is supported for 1-D, 2-D; and 3-D histograms. During filling, some statistics parameters are; incremented to compute the mean value and root mean square with the; maximum precision. In case of histograms of type **`TH1C`**,; **`TH1S`**, **`TH2C`**, **`TH2S`**, **`TH3C`**, **`TH3S`** a check is; made that the bin contents do not exceed the maximum positive capacity; (127 or 65 535). Histograms of all types may have positive or/and; negative bin contents. ## Random Numbers and Histograms. **`TH1`**`::FillRandom()` can be used to randomly fill a histogram; using the contents of an existing **`TF1`** function or another; **`TH1",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Histograms.md:8404,extend,extend,8404,documentation/users-guide/Histograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Histograms.md,1,['extend'],['extend']
Modifiability,x/PostingList.h; clang-tools-extra/clangd/index/dex/Token.h; clang-tools-extra/clangd/index/dex/Trigram.cpp; clang-tools-extra/clangd/index/dex/Trigram.h; clang-tools-extra/clangd/index/dex/dexp/Dexp.cpp; clang-tools-extra/clangd/index/remote/Client.cpp; clang-tools-extra/clangd/index/remote/Client.h; clang-tools-extra/clangd/index/remote/marshalling/Marshalling.cpp; clang-tools-extra/clangd/index/remote/marshalling/Marshalling.h; clang-tools-extra/clangd/index/remote/monitor/Monitor.cpp; clang-tools-extra/clangd/index/remote/server/Server.cpp; clang-tools-extra/clangd/index/remote/unimplemented/UnimplementedClient.cpp; clang-tools-extra/clangd/indexer/IndexerMain.cpp; clang-tools-extra/clangd/refactor/InsertionPoint.cpp; clang-tools-extra/clangd/refactor/InsertionPoint.h; clang-tools-extra/clangd/refactor/Rename.h; clang-tools-extra/clangd/refactor/Tweak.cpp; clang-tools-extra/clangd/refactor/Tweak.h; clang-tools-extra/clangd/refactor/tweaks/AddUsing.cpp; clang-tools-extra/clangd/refactor/tweaks/AnnotateHighlightings.cpp; clang-tools-extra/clangd/refactor/tweaks/DefineInline.cpp; clang-tools-extra/clangd/refactor/tweaks/DefineOutline.cpp; clang-tools-extra/clangd/refactor/tweaks/DumpAST.cpp; clang-tools-extra/clangd/refactor/tweaks/ExpandMacro.cpp; clang-tools-extra/clangd/refactor/tweaks/ExtractFunction.cpp; clang-tools-extra/clangd/refactor/tweaks/ObjCLocalizeStringLiteral.cpp; clang-tools-extra/clangd/refactor/tweaks/RemoveUsingNamespace.cpp; clang-tools-extra/clangd/refactor/tweaks/SwapIfBranches.cpp; clang-tools-extra/clangd/support/Cancellation.cpp; clang-tools-extra/clangd/support/Cancellation.h; clang-tools-extra/clangd/support/Context.cpp; clang-tools-extra/clangd/support/Context.h; clang-tools-extra/clangd/support/FileCache.cpp; clang-tools-extra/clangd/support/FileCache.h; clang-tools-extra/clangd/support/Function.h; clang-tools-extra/clangd/support/Logger.cpp; clang-tools-extra/clangd/support/Markup.cpp; clang-tools-extra/clangd/support/Markup.h; clang-,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:80318,refactor,refactor,80318,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['refactor'],['refactor']
Modifiability,"x170fa80 'N' 'const int'))); (UnaryOperator 0x173b0b0 'int' lvalue prefix '++'; (DeclRefExpr 0x173b088 'int' lvalue Var 0x173af50 'i' 'int')); (CompoundStatement ... We already know that the declaration and increments both match, or this; loop wouldn't have been dumped. The culprit lies in the implicit cast; applied to the first operand (i.e. the LHS) of the less-than operator,; an L-value to R-value conversion applied to the expression referencing; ``i``. Thankfully, the matcher library offers a solution to this problem; in the form of ``ignoringParenImpCasts``, which instructs the matcher to; ignore implicit casts and parentheses before continuing to match.; Adjusting the condition operator will restore the desired match. .. code-block:: c++. hasCondition(binaryOperator(; hasOperatorName(""<""),; hasLHS(ignoringParenImpCasts(declRefExpr(; to(varDecl(hasType(isInteger())))))),; hasRHS(expr(hasType(isInteger()))))). After adding binds to the expressions we wished to capture and; extracting the identifier strings into variables, we have array-step-2; completed. Step 4: Retrieving Matched Nodes; ================================. So far, the matcher callback isn't very interesting: it just dumps the; loop's AST. At some point, we will need to make changes to the input; source code. Next, we'll work on using the nodes we bound in the; previous step. The ``MatchFinder::run()`` callback takes a; ``MatchFinder::MatchResult&`` as its parameter. We're most interested in; its ``Context`` and ``Nodes`` members. Clang uses the ``ASTContext``; class to represent contextual information about the AST, as the name; implies, though the most functionally important detail is that several; operations require an ``ASTContext*`` parameter. More immediately useful; is the set of matched nodes, and how we retrieve them. Since we bind three variables (identified by ConditionVarName,; InitVarName, and IncrementVarName), we can obtain the matched nodes by; using the ``getNodeAs()`` member functi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersTutorial.rst:15553,variab,variables,15553,interpreter/llvm-project/clang/docs/LibASTMatchersTutorial.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersTutorial.rst,1,['variab'],['variables']
Modifiability,"x[] = { { 1.0f, 1.0f } }; // [0] = (1, 1); complex float x[] = { 1.0f, 1.0f }; // [0] = (1, 0), [1] = (1, 0). This extension also works in C++ mode, as far as that goes, but does not apply; to the C++ ``std::complex``. (In C++11, list initialization allows the same; syntax to be used with ``std::complex`` with the same meaning.). For GCC compatibility, ``__builtin_complex(re, im)`` can also be used to; construct a complex number from the given real and imaginary components. OpenCL Features; ===============. Clang supports internal OpenCL extensions documented below. ``__cl_clang_bitfields``; --------------------------------. With this extension it is possible to enable bitfields in structs; or unions using the OpenCL extension pragma mechanism detailed in; `the OpenCL Extension Specification, section 1.2; <https://www.khronos.org/registry/OpenCL/specs/3.0-unified/html/OpenCL_Ext.html#extensions-overview>`_. Use of bitfields in OpenCL kernels can result in reduced portability as struct; layout is not guaranteed to be consistent when compiled by different compilers.; If structs with bitfields are used as kernel function parameters, it can result; in incorrect functionality when the layout is different between the host and; device code. **Example of Use**:. .. code-block:: c++. #pragma OPENCL EXTENSION __cl_clang_bitfields : enable; struct with_bitfield {; unsigned int i : 5; // compiled - no diagnostic generated; };. #pragma OPENCL EXTENSION __cl_clang_bitfields : disable; struct without_bitfield {; unsigned int i : 5; // error - bitfields are not supported; };. ``__cl_clang_function_pointers``; --------------------------------. With this extension it is possible to enable various language features that; are relying on function pointers using regular OpenCL extension pragma; mechanism detailed in `the OpenCL Extension Specification,; section 1.2; <https://www.khronos.org/registry/OpenCL/specs/3.0-unified/html/OpenCL_Ext.html#extensions-overview>`_. In C++ for OpenCL t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:85946,portab,portability,85946,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['portab'],['portability']
Modifiability,"x`. ``` {.cpp}; ""temp:mass:px""; ```. The symbols used for the type are:. - `C`: a character string terminated by the 0 character; - `B`: an 8 bit signed integer; - `b`: an 8 bit unsigned integer; - `S`: a 16 bit signed integer; - `s`: a 16 bit unsigned integer; - `I`: a 32 bit signed integer; - `i`: a 32 bit unsigned integer; - `L`: a 64 bit signed integer; - `l`: a 64 bit unsigned integer; - `G`: a long signed integer, stored as 64 bit; - `g`: a long unsigned integer, stored as 64 bit; - `F`: a 32 bit floating point; - `D`: a 64 bit floating point; - `O`: [the letter 'o', not a zero] a boolean (Bool\_t). The type is used for a byte count to decide how much space to allocate.; The variable written is simply the block of bytes starting at the; starting address given in the second parameter. It may or may not match; the leaf list depending on whether or not the programmer is being; careful when choosing the leaf address, name, and type. By default, a variable will be copied with the number of bytes specified; in the type descriptor symbol. However, if the type consists of two; characters, the number specifies the number of bytes to be used when; copying the variable to the output buffer. The line below describes; `ntrack` to be written as a 16-bit integer (rather than a 32-bit; integer). ``` {.cpp}; ""ntrack/I2""; ```. With this Branch method, you can also add a leaf that holds an entire; array of variables. To add an array of floats use the `f[n]` notation; when describing the leaf. ``` {.cpp}; Float_t f[10];; tree->Branch(""fBranch"",f,""f[10]/F"");; ```. You can also add an array of variable length:. ``` {.cpp}; {; TFile *f = new TFile(""peter.root"",""recreate"");; Int_t nPhot;; Float_t E[500];; TTree* nEmcPhotons = new TTree(""nEmcPhotons"",""EMC Photons"");; nEmcPhotons->Branch(""nPhot"",&nPhot,""nPhot/I"");; nEmcPhotons->Branch(""E"",E,""E[nPhot]/F"");; }; ```. See ""Example 2: A Tree with a C Structure"" below; (`$ROOTSYS/tutorials/tree/tree2.C`) and `staff.C` at the beginning of; thi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:22035,variab,variable,22035,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['variab'],['variable']
Modifiability,"xamples, it now should be; clear how easy it is to convert any ROOT Macro in C++ to a Python version. As another example, let us revisit macro3 from Chapter 4. A straight-forward; Python version relying on the ROOT class `TMath`:. ``` {.python}; @ROOT_INCLUDE_FILE macros/macro3.py; ```. ### More Python- less C++ ###. You may have noticed already that there are some Python modules providing; functionality similar to ROOT classes, which fit more seamlessly into your; Python code. A more “pythonic” version of the above macro3 would use a replacement of the; ROOT class TMath for the provisioning of data to TGraphPolar. With the math; package, the part of the code becomes. ``` {.cpp}; import math; from array import array; from ROOT import TCanvas , TGraphPolar; ...; ipt=range(0,npoints); r=array('d',map(lambda x: x*(rmax-rmin)/(npoints-1.)+rmin,ipt)); theta=array('d',map(math.sin,r)); e=array('d',npoints*[0.]); ... ```. #### Customised Binning ####; This example combines comfortable handling of arrays in Python to define; variable bin sizes of a ROOT histogram. All we need to know is the interface; of the relevant ROOT class and its methods (from the ROOT documentation):. ``` {.cpp}; TH1F(const char* name , const char* title , Int_t nbinsx , const Double_t* xbins); ```. Here is the Python code:. ``` {.python}; import ROOT; from array import array; arrBins = array('d' ,(1 ,4 ,9 ,16) ) # array of bin edges; histo = ROOT.TH1F(""hist"", ""hist"", len(arrBins)-1, arrBins); # fill it with equally spaced numbers; for i in range (1 ,16) :; histo.Fill(i); histo.Draw (); ```. ## Custom code: from C++ to Python ##; The ROOT interpreter and type sytem offer interesting possibilities when it comes; to JITting of C++ code.; Take for example this header file, containing a class and a function. ```{.cpp}; // file cpp2pythonExample.h; #include ""stdio.h"". class A{; public:; A(int i):m_i(i){}; int getI() const {return m_i;}; private:; int m_i=0;; };. void printA(const A& a ){; printf (""The val",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/root_in_python.md:2865,variab,variable,2865,documentation/primer/root_in_python.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/root_in_python.md,1,['variab'],['variable']
Modifiability,"xes that are allowed in the; file-to-main-include mapping. When guessing whether a #include is the ""main"" include (to assign; category 0, see above), use this regex of allowed suffixes to the header; stem. A partial match is done, so that:; - """" means ""arbitrary suffix""; - ""$"" means ""no suffix"". For example, if configured to ""(_test)?$"", then a header a.h would be seen; as the ""main"" include in both a.cc and a_test.cc. .. _IncludeIsMainSourceRegex:. **IncludeIsMainSourceRegex** (``String``) :versionbadge:`clang-format 10` :ref:`¶ <IncludeIsMainSourceRegex>`; Specify a regular expression for files being formatted; that are allowed to be considered ""main"" in the; file-to-main-include mapping. By default, clang-format considers files as ""main"" only when they end; with: ``.c``, ``.cc``, ``.cpp``, ``.c++``, ``.cxx``, ``.m`` or ``.mm``; extensions.; For these files a guessing of ""main"" include takes place; (to assign category 0, see above). This config option allows for; additional suffixes and extensions for files to be considered as ""main"". For example, if this option is configured to ``(Impl\.hpp)$``,; then a file ``ClassImpl.hpp`` is considered ""main"" (in addition to; ``Class.c``, ``Class.cc``, ``Class.cpp`` and so on) and ""main; include file"" logic will be executed (with *IncludeIsMainRegex* setting; also being respected in later phase). Without this option set,; ``ClassImpl.hpp`` would not have the main include file put on top; before any other include. .. _IndentAccessModifiers:. **IndentAccessModifiers** (``Boolean``) :versionbadge:`clang-format 13` :ref:`¶ <IndentAccessModifiers>`; Specify whether access modifiers should have their own indentation level. When ``false``, access modifiers are indented (or outdented) relative to; the record members, respecting the ``AccessModifierOffset``. Record; members are indented one level below the record.; When ``true``, access modifiers get their own indentation level. As a; consequence, record members are always indented 2 ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:69157,config,config,69157,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['config'],['config']
Modifiability,"xity reaching the specialized topics at the end. The; experienced user looking for special topics may find these chapters; useful: see ""Networking"", ""Writing a Graphical User Interface"",; ""Threads"", and ""PROOF: Parallel Processing"". ## Conventions Used in This Book. We tried to follow a style convention for the sake of clarity. The; styles in used are described below. To show source code in scripts or source files:. ``` {.cpp}; {; cout << "" Hello"" << endl;; float x = 3.;; float y = 5.;; int i = 101;; cout <<"" x = ""<<x<<"" y = ""<<y<<"" i = ""<<i<< endl;; }; ```. To show the ROOT command line, we show the ROOT prompt without numbers.; In the interactive system, the ROOT prompt has a line number; (`root[12]`); for the sake of simplicity, the line numbers are left; off. ``` {.cpp}; root[] TLine l; root[] l.Print(); TLine X1=0.000000 Y1=0.000000 X2=0.000000 Y2=0.000000; ```. Italic bold monotype font indicates a global variable, for example; ***`gDirectory`***. When a variable term is used, it is shown between angled brackets. In; the example below the variable term \<library\> can be replaced with; any library in the `$ROOTSYS` directory: `$ROOTSYS/<library>/inc.`. ## The Framework. ROOT is an object-oriented framework aimed at solving the data; analysis challenges of high-energy physics. There are two key words in; this definition, object oriented and framework. First, we explain what; we mean by a framework and then why it is an object-oriented; framework. ### What Is a Framework?. Programming inside a framework is a little like living in a city.; Plumbing, electricity, telephone, and transportation are services; provided by the city. In your house, you have interfaces to the; services such as light switches, electrical outlets, and telephones.; The details, for example, the routing algorithm of the phone switching; system, are transparent to you as the user. You do not care; you are; only interested in using the phone to communicate with your; collaborators to solve your",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:4331,variab,variable,4331,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,1,['variab'],['variable']
Modifiability,"xpected 'in' keyword after 'var'"");; getNextToken(); // eat 'in'. auto Body = ParseExpression();; if (!Body); return nullptr;. return std::make_unique<VarExprAST>(std::move(VarNames),; std::move(Body));; }. Now that we can parse and represent the code, we need to support; emission of LLVM IR for it. This code starts out with:. .. code-block:: c++. Value *VarExprAST::codegen() {; std::vector<AllocaInst *> OldBindings;. Function *TheFunction = Builder->GetInsertBlock()->getParent();. // Register all variables and emit their initializer.; for (unsigned i = 0, e = VarNames.size(); i != e; ++i) {; const std::string &VarName = VarNames[i].first;; ExprAST *Init = VarNames[i].second.get();. Basically it loops over all the variables, installing them one at a; time. For each variable we put into the symbol table, we remember the; previous value that we replace in OldBindings. .. code-block:: c++. // Emit the initializer before adding the variable to scope, this prevents; // the initializer from referencing the variable itself, and permits stuff; // like this:; // var a = 1 in; // var a = a in ... # refers to outer 'a'.; Value *InitVal;; if (Init) {; InitVal = Init->codegen();; if (!InitVal); return nullptr;; } else { // If not specified, use 0.0.; InitVal = ConstantFP::get(*TheContext, APFloat(0.0));; }. AllocaInst *Alloca = CreateEntryBlockAlloca(TheFunction, VarName);; Builder->CreateStore(InitVal, Alloca);. // Remember the old variable binding so that we can restore the binding when; // we unrecurse.; OldBindings.push_back(NamedValues[VarName]);. // Remember this binding.; NamedValues[VarName] = Alloca;; }. There are more comments here than code. The basic idea is that we emit; the initializer, create the alloca, then update the symbol table to; point to it. Once all the variables are installed in the symbol table,; we evaluate the body of the var/in expression:. .. code-block:: c++. // Codegen the body, now that all vars are in scope.; Value *BodyVal = Body->codegen();; i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:27184,variab,variable,27184,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,2,['variab'],['variable']
Modifiability,"xt. ### Dynamic Path: `ROOT_LIBRARY_PATH`. A new way to set ROOT's ""Dynamic Path"" was added: the; environment variable `ROOT_LIBRARY_PATH`. On Unix it should contain a colon; separated list of paths, on Windows a semicolon separated list. It is; intended to be cross platform and to be specific to ROOT (and thus not; interfere with the system's shared linker).; The final ""Dynamic Path"" is now composed of these sources in order:; 1. `ROOT_LIBRARY_PATH` environment variable; 2. System specific shared linker environment variables like; `LD_LIBRARY_PATH`, `LIBPATH`, or `PATH`.; 3. Setting from rootrc; 4. ROOT's builtin library directory. ### Interpreter. - cling's LLVM is upgraded to version 9.0; - New interface to enable/disable optional cling features. Currently, it can be used to enable/disable support for redefinitions. See [this](https://github.com/root-project/cling/issues/360) issue for more information. ### Multithreading. - Fix an uninitialized variable in global read-write lock which could have caused deadlocks or crashes in some rare cases.; - Default global read-write lock transitioned to new implementation based on TBB thread local storage when TBB is available on supported platforms (all except Windows). This gives an O(10%) performance improvement for some typical RDataFrame scenarios with 256 threads due to reduced lock contention. ## I/O Libraries. - Exclusive use of the global lock is reduced or migrated to finer grained read and write locks in a few hotspots that occur during file opening/closing or task initialization in RDataFrame. This can lead to O(100x) improvements for some typical RDataFrame scenarios with 256 threads due to massively reduced lock contention. ## TTree Libraries. - `TTree` now supports the inclusion of leaves of types `long` and `unsigned long` (and therefore also `std::size_t` on most systems) also for branches in ""leaflist mode"". The corresponding leaflist letters are 'G' and 'g'.; - when looping over a `TTree` with a friend wit",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md:3875,variab,variable,3875,README/ReleaseNotes/v624/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v624/index.md,1,['variab'],['variable']
Modifiability,"xtensions; ======================. Objective-C extends the definition of a Block reference type to be; that also of id. A variable or expression of Block type may be; messaged or used as a parameter wherever an id may be. The converse is; also true. Block references may thus appear as properties and are; subject to the assign, retain, and copy attribute logic that is; reserved for objects. All Blocks are constructed to be Objective-C objects regardless of; whether the Objective-C runtime is operational in the program or; not. Blocks using automatic (stack) memory are objects and may be; messaged, although they may not be assigned into ``__weak`` locations; if garbage collection is enabled. Within a Block literal expression within a method definition; references to instance variables are also imported into the lexical; scope of the compound statement. These variables are implicitly; qualified as references from self, and so self is imported as a const; copy. The net effect is that instance variables can be mutated. The :block-term:`Block_copy` operator retains all objects held in; variables of automatic storage referenced within the Block expression; (or form strong references if running under garbage collection).; Object variables of ``__block`` storage type are assumed to hold; normal pointers with no provision for retain and release messages. Foundation defines (and supplies) ``-copy`` and ``-release`` methods for; Blocks. In the Objective-C and Objective-C++ languages, we allow the; ``__weak`` specifier for ``__block`` variables of object type. If; garbage collection is not enabled, this qualifier causes these; variables to be kept without retain messages being sent. This; knowingly leads to dangling pointers if the Block (or a copy) outlives; the lifetime of this object. In garbage collected environments, the ``__weak`` variable is set to; nil when the object it references is collected, as long as the; ``__block`` variable resides in the heap (either by default ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst:9627,variab,variables,9627,interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,1,['variab'],['variables']
Modifiability,"y (or make sure ``llvm-symbolizer`` is in your; ``$PATH``):. .. code-block:: console. % ASAN_SYMBOLIZER_PATH=/usr/local/bin/llvm-symbolizer ./a.out; ==9442== ERROR: AddressSanitizer heap-use-after-free on address 0x7f7ddab8c084 at pc 0x403c8c bp 0x7fff87fb82d0 sp 0x7fff87fb82c8; READ of size 4 at 0x7f7ddab8c084 thread T0; #0 0x403c8c in main example_UseAfterFree.cc:4; #1 0x7f7ddabcac4d in __libc_start_main ??:0; 0x7f7ddab8c084 is located 4 bytes inside of 400-byte region [0x7f7ddab8c080,0x7f7ddab8c210); freed by thread T0 here:; #0 0x404704 in operator delete[](void*) ??:0; #1 0x403c53 in main example_UseAfterFree.cc:4; #2 0x7f7ddabcac4d in __libc_start_main ??:0; previously allocated by thread T0 here:; #0 0x404544 in operator new[](unsigned long) ??:0; #1 0x403c43 in main example_UseAfterFree.cc:2; #2 0x7f7ddabcac4d in __libc_start_main ??:0; ==9442== ABORTING. If that does not work for you (e.g. your process is sandboxed), you can use a; separate script to symbolize the result offline (online symbolization can be; force disabled by setting ``ASAN_OPTIONS=symbolize=0``):. .. code-block:: console. % ASAN_OPTIONS=symbolize=0 ./a.out 2> log; % projects/compiler-rt/lib/asan/scripts/asan_symbolize.py / < log | c++filt; ==9442== ERROR: AddressSanitizer heap-use-after-free on address 0x7f7ddab8c084 at pc 0x403c8c bp 0x7fff87fb82d0 sp 0x7fff87fb82c8; READ of size 4 at 0x7f7ddab8c084 thread T0; #0 0x403c8c in main example_UseAfterFree.cc:4; #1 0x7f7ddabcac4d in __libc_start_main ??:0; ... Note that on macOS you may need to run ``dsymutil`` on your binary to have the; file\:line info in the AddressSanitizer reports. Additional Checks; =================. Initialization order checking; -----------------------------. AddressSanitizer can optionally detect dynamic initialization order problems,; when initialization of globals defined in one translation unit uses; globals defined in another translation unit. To enable this check at runtime,; you should set environment variable; `",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:4526,sandbox,sandboxed,4526,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst,1,['sandbox'],['sandboxed']
Modifiability,"y be applied to one; parameter. .. _swiftasync:. ``swiftasync``; This indicates that the parameter is the asynchronous context parameter and; triggers the creation of a target-specific extended frame record to store; this pointer. This is not a valid attribute for return values and can only; be applied to one parameter. ``swifterror``; This attribute is motivated to model and optimize Swift error handling. It; can be applied to a parameter with pointer to pointer type or a; pointer-sized alloca. At the call site, the actual argument that corresponds; to a ``swifterror`` parameter has to come from a ``swifterror`` alloca or; the ``swifterror`` parameter of the caller. A ``swifterror`` value (either; the parameter or the alloca) can only be loaded and stored from, or used as; a ``swifterror`` argument. This is not a valid attribute for return values; and can only be applied to one parameter. These constraints allow the calling convention to optimize access to; ``swifterror`` variables by associating them with a specific register at; call boundaries rather than placing them in memory. Since this does change; the calling convention, a function which uses the ``swifterror`` attribute; on a parameter is not ABI-compatible with one which does not. These constraints also allow LLVM to assume that a ``swifterror`` argument; does not alias any other memory visible within a function and that a; ``swifterror`` alloca passed as an argument does not escape. ``immarg``; This indicates the parameter is required to be an immediate; value. This must be a trivial immediate integer or floating-point; constant. Undef or constant expressions are not valid. This is; only valid on intrinsic declarations and cannot be applied to a; call site or arbitrary function. ``noundef``; This attribute applies to parameters and return values. If the value; representation contains any undefined or poison bits, the behavior is; undefined. Note that this does not refer to padding introduced by the; type'",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:63806,variab,variables,63806,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variables']
Modifiability,"y centered. - Angle = 0 (degrees). - Color = 1 (black). - Size = calculate when number of entries is known. - Font = helvetica-medium-r-normal scalable font = 42, and bold = 62; for title. The title is a regular entry and supports **`TLatex`**. The default is; no title (`header = 0`). The options are the same as for **`TPave`**; by; default, they are ""`brand`"". Once the legend box is created, one has to; add the text with the `AddEntry()` method:. ``` {.cpp}; TLegendEntry* TLegend::AddEntry(TObject *obj,; const char *label,; Option_t *option); ```. The parameters are:. - `*obj `is a pointer to an object having marker, line, or fill; attributes (a histogram, or a graph). - `label` is the label to be associated to the object. - `option`:. - ""L"" draw line associated with line attributes of `obj`, if `obj`; inherits from **`TAttLine`**. - ""P"" draw poly-marker associated with marker attributes of `obj`, if; `obj` inherits **`TAttMarker`**. - ""F"" draw a box with fill associated with fill attributes of `obj`,; if `obj` inherits **`TAttFill`**. One may also use the other form of the method `AddEntry`:. ``` {.cpp}; TLegendEntry* TLegend::AddEntry(const char *name,; const char *label,; Option_t *option); ```. Here `name` is the name of the object in the pad. Other parameters are; as in the previous case. Next example shows how to create a legend:. ``` {.cpp}; leg = new TLegend(0.4,0.6,0.89,0.89);; leg->AddEntry(fun1,""One Theory"",""l"");; leg->AddEntry(fun3,""Another Theory"",""f"");; leg->AddEntry(gr,""The Data"",""p"");; leg->Draw();; // oops we forgot the blue line... add it after; leg->AddEntry(fun2,; ""#sqrt{2#pi} P_{T} (#gamma) latex formula"",""f"");; // and add a header (or ""title"") for the legend; leg->SetHeader(""The Legend Title"");; leg->Draw();; ```. Here `fun1`, `fun2`, `fun3` and `gr` are pre-existing functions and; graphs. You can edit the **`TLegend`** by right clicking on it. ![A legend example](pictures/030000D8.png). ## The PostScript Interface. To generate a PostScript (o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:91075,inherit,inherits,91075,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['inherit'],['inherits']
Modifiability,"y common collector designs and easy; extension points. If you don't already have a specific binary interface; you need to support, we recommend trying to use one of these built in collector; strategies. .. _gc_intrinsics:. LLVM IR Features; ================. This section describes the garbage collection facilities provided by the; :doc:`LLVM intermediate representation <LangRef>`. The exact behavior of these; IR features is specified by the selected :ref:`GC strategy description; <plugin>`. Specifying GC code generation: ``gc ""...""``; -------------------------------------------. .. code-block:: text. define <returntype> @name(...) gc ""name"" { ... }. The ``gc`` function attribute is used to specify the desired GC strategy to the; compiler. Its programmatic equivalent is the ``setGC`` method of ``Function``. Setting ``gc ""name""`` on a function triggers a search for a matching subclass; of GCStrategy. Some collector strategies are built in. You can add others; using either the loadable plugin mechanism, or by patching your copy of LLVM.; It is the selected GC strategy which defines the exact nature of the code; generated to support GC. If none is found, the compiler will raise an error. Specifying the GC style on a per-function basis allows LLVM to link together; programs that use different garbage collection algorithms (or none at all). .. _gcroot:. Identifying GC roots on the stack; ----------------------------------. LLVM currently supports two different mechanisms for describing references in; compiled code at safepoints. ``llvm.gcroot`` is the older mechanism;; ``gc.statepoint`` has been added more recently. At the moment, you can choose; either implementation (on a per :ref:`GC strategy <plugin>` basis). Longer; term, we will probably either migrate away from ``llvm.gcroot`` entirely, or; substantially merge their implementations. Note that most new development; work is focused on ``gc.statepoint``. Using ``gc.statepoint``; ^^^^^^^^^^^^^^^^^^^^^^^^; :doc:`This pa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:8951,plugin,plugin,8951,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['plugin'],['plugin']
Modifiability,"y context menus for improving interactivity; - Implement col0 and col0z draw option for TH2 histograms, similar to ROOT6; - Implement box and hbox draw options for TH1 class; - Significant (factor 4) I/O performance improvement; - New 'flex' layout:; - create frames like in Multi Document Interface; - one could move/resize/minimize/maximize such frames. For more details, like the complete change log, the documentation, and very detailed examples, see the [JSROOT home page](https://root.cern.ch/js) and the [JSROOT project github page](https://github.com/linev/jsroot) . ## Tutorials; * New tutorial `treegetval.C` illustrating how to retrieve `TTree` variables in arrays.; * Add script to automatically translate tutorials into notebooks; * Embed it into the documentation generation; * Make the notebooks available in the [tutorials section of the class documentation](https://root.cern/doc/master/group__Tutorials.html). ## Build, Configuration and Testing Infrastructure; - `root-config` does not suppress deprecation warnings (-Wno-deprecated-declarations) anymore. This means compilers will now diagnose the use of deprecated interfaces in user code.; - Added new 'builtin_vc' option to bundle a version of Vc within ROOT.; The default is OFF, however if the Vc package is not found in the system the option is switched to; ON if the option 'vc' option is ON.; - Many improvements (provided by Mattias Ellert):; - Build RFIO using dpm libraries if castor libraries are not available; - Add missing glib header path in GFAL module for version > 2; - Search also for globus libraries wouthout the flavour in the name; - Add missing io/hdfs/CMakeLists.txt; - net/globusauth has no installed headers - remove ROOT_INSTALL_HEADERS(); - Add missing pieces to the cmake config that are built by configure: bin/pq2, bin/rootd, bin/xpdtest, initd and xinitd start-up scripts; - Only link to libgfortranbegin.a when it is provided by the compiler; - Don't remove -Wall without also removing -Werror=*;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:28227,config,config,28227,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['config'],['config']
Modifiability,"y dynamically allocated ref-countable object passed as a call argument spans past the end of the call. This applies to call to any function, method, lambda, function pointer or functor. Ref-countable types aren't supposed to be allocated on stack so we check arguments for parameters of raw pointers and references to uncounted types. Here are some examples of situations that we warn about as they *might* be potentially unsafe. The logic is that either we're able to guarantee that an argument is safe or it's considered if not a bug then bug-prone. .. code-block:: cpp. RefCountable* provide_uncounted();; void consume(RefCountable*);. // In these cases we can't make sure callee won't directly or indirectly call `deref()` on the argument which could make it unsafe from such point until the end of the call. void foo1() {; consume(provide_uncounted()); // warn; }. void foo2() {; RefCountable* uncounted = provide_uncounted();; consume(uncounted); // warn; }. Although we are enforcing member variables to be ref-counted by `webkit.NoUncountedMemberChecker` any method of the same class still has unrestricted access to these. Since from a caller's perspective we can't guarantee a particular member won't get modified by callee (directly or indirectly) we don't consider values obtained from members safe. Note: It's likely this heuristic could be made more precise with fewer false positives - for example calls to free functions that don't have any parameter other than the pointer should be safe as the callee won't be able to tamper with the member unless it's a global variable. .. code-block:: cpp. struct Foo {; RefPtr<RefCountable> member;; void consume(RefCountable*) { /* ... */ }; void bugprone() {; consume(member.get()); // warn; }; };. The implementation of this rule is a heuristic - we define a whitelist of kinds of values that are considered safe to be passed as arguments. If we can't prove an argument is safe it's considered an error. Allowed kinds of arguments:. - values o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst:82007,variab,variables,82007,interpreter/llvm-project/clang/docs/analyzer/checkers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/checkers.rst,1,['variab'],['variables']
Modifiability,"y following the `.. code-block:: c`, but; it looks like garbage; the line numbers don't even line up with the; lines. Is this a Sphinx bug, or is it a CSS problem?. .. code-block:: c. 1 int compute_factorial(int n); 2 {; 3 if (n <= 1); 4 return 1;; 5; 6 int f = n;; 7 while (--n > 1); 8 f *= n;; 9 return f;; 10 }; 11; 12; 13 int main(int argc, char** argv); 14 {; 15 if (argc < 2); 16 return -1;; 17 char firstletter = argv[1][0];; 18 int result = compute_factorial(firstletter - '0');; 19; 20 // Returned result is clipped at 255...; 21 return result;; 22 }. Here is a sample command line session that shows how to build and run this; code via ``lli`` inside LLDB:. .. code-block:: bash. > export BINPATH=/workspaces/llvm-project/build/bin; > $BINPATH/clang -g -S -emit-llvm --target=x86_64-unknown-unknown-elf showdebug.c; > lldb $BINPATH/lli; (lldb) target create ""/workspaces/llvm-project/build/bin/lli""; Current executable set to '/workspaces/llvm-project/build/bin/lli' (x86_64).; (lldb) settings set plugin.jit-loader.gdb.enable on; (lldb) b compute_factorial; Breakpoint 1: no locations (pending).; WARNING: Unable to resolve breakpoint to any actual locations.; (lldb) run --jit-kind=mcjit showdebug.ll 5; 1 location added to breakpoint 1; Process 21340 stopped; * thread #1, name = 'lli', stop reason = breakpoint 1.1; frame #0: 0x00007ffff7fd0007 JIT(0x45c2cb0)`compute_factorial(n=5) at showdebug.c:3:11; 1 int compute_factorial(int n); 2 {; -> 3 if (n <= 1); 4 return 1;; 5 int f = n;; 6 while (--n > 1); 7 f *= n;; (lldb) p n; (int) $0 = 5; (lldb) b showdebug.c:9; Breakpoint 2: where = JIT(0x45c2cb0)`compute_factorial + 60 at showdebug.c:9:1, address = 0x00007ffff7fd003c; (lldb) c; Process 21340 resuming; Process 21340 stopped; * thread #1, name = 'lli', stop reason = breakpoint 2.1; frame #0: 0x00007ffff7fd003c JIT(0x45c2cb0)`compute_factorial(n=1) at showdebug.c:9:1; 6 while (--n > 1); 7 f *= n;; 8 return f;; -> 9 }; 10; 11 int main(int argc, char** argv); 12 {; (lldb) p f; (",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst:3524,plugin,plugin,3524,interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst,1,['plugin'],['plugin']
Modifiability,"y from the second last entry and appends the result to the; expression stack.; - ``DW_OP_plus_uconst, 93`` adds ``93`` to the working expression.; - ``DW_OP_LLVM_fragment, 16, 8`` specifies the offset and size (``16`` and ``8``; here, respectively) of the variable fragment from the working expression. Note; that contrary to DW_OP_bit_piece, the offset is describing the location; within the described source variable.; - ``DW_OP_LLVM_convert, 16, DW_ATE_signed`` specifies a bit size and encoding; (``16`` and ``DW_ATE_signed`` here, respectively) to which the top of the; expression stack is to be converted. Maps into a ``DW_OP_convert`` operation; that references a base type constructed from the supplied values.; - ``DW_OP_LLVM_tag_offset, tag_offset`` specifies that a memory tag should be; optionally applied to the pointer. The memory tag is derived from the; given tag offset in an implementation-defined manner.; - ``DW_OP_swap`` swaps top two stack entries.; - ``DW_OP_xderef`` provides extended dereference mechanism. The entry at the top; of the stack is treated as an address. The second stack entry is treated as an; address space identifier.; - ``DW_OP_stack_value`` marks a constant value.; - ``DW_OP_LLVM_entry_value, N`` refers to the value a register had upon; function entry. When targeting DWARF, a ``DBG_VALUE(reg, ...,; DIExpression(DW_OP_LLVM_entry_value, 1, ...)`` is lowered to; ``DW_OP_entry_value [reg], ...``, which pushes the value ``reg`` had upon; function entry onto the DWARF expression stack. The next ``(N - 1)`` operations will be part of the ``DW_OP_entry_value``; block argument. For example, ``!DIExpression(DW_OP_LLVM_entry_value, 1,; DW_OP_plus_uconst, 123, DW_OP_stack_value)`` specifies an expression where; the entry value of ``reg`` is pushed onto the stack, and is added with 123.; Due to framework limitations ``N`` must be 1, in other words,; ``DW_OP_entry_value`` always refers to the value/address operand of the; instruction. Because ``DW_OP_LLVM",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:262792,extend,extended,262792,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['extend'],['extended']
Modifiability,"y instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument all variables; as usual but additionally store stack-safe information in the; ``ASanStackVariableDescription``. Then if AddressSanitizer detects a bug on; a 'safe' variable we can produce an additional report to let the user know that; probably Stack Safety Analysis failed and we should check for a bug in the; compiler.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:1677,variab,variables,1677,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,3,['variab'],"['variable', 'variables']"
Modifiability,"y lines specified by ``--dump-input-filter``.; When there are multiple occurrences of this option, the largest specified; ``<N>`` has precedence. The default is 5. .. option:: --dump-input-filter <value>. In the dump requested by ``--dump-input``, print only input lines of kind; ``<value>`` plus any context specified by ``--dump-input-context``. When; there are multiple occurrences of this option, the ``<value>`` that appears; earliest in the list below has precedence. The default is ``error`` when; ``--dump-input=fail``, and it's ``all`` when ``--dump-input=always``. * ``all`` - All input lines; * ``annotation-full`` - Input lines with annotations; * ``annotation`` - Input lines with starting points of annotations; * ``error`` - Input lines with starting points of error annotations. .. option:: --enable-var-scope. Enables scope for regex variables. Variables with names that start with ``$`` are considered global and; remain set throughout the file. All other variables get undefined after each encountered ``CHECK-LABEL``. .. option:: -D<VAR=VALUE>. Sets a filecheck pattern variable ``VAR`` with value ``VALUE`` that can be; used in ``CHECK:`` lines. .. option:: -D#<FMT>,<NUMVAR>=<NUMERIC EXPRESSION>. Sets a filecheck numeric variable ``NUMVAR`` of matching format ``FMT`` to; the result of evaluating ``<NUMERIC EXPRESSION>`` that can be used in; ``CHECK:`` lines. See section; ``FileCheck Numeric Variables and Expressions`` for details on supported; numeric expressions. .. option:: -version. Show the version number of this program. .. option:: -v. Print good directive pattern matches. However, if ``-dump-input=fail`` or; ``-dump-input=always``, add those matches as input annotations instead. .. option:: -vv. Print information helpful in diagnosing internal FileCheck issues, such as; discarded overlapping ``CHECK-DAG:`` matches, implicit EOF pattern matches,; and ``CHECK-NOT:`` patterns that do not have matches. Implies ``-v``.; However, if ``-dump-input=fail`` or ``-du",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst:6041,variab,variables,6041,interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,1,['variab'],['variables']
Modifiability,"y of; the back-end, which has more accurate information about register pressure and; also handles other optimizations than LICM that increase live-ranges. This pass uses alias analysis for two purposes:. #. Moving loop invariant loads and calls out of loops. If we can determine; that a load or call inside of a loop never aliases anything stored to, we; can hoist it or sink it like any other instruction. #. Scalar Promotion of Memory. If there is a store instruction inside of the; loop, we try to move the store to happen AFTER the loop instead of inside of; the loop. This can only happen if a few conditions are true:. #. The pointer stored through is loop invariant.; #. There are no stores or loads in the loop which *may* alias the pointer.; There are no calls in the loop which mod/ref the pointer. If these conditions are true, we can promote the loads and stores in the; loop of the pointer to use a temporary alloca'd variable. We then use the; :ref:`mem2reg <passes-mem2reg>` functionality to construct the appropriate; SSA form for the variable. ``loop-deletion``: Delete dead loops; ------------------------------------. This file implements the Dead Loop Deletion Pass. This pass is responsible for; eliminating loops with non-infinite computable trip counts that have no side; effects or volatile instructions, and do not contribute to the computation of; the function's return value. .. _passes-loop-extract:. ``loop-extract``: Extract loops into new functions; --------------------------------------------------. A pass wrapper around the ``ExtractLoop()`` scalar transformation to extract; each top-level loop into its own new function. If the loop is the *only* loop; in a given function, it is not touched. This is a pass most useful for; debugging via bugpoint. ``loop-reduce``: Loop Strength Reduction; ----------------------------------------. This pass performs a strength reduction on array references inside loops that; have as one or more of their components the loop in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:25152,variab,variable,25152,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['variab'],['variable']
Modifiability,"y reasoning about; the semantics of code. The goal of the Clang Static Analyzer is to provide a; industrial-quality static analysis framework for analyzing C, C++, and; Objective-C programs that is freely available, extensible, and has a high quality of implementation.; Part of Clang and LLVM; As its name implies, the Clang Static Analyzer is built on top of Clang and LLVM.; Strictly speaking, the analyzer is part of Clang, as Clang consists of a set of; reusable C++ libraries for building powerful source-level tools. The static; analysis engine used by the Clang Static Analyzer is a Clang library, and has; the capability to be reused in different contexts and by different clients.; Important Points to Consider; While we believe that the static analyzer is already very useful for finding; bugs, we ask you to bear in mind a few points when using it.; Work-in-Progress; The analyzer is a continuous work-in-progress. There are many planned; enhancements to improve both the precision and scope of its analysis algorithms; as well as the kinds of bugs it will find. While there are fundamental; limitations to what static analysis can do, we have a long way to go before; hitting that wall.; Slower than Compilation; Operationally, using static analysis to; automatically find deep program bugs is about trading CPU time for the hardening; of code. Because of the deep analysis performed by state-of-the-art static; analysis tools, static analysis can be much slower than compilation.; While the Clang Static Analyzer is being designed to be as fast and; light-weight as possible, please do not expect it to be as fast as compiling a; program (even with optimizations enabled). Some of the algorithms needed to find; bugs require in the worst case exponential time.; The Clang Static Analyzer runs in a reasonable amount of time by both; bounding the amount of checking work it will do as well as using clever; algorithms to reduce the amount of work it must do to find bugs.; False Positive",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/index.html:2433,enhance,enhancements,2433,interpreter/llvm-project/clang/www/analyzer/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/index.html,1,['enhance'],['enhancements']
Modifiability,"y reasons the term ""undef; dbg.value"" may be used in existing code. The ``DbgVariableIntrinsic`` methods; ``isKillLocation`` and ``setKillLocation`` should be used where possible rather; than inspecting location operands directly to check or set whether a dbg.value; is a kill location. In general, if any dbg.value has its operand optimized out and cannot be; recovered, then a kill dbg.value is necessary to terminate earlier variable; locations. Additional kill dbg.values may be necessary when the debugger can; observe re-ordering of assignments. How variable location metadata is transformed during CodeGen; ============================================================. LLVM preserves debug information throughout mid-level and backend passes,; ultimately producing a mapping between source-level information and; instruction ranges. This; is relatively straightforwards for line number information, as mapping; instructions to line numbers is a simple association. For variable locations; however the story is more complex. As each ``llvm.dbg.value`` intrinsic; represents a source-level assignment of a value to a source variable, the; variable location intrinsics effectively embed a small imperative program; within the LLVM IR. By the end of CodeGen, this becomes a mapping from each; variable to their machine locations over ranges of instructions.; From IR to object emission, the major transformations which affect variable; location fidelity are:. 1. Instruction Selection; 2. Register allocation; 3. Block layout. each of which are discussed below. In addition, instruction scheduling can; significantly change the ordering of the program, and occurs in a number of; different passes. Some variable locations are not transformed during CodeGen. Stack locations; specified by ``llvm.dbg.declare`` are valid and unchanging for the entire; duration of the function, and are recorded in a simple MachineFunction table.; Location changes in the prologue and epilogue of a function are also ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:24249,variab,variable,24249,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['variab'],['variable']
Modifiability,"y the ``ROOT::Fit::DataOptions`` class, the range by the ``ROOT::Fit::DataRange`` class. Here is an example how to specify the input option to use the integral of the function value in the bin instead of using the function value; evaluated at the bin center, when doing the fit and to use a; range beween the 'xmin' and 'xmax' values. ``` {.cpp}; ROOT::Fit::DataOptions opt;; opt.fIntegral = true;; ROOT::Fit::DataRange range(xmin,xmax);; ROOT::Fit::BinData data(opt,range);; // fill the bin data using the histogram; // we can do this using the following helper function from the Hist library; TH1 * h1 = (TH1*) gDirectory->Get(""myHistogram"");; ROOT::Fit::FillData(data, h1);; ```. The list of possible fit options available is the following:; ``` {.cpp}; ROOT::Fit::DataOptions opt;; opt.fIntegral = true; // use integral of bin content instead of bin center (default is false).; opt.fBinVolume = true; // normalize data by the bin volume (default is false).; // This is for fitting density functions in histograms with variable bin sizes.; opt.fUseRange =true; // use the function range when creating the fit data (default is false).; opt.fExpErrors = true; // use the expected errors estimated from the function values; // assuming Poisson statistics and not the observed errors (default is false).; opt.fUseEmpty = true; // use empty bins when fitting (default is false). If fExpErrors; 							 // is not set an arbitrary error = 1 is assigned to those bins.; opt.fErrors1 = true; // Set all measured errors to 1 (default is false).; opt.fCoordErrors = false; // When available coordinate errors are not used in the fit; // (default is true: the errors are used when they are available,; // e.g. fitting a TGraphErrors).; opt.fAsymErrors = false; // When available asymmetric errors are considered in the fit; // (default is true, the asymmetric errors are used when they are available,; // e.g. fitting a TGraphAsymmErrors).; ```. The `ROOT::Fit::DataRange` class supports defining multiple rect",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:31949,variab,variable,31949,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['variab'],['variable']
Modifiability,"y the preprocessed content of; ""system"" headers to the output; instead, preserve the #include directive.; This can greatly reduce the volume of text produced by :option:`-E` which; can be helpful when trying to produce a ""small"" reproduceable test case. This option does not guarantee reproduceability, however. If the including; source defines preprocessor symbols that influence the behavior of system; headers (for example, ``_XOPEN_SOURCE``) the operation of :option:`-E` will; remove that definition and thus can change the semantics of the included; header. Also, using a different version of the system headers (especially a; different version of the STL) may result in different behavior. Always verify; the preprocessed file by compiling it separately. ENVIRONMENT; -----------. .. envvar:: TMPDIR, TEMP, TMP. These environment variables are checked, in order, for the location to write; temporary files used during the compilation process. .. envvar:: CPATH. If this environment variable is present, it is treated as a delimited list of; paths to be added to the default system include path list. The delimiter is; the platform dependent delimiter, as used in the PATH environment variable. Empty components in the environment variable are ignored. .. envvar:: C_INCLUDE_PATH, OBJC_INCLUDE_PATH, CPLUS_INCLUDE_PATH, OBJCPLUS_INCLUDE_PATH. These environment variables specify additional paths, as for :envvar:`CPATH`, which are; only used when processing the appropriate language. .. envvar:: MACOSX_DEPLOYMENT_TARGET. If :option:`-mmacosx-version-min` is unspecified, the default deployment; target is read from this environment variable. This option only affects; Darwin targets. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/issues/>. Most bug reports should; include preprocessed source files (use the :option:`-E` option) and the full; output of the compiler, along with information to reproduce. SEE ALSO; --------. :manpage:`as(1)`, :manpage:`ld(1)`; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:20952,variab,variable,20952,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,5,['variab'],"['variable', 'variables']"
Modifiability,"y the supported attributes. That means that even though; ``variable(unless(is_parameter))`` is a valid match rule,; ``variable(unless(is_thread_local))`` is not. Supported Attributes; --------------------. Not all attributes can be used with the ``#pragma clang attribute`` directive.; Notably, statement attributes like ``[[fallthrough]]`` or type attributes; like ``address_space`` aren't supported by this directive. You can determine; whether or not an attribute is supported by the pragma by referring to the; :doc:`individual documentation for that attribute <AttributeReference>`. The attributes are applied to all matching declarations individually, even when; the attribute is semantically incorrect. The attributes that aren't applied to; any declaration are not verified semantically. Specifying section names for global objects (#pragma clang section); ===================================================================. The ``#pragma clang section`` directive provides a means to assign section-names; to global variables, functions and static variables. The section names can be specified as:. .. code-block:: c++. #pragma clang section bss=""myBSS"" data=""myData"" rodata=""myRodata"" relro=""myRelro"" text=""myText"". The section names can be reverted back to default name by supplying an empty; string to the section kind, for example:. .. code-block:: c++. #pragma clang section bss="""" data="""" text="""" rodata="""" relro="""". The ``#pragma clang section`` directive obeys the following rules:. * The pragma applies to all global variable, statics and function declarations; from the pragma to the end of the translation unit. * The pragma clang section is enabled automatically, without need of any flags. * This feature is only defined to work sensibly for ELF targets. * If section name is specified through _attribute_((section(""myname""))), then; the attribute name gains precedence. * Global variables that are initialized to zero will be placed in the named; bss section, if one is present",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:186532,variab,variables,186532,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,2,['variab'],['variables']
Modifiability,"y those; of Clang itself. They are entirely within the Clang *project*,; regardless of the version control scheme. Core Clang Tools; ================. The core set of Clang tools that are within the main repository are; tools that very specifically complement, and allow use and testing of; *Clang* specific functionality. ``clang-check``; ---------------. :doc:`ClangCheck` combines the LibTooling framework for running a; Clang tool with the basic Clang diagnostics by syntax checking specific files; in a fast, command line interface. It can also accept flags to re-display the; diagnostics in different formats with different flags, suitable for use driving; an IDE or editor. Furthermore, it can be used in fixit-mode to directly apply; fixit-hints offered by clang. See :doc:`HowToSetupToolingForLLVM` for; instructions on how to setup and used `clang-check`. ``clang-format``; ----------------. Clang-format is both a :doc:`library <LibFormat>` and a :doc:`stand-alone tool; <ClangFormat>` with the goal of automatically reformatting C++ sources files; according to configurable style guides. To do so, clang-format uses Clang's; ``Lexer`` to transform an input file into a token stream and then changes all; the whitespace around those tokens. The goal is for clang-format to serve both; as a user tool (ideally with powerful IDE integrations) and as part of other; refactoring tools, e.g. to do a reformatting of all the lines changed during a; renaming. Extra Clang Tools; =================. As various categories of Clang Tools are added to the extra repository,; they'll be tracked here. The focus of this documentation is on the scope; and features of the tools for other tool developers; each tool should; provide its own user-focused documentation. ``clang-tidy``; --------------. `clang-tidy <https://clang.llvm.org/extra/clang-tidy/>`_ is a clang-based C++; linter tool. It provides an extensible framework for building compiler-based; static analyses detecting and fixing bug-prone ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangTools.rst:3421,config,configurable,3421,interpreter/llvm-project/clang/docs/ClangTools.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangTools.rst,1,['config'],['configurable']
Modifiability,"y to do much better than that, with its own; n-tuple classes. Among the many advantages provided by these classes one; could cite. - Optimised disk I/O. - Possibility to store many n-tuple rows. - Write the n-tuples in ROOT files. - Interactive inspection with `TBrowser`. - Store not only numbers, but also *objects* in the columns. In this section we will discuss briefly the `TNtuple` class, which is a; simplified version of the `TTree` class. A ROOT `TNtuple` object can; store rows of float entries. Let's tackle the problem according to the; usual strategy commenting a minimal example. ``` {.cpp}; @ROOT_INCLUDE_FILE macros/write_ntuple_to_file.C; ```. This data written to this example n-tuple represents, in the statistical; sense, three independent variables (Potential or Voltage, Pressure and; Temperature), and one variable (Current) which depends on the others; according to very simple laws, and an additional Gaussian smearing. This; set of variables mimics a measurement of an electrical resistance while; varying pressure and temperature. Imagine your task now consists in finding the relations among the; variables -- of course without knowing the code used to generate them.; You will see that the possibilities of the `NTuple` class enable you to; perform this analysis task. Open the ROOT file (`cond_data.root`); written by the macro above in an interactive session and use a; `TBrowser` to interactively inspect it:. ``` {.cpp}; root[0] TBrowser b; ```; You find the columns of your n-tuple written as *leafs*. Simply clicking; on them you can obtain histograms of the variables!. Next, try the following commands at the shell prompt and in the; interactive ROOT shell, respectively:. ``` {.cpp}; > root conductivity_experiment.root; Attaching file conductivity_experiment.root as _file0...; root [0] cond_data->Draw(""Current:Potential""); ```. You just produced a correlation plot with one single line of code!. Try to extend the syntax typing for example. ``` {.cpp}; root [1",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md:2590,variab,variables,2590,documentation/primer/filio.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md,1,['variab'],['variables']
Modifiability,"y to:. - have a system-wide, sysadmin-provided experiment configuration. - execute user actions either *before* or *after* the execution of the; system-wide script (for instance, choosing the preferred version of; the experiment's software). - transfer a custom user **payload** on each PROOF worker (for instance,; user's client-generated Grid credentials to make PROOF workers; capable of accessing a remote authenticated storage). Configuration files are searched for in two different locations:. - a system-wide directory: `<client_install_dir>/etc`. - user's home directory: `~/.vaf`. > A system-wide configuration file always has precedence over user's; > configuration. It is thus possible for the sysadmin to enforce a; > policy where some scripts cannot ever be overridden. Thanks to this separation, users can maintain an uncluttered directory; with very simple configuration files that contain only what really needs; or is allowed to be customized: for instance, user might specify a single line; containing the needed ROOT version, while all the technicalities to set; up the environment are taken care of inside system-installed scripts,; leaving the user's configuration directory clean and uncluttered. ### Local environment configuration. All the local environment files are loaded at the time of the; client's startup following a certain order. - `common.before`. - `local.before`. - `local.conf`. - `$VafConf_LocalPodLocation/PoD_env.sh`. - `common.after`. - `local.after`. The `common.*` files are sourced both for the local and the remote; environment. This might be convenient to avoid repeating the same; configuration in different places. Each file is looked for first in the system-wide directory and then in; the user's directory. If a configuration file does not exist, it is; silently skipped. The `$VafConf_LocalPodLocation/PoD_env.sh` environment script, provided; with each PROOF on Demand installation, *must exist*: without this file,; the VAF client won't start. ###",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md:2157,config,configuration,2157,proof/doc/confman/UsingVirtualAnalysisFacility.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/UsingVirtualAnalysisFacility.md,2,['config'],['configuration']
Modifiability,"y value. Here are the possible suffixes for some primary *value*. *value*\ ``{17}``; The final value is bit 17 of the integer *value* (note the braces). *value*\ ``{8...15}``; The final value is bits 8--15 of the integer *value*. The order of the; bits can be reversed by specifying ``{15...8}``. *value*\ ``[i]``; The final value is element `i` of the list *value* (note the brackets).; In other words, the brackets act as a subscripting operator on the list.; This is the case only when a single element is specified. *value*\ ``[i,]``; The final value is a list that contains a single element `i` of the list.; In short, a list slice with a single element. *value*\ ``[4...7,17,2...3,4]``; The final value is a new list that is a slice of the list *value*.; The new list contains elements 4, 5, 6, 7, 17, 2, 3, and 4.; Elements may be included multiple times and in any order. This is the result; only when more than one element is specified. *value*\ ``[i,m...n,j,ls]``; Each element may be an expression (variables, bang operators).; The type of `m` and `n` should be `int`.; The type of `i`, `j`, and `ls` should be either `int` or `list<int>`. *value*\ ``.``\ *field*; The final value is the value of the specified *field* in the specified; record *value*. The paste operator; ------------------. The paste operator (``#``) is the only infix operator available in TableGen; expressions. It allows you to concatenate strings or lists, but has a few; unusual features. The paste operator can be used when specifying the record name in a; :token:`Def` or :token:`Defm` statement, in which case it must construct a; string. If an operand is an undefined name (:token:`TokIdentifier`) or the; name of a global :token:`Defvar` or :token:`Defset`, it is treated as a; verbatim string of characters. The value of a global name is not used. The paste operator can be used in all other value expressions, in which case; it can construct a string or a list. Rather oddly, but consistent with the; previous",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:19844,variab,variables,19844,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['variab'],['variables']
Modifiability,"y, it contains a few helpful member functions that try to make common; operations easy. .. _m_Module:. Important Public Members of the ``Module`` class; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. * ``Module::Module(std::string name = """")``. Constructing a Module_ is easy. You can optionally provide a name for it; (probably based on the name of the translation unit). * | ``Module::iterator`` - Typedef for function list iterator; | ``Module::const_iterator`` - Typedef for const_iterator.; | ``begin()``, ``end()``, ``size()``, ``empty()``. These are forwarding methods that make it easy to access the contents of a; ``Module`` object's :ref:`Function <c_Function>` list. * ``Module::FunctionListType &getFunctionList()``. Returns the list of :ref:`Function <c_Function>`\ s. This is necessary to use; when you need to update the list or perform a complex action that doesn't have; a forwarding method. ----------------. * | ``Module::global_iterator`` - Typedef for global variable list iterator; | ``Module::const_global_iterator`` - Typedef for const_iterator.; | ``Module::insertGlobalVariable()`` - Inserts a global variable to the list.; | ``Module::removeGlobalVariable()`` - Removes a global variable from the list.; | ``Module::eraseGlobalVariable()`` - Removes a global variable from the list and deletes it.; | ``global_begin()``, ``global_end()``, ``global_size()``, ``global_empty()``. These are forwarding methods that make it easy to access the contents of a; ``Module`` object's GlobalVariable_ list. ----------------. * ``SymbolTable *getSymbolTable()``. Return a reference to the SymbolTable_ for this ``Module``. ----------------. * ``Function *getFunction(StringRef Name) const``. Look up the specified function in the ``Module`` SymbolTable_. If it does not; exist, return ``null``. * ``FunctionCallee getOrInsertFunction(const std::string &Name,; const FunctionType *T)``. Look up the specified function in the ``Module`` SymbolTable_. If; it does not exist, add an exte",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:138977,variab,variable,138977,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['variab'],['variable']
Modifiability,"y/italian-english/scudo>`_; (and Escudo in Spanish). Design; ======. Allocator; ---------; Scudo was designed with security in mind, but aims at striking a good balance; between security and performance. It was designed to be highly tunable and; configurable, and while we provide some default configurations, we encourage; consumers to come up with the parameters that will work best for their use; cases. The allocator combines several components that serve distinct purposes:. - the Primary allocator: fast and efficient, it services smaller allocation; sizes by carving reserved memory regions into blocks of identical size. There; are currently two Primary allocators implemented, specific to 32 and 64 bit; architectures. It is configurable via compile time options. - the Secondary allocator: slower, it services larger allocation sizes via the; memory mapping primitives of the underlying operating system. Secondary backed; allocations are surrounded by Guard Pages. It is also configurable via compile; time options. - the thread specific data Registry: defines how local caches operate for each; thread. There are currently two models implemented: the exclusive model where; each thread holds its own caches (using the ELF TLS); or the shared model; where threads share a fixed size pool of caches. - the Quarantine: offers a way to delay the deallocation operations, preventing; blocks to be immediately available for reuse. Blocks held will be recycled; once certain size criteria are reached. This is essentially a delayed freelist; which can help mitigate some use-after-free situations. This feature is fairly; costly in terms of performance and memory footprint, is mostly controlled by; runtime options and is disabled by default. Allocations Header; ------------------; Every chunk of heap memory returned to an application by the allocator will be; preceded by a header. This has two purposes:. - being to store various information about the chunk, that can be leveraged to; ensure",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst:1720,config,configurable,1720,interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ScudoHardenedAllocator.rst,1,['config'],['configurable']
Modifiability,"y; 4. Fix - problem with empty STL containers; 5. Fix - empty baskets at the end of branch store; 6. Fix - problem with zooming in THStack. ## Changes in 5.0.0; 1. Reading TTree data; - all kinds of branches, including split STL containers; - branches with several elementary leaves; - branches from different ROOT files; - JSROOT.TSelector class to access TTree data; - simple access to branch data with ""dump"" draw option; 2. TTree::Draw support; - simple 1D/2D/3D histograms; - simple cut conditions; - configurable histogram like ""px:py>>hist(50,-5,5,50,-5,5)""; - strings support; - iterate over arrays indexes, let use another branch as index values; - support ""Entry$"" and ""Entries$"" variables in expressions; - bits histogram like ""event.fTracks.fBits>>bits(16)""; - special handling of TBits; - arbitrary math function from JavaScript Math class, some TMath:: function from ROOT; - if branch is object, one could use methods ""TMath::Abs(lep1_p4.X()+lep1_p4.Y())""; - interactive player to configure and execute draw expression; 3. Full support of Float16_t and Double32_t types in I/O; 4. Drawing of RooPlot objects, I/O support for RooFit classes; 5. Many improvements in object inspector; - support of large lists; only first part is shown; - support of large arrays; values group in decades; - allow to call draw function for sub-elements in inspector; 6. Canvas or selected sub-pad can be enlarged when double-clicked outside frame (#116); Complete drawing will be expanded to the visible space.; Not available for flex, tabs and collapsible layouts.; 7. Support reading of local ROOT files with HTML5 FileReader.; Files can be selected only with interactive dialog.; 8. Combine ""Ctrl"" and ""Shift"" keys with mouse click on the items:; - with Shift key typically object inspector will be activated; - with Ctrl key alternative draw options will be used (like colz for TH2); 9. Update libraries; - d3.js - 4.4.4; - three.js - 84; - jquery - 3.3.1; - jquery-ui - 1.12.1. ## Changes in 4.8.2; 1",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:47491,config,configure,47491,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['config'],['configure']
Modifiability,"y; 9. Migrate to Node.js 8, do not support older versions. ## Changes in 5.5.2; 1. Fix - draw TH2Poly bins outline when no content specified; 2. Fix - always set axis interactive handlers (#170); 3. Fix - take into account zaxis properties when drawing color palette (#171). ## Changes in 5.5.1; 1. Fix - adjust v7 part to new class naming convention, started with R; 2. Fix - show RCanvas title; 3. New - implement 'nocache' option for JSROOT scripts loading. When specified in URL with; JSRootCore.js script, tries to avoid scripts caching problem by adding stamp parameter to all URLs; 4. New - provide simple drawing for TObjString (#164). ## Changes in 5.5.0; 1. Introduce JSROOT.StoreJSON() function. It creates JSON code for the; TCanvas with all drawn objects inside. Allows to store current canvas state; 2. Support ""item=img:file.png"" parameter to insert images in existing layout (#151); 3. Support TTree drawing into TGraph (#153), thanks @cozzyd; 4. Let configure ""&toolbar=right"" in URL to change position of tool buttons; 5. Let configure ""&divsize=500x400"" in URL of size of main div element (default - full browser); 6. Implement ""optstat1001"" and ""optfit101"" draw options for histograms; 7. Remove ""autocol"" options - standard ""plc"" should be used instead; 8. Provide drawing of artificial ""$legend"" item - it creates TLegend for all primitives in pad; Can be used when several histograms or several graphs superimposed; 9. Let configure ""&toolbar=vert"" in URL to change orientation of tool buttons; 10. Improve markers and error bars drawing for TH1/TProfile. ## Changes in 5.4.3; 1. Fix - draw functions also when histogram ""same"" option used (#159); 2. Fix - when draw histogram as markers improve optimization algorithm; 3. Fix - correct histogram Y-axis range selection in logarithmic scale; 4. Fix - for TH2 draw options allow combination ""colztext"" (#162); 5. Fix - PNG file generation with 3D drawings inside. ## Changes in 5.4.2; 1. Fix - take into account extra quotes in m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:33765,config,configure,33765,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['config'],['configure']
Modifiability,"y; `LineDraw(Line l)` and call it with your object as argument:. ``` {.cpp}; LineDraw(firstline);; ```. In C++, we would not do that. We would instead define a class like this:. ``` {.cpp}; class TLine {; Double_t x1;; Double_t y1;; Double_t x2;; Double_t y2;; TLine(int x1, int y1, int x2, int y2);; void Draw();; }; ```. Here we added two functions, that we will call methods or member; functions, to the **`TLine`** class. The first method is used for; initializing the line objects we would build. It is called a; constructor. The second one is the `Draw` method itself. Therefore, to; build and draw a line, we have to do:. ``` {.cpp}; TLine l(0.2,0.2,0.8,0.9);; l.Draw();; ```. The first line builds the object `l` by calling its constructor. The; second line calls the **`TLine`**`::Draw()` method of this object. You; don't need to pass any parameters to this method since it applies to; the object `l`, which knows the coordinates of the line. These are; internal variables `x1`, `y1`, `x2`, `y2` that were initialized by the; constructor. ## Inheritance and Data Encapsulation. We have defined a **`TLine`** class that contains everything necessary; to draw a line. If we want to draw an arrow, is it so different from; drawing a line? We just have to draw a triangle at one end. It would; be very inefficient to define the class **`TArrow`** from scratch.; Fortunately, inheritance allows a class to be defined from an existing; class. We would write something like:. ``` {.cpp}; class TArrow : public TLine {; int ArrowHeadSize;; void Draw();; void SetArrowSize(int arrowsize);; }; ```. The keyword ""`public`"" will be explained later. The class **`TArrow`**; now contains everything that the class **`TLine`** does, and a couple; of more things, the size of the arrowhead and a function that can; change it. The Draw method of **`TArrow`** will draw the head and call; the draw method of **`TLine`**. We just have to write the code for; drawing the head!. ### Method Overriding. Giving th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/ALittleC++.md:2148,variab,variables,2148,documentation/users-guide/ALittleC++.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/ALittleC++.md,1,['variab'],['variables']
Modifiability,"y; clang-format is turned off or back on. .. code-block:: c++. int formatted_code;; // clang-format off; void unformatted_code ;; // clang-format on; void formatted_code_again;. Configuring Style in Code; =========================. When using ``clang::format::reformat(...)`` functions, the format is specified; by supplying the `clang::format::FormatStyle; <https://clang.llvm.org/doxygen/structclang_1_1format_1_1FormatStyle.html>`_; structure. Configurable Format Style Options; =================================. This section lists the supported style options. Value type is specified for; each option. For enumeration types possible values are specified both as a C++; enumeration member (with a prefix, e.g. ``LS_Auto``), and as a value usable in; the configuration (without a prefix: ``Auto``). .. _BasedOnStyle:. **BasedOnStyle** (``String``) :ref:`¶ <BasedOnStyle>`; The style used for all options not specifically set in the configuration. This option is supported only in the :program:`clang-format` configuration; (both within ``-style='{...}'`` and the ``.clang-format`` file). Possible values:. * ``LLVM``; A style complying with the `LLVM coding standards; <https://llvm.org/docs/CodingStandards.html>`_; * ``Google``; A style complying with `Google's C++ style guide; <https://google.github.io/styleguide/cppguide.html>`_; * ``Chromium``; A style complying with `Chromium's style guide; <https://chromium.googlesource.com/chromium/src/+/refs/heads/main/styleguide/styleguide.md>`_; * ``Mozilla``; A style complying with `Mozilla's style guide; <https://firefox-source-docs.mozilla.org/code-quality/coding-style/index.html>`_; * ``WebKit``; A style complying with `WebKit's style guide; <https://www.webkit.org/coding/coding-style.html>`_; * ``Microsoft``; A style complying with `Microsoft's style guide; <https://docs.microsoft.com/en-us/visualstudio/ide/editorconfig-code-style-settings-reference>`_; * ``GNU``; A style complying with the `GNU coding standards; <https://www.gnu.org",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:5266,config,configuration,5266,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['config'],['configuration']
Modifiability,"y; please take a look at; the `latest version of PrintFunctionNames.cpp; <https://github.com/llvm/llvm-project/blob/main/clang/examples/PrintFunctionNames/PrintFunctionNames.cpp>`_. Running the plugin; ==================. Using the compiler driver; --------------------------. The Clang driver accepts the `-fplugin` option to load a plugin.; Clang plugins can receive arguments from the compiler driver command; line via the `fplugin-arg-<plugin name>-<argument>` option. Using this; method, the plugin name cannot contain dashes itself, but the argument; passed to the plugin can. .. code-block:: console. $ export BD=/path/to/build/directory; $ make -C $BD CallSuperAttr; $ clang++ -fplugin=$BD/lib/CallSuperAttr.so \; -fplugin-arg-call_super_plugin-help \; test.cpp. If your plugin name contains dashes, either rename the plugin or used the; cc1 command line options listed below. Using the cc1 command line; --------------------------. To run a plugin, the dynamic library containing the plugin registry must be; loaded via the `-load` command line option. This will load all plugins; that are registered, and you can select the plugins to run by specifying the; `-plugin` option. Additional parameters for the plugins can be passed with; `-plugin-arg-<plugin-name>`. Note that those options must reach clang's cc1 process. There are two; ways to do so:. * Directly call the parsing process by using the `-cc1` option; this; has the downside of not configuring the default header search paths, so; you'll need to specify the full system path configuration on the command; line.; * Use clang as usual, but prefix all arguments to the cc1 process with; `-Xclang`. For example, to run the ``print-function-names`` plugin over a source file in; clang, first build the plugin, and then call clang with the plugin from the; source tree:. .. code-block:: console. $ export BD=/path/to/build/directory; $ (cd $BD && make PrintFunctionNames ); $ clang++ -D_GNU_SOURCE -D_DEBUG -D__STDC_CONSTANT_MACROS \; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangPlugins.rst:5175,plugin,plugin,5175,interpreter/llvm-project/clang/docs/ClangPlugins.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangPlugins.rst,2,['plugin'],['plugin']
Modifiability,"yLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help message. CreateMVAPdfs No False − Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False − Events with negative weights are ignored in the training (but are included for testing and performance evaluation). FitMethod No GA GA, SA, MC, MCEvents, MINUIT, EventScan Minimisation Method (GA, SA, and MC are the primary methods to be used; the others have been introduced for testing purposes and are depreciated). EffMethod No EffSel EffSel, EffPDF Selection Method. CutRangeMin Yes -1 − Minimum of allowed cut range (set per variable). CutRangeMax Yes -1 − Maximum of allowed cut range (set per variable). VarProp Yes NotEnforced NotEnforced, FMax, FMin, FSmart Categorisation of cuts. Configuration options for MVA method :. Configuration options reference for MVA method: PDEFoam. Option Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help message. CreateMVAPdfs No False − Create PDFs for classifier outputs (signal and background). Ig",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:25469,variab,variable,25469,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,1,['variab'],['variable']
Modifiability,"y_streambuf);; }; };. void test() {; my_stream1<char> *p1 = new my_stream1<char>;; my_stream2<char> *p2 = new my_stream2<char>;; p1->narrow('a', 'b'); // warn; p2->narrow('a', 'b'); // ok; }. undefbehavior.MinusOnePosType; (C++); Undefined behavior: passing -1 to any streambuf/; istream/ostream member that accepts a value of; type traits::pos_type result in undefined behavior.; Source: C++03 27.4.3.2p3; C++11 27.5.4.2p3. #include <fstream>. class my_streambuf : public std::streambuf {; void f() {; seekpos(-1); // warn; }; };. #include <fstream>. void test() {; std::filebuf fb;; std::istream in(&fb);; std::filebuf::off_type pos(-1);; in.seekg(pos); // warn; }. different. Name, DescriptionExampleProgress. different.SuccessiveAssign; (C); Successive assign to a variable. int test() {; int i;; i=1;; i=2; // warn; return i;; }. different.NullDerefStmtOrder; (C); Dereferencing of the null pointer might take place. Checking the pointer for; null should be performed first.; Note: possibly an enhancement to ; core.NullDereference. struct S {; int x;; };. struct S* f();. void test() {; struct S *p1 = f();; int x1 = p1->x; // warn; if (p1) {};. struct S *p2 = f();; int x2 = p2->x; // ok; }. different.NullDerefCondOrder; (C); Dereferencing of the null pointer might take place. Checking the pointer for; null should be performed first.; Note: possibly an enhancement to ; core.NullDereference. struct S {int i;};. struct S* f();. void test() {; struct S *p = f();; if (p->i && p) {}; // warn; }. different.MultipleAccessors; (C++); Identical accessor bodies. Possibly a misprint. class A {; int i;; int j;; public:; int getI() { return i; }; int getJ() { return i; } // warn; };. class A {; int i;; int j;; public:; void setI(int& ii) { i = ii; }; void setJ(int& jj) { i = jj; } // warn; };. different.AccessorsForPublic; (C++); Accessors exist for a public class field. Should this field really be; public?. class A {; public:; int i; // warn; int getI() { return i; }; void setI(int& ii) { ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html:19959,enhance,enhancement,19959,interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,1,['enhance'],['enhancement']
Modifiability,"y_string ""a b c d""). Lists of Lists; --------------. One of the more complicated patterns in CMake is lists of lists. Because a list; cannot contain an element with a semi-colon to construct a list of lists you; make a list of variable names that refer to other lists. For example:. .. code-block:: cmake. set(list_of_lists a b c); set(a 1 2 3); set(b 4 5 6); set(c 7 8 9). With this layout you can iterate through the list of lists printing each value; with the following code:. .. code-block:: cmake. foreach(list_name IN LISTS list_of_lists); foreach(value IN LISTS ${list_name}); message(${value}); endforeach(); endforeach(). You'll notice that the inner foreach loop's list is doubly dereferenced. This is; because the first dereference turns ``list_name`` into the name of the sub-list; (a, b, or c in the example), then the second dereference is to get the value of; the list. This pattern is used throughout CMake, the most common example is the compiler; flags options, which CMake refers to using the following variable expansions:; CMAKE_${LANGUAGE}_FLAGS and CMAKE_${LANGUAGE}_FLAGS_${CMAKE_BUILD_TYPE}. Other Types; -----------. Variables that are cached or specified on the command line can have types; associated with them. The variable's type is used by CMake's UI tool to display; the right input field. A variable's type generally doesn't impact evaluation,; however CMake does have special handling for some variables such as PATH.; You can read more about the special handling in `CMake's set documentation; <https://cmake.org/cmake/help/v3.5/command/set.html#set-cache-entry>`_. Scope; -----. CMake inherently has a directory-based scoping. Setting a variable in a; CMakeLists file, will set the variable for that file, and all subdirectories.; Variables set in a CMake module that is included in a CMakeLists file will be; set in the scope they are included from, and all subdirectories. When a variable that is already set is set again in a subdirectory it overrides; the valu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:5591,variab,variable,5591,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst,1,['variab'],['variable']
Modifiability,"yms are; valuable [ParzyszekAcronym]_ [LattnerAcronym]_. The most commonly cited acronym; is ``TLI`` however that is used to refer to both ``TargetLowering`` and; ``TargetLibraryInfo`` [GreeneDistinguish]_. The following is a list of acronyms considered sufficiently useful that the; benefit of using them outweighs the cost of learning them. Acronyms that are; either not on the list or are used to refer to a different type should be; expanded. ============================ =============; Class name Variable name; ============================ =============; DeterministicFiniteAutomaton dfa; DominatorTree dt; LoopInfo li; MachineFunction mf; MachineInstr mi; MachineRegisterInfo mri; ScalarEvolution se; TargetInstrInfo tii; TargetLibraryInfo tli; TargetRegisterInfo tri; ============================ =============. In some cases renaming acronyms to the full type name will result in overly; verbose code. Unlike most classes, a variable's scope is limited and therefore; some of its purpose can implied from that scope, meaning that fewer words are; necessary to give it a clear name. For example, in an optimization pass the reader; can assume that a variable's purpose relates to optimization and therefore an; ``OptimizationRemarkEmitter`` variable could be given the name ``remarkEmitter``; or even ``remarker``. The following is a list of longer class names and the associated shorter; variable name. ========================= =============; Class name Variable name; ========================= =============; BasicBlock block; ConstantExpr expr; ExecutionEngine engine; MachineOperand operand; OptimizationRemarkEmitter remarker; PreservedAnalyses analyses; PreservedAnalysesChecker checker; TargetLowering lowering; TargetMachine machine; ========================= =============. Transition Options; ==================. There are three main options for transitioning:. 1. Keep the current coding standard; 2. Laissez faire; 3. Big bang. Keep the current coding standard; -----------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst:6450,variab,variable,6450,interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst,1,['variab'],['variable']
Modifiability,"you must export ``MACOSX_DEPLOYMENT_TARGET=10.9`` before running; the script. This script builds three phases of Clang+LLVM twice each (Release and; Release+Asserts), so use screen or nohup to avoid headaches, since it'll take; a long time. Use the ``--help`` option to see all the options and chose it according to; your needs. findRegressions-nightly.py; --------------------------. TODO. .. _test-suite:. Test Suite; ==========. .. contents::; :local:. Follow the `LNT Quick Start Guide; <https://llvm.org/docs/lnt/quickstart.html>`__ link on how to set-up the; test-suite. The binary location you'll have to use for testing is inside the; ``rcN/Phase3/Release+Asserts/llvmCore-REL-RC.install``.; Link that directory to an easier location and run the test-suite. An example on the run command line, assuming you created a link from the correct; install directory to ``~/devel/llvm/install``::. ./sandbox/bin/python sandbox/bin/lnt runtest \; nt \; -j4 \; --sandbox sandbox \; --test-suite ~/devel/llvm/test/test-suite \; --cc ~/devel/llvm/install/bin/clang \; --cxx ~/devel/llvm/install/bin/clang++. It should have no new regressions, compared to the previous release or release; candidate. You don't need to fix all the bugs in the test-suite, since they're; not necessarily meant to pass on all architectures all the time. This is; due to the nature of the result checking, which relies on direct comparison,; and most of the time, the failures are related to bad output checking, rather; than bad code generation. If the errors are in LLVM itself, please report every single regression found; as blocker, and all the other bugs as important, but not necessarily blocking; the release to proceed. They can be set as ""known failures"" and to be; fix on a future date. .. _pre-release-process:. Pre-Release Process; ===================. .. contents::; :local:. When the release process is announced on the mailing list, you should prepare; for the testing, by applying the same testing you'll do on",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst:3873,sandbox,sandbox,3873,interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseProcess.rst,4,['sandbox'],['sandbox']
Modifiability,"yout you can iterate through the list of lists printing each value; with the following code:. .. code-block:: cmake. foreach(list_name IN LISTS list_of_lists); foreach(value IN LISTS ${list_name}); message(${value}); endforeach(); endforeach(). You'll notice that the inner foreach loop's list is doubly dereferenced. This is; because the first dereference turns ``list_name`` into the name of the sub-list; (a, b, or c in the example), then the second dereference is to get the value of; the list. This pattern is used throughout CMake, the most common example is the compiler; flags options, which CMake refers to using the following variable expansions:; CMAKE_${LANGUAGE}_FLAGS and CMAKE_${LANGUAGE}_FLAGS_${CMAKE_BUILD_TYPE}. Other Types; -----------. Variables that are cached or specified on the command line can have types; associated with them. The variable's type is used by CMake's UI tool to display; the right input field. A variable's type generally doesn't impact evaluation,; however CMake does have special handling for some variables such as PATH.; You can read more about the special handling in `CMake's set documentation; <https://cmake.org/cmake/help/v3.5/command/set.html#set-cache-entry>`_. Scope; -----. CMake inherently has a directory-based scoping. Setting a variable in a; CMakeLists file, will set the variable for that file, and all subdirectories.; Variables set in a CMake module that is included in a CMakeLists file will be; set in the scope they are included from, and all subdirectories. When a variable that is already set is set again in a subdirectory it overrides; the value in that scope and any deeper subdirectories. The CMake set command provides two scope-related options. PARENT_SCOPE sets a; variable into the parent scope, and not the current scope. The CACHE option sets; the variable in the CMakeCache, which results in it being set in all scopes. The; CACHE option will not set a variable that already exists in the CACHE unless the; FORCE option i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:5893,variab,variable,5893,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst,2,['variab'],"['variable', 'variables']"
Modifiability,"yout. - The scheduling the I/O customization rules within a StreamerInfo is now as soon as possible, i.e. after all sources have been read. One significant consequence is that now when an object is stored in a split branch; the rule is associtated with the branch of the last of the rule's sources rather; than the last of the object's data member. - Properly support TStreamerInfo written by ROOT v4.00. - Fix the ordering of the keys in a TFile being written; in particular fixing the result of GetKey and FindKey which were no longer returning the lastest cycle for a TFile being written since v5.34/11. ## Networking Libraries. ### HTTP Server. ##### Command Interface; One can now register an arbitrary command to the server, which become visible in the web browser. Then, when the item is clicked by the user, the command ends-up in a gROOT->ProcessLineSync() call. ##### Custom Properties ; Custom properties can be configured for any item in the server. For example, one could configure an icon for each item visible in the browser. Or one could 'hide' any item from the user (but keep access with normal http requests). With such properties one could specify which item is drawn when web page is loaded, or configure monitoring. See tutorials/http/httpcontrol.C macro for more details. ##### Method Calls; Implement exe.json requests to be able to execute any method of registered objects. This request is used to provide remote TTree::Draw() functionality. ##### Misc; Correctly set 'Cache-Control' headers when replying to http requests.; Better support of STL containers when converting objects into json with TBufferJSON class. ## JavaScript ROOT. - Several files can now be loaded simultaneously; - Use d3.time.scale to display time scales; - Implemented drag and drop to superimpose histograms or graphs; - Allow selection of drawing option via context menu; - Better support of touch devices; - Provide simple layout, making it default; - Allow to open ROOT files in online session (vi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:9702,config,configure,9702,README/ReleaseNotes/v604/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md,1,['config'],['configure']
Modifiability,"ype hierarchy in C++ programs. The first is; a genuine type hierarchy where different types in the hierarchy model; a specific subset of the functionality and semantics, and these types nest; strictly within each other. Good examples of this can be seen in the ``Value``; or ``Type`` type hierarchies. A second is the desire to dispatch dynamically across a collection of; polymorphic interface implementations. This latter use case can be modeled with; virtual dispatch and inheritance by defining an abstract interface base class; which all implementations derive from and override. However, this; implementation strategy forces an **""is-a""** relationship to exist that is not; actually meaningful. There is often not some nested hierarchy of useful; generalizations which code might interact with and move up and down. Instead,; there is a singular interface which is dispatched across a range of; implementations. The preferred implementation strategy for the second use case is that of; generic programming (sometimes called ""compile-time duck typing"" or ""static; polymorphism""). For example, a template over some type parameter ``T`` can be; instantiated across any particular implementation that conforms to the; interface or *concept*. A good example here is the highly generic properties of; any type which models a node in a directed graph. LLVM models these primarily; through templates and generic programming. Such templates include the; ``LoopInfoBase`` and ``DominatorTreeBase``. When this type of polymorphism; truly needs **dynamic** dispatch you can generalize it using a technique; called *concept-based polymorphism*. This pattern emulates the interfaces and; behaviors of templates using a very limited form of virtual dispatch for type; erasure inside its implementation. You can find examples of this technique in; the ``PassManager.h`` system, and there is a more detailed introduction to it; by Sean Parent in several of his talks and papers:. #. `Inheritance Is The Base Clas",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:130165,polymorphi,polymorphism,130165,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['polymorphi'],['polymorphism']
Modifiability,"ype is; determined at runtime and we are not 100% sure that our type info is; correct. For virtual calls, inline the most plausible definition. * ``analyzer-config ipa=dynamic-bifurcate`` - Same as -analyzer-config ipa=dynamic,; but the path is split. We inline on one branch and do not inline on the; other. This mode does not drop the coverage in cases when the parent class; has code that is only exercised when some of its methods are overridden. Currently, ``-analyzer-config ipa=dynamic-bifurcate`` is the default mode. While ``-analyzer-config ipa`` determines in general how aggressively the analyzer; will try to inline functions, several additional options control which types of; functions can inlined, in an all-or-nothing way. These options use the; analyzer's configuration table, so they are all specified as follows:. ``-analyzer-config OPTION=VALUE``. c++-inlining; ------------. This option controls which C++ member functions may be inlined. ``-analyzer-config c++-inlining=[none | methods | constructors | destructors]``. Each of these modes implies that all the previous member function kinds will be; inlined as well; it doesn't make sense to inline destructors without inlining; constructors, for example. The default c++-inlining mode is 'destructors', meaning that all member; functions with visible definitions will be considered for inlining. In some; cases the analyzer may still choose not to inline the function. Note that under 'constructors', constructors for types with non-trivial; destructors will not be inlined. Additionally, no C++ member functions will be; inlined under -analyzer-config ipa=none or -analyzer-config ipa=basic-inlining,; regardless of the setting of the c++-inlining mode. c++-template-inlining; ^^^^^^^^^^^^^^^^^^^^^. This option controls whether C++ templated functions may be inlined. ``-analyzer-config c++-template-inlining=[true | false]``. Currently, template functions are considered for inlining by default. The motivation behind this o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst:1913,config,config,1913,interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst,1,['config'],['config']
Modifiability,"ype of a thrown exception differs from those specified in; a throw(type) specifier. struct S{};. void test() throw(int) {; S s;; throw (s); // warn; }. smart pointers. Name, DescriptionExampleProgress. smartptr.SmartPtrInit; (C++); C++03: auto_ptr should store a pointer to an object obtained via; new as allocated memory will be cleaned using delete.; C++11: one should use unique_ptr<type[]> to keep a; pointer to memory allocated by new[].; C++11: to keep a pointer to memory allocated by new[] in; a shared_ptr one should use a custom deleter that calls ; delete[]..; Source: C++03 20.4.5p1; C++11 auto_ptr is deprecated (D.10). #include <stdlib.h>; #include <memory>. void test() {; std::auto_ptr<int> p1(new int); // Ok; std::auto_ptr<int> p2(new int[3]); // warn; }. #include <stdlib.h>; #include <memory>. void test() {; std::auto_ptr<int> p((int *)malloc(sizeof(int))); // warn; }. dead code. Name, DescriptionExampleProgress. deadcode.UnmodifiedVariable; (C, C++); A variable is never modified but was not declared const and is not a; reference.(opt-in checker). extern int computeDelta();. int test(bool cond) {; int i = 0;; if (cond) {; const int delta = computeDelta();; // warn: forgot to modify 'i'; }; return i;; }. PR16890. deadcode.IdempotentOperations; (C); Warn about idempotent operations. void test() {; int x = 7;; x = x; // warn: value is always the same; }. void test() {; int x = 7;; x /= x; // warn: value is always 1; }. void test() {; int x = 7, one = 1;; x *= one; // warn: right op is always 1; }. void test() {; int x = 7, zero = 0;; x = x - zero;; // warn: the right operand to '-' is always 0; }. removed from alpha.deadcode.* at; r198476. POSIX. Name, DescriptionExampleProgress. posix.Errno; (C); Record that errno is non-zero when certain functions; fail. #include <stdlib.h>. int readWrapper(int fd, int *count) {; int lcount = read(fd, globalBuf, sizeof(globalBuf));; if (lcount < 0); return errno;; *count = lcount;; return 0;; }. void use(int fd) {; int count",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html:4224,variab,variable,4224,interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,1,['variab'],['variable']
Modifiability,"ype_information>`_, for example,; ``dynamic_cast<>``). That said, LLVM does make extensive use of a hand-rolled form of RTTI that use; templates like :ref:`isa\<>, cast\<>, and dyn_cast\<> <isa>`.; This form of RTTI is opt-in and can be; :doc:`added to any class <HowToSetUpLLVMStyleRTTI>`. Prefer C++-style casts; ^^^^^^^^^^^^^^^^^^^^^^. When casting, use ``static_cast``, ``reinterpret_cast``, and ``const_cast``,; rather than C-style casts. There are two exceptions to this:. * When casting to ``void`` to suppress warnings about unused variables (as an; alternative to ``[[maybe_unused]]``). Prefer C-style casts in this instance. * When casting between integral types (including enums that are not strongly-; typed), functional-style casts are permitted as an alternative to; ``static_cast``. .. _static constructor:. Do not use Static Constructors; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Static constructors and destructors (e.g., global variables whose types have a; constructor or destructor) should not be added to the code base, and should be; removed wherever possible. Globals in different source files are initialized in `arbitrary order; <https://yosefk.com/c++fqa/ctors.html#fqa-10.12>`_, making the code more; difficult to reason about. Static constructors have negative impact on launch time of programs that use; LLVM as a library. We would really like for there to be zero cost for linking; in an additional LLVM target or other library into an application, but static; constructors undermine this goal. Use of ``class`` and ``struct`` Keywords; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. In C++, the ``class`` and ``struct`` keywords can be used almost; interchangeably. The only difference is when they are used to declare a class:; ``class`` makes all members private by default while ``struct`` makes all; members public by default. * All declarations and definitions of a given ``class`` or ``struct`` must use; the same keyword. For example:. .. code-block:: c++. // Avoid if `Example",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:23346,variab,variables,23346,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['variab'],['variables']
Modifiability,"ype`` carries a reference to its owning context, most other entities can; determine what context they belong to by looking at their own ``Type``. If you; are adding new entities to LLVM IR, please try to maintain this interface; design. .. _jitthreading:. Threads and the JIT; -------------------. LLVM's ""eager"" JIT compiler is safe to use in threaded programs. Multiple; threads can call ``ExecutionEngine::getPointerToFunction()`` or; ``ExecutionEngine::runFunction()`` concurrently, and multiple threads can run; code output by the JIT concurrently. The user must still ensure that only one; thread accesses IR in a given ``LLVMContext`` while another thread might be; modifying it. One way to do that is to always hold the JIT lock while accessing; IR outside the JIT (the JIT *modifies* the IR by adding ``CallbackVH``\ s).; Another way is to only call ``getPointerToFunction()`` from the; ``LLVMContext``'s thread. When the JIT is configured to compile lazily (using; ``ExecutionEngine::DisableLazyCompilation(false)``), there is currently a `race; condition <https://bugs.llvm.org/show_bug.cgi?id=5184>`_ in updating call sites; after a function is lazily-jitted. It's still possible to use the lazy JIT in a; threaded program if you ensure that only one thread at a time can call any; particular lazy stub and that the JIT lock guards any IR access, but we suggest; using only the eager JIT in threaded programs. .. _advanced:. Advanced Topics; ===============. This section describes some of the advanced or obscure API's that most clients; do not need to be aware of. These API's tend manage the inner workings of the; LLVM system, and only need to be accessed in unusual circumstances. .. _SymbolTable:. The ``ValueSymbolTable`` class; ------------------------------. The ``ValueSymbolTable`` (`doxygen; <https://llvm.org/doxygen/classllvm_1_1ValueSymbolTable.html>`__) class provides; a symbol table that the :ref:`Function <c_Function>` and Module_ classes use for; naming value definiti",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:124749,config,configured,124749,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['config'],['configured']
Modifiability,"ypes; supported by QL you will get a window showing the file content, for file types; not supported you will get a generic window showing some basic file info. The idea of QL is that file content can be shown without the heavy application; startup process. Generating a QL view of a ROOT file depends on the size of the; file, but generally it is a quick operation. Get the binary for the ROOTQL plugin from:. ftp://root.cern.ch/root/ROOTQL.tgz. To install the plugin, after untarring the above file, just drag the bundle; ROOTQL.qlgenerator to /Library/QuickLook (global, i.e. for all users on a; system) or to ~/Library/QuickLook (local, this user only) directory.; You may need to create that folder if it doesn't already exist. To build from source, get it from svn using:. svn co http://root.cern.ch/svn/root/trunk/misc/rootql rootql. Open the ROOTQL project in Xcode and click on ""Build"" (make sure the Active; Build Configuration is set the ""Release""). Copy the resulting; plugin from build/Release to the desired QuickLook directory. SpotLight plugin for MacOS X. This is a Spotlight plugin that allows ROOT files to be indexed by SL.; Once indexed SL can find ROOT files based on the names and titles of the; objects in the files. Spotlight is available on MacOS X since version 10.4 (Tiger). To use SL; select the SL icon on the top right of the menubar and type in a search text. Get the binary for the ROOTSL plugin from:. ftp://root.cern.ch/root/ROOTSL.tgz. To install the plugin, after untarring the above file, just drag the bundle; ROOTSL.mdimporter to /Library/Spotlight (global, i.e. for all users on a; system) or to ~/Library/Spotlight (local, this user only) directory.; You may need to create that folder if it doesn't already exist. To build from source, get it from svn using:. svn co http://root.cern.ch/svn/root/trunk/misc/rootsl rootsl. Open the ROOTSL project in Xcode and click on ""Build"" (make sure the Active; Build Configuration is set the ""Release""). Copy the resulti",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/misc/doc/v524/index.html:1249,plugin,plugin,1249,misc/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/misc/doc/v524/index.html,1,['plugin'],['plugin']
Modifiability,"ys whose size is a value-dependent expression. Given; template<typename T, int Size>; class array {; T data[Size];; };; dependentSizedArrayType(); matches ""T data[Size]"". Matcher<Type>dependentSizedExtVectorTypeMatcher<DependentSizedExtVectorType>...; Matches C++ extended vector type where either the type or size is; dependent. Given; template<typename T, int Size>; class vector {; typedef T __attribute__((ext_vector_type(Size))) type;; };; dependentSizedExtVectorType(); matches ""T __attribute__((ext_vector_type(Size)))"". Matcher<Type>elaboratedTypeMatcher<ElaboratedType>...; Matches types specified with an elaborated type keyword or with a; qualified name. Given; namespace N {; namespace M {; class D {};; }; }; class C {};. class C c;; N::M::D d;. elaboratedType() matches the type of the variable declarations of both; c and d. Matcher<Type>enumTypeMatcher<EnumType>...; Matches enum types. Given; enum C { Green };; enum class S { Red };. C c;; S s;. enumType() matches the type of the variable declarations of both c and; s. Matcher<Type>functionProtoTypeMatcher<FunctionProtoType>...; Matches FunctionProtoType nodes. Given; int (*f)(int);; void g();; functionProtoType(); matches ""int (*f)(int)"" and the type of ""g"" in C++ mode.; In C mode, ""g"" is not matched because it does not contain a prototype. Matcher<Type>functionTypeMatcher<FunctionType>...; Matches FunctionType nodes. Given; int (*f)(int);; void g();; functionType(); matches ""int (*f)(int)"" and the type of ""g"". Matcher<Type>incompleteArrayTypeMatcher<IncompleteArrayType>...; Matches C arrays with unspecified size. Given; int a[] = { 2, 3 };; int b[42];; void f(int c[]) { int d[a[0]]; };; incompleteArrayType(); matches ""int a[]"" and ""int c[]"". Matcher<Type>injectedClassNameTypeMatcher<InjectedClassNameType>...; Matches injected class name types. Example matches S s, but not S<T> s.; (matcher = parmVarDecl(hasType(injectedClassNameType()))); template <typename T> struct S {; void f(S s);; void g(S<T> s);; };. Matc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html:47988,variab,variable,47988,interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,1,['variab'],['variable']
Modifiability,"ysis results from the outer analysis manager; should be immutable, so invalidation shouldn't be a concern. However, it is; possible for some inner analysis to depend on some outer analysis, and when; the outer analysis is invalidated, we need to make sure that dependent inner; analyses are also invalidated. This actually happens with alias analysis; results. Alias analysis is a function-level analysis, but there are; module-level implementations of specific types of alias analysis. Currently; ``GlobalsAA`` is the only module-level alias analysis and it generally is not; invalidated so this is not so much of a concern. See; ``OuterAnalysisManagerProxy::Result::registerOuterAnalysisInvalidation()``; for more details. Invoking ``opt``; ================. .. code-block:: shell. $ opt -passes='pass1,pass2' /tmp/a.ll -S; # -p is an alias for -passes; $ opt -p pass1,pass2 /tmp/a.ll -S. The new PM typically requires explicit pass nesting. For example, to run a; function pass, then a module pass, we need to wrap the function pass in a module; adaptor:. .. code-block:: shell. $ opt -passes='function(no-op-function),no-op-module' /tmp/a.ll -S. A more complete example, and ``-debug-pass-manager`` to show the execution; order:. .. code-block:: shell. $ opt -passes='no-op-module,cgscc(no-op-cgscc,function(no-op-function,loop(no-op-loop))),function(no-op-function,loop(no-op-loop))' /tmp/a.ll -S -debug-pass-manager. Improper nesting can lead to error messages such as. .. code-block:: shell. $ opt -passes='no-op-function,no-op-module' /tmp/a.ll -S; opt: unknown function pass 'no-op-module'. The nesting is: module (-> cgscc) -> function -> loop, where the CGSCC nesting is optional. There are a couple of special cases for easier typing:. * If the first pass is not a module pass, a pass manager of the first pass is; implicitly created. * For example, the following are equivalent. .. code-block:: shell. $ opt -passes='no-op-function,no-op-function' /tmp/a.ll -S; $ opt -passes='function(no",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst:18641,adapt,adaptor,18641,interpreter/llvm-project/llvm/docs/NewPassManager.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NewPassManager.rst,1,['adapt'],['adaptor']
Modifiability,"ysis, financial movements'; predictions and analysis, or sales forecast and product shipping; optimization. In particles physics neural networks are mainly used for; classification tasks (signal over background discrimination). A vast; majority of commonly used neural networks are multilayer perceptrons.; This implementation of multilayer perceptrons is inspired from the; `MLPfit` package, which remains one of the fastest tools for neural; networks studies. ### The MLP. The multilayer perceptron is a simple feed-forward network with the; following structure showed on the left. ![](pictures/0300008D.png). It is made of neurons characterized by a bias and weighted links in; between - let's call those links synapses. The input neurons receive; the inputs, normalize them and forward them to the first hidden layer.; Each neuron in any subsequent layer first computes a linear; combination of the outputs of the previous layer. The output of the; neuron is then function of that combination with f being linear for; output neurons or a sigmoid for hidden layers. Such a structure is very useful because of two theorems:. 1- A linear combination of `sigmoids` can approximate any continuous; function. 2- Trained with `output=1` for the signal and 0 for the background,; the approximated function of inputs `X` is the probability of signal,; knowing `X`. ### Learning Methods. The aim of all learning methods is to minimize the total error on a; set of weighted examples. The error is defined as the sum in quadrate,; divided by two, of the error on each individual output neuron. In all; methods implemented in this library, one needs to compute the first; derivative of that error with respect to the weights. Exploiting the; well-known properties of the derivative, one can express this; derivative as the product of the local partial derivative by the; weighted sum of the outputs derivatives (for a neuron) or as the; product of the input value with the local partial derivative of the; outp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:71081,layers,layers,71081,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['layers'],['layers']
Modifiability,"yzer-config ipa``:. * ``analyzer-config ipa=none`` - All inlining is disabled. This is the only mode; available in LLVM 3.1 and earlier and in Xcode 4.3 and earlier. * ``analyzer-config ipa=basic-inlining`` - Turns on inlining for C functions, C++; static member functions, and blocks -- essentially, the calls that behave; like simple C function calls. This is essentially the mode used in; Xcode 4.4. * ``analyzer-config ipa=inlining`` - Turns on inlining when we can confidently find; the function/method body corresponding to the call. (C functions, static; functions, devirtualized C++ methods, Objective-C class methods, Objective-C; instance methods when ExprEngine is confident about the dynamic type of the; instance). * ``analyzer-config ipa=dynamic`` - Inline instance methods for which the type is; determined at runtime and we are not 100% sure that our type info is; correct. For virtual calls, inline the most plausible definition. * ``analyzer-config ipa=dynamic-bifurcate`` - Same as -analyzer-config ipa=dynamic,; but the path is split. We inline on one branch and do not inline on the; other. This mode does not drop the coverage in cases when the parent class; has code that is only exercised when some of its methods are overridden. Currently, ``-analyzer-config ipa=dynamic-bifurcate`` is the default mode. While ``-analyzer-config ipa`` determines in general how aggressively the analyzer; will try to inline functions, several additional options control which types of; functions can inlined, in an all-or-nothing way. These options use the; analyzer's configuration table, so they are all specified as follows:. ``-analyzer-config OPTION=VALUE``. c++-inlining; ------------. This option controls which C++ member functions may be inlined. ``-analyzer-config c++-inlining=[none | methods | constructors | destructors]``. Each of these modes implies that all the previous member function kinds will be; inlined as well; it doesn't make sense to inline destructors without inlin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst:1097,config,config,1097,interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/analyzer/developer-docs/IPA.rst,2,['config'],['config']
Modifiability,"y| Libraries to link against. |; +----------------------+---------------------------------------------------------------------------------------------+; |H_DIRS directory | Base directories for H_FILES. |; +----------------------+---------------------------------------------------------------------------------------------+; |H_FILES h_file | Header files for which to generate bindings in pkg. |; | | Absolute filenames, or filenames relative to H_DIRS. All |; | | definitions found directly in these files will contribute |; | | to the bindings. (NOTE: This means that if ""forwarding |; | | headers"" are present, the real ""legacy"" headers must be |; | | specified as H_FILES). |; | | All header files which contribute to a given C++ namespace |; | | should be grouped into a single pkg to ensure a 1-to-1 |; | | mapping with the implementing Python class. |; +----------------------+---------------------------------------------------------------------------------------------+. Returns via PARENT_SCOPE variables::. target The CMake target used to build.; setup_py The setup.py script used to build or install pkg. Examples::. find_package(Qt5Core NO_MODULE); find_package(KF5KDcraw NO_MODULE); get_target_property(_H_DIRS KF5::KDcraw INTERFACE_INCLUDE_DIRECTORIES); get_target_property(_LINK_LIBRARIES KF5::KDcraw INTERFACE_LINK_LIBRARIES); set(_LINK_LIBRARIES KF5::KDcraw ${_LINK_LIBRARIES}); include(${KF5KDcraw_DIR}/KF5KDcrawConfigVersion.cmake). cppyy_add_bindings(; ""KDCRAW"" ""${PACKAGE_VERSION}"" ""Shaheed"" ""srhaque@theiet.org""; LANGUAGE_STANDARD ""14""; LINKDEFS ""../linkdef_overrides.h""; GENERATE_OPTIONS ""-D__PIC__;-Wno-macro-redefined""; INCLUDE_DIRS ${Qt5Core_INCLUDE_DIRS}; LINK_LIBRARIES ${_LINK_LIBRARIES}; H_DIRS ${_H_DIRS}; H_FILES ""dcrawinfocontainer.h;kdcraw.h;rawdecodingsettings.h;rawfiles.h""). cppyy_find_pips; ^^^^^^^^^^^^^^^. Return a list of available pip programs. .. _`support for exporting all`: https://cmake.org/cmake/help/latest/prop_tgt/WINDOWS_EXPORT_ALL_SYMBOLS.html;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:10404,variab,variables,10404,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,1,['variab'],['variables']
Modifiability,"zation of `TDirectory` in favor of item-getting syntax. The new recommended way to get objects from a `TFile` or any `TDirectory` in general is now via `__getitem__`:. ```python; tree = my_file[""my_tree""] # instead of my_file.my_tree; ```. This is more consistent with other Python collections (like dictionaries), makes sure that member functions can't be confused with branch names, and easily allows you to use string variables as keys. With the new dictionary-like syntax, you can also get objects with names that don't qualify as a Python variable. Here is a short demo:; ```python; import ROOT. with ROOT.TFile.Open(""my_file.root"", ""RECREATE"") as my_file:. # Populate the TFile with simple objects.; my_file.WriteObject(ROOT.std.string(""hello world""), ""my_string""); my_file.WriteObject(ROOT.vector[""int""]([1, 2, 3]), ""my vector""). print(my_file[""my_string""]) # new syntax; print(my_file.my_string) # old deprecated syntax. # With the dictionary syntax, you can also use names that don't qualify as; # a Python variable:; print(my_file[""my vector""]); # print(my_file.my vector) # the old syntax would not work here!; ```. The old pythonization with the `__getattr__` syntax still works, but emits a deprecation warning and will be removed from ROOT 6.34. ### Removal of Python 2 support. ROOT does no longer support Python 2. The minimum Python version necessary to use ROOT in a Python application is 3.8.; As a consequence, any reference to Python 2 in ROOT code was removed and certain configuration options are no longer; usable, e.g. * `root-config --python2-version`; * cmake -Dpyroot-python2. The cmake build system now looks for the standard `Python3` package and previously custom Python-related cmake variables; are now just the ones automatically produced by cmake (see https://cmake.org/cmake/help/latest/module/FindPython.html). ### More usage of the public cppyy API. Many implementation details of the ROOT pythonizations were moved from C++ functions to pure Python bindings usin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md:22167,variab,variable,22167,README/ReleaseNotes/v632/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v632/index.md,1,['variab'],['variable']
Modifiability,"zation`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnSCC; <writing-an-llvm-pass-runOnSCC>` for every SCC in the program being compiled. .. _writing-an-llvm-pass-FunctionPass:. The ``FunctionPass`` class; --------------------------. In contrast to ``ModulePass`` subclasses, `FunctionPass; <https://llvm.org/doxygen/classllvm_1_1Pass.html>`_ subclasses do have a; predictable, local behavior that can be expected by the system. All; ``FunctionPass`` execute on each function in the program independent of all of; the other functions in the program. ``FunctionPass``\ es do not require that; they are executed in a particular order, and ``FunctionPass``\ es do not modify; external functions. To be explicit, ``FunctionPass`` subclasses are not allowed to:. #. Inspect or modify a ``Function`` other than the one currently being processed.; #. Add or remove ``Function``\ s from the current ``Module``.; #. Add or remove global variables from the current ``Module``.; #. Maintain state across invocations of :ref:`runOnFunction; <writing-an-llvm-pass-runOnFunction>` (including global data). Implementing a ``FunctionPass`` is usually straightforward (See the :ref:`Hello; World <writing-an-llvm-pass-basiccode>` pass for example).; ``FunctionPass``\ es may override three virtual methods to do their work. All; of these methods should return ``true`` if they modified the program, or; ``false`` if they didn't. .. _writing-an-llvm-pass-doInitialization-mod:. The ``doInitialization(Module &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Module &M);. The ``doInitialization`` method is allowed to do most of the things that; ``FunctionPass``\ es are not allowed to do. They can add and remove functions,; get pointers to functions, etc. The ``doInitialization`` method is designed to; do simple initialization type of stuff that does not depend on the functions; being processe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:17819,variab,variables,17819,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['variab'],['variables']
Modifiability,"ze a ``T __strong *`` with a ``U __strong *``. For purposes of overload resolution, an implicit conversion sequence requiring; a pass-by-writeback is always worse than an implicit conversion sequence not; requiring a pass-by-writeback. The pass-by-writeback is ill-formed if the argument expression does not have a; legal form:. * ``&var``, where ``var`` is a scalar variable of automatic storage duration; with retainable object pointer type; * a conditional expression where the second and third operands are both legal; forms; * a cast whose operand is a legal form; * a null pointer constant. .. admonition:: Rationale. The restriction in the form of the argument serves two purposes. First, it; makes it impossible to pass the address of an array to the argument, which; serves to protect against an otherwise serious risk of mis-inferring an; ""array"" argument as an out-parameter. Second, it makes it much less likely; that the user will see confusing aliasing problems due to the implementation,; below, where their store to the writeback temporary is not immediately seen; in the original argument variable. A pass-by-writeback is evaluated as follows:. #. The argument is evaluated to yield a pointer ``p`` of type ``U oq *``.; #. If ``p`` is a null pointer, then a null pointer is passed as the argument,; and no further work is required for the pass-by-writeback.; #. Otherwise, a temporary of type ``T __autoreleasing`` is created and; initialized to a null pointer.; #. If the parameter is not an Objective-C method parameter marked ``out``,; then ``*p`` is read, and the result is written into the temporary with; primitive semantics.; #. The address of the temporary is passed as the argument to the actual call.; #. After the call completes, the temporary is loaded with primitive; semantics, and that value is assigned into ``*p``. .. admonition:: Rationale. This is all admittedly convoluted. In an ideal world, we would see that a; local variable is being passed to an out-parameter",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:49904,variab,variable,49904,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['variab'],['variable']
Modifiability,"ze"" case, but; the stack size is too large to encode in the compact unwind encoding. Instead; it requires that the function contains ""``subl $nnnnnn, %esp``"" in its; prolog. The compact encoding contains the offset to the ``$nnnnnn`` value in; the function in bits 9-12 (mask: ``0x00001C00``). .. _Late Machine Code Optimizations:. Late Machine Code Optimizations; -------------------------------. .. note::. To Be Written. .. _Code Emission:. Code Emission; -------------. The code emission step of code generation is responsible for lowering from the; code generator abstractions (like `MachineFunction`_, `MachineInstr`_, etc) down; to the abstractions used by the MC layer (`MCInst`_, `MCStreamer`_, etc). This; is done with a combination of several different classes: the (misnamed); target-independent AsmPrinter class, target-specific subclasses of AsmPrinter; (such as SparcAsmPrinter), and the TargetLoweringObjectFile class. Since the MC layer works at the level of abstraction of object files, it doesn't; have a notion of functions, global variables etc. Instead, it thinks about; labels, directives, and instructions. A key class used at this time is the; MCStreamer class. This is an abstract API that is implemented in different ways; (e.g. to output a .s file, output an ELF .o file, etc) that is effectively an; ""assembler API"". MCStreamer has one method per directive, such as EmitLabel,; EmitSymbolAttribute, switchSection, etc, which directly correspond to assembly; level directives. If you are interested in implementing a code generator for a target, there are; three important things that you have to implement for your target:. #. First, you need a subclass of AsmPrinter for your target. This class; implements the general lowering process converting MachineFunction's into MC; label constructs. The AsmPrinter base class provides a number of useful; methods and routines, and also allows you to override the lowering process in; some important ways. You should get much of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:75456,variab,variables,75456,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['variab'],['variables']
Modifiability,"ze`.; Higher values lead to more accurate measurements but lengthen the benchmark. .. option:: --loop-body-size=<Preferred loop body size>. Only effective for `-repetition-mode=[loop|min]`.; Instead of looping over the snippet directly, first duplicate it so that the; loop body contains at least this many instructions. This potentially results; in loop body being cached in the CPU Op Cache / Loop Cache, which allows to; which may have higher throughput than the CPU decoders. .. option:: --max-configs-per-opcode=<value>. Specify the maximum configurations that can be generated for each opcode.; By default this is `1`, meaning that we assume that a single measurement is; enough to characterize an opcode. This might not be true of all instructions:; for example, the performance characteristics of the LEA instruction on X86; depends on the value of assigned registers and immediates. Setting a value of; `-max-configs-per-opcode` larger than `1` allows `llvm-exegesis` to explore; more configurations to discover if some register or immediate assignments; lead to different performance characteristics. .. option:: --benchmarks-file=</path/to/file>. File to read (`analysis` mode) or write (`latency`/`uops`/`inverse_throughput`; modes) benchmark results. ""-"" uses stdin/stdout. .. option:: --analysis-clusters-output-file=</path/to/file>. If provided, write the analysis clusters as CSV to this file. ""-"" prints to; stdout. By default, this analysis is not run. .. option:: --analysis-inconsistencies-output-file=</path/to/file>. If non-empty, write inconsistencies found during analysis to this file. `-`; prints to stdout. By default, this analysis is not run. .. option:: --analysis-filter=[all|reg-only|mem-only]. By default, all benchmark results are analysed, but sometimes it may be useful; to only look at those that to not involve memory, or vice versa. This option; allows to either keep all benchmarks, or filter out (ignore) either all the; ones that do involve memory (involve in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:14277,config,configs-per-opcode,14277,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,2,['config'],"['configs-per-opcode', 'configurations']"
Modifiability,"zer, ``inttoptr`` and ``ptrtoint`` for; non-integral types are analogous to ones on integral types with one; key exception: the optimizer may not, in general, insert new dynamic; occurrences of such casts. If a new cast is inserted, the optimizer would; need to either ensure that a) all possible values are valid, or b); appropriate fencing is inserted. Since the appropriate fencing is; implementation defined, the optimizer can't do the latter. The former is; challenging as many commonly expected properties, such as; ``ptrtoint(v)-ptrtoint(v) == 0``, don't hold for non-integral types.; Similar restrictions apply to intrinsics that might examine the pointer bits,; such as :ref:`llvm.ptrmask<int_ptrmask>`. . The alignment information provided by the frontend for a non-integral pointer; (typically using attributes or metadata) must be valid for every possible ; representation of the pointer. .. _globalvars:. Global Variables; ----------------. Global variables define regions of memory allocated at compilation time; instead of run-time. Global variable definitions must be initialized. Global variables in other translation units can also be declared, in which; case they don't have an initializer. Global variables can optionally specify a :ref:`linkage type <linkage>`. Either global variable definitions or declarations may have an explicit section; to be placed in and may have an optional explicit alignment specified. If there; is a mismatch between the explicit or inferred section information for the; variable declaration and its definition the resulting behavior is undefined. A variable may be defined as a global ``constant``, which indicates that; the contents of the variable will **never** be modified (enabling better; optimization, allowing the global data to be placed in the read-only; section of an executable, etc). Note that variables that need runtime; initialization cannot be marked ``constant`` as there is a store to the; variable. LLVM explicitly allows *declar",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:30394,variab,variables,30394,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variables']
Modifiability,"zer-list; Clang 3.7. 1632; CD5; Lambda capture in member initializers; Unknown. 1633; CD4; Copy-initialization in member initialization; Unknown. 1634; drafting; Temporary storage duration; Not resolved. 1635; drafting; How similar are template default arguments to function default arguments?; Not resolved. 1636; CD5; Bits required for negative enumerator values; Unknown. 1637; NAD; Recursion in constexpr template default constructor; Unknown. 1638; CD4; Declaring an explicit specialization of a scoped enumeration; Clang 3.1. 1639; CD4; exception-specifications and pointer/pointer-to-member expressions; Unknown. 1640; CD5; Array of abstract instance of class template; Unknown. 1641; NAD; Assignment in member initializer; Unknown. 1642; DRWP; Missing requirements for prvalue operands; Unknown. 1643; NAD; Default arguments for template parameter packs; Unknown. 1644; NAD; Equivalent exception-specifications in function template declarations; Unknown. 1645; CD4; Identical inheriting constructors via default arguments; Clang 3.9. 1646; CD5; decltype-specifiers, abstract classes, and deduction failure; Unknown. 1647; drafting; Type agreement of non-type template arguments in partial specializations; Not resolved. 1648; C++14; thread_local vs block extern declarations; Unknown. 1649; C++14; Error in the syntax of mem-initializer-list; Unknown. 1650; NAD; Class prvalues in reference initialization; Unknown. 1651; NAD; Lifetime extension of temporary via reference to subobject; Unknown. 1652; CD4; Object addresses in constexpr expressions; Clang 3.6. 1653; CD4; Removing deprecated increment of bool; Clang 4 (C++17 onwards). 1654; dup; Literal types and constexpr defaulted constructors; Unknown. 1655; drafting; Line endings in raw string literals; Not resolved. 1656; CD6; Encoding of numerically-escaped characters; Unknown. 1657; CD4; Attributes for namespaces and enumerators; Unknown. 1658; C++14; Deleted default constructor for abstract class via destructor; Clang 5. 1659; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html:111136,inherit,inheriting,111136,interpreter/llvm-project/clang/www/cxx_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/cxx_dr_status.html,1,['inherit'],['inheriting']
Modifiability,"zerOptions` class.; For example to select `Minuit2` instead of `Minuit` for fitting an histogram do:. ``` {.cpp}; ROOT::Math::MinimizerOptions::SetDefaultMinimizer(""Minuit2"");; // fit the histogram histo with the gaussian pre-defined function; histo->Fit(""gaus"");; ```. In the following we will give some brief description of the minimization packages.; The packages all implement the `ROOT::Math::Minimizer` interface which can be use for; finding the minimum of a multi-dimensional function.; The interface is documented in the Mathematical Library Chapter. In addition packages like Minuit or Minuit2 provide their own interfaces. ## MINUIT (Old TMInuit Version). This package was originally written in FORTRAN by Fred James and part; of `PACKLIB` (patch D506). It has been converted to a C++ class by; René Brun. The current implementation in C++ is a straightforward; conversion of the original FORTRAN version. The main changes are:. - The variables in the various `Minuit` labeled common blocks have; been changed to the **`TMinuit`** class data members. - The internal arrays with a maximum dimension depending on the; maximum number of parameters are now data members' arrays with a; dynamic dimension such that one can fit very large problems by; simply initializing the **`TMinuit`** constructor with the maximum; number of parameters. - The include file `Minuit.h` has been commented as much as possible; using existing comments in the code or the printed documentation. - The original `Minuit` subroutines are now member functions. - Constructors and destructor have been added. - Instead of passing the `FCN` function in the argument list, the; addresses of this function is stored as pointer in the data; members of the class. This is by far more elegant and flexible in; an interactive environment. The member function `SetFCN` can be; used to define this pointer. - The ROOT static function `Printf` is provided to replace all; format statements and to print on currently defined out",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:53268,variab,variables,53268,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['variab'],['variables']
Modifiability,"zonk(); br label %exit; falsebr:; %fval = add i32 %bar, 2; call @llvm.dbg.value(metadata i32 %fval, metadata !1, metadata !2); %g2 = call i32 @gazonk(); br label %exit; exit:; %merge = phi [ %tval, %truebr ], [ %fval, %falsebr ]; %g = phi [ %g1, %truebr ], [ %g2, %falsebr ]; call @llvm.dbg.value(metadata i32 %merge, metadata !1, metadata !2); call @llvm.dbg.value(metadata i32 %g, metadata !3, metadata !2); %plusten = add i32 %merge, 10; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2); ret i32 %toret; }. Containing two source-level variables in ``!1`` and ``!3``. The function could,; perhaps, be optimized into the following code:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; %g = call i32 @gazonk(); %addoper = select i1 %cond, i32 11, i32 12; %plusten = add i32 %bar, %addoper; %toret = add i32 %plusten, %g; ret i32 %toret; }. What ``llvm.dbg.value`` intrinsics should be placed to represent the original variable; locations in this code? Unfortunately the second, third and fourth; dbg.values for ``!1`` in the source function have had their operands; (%tval, %fval, %merge) optimized out. Assuming we cannot recover them, we; might consider this placement of dbg.values:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); %g = call i32 @gazonk(); call @llvm.dbg.value(metadata i32 %g, metadata !3, metadata !2); %addoper = select i1 %cond, i32 11, i32 12; %plusten = add i32 %bar, %addoper; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2); ret i32 %toret; }. However, this will cause ``!3`` to have the return value of ``@gazonk()`` at; the same time as ``!1`` has the constant value zero -- a pair of assignments; that never occurred in the unoptimized program. To avoid this, we must terminate; the range that ``!1`` has the constant value assignment by inserting a poison; dbg",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:21207,variab,variable,21207,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['variab'],['variable']
Modifiability,"{#; sphinxdoc/layout.html; ~~~~~~~~~~~~~~~~~~~~~. Sphinx layout template for the sphinxdoc theme. :copyright: Copyright 2007-2010 by the Sphinx team, see AUTHORS.; :license: BSD, see LICENSE for details.; #}; {% extends ""basic/layout.html"" %}. {% block relbar1 %}. {{ super() }}; {% endblock %}. {# put the sidebar before the body #}; {% block sidebar1 %}{{ sidebar() }}{% endblock %}; {% block sidebar2 %}{% endblock %}; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/_themes/llvm-theme/layout.html:212,extend,extends,212,interpreter/llvm-project/llvm/docs/_themes/llvm-theme/layout.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/_themes/llvm-theme/layout.html,1,['extend'],['extends']
Modifiability,"{% extends ""!layout.html"" %}. {% block extrahead %}. {% endblock %}. {% block rootrellink %}; LLVM Home | ; Documentation»; {% endblock %}; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/_templates/layout.html:3,extend,extends,3,interpreter/llvm-project/llvm/docs/_templates/layout.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/_templates/layout.html,1,['extend'],['extends']
Modifiability,"{; ...; }; };. Refactoring Action Rules; ------------------------. An individual refactoring action is responsible for creating the set of; grouped refactoring action rules that represent one refactoring operation.; Although the rules in one action may have a number of different implementations,; they should strive to produce a similar result. It should be easy for users to; identify which refactoring action produced the result regardless of which; refactoring action rule was used. The distinction between actions and rules enables the creation of actions; that define a set of different rules that produce similar results. For example,; the ""add missing switch cases"" refactoring operation typically adds missing; cases to one switch at a time. However, it could be useful to have a; refactoring that works on all switches that operate on a particular enum, as; one could then automatically update all of them after adding a new enum; constant. To achieve that, we can create two different rules that will use one; ``clang-refactor`` subcommand. The first rule will describe a local operation; that's initiated when the user selects a single switch. The second rule will; describe a global operation that works across translation units and is initiated; when the user provides the name of the enum to clang-refactor (or the user could; select the enum declaration instead). The clang-refactor tool will then analyze; the selection and other options passed to the refactoring action, and will pick; the most appropriate rule for the given selection and other options. Rule Types; ^^^^^^^^^^. Clang's refactoring engine supports several different refactoring rules:. - ``SourceChangeRefactoringRule`` produces source replacements that are applied; to the source files. Subclasses that choose to implement this rule have to; implement the ``createSourceReplacements`` member function. This type of; rule is typically used to implement local refactorings that transform the; source in one translatio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/RefactoringEngine.rst:3098,refactor,refactor,3098,interpreter/llvm-project/clang/docs/RefactoringEngine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/RefactoringEngine.rst,1,['refactor'],['refactor']
Modifiability,"{; //_Block_byref_release(src->captured_i);; _Block_object_dispose(src->captured_i, BLOCK_FIELD_IS_BYREF | BLOCK_BYREF_CALLER);; }. static struct __block_descriptor_5 {; unsigned long int reserved;; unsigned long int Block_size;; void (*copy_helper)(struct __block_literal_5 *dst, struct __block_literal_5 *src);; void (*dispose_helper)(struct __block_literal_5 *);; } __block_descriptor_5 = { 0, sizeof(struct __block_literal_5) __block_copy_5, __block_dispose_5 };. and:. .. code-block:: c. struct _block_byref_i i = {( .isa=NULL, .forwarding=&i, .flags=0, .size=sizeof(struct _block_byref_i), .captured_i=2 )};; struct __block_literal_5 _block_literal = {; &_NSConcreteStackBlock,; (1<<25)|(1<<29), <uninitialized>,; __block_invoke_5,; &__block_descriptor_5,; &i,; };. Importing ``__attribute__((NSObject))`` ``__block`` variables; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. A ``__block`` variable that is also marked ``__attribute__((NSObject))`` should; have ``byref_keep`` and ``byref_dispose`` helper functions that use; ``_Block_object_assign`` and ``_Block_object_dispose``. ``__block`` escapes; ^^^^^^^^^^^^^^^^^^^. Because ``Blocks`` referencing ``__block`` variables may have ``Block_copy()``; performed upon them the underlying storage for the variables may move to the; heap. In Objective-C Garbage Collection Only compilation environments the heap; used is the garbage collected one and no further action is required. Otherwise; the compiler must issue a call to potentially release any heap storage for; ``__block`` variables at all escapes or terminations of their scope. The call; should be:. .. code-block:: c. _Block_object_dispose(&_block_byref_foo, BLOCK_FIELD_IS_BYREF);. Nesting; ^^^^^^^. ``Blocks`` may contain ``Block`` literal expressions. Any variables used within; inner blocks are imported into all enclosing ``Block`` scopes even if the; variables are not used. This includes ``const`` imports as well as ``__block``; variables. Objective C Extensio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst:17506,variab,variable,17506,interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst,1,['variab'],['variable']
Modifiability,"{target=thumbv6m-none-unknown-eabi}; # then this multilib variant will be considered a match.; Flags: [--target=thumbv6m-none-unknown-eabi]. # Similarly, a multilib variant targeting Arm v7-M with an FPU (floating; # point unit).; - Dir: thumb/v7-m; # Here, the flags generated by Clang must be a superset of; # {--target=thumbv7m-none-eabi, -mfpu=fpv4-sp-d16} for this multilib variant; # to be a match.; Flags: [--target=thumbv7m-none-eabi, -mfpu=fpv4-sp-d16]. # The second section of the file is a list of regular expressions that are; # used to map from flags generated from command line options to custom flags.; # This is optional.; # Each regular expression must match a whole flag string.; # Flags in the ""Flags"" list will be added if any flag generated from command; # line options matches the regular expression.; Mappings:. # Set a ""--target=thumbv7m-none-eabi"" flag if the regular expression matches; # any of the flags generated from the command line options.; # Match is a POSIX extended regular expression string.; - Match: --target=thumbv([7-9]|[1-9][0-9]+).*; # Flags is a list of one or more strings.; Flags: [--target=thumbv7m-none-eabi]. Design principles; =================. Stable interface; ----------------. ``multilib.yaml`` and ``-print-multi-flags-experimental`` are new; interfaces to Clang. In order for them to be usable over time and across LLVM; versions their interfaces should be stable.; The new multilib system will be considered experimental in LLVM 17, but in; LLVM 18 it will be stable. In particular this is important to which multilib; selection flags Clang generates from command line options. Once a flag is; generated by a released version of Clang it may be used in ``multilib.yaml``; files that exist independently of the LLVM release cycle, and therefore; ceasing to generate the flag would be a breaking change and should be; avoided. However, an exception is the normalization of ``-march``.; ``-march`` for Arm architectures contains a list of enable",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst:9066,extend,extended,9066,interpreter/llvm-project/clang/docs/Multilib.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Multilib.rst,1,['extend'],['extended']
Modifiability,"{};; void y(X &x) { x; X z; }; class Y { friend class X; };; class Z : public virtual X {};. Example matches class Derived; (matcher = cxxRecordDecl(hasAnyBase(hasType(cxxRecordDecl(hasName(""Base"")))))); class Base {};; class Derived : Base {};. Usable as: Matcher<Expr>, Matcher<FriendDecl>, Matcher<ValueDecl>,; Matcher<CXXBaseSpecifier>. Matcher<ValueDecl>hasTypeMatcher<QualType> InnerMatcher; Matches if the expression's or declaration's type matches a type; matcher. Example matches x (matcher = expr(hasType(cxxRecordDecl(hasName(""X""))))); and z (matcher = varDecl(hasType(cxxRecordDecl(hasName(""X""))))); and U (matcher = typedefDecl(hasType(asString(""int""))); and friend class X (matcher = friendDecl(hasType(""X"")); and public virtual X (matcher = cxxBaseSpecifier(hasType(; asString(""class X""))); class X {};; void y(X &x) { x; X z; }; typedef int U;; class Y { friend class X; };; class Z : public virtual X {};. Matcher<VarDecl>hasInitializerMatcher<Expr> InnerMatcher; Matches a variable declaration that has an initializer expression; that matches the given matcher. Example matches x (matcher = varDecl(hasInitializer(callExpr()))); bool y() { return true; }; bool x = y();. Matcher<VariableArrayType>hasSizeExprMatcher<Expr> InnerMatcher; Matches VariableArrayType nodes that have a specific size; expression. Given; void f(int b) {; int a[b];; }; variableArrayType(hasSizeExpr(ignoringImpCasts(declRefExpr(to(; varDecl(hasName(""b""))))))); matches ""int a[b]"". Matcher<WhileStmt>hasBodyMatcher<Stmt> InnerMatcher; Matches a 'for', 'while', 'while' statement or a function or coroutine; definition that has a given body. Note that in case of functions or; coroutines this matcher only matches the definition itself and not the; other declarations of the same function or coroutine. Given; for (;;) {}; forStmt(hasBody(compoundStmt())); matches 'for (;;) {}'; with compoundStmt(); matching '{}'. Given; void f();; void f() {}; functionDecl(hasBody(compoundStmt())); matches 'void f() {}'; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html:253700,variab,variable,253700,interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LibASTMatchersReference.html,1,['variab'],['variable']
Modifiability,"| 0x100 |; +--------------------------------------+-------+; | DW_APPLE_PROPERTY_weak | 0x200 |; +--------------------------------------+-------+; | DW_APPLE_PROPERTY_strong | 0x400 |; +--------------------------------------+-------+; | DW_APPLE_PROPERTY_unsafe_unretained | 0x800 |; +--------------------------------------+-------+; | DW_APPLE_PROPERTY_nullability | 0x1000|; +--------------------------------------+-------+; | DW_APPLE_PROPERTY_null_resettable | 0x2000|; +--------------------------------------+-------+; | DW_APPLE_PROPERTY_class | 0x4000|; +--------------------------------------+-------+. Name Accelerator Tables; -----------------------. Introduction; ^^^^^^^^^^^^. The ""``.debug_pubnames``"" and ""``.debug_pubtypes``"" formats are not what a; debugger needs. The ""``pub``"" in the section name indicates that the entries; in the table are publicly visible names only. This means no static or hidden; functions show up in the ""``.debug_pubnames``"". No static variables or private; class variables are in the ""``.debug_pubtypes``"". Many compilers add different; things to these tables, so we can't rely upon the contents between gcc, icc, or; clang. The typical query given by users tends not to match up with the contents of; these tables. For example, the DWARF spec states that ""In the case of the name; of a function member or static data member of a C++ structure, class or union,; the name presented in the ""``.debug_pubnames``"" section is not the simple name; given by the ``DW_AT_name attribute`` of the referenced debugging information; entry, but rather the fully qualified name of the data or function member.""; So the only names in these tables for complex C++ entries is a fully; qualified name. Debugger users tend not to enter their search strings as; ""``a::b::c(int,const Foo&) const``"", but rather as ""``c``"", ""``b::c``"" , or; ""``a::b::c``"". So the name entered in the name table must be demangled in; order to chop it up appropriately and additional names must be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:56791,variab,variables,56791,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,2,['variab'],['variables']
Modifiability,"| U <number> -> linear with uval modifier; | ls <pos> -> runtime linear; | Rs <pos> -> runtime linear with ref modifier; | Ls <pos> -> runtime linear with val modifier; | Us <pos> -> runtime linear with uval modifier; | u -> uniform. <scalar_name>:= name of the scalar function. <vector_redirection>:= optional, custom name of the vector function. ``preallocated(<ty>)``; This attribute is required on calls to ``llvm.call.preallocated.arg``; and cannot be used on any other call. See; :ref:`llvm.call.preallocated.arg<int_call_preallocated_arg>` for more; details. .. _glattrs:. Global Attributes; -----------------. Attributes may be set to communicate additional information about a global variable.; Unlike :ref:`function attributes <fnattrs>`, attributes on a global variable; are grouped into a single :ref:`attribute group <attrgrp>`. ``no_sanitize_address``; This attribute indicates that the global variable should not have; AddressSanitizer instrumentation applied to it, because it was annotated; with `__attribute__((no_sanitize(""address"")))`,; `__attribute__((disable_sanitizer_instrumentation))`, or included in the; `-fsanitize-ignorelist` file.; ``no_sanitize_hwaddress``; This attribute indicates that the global variable should not have; HWAddressSanitizer instrumentation applied to it, because it was annotated; with `__attribute__((no_sanitize(""hwaddress"")))`,; `__attribute__((disable_sanitizer_instrumentation))`, or included in the; `-fsanitize-ignorelist` file.; ``sanitize_memtag``; This attribute indicates that the global variable should have AArch64 memory; tags (MTE) instrumentation applied to it. This attribute causes the; suppression of certain optimisations, like GlobalMerge, as well as ensuring; extra directives are emitted in the assembly and extra bits of metadata are; placed in the object file so that the linker can ensure the accesses are; protected by MTE. This attribute is added by clang when; `-fsanitize=memtag-globals` is provided, as long as the glob",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:115207,variab,variable,115207,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['variab'],['variable']
Modifiability,"}. static struct __block_descriptor_10 {; unsigned long int reserved;; unsigned long int Block_size;; void (*copy_helper)(struct __block_literal_10 *dst, struct __block_literal_10 *src);; void (*dispose_helper)(struct __block_literal_10 *);; } __block_descriptor_10 = { 0, sizeof(struct __block_literal_10), __block_copy_10, __block_dispose_10 };. and the code would be:. .. code-block:: c++. {; FOO foo;; comp_ctor(&foo); // default constructor; struct __block_literal_10 _block_literal = {; &_NSConcreteStackBlock,; (1<<25)|(1<<26)|(1<<29), <uninitialized>,; __block_invoke_10,; &__block_descriptor_10,; };; comp_ctor(&_block_literal->foo, &foo); // const copy into stack version; struct __block_literal_10 &block = &_block_literal; // assign literal to block variable; block->invoke(block); // invoke block; comp_dtor(&_block_literal->foo); // destroy stack version of const block copy; comp_dtor(&foo); // destroy original version; }. C++ objects stored in ``__block`` storage start out on the stack in a; ``block_byref`` data structure as do other variables. Such objects (if not; ``const`` objects) must support a regular copy constructor. The ``block_byref``; data structure will have copy and destroy helper routines synthesized by the; compiler. The copy helper will have code created to perform the copy; constructor based on the initial stack ``block_byref`` data structure, and will; also set the (1<<26) bit in addition to the (1<<25) bit. The destroy helper; will have code to do the destructor on the object stored within the supplied; ``block_byref`` heap data structure. For example,. .. code-block:: c++. __block FOO blockStorageFoo;. requires the normal constructor for the embedded ``blockStorageFoo`` object:. .. code-block:: c++. FOO_ctor(& _block_byref_blockStorageFoo->blockStorageFoo);. and at scope termination the destructor:. .. code-block:: c++. FOO_dtor(& _block_byref_blockStorageFoo->blockStorageFoo);. Note that the forwarding indirection is *NOT* used. The compiler w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst:26048,variab,variables,26048,interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Block-ABI-Apple.rst,1,['variab'],['variables']
Modifiability,"}. void foo(bool b); {; if (b); {; baz(2);; }; else; {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_WebKit`` (in configuration: ``WebKit``); Like ``Attach``, but break before functions. .. code-block:: c++. namespace N {; enum E {; E1,; E2,; };. class C {; public:; C();; };. bool baz(int i); {; try {; do {; switch (i) {; case 1: {; foobar();; break;; }; default: {; break;; }; }; } while (--i);; return true;; } catch (...) {; handleError();; return false;; }; }. void foo(bool b); {; if (b) {; baz(2);; } else {; baz(5);; }; }. void bar() { foo(true); }; } // namespace N. * ``BS_Custom`` (in configuration: ``Custom``); Configure each individual brace in ``BraceWrapping``. .. _BreakBeforeConceptDeclarations:. **BreakBeforeConceptDeclarations** (``BreakBeforeConceptDeclarationsStyle``) :versionbadge:`clang-format 12` :ref:`¶ <BreakBeforeConceptDeclarations>`; The concept declaration style to use. Possible values:. * ``BBCDS_Never`` (in configuration: ``Never``); Keep the template declaration line together with ``concept``. .. code-block:: c++. template <typename T> concept C = ...;. * ``BBCDS_Allowed`` (in configuration: ``Allowed``); Breaking between template declaration and ``concept`` is allowed. The; actual behavior depends on the content and line breaking rules and; penalties. * ``BBCDS_Always`` (in configuration: ``Always``); Always break before ``concept``, putting it in the line after the; template declaration. .. code-block:: c++. template <typename T>; concept C = ...;. .. _BreakBeforeInlineASMColon:. **BreakBeforeInlineASMColon** (``BreakBeforeInlineASMColonStyle``) :versionbadge:`clang-format 16` :ref:`¶ <BreakBeforeInlineASMColon>`; The inline ASM colon style to use. Possible values:. * ``BBIAS_Never`` (in configuration: ``Never``); No break before inline ASM colon. .. code-block:: c++. asm volatile(""string"", : : val);. * ``BBIAS_OnlyMultiline`` (in configuration: ``OnlyMultiline``); Break before inline ASM colon if the line length is l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst:52240,config,configuration,52240,interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangFormatStyleOptions.rst,1,['config'],['configuration']
Modifiability,"}; ${_CLAD_LIBRARY_PATH}/${CMAKE_STATIC_LIBRARY_PREFIX}cladDifferentiator${CMAKE_STATIC_LIBRARY_SUFFIX}; ); endif(). if(APPLE); set(_clad_extra_cmake_args -DCMAKE_OSX_SYSROOT=${CMAKE_OSX_SYSROOT}); endif(). if (CMAKE_CXX_STANDARD); list(APPEND _clad_extra_cmake_args -DCMAKE_CXX_STANDARD=${CMAKE_CXX_STANDARD}); endif(CMAKE_CXX_STANDARD). if (Clang_DIR); list(APPEND _clad_extra_cmake_args -DClang_DIR=${Clang_DIR} -DClang_CONFIG_EXTRA_PATH_HINTS=${Clang_Config_ExtraPathHints}); endif(Clang_DIR). if (LLVM_FORCE_USE_OLD_TOOLCHAIN); list(APPEND _clad_extra_cmake_args -DLLVM_FORCE_USE_OLD_TOOLCHAIN=${LLVM_FORCE_USE_OLD_TOOLCHAIN}); endif(LLVM_FORCE_USE_OLD_TOOLCHAIN). list(APPEND _clad_extra_cmake_args -DCLAD_BUILD_STATIC_ONLY=ON). # Wrap download, configure and build steps in a script to log output; set(_clad_extra_settings; LOG_DOWNLOAD ON; LOG_CONFIGURE ON; LOG_BUILD ON; LOG_INSTALL ON; LOG_OUTPUT_ON_FAILURE ON; ). # If the CLAD_SOURCE_DIR variable is defined in the CMake configuration, we're; # skipping the download of the repository and use the passed directory.; if (DEFINED CLAD_SOURCE_DIR); list(APPEND _clad_extra_settings DOWNLOAD_COMMAND """"); list(APPEND _clad_extra_settings SOURCE_DIR ${CLAD_SOURCE_DIR}); endif(). #list(APPEND _clad_patches_list ""patch1.patch"" ""patch2.patch""); #set(_clad_patch_command; # ${CMAKE_COMMAND} -E copy_directory; # ${CMAKE_SOURCE_DIR}/interpreter/cling/tools/plugins/clad/patches <SOURCE_DIR>; # && git checkout <SOURCE_DIR>; # && git apply --ignore-space-change --ignore-whitespace ${_clad_patches_list}; # ). ExternalProject_Add(; clad; GIT_REPOSITORY https://github.com/vgvassilev/clad.git; GIT_TAG v1.7; UPDATE_COMMAND """"; PATCH_COMMAND ${_clad_patch_command}; CMAKE_ARGS -G ${CMAKE_GENERATOR}; -DCMAKE_BUILD_TYPE=${CMAKE_BUILD_TYPE}; -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER}; -DCMAKE_C_FLAGS=${CMAKE_C_FLAGS}; -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER}; -DCMAKE_CXX_FLAGS=${CLAD_CXX_FLAGS}; -DCMAKE_INSTALL_PREFIX=${clad_install_dir}/plugins; -D",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/plugins/clad/CMakeLists.txt:2349,variab,variable,2349,interpreter/cling/tools/plugins/clad/CMakeLists.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/plugins/clad/CMakeLists.txt,2,"['config', 'variab']","['configuration', 'variable']"
Modifiability,"}][f61]. ## Toy Monte Carlo Experiments ##. Let us look at a simple example of a toy experiment comparing two; methods to fit a function to a histogram, the $\chi^{2}$. method and a method called ""binned log-likelihood fit"", both available in ROOT. As a very simple yet powerful quantity to check the quality of the fit; results, we construct for each pseudo-data set the so-called ""pull"", the; difference of the estimated and the true value of a parameter,; normalised to the estimated error on the parameter,; $\frac{(p_{estim} - p_{true})}{\sigma_{p}}$. If everything is OK, the; distribution of the pull values is a standard normal distribution, i.e.; a Gaussian distribution centred around zero with a standard deviation of one. The macro performs a rather big number of toy experiments, where a; histogram is repeatedly filled with Gaussian distributed numbers,; representing the pseudo-data in this example. Each time, a fit is; performed according to the selected method, and the pull is calculated; and filled into a histogram. Here is the code:. ``` {.cpp .numberLines}; @ROOT_INCLUDE_FILE macros/macro9.C; ```. Your present knowledge of ROOT should be enough to understand all the; technicalities behind the macro. Note that the variable `pull` in line; *61* is different from the definition above: instead of the parameter; error on `mean`, the fitted standard deviation of the distribution; divided by the square root of the number of entries,; `sig/sqrt(n_tot_entries)`, is used. - What method exhibits the better performance with the default; parameters ?. - What happens if you increase the number of entries per histogram by; a factor of ten ? Why ?. The answers to these questions are well beyond the scope of this guide.; Basically all books about statistical methods provide a complete; treatment of the aforementioned topics. [^5]: ""Monte Carlo"" simulation means that random numbers play a role here; which is as crucial as in games of pure chance in the Casino of Monte Carlo.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/functions_and_parameter_estimation.md:5244,variab,variable,5244,documentation/primer/functions_and_parameter_estimation.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/functions_and_parameter_estimation.md,1,['variab'],['variable']
Modifiability,"~~~{.cpp}; void RemoveNode(TGeoNode* node); TGeoNode*ReplaceNode(TGeoNode* nodeorig, TGeoShape* newshape = 0,; TGeoMatrix* newpos = 0, TGeoMedium* newmed = 0); ~~~. The last method allows replacing an existing daughter of a volume with; another one. Providing only the node to be replaced will just create a; new volume for the node but having exactly the same parameters as the; old one. This helps in case of divisions for decoupling a node from the; logical hierarchy so getting new content/properties. For non-divided; volumes, one can change the shape and/or the position of the daughter. \anchor GP01bd; #### Virtual Containers and Assemblies of Volumes. Virtual containers are volumes that do not represent real objects, but; they are needed for grouping and positioning together other volumes.; Such grouping helps not only geometry creation, but also optimizes; tracking performance; therefore, it is highly recommended. Virtual; volumes need to inherit material/medium properties from the volume they; are placed into in order to be ""invisible"" at tracking time. Let us suppose that we need to group together two volumes `A` and `B`; into a structure and position this into several other volumes `D,E,` and; `F`. What we need to do is to create a virtual container volume `C`; holding `A` and `B`, then position `C` in the other volumes. Note that `C` is a volume having a determined medium. Since it is not a; real volume, we need to manually set its medium the same as that of; `D,E` or `F` in order to make it ""invisible"" (same physics properties).; In other words, the limitation in proceeding this way is that `D,E,` and; `F` must point to the same medium. If this was not the case, we would; have to define different virtual volumes for each placement: `C`, `C`'; and `C`\"", having the same shape but different media matching the; corresponding containers. This might not happen so often, but when it; does, it forces the creation of several extra virtual volumes. Other; limitation co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:30381,inherit,inherit,30381,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['inherit'],['inherit']
Modifiability,"~~~~~~~; A *link-declaration* specifies a library or framework against which a program should be linked if the enclosing module is imported in any translation unit in that program. .. parsed-literal::. *link-declaration*:; ``link`` ``framework``:sub:`opt` *string-literal*. The *string-literal* specifies the name of the library or framework against which the program should be linked. For example, specifying ""clangBasic"" would instruct the linker to link with ``-lclangBasic`` for a Unix-style linker. A *link-declaration* with the ``framework`` specifies that the linker should link against the named framework, e.g., with ``-framework MyFramework``. .. note::. Automatic linking with the ``link`` directive is not yet widely; implemented, because it requires support from both the object file; format and the linker. The notion is similar to Microsoft Visual; Studio's ``#pragma comment(lib...)``. Configuration macros declaration; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~; The *config-macros-declaration* specifies the set of configuration macros that have an effect on the API of the enclosing module. .. parsed-literal::. *config-macros-declaration*:; ``config_macros`` *attributes*:sub:`opt` *config-macro-list*:sub:`opt`. *config-macro-list*:; *identifier* (',' *identifier*)*. Each *identifier* in the *config-macro-list* specifies the name of a macro. The compiler is required to maintain different variants of the given module for differing definitions of any of the named macros. A *config-macros-declaration* shall only be present on a top-level module, i.e., a module that is not nested within an enclosing module. The ``exhaustive`` attribute specifies that the list of macros in the *config-macros-declaration* is exhaustive, meaning that no other macro definition is intended to have an effect on the API of that module. .. note::. The ``exhaustive`` attribute implies that any macro definitions; for macros not listed as configuration macros should be ignored; completely when building the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:46264,config,config-macros-declaration,46264,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,2,['config'],"['config-macros-declaration', 'configuration']"
Performance,"	%esi, %edi; 	testb	$-1, %dil; 	sete	%al; 	movzbl	%al, %eax; 	ret. A cmpb instead of the xorl+testb would be one instruction shorter. //===---------------------------------------------------------------------===//. Given the following C code:; int f(int a, int b) { return (signed char)a == (signed char)b; }. We generate the following IR with clang:; define i32 @f(i32 %a, i32 %b) nounwind readnone {; entry:; %sext = shl i32 %a, 24 ; <i32> [#uses=1]; %conv1 = ashr i32 %sext, 24 ; <i32> [#uses=1]; %sext6 = shl i32 %b, 24 ; <i32> [#uses=1]; %conv4 = ashr i32 %sext6, 24 ; <i32> [#uses=1]; %cmp = icmp eq i32 %conv1, %conv4 ; <i1> [#uses=1]; %conv5 = zext i1 %cmp to i32 ; <i32> [#uses=1]; ret i32 %conv5; }. And the following x86 code:; 	movsbl	%sil, %eax; 	movsbl	%dil, %ecx; 	cmpl	%eax, %ecx; 	sete	%al; 	movzbl	%al, %eax; 	ret. It should be possible to eliminate the sign extensions. //===---------------------------------------------------------------------===//. LLVM misses a load+store narrowing opportunity in this code:. %struct.bf = type { i64, i16, i16, i32 }. @bfi = external global %struct.bf* ; <%struct.bf**> [#uses=2]. define void @t1() nounwind ssp {; entry:; %0 = load %struct.bf** @bfi, align 8 ; <%struct.bf*> [#uses=1]; %1 = getelementptr %struct.bf* %0, i64 0, i32 1 ; <i16*> [#uses=1]; %2 = bitcast i16* %1 to i32* ; <i32*> [#uses=2]; %3 = load i32* %2, align 1 ; <i32> [#uses=1]; %4 = and i32 %3, -65537 ; <i32> [#uses=1]; store i32 %4, i32* %2, align 1; %5 = load %struct.bf** @bfi, align 8 ; <%struct.bf*> [#uses=1]; %6 = getelementptr %struct.bf* %5, i64 0, i32 1 ; <i16*> [#uses=1]; %7 = bitcast i16* %6 to i32* ; <i32*> [#uses=2]; %8 = load i32* %7, align 1 ; <i32> [#uses=1]; %9 = and i32 %8, -131073 ; <i32> [#uses=1]; store i32 %9, i32* %7, align 1; ret void; }. LLVM currently emits this:. movq bfi(%rip), %rax; andl $-65537, 8(%rax); movq bfi(%rip), %rax; andl $-131073, 8(%rax); ret. It could narrow the loads and stores to emit this:. movq bfi(%rip), %rax; andb ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:37276,load,load,37276,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,1,['load'],['load']
Performance,"	%xmm2, %xmm2, %xmm3; - - - 1.00 - 1.00 - - - - - - - - vhaddps	%xmm3, %xmm3, %xmm4. According to this report, the dot-product kernel has been executed 300 times,; for a total of 900 simulated instructions. The total number of simulated micro; opcodes (uOps) is also 900. The report is structured in three main sections. The first section collects a; few performance numbers; the goal of this section is to give a very quick; overview of the performance throughput. Important performance indicators are; **IPC**, **uOps Per Cycle**, and **Block RThroughput** (Block Reciprocal; Throughput). Field *DispatchWidth* is the maximum number of micro opcodes that are dispatched; to the out-of-order backend every simulated cycle. For processors with an; in-order backend, *DispatchWidth* is the maximum number of micro opcodes issued; to the backend every simulated cycle. IPC is computed dividing the total number of simulated instructions by the total; number of cycles. Field *Block RThroughput* is the reciprocal of the block throughput. Block; throughput is a theoretical quantity computed as the maximum number of blocks; (i.e. iterations) that can be executed per simulated clock cycle in the absence; of loop carried dependencies. Block throughput is superiorly limited by the; dispatch rate, and the availability of hardware resources. In the absence of loop-carried data dependencies, the observed IPC tends to a; theoretical maximum which can be computed by dividing the number of instructions; of a single iteration by the `Block RThroughput`. Field 'uOps Per Cycle' is computed dividing the total number of simulated micro; opcodes by the total number of cycles. A delta between Dispatch Width and this; field is an indicator of a performance issue. In the absence of loop-carried; data dependencies, the observed 'uOps Per Cycle' should tend to a theoretical; maximum throughput which can be computed by dividing the number of uOps of a; single iteration by the `Block RThroughput`. Field *uOp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:16334,throughput,throughput,16334,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['throughput'],['throughput']
Performance," 	fldl	8(%esp); 	fisttpll	(%esp); 	movl	4(%esp), %edx; 	movl	(%esp), %eax; 	addl	$20, %esp; 	#FP_REG_KILL; 	ret. This should just fldl directly from the input stack slot. //===---------------------------------------------------------------------===//. This code:; int foo (int x) { return (x & 65535) | 255; }. Should compile into:. _foo:; movzwl 4(%esp), %eax; orl $255, %eax; ret. instead of:; _foo:; 	movl	$65280, %eax; 	andl	4(%esp), %eax; 	orl	$255, %eax; 	ret. //===---------------------------------------------------------------------===//. We're codegen'ing multiply of long longs inefficiently:. unsigned long long LLM(unsigned long long arg1, unsigned long long arg2) {; return arg1 * arg2;; }. We compile to (fomit-frame-pointer):. _LLM:; 	pushl	%esi; 	movl	8(%esp), %ecx; 	movl	16(%esp), %esi; 	movl	%esi, %eax; 	mull	%ecx; 	imull	12(%esp), %esi; 	addl	%edx, %esi; 	imull	20(%esp), %ecx; 	movl	%esi, %edx; 	addl	%ecx, %edx; 	popl	%esi; 	ret. This looks like a scheduling deficiency and lack of remat of the load from; the argument area. ICC apparently produces:. movl 8(%esp), %ecx; imull 12(%esp), %ecx; movl 16(%esp), %eax; imull 4(%esp), %eax ; addl %eax, %ecx ; movl 4(%esp), %eax; mull 12(%esp) ; addl %ecx, %edx; ret. Note that it remat'd loads from 4(esp) and 12(esp). See this GCC PR:; http://gcc.gnu.org/bugzilla/show_bug.cgi?id=17236. //===---------------------------------------------------------------------===//. We can fold a store into ""zeroing a reg"". Instead of:. xorl %eax, %eax; movl %eax, 124(%esp). we should get:. movl $0, 124(%esp). if the flags of the xor are dead. Likewise, we isel ""x<<1"" into ""add reg,reg"". If reg is spilled, this should; be folded into: shl [mem], 1. //===---------------------------------------------------------------------===//. In SSE mode, we turn abs and neg into a load from the constant pool plus a xor; or and instruction, for example:. 	xorpd	LCPI1_0, %xmm2. However, if xmm2 gets spilled, we end up with really ugly code like this:.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:21499,load,load,21499,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,1,['load'],['load']
Performance," ![Overlap checking](pictures/030001DF.png). This can be activated both at volume level (checking for illegal; overlaps only one level inside a given volume) and from the geometry; manager level (checking full geometry):. ``` {.cpp}; myVolume->CheckOverlaps(precision, option);; gGeoManager->CheckOverlaps(precision);; myNode->CheckOverlaps(precision);; ```. Here precision represents the desired maximum accepted overlap value in; centimeters (default value is 0.1). This tool checks all possible; significant pairs of candidates inside a given volume (not declared as; overlapping or division volumes). The check is performed by verifying; the mesh representation of one candidate against the shape of the other.; This sort of check cannot identify all possible overlapping topologies,; but it works for more than 95% and is much faster than the usual; shape-to-shape comparison. For a 100% reliability, one can perform the; check at the level of a single volume by using `option`=""`d`"" or; `option`=""`d<number>`"" to perform overlap checking by sampling the; volume with \<`number`\> random points (default 1 million). This; produces also a picture showing in red the overlapping region and; estimates the volume of the overlaps. An extrusion A) is declared in any of the following cases:. - At least one of the vertices of the daughter mesh representation is; outside the mother volume (in fact its shape) and having a safety; distance to the mother greater than the desired value;; - At least one of the mother vertices is contained also by one of its; daughters, in the same conditions. An overlap B) is declared if:. - At least one vertex of a positioned volume mesh is contained (having; a safety bigger than the accepted maximum value) by other positioned; volume inside the same container. The check is performed also by; inverting the candidates. The code is highly optimized to avoid checking candidates that are far; away in space by performing a fast check on their bounding boxes. Once; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:133278,perform,perform,133278,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,2,['perform'],['perform']
Performance," !ne; : !not !or !range !repr !setdagarg; : !setdagname !setdagop !shl !size !sra; : !srl !strconcat !sub !subst !substr; : !tail !tolower !toupper !xor. The ``!cond`` operator has a slightly different; syntax compared to other bang operators, so it is defined separately:. .. productionlist::; CondOperator: !cond. See `Appendix A: Bang Operators`_ for a description of each bang operator. Include files; -------------. TableGen has an include mechanism. The content of the included file; lexically replaces the ``include`` directive and is then parsed as if it was; originally in the main file. .. productionlist::; IncludeDirective: ""include"" `TokString`. Portions of the main file and included files can be conditionalized using; preprocessor directives. .. productionlist::; PreprocessorDirective: ""#define"" | ""#ifdef"" | ""#ifndef"". Types; =====. The TableGen language is statically typed, using a simple but complete type; system. Types are used to check for errors, to perform implicit conversions,; and to help interface designers constrain the allowed input. Every value is; required to have an associated type. TableGen supports a mixture of low-level types (e.g., ``bit``) and; high-level types (e.g., ``dag``). This flexibility allows you to describe a; wide range of records conveniently and compactly. .. productionlist::; Type: ""bit"" | ""int"" | ""string"" | ""dag""; :| ""bits"" ""<"" `TokInteger` "">""; :| ""list"" ""<"" `Type` "">""; :| `ClassID`; ClassID: `TokIdentifier`. ``bit``; A ``bit`` is a boolean value that can be 0 or 1. ``int``; The ``int`` type represents a simple 64-bit integer value, such as 5 or; -42. ``string``; The ``string`` type represents an ordered sequence of characters of arbitrary; length. ``bits<``\ *n*\ ``>``; The ``bits`` type is a fixed-sized integer of arbitrary length *n* that; is treated as separate bits. These bits can be accessed individually.; A field of this type is useful for representing an instruction operation; code, register number, or address mode/reg",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:10301,perform,perform,10301,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['perform'],['perform']
Performance," ""SetLineAttributes"", then left-click on ""Set Parameters"". This gives; access to a panel allowing you to interactively change the parameters of; the function, as shown in Figure [2.4](#f24). Change the slit width, or go from one to; two and then three or more slits, just as you like. When clicking on; ""Apply"", the function plot is updated to reflect the actual value of the; parameters you have set. [f25]: figures/ROOTPanel_FitPanel.png ""f25""; <a name=""f25""></a>. ![Fit Panel. \label{f25}][f25]. Another very useful interactive tool is the `FitPanel`, available for the; classes `TGraphErrors` and `TH1F`. Predefined fit functions can be selected; from a pull-down menu, including ""`gaus`"", ""`expo`"" and ""`pol0`"" - ""`pol9`""; for Gaussian and exponential functions or polynomials of degree 0 to 9,; respectively. In addition, user-defined functions using the same syntax as; for functions with parameters are possible. After setting the initial parameters, a fit of the selected function to the; data of a graph or histogram can be performed and the result displayed on the plot.; The fit panel is shown in Figure [2.5](#f25). The fit panel has a number of control options to; select the fit method, fix or release individual parameters in the fit, to steer; the level of output printed on the console, or to extract and display additional; information like contour lines showing parameter correlations. As function fitting; is of prime importance in any kind of data analysis, this topic will again show up; later. If you are satisfied with your plot, you probably want to save it. Just; close all selector boxes you opened previously and select the menu item; `Save as...` from the menu line of the window. It will pop up a file; selector box to allow you to choose the format, file name and target; directory to store the image. There is one very noticeable feature here:; you can store a plot as a root macro! In this macro, you find the C++; representation of all methods and classes involved i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/ROOT_as_calculator.md:15323,perform,performed,15323,documentation/primer/ROOT_as_calculator.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/ROOT_as_calculator.md,1,['perform'],['performed']
Performance," ""Wingdings"" fonts; 25. Make ""col"" default draw option for TH2 in JSROOT gui. ## Changes in 6.3.4; 1. Fix bug in handling superimposing items via URL syntax; 2. Enable geometry clipping in node.js; 3. Upgrade node.js packages; 4. Let draw TGeo object inside TCanvas; 5. Let superimpose TPolyLine3D and TPolyMarker3D with TGeo drawing; 6. Fix plain #sum and #int parsing in TLatex; 7. Fix ticks position for axes with labels. ## Changes in 6.3.3; 1. Fix TEfficiency drawing; 2. Provide TPadPainter.divide method; 3. Fix browsing remote file via THttpServer; 4. Fix lego draw update while zooming. ## Changes in 6.3.2; 1. Fix bug in TH1 drawing when minimum or/and maximum was configured for histogram. ## Changes in 6.3.1; 1. Fix bug with col draw option in TH2/RH2. ## Changes in 6.3.0; 1. Fully rewrite TLatex parsing, use svg elements instead of plain text/tspan; 2. Make TLatex reliably working in node.js, does not depend from availability of canvas component; 3. Many optimizations to produce smaller (and faster) SVG output; 4. Provide x3dscNNN and y3dscNNN draw option for histogram to resize x/y axis in 3D plots; 5. Provide ""Find label"" command in TAxis context menu to zoom into bin region; 6. Allows to use JSROOT.define() in external scripts; 7. Provide JSROOT.Painter.setDefaultDrawOpt() to change class default draw option; 8. Provide example of custom entries in histogram context menu; 9. Provide alternative external location for zstd-codec, let use zstd even when not found locally; 10. Let skip HEAD requests when reading files, adding ""^"" symbol to file name (#223); 11. Show long histogram names in stats box when possible; 12. Fix logic how ""ndiv"" parameter of TAxis is handled, showing really the configured number of ticks; 13. Fix problem with curved TGraph drawings (#218); 14. Fix problems with TGraph drawing updates; 15. Base version for ROOT 6.26 release. ## Changes in 6.2.2; 1. Fix - proper fill TH1 which drawn with line option; 2. Fix - object drawing from inspector",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:21188,optimiz,optimizations,21188,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['optimiz'],['optimizations']
Performance," # Conditionally update predicate state.; testl %edx, %edx; je .LBB0_4; .LBB0_1:; cmoveq %r8, %rax # Conditionally update predicate state.; popq %rax; retq; .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; ...; ```. Here we create the ""empty"" or ""correct execution"" predicate state by zeroing; `%rax`, and we create a constant ""incorrect execution"" predicate value by; putting `-1` into `%r8`. Then, along each edge coming out of a conditional; branch we do a conditional move that in a correct execution will be a no-op,; but if misspeculated, will replace the `%rax` with the value of `%r8`.; Misspeculating any one of the three predicates will cause `%rax` to hold the; ""incorrect execution"" value from `%r8` as we preserve incoming values when; execution is correct rather than overwriting it. We now have a value in `%rax` in each basic block that indicates if at some; point previously a predicate was mispredicted. And we have arranged for that; value to be particularly effective when used below to harden loads. ##### Indirect Call, Branch, and Return Predicates. There is no analogous flag to use when tracing indirect calls, branches, and; returns. The predicate state must be accumulated through some other means.; Fundamentally, this is the reverse of the problem posed in CFI: we need to; check where we came from rather than where we are going. For function-local; jump tables, this is easily arranged by testing the input to the jump table; within each destination (not yet implemented, use retpolines):; ```; pushq %rax; xorl %eax, %eax # Zero out initial predicate state.; movq $-1, %r8 # Put all-ones mask into a register.; jmpq *.LJTI0_0(,%rdi,8) # Indirect jump through table.; .LBB0_2: # %sw.bb; testq $0, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally update predicate state.; ...; jmp _Z4leaki # TAILCALL. .LBB0_3: # %sw.bb1; testq $1, %rdi # Validate index used for jump table.; cmovneq %r8, %rax # Conditionally up",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:17804,load,loads,17804,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['loads']
Performance," #+4]; add r0, r0, #2. //===---------------------------------------------------------------------===//. LLVM aggressively lift CSE out of loop. Sometimes this can be negative side-; effects:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; load [i + R1]; ...; load [i + R2]; ...; load [i + R3]. Suppose there is high register pressure, R1, R2, R3, can be spilled. We need; to implement proper re-materialization to handle this:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; R1 = X + 4 @ re-materialized; load [i + R1]; ...; R2 = X + 7 @ re-materialized; load [i + R2]; ...; R3 = X + 15 @ re-materialized; load [i + R3]. Furthermore, with re-association, we can enable sharing:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; T = i + X; load [T + 4]; ...; load [T + 7]; ...; load [T + 15]; //===---------------------------------------------------------------------===//. It's not always a good idea to choose rematerialization over spilling. If all; the load / store instructions would be folded then spilling is cheaper because; it won't require new live intervals / registers. See 2003-05-31-LongShifts for; an example. //===---------------------------------------------------------------------===//. With a copying garbage collector, derived pointers must not be retained across; collector safe points; the collector could move the objects and invalidate the; derived pointer. This is bad enough in the first place, but safe points can; crop up unpredictably. Consider:. %array = load { i32, [0 x %obj] }** %array_addr; %nth_el = getelementptr { i32, [0 x %obj] }* %array, i32 0, i32 %n; %old = load %obj** %nth_el; %z = div i64 %x, %y; store %obj* %new, %obj** %nth_el. If the i64 division is lowered to a libcall, then a safe point will (must); appear for the call site. If a collection occurs, %array and %nth_el no longer; point into the correct object. The fix for this is to copy address calculations so that dependent pointers; are never live across safe point boundaries. But the loads cannot be cop",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt:2457,load,load,2457,interpreter/llvm-project/llvm/lib/CodeGen/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt,1,['load'],['load']
Performance," #. Each read of the variable becomes a load from the stack.; #. Each update of the variable becomes a store to the stack.; #. Taking the address of a variable just uses the stack address; directly. While this solution has solved our immediate problem, it introduced; another one: we have now apparently introduced a lot of stack traffic; for very simple and common operations, a major performance problem.; Fortunately for us, the LLVM optimizer has a highly-tuned optimization; pass named ""mem2reg"" that handles this case, promoting allocas like this; into SSA registers, inserting Phi nodes as appropriate. If you run this; example through the pass, for example, you'll get:. .. code-block:: bash. $ llvm-as < example.ll | opt -passes=mem2reg | llvm-dis; @G = weak global i32 0; @H = weak global i32 0. define i32 @test(i1 %Condition) {; entry:; br i1 %Condition, label %cond_true, label %cond_false. cond_true:; %X.0 = load i32, i32* @G; br label %cond_next. cond_false:; %X.1 = load i32, i32* @H; br label %cond_next. cond_next:; %X.01 = phi i32 [ %X.1, %cond_false ], [ %X.0, %cond_true ]; ret i32 %X.01; }. The mem2reg pass implements the standard ""iterated dominance frontier""; algorithm for constructing SSA form and has a number of optimizations; that speed up (very common) degenerate cases. The mem2reg optimization; pass is the answer to dealing with mutable variables, and we highly; recommend that you depend on it. Note that mem2reg only works on; variables in certain circumstances:. #. mem2reg is alloca-driven: it looks for allocas and if it can handle; them, it promotes them. It does not apply to global variables or heap; allocations.; #. mem2reg only looks for alloca instructions in the entry block of the; function. Being in the entry block guarantees that the alloca is only; executed once, which makes analysis simpler.; #. mem2reg only promotes allocas whose uses are direct loads and stores.; If the address of the stack object is passed to a function, or if any; funny po",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:7236,load,load,7236,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['load'],['load']
Performance," #176, #179, #180, #182. 2019-11-07: 1.5.7; -----------------. * Allow implicit converions for move arguments; * Choose vector over initializer_list if part of the template argument list. 2019-11-03: 1.5.6; -----------------. * Added public C++ API for some CPyCppyy core functions (CPython only); * Support for char16_t/char16_t* and char32_t/char32_t*; * Respect ``std::hash`` in ``__hash__``; * Fix iteration over vector of shared_ptr; * Length checking on global variables of type 'signed char[N]'; * Properly support overloaded templated with non-templated ``__setitem__``; * Support for array of const char* as C-strings; * Enable type resolution of clang's builtin ``__type_pack_element``; * Fix for inner class type naming when it directly declares a variable. 2019-10-16: 1.5.5; -----------------. * Added signal -> exception support in cppyy.ll; * Support for lazily combining overloads of operator*/+-; * No longer call trivial destructors; * Support for free function unary operators; * Refactored and optimized operator==/!= usage; * Refactored converters/executors for lower memory usage; * Bug fixes in rootcling and _cppyy_generator.py. 2019-09-25: 1.5.4; -----------------. * operator+/* now respect C++-side associativity; * Fix potential crash if modules are reloaded; * Fix some portability issues on Mac/Windows of cppyy-cling. 2019-09-15: 1.5.3; -----------------. * Performance improvements; * Support for anonymous/unnamed/nested unions; * Extended documentation. 2019-09-06: 1.5.2; -----------------. * Added a ""low level"" interface (cppyy.ll) for hard-casting and ll types; * Extended support for passing ctypes arguments through ptr, ref, ptr-ptr; * Fixed crash when creating an array of instances of a scoped inner struct; * Extended documentation. 2019-08-26: 1.5.1; -----------------. * Upgrade cppyy-cling to 6.18.2; * Various patches to upstream's pre-compiled header generation and use; * Instantiate templates with larger integer types if argument values require; * I",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:16344,optimiz,optimized,16344,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,1,['optimiz'],['optimized']
Performance," #2 sounded good to me. I'm not sure I understand your; > concern about an explicit 'icall' instruction?. I worry too much. :) The other alternative has been removed. 'icall' is; now up in the instruction list next to 'call'. > I believe tail calls are relatively easy to identify; do you know why; > .NET has a tailcall instruction?. Although I am just guessing, I believe it probably has to do with the fact; that they want languages like Haskell and lisp to be efficiently runnable; on their VM. Of course this means that the VM MUST implement tail calls; 'correctly', or else life will suck. :) I would put this into a future; feature bin, because it could be pretty handy... > A pair of important synchronization instr'ns to think about:; > load-linked; > store-conditional. What is 'load-linked'? I think that (at least for now) I should add these; to the 'possible extensions' section, because they are not immediately; needed... > Other classes of instructions that are valuable for pipeline; > performance:; > conditional-move ; > predicated instructions. Conditional move is effectly a special case of a predicated; instruction... and I think that all predicated instructions can possibly; be implemented later in LLVM. It would significantly change things, and; it doesn't seem to be very necessary right now. It would seem to; complicate flow control analysis a LOT in the virtual machine. I would; tend to prefer that a predicated architecture like IA64 convert from a; ""basic block"" representation to a predicated rep as part of it's dynamic; complication phase. Also, if a basic block contains ONLY a move, then; that can be trivally translated into a conditional move... > I agree that we need a static data space. Otherwise, emulating global; > data gets unnecessarily complex. Definitely. Also a later item though. :). > We once talked about adding a symbolic thread-id field to each; > ..; > Instead, it could a great topic for a separate study. Agreed. :). > What is the semantics",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveCommentsResponse.txt:6166,perform,performance,6166,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveCommentsResponse.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveCommentsResponse.txt,1,['perform'],['performance']
Performance," $ cmake -C <path to cache file> <path to sources>. CMake cache scripts are processed in an isolated scope, only cached variables; remain set when the main configuration runs. CMake cached variables do not reset; variables that are already set unless the FORCE option is specified. A few notes about CMake Caches:. - Order of command line arguments is important. - -D arguments specified before -C are set before the cache is processed and; can be read inside the cache file; - -D arguments specified after -C are set after the cache is processed and; are unset inside the cache file. - All -D arguments will override cache file settings; - CMAKE_TOOLCHAIN_FILE is evaluated after both the cache file and the command; line arguments; - It is recommended that all -D options should be specified *before* -C. For more information about some of the advanced build configurations supported; via Cache files see :doc:`AdvancedBuilds`. Executing the Tests; ===================. Testing is performed when the *check-all* target is built. For instance, if you are; using Makefiles, execute this command in the root of your build directory:. .. code-block:: console. $ make check-all. On Visual Studio, you may run tests by building the project ""check-all"".; For more information about testing, see the :doc:`TestingGuide`. Cross compiling; ===============. See `this wiki page <https://gitlab.kitware.com/cmake/community/wikis/doc/cmake/CrossCompiling>`_ for; generic instructions on how to cross-compile with CMake. It goes into detailed; explanations and may seem daunting, but it is not. On the wiki page there are; several examples including toolchain files. Go directly to the; ``Information how to set up various cross compiling toolchains`` section; for a quick solution. Also see the `LLVM-related variables`_ section for variables used when; cross-compiling. Embedding LLVM in your project; ==============================. From LLVM 3.5 onwards the CMake build system exports LLVM libraries as; impor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst:39912,perform,performed,39912,interpreter/llvm-project/llvm/docs/CMake.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMake.rst,1,['perform'],['performed']
Performance," $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2. Here, to avoid presenting a state in which the first assignment to ``!1``; disappears, the DBG_VALUE at the top of the block assigns the variable the; undefined location, until its value is available at the end of the block where; an additional DBG_VALUE is added. Were any other DBG_VALUE for ``!1`` to occur; in the instructions that the MOV32rm was sunk past, the DBG_VALUE for ``%1``; would be dropped and the debugger would never observe it in the variable. This; accurately reflects that the value is not available during the corresponding; portion of the original program. Variable locations during Register Allocation; ---------------------------------------------. To avoid debug instructions interfering with the register allocator, the; LiveDebugVariables pass extracts variable locations from a MIR function and; deletes the corresponding DBG_VALUE instructions. Some localized copy; propagation is performed within blocks. After register allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations. To avoid encoding incorrect variable locations, in this; pass any DBG_VALUE of a virtual register that is not live, is replaced by; the undefined location. The LiveDebugVariables may insert redundant DBG_VALUEs; because of virtual register rewriting. These will be subsequently removed by; the RemoveRedundantDebugValues pass. LiveDebugValues expansion of variable locations; -----------------------------------------------. After all optimizations have run and shortly before emission, the; LiveDebugValues pass runs to achieve two aims:. * To propagate the location of variables through copies and register spills,; * For every block, to record every valid variable location in that block. After this pass the DBG_VALUE instruction changes meaning: rather than; correspo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:35887,perform,performed,35887,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['perform'],['performed']
Performance," %inFloat3.713, <4 x float>* %P2; ret void; }. Generates:. _test:; 	movl	8(%esp), %eax; 	movaps	(%eax), %xmm0; 	pxor	%xmm1, %xmm1; 	movaps	%xmm0, %xmm2; 	shufps	$50, %xmm1, %xmm2; 	shufps	$132, %xmm2, %xmm0; 	movaps	%xmm0, (%eax); 	ret. Would it be better to generate:. _test:; movl 8(%esp), %ecx; movaps (%ecx), %xmm0; 	xor %eax, %eax; pinsrw $6, %eax, %xmm0; pinsrw $7, %eax, %xmm0; movaps %xmm0, (%ecx); ret. ?. //===---------------------------------------------------------------------===//. Some useful information in the Apple Altivec / SSE Migration Guide:. http://developer.apple.com/documentation/Performance/Conceptual/; Accelerate_sse_migration/index.html. e.g. SSE select using and, andnot, or. Various SSE compare translations. //===---------------------------------------------------------------------===//. Add hooks to commute some CMPP operations. //===---------------------------------------------------------------------===//. Apply the same transformation that merged four float into a single 128-bit load; to loads from constant pool. //===---------------------------------------------------------------------===//. Floating point max / min are commutable when -enable-unsafe-fp-path is; specified. We should turn int_x86_sse_max_ss and X86ISD::FMIN etc. into other; nodes which are selected to max / min instructions that are marked commutable. //===---------------------------------------------------------------------===//. We should materialize vector constants like ""all ones"" and ""signbit"" with ; code like:. cmpeqps xmm1, xmm1 ; xmm1 = all-ones. and:; cmpeqps xmm1, xmm1 ; xmm1 = all-ones; psrlq xmm1, 31 ; xmm1 = all 100000000000... instead of using a load from the constant pool. The later is important for; ABS/NEG/copysign etc. //===---------------------------------------------------------------------===//. These functions:. #include <xmmintrin.h>; __m128i a;; void x(unsigned short n) {; a = _mm_slli_epi32 (a, n);; }; void y(unsigned n) {; a = _mm_slli_epi32 (a, n",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt:9454,load,load,9454,interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,2,['load'],"['load', 'loads']"
Performance," %mask, <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>; %reduction = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %masked.a); %also.r = call i32 @llvm.umin.i32(i32 %reduction, i32 %start). .. _int_vp_reduce_fmax:. '``llvm.vp.reduce.fmax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fmax.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, float <vector_length>); declare double @llvm.vp.reduce.fmax.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmax``' intrinsic performs the floating-point ``MAX``; reduction (:ref:`llvm.vector.reduce.fmax <int_vector_reduce_fmax>`) of the; vector operand ``val`` on each enabled lane, taking the maximum of that and the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. The neutral value is dependent on the :ref:`fast-math flags <fastmath>`. If no; flags are set, the neutral value is ``-QNAN``. If ``nnan`` and ``ninf`` are; both set, then the neutral value is the smallest floating-point value for the; result type. If only ``nnan``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:771760,perform,performed,771760,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance," %mask, i32 %evl); declare <vscale x 1 x i64> @llvm.vp.load.nxv1i64.p6(ptr addrspace(6) %ptr, <vscale x 1 x i1> %mask, i32 %evl). Overview:; """""""""""""""""". The '``llvm.vp.load.*``' intrinsic is the vector length predicated version of; the :ref:`llvm.masked.load <int_mload>` intrinsic. Arguments:; """""""""""""""""""". The first operand is the base pointer for the load. The second operand is a; vector of boolean values with the same number of elements as the return type.; The third is the explicit vector length of the operation. The return type and; underlying type of the base pointer are the same vector types. The :ref:`align <attr_align>` parameter attribute can be provided for the first; operand. Semantics:; """""""""""""""""""". The '``llvm.vp.load``' intrinsic reads a vector from memory in the same way as; the '``llvm.masked.load``' intrinsic, where the mask is taken from the; combination of the '``mask``' and '``evl``' operands in the usual VP way.; Certain '``llvm.masked.load``' operands do not have corresponding operands in; '``llvm.vp.load``': the '``passthru``' operand is implicitly ``poison``; the; '``alignment``' operand is taken as the ``align`` parameter attribute, if; provided. The default alignment is taken as the ABI alignment of the return; type as specified by the :ref:`datalayout string<langref_datalayout>`. Examples:; """""""""""""""""". .. code-block:: text. %r = call <8 x i8> @llvm.vp.load.v8i8.p0(ptr align 2 %ptr, <8 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %also.r = call <8 x i8> @llvm.masked.load.v8i8.p0(ptr %ptr, i32 2, <8 x i1> %mask, <8 x i8> poison). .. _int_vp_store:. '``llvm.vp.store``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare void @llvm.vp.store.v4f32.p0(<4 x float> %val, ptr %ptr, <4 x i1> %mask, i32 %evl); declare void @llvm.vp.store.nxv2i16.p0(<vscale x 2 x i16> %val, ptr %ptr, <vscale x 2 x i1> %mask, i32 %evl); declare void @llv",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:784248,load,load,784248,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," '``llvm.pcmarker``' intrinsic is a method to export a Program; Counter (PC) in a region of code to simulators and other tools. The; method is target specific, but it is expected that the marker will use; exported symbols to transmit the PC of the marker. The marker makes no; guarantees that it will remain with any specific instruction after; optimizations. It is possible that the presence of a marker will inhibit; optimizations. The intended use is to be inserted after optimizations to; allow correlations of simulation runs. Arguments:; """""""""""""""""""". ``id`` is a numerical id identifying the marker. Semantics:; """""""""""""""""""". This intrinsic does not modify the behavior of the program. Backends; that do not support this intrinsic may ignore it. '``llvm.readcyclecounter``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i64 @llvm.readcyclecounter(). Overview:; """""""""""""""""". The '``llvm.readcyclecounter``' intrinsic provides access to the cycle; counter register (or similar low latency, high accuracy clocks) on those; targets that support it. On X86, it should map to RDTSC. On Alpha, it; should map to RPCC. As the backing counters overflow quickly (on the; order of 9 seconds on alpha), this should only be used for small; timings. Semantics:; """""""""""""""""""". When directly supported, reading the cycle counter should not modify any; memory. Implementations are allowed to either return an application; specific value or a system wide value. On backends without support, this; is lowered to a constant 0. Note that runtime support may be conditional on the privilege-level code is; running at and the host platform. '``llvm.clear_cache``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.clear_cache(ptr, ptr). Overview:; """""""""""""""""". The '``llvm.clear_cache``' intrinsic ensures visibility of modifications; in the specified range to the execution unit of the processor. On; targets with non-unified instruction and data cache, t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:525204,latency,latency,525204,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['latency'],['latency']
Performance," 'any' causes the merge command to; fail if any profiles are invalid, and 'all' causes the merge command to fail; only if all profiles are invalid. If 'all' is set, information from any; invalid profiles is excluded from the final merged product. The default; failure mode is 'any'. .. option:: --prof-sym-list=<path>. Specify a file which contains a list of symbols to generate profile symbol; list in the profile. This option can only be used with sample-based profile; in extbinary format. The entries in this file are newline-separated. .. option:: --compress-all-sections=[true|false]. Compress all sections when writing the profile. This option can only be used; with sample-based profile in extbinary format. .. option:: --use-md5=[true|false]. Use MD5 to represent string in name table when writing the profile.; This option can only be used with sample-based profile in extbinary format. .. option:: --gen-partial-profile=[true|false]. Mark the profile to be a partial profile which only provides partial profile; coverage for the optimized target. This option can only be used with; sample-based profile in extbinary format. .. option:: --convert-sample-profile-layout=[nest|flat]. Convert the merged profile into a profile with a new layout. Supported; layout are ``nest`` (Nested profile, the input should be CS flat profile) and; ``flat`` (Profile with nested inlinees flattened out). .. option:: --supplement-instr-with-sample=<file>. Supplement an instrumentation profile with sample profile. The sample profile; is the input of the flag. Output will be in instrumentation format (only works; with -instr). .. option:: --zero-counter-threshold=<float>. For the function which is cold in instr profile but hot in sample profile, if; the ratio of the number of zero counters divided by the total number of; counters is above the threshold, the profile of the function will be regarded; as being harmful for performance and will be dropped. .. option:: --instr-prof-cold-threshold=<int>. U",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst:5154,optimiz,optimized,5154,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,1,['optimiz'],['optimized']
Performance," 'fn'. Remove 'protocol+server' from file tagging and matching, i.e. use; only filepath+anchor; in this way a list is valid even after re-staging; of the dataset files, which typically changes the end-point data servers.; Entry-lists created with the full path should still be matched correctly. Miscellaneous. Repaired the behavior of TTreeCache when the TTree has a dramatic dynamic range with a lots of very small entriesat the beginning and very large entries at the end, the size in bytes of the cluster for the later entries will be very large (because of the cluster size in entries is large!). TTreeCache::FillBuffer was always attempting to load complete clusters not matter the; size (even with the size was larger than 2GB!). This patch resolves the issue by limiting the amount of memory used to:. The requested size if more than one cluster fits in the cache.; Twice the requested size if at least one basket per branch fits in the cache.; Four time the requested size in the case where the cache can not even hold one basket per branch. The filling will restart at the next cluster boundary in the case a) and will; restart at the maximum of entry number read in the cache in the case b) and c).; Baskets that are below this boundary and did not fit in the cache will be read; individually.; Repaired the basket flushing frequency when the TTree has already more than one cluster size.; Repaired binning of string histogram generated by TTree::Draw.; Many bug fixes and fix for issues discovery by Coverity, see change log for more details.; In TTree::MakeProxy add proper support for top level stl collection of objects and for stl collection of objects that are 'empty' in the file (and thus we know nothing about its content).; Avoid deficiency in hadd when the resulting TTree is longer than the AutoSave length *and* the TFileMerger needs to handle the input files in more than one pass for example when there is more than 1000 input files or the -n option is passed to hadd.; Fix s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html:3393,cache,cache,3393,tree/doc/v534/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html,1,['cache'],['cache']
Performance," 'malloc/calloc/realloc' call and the operand; of sizeof expressions contained within its argument(s).; checker-264; built: April 26, 2012; highlights:; This release contains misc. bug fixes and performance enhancements over checker-263, including; a reduction of some kinds of false positives related to the malloc() checker.; checker-263; built: March 22, 2012; highlights:. Fixes several serious bugs with inter-procedural analysis, including a case where retain/releases would be ""double-counted"". checker-262; built: March 15, 2012; highlights:. Enables experimental interprocedural analysis (within a file), which greatly amplifies the analyzer's ability to find issues.; Many bug fixes to the malloc/free checker.; Support for new Objective-C NSArray/NSDictionary/NSNumber literals syntax, and Objective-C container subscripting. NOTE: This build contains new interprocedural analysis that allows the analyzer to find more complicated bugs that span function boundaries. It may have problems, performance issues, etc. We'd like to hear about them. checker-261; built: February 22, 2012; highlights:. Contains a new experimental malloc/free checker.; Better support for projects using ARC.; Warns about null pointers passed as arguments to C string functions.; Warns about common anti-patterns in 'strncat' size argument, which can lead to buffer overflows.; set-xcode-analyzer now supports self-contained Xcode.app (Xcode 4.3 and later).; Contains a newer version of the analyzer than Xcode 4.3.; Misc. bug fixes and performance work. checker-260; built: January 25, 2012; highlights:; This is essentially the same as checker-259, but enables the following experimental checkers (please provide feedback):. Warns about unsafe uses of CFArrayCreate, CFSetCreate, and CFDictionaryCreate; Warns about unsafe uses of getpw, gets, which are sources of buffer overflows; Warns about unsafe uses of mktemp and mktemps, which can lead to insecure temporary files; Warns about unsafe uses of vfork, whic",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html:8721,perform,performance,8721,interpreter/llvm-project/clang/www/analyzer/release_notes.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html,1,['perform'],['performance']
Performance," (If you are writing a backend for an; architecture which cannot satisfy these restrictions and cares about; concurrency, please send an email to llvm-dev.). Unordered; ---------. Unordered is the lowest level of atomicity. It essentially guarantees that races; produce somewhat sane results instead of having undefined behavior. It also; guarantees the operation to be lock-free, so it does not depend on the data; being part of a special atomic structure or depend on a separate per-process; global lock. Note that code generation will fail for unsupported atomic; operations; if you need such an operation, use explicit locking. Relevant standard; This is intended to match the Java memory model for shared variables. Notes for frontends; This cannot be used for synchronization, but is useful for Java and other; ""safe"" languages which need to guarantee that the generated code never; exhibits undefined behavior. Note that this guarantee is cheap on common; platforms for loads of a native width, but can be expensive or unavailable for; wider loads, like a 64-bit store on ARM. (A frontend for Java or other ""safe""; languages would normally split a 64-bit store on ARM into two 32-bit unordered; stores.). Notes for optimizers; In terms of the optimizer, this prohibits any transformation that transforms a; single load into multiple loads, transforms a store into multiple stores,; narrows a store, or stores a value which would not be stored otherwise. Some; examples of unsafe optimizations are narrowing an assignment into a bitfield,; rematerializing a load, and turning loads and stores into a memcpy; call. Reordering unordered operations is safe, though, and optimizers should; take advantage of that because unordered operations are common in languages; that need them. Notes for code generation; These operations are required to be atomic in the sense that if you use; unordered loads and unordered stores, a load cannot see a value which was; never stored. A normal load or store ins",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:8744,load,loads,8744,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,2,['load'],['loads']
Performance," (LDS) address space and is treated as work-group. The memory model does not support the region address space which is treated as; non-atomic. Acquire memory ordering is not meaningful on store atomic instructions and is; treated as non-atomic. Release memory ordering is not meaningful on load atomic instructions and is; treated a non-atomic. Acquire-release memory ordering is not meaningful on load or store atomic; instructions and is treated as acquire and release respectively. The memory order also adds the single thread optimization constraints defined in; table; :ref:`amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table`. .. table:: AMDHSA Memory Model Single Thread Optimization Constraints; :name: amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table. ============ ==============================================================; LLVM Memory Optimization Constraints; Ordering; ============ ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved after the release.; - If a fence then same as store atomic, plus no following; associated fence-paired-atomic can be moved before the; fence.; acq_rel Same constraints as both acquire and release.; seq_cst - If a load atomic then same constraints as acquire, plus no; preceding sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved after the; seq_cst.; - If a store atomic then the same constraints as release, plus; no following sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction ca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:204754,load,load,204754,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,3,['load'],['load']
Performance," (MEMrr $rs1, $rs2):$addr),; ""ld [$addr], $dst"",; [(set i32:$dst, (load ADDRrr:$addr))]>;. The fourth parameter is the input source, which uses the address operand; ``MEMrr`` that is defined earlier in ``SparcInstrInfo.td``:. .. code-block:: text. def MEMrr : Operand<i32> {; let PrintMethod = ""printMemOperand"";; let MIOperandInfo = (ops IntRegs, IntRegs);; }. The fifth parameter is a string that is used by the assembly printer and can be; left as an empty string until the assembly printer interface is implemented.; The sixth and final parameter is the pattern used to match the instruction; during the SelectionDAG Select Phase described in :doc:`CodeGenerator`.; This parameter is detailed in the next section, :ref:`instruction-selector`. Instruction class definitions are not overloaded for different operand types,; so separate versions of instructions are needed for register, memory, or; immediate value operands. For example, to perform a Load Integer instruction; for a Word from an immediate operand to a register, the following instruction; class is defined:. .. code-block:: text. def LDri : F3_2 <3, 0b000000, (outs IntRegs:$rd), (ins (MEMri $rs1, $simm13):$addr),; ""ld [$addr], $dst"",; [(set i32:$rd, (load ADDRri:$addr))]>;. Writing these definitions for so many similar instructions can involve a lot of; cut and paste. In ``.td`` files, the ``multiclass`` directive enables the; creation of templates to define several instruction classes at once (using the; ``defm`` directive). For example in ``SparcInstrInfo.td``, the ``multiclass``; pattern ``F3_12`` is defined to create 2 instruction classes each time; ``F3_12`` is invoked:. .. code-block:: text. multiclass F3_12 <string OpcStr, bits<6> Op3Val, SDNode OpNode> {; def rr : F3_1 <2, Op3Val,; (outs IntRegs:$rd), (ins IntRegs:$rs1, IntRegs:$rs1),; !strconcat(OpcStr, "" $rs1, $rs2, $rd""),; [(set i32:$rd, (OpNode i32:$rs1, i32:$rs2))]>;; def ri : F3_2 <2, Op3Val,; (outs IntRegs:$rd), (ins IntRegs:$rs1, i32imm:$simm13),; !",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:33959,perform,perform,33959,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['perform'],['perform']
Performance," (all the registers that are; preserved on the fast path, composed of the entry and exit blocks). This calling convention behaves identical to the `C` calling convention on; how arguments and return values are passed, but it uses a different set of; caller/callee-saved registers. Given that each platform has its own lowering sequence, hence its own set; of preserved registers, we can't use the existing `PreserveMost`. - On X86-64 the callee preserves all general purpose registers, except for; RDI and RAX.; ""``tailcc``"" - Tail callable calling convention; This calling convention ensures that calls in tail position will always be; tail call optimized. This calling convention is equivalent to fastcc,; except for an additional guarantee that tail calls will be produced; whenever possible. `Tail calls can only be optimized when this, the fastcc,; the GHC or the HiPE convention is used. <CodeGenerator.html#tail-call-optimization>`_; This calling convention does not support varargs and requires the prototype of; all callees to exactly match the prototype of the function definition.; ""``swiftcc``"" - This calling convention is used for Swift language.; - On X86-64 RCX and R8 are available for additional integer returns, and; XMM2 and XMM3 are available for additional FP/vector returns.; - On iOS platforms, we use AAPCS-VFP calling convention.; ""``swifttailcc``""; This calling convention is like ``swiftcc`` in most respects, but also the; callee pops the argument area of the stack so that mandatory tail calls are; possible as in ``tailcc``.; ""``cfguard_checkcc``"" - Windows Control Flow Guard (Check mechanism); This calling convention is used for the Control Flow Guard check function,; calls to which can be inserted before indirect calls to check that the call; target is a valid function address. The check function has no return value,; but it will trigger an OS-level error if the address is not a valid target.; The set of registers preserved by the check function, and the regi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:21303,optimiz,optimization,21303,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimization']
Performance," (and later ip) is the hidden parameter from caller to store the value in. The; first ldmia loads the constants into r0, r1, r2. The last stmia stores r0, r1,; r2 into the address passed in. However, there is one additional stmia that; stores r0, r1, and r2 to some stack location. The store is dead. The llvm-gcc generated code looks like this:. csretcc void %foo(%struct.s* %agg.result) {; entry:; 	%S = alloca %struct.s, align 4		; <%struct.s*> [#uses=1]; 	%memtmp = alloca %struct.s		; <%struct.s*> [#uses=1]; 	cast %struct.s* %S to sbyte*		; <sbyte*>:0 [#uses=2]; 	call void %llvm.memcpy.i32( sbyte* %0, sbyte* cast ({ double, int }* %C.0.904 to sbyte*), uint 12, uint 4 ); 	cast %struct.s* %agg.result to sbyte*		; <sbyte*>:1 [#uses=2]; 	call void %llvm.memcpy.i32( sbyte* %1, sbyte* %0, uint 12, uint 0 ); 	cast %struct.s* %memtmp to sbyte*		; <sbyte*>:2 [#uses=1]; 	call void %llvm.memcpy.i32( sbyte* %2, sbyte* %1, uint 12, uint 0 ); 	ret void; }. llc ends up issuing two memcpy's (the first memcpy becomes 3 loads from; constantpool). Perhaps we should 1) fix llvm-gcc so the memcpy is translated; into a number of load and stores, or 2) custom lower memcpy (of small size) to; be ldmia / stmia. I think option 2 is better but the current register; allocator cannot allocate a chunk of registers at a time. A feasible temporary solution is to use specific physical registers at the; lowering time for small (<= 4 words?) transfer size. * ARM CSRet calling convention requires the hidden argument to be returned by; the callee. //===---------------------------------------------------------------------===//. We can definitely do a better job on BB placements to eliminate some branches.; It's very common to see llvm generated assembly code that looks like this:. LBB3:; ...; LBB4:; ...; beq LBB3; b LBB2. If BB4 is the only predecessor of BB3, then we can emit BB3 after BB4. We can; then eliminate beq and turn the unconditional branch to LBB2 to a bne. See McCat/18-imp/ComputeBoundingBo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:7110,load,loads,7110,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,1,['load'],['loads']
Performance," (stateless AA impl); Function Alias Analysis Results; Memory Dependence Analysis; Global Value Numbering; Hello World Pass; Dominator Tree Construction; Natural Loop Information; Canonicalize natural loops; Loop-Closed SSA Form Pass; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Scalar Evolution Analysis; Loop Pass Manager; Loop Invariant Code Motion; Module Verifier; Bitcode Writer; Hello: __main; Hello: puts; Hello: main. Here we see that the :ref:`Hello World <writing-an-llvm-pass-basiccode>` pass; has killed the Dominator Tree pass, even though it doesn't modify the code at; all! To fix this, we need to add the following :ref:`getAnalysisUsage; <writing-an-llvm-pass-getAnalysisUsage>` method to our pass:. .. code-block:: c++. // We don't modify the program, so we preserve all analyses; void getAnalysisUsage(AnalysisUsage &AU) const override {; AU.setPreservesAll();; }. Now when we run our pass, we get this output:. .. code-block:: console. $ opt -load lib/LLVMHello.so -gvn -hello -licm --debug-pass=Structure < hello.bc > /dev/null; Pass Arguments: -gvn -hello -licm; ModulePass Manager; FunctionPass Manager; Dominator Tree Construction; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Memory Dependence Analysis; Global Value Numbering; Hello World Pass; Natural Loop Information; Canonicalize natural loops; Loop-Closed SSA Form Pass; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Scalar Evolution Analysis; Loop Pass Manager; Loop Invariant Code Motion; Module Verifier; Bitcode Writer; Hello: __main; Hello: puts; Hello: main. Which shows that we don't accidentally invalidate dominator information; anymore, and therefore do not have to compute it twice. .. _writing-an-llvm-pass-releaseMemory:. The ``releaseMemory`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual void releaseMemory();. The ``PassManager`` automatically determines when to compute analysis results,; an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:46065,load,load,46065,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['load'],['load']
Performance," **`TGeoVolumeAssembly`** object and position the components inside as; for any volume:. ``` {.cpp}; TGeoVolume *vol = new TGeoVolumeAssembly(name);; vol->AddNode(vdaughter1, cpy1, matrix1);; vol->AddNode(vdaughter2, cpy2, matrix2);; ```. Note that components cannot be declared as ""overlapping"" and that a; component can be an assembly volume. For existing flat volume; structures, one can define assemblies to force a hierarchical structure; therefore optimizing the performance. Usage of assemblies does NOT imply; penalties in performance, but in some cases, it can be observed that it; is not as performing as bounding the structure in a container volume; with a simple shape. Choosing a normal container is therefore; recommended whenever possible. ![Assemblies of volumes](pictures/080001CF.png). ### Geometrical Transformations. All geometrical transformations handled by the modeller are provided as; a built-in package. This was designed to minimize memory requirements; and optimize performance of point/vector master-to-local and; local-to-master computation. We need to have in mind that a; transformation in **`TGeo`** has two major use-cases. The first one is; for defining the placement of a volume with respect to its container; reference frame. This frame will be called 'master' and the frame of the; positioned volume - 'local'. If `T` is a transformation used for; positioning volume daughters, then: `MASTER = T * LOCAL`. Therefore `T `is used to perform a local to master conversion, while; `T-1` for a master to local conversion. The second use case is the; computation of the global transformation of a given object in the; geometry. Since the geometry is built as 'volumes-inside-volumes', the; global transformation represents the pile-up of all local; transformations in the corresponding branch. Once a given object in the; hierarchy becomes the current one, the conversion from master to local; coordinates or the other way around can be done from the manager class. A g",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:91160,optimiz,optimize,91160,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,2,"['optimiz', 'perform']","['optimize', 'performance']"
Performance," *name*; exists; 0 otherwise. *name* should be of type *string*. ``!filter(``\ *var*\ ``,`` *list*\ ``,`` *predicate*\ ``)``. This operator creates a new ``list`` by filtering the elements in; *list*. To perform the filtering, TableGen binds the variable *var* to each; element and then evaluates the *predicate* expression, which presumably; refers to *var*. The predicate must; produce a boolean value (``bit``, ``bits``, or ``int``). The value is; interpreted as with ``!if``:; if the value is 0, the element is not included in the new list. If the value; is anything else, the element is included. ``!find(``\ *string1*\ ``,`` *string2*\ [``,`` *start*]\ ``)``; This operator searches for *string2* in *string1* and produces its; position. The starting position of the search may be specified by *start*,; which can range between 0 and the length of *string1*; the default is 0.; If the string is not found, the result is -1. ``!foldl(``\ *init*\ ``,`` *list*\ ``,`` *acc*\ ``,`` *var*\ ``,`` *expr*\ ``)``; This operator performs a left-fold over the items in *list*. The; variable *acc* acts as the accumulator and is initialized to *init*.; The variable *var* is bound to each element in the *list*. The; expression is evaluated for each element and presumably uses *acc* and; *var* to calculate the accumulated value, which ``!foldl`` stores back in; *acc*. The type of *acc* is the same as *init*; the type of *var* is the; same as the elements of *list*; *expr* must have the same type as *init*. The following example computes the total of the ``Number`` field in the; list of records in ``RecList``::. int x = !foldl(0, RecList, total, rec, !add(total, rec.Number));. If your goal is to filter the list and produce a new list that includes only; some of the elements, see ``!filter``. ``!foreach(``\ *var*\ ``,`` *sequence*\ ``,`` *expr*\ ``)``; This operator creates a new ``list``/``dag`` in which each element is a; function of the corresponding element in the *sequence* ``list``/``dag",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:63934,perform,performs,63934,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['perform'],['performs']
Performance, *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load; glc=1 slc=1. - volatile. 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_store; - constant; - !volatile & nontemporal. 1. buffer/global/flat_store; glc=1 slc=1. - volatile. 1. buffer/global/flat_store; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - workgroup - generic; load atomic monotonic - agent - global 1. buffer/global/flat_load; - system - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; - system; store atomic monotonic - singlethread - local 1. ds_store; - wavefront; - workgroup; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; - system; atomicrmw monotonic - singlethread - local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ----------------------,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:213061,load,load,213061,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance," *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load; glc=1 slc=1. - volatile. 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_store; - constant; - !volatile & nontemporal. 1. buffer/global/flat_store; glc=1 slc=1. - volatile. 1. buffer/global/flat_store; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/flat_load; - wavefront - generic; load atomic monotonic - workgroup - global 1. buffer/global/flat_load; - generic glc=1. - If not TgSplit execution; mode, omit glc=1. load atomic monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_load; load atomic monotonic - agent - global 1. buffer/global/flat_load; - generic glc=1; load atomic monotonic - system - global 1. buffer/global/flat_load; - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; store atomic m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:243549,load,load,243549,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance," *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store atomic/; atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:361136,load,load,361136,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," *start = A.GetMatrixArray();; Double_t *rp1 = start+i*ncols;; const Double_t *rp2 = start+j*ncols;; while (rp1 < start+ncols) *rp1++ = *rp2++;; ```. Check that the columns of a Haar -matrix of order `order` are indeed; orthogonal:. ``` {.cpp}; const TMatrixD haar = THaarMatrixD(order);; TVectorD colj(1<<order);; TVectorD coll(1<<order);; for (Int_t j = haar.GetColLwb(); j <= haar.GetColUpb(); j++) {; colj = TMatrixDColumn_const(haar,j);; Assert(TMath::Abs(colj*colj-1.0) <= 1.0e-15);. for (Int_t l = j+1; l <= haar.GetColUpb(); l++) {; coll = TMatrixDColumn_const(haar,l);; Assert(TMath::Abs(colj*coll) <= 1.0e-15);; }; }; ```. Multiplying part of a matrix with another part of that matrix (they can overlap). ``` {.cpp}; TMatrixDSub(m,1,3,1,3) *= m.GetSub(5,7,5,7);; ```. ## Matrix Decompositions. The linear algebra package offers several classes to assist in matrix; decompositions. Each of the decomposition methods performs a set of; matrix transformations to facilitate solving a system of linear; equations, the formation of inverses as well as the estimation of; determinants and condition numbers. More specifically the classes; **`TDecompLU`**, **`TDecompBK`**, **`TDecompChol`**, **`TDecompQRH`** and; **`TDecompSVD`** give a simple and consistent interface to the LU,; Bunch-Kaufman, Cholesky, QR and SVD decompositions. All of these classes; are derived from the base class **`TDecompBase`** of which the important; methods are listed in next table:. +-----------------------------------------------------+--------------------------------------+; | Method | Action |; +-----------------------------------------------------+--------------------------------------+; | `Bool_t Decompose()` | perform the matrix decomposition |; +-----------------------------------------------------+--------------------------------------+; | `Double_t Condition()` | calculate ||*A*||1 ||*A*-1||1, |; | | see ""Condition number"" |; +-----------------------------------------------------+----------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md:33489,perform,performs,33489,documentation/users-guide/LinearAlgebra.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/LinearAlgebra.md,1,['perform'],['performs']
Performance," *uOps Per Cycle* is bounded from above by the dispatch width. That is; because the dispatch width limits the maximum size of a dispatch group. Both IPC; and 'uOps Per Cycle' are limited by the amount of hardware parallelism. The; availability of hardware resources affects the resource pressure distribution,; and it limits the number of instructions that can be executed in parallel every; cycle. A delta between Dispatch Width and the theoretical maximum uOps per; Cycle (computed by dividing the number of uOps of a single iteration by the; `Block RThroughput`) is an indicator of a performance bottleneck caused by the; lack of hardware resources.; In general, the lower the Block RThroughput, the better. In this example, ``uOps per iteration/Block RThroughput`` is 1.50. Since there; are no loop-carried dependencies, the observed `uOps Per Cycle` is expected to; approach 1.50 when the number of iterations tends to infinity. The delta between; the Dispatch Width (2.00), and the theoretical maximum uOp throughput (1.50) is; an indicator of a performance bottleneck caused by the lack of hardware; resources, and the *Resource pressure view* can help to identify the problematic; resource usage. The second section of the report is the `instruction info view`. It shows the; latency and reciprocal throughput of every instruction in the sequence. It also; reports extra information related to the number of micro opcodes, and opcode; properties (i.e., 'MayLoad', 'MayStore', and 'HasSideEffects'). Field *RThroughput* is the reciprocal of the instruction throughput. Throughput; is computed as the maximum number of instructions of a same type that can be; executed per clock cycle in the absence of operand dependencies. In this; example, the reciprocal throughput of a vector float multiply is 1; cycles/instruction. That is because the FP multiplier JFPM is only available; from pipeline JFPU1. Instruction encodings are displayed within the instruction info view when flag; `-show-encodin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:18318,throughput,throughput,18318,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['throughput'],['throughput']
Performance," *‘No drawing'* sets On/Off the option ""`0`""- do not draw the fit; results. *‘Do not store/draw'* sets On/Off option ""`N`""- do not store the; function and do not draw it. ### Advances Options. The advance option button is enabled only after having performed the fit and provides; additional drawing options that can be used after having done the fit. These new drawing tools,; which can be selected by the ""Advanced Drawing Tool"" panel that pops up when clicking the ""Advanced"" button, are:. * *Contour*: to plot the confidence contour of two chosen parameters. One can select the number of points to draw the contour; (more points might require more time to compute it), the parameters and the desired confidence level . * *Scan* : to plot a scan of the minimization function (likelihood or chi-squared) around the minimum as function of the chosen parameter. * *Conf Interval* : to plot the confidence interval of the fitted function as a filled coloured band around its central value.; One can select the desired confidence level for the band to be plotted. ### Print Options. This set of options specifies the amount of feedback printed on the; root command line after performed fits. *‘Verbose'* - prints fit results after each iteration. *‘Quiet'* - no fit information is printed. *‘Default'* - between Verbose and Quiet. ### Command Buttons. *Fit button* - performs a fit taking different option settings via the; Fit Panel interface. *Reset* - sets the GUI elements and related fit settings to the; default ones. *Close* - closes the Fit panel window. ### Minimization Options. With this tab one can select specific options for minimization. These include. * The minimizer library ( *Minuit*, *Minuit2*, *Fumili*, *GSL*, *Genetics* ); * The method (algorithm) for minimization. For example for Minuit one can choose between (*Migrad*, *Simplex* or *Scan*); * Error definition; * Minimization tolerance; * Number of iterations/function calls; * Print Level: (*Default*, *Verbose* or *Quiet*). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md:5436,perform,performed,5436,gui/fitpanel/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/gui/fitpanel/doc/index.md,2,['perform'],"['performed', 'performs']"
Performance," +-------------------------------+-------------------------------+---------------------+; | | ``LDR`` layout | ``LD1`` layout |; +===============================+===============================+=====================+; | Lane ordering | ``LDR + REV`` | ``LD1`` |; +-------------------------------+-------------------------------+---------------------+; | AAPCS | ``LDR`` | ``LD1 + REV`` |; +-------------------------------+-------------------------------+---------------------+; | Alignment for strict mode | ``LDR`` / ``LD1 + REV`` | ``LD1`` |; +-------------------------------+-------------------------------+---------------------+. Neither approach is perfect, and choosing one boils down to choosing the lesser of two evils. The issue with lane ordering, it was decided, would have to change target-agnostic compiler passes and would result in a strange IR in which lane indices were reversed. It was decided that this was worse than the changes that would have to be made to support ``LD1``, so ``LD1`` was chosen as the canonical vector load instruction (and by inference, ``ST1`` for vector stores). Implementation; ==============. There are 3 parts to the implementation:. 1. Predicate ``LDR`` and ``STR`` instructions so that they are never allowed to be selected to generate vector loads and stores. The exception is one-lane vectors [1]_ - these by definition cannot have lane ordering problems so are fine to use ``LDR``/``STR``. 2. Create code generation patterns for bitconverts that create ``REV`` instructions. 3. Make sure appropriate bitconverts are created so that vector values get passed over call boundaries as 1-element vectors (which is the same as if they were loaded with ``LDR``). Bitconverts; -----------. .. image:: ARM-BE-bitcastfail.png; :align: right. The main problem with the ``LD1`` solution is dealing with bitconverts (or bitcasts, or reinterpret casts). These are pseudo instructions that only change the compiler's interpretation of data, not the underlying data ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst:9090,load,load,9090,interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,1,['load'],['load']
Performance," - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - workgroup - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - agent - generic 1. flat_atomic; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence fla",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:216110,cache,cache,216110,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and L2 writeback; have completed before; performing the; atomicrmw that is; being released. 3. flat_atomic sc1=1; 4. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 5. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/sto",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:324712,load,load,324712,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," - generic sc1=1; atomicrmw monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_atomic; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load sc0=1; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_inv. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load sc0=1; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_inv and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/g",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:296280,load,load,296280,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - agent - generic 1. flat_atomic; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the; value read by the; fence-paired-atomic. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:216622,load,load,216622,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," - this gives you; dereferencability information. In MCJIT, use getSymbolAddress to provide; actual address. #. Be wary of ordered and atomic memory operations. They are hard to optimize; and may not be well optimized by the current optimizer. Depending on your; source language, you may consider using fences instead. #. If calling a function which is known to throw an exception (unwind), use; an invoke with a normal destination which contains an unreachable; instruction. This form conveys to the optimizer that the call returns; abnormally. For an invoke which neither returns normally or requires unwind; code in the current function, you can use a noreturn call instruction if; desired. This is generally not required because the optimizer will convert; an invoke with an unreachable unwind destination to a call instruction. #. Use profile metadata to indicate statically known cold paths, even if; dynamic profiling information is not available. This can make a large; difference in code placement and thus the performance of tight loops. #. When generating code for loops, try to avoid terminating the header block of; the loop earlier than necessary. If the terminator of the loop header; block is a loop exiting conditional branch, the effectiveness of LICM will; be limited for loads not in the header. (This is due to the fact that LLVM; may not know such a load is safe to speculatively execute and thus can't; lift an otherwise loop invariant load unless it can prove the exiting; condition is not taken.) It can be profitable, in some cases, to emit such; instructions into the header even if they are not used along a rarely; executed path that exits the loop. This guidance specifically does not; apply if the condition which terminates the loop header is itself invariant,; or can be easily discharged by inspecting the loop index variables. #. In hot loops, consider duplicating instructions from small basic blocks; which end in highly predictable terminators into their successo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:7199,perform,performance,7199,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['perform'],['performance']
Performance," ---------------------------------------. LLVM provides intrinsics for predicated vector load and store operations. The predicate is specified by a mask operand, which holds one bit per vector element, switching the associated vector lane on or off. The memory addresses corresponding to the ""off"" lanes are not accessed. When all bits of the mask are on, the intrinsic is identical to a regular vector load or store. When all bits are off, no memory is accessed. .. _int_mload:. '``llvm.masked.load.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. The loaded data is a vector of any integer, floating-point or pointer data type. ::. declare <16 x float> @llvm.masked.load.v16f32.p0(ptr <ptr>, i32 <alignment>, <16 x i1> <mask>, <16 x float> <passthru>); declare <2 x double> @llvm.masked.load.v2f64.p0(ptr <ptr>, i32 <alignment>, <2 x i1> <mask>, <2 x double> <passthru>); ;; The data is a vector of pointers; declare <8 x ptr> @llvm.masked.load.v8p0.p0(ptr <ptr>, i32 <alignment>, <8 x i1> <mask>, <8 x ptr> <passthru>). Overview:; """""""""""""""""". Reads a vector from memory according to the provided mask. The mask holds a bit for each vector lane, and is used to prevent memory accesses to the masked-off lanes. The masked-off lanes in the result vector are taken from the corresponding lanes of the '``passthru``' operand. Arguments:; """""""""""""""""""". The first operand is the base pointer for the load. The second operand is the alignment of the source location. It must be a power of two constant integer value. The third operand, mask, is a vector of boolean values with the same number of elements as the return type. The fourth is a pass-through value that is used to fill the masked-off lanes of the result. The return type, underlying type of the base pointer and the type of the '``passthru``' operand are the same vector types. Semantics:; """""""""""""""""""". The '``llvm.masked.load``' intrinsic is designed for conditional reading of selected vect",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:843648,load,load,843648,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," ---------------. The following options exist in RNTuple for multithreaded data processing. ### Implicit Multi-Threading; When `ROOT::EnableImplicitMT()` is used, RNTuple uses ROOT's task arena to compress and decompress pages.; That requires writes to be buffered and reads uses the cluster pool resp.; The RNTuple data source for RDataFrame lets RDataFrame full control of the thread pool.; That means that RDataFrame uses a separate data source for every thread, each of the data sources runs in sequential mode. ### Concurrent Readers; Multiple readers can read the same RNTuple concurrently as long as access to every individual reader is sequential. ### Parallel REntry Preparation; Multiple `REntry` object can be concurrently prepared by multiple threads.; I.e., construction and binding of the objects can happen in parallel.; The actual reading and writing of entries (`RNTupleReader::LoadEntry()`, `RNTupleWriter::Fill()`) needs to be protected by a mutex.; This is considered ""mild scalability parallelization"" in RNTuple. ### RNTupleParallelWriter; The parallel writer offers the most scalable parallel writing interface.; Multiple _fill contexts_ can concurrently serialize and compress data.; Every fill context prepares a set of entire clusters in the final on-disk layout.; When a fill context flushes data,; a brief serialization point handles the RNTuple meta-data updates and the reservation of disk space to write into. Low precision float types; --------------------------; RNTuple supports encoding floating point types with a lower precision when writing them to disk. This encoding is specified by the; user per field and it is independent on the in-memory type used for that field (meaning both a `RField<double>` or `RField<float>` can; be mapped to e.g. a low-precision 16 bit float). RNTuple supports the following encodings (all mutually exclusive):. - **Real16**/**SplitReal16**: IEEE-754 half precision float. Set by calling `RField::SetHalfPrecision()`;; - **Real32Tru",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:25380,scalab,scalability,25380,tree/ntuple/v7/doc/Architecture.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md,1,['scalab'],['scalability']
Performance," -> target-specific intrinsic by overriding; ``shouldExpandAtomicRMWInIR``, ``emitMaskedAtomicRMWIntrinsic``,; ``shouldExpandAtomicCmpXchgInIR``, and ``emitMaskedAtomicCmpXchgIntrinsic``. For an example of these look at the ARM (first five lowerings) or RISC-V (last; lowering) backend. AtomicExpandPass supports two strategies for lowering atomicrmw/cmpxchg to; load-linked/store-conditional (LL/SC) loops. The first expands the LL/SC loop; in IR, calling target lowering hooks to emit intrinsics for the LL and SC; operations. However, many architectures have strict requirements for LL/SC; loops to ensure forward progress, such as restrictions on the number and type; of instructions in the loop. It isn't possible to enforce these restrictions; when the loop is expanded in LLVM IR, and so affected targets may prefer to; expand to LL/SC loops at a very late stage (i.e. after register allocation).; AtomicExpandPass can help support lowering of part-word atomicrmw or cmpxchg; using this strategy by producing IR for any shifting and masking that can be; performed outside of the LL/SC loop. Libcalls: __atomic_*; ====================. There are two kinds of atomic library calls that are generated by LLVM. Please; note that both sets of library functions somewhat confusingly share the names of; builtin functions defined by clang. Despite this, the library functions are; not directly related to the builtins: it is *not* the case that ``__atomic_*``; builtins lower to ``__atomic_*`` library calls and ``__sync_*`` builtins lower; to ``__sync_*`` library calls. The first set of library functions are named ``__atomic_*``. This set has been; ""standardized"" by GCC, and is described below. (See also `GCC's documentation; <https://gcc.gnu.org/wiki/Atomic/GCCMM/LIbrary>`_). LLVM's AtomicExpandPass will translate atomic operations on data sizes above; ``MaxAtomicSizeInBitsSupported`` into calls to these functions. There are four generic functions, which can be called with data of any size",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:22579,perform,performed,22579,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['perform'],['performed']
Performance," -O3 - Enable expensive optimizations; -debug_level - Set the debugging level:; =none - disable debug information; =quick - enable quick debug information; =detailed - enable detailed debug information; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. Again, the only structural difference between the debug level declaration and; the optimization level declaration is that the debug level declaration includes; an option name (``""debug_level""``), which automatically changes how the library; processes the argument. The CommandLine library supports both forms so that you; can choose the form most appropriate for your application. .. _lists:. Parsing a list of options; -------------------------. Now that we have the standard run-of-the-mill argument types out of the way,; lets get a little wild and crazy. Lets say that we want our optimizer to accept; a **list** of optimizations to perform, allowing duplicates. For example, we; might want to run: ""``compiler -dce -instsimplify -inline -dce -strip``"". In this; case, the order of the arguments and the number of appearances is very; important. This is what the ""``cl::list``"" template is for. First, start by; defining an enum of the optimizations that you would like to perform:. .. code-block:: c++. enum Opts {; // 'inline' is a C++ keyword, so name it 'inlining'; dce, instsimplify, inlining, strip; };. Then define your ""``cl::list``"" variable:. .. code-block:: c++. cl::list<Opts> OptimizationList(cl::desc(""Available Optimizations:""),; cl::values(; clEnumVal(dce , ""Dead Code Elimination""),; clEnumVal(instsimplify , ""Instruction Simplification""),; clEnumValN(inlining, ""inline"", ""Procedure Integration""),; clEnumVal(strip , ""Strip Symbols"")));. This defines a variable that is conceptually of the type; ""``std::vector<enum Opts>``"". Thus, you can access it with standard vector; methods:. .. code-b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:19259,optimiz,optimizer,19259,interpreter/llvm-project/llvm/docs/CommandLine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst,3,"['optimiz', 'perform']","['optimizations', 'optimizer', 'perform']"
Performance," -arch i386 -arch x86_64 t0.c t1.c; 0: input, ""t0.c"", c; 1: preprocessor, {0}, cpp-output; 2: compiler, {1}, assembler; 3: assembler, {2}, object; 4: bind-arch, ""i386"", {3}, object; 5: bind-arch, ""x86_64"", {3}, object; 6: lipo, {4, 5}, object; 7: input, ""t1.c"", c; 8: preprocessor, {7}, cpp-output; 9: compiler, {8}, assembler; 10: assembler, {9}, object; 11: bind-arch, ""i386"", {10}, object; 12: bind-arch, ""x86_64"", {10}, object; 13: lipo, {11, 12}, object. After this stage is complete the compilation process is divided into; a simple set of actions which need to be performed to produce; intermediate or final outputs (in some cases, like ``-fsyntax-only``,; there is no ""real"" final output). Phases are well known compilation; steps, such as ""preprocess"", ""compile"", ""assemble"", ""link"", etc. #. **Bind: Tool & Filename Selection**. This stage (in conjunction with the Translate stage) turns the tree; of Actions into a list of actual subprocess to run. Conceptually, the; driver performs a top down matching to assign Action(s) to Tools. The; ToolChain is responsible for selecting the tool to perform a; particular action; once selected the driver interacts with the tool; to see if it can match additional actions (for example, by having an; integrated preprocessor). Once Tools have been selected for all actions, the driver determines; how the tools should be connected (for example, using an inprocess; module, pipes, temporary files, or user provided filenames). If an; output file is required, the driver also computes the appropriate; file name (the suffix and file location depend on the input types and; options such as ``-save-temps``). The driver interacts with a ToolChain to perform the Tool bindings.; Each ToolChain contains information about all the tools needed for; compilation for a particular architecture, platform, and operating; system. A single driver invocation may query multiple ToolChains; during one compilation in order to interact with tools for separate; archite",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DriverInternals.rst:8672,perform,performs,8672,interpreter/llvm-project/clang/docs/DriverInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DriverInternals.rst,1,['perform'],['performs']
Performance," -debug-only=foo; 'foo' debug type; $ opt < a.bc > /dev/null -mypass -debug-only=bar; 'bar' debug type; $ opt < a.bc > /dev/null -mypass -debug-only=foo,bar; 'foo' debug type; 'bar' debug type. Of course, in practice, you should only set ``DEBUG_TYPE`` at the top of a file,; to specify the debug type for the entire module. Be careful that you only do; this after including Debug.h and not around any #include of headers. Also, you; should use names more meaningful than ""foo"" and ""bar"", because there is no; system in place to ensure that names do not conflict. If two different modules; use the same string, they will all be turned on when the name is specified.; This allows, for example, all debug information for instruction scheduling to be; enabled with ``-debug-only=InstrSched``, even if the source lives in multiple; files. The name must not include a comma (,) as that is used to separate the; arguments of the ``-debug-only`` option. For performance reasons, -debug-only is not available in optimized build; (``--enable-optimized``) of LLVM. The ``DEBUG_WITH_TYPE`` macro is also available for situations where you would; like to set ``DEBUG_TYPE``, but only for one specific ``DEBUG`` statement. It; takes an additional first parameter, which is the type to use. For example, the; preceding example could be written as:. .. code-block:: c++. DEBUG_WITH_TYPE(""foo"", dbgs() << ""'foo' debug type\n"");; DEBUG_WITH_TYPE(""bar"", dbgs() << ""'bar' debug type\n"");. .. _Statistic:. The ``Statistic`` class & ``-stats`` option; -------------------------------------------. The ``llvm/ADT/Statistic.h`` (`doxygen; <https://llvm.org/doxygen/Statistic_8h_source.html>`__) file provides a class; named ``Statistic`` that is used as a unified way to keep track of what the LLVM; compiler is doing and how effective various optimizations are. It is useful to; see what optimizations are contributing to making a particular program run; faster. Often you may run your pass on some big program, and you're",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:45690,perform,performance,45690,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,3,"['optimiz', 'perform']","['optimized', 'performance']"
Performance," -emit-obj use.c -fmodules -fimplicit-module-maps -fmodules-cache-path=prebuilt -fdisable-module-hash; ls prebuilt/*.pcm; # prebuilt/A.pcm prebuilt/B.pcm. Note that with explicit or prebuilt modules, we are responsible for, and should be particularly careful about the compatibility of our modules.; Using mismatching compilation options and modules may lead to issues. .. code-block:: sh. clang -cc1 -emit-obj use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt -DENABLE_A; # use.c:4:10: warning: implicit declaration of function 'a' is invalid in C99 [-Wimplicit-function-declaration]; # return a(x);; # ^; # 1 warning generated. So we need to maintain multiple versions of prebuilt modules. We can do so using a manual module mapping, or pointing to a different prebuilt module cache path. For example:. .. code-block:: sh. rm -rf prebuilt ; mkdir prebuilt ; rm -rf prebuilt_a ; mkdir prebuilt_a; clang -cc1 -emit-obj use.c -fmodules -fimplicit-module-maps -fmodules-cache-path=prebuilt -fdisable-module-hash; clang -cc1 -emit-obj use.c -fmodules -fimplicit-module-maps -fmodules-cache-path=prebuilt_a -fdisable-module-hash -DENABLE_A; clang -cc1 -emit-obj use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt; clang -cc1 -emit-obj use.c -fmodules -fimplicit-module-maps -fprebuilt-module-path=prebuilt_a -DENABLE_A. Instead of managing the different module versions manually, we can build implicit modules in a given cache path (using ``-fmodules-cache-path``), and reuse them as prebuilt implicit modules by passing ``-fprebuilt-module-path`` and ``-fprebuilt-implicit-modules``. .. code-block:: sh. rm -rf prebuilt; mkdir prebuilt; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fmodules-cache-path=prebuilt; clang -cc1 -emit-obj -o use.o use.c -fmodules -fimplicit-module-maps -fmodules-cache-path=prebuilt -DENABLE_A; find prebuilt -name ""*.pcm""; # prebuilt/1AYBIGPM8R2GA/A-3L1K4LUA6O31.pcm; # prebuilt/1AYBIGPM8R2GA/B-3L1K4LUA6O31.p",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:21777,cache,cache-path,21777,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['cache'],['cache-path']
Performance," -fprofile-exclude-files=""^/usr/include/.*$"" \; -fprofile-filter-files=""^/usr/.*$"". In that case ``/usr/foo/oof.h`` is instrumented since it matches the filter regex and; doesn't match the exclude regex, but ``/usr/include/foo.h`` doesn't since it matches; the exclude regex. Controlling Debug Information; -----------------------------. Controlling Size of Debug Information; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Debug info kind generated by Clang can be set by one of the flags listed; below. If multiple flags are present, the last one is used. .. option:: -g0. Don't generate any debug info (default). .. option:: -gline-tables-only. Generate line number tables only. This kind of debug info allows to obtain stack traces with function names,; file names and line numbers (by such tools as ``gdb`` or ``addr2line``). It; doesn't contain any other data (e.g. description of local variables or; function parameters). .. option:: -fstandalone-debug. Clang supports a number of optimizations to reduce the size of debug; information in the binary. They work based on the assumption that; the debug type information can be spread out over multiple; compilation units. Specifically, the optimizations are:. - will not emit type definitions for types that are not needed by a; module and could be replaced with a forward declaration.; - will only emit type info for a dynamic C++ class in the module that; contains the vtable for the class.; - will only emit type info for a C++ class (non-trivial, non-aggregate); in the modules that contain a definition for one of its constructors.; - will only emit type definitions for types that are the subject of explicit; template instantiation declarations in the presence of an explicit; instantiation definition for the type. The **-fstandalone-debug** option turns off these optimizations.; This is useful when working with 3rd-party libraries that don't come; with debug information. Note that Clang will never emit type; information for types that are no",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:124977,optimiz,optimizations,124977,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimizations']
Performance," . TMVA. TMVA version 4.1.0 is included in this root release. The most; important new feature is the support for simulataneous classification ; of multiple output classes for several multi-variate methods. ; A lot of effort went into consolidation of the software,; i.e. method performance and robustness, and framework; stability. The changes with respect to ROOT 5.27 / TMVA 4.0.7 are; in detail:. Framework. Multi-class support. The support of multiple; output classes (i.e., more than a single background and signal; class) has been enabled for these methods: MLP (NN), BDTG,; FDA.; The multiclass; functionality can be enabled with the Factory option; ""AnalysisType=multiclass"". Training data is; specified with an additional classname, e.g. via; factory->AddTree(tree,""classname"");. After the; training a genetic algorithm is invoked to determine the best; cuts for selecting a specific class, based on the figure of; merit: purity*efficiency. TMVA comes with two examples in; $ROOTSYS/tmva/test: TMVAMulticlass.C; and TMVAMulticlassApplication.C. New TMVA event vector building. The code; for splitting the input data into training and test samples for; all classes and the mixing of those samples to one training and; one test sample has been rewritten completely. The new code is; more performant and has a clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:278,perform,performance,278,tmva/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html,1,['perform'],['performance']
Performance," . TMVA; ; This version corresponds to TMVA version 3.9.5.; ; . New; reference page for configuration options The; page is automatically generated for each new release. Next to; the classifiers also exist information links for hints to; improve the classifier performance (click on the ""i""; button). Many thanks to Zhiyi Liu (Fraser U) for suggesting; this.; ; Methods:. BDT: New Decision Tree Pruning algorithm: Cost; Complexity Pruning a la CART. Written by Doug Schouten; (Fraser U.). It replaces the old CostComplexity and; CostComplexity2 algorithms.; . BDT: New no splitting option (choosable with; NCuts<0) that finds best split point by first sorting the; events for each variable and then looping through all; events, placing the cuts always in the middle between two; of the sorted events, and finding the true possible; maximum separation gain in the training sample by cutting; on this variable.; . BDT, AdaBoost The beta parameter is now an; option (default is 1).; . BDT: The node purity at which a node is; classified as signal (respective background node) for; determining the error fraction in the pruning became a; parameter that can be set via the option NodePurityLimit; (default is 0.5).; . Dataset preparation:. First implementation of a new preprocessing method: transformation of the; variables first into a Gaussian distribution, then performing a decorrelation of; the ""Gaussianised"" variables. The transformation is again done by default such that; (by default) the signal distributions become Gaussian and are decorrelated. Note ; that simultaneous Gaussianisation and decorrelation of signal and background is ; only possible (and done) for methods, such as Likelihood, which test both hypotheses.; . Bug fixes:. Fix in Expected error pruning: Rather than multiplying both sides, the error on ; the node and the sub-tree, with the prune strength, now only the expected error ; of the sub-tree is scaled.; . Fix in FDA parsing of the input formula. There were problems when",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html:260,perform,performance,260,tmva/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html,1,['perform'],['performance']
Performance," .. code::. <bundle-entry-id> ::== <offload-kind> ""-"" <target-triple> [ ""-"" <target-id> ]. Where:. **offload-kind**; The runtime responsible for managing the bundled entry code object. See; :ref:`clang-offload-kind-table`. .. table:: Bundled Code Object Offload Kind; :name: clang-offload-kind-table. ============= ==============================================================; Offload Kind Description; ============= ==============================================================; host Host code object. ``clang-offload-bundler`` always includes; this entry as the first bundled code object entry. For an; embedded bundled code object this entry is not used by the; runtime and so is generally an empty code object. hip Offload code object for the HIP language. Used for all; HIP language offload code objects when the; ``clang-offload-bundler`` is used to bundle code objects as; intermediate steps of the tool chain. Also used for AMD GPU; code objects before ABI version V4 when the; ``clang-offload-bundler`` is used to create a *fat binary*; to be loaded by the HIP runtime. The fat binary can be; loaded directly from a file, or be embedded in the host code; object as a data section with the name ``.hip_fatbin``. hipv4 Offload code object for the HIP language. Used for AMD GPU; code objects with at least ABI version V4 when the; ``clang-offload-bundler`` is used to create a *fat binary*; to be loaded by the HIP runtime. The fat binary can be; loaded directly from a file, or be embedded in the host code; object as a data section with the name ``.hip_fatbin``. openmp Offload code object for the OpenMP language extension.; ============= ==============================================================. **target-triple**; The target triple of the code object. See `Target Triple; <https://clang.llvm.org/docs/CrossCompilation.html#target-triple>`_. The bundler accepts target triples with or without the optional environment; field:. ``<arch><sub>-<vendor>-<sys>``, or; ``<arch><sub>-<ven",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst:8746,load,loaded,8746,interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ClangOffloadBundler.rst,1,['load'],['loaded']
Performance," .. option:: --num-repetitions=<Number of repetitions>. Specify the target number of executed instructions. Note that the actual; repetition count of the snippet will be `num-repetitions`/`snippet size`.; Higher values lead to more accurate measurements but lengthen the benchmark. .. option:: --loop-body-size=<Preferred loop body size>. Only effective for `-repetition-mode=[loop|min]`.; Instead of looping over the snippet directly, first duplicate it so that the; loop body contains at least this many instructions. This potentially results; in loop body being cached in the CPU Op Cache / Loop Cache, which allows to; which may have higher throughput than the CPU decoders. .. option:: --max-configs-per-opcode=<value>. Specify the maximum configurations that can be generated for each opcode.; By default this is `1`, meaning that we assume that a single measurement is; enough to characterize an opcode. This might not be true of all instructions:; for example, the performance characteristics of the LEA instruction on X86; depends on the value of assigned registers and immediates. Setting a value of; `-max-configs-per-opcode` larger than `1` allows `llvm-exegesis` to explore; more configurations to discover if some register or immediate assignments; lead to different performance characteristics. .. option:: --benchmarks-file=</path/to/file>. File to read (`analysis` mode) or write (`latency`/`uops`/`inverse_throughput`; modes) benchmark results. ""-"" uses stdin/stdout. .. option:: --analysis-clusters-output-file=</path/to/file>. If provided, write the analysis clusters as CSV to this file. ""-"" prints to; stdout. By default, this analysis is not run. .. option:: --analysis-inconsistencies-output-file=</path/to/file>. If non-empty, write inconsistencies found during analysis to this file. `-`; prints to stdout. By default, this analysis is not run. .. option:: --analysis-filter=[all|reg-only|mem-only]. By default, all benchmark results are analysed, but sometimes it may be us",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:14133,perform,performance,14133,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,1,['perform'],['performance']
Performance," .. option:: -foptimization-record-file. Control the file to which optimization reports are written. This implies; :ref:`-fsave-optimization-record <opt_fsave-optimization-record>`. On Darwin platforms, this is incompatible with passing multiple; ``-arch <arch>`` options. .. option:: -foptimization-record-passes. Only include passes which match a specified regular expression. When optimization reports are being output (see; :ref:`-fsave-optimization-record <opt_fsave-optimization-record>`), this; option controls the passes that will be included in the final report. If this option is not used, all the passes are included in the optimization; record. .. _opt_fdiagnostics-show-hotness:. .. option:: -f[no-]diagnostics-show-hotness. Enable profile hotness information in diagnostic line. This option controls whether Clang prints the profile hotness associated; with diagnostics in the presence of profile-guided optimization information.; This is currently supported with optimization remarks (see; :ref:`Options to Emit Optimization Reports <rpass>`). The hotness information; allows users to focus on the hot optimization remarks that are likely to be; more relevant for run-time performance. For example, in this output, the block containing the callsite of `foo` was; executed 3000 times according to the profile data:. ::. s.c:7:10: remark: foo inlined into bar (hotness: 3000) [-Rpass-analysis=inline]; sum += foo(x, x - 2);; ^. This option is implied when; :ref:`-fsave-optimization-record <opt_fsave-optimization-record>` is used.; Otherwise, it defaults to off. .. option:: -fdiagnostics-hotness-threshold. Prevent optimization remarks from being output if they do not have at least; this hotness value. This option, which defaults to zero, controls the minimum hotness an; optimization remark would need in order to be output by Clang. This is; currently supported with optimization remarks (see :ref:`Options to Emit; Optimization Reports <rpass>`) when profile hotness information in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:14052,optimiz,optimization,14052,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimization']
Performance," .. option:: -mcpu=<cpuname>. Specify a specific chip in the current architecture to generate code for.; By default this is inferred from the target triple and autodetected to; the current architecture. For a list of available CPUs, use:. .. code-block:: none. llvm-as < /dev/null | llc -march=xyz -mcpu=help. .. option:: -filetype=<output file type>. Specify what kind of output ``llc`` should generated. Options are: ``asm``; for textual assembly ( ``'.s'``), ``obj`` for native object files (``'.o'``); and ``null`` for not emitting anything (for performance testing). Note that not all targets support all options. .. option:: -mattr=a1,+a2,-a3,... Override or control specific attributes of the target, such as whether SIMD; operations are enabled or not. The default set of attributes is set by the; current CPU. For a list of available attributes, use:. .. code-block:: none. llvm-as < /dev/null | llc -march=xyz -mattr=help. .. option:: --frame-pointer. Specify effect of frame pointer elimination optimization (all,non-leaf,none). .. option:: --disable-excess-fp-precision. Disable optimizations that may produce excess precision for floating point.; Note that this option can dramatically slow down code on some systems; (e.g. X86). .. option:: --enable-no-infs-fp-math. Enable optimizations that assume no Inf values. .. option:: --enable-no-nans-fp-math. Enable optimizations that assume no NAN values. .. option:: --enable-no-signed-zeros-fp-math. Enable FP math optimizations that assume the sign of 0 is insignificant. .. option:: --enable-no-trapping-fp-math. Enable setting the FP exceptions build attribute not to use exceptions. .. option:: --enable-unsafe-fp-math. Enable optimizations that make unsafe assumptions about IEEE math (e.g. that; addition is associative) or may not work for all input ranges. These; optimizations allow the code generator to make use of some instructions which; would otherwise not be usable (such as ``fsin`` on X86). .. option:: --stats. Print stat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst:3154,optimiz,optimization,3154,interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst,1,['optimiz'],['optimization']
Performance," // (if possible) and add again; if (reqSections != TBuffer3D::kNone); shape.GetBuffer3D(reqSections, localFrame);; ```. Together these allow clients to publish objects to any one of the 3D; viewers free of viewer specific drawing code. They allow our simple x3d; viewer, and considerably more sophisticated OpenGL one to both work with; both geometry libraries (`g3d` and `geom`) efficiently. In addition to external viewers, created in separate windows, this; architecture is also used by internal **`TPad`** drawing when it; requires 3D projections. Publishing to a viewer consists of the; following steps:. 1- Create / obtain viewer handle. 2- Begin scene on viewer. 3- Fill mandatory parts of TBuffer3D describing object. 4- Add to viewer. 5- Fill optional parts of TBuffer3D as requested by viewer. [ .... repeat 3/4/5 as required for other/child objects]. 6- End scene on viewer. You should attach the top-level node of your external geometry (or the; manager) to a **`TPad`** object using **`TObject::Draw()`, and perform; the publishing to the viewer in your object's `TObject::Paint()`; overloaded method. See ""Scene Rebuilds"", and example scripts, for more; details.**. #### Creating / Obtaining Viewer Handle. External viewers are bound to a **`TPad`** object (this may be removed; as a requirement in the future). You can create or obtain the current; viewer handle via the method:. ``` {.cpp}; TVirtualViewer3D * v = gPad->GetViewer3D(""type"");; ```. Here the ""type"" string defines the viewer type - currently one of:. - ""`ogl`"" : External GL viewer. - ""`x3d`"": External X3D viewer. - ""`pad`"": Pad viewer. If no type is passed (null string), and there is no current viewer, then; the type is defaulted to ""`pad`"". If no type is passed and there is a; current viewer, then this is returned - hence once a viewer is created; it can be obtained elsewhere by:. ``` {.cpp}; TVirtualViewer3D * v = gPad->GetViewer3D();; ```. #### Opening / Closing Scenes. Objects must be added to viewer betwee",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:124545,perform,perform,124545,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['perform'],['perform']
Performance," // error - bitfields are not supported; };. ``__cl_clang_function_pointers``; --------------------------------. With this extension it is possible to enable various language features that; are relying on function pointers using regular OpenCL extension pragma; mechanism detailed in `the OpenCL Extension Specification,; section 1.2; <https://www.khronos.org/registry/OpenCL/specs/3.0-unified/html/OpenCL_Ext.html#extensions-overview>`_. In C++ for OpenCL this also enables:. - Use of member function pointers;. - Unrestricted use of references to functions;. - Virtual member functions. Such functionality is not conformant and does not guarantee to compile; correctly in any circumstances. It can be used if:. - the kernel source does not contain call expressions to (member-) function; pointers, or virtual functions. For example this extension can be used in; metaprogramming algorithms to be able to specify/detect types generically. - the generated kernel binary does not contain indirect calls because they; are eliminated using compiler optimizations e.g. devirtualization. - the selected target supports the function pointer like functionality e.g.; most CPU targets. **Example of Use**:. .. code-block:: c++. #pragma OPENCL EXTENSION __cl_clang_function_pointers : enable; void foo(); {; void (*fp)(); // compiled - no diagnostic generated; }. #pragma OPENCL EXTENSION __cl_clang_function_pointers : disable; void bar(); {; void (*fp)(); // error - pointers to function are not allowed; }. ``__cl_clang_variadic_functions``; ---------------------------------. With this extension it is possible to enable variadic arguments in functions; using regular OpenCL extension pragma mechanism detailed in `the OpenCL; Extension Specification, section 1.2; <https://www.khronos.org/registry/OpenCL/specs/3.0-unified/html/OpenCL_Ext.html#extensions-overview>`_. This is not conformant behavior and it can only be used portably when the; functions with variadic prototypes do not get generated in bin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:87556,optimiz,optimizations,87556,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['optimiz'],['optimizations']
Performance," /// Sets a callback to be invoked on calls to `write`. The callback is invoked; /// before the write is done. The write is not guaranteed to succeed when the; /// callback executes. Pass in NULL to remove any callback.; typedef void (*dfsan_write_callback_t)(int fd, const void *buf, size_t count);; void dfsan_set_write_callback(dfsan_write_callback_t labeled_write_callback);. /// Callbacks to be invoked on calls to `memcmp` or `strncmp`.; void dfsan_weak_hook_memcmp(void *caller_pc, const void *s1, const void *s2,; size_t n, dfsan_label s1_label,; dfsan_label s2_label, dfsan_label n_label);; void dfsan_weak_hook_strncmp(void *caller_pc, const char *s1, const char *s2,; size_t n, dfsan_label s1_label,; dfsan_label s2_label, dfsan_label n_label);. Taint label representation; --------------------------. We use an 8-bit unsigned integer for the representation of a; label. The label identifier 0 is special, and means that the data item; is unlabelled. This is optimizing for low CPU and code size overhead; of the instrumentation. When a label union operation is requested at a; join point (any arithmetic or logical operation with two or more; operands, such as addition), we can simply OR the two labels in O(1). Users are responsible for managing the 8 integer labels (i.e., keeping; track of what labels they have used so far, picking one that is yet; unused, etc). Origin tracking trace representation; ------------------------------------. An origin tracking trace is a list of chains. Each chain has a stack trace; where the DFSan runtime records a label propagation, and a pointer to its; previous chain. The very first chain does not point to any chain. Every four 4-bytes aligned application bytes share a 4-byte origin trace ID. A; 4-byte origin trace ID contains a 4-bit depth and a 28-bit hash ID of a chain. A chain ID is calculated as a hash from a chain structure. A chain structure; contains a stack ID and the previous chain ID. The chain head has a zero; previous chain ID",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst:5705,optimiz,optimizing,5705,interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowSanitizerDesign.rst,1,['optimiz'],['optimizing']
Performance," 0.0), 2.0). Since we know that x+2.0 doesn't care about the sign of any zeros in X, we can; transform the fmul to 0.0, and then the fadd to 2.0. //===---------------------------------------------------------------------===//. We should enhance memcpy/memcpy/memset to allow a metadata node on them; indicating that some bytes of the transfer are undefined. This is useful for; frontends like clang when lowering struct copies, when some elements of the; struct are undefined. Consider something like this:. struct x {; char a;; int b[4];; };; void foo(struct x*P);; struct x testfunc() {; struct x V1, V2;; foo(&V1);; V2 = V1;. return V2;; }. We currently compile this to:; $ clang t.c -S -o - -O0 -emit-llvm | opt -sroa -S. %struct.x = type { i8, [4 x i32] }. define void @testfunc(%struct.x* sret %agg.result) nounwind ssp {; entry:; %V1 = alloca %struct.x, align 4; call void @foo(%struct.x* %V1); %tmp1 = bitcast %struct.x* %V1 to i8*; %0 = bitcast %struct.x* %V1 to i160*; %srcval1 = load i160* %0, align 4; %tmp2 = bitcast %struct.x* %agg.result to i8*; %1 = bitcast %struct.x* %agg.result to i160*; store i160 %srcval1, i160* %1, align 4; ret void; }. This happens because SRoA sees that the temp alloca has is being memcpy'd into; and out of and it has holes and it has to be conservative. If we knew about the; holes, then this could be much much better. Having information about these holes would also improve memcpy (etc) lowering at; llc time when it gets inlined, because we can use smaller transfers. This also; avoids partial register stalls in some important cases. //===---------------------------------------------------------------------===//. We don't fold (icmp (add) (add)) unless the two adds only have a single use.; There are a lot of cases that we're refusing to fold in (e.g.) 256.bzip2, for; example:. %indvar.next90 = add i64 %indvar89, 1 ;; Has 2 uses; %tmp96 = add i64 %tmp95, 1 ;; Has 1 use; %exitcond97 = icmp eq i64 %indvar.next90, %tmp96. We don't fold this becaus",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:62876,load,load,62876,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,1,['load'],['load']
Performance," 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vm/vscnt(0). - If CU wavefront execution; mode, omit.; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than the; atomicrmw value; being acquired. 4. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store ato",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:363975,perform,performing,363975,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance," 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures any; following global; data read is no; older than the; atomicrmw value; being acquired. 4. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being rele",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:267515,load,loads,267515,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," 1.4.10; -------------------. * Imported several FindCppyy.cmake improvements from Camille's cppyy-bbhash; * Fixes to cppyy-generator for unresolved templates, void, etc.; * Fixes in typedef parsing for template arguments in unknown namespaces; * Fix in templated operator code generation; * Fixed ref-counting error for instantiated template methods. 2019-04-25 : 1.4.9; ------------------. * Fix import error on pypy-c. 2019-04-22 : 1.4.8; ------------------. * ``std::tuple`` is now iterable for return assignments w/o tie; * Support for opaque handles and typedefs of pointers to classes; * Keep unresolved enums desugared and provide generic converters; * Treat int8_t and uint8_t as integers (even when they are chars); * Fix lookup of enum values in global namespace; * Backported name mangling (esp. for static/global data lookup) for 32b Windows; * Fixed more linker problems with malloc on 64b Windows; * Consistency in buffer length calculations and c_int/c_uint handling on Windows; * Properly resolve overloaded functions with using of templates from bases; * Get templated constructor info from decl instead of name comparison; * Fixed a performance regression for free functions. 2019-04-04 : 1.4.7; ------------------. * Enable initializer_list conversion on Windows as well; * Improved mapping of operator() for indexing (e.g. for matrices); * Implicit conversion no longer uses global state to prevent recursion; * Improved overload reordering; * Fixes for templated constructors in namespaces. 2019-04-02 : 1.4.6; ------------------. * More transparent use of smart pointers such as shared_ptr; * Expose versioned std namespace through using on Mac; * Improved error handling and interface checking in cross-inheritance; * Argument of (const/non-const) ref types support in callbacks/cross-inheritance; * Do template argument resolution in order: reference, pointer, value; * Fix for return type deduction of resolved but uninstantiated templates; * Fix wrapper generation for defau",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:20595,perform,performance,20595,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,1,['perform'],['performance']
Performance," 10.59s +/- 0.05 (700 entries) ; cms3.root Y 0.717 Gb 8.29s +/- 0.08 (700 entries) ; cms5.root N 1.55 Gb 10.20s +/- 0.17 (700 entries) ; cms5.root Y 1.40 Gb 8.09s +/- 0.08 (700 entries) . In the case of a data member which is a pointer to a STL container, eg:; std::container<Data> *fDataObjects;; and which is stored member-wise, add support for the schema evolution of the class 'Data'. This requires a change in the on file format used to store this type; of data members (i.e. by adding inline the version number of the class; 'Data'). To read file containing this construct and written with this revision; using an older version of ROOT you will need the following patches:; For v5.22/00, you will need the patch r33174; or v5.22/00k; For v5.26/00, you will need patch r33176; or v5.26/00c. Additionally, we no longer allow the member wise streaming of a class which; has a custom streamer nor of any data members marked with //||. Run time performance. We introduced an optimized infrastructure for reading objects using a StreamerInfo. Rather than driving the streaming using a switch statement inside TStreamerInfo::ReadBuffer,; the streaming is now driven using a simple loop over a sequence of configured StreamerInfo actions. This improves run-time performance by allowing a dramatic reduction in function calls and code; branches at the expense of some code duplication. There are 3 versions of this loop implemented in TBufferFile and overloaded in TBufferXML and TBufferSQL:. virtual Int_t ReadSequence(const TStreamerInfoActions::TActionSequence &sequence, void *object);; virtual Int_t ReadSequence(const TStreamerInfoActions::TActionSequence &sequence,; void *start_collection, void *end_collection);; virtual Int_t ReadSequence(const TStreamerInfoActions::TActionSequence &sequence,; void *start_collection, void *end_collection);. The 1st version is optimized to read a single object. The 2nd version is optimized to read the content of TClonesArrays and vectors of pointers to obj",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html:2855,optimiz,optimized,2855,io/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html,1,['optimiz'],['optimized']
Performance," 2 64-bit address of amd_queue_t; (enable_sgpr_queue_ptr) object for AQL queue on which; the dispatch packet was; queued.; then Kernarg Segment Ptr 2 64-bit address of Kernarg; (enable_sgpr_kernarg segment. This is directly; _segment_ptr) copied from the; kernarg_address in the kernel; dispatch packet. Having CP load it once avoids; loading it at the beginning of; every wavefront.; then Dispatch Id 2 64-bit Dispatch ID of the; (enable_sgpr_dispatch_id) dispatch packet being; executed.; then Flat Scratch Init 2 See; (enable_sgpr_flat_scratch :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`.; _init); then Preloaded Kernargs N/A See; (kernarg_preload_spec :ref:`amdgpu-amdhsa-kernarg-preload`.; _length); then Private Segment Size 1 The 32-bit byte size of a; (enable_sgpr_private single work-item's memory; _segment_size) allocation. This is the; value from the kernel; dispatch packet Private; Segment Byte Size rounded up; by CP to a multiple of; DWORD. Having CP load it once avoids; loading it at the beginning of; every wavefront. This is not used for; GFX7-GFX8 since it is the same; value as the second SGPR of; Flat Scratch Init. However, it; may be needed for GFX9-GFX11 which; changes the meaning of the; Flat Scratch Init value.; then Work-Group Id X 1 32-bit work-group id in X; (enable_sgpr_workgroup_id dimension of grid for; _X) wavefront.; then Work-Group Id Y 1 32-bit work-group id in Y; (enable_sgpr_workgroup_id dimension of grid for; _Y) wavefront.; then Work-Group Id Z 1 32-bit work-group id in Z; (enable_sgpr_workgroup_id dimension of grid for; _Z) wavefront.; then Work-Group Info 1 {first_wavefront, 14'b0000,; (enable_sgpr_workgroup ordered_append_term[10:0],; _info) threadgroup_size_in_wavefronts[5:0]}; then Scratch Wavefront Offset 1 See; (enable_sgpr_private :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`.; _segment_wavefront_offset) and; :ref:`amdgpu-amdhsa-kernel-prolog-private-segment-buffer`.; ========== ========================== ====== ================",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:185512,load,load,185512,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],"['load', 'loading']"
Performance," 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local; atomicrmw value; being acquired. atomicrmw acquire - workgroup - generic 1. flat_atomic; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:250636,cache,cache,250636,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," 5. ``DW_OP_LLVM_call_frame_entry_reg`` *New*. ``DW_OP_LLVM_call_frame_entry_reg`` has a single unsigned LEB128 integer; operand that represents a target architecture register number R. It pushes a location description L that holds the value of register R on; entry to the current subprogram as defined by the call frame information; (see :ref:`amdgpu-dwarf-call-frame-information`). *If there is no call frame information defined, then the default rules for; the target architecture are used. If the register rule is* undefined\ *, then; the undefined location description is pushed. If the register rule is* same; value\ *, then a register location description for R is pushed.*. .. _amdgpu-dwarf-undefined-location-description-operations:. A.2.5.4.4.2 Undefined Location Description Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces DWARF Version 5 section 2.6.1.1.1. *The undefined location storage represents a piece or all of an object that is; present in the source but not in the object code (perhaps due to optimization).; Neither reading nor writing to the undefined location storage is meaningful.*. An undefined location description specifies the undefined location storage.; There is no concept of the size of the undefined location storage, nor of a bit; offset for an undefined location description. The ``DW_OP_LLVM_*offset``; operations leave an undefined location description unchanged. The; ``DW_OP_*piece`` operations can explicitly or implicitly specify an undefined; location description, allowing any size and offset to be specified, and results; in a part with all undefined bits. 1. ``DW_OP_LLVM_undefined`` *New*. ``DW_OP_LLVM_undefined`` pushes a location description L that comprises one; undefined location description SL. .. _amdgpu-dwarf-memory-location-description-operations:. A.2.5.4.4.3 Memory Location Description Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces par",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:103202,optimiz,optimization,103202,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['optimiz'],['optimization']
Performance," 8.20s +/- 0.05 (1000 entries) ; cms3.root N 0.780 Gb 10.59s +/- 0.05 (700 entries) ; cms3.root Y 0.717 Gb 8.29s +/- 0.08 (700 entries) ; cms5.root N 1.55 Gb 10.20s +/- 0.17 (700 entries) ; cms5.root Y 1.40 Gb 8.09s +/- 0.08 (700 entries) . In the case of a data member which is a pointer to a STL container, eg:; std::container<Data> *fDataObjects;; and which is stored member-wise, add support for the schema evolution of the class 'Data'. This requires a change in the on file format used to store this type; of data members (i.e. by adding inline the version number of the class; 'Data'). To read file containing this construct and written with this revision; using an older version of ROOT you will need the following patches:; For v5.22/00, you will need the patch r33174; or v5.22/00k; For v5.26/00, you will need patch r33176; or v5.26/00c. Additionally, we no longer allow the member wise streaming of a class which; has a custom streamer nor of any data members marked with //||. Run time performance. We introduced an optimized infrastructure for reading objects using a StreamerInfo. Rather than driving the streaming using a switch statement inside TStreamerInfo::ReadBuffer,; the streaming is now driven using a simple loop over a sequence of configured StreamerInfo actions. This improves run-time performance by allowing a dramatic reduction in function calls and code; branches at the expense of some code duplication. There are 3 versions of this loop implemented in TBufferFile and overloaded in TBufferXML and TBufferSQL:. virtual Int_t ReadSequence(const TStreamerInfoActions::TActionSequence &sequence, void *object);; virtual Int_t ReadSequence(const TStreamerInfoActions::TActionSequence &sequence,; void *start_collection, void *end_collection);; virtual Int_t ReadSequence(const TStreamerInfoActions::TActionSequence &sequence,; void *start_collection, void *end_collection);. The 1st version is optimized to read a single object. The 2nd version is optimized to read the co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html:2825,perform,performance,2825,io/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html,1,['perform'],['performance']
Performance," ; CHECK-LABEL: D_ctor_base:. The use of ``CHECK-LABEL:`` directives in this case ensures that the three; ``CHECK:`` directives only accept lines corresponding to the body of the; ``@C_ctor_base`` function, even if the patterns match lines found later in; the file. Furthermore, if one of these three ``CHECK:`` directives fail,; FileCheck will recover by continuing to the next block, allowing multiple test; failures to be detected in a single invocation. There is no requirement that ``CHECK-LABEL:`` directives contain strings that; correspond to actual syntactic labels in a source or output language: they must; simply uniquely match a single line in the file being verified. ``CHECK-LABEL:`` directives cannot contain variable definitions or uses. Directive modifiers; ~~~~~~~~~~~~~~~~~~~. A directive modifier can be append to a directive by following the directive; with ``{<modifier>}`` where the only supported value for ``<modifier>`` is; ``LITERAL``. The ``LITERAL`` directive modifier can be used to perform a literal match. The; modifier results in the directive not recognizing any syntax to perform regex; matching, variable capture or any substitutions. This is useful when the text; to match would require excessive escaping otherwise. For example, the; following will perform literal matches rather than considering these as; regular expressions:. .. code-block:: text. Input: [[[10, 20]], [[30, 40]]]; Output %r10: [[10, 20]]; Output %r10: [[30, 40]]. ; CHECK{LITERAL}: [[[10, 20]], [[30, 40]]]; ; CHECK-DAG{LITERAL}: [[30, 40]]; ; CHECK-DAG{LITERAL}: [[10, 20]]. FileCheck Regex Matching Syntax; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. All FileCheck directives take a pattern to match.; For most uses of FileCheck, fixed string matching is perfectly sufficient. For; some things, a more flexible form of matching is desired. To support this,; FileCheck allows you to specify regular expressions in matching strings,; surrounded by double braces: ``{{yourregex}}``. FileCheck implements ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst:23976,perform,perform,23976,interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,1,['perform'],['perform']
Performance," ; variables in SSA form, as opposed to having a two dimensional namespace; of the original variable and the SSA instance subscript. ARGUMENT AGAINST:; * A two dimensional namespace would be valuable when doing alias ; analysis because the extra information can help limit the scope of; analysis. ARGUMENT FOR:; * Including this information would require that all users of the LLVM; bytecode would have to parse and handle it. This would slow down the; common case and inflate the instruction representation with another; infinite variable space. REASONING:; * It was decided that because original variable sources could be; reconstructed from SSA form in linear time, that it would be an; unjustified expense for the common case to include the extra; information for one optimization. Alias analysis itself is typically; greater than linear in asymptotic complexity, so this extra analaysis; would not affect the runtime of the optimization in a significant; way. Additionally, this would be an unlikely optimization to do at; runtime. IDEAS TO CONSIDER; -----------------. 1. Including dominator information in the LLVM bytecode; representation. This is one example of an analysis result that may be; packaged with the bytecodes themselves. As a conceptual implementation ; idea, we could include an immediate dominator number for each basic block; in the LLVM bytecode program. Basic blocks could be numbered according; to the order of occurrence in the bytecode representation. 2. Including loop header and body information. This would facilitate; detection of intervals and natural loops. UNRESOLVED ISSUES ; ----------------- . 1. Will oSUIF provide enough of an infrastructure to support the research; that we will be doing? We know that it has less than stellar; performance, but hope that this will be of little importance for our; static compiler. This could affect us if we decided to do some IP; research. Also we do not yet understand the level of exception support; currently implemente",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-12-06-MeetingSummary.txt:1198,optimiz,optimization,1198,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-12-06-MeetingSummary.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-12-06-MeetingSummary.txt,1,['optimiz'],['optimization']
Performance," ; yields i32:result = 2; <result> = lshr i32 4, 2 ; yields i32:result = 1; <result> = lshr i8 4, 3 ; yields i8:result = 0; <result> = lshr i8 -2, 1 ; yields i8:result = 0x7F; <result> = lshr i32 1, 32 ; undefined; <result> = lshr <2 x i32> < i32 -2, i32 4>, < i32 1, i32 2> ; yields: result=<2 x i32> < i32 0x7FFFFFFF, i32 1>. .. _i_ashr:. '``ashr``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = ashr <ty> <op1>, <op2> ; yields ty:result; <result> = ashr exact <ty> <op1>, <op2> ; yields ty:result. Overview:; """""""""""""""""". The '``ashr``' instruction (arithmetic shift right) returns the first; operand shifted to the right a specified number of bits with sign; extension. Arguments:; """""""""""""""""""". Both arguments to the '``ashr``' instruction must be the same; :ref:`integer <t_integer>` or :ref:`vector <t_vector>` of integer type.; '``op2``' is treated as an unsigned value. Semantics:; """""""""""""""""""". This instruction always performs an arithmetic shift right operation,; The most significant bits of the result will be filled with the sign bit; of ``op1``. If ``op2`` is (statically or dynamically) equal to or larger; than the number of bits in ``op1``, this instruction returns a :ref:`poison; value <poisonvalues>`. If the arguments are vectors, each vector element; of ``op1`` is shifted by the corresponding shift amount in ``op2``. If the ``exact`` keyword is present, the result value of the ``ashr`` is; a poison value if any of the bits shifted out are non-zero. Example:; """""""""""""""". .. code-block:: text. <result> = ashr i32 4, 1 ; yields i32:result = 2; <result> = ashr i32 4, 2 ; yields i32:result = 1; <result> = ashr i8 4, 3 ; yields i8:result = 0; <result> = ashr i8 -2, 1 ; yields i8:result = -1; <result> = ashr i32 1, 32 ; undefined; <result> = ashr <2 x i32> < i32 -2, i32 4>, < i32 1, i32 3> ; yields: result=<2 x i32> < i32 -1, i32 0>. .. _i_and:. '``and``' Instruction; ^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = and <ty> <op1>, <op2> ; yields ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:396139,perform,performs,396139,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," ;. splits parameter m in the product of states of c and d. Another possibility; is the 'constrained' split which clones the parameter for all but one state; and insert a formula specialization in a chosen state that evaluates; to 1 - sum_i(a_i) where a_i are all other specializations. For example,; given a category c with state ""A"",""B"",""C"",""D"" the specification. SplitParamConstrained(""m"",""c"",""D""). will result in parameters m_A,m_B,m_C and a formula expression m_D; that evaluates to (1-(m_A+m_B+m_C)). Constrained split can also be; specified in product of categories. In that case the name of the; remainder state follows the syntax {State1;State2} where State1; and State2 are the state names of the two spitting categories. Additional; functionality exists to work with multiple prototype p.d.f.s simultaneously. ; Improved infrastructure for caching p.d.f and functions. The infrastructure that exists for caching p.d.f.s, i.e. p.d.f that precalculate their value; for all observable values at one and cache those in a histogram that is returned as p.d.f shape; (with optional interpolation), has been expanded. This infrastructure comprises RooAbsCached; the base class for all caching p.d.fs, RooAbsSelfCachedPdf a base class for end-user; caching p.d.f implementations that simply cache the result of evaluate() and RooCachedPdf; that can wrap and cache any input p.d.f specified in its constructor. . By default a p.d.f is sampled and cached in all observables in any; given use context, with no need to specify what those are in advance.; The internal code has also been changed such that all cache; histograms now store pre-normalized p.d.f, which is more efficient; than 'raw' p.d.f histograms that are explicitly post-normalized; through integration. Multiple different use cases (e.g. definitions; of what are observables vs parameters) can be cached; simultaneously. Now it is also possible to specify that p.d.f.s; should be sampled and cached in one or more parameter dimensions; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:13642,cache,cache,13642,roofit/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html,1,['cache'],['cache']
Performance," <4 x i32> %t, <4 x i32> poison. '``llvm.vp.is.fpclass.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <vscale x 2 x i1> @llvm.vp.is.fpclass.nxv2f32(<vscale x 2 x float> <op>, i32 <test>, <vscale x 2 x i1> <mask>, i32 <vector_length>); declare <2 x i1> @llvm.vp.is.fpclass.v2f16(<2 x half> <op>, i32 <test>, <2 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated llvm.is.fpclass :ref:`llvm.is.fpclass <llvm.is.fpclass>`. Arguments:; """""""""""""""""""". The first operand is a floating-point vector, the result type is a vector of; boolean with the same number of elements as the first argument. The second; operand specifies, which tests to perform :ref:`llvm.is.fpclass <llvm.is.fpclass>`.; The third operand is the vector mask and has the same number of elements as the; result vector type. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.is.fpclass``' intrinsic performs llvm.is.fpclass (:ref:`llvm.is.fpclass <llvm.is.fpclass>`). Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <2 x i1> @llvm.vp.is.fpclass.v2f16(<2 x half> %x, i32 3, <2 x i1> %m, i32 %evl); %t = call <vscale x 2 x i1> @llvm.vp.is.fpclass.nxv2f16(<vscale x 2 x half> %x, i32 3, <vscale x 2 x i1> %m, i32 %evl). .. _int_mload_mstore:. Masked Vector Load and Store Intrinsics; ---------------------------------------. LLVM provides intrinsics for predicated vector load and store operations. The predicate is specified by a mask operand, which holds one bit per vector element, switching the associated vector lane on or off. The memory addresses corresponding to the ""off"" lanes are not accessed. When all bits of the mask are on, the intrinsic is identical to a regular vector load or store. When all bits are off, no memory is accessed. .. _int_mload:. '``llvm.masked.load.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. The l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:842263,perform,performs,842263,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," <4 x i32> @llvm.bswap.v4i32(<4 x i32> %a); %also.r = select <4 x i1> %mask, <4 x i32> %t, <4 x i32> poison. .. _int_vp_ctpop:. '``llvm.vp.ctpop.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x i32> @llvm.vp.ctpop.v16i32 (<16 x i32> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x i32> @llvm.vp.ctpop.nxv4i32 (<vscale x 4 x i32> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x i64> @llvm.vp.ctpop.v256i64 (<256 x i64> <op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated ctpop of a vector of integers. Arguments:; """""""""""""""""""". The first operand and the result have the same vector of integer type. The; second operand is the vector mask and has the same number of elements as the; result vector type. The third operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.ctpop``' intrinsic performs ctpop (:ref:`ctpop <int_ctpop>`) of the first operand on each; enabled lane. The result on disabled lanes is a :ref:`poison value <poisonvalues>`. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x i32> @llvm.vp.ctpop.v4i32(<4 x i32> %a, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x i32> @llvm.ctpop.v4i32(<4 x i32> %a); %also.r = select <4 x i1> %mask, <4 x i32> %t, <4 x i32> poison. .. _int_vp_ctlz:. '``llvm.vp.ctlz.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x i32> @llvm.vp.ctlz.v16i32 (<16 x i32> <op>, <16 x i1> <mask>, i32 <vector_length>, i1 <is_zero_poison>); declare <vscale x 4 x i32> @llvm.vp.ctlz.nxv4i32 (<vscale x 4 x i32> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>, i1 <is_zero_poison>); declare <256 x i64> @llvm.vp.ctlz.v256i64 (<256 x i64> <op>, <256 x i1> <mask>, i32 <vector_length>, i1 <is_zero_poison>). Overview:; """""""""""""""""". Predicated ctl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:834886,perform,performs,834886,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," <i32> [#uses=2]; 	%tmp9 = add i32 %x.0.0, 1		; <i32> [#uses=2]; 	%tmp = icmp sgt i32 %tmp9, 39		; <i1> [#uses=1]; 	br i1 %tmp, label %bb12, label %cond_true. bb12:		; preds = %cond_true; 	ret i32 %tmp7; }; is pessimized by -loop-reduce and -indvars. //===---------------------------------------------------------------------===//. u32 to float conversion improvement:. float uint32_2_float( unsigned u ) {; float fl = (int) (u & 0xffff);; float fh = (int) (u >> 16);; fh *= 0x1.0p16f;; return fh + fl;; }. 00000000 subl $0x04,%esp; 00000003 movl 0x08(%esp,1),%eax; 00000007 movl %eax,%ecx; 00000009 shrl $0x10,%ecx; 0000000c cvtsi2ss %ecx,%xmm0; 00000010 andl $0x0000ffff,%eax; 00000015 cvtsi2ss %eax,%xmm1; 00000019 mulss 0x00000078,%xmm0; 00000021 addss %xmm1,%xmm0; 00000025 movss %xmm0,(%esp,1); 0000002a flds (%esp,1); 0000002d addl $0x04,%esp; 00000030 ret. //===---------------------------------------------------------------------===//. When using fastcc abi, align stack slot of argument of type double on 8 byte; boundary to improve performance. //===---------------------------------------------------------------------===//. GCC's ix86_expand_int_movcc function (in i386.c) has a ton of interesting; simplifications for integer ""x cmp y ? a : b"". //===---------------------------------------------------------------------===//. Consider the expansion of:. define i32 @test3(i32 %X) {; %tmp1 = urem i32 %X, 255; ret i32 %tmp1; }. Currently it compiles to:. ...; movl $2155905153, %ecx; movl 8(%esp), %esi; movl %esi, %eax; mull %ecx; ... This could be ""reassociated"" into:. movl $2155905153, %eax; movl 8(%esp), %ecx; mull %ecx. to avoid the copy. In fact, the existing two-address stuff would do this; except that mul isn't a commutative 2-addr instruction. I guess this has; to be done at isel time based on the #uses to mul?. //===---------------------------------------------------------------------===//. Make sure the instruction which starts a loop does not cross a cacheline; bound",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:9581,perform,performance,9581,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,1,['perform'],['performance']
Performance," <val>, i64 <expected_val>, double <prob>). Overview:; """""""""""""""""". The ``llvm.expect.with.probability`` intrinsic provides information about; expected value of ``val`` with probability(or confidence) ``prob``, which can; be used by optimizers. Arguments:; """""""""""""""""""". The ``llvm.expect.with.probability`` intrinsic takes three arguments. The first; argument is a value. The second argument is an expected value. The third; argument is a probability. Semantics:; """""""""""""""""""". This intrinsic is lowered to the ``val``. .. _int_assume:. '``llvm.assume``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.assume(i1 %cond). Overview:; """""""""""""""""". The ``llvm.assume`` allows the optimizer to assume that the provided; condition is true. This information can then be used in simplifying other parts; of the code. More complex assumptions can be encoded as; :ref:`assume operand bundles <assume_opbundles>`. Arguments:; """""""""""""""""""". The argument of the call is the condition which the optimizer may assume is; always true. Semantics:; """""""""""""""""""". The intrinsic allows the optimizer to assume that the provided condition is; always true whenever the control flow reaches the intrinsic call. No code is; generated for this intrinsic, and instructions that contribute only to the; provided condition are not used for code generation. If the condition is; violated during execution, the behavior is undefined. Note that the optimizer might limit the transformations performed on values; used by the ``llvm.assume`` intrinsic in order to preserve the instructions; only used to form the intrinsic's input argument. This might prove undesirable; if the extra information provided by the ``llvm.assume`` intrinsic does not cause; sufficient overall improvement in code quality. For this reason,; ``llvm.assume`` should not be used to document basic mathematical invariants; that the optimizer can otherwise deduce or facts that are of little use to the; optimizer. .. _int_ssa_copy:. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:935512,optimiz,optimizer,935512,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizer']
Performance," <vscale x 4 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". The '``llvm.vp.zext``' intrinsic zero extends its first operand to the return; type. The operation has a mask and an explicit vector length parameter. Arguments:; """""""""""""""""""". The '``llvm.vp.zext``' intrinsic takes a value to cast as its first operand.; The return type is the type to cast the value to. Both types must be vectors of; :ref:`integer <t_integer>` type. The bit size of the value must be smaller than; the bit size of the return type. The second operand is the vector mask. The; return type, the value to cast, and the vector mask have the same number of; elements. The third operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.zext``' intrinsic fill the high order bits of the value with zero; bits until it reaches the size of the return type. When zero extending from i1,; the result will always be either 0 or 1. The conversion is performed on lane; positions below the explicit vector length and where the vector mask is true.; Masked-off lanes are ``poison``. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x i32> @llvm.vp.zext.v4i32.v4i16(<4 x i16> %a, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = zext <4 x i16> %a to <4 x i32>; %also.r = select <4 x i1> %mask, <4 x i32> %t, <4 x i32> poison. .. _int_vp_sext:. '``llvm.vp.sext.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x i32> @llvm.vp.sext.v16i32.v16i16 (<16 x i16> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x i32> @llvm.vp.sext.nxv4i32.nxv4i16 (<vscale x 4 x i16> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". The '``llvm.vp.sext``' intrinsic sign extends its first operand to the return; type. The operation has a mask and an explicit vector length parameter. Arguments:; """""""""""""""""""". The '``llvm.vp.sext``' intrinsi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:798843,perform,performed,798843,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance," = Int_t(fChain->GetEntries());; TH1F *myHisto = new TH1F(""myHisto"",""fPx"", 100, -5,5);; TH1F *smallHisto = new TH1F(""small"",""fPx"", 100, -5,5);; ...; ```. In the for-loop, we need to add another for-loop to go over all the; tracks. In the outer for-loop, we get the entry and the number of; tracks. In the inner for-loop, we fill the large histogram (`myHisto`); with all tracks and the small histogram (`smallHisto`) with the track if; it is in the first 100. ``` {.cpp}; ...; for (Int_t jentry=0; jentry<nentries;jentry++) {; GetEntry(jentry);; for (Int_t j = 0; j < 100; j++) {; myHisto->Fill(fTracks_fPx[j]);; if (j < 100) {; smallHisto->Fill(fTracks_fPx[j]);; }; }; }; ...; ```. Outside of the for-loop, we draw both histograms on the same canvas. ``` {.cpp}; ...; myHisto->Draw();; smallHisto->Draw(""Same"");; ...; ```. Save these changes to `MyClass.C` and start a fresh root session. We; will now load `MyClass` and experiment with its methods. ### Loading MyClass. The first step is to load the library and the class file. Then we can; instantiate a `MyClass` object. ``` {.cpp}; root[] .L libEvent.so; root[] .L MyClass.C; root[] MyClass m; ```. Now we can get a specific entry and populate the event leaf. In the code; snipped below, we get entry 0, and print the number of tracks (594).; Then we get entry 1 and print the number of tracks (597). ``` {.cpp}; root[] m.GetEntry(0); (int)57503; root[] m.fNtrack(); (Int_t)594; root[] m.GetEntry(1); (int)48045; root[] m.fNtrack(); (Int_t)597; ```. Now we can call the `Loop` method, which will build and display the two; histograms. ``` {.cpp}; root[] m.Loop(); ```. You should now see a canvas that looks like this. ![](pictures/03000106.png). To conclude the discussion on `MakeClass` let us lists the steps that; got us here. - Call `TTree::MakeClass`, which automatically creates a class to loop; over the tree. - Modify the `MyClass::Loop()` method in `MyClass.C` to fit your task. - Load and instantiate `MyClass`, and run `MyClass::Loop",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:130008,load,load,130008,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['load'],['load']
Performance," = alloca i32 ; yields ptr; store i32 3, ptr %ptr ; yields void; %val = load i32, ptr %ptr ; yields i32:val = i32 3. .. _i_store:. '``store``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. store [volatile] <ty> <value>, ptr <pointer>[, align <alignment>][, !nontemporal !<nontemp_node>][, !invariant.group !<empty_node>] ; yields void; store atomic [volatile] <ty> <value>, ptr <pointer> [syncscope(""<target-scope>"")] <ordering>, align <alignment> [, !invariant.group !<empty_node>] ; yields void; !<nontemp_node> = !{ i32 1 }; !<empty_node> = !{}. Overview:; """""""""""""""""". The '``store``' instruction is used to write to memory. Arguments:; """""""""""""""""""". There are two arguments to the ``store`` instruction: a value to store and an; address at which to store it. The type of the ``<pointer>`` operand must be a; pointer to the :ref:`first class <t_firstclass>` type of the ``<value>``; operand. If the ``store`` is marked as ``volatile``, then the optimizer is not; allowed to modify the number or order of execution of this ``store`` with other; :ref:`volatile operations <volatile>`. Only values of :ref:`first class; <t_firstclass>` types of known size (i.e. not containing an :ref:`opaque; structural type <t_opaque>`) can be stored. If the ``store`` is marked as ``atomic``, it takes an extra :ref:`ordering; <ordering>` and optional ``syncscope(""<target-scope>"")`` argument. The; ``acquire`` and ``acq_rel`` orderings aren't valid on ``store`` instructions.; Atomic loads produce :ref:`defined <memmodel>` results when they may see; multiple atomic stores. The type of the pointee must be an integer, pointer, or; floating-point type whose bit width is a power of two greater than or equal to; eight and less than or equal to a target-specific size limit. ``align`` must be; explicitly specified on atomic stores. Note: if the alignment is not greater or; equal to the size of the `<value>` type, the atomic operation is likely to; require a lock and have poor performance. ``!nontemp",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:419852,optimiz,optimizer,419852,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizer']
Performance," = centered. - 3 = top. For example, align: 11 = left adjusted and bottom adjusted; 32 = right; adjusted and vertically centered. #### Setting Text Angle. Use `TAttText::SetTextAngle` to set the text angle. The `angle` is the; degrees of the horizontal. ``` {.cpp}; root[] la->SetTextAngle(angle); ```. #### Setting Text Color. Use `TAttText::SetTextColor` to set the text color. The `color` is the; color index. The colors are described in ""Color and Color Palettes"". ``` {.cpp}; root[] la->SetTextColor(color); ```. #### Setting Text Font. Use `TAttText::SetTextFont` to set the font. The parameter font is the; font code, combining the font and precision:; `font = 10 * fontID + precision`. ``` {.cpp}; root[] la->SetTextFont(font); ```. The table below lists the available fonts. The font IDs must be between; 1 and 14. The precision can be:. - Precision = 0 fast hardware fonts (steps in the size). - Precision = 1 scalable and rotate-able hardware fonts (see below). - Precision = 2 scalable and rotate-able hardware fonts. When precision 0 is used, only the original non-scaled system fonts are; used. The fonts have a minimum (4) and maximum (37) size in pixels.; These fonts are fast and are of good quality. Their size varies with; large steps and they cannot be rotated. Precision 1 and 2 fonts have a; different behavior depending if True Type Fonts (TTF) are used or not.; If TTF are used, you always get very good quality scalable and; rotate-able fonts. However, TTF are slow. Precision 1 and 2 fonts have a; different behavior for PostScript in case of **`TLatex`** objects:. - With precision 1, the PostScript text uses the old convention (see; **`TPostScript`**) for some special characters to draw sub and; superscripts or Greek text. - With precision 2, the ""PostScript"" special characters are drawn as; such. To draw sub and superscripts it is highly recommended to use; **`TLatex`** objects instead. For example: `font = 62` is the font with ID `6` and precision `2`. ![Font's ex",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:70743,scalab,scalable,70743,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['scalab'],['scalable']
Performance," = extractvalue {i32, i1} %res, 0; %obit = extractvalue {i32, i1} %res, 1; br i1 %obit, label %overflow, label %normal. Saturation Arithmetic Intrinsics; ---------------------------------. Saturation arithmetic is a version of arithmetic in which operations are; limited to a fixed range between a minimum and maximum value. If the result of; an operation is greater than the maximum value, the result is set (or; ""clamped"") to this maximum. If it is below the minimum, it is clamped to this; minimum. '``llvm.sadd.sat.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.sadd.sat``; on any integer bit width or vectors of integers. ::. declare i16 @llvm.sadd.sat.i16(i16 %a, i16 %b); declare i32 @llvm.sadd.sat.i32(i32 %a, i32 %b); declare i64 @llvm.sadd.sat.i64(i64 %a, i64 %b); declare <4 x i32> @llvm.sadd.sat.v4i32(<4 x i32> %a, <4 x i32> %b). Overview; """""""""""""""""". The '``llvm.sadd.sat``' family of intrinsic functions perform signed; saturating addition on the 2 arguments. Arguments; """""""""""""""""""". The arguments (%a and %b) and the result may be of integer types of any bit; width, but they must have the same bit width. ``%a`` and ``%b`` are the two; values that will undergo signed addition. Semantics:; """""""""""""""""""". The maximum value this operation can clamp to is the largest signed value; representable by the bit width of the arguments. The minimum value is the; smallest signed value representable by this bit width. Examples; """""""""""""""""". .. code-block:: llvm. %res = call i4 @llvm.sadd.sat.i4(i4 1, i4 2) ; %res = 3; %res = call i4 @llvm.sadd.sat.i4(i4 5, i4 6) ; %res = 7; %res = call i4 @llvm.sadd.sat.i4(i4 -4, i4 2) ; %res = -2; %res = call i4 @llvm.sadd.sat.i4(i4 -4, i4 -5) ; %res = -8. '``llvm.uadd.sat.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.uadd.sat``; on any integer bit width or vectors of integers. ::. declare i16 @llvm.uadd.sat.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:611437,perform,perform,611437,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance," = getelementptr inbounds %struct.anon* %tmp3, i64 %indvar, i32 0; %tmp5 = load double* %tmp4, align 8, !tbaa !4; %idxprom7 = sext i32 %i.01718 to i64; %tmp10 = getelementptr inbounds %struct.anon* %tmp3, i64 %idxprom7, i32 0; %tmp11 = load double* %tmp10, align 8, !tbaa !4; %cmp12 = fcmp ogt double %tmp5, %tmp11; br i1 %cmp12, label %if.then, label %for.inc. if.then: ; preds = %for.body; %i.017 = trunc i64 %indvar to i32; br label %for.inc. for.inc: ; preds = %for.body, %if.then; %i.01719 = phi i32 [ %i.01718, %for.body ], [ %i.017, %if.then ]; %indvar.next = add i64 %indvar, 1; %exitcond = icmp eq i64 %indvar.next, %tmp22; br i1 %exitcond, label %for.cond.for.end_crit_edge, label %for.body. It is good that we hoisted the reloads of numf2's, and Y out of the loop and; sunk the store to winner out. However, this is awful on several levels: the conditional truncate in the loop; (-indvars at fault? why can't we completely promote the IV to i64?). Beyond that, we have a partially redundant load in the loop: if ""winner"" (aka ; %i.01718) isn't updated, we reload Y[winner].y the next time through the loop.; Similarly, the addressing that feeds it (including the sext) is redundant. In; the end we get this generated assembly:. LBB0_2: ## %for.body; ## =>This Inner Loop Header: Depth=1; 	movsd	(%rdi), %xmm0; 	movslq	%edx, %r8; 	shlq	$4, %r8; 	ucomisd	(%rcx,%r8), %xmm0; 	jbe	LBB0_4; 	movl	%esi, %edx; LBB0_4: ## %for.inc; 	addq	$16, %rdi; 	incq	%rsi; 	cmpq	%rsi, %rax; 	jne	LBB0_2. All things considered this isn't too bad, but we shouldn't need the movslq or; the shlq instruction, or the load folded into ucomisd every time through the; loop. On an x86-specific topic, if the loop can't be restructure, the movl should be a; cmov. //===---------------------------------------------------------------------===//. [STORE SINKING]. GCC PR37810 is an interesting case where we should sink load/store reload; into the if block and outside the loop, so we don't reload/store it on the; non-c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:31194,load,load,31194,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,1,['load'],['load']
Performance," = icmp eq i32 %decl_context_addr.0, 1 ; %decl_context_addr.1 = select i1 %tmp1, i32 0, i32 %decl_context_addr.0. tmp1 should be simplified to something like:; (!tmp || decl_context == 1). This allows recursive simplifications, tmp1 is used all over the place in; the function, e.g. by:. %tmp23 = icmp eq i32 %decl_context_addr.1, 0 ; <i1> [#uses=1]; %tmp24 = xor i1 %tmp1, true ; <i1> [#uses=1]; %or.cond8 = and i1 %tmp23, %tmp24 ; <i1> [#uses=1]. later. //===---------------------------------------------------------------------===//. [STORE SINKING]. Store sinking: This code:. void f (int n, int *cond, int *res) {; int i;; *res = 0;; for (i = 0; i < n; i++); if (*cond); *res ^= 234; /* (*) */; }. On this function GVN hoists the fully redundant value of *res, but nothing; moves the store out. This gives us this code:. bb:		; preds = %bb2, %entry; 	%.rle = phi i32 [ 0, %entry ], [ %.rle6, %bb2 ]	; 	%i.05 = phi i32 [ 0, %entry ], [ %indvar.next, %bb2 ]; 	%1 = load i32* %cond, align 4; 	%2 = icmp eq i32 %1, 0; 	br i1 %2, label %bb2, label %bb1. bb1:		; preds = %bb; 	%3 = xor i32 %.rle, 234	; 	store i32 %3, i32* %res, align 4; 	br label %bb2. bb2:		; preds = %bb, %bb1; 	%.rle6 = phi i32 [ %3, %bb1 ], [ %.rle, %bb ]	; 	%indvar.next = add i32 %i.05, 1	; 	%exitcond = icmp eq i32 %indvar.next, %n; 	br i1 %exitcond, label %return, label %bb. DSE should sink partially dead stores to get the store out of the loop. Here's another partial dead case:; http://gcc.gnu.org/bugzilla/show_bug.cgi?id=12395. //===---------------------------------------------------------------------===//. Scalar PRE hoists the mul in the common block up to the else:. int test (int a, int b, int c, int g) {; int d, e;; if (a); d = b * c;; else; d = b - c;; e = b * c + g;; return d + e;; }. It would be better to do the mul once to reduce codesize above the if.; This is GCC PR38204. //===---------------------------------------------------------------------===//; This simple function from 179.art:. int winner, nu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:28808,load,load,28808,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,1,['load'],['load']
Performance," = ptrs[i] + offset*sizeof(i8); %A = getelementptr i8, <4 x ptr> %ptrs, i64 %offset. ; Add distinct offsets to the same pointer:; ; A[i] = ptr + offsets[i]*sizeof(i8); %A = getelementptr i8, ptr %ptr, <4 x i64> %offsets. ; In all cases described above the type of the result is <4 x ptr>. The two following instructions are equivalent:. .. code-block:: llvm. getelementptr %struct.ST, <4 x ptr> %s, <4 x i64> %ind1,; <4 x i32> <i32 2, i32 2, i32 2, i32 2>,; <4 x i32> <i32 1, i32 1, i32 1, i32 1>,; <4 x i32> %ind4,; <4 x i64> <i64 13, i64 13, i64 13, i64 13>. getelementptr %struct.ST, <4 x ptr> %s, <4 x i64> %ind1,; i32 2, i32 1, <4 x i32> %ind4, i64 13. Let's look at the C code, where the vector version of ``getelementptr``; makes sense:. .. code-block:: c. // Let's assume that we vectorize the following loop:; double *A, *B; int *C;; for (int i = 0; i < size; ++i) {; A[i] = B[C[i]];; }. .. code-block:: llvm. ; get pointers for 8 elements from array B; %ptrs = getelementptr double, ptr %B, <8 x i32> %C; ; load 8 elements from array B into A; %A = call <8 x double> @llvm.masked.gather.v8f64.v8p0f64(<8 x ptr> %ptrs,; i32 8, <8 x i1> %mask, <8 x double> %passthru). Conversion Operations; ---------------------. The instructions in this category are the conversion instructions; (casting) which all take a single operand and a type. They perform; various bit conversions on the operand. .. _i_trunc:. '``trunc .. to``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = trunc <ty> <value> to <ty2> ; yields ty2. Overview:; """""""""""""""""". The '``trunc``' instruction truncates its operand to the type ``ty2``. Arguments:; """""""""""""""""""". The '``trunc``' instruction takes a value to trunc, and a type to trunc; it to. Both types must be of :ref:`integer <t_integer>` types, or vectors; of the same number of integers. The bit size of the ``value`` must be; larger than the bit size of the destination type, ``ty2``. Equal sized; types are not allowed. Semantics:; """"""""""""""""""",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:441667,load,load,441667,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," = v*v`** ` = t*t-x*x-y*y-z*z `. If `mag2` is negative: **`mag = -Sqrt(-mag*mag)`**. The methods are:. ``` {.cpp}; Double_t s, s2;; s = v1.Dot(v2);// scalar product; s = v1*v2;// scalar product; s2 = v.Mag2();ors2 = v.M2();; s = v.Mag();s = v.M();; ```. Since in case of momentum and energy the magnitude has the meaning of; invariant mass **`TLorentzVector`** provides the more meaningful aliases; `M2()` and `M()`. The methods `Beta()` and `Gamma()` returns `beta` and; `gamma = 1/Sqrt(1-beta*beta)`. ### Lorentz Boost. A boost in a general direction can be parameterized with three; parameters which can be taken as the components of a three vector; `b=(bx,by,bz)`. With `x=(x,y,z)` and `gamma=1/Sqrt(1-beta*beta)` (beta; being the module of vector b)`,` an arbitrary active Lorentz boost; transformation (from the rod frame to the original frame) can be written; as:. `x = x' + (gamma-1)/(beta*beta)*(b*x')*b + gamma*t'*b `. `t = gamma(t'+ b*x') `. The `Boost()` method performs a boost transformation from the rod frame; to the original frame. `BoostVector()` returns a **`TVector3`** of the; spatial components divided by the time component:. ``` {.cpp}; TVector3 b;; v.Boost(bx,by,bz);; v.Boost(b);; b = v.BoostVector();// b=(x/t,y/t,z/t); ```. ### Rotations. There are four sets of functions to rotate the **`TVector3`** component; of a **`TLorentzVector`**:. Around Axes:. ``` {.cpp}; v.RotateX(TMath::Pi()/2.);; v.RotateY(.5);; v.RotateZ(.99);; ```. Around an arbitrary axis:. ``` {.cpp}; v.Rotate(TMath::Pi()/4., v1); // rotation around v1; ```. Transformation from rotated frame:. ``` {.cpp}; v.RotateUz(direction); // direction must be a unit TVector3; ```. Rotation by **`TRotation`**:. ``` {.cpp}; TRotation r;; v.Transform(r);//or v *= r; (v = r*v); ```. ### Miscellaneous. Angle between two vectors:. ``` {.cpp}; Double_t a = v1.Angle(v2);// get angle between v1 and v2; ```. Methods `Plus()` and `Minus()` return the positive and negative; light-cone components:. ``` {.cpp}; Double",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PhysicsVectors.md:13632,perform,performs,13632,documentation/users-guide/PhysicsVectors.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PhysicsVectors.md,1,['perform'],['performs']
Performance," =================== =============== =============== =======================================. .. .. table:: AMDGPU Trap Handler for AMDHSA OS Code Object V3; :name: amdgpu-trap-handler-for-amdhsa-os-v3-table. =================== =============== =============== =======================================; Usage Code Sequence Trap Handler Description; Inputs; =================== =============== =============== =======================================; reserved ``s_trap 0x00`` Reserved by hardware.; debugger breakpoint ``s_trap 0x01`` *none* Reserved for debugger to use for; breakpoints. Causes wave to be halted; with the PC at the trap instruction.; The debugger is responsible to resume; the wave, including the instruction; that the breakpoint overwrote.; ``llvm.trap`` ``s_trap 0x02`` ``SGPR0-1``: Causes wave to be halted with the PC at; ``queue_ptr`` the trap instruction. The associated; queue is signalled to put it into the; error state. When the queue is put in; the error state, the waves executing; dispatches on the queue will be; terminated.; ``llvm.debugtrap`` ``s_trap 0x03`` *none* - If debugger not enabled then behaves; as a no-operation. The trap handler; is entered and immediately returns to; continue execution of the wavefront.; - If the debugger is enabled, causes; the debug trap to be reported by the; debugger and the wavefront is put in; the halt state with the PC at the; instruction. The debugger must; increment the PC and resume the wave.; reserved ``s_trap 0x04`` Reserved.; reserved ``s_trap 0x05`` Reserved.; reserved ``s_trap 0x06`` Reserved.; reserved ``s_trap 0x07`` Reserved.; reserved ``s_trap 0x08`` Reserved.; reserved ``s_trap 0xfe`` Reserved.; reserved ``s_trap 0xff`` Reserved.; =================== =============== =============== =======================================. .. .. table:: AMDGPU Trap Handler for AMDHSA OS Code Object V4 and Above; :name: amdgpu-trap-handler-for-amdhsa-os-v4-onwards-table. =================== =============== ==============",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:383111,queue,queue,383111,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['queue'],['queue']
Performance," =============================== =========================================================. dlc; ~~~. See a description :ref:`here<amdgpu_synid_dlc>`. Miscellaneous Modifiers; -----------------------. .. _amdgpu_synid_dlc:. dlc; ~~~. Controls device level cache policy for memory operations. Used for synchronization.; When specified, forces operation to bypass device level cache, making the operation device; level coherent. By default, instructions use device level cache. ======================================== ================================================; Syntax Description; ======================================== ================================================; dlc Bypass device level cache.; ======================================== ================================================. .. _amdgpu_synid_glc:. glc; ~~~. For atomic opcodes, this modifier indicates that the instruction returns the value from memory; before the operation. For other opcodes, it is used together with :ref:`slc<amdgpu_synid_slc>`; to specify cache policy. The default value is off (0). ======================================== ================================================; Syntax Description; ======================================== ================================================; glc Set glc bit to 1.; ======================================== ================================================. .. _amdgpu_synid_lds:. lds; ~~~. Specifies where to store the result: VGPRs or LDS (VGPRs by default). ======================================== ===========================; Syntax Description; ======================================== ===========================; lds Store the result in LDS.; ======================================== ===========================. .. _amdgpu_synid_nv:. nv; ~~. Specifies if the instruction is operating on non-volatile memory.; By default, memory is volatile. ======================================== ================================================; Syntax Description; =",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:17838,cache,cache,17838,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,1,['cache'],['cache']
Performance," ====================================================; .. contents::; :local:; :depth: 1. Introduction; ============. The -opt-bisect-limit option provides a way to disable all optimization passes; above a specified limit without modifying the way in which the Pass Managers; are populated. The intention of this option is to assist in tracking down; problems where incorrect transformations during optimization result in incorrect; run-time behavior. This feature is implemented on an opt-in basis. Passes which can be safely; skipped while still allowing correct code generation call a function to; check the opt-bisect limit before performing optimizations. Passes which; either must be run or do not modify the IR do not perform this check and are; therefore never skipped. Generally, this means analysis passes, passes; that are run at CodeGenOptLevel::None and passes which are required for register; allocation. The -opt-bisect-limit option can be used with any tool, including front ends; such as clang, that uses the core LLVM library for optimization and code; generation. The exact syntax for invoking the option is discussed below. This feature is not intended to replace other debugging tools such as bugpoint.; Rather it provides an alternate course of action when reproducing the problem; requires a complex build infrastructure that would make using bugpoint; impractical or when reproducing the failure requires a sequence of; transformations that is difficult to replicate with tools like opt and llc. Getting Started; ===============. The -opt-bisect-limit command line option can be passed directly to tools such; as opt, llc and lli. The syntax is as follows:. ::. <tool name> [other options] -opt-bisect-limit=<limit>. If a value of -1 is used the tool will perform all optimizations but a message; will be printed to stderr for each optimization that could be skipped; indicating the index value that is associated with that optimization. To skip; optimizations, pass the value",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OptBisect.rst:1155,optimiz,optimization,1155,interpreter/llvm-project/llvm/docs/OptBisect.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OptBisect.rst,1,['optimiz'],['optimization']
Performance," @llvm.masked.load.v8p0.p0(ptr <ptr>, i32 <alignment>, <8 x i1> <mask>, <8 x ptr> <passthru>). Overview:; """""""""""""""""". Reads a vector from memory according to the provided mask. The mask holds a bit for each vector lane, and is used to prevent memory accesses to the masked-off lanes. The masked-off lanes in the result vector are taken from the corresponding lanes of the '``passthru``' operand. Arguments:; """""""""""""""""""". The first operand is the base pointer for the load. The second operand is the alignment of the source location. It must be a power of two constant integer value. The third operand, mask, is a vector of boolean values with the same number of elements as the return type. The fourth is a pass-through value that is used to fill the masked-off lanes of the result. The return type, underlying type of the base pointer and the type of the '``passthru``' operand are the same vector types. Semantics:; """""""""""""""""""". The '``llvm.masked.load``' intrinsic is designed for conditional reading of selected vector elements in a single IR operation. It is useful for targets that support vector masked loads and allows vectorizing predicated basic blocks on these targets. Other targets may support this intrinsic differently, for example by lowering it into a sequence of branches that guard scalar load operations.; The result of this operation is equivalent to a regular vector load instruction followed by a 'select' between the loaded and the passthru values, predicated on the same mask. However, using this intrinsic prevents exceptions on memory access to masked-off lanes. ::. %res = call <16 x float> @llvm.masked.load.v16f32.p0(ptr %ptr, i32 4, <16 x i1>%mask, <16 x float> %passthru). ;; The result of the two following instructions is identical aside from potential memory access exception; %loadlal = load <16 x float>, ptr %ptr, align 4; %res = select <16 x i1> %mask, <16 x float> %loadlal, <16 x float> %passthru. .. _int_mstore:. '``llvm.masked.store.*``' Intrinsics; ^^^^^^^^^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:844581,load,load,844581,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," A single transient buffer holding the compressed data is now managed by TTree (and could be made thread local); rather than having one per TBranch.; In TTree::Fill, call FlushBasket before calling OptimizeBaskets so that we have a correct; and accurate value of fTotBytes to use as the requested memory.; In TTree::OptimizeBasket enforces hard minimun for the basket size (no lower than the; estimate size of one entry in the branch and no lower than 8 bytes). TTree::Process. Add support for the flag TSelector::kAbortFile. TTree::Draw. The line width setting was missing in a few places.; Namely support the option 'a' for TGraphs in TTree::Draw (delegate the axis management to the TGraph object). TTreeSQL. Allow TTreeSQL to see temporary tables.; Avoid creating the unnecessary array fEntryOffset ... which when its content is always set to zero actually prevent reading text field with TTreeSQL.; Properly find the column even if they were not created by TTreeSQL itself. Fix the loading of data for the last column. Other. Update the branch split mechanism to no longer split a base class; that can not be split (i.e. respect the information returned; by TStreamerElement::CannotSplit (and thus TClass::CanSplit).; In TChain::ls, print the name of the chain and indent the list of files (this fixes #79909).; When setting fBranch in the loaded basket, make sure to set it also for the first/only basket ; this prevents a crash when calling SetBasketSize for a split top level branch in a file produced by v4.00/08.; In TTree::Streamer, if the object we are reading in was already attached to a directory, let's make sure to unregister the object before setting fDirectory to zero.; Prevent TChainIndex and TTreeIndex from finding the branches from the friend tree when looking up the value in the master/parent TTree. This fixes #79166.; Update GetEntryNumberFriend and related functions to retun a Long64_t as needed.; Fix the case of a split collection which contains a class with one; data ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html:3154,load,loading,3154,tree/doc/v530/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html,1,['load'],['loading']
Performance," AMD graphics targets. Functions with this calling convention; cannot be used as entry points.; ..TODO::; Describe. ``amdgpu_gs`` Used for Mesa/AMDPAL geometry shaders.; ..TODO::; Describe. ``amdgpu_hs`` Used for Mesa/AMDPAL hull shaders (= tessellation control shaders).; ..TODO::; Describe. ``amdgpu_kernel`` See :ref:`amdgpu-amdhsa-function-call-convention-kernel-functions`. ``amdgpu_ls`` Used for AMDPAL vertex shader if tessellation is in use.; ..TODO::; Describe. ``amdgpu_ps`` Used for Mesa/AMDPAL pixel shaders.; ..TODO::; Describe. ``amdgpu_vs`` Used for Mesa/AMDPAL last shader stage before rasterization (vertex; shader if tessellation and geometry are not in use, or otherwise; copy shader if one is needed).; ..TODO::; Describe. =============================== ==========================================================. .. _amdgpu-elf-code-object:. ELF Code Object; ===============. The AMDGPU backend generates a standard ELF [ELF]_ relocatable code object that; can be linked by ``lld`` to produce a standard ELF shared code object which can; be loaded and executed on an AMDGPU target. .. _amdgpu-elf-header:. Header; ------. The AMDGPU backend uses the following ELF header:. .. table:: AMDGPU ELF Header; :name: amdgpu-elf-header-table. ========================== ===============================; Field Value; ========================== ===============================; ``e_ident[EI_CLASS]`` ``ELFCLASS64``; ``e_ident[EI_DATA]`` ``ELFDATA2LSB``; ``e_ident[EI_OSABI]`` - ``ELFOSABI_NONE``; - ``ELFOSABI_AMDGPU_HSA``; - ``ELFOSABI_AMDGPU_PAL``; - ``ELFOSABI_AMDGPU_MESA3D``; ``e_ident[EI_ABIVERSION]`` - ``ELFABIVERSION_AMDGPU_HSA_V2``; - ``ELFABIVERSION_AMDGPU_HSA_V3``; - ``ELFABIVERSION_AMDGPU_HSA_V4``; - ``ELFABIVERSION_AMDGPU_HSA_V5``; - ``ELFABIVERSION_AMDGPU_PAL``; - ``ELFABIVERSION_AMDGPU_MESA3D``; ``e_type`` - ``ET_REL``; - ``ET_DYN``; ``e_machine`` ``EM_AMDGPU``; ``e_entry`` 0; ``e_flags`` See :ref:`amdgpu-elf-header-e_flags-v2-table`,; :ref:`amdgpu-elf-header-e_flag",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:55872,load,loaded,55872,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loaded']
Performance," AddressSanitizer is **2x**. How to build; ============. Build LLVM/Clang with `CMake <https://llvm.org/docs/CMake.html>` and enable; the ``compiler-rt`` runtime. An example CMake configuration that will allow; for the use/testing of AddressSanitizer:. .. code-block:: console. $ cmake -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_PROJECTS=""clang"" -DLLVM_ENABLE_RUNTIMES=""compiler-rt"" <path to source>/llvm. Usage; =====. Simply compile and link your program with ``-fsanitize=address`` flag. The; AddressSanitizer run-time library should be linked to the final executable, so; make sure to use ``clang`` (not ``ld``) for the final link step. When linking; shared libraries, the AddressSanitizer run-time is not linked, so; ``-Wl,-z,defs`` may cause link errors (don't use it with AddressSanitizer). To; get a reasonable performance add ``-O1`` or higher. To get nicer stack traces; in error messages add ``-fno-omit-frame-pointer``. To get perfect stack traces; you may need to disable inlining (just use ``-O1``) and tail call elimination; (``-fno-optimize-sibling-calls``). .. code-block:: console. % cat example_UseAfterFree.cc; int main(int argc, char **argv) {; int *array = new int[100];; delete [] array;; return array[argc]; // BOOM; }. # Compile and link; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer example_UseAfterFree.cc. or:. .. code-block:: console. # Compile; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer -c example_UseAfterFree.cc; # Link; % clang++ -g -fsanitize=address example_UseAfterFree.o. If a bug is detected, the program will print an error message to stderr and; exit with a non-zero exit code. AddressSanitizer exits on the first detected error.; This is by design:. * This approach allows AddressSanitizer to produce faster and smaller generated code; (both by ~5%).; * Fixing bugs becomes unavoidable. AddressSanitizer does not produce; false alarms. Once a memory corruption occurs, the program is in an inconsistent; state, which could lead t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:1836,optimiz,optimize-sibling-calls,1836,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst,1,['optimiz'],['optimize-sibling-calls']
Performance," Allocation; ---------------------------------------------. To avoid debug instructions interfering with the register allocator, the; LiveDebugVariables pass extracts variable locations from a MIR function and; deletes the corresponding DBG_VALUE instructions. Some localized copy; propagation is performed within blocks. After register allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations. To avoid encoding incorrect variable locations, in this; pass any DBG_VALUE of a virtual register that is not live, is replaced by; the undefined location. The LiveDebugVariables may insert redundant DBG_VALUEs; because of virtual register rewriting. These will be subsequently removed by; the RemoveRedundantDebugValues pass. LiveDebugValues expansion of variable locations; -----------------------------------------------. After all optimizations have run and shortly before emission, the; LiveDebugValues pass runs to achieve two aims:. * To propagate the location of variables through copies and register spills,; * For every block, to record every valid variable location in that block. After this pass the DBG_VALUE instruction changes meaning: rather than; corresponding to a source-level assignment where the variable may change value,; it asserts the location of a variable in a block, and loses effect outside the; block. Propagating variable locations through copies and spills is; straightforwards: determining the variable location in every basic block; requires the consideration of control flow. Consider the following IR, which; presents several difficulties:. .. code-block:: text. define dso_local i32 @foo(i1 %cond, i32 %input) !dbg !12 {; entry:; br i1 %cond, label %truebr, label %falsebr. bb1:; %value = phi i32 [ %value1, %truebr ], [ %value2, %falsebr ]; br label %exit, !dbg !26. truebr:; call void @llvm.dbg.value(metadata i32 %input, metadata !30, metadat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:36544,optimiz,optimizations,36544,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['optimiz'],['optimizations']
Performance," At global scope.; uselistorder ptr @global, { 1, 2, 0 }; uselistorder i32 7, { 1, 0 }; uselistorder i32 (i32) @bar, { 1, 0 }; uselistorder_bb @foo, %bb, { 5, 1, 3, 2, 0, 4 }. .. _source_filename:. Source Filename; ---------------. The *source filename* string is set to the original module identifier,; which will be the name of the compiled source file when compiling from; source through the clang front end, for example. It is then preserved through; the IR and bitcode. This is currently necessary to generate a consistent unique global; identifier for local functions used in profile data, which prepends the; source file name to the local function name. The syntax for the source file name is simply:. .. code-block:: text. source_filename = ""/path/to/source.c"". .. _typesystem:. Type System; ===========. The LLVM type system is one of the most important features of the; intermediate representation. Being typed enables a number of; optimizations to be performed on the intermediate representation; directly, without having to do extra analyses on the side before the; transformation. A strong type system makes it easier to read the; generated code and enables novel analyses and transformations that are; not feasible to perform on normal three address code representations. .. _t_void:. Void Type; ---------. :Overview:. The void type does not represent any value and has no size. :Syntax:. ::. void. .. _t_function:. Function Type; -------------. :Overview:. The function type can be thought of as a function signature. It consists of a; return type and a list of formal parameter types. The return type of a function; type is a void type or first class type --- except for :ref:`label <t_label>`; and :ref:`metadata <t_metadata>` types. :Syntax:. ::. <returntype> (<parameter list>). ...where '``<parameter list>``' is a comma-separated list of type; specifiers. Optionally, the parameter list may include a type ``...``, which; indicates that the function takes a variable number of arg",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:165348,optimiz,optimizations,165348,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,"['optimiz', 'perform']","['optimizations', 'performed']"
Performance," C Standard are; currently under investigation. Any defect report whose status in Clang is; currently unknown will be marked in purple.; The LLVM bug tracker uses; the ""c"", ""c99"", ""c11"", ""c17"", and ""c23"" labels to track known bugs with Clang's language; conformance. Number; Status; Issue title; Available in Clang?. 1; C89; Do functions return values by copying?; Yes. 2; NAD; Subclause 6.8.3.2: Semantics of #; Unknown. 3; NAD; Subclause 6.1.8: Preprocessing numbers; Unknown. 4; NAD; Are multiple definitions of unused identifiers with external linkage permitted?; Yes. 5; NAD; May a conforming implementation define and recognize a pragma which would change the semantics of the language?; Yes. 6; C89; It is unclear how the strtoul function behaves when presented with a subject sequence that begins with a minus sign; N/A. 7; NAD; Are declarations of the form struct-or-union identifier ; permitted after the identifier tag has already been declared?; Yes. 8; NAD; Can a conforming C compiler to perform dead-store elimination?; Yes. 9; C89; Use of typedef names in parameter declarations; No. 10; NAD; Is a typedef to an incomplete type legal?; Yes. 11; C89; Merging of declarations for linked identifier; Yes. 12; NAD; Is it valid to take the address of a dereferenced void pointer?; Yes. 13; C89; Compatible and composite function types; Yes. 14; C89; Issues with setjmp and fscanf descriptions; N/A. 15; NAD; What is the promoted type of a plain int bit-field?; Yes. 16; C89; What does static storage duration do when zero for the type is not all zero bits?; Unknown. 17; C89; 39 unrelated questions about C89; Unknown. 18; NAD; How does fscanf behave in the presence of multibyte characters?; N/A. 19; NAD; Definition of the term ""printing character"" and isgraph(); N/A. 20; NAD; Is a compiler which allows the Relaxed Ref/Def linkage model to be considered a conforming compiler?; Yes. 21; C89; What is the result of: printf(""%#.4o"", 345);?; N/A. 22; C89; What is the result of: strtod(""10",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_dr_status.html:1236,perform,perform,1236,interpreter/llvm-project/clang/www/c_dr_status.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/c_dr_status.html,1,['perform'],['perform']
Performance," CMake language-defined functions. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(HelloWorld); add_executable(HelloWorld HelloWorld.cpp). The CMake language provides control flow constructs in the form of foreach loops; and if blocks. To make the example above more complicated you could add an if; block to define ""APPLE"" when targeting Apple platforms:. .. code-block:: cmake. cmake_minimum_required(VERSION 3.20.0); project(HelloWorld); add_executable(HelloWorld HelloWorld.cpp); if(APPLE); target_compile_definitions(HelloWorld PUBLIC APPLE); endif(). Variables, Types, and Scope; ===========================. Dereferencing; -------------. In CMake variables are ""stringly"" typed. All variables are represented as; strings throughout evaluation. Wrapping a variable in ``${}`` dereferences it; and results in a literal substitution of the name for the value. CMake refers to; this as ""variable evaluation"" in their documentation. Dereferences are performed; *before* the command being called receives the arguments. This means; dereferencing a list results in multiple separate arguments being passed to the; command. Variable dereferences can be nested and be used to model complex data. For; example:. .. code-block:: cmake. set(var_name var1); set(${var_name} foo) # same as ""set(var1 foo)""; set(${${var_name}}_var bar) # same as ""set(foo_var bar)"". Dereferencing an unset variable results in an empty expansion. It is a common; pattern in CMake to conditionally set variables knowing that it will be used in; code paths that the variable isn't set. There are examples of this throughout; the LLVM CMake build system. An example of variable empty expansion is:. .. code-block:: cmake. if(APPLE); set(extra_sources Apple.cpp); endif(); add_executable(HelloWorld HelloWorld.cpp ${extra_sources}). In this example the ``extra_sources`` variable is only defined if you're; targeting an Apple platform. For all other targets the ``extra_sources`` will be; evaluated as empty",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:3153,perform,performed,3153,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst,1,['perform'],['performed']
Performance," CU. In WGP wavefront execution mode the; wavefronts may be executed by different SIMDs in different CUs in the same; WGP.; * Each WGP has a single LDS memory shared by the wavefronts of the work-groups; executing on it.; * All LDS operations of a WGP are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; WGP. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations.; Completion of load/store/sample operations are reported to a wavefront in; execution order of other load/store/sample operations performed by that; wavefront.; * The vector memory operations access a vector L0 cache. There is a single L0; cache per CU. Each SIMD of a CU accesses the same L0 cache. Therefore, no; special action is required for coherence between the lanes of a single; wavefront. However, a ``buffer_gl0_inv`` is required for coherence between; wavefronts executing in the same work-group as they may be executing on SIMDs; of different CUs that access different L0s. A ``buffer_gl0_inv`` is also; required for coherence between wavefronts executing in different work-groups; as they may be executing on different WGPs.; * The scalar memory operations access a scalar L0 cache shared by all wavefronts; on a WGP. The scalar and vector L0 caches are not coherent. However, scalar; operations are used in a restricted way so do not impact the me",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:336544,perform,performed,336544,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performed']
Performance," CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by coherent requests. Coherent requests are caused; by GPU accesses to pages with the PTE C-bit set, by CPU accesses over; XGMI, and by PCIe requests that are configured to be coherent requests.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter and and the PTE C-bit being set.; * Since all work-groups on the same agent share the same L2, no L2; invalidation or writeback is required for coherence.; * To ensure coherence of local and remote memory writes of work-groups in; different agents a ``buffer_wbl2`` is required. It will writeback dirty L2; cache lines of MTYPE RW (used for local coarse grain memory) and MTYPE NC; ()used for remote coarse grain memory). Note that MTYPE CC (used for local; fine grain memory) causes write through to DRAM, and MTYPE UC (used for; remote fine grain memory) bypasses the L2, so both will never result in; dirty L2 cache lines.; * To ensure coherence of local and remote memory reads of work-groups in; different agents a ``buffer_invl2`` is required. It will invalidate L2; cache lines with MTYPE NC (used for remote coarse grain memory). Note that; MTYPE CC (used for local fine grain memory) and MTYPE RW (used for local; coarse memory) cause local reads to be invalidated by remote writes with; with the PTE C-bit so these cache lines are not invalidated. Note that; MTYPE UC (used for remote fine grain memory) bypasses the L2, so will; never result in L2 cache lines that need to be invalidated. * PCIe access from the GPU to the CPU memory is kept coherent by using the; MTYPE UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for progra",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:239068,cache,cache,239068,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," Chapter 2 of the ""Building an ORC-based JIT in LLVM"" tutorial. In; `Chapter 1 <BuildingAJIT1.html>`_ of this series we examined a basic JIT; class, KaleidoscopeJIT, that could take LLVM IR modules as input and produce; executable code in memory. KaleidoscopeJIT was able to do this with relatively; little code by composing two off-the-shelf *ORC layers*: IRCompileLayer and; ObjectLinkingLayer, to do much of the heavy lifting. In this layer we'll learn more about the ORC layer concept by using a new layer,; IRTransformLayer, to add IR optimization support to KaleidoscopeJIT. Optimizing Modules using the IRTransformLayer; =============================================. In `Chapter 4 <LangImpl04.html>`_ of the ""Implementing a language with LLVM""; tutorial series the llvm *FunctionPassManager* is introduced as a means for; optimizing LLVM IR. Interested readers may read that chapter for details, but; in short: to optimize a Module we create an llvm::FunctionPassManager; instance, configure it with a set of optimizations, then run the PassManager on; a Module to mutate it into a (hopefully) more optimized but semantically; equivalent form. In the original tutorial series the FunctionPassManager was; created outside the KaleidoscopeJIT and modules were optimized before being; added to it. In this Chapter we will make optimization a phase of our JIT; instead. For now this will provide us a motivation to learn more about ORC; layers, but in the long term making optimization part of our JIT will yield an; important benefit: When we begin lazily compiling code (i.e. deferring; compilation of each function until the first time it's run) having; optimization managed by our JIT will allow us to optimize lazily too, rather; than having to do all our optimization up-front. To add optimization support to our JIT we will take the KaleidoscopeJIT from; Chapter 1 and compose an ORC *IRTransformLayer* on top. We will look at how the; IRTransformLayer works in more detail below, but the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst:1614,optimiz,optimize,1614,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,3,['optimiz'],"['optimizations', 'optimize', 'optimized']"
Performance," Clang implements. These; lists currently have a number of entries marked as Unknown.; Completing the investigation involves adding test coverage for; C; and; C++; defect reports and updating the documentation accordingly.; Bug triage: Clang's ; issue trackercurrently has over 20,000 open issues, many of which are not; appropriately tagged, are no longer reproducible, could use a reduced test case,; or otherwise needs some manual interaction. We can always use help with; bug triage and; issue tracker maintenance. Improve build times with Clang: the time it takes Clang to process a; translation unit is very important to our users; the lower the build time, the; better the overall user experience. It would be good to improve Clang's; performance as well as to find ways to proactively alert us when we've; introduced a change that has significant negative impact on build times.; Complete support for the experimental constant expression interpreter; : Clang's production constant expression interpreter computes a constant; expression result by walking over AST nodes, performing calculations as it; goes. This does not have good performance properties, and so we've begun work; on an ; experimental constant expression interpreter that works by converting the; AST into bytecode that is interpreted. This effort has a long tail of work left; to complete because it requires implementing byte code for every kind of; expression and type that can be used in a constant expression for C++ and C. Improve clang-doc: Clang's library-based design allows it to be used; by a variety of tools that reason about source code.; clang-doc is one; great application of this functionality, which generates code documentation; from source code. The tool is in early stages of development and could use more; dedicated effort to complete the implementation.; Self-testing using clang: There are several neat ways to; improve the quality of clang by self-testing. Some examples:. Improve the reliability of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/OpenProjects.html:3476,perform,performing,3476,interpreter/llvm-project/clang/www/OpenProjects.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/OpenProjects.html,1,['perform'],['performing']
Performance," Code command. .. option:: --macho-dsymtab. Display the Dsymtab command. .. option:: --macho-indirect-symbols. Display indirect symbols. .. option:: --macho-linker-options. Display the Mach-O-specific linker options. .. option:: --macho-segment. Display the Segment command. .. option:: --macho-version-min. Display the version min command. PE/COFF SPECIFIC OPTIONS; ------------------------. The following options are implemented only for the PE/COFF file format. .. option:: --codeview. Display CodeView debug information. .. option:: --codeview-ghash. Enable global hashing for CodeView type stream de-duplication. .. option:: --codeview-merged-types. Display the merged CodeView type stream. .. option:: --codeview-subsection-bytes. Dump raw contents of CodeView debug sections and records. .. option:: --coff-basereloc. Display the .reloc section. .. option:: --coff-debug-directory. Display the debug directory. .. option:: --coff-tls-directory. Display the TLS directory. .. option:: --coff-directives. Display the .drectve section. .. option:: --coff-exports. Display the export table. .. option:: --coff-imports. Display the import table. .. option:: --coff-load-config. Display the load config. .. option:: --coff-resources. Display the .rsrc section. XCOFF SPECIFIC OPTIONS; ----------------------. The following options are implemented only for the XCOFF file format. .. option:: --auxiliary-header. Display XCOFF Auxiliary header. .. option:: --exception-section. Display XCOFF exception section entries. .. option:: --loader-section-header. Display XCOFF loader section header. .. option:: --loader-section-symbols. Display symbol table of loader section. .. option:: --loader-section-relocations. Display relocation entries of loader section. EXIT STATUS; -----------. :program:`llvm-readobj` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. SEE ALSO; --------. :manpage:`llvm-nm(1)`, :manpage:`llvm-objdump(1)`, :manpage:`llvm-readelf(1)`; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:8274,load,load-config,8274,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,8,['load'],"['load', 'load-config', 'loader', 'loader-section-header', 'loader-section-relocations', 'loader-section-symbols']"
Performance," Complete support for big-endian architectures (PR [#10402](https://github.com/root-project/root/pull/10402)). - Support for `std::pair<T1, T2>` and `std::tuple<Ts...>` fields. - Support for C array fields whose type is of the form `T[N]`. Note that only single-dimension arrays are currently supported. - Improvements to the ROOT file embedding (PR [#10558](https://github.com/root-project/root/pull/10558)). In particular, a `RNTupleReader` or `RDataFrame` object can be created from a `TFile` instance as follows; ```; auto f = TFile::Open(""data.root"");; auto ntpl = f->Get<ROOT::Experimental::RNTuple>(""Events"");. auto reader = ROOT::Experimental::RNTupleReader::Open(ntpl);; // or for RDataFrame; auto rdf = ROOT::Experimental::MakeNTupleDataFrame(ntpl);; ```. - If buffered write is enabled, vector writes are used where possible. In particular, this yields important improvements in storage backends leveraging parallel writes, e.g. in object storages. - Large read/write throughput improvements in the experimental Intel DAOS backend. - `RNTupleWriter::Fill()` now returns the number of uncompressed bytes written, which is align with TTree behavior. - Support for user-defined classes that behave as a collection via the `TVirtualCollectionProxy` interface.; Fields created via `RFieldBase::Create()` automatically detect the presence of a collection proxy at run-time. However, if `RField<T>` (`T` being a class) is used instead, the trait `IsCollectionProxy<T>` must be set for the given type (see PR [#11525](https://github.com/root-project/root/pull/11525) for details).; Note that associative collections are not yet supported. - Some internal support for per field post-read callbacks. This functionality will be presented in upcoming releases through custom I/O rules. Please, report any issues regarding the abovementioned features should you encounter them.; RNTuple is still experimental and is scheduled to become production grade in 2024. Thus, we appreciate feedback and suggesti",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md:9633,throughput,throughput,9633,README/ReleaseNotes/v628/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md,1,['throughput'],['throughput']
Performance," DAG node with the same operator and arguments as; *dag*, but replacing the name of the argument specified by the *key* with; *name*. That *key* could be either an integer index or a string name. ``!setdagop(``\ *dag*\ ``,`` *op*\ ``)``; This operator produces a DAG node with the same arguments as *dag*, but with its; operator replaced with *op*. Example: ``!setdagop((foo 1, 2), bar)`` results in ``(bar 1, 2)``. ``!shl(``\ *a*\ ``,`` *count*\ ``)``; This operator shifts *a* left logically by *count* bits and produces the resulting; value. The operation is performed on a 64-bit integer; the result; is undefined for shift counts outside 0...63. ``!size(``\ *a*\ ``)``; This operator produces the size of the string, list, or dag *a*.; The size of a DAG is the number of arguments; the operator does not count. ``!sra(``\ *a*\ ``,`` *count*\ ``)``; This operator shifts *a* right arithmetically by *count* bits and produces the resulting; value. The operation is performed on a 64-bit integer; the result; is undefined for shift counts outside 0...63. ``!srl(``\ *a*\ ``,`` *count*\ ``)``; This operator shifts *a* right logically by *count* bits and produces the resulting; value. The operation is performed on a 64-bit integer; the result; is undefined for shift counts outside 0...63. ``!strconcat(``\ *str1*\ ``,`` *str2*\ ``, ...)``; This operator concatenates the string arguments *str1*, *str2*, etc., and; produces the resulting string. ``!sub(``\ *a*\ ``,`` *b*\ ``)``; This operator subtracts *b* from *a* and produces the arithmetic difference. ``!subst(``\ *target*\ ``,`` *repl*\ ``,`` *value*\ ``)``; This operator replaces all occurrences of the *target* in the *value* with; the *repl* and produces the resulting value. The *value* can; be a string, in which case substring substitution is performed. The *value* can be a record name, in which case the operator produces the *repl*; record if the *target* record name equals the *value* record name; otherwise it; produces the *va",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst:71849,perform,performed,71849,interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/ProgRef.rst,1,['perform'],['performed']
Performance," Enabling optimization remarks; =============================. There are two modes that are supported for enabling optimization remarks in; LLVM: through remark diagnostics, or through serialized remarks. Remark diagnostics; ------------------. Optimization remarks can be emitted as diagnostics. These diagnostics will be; propagated to front-ends if desired, or emitted by tools like :doc:`llc; <CommandGuide/llc>` or :doc:`opt <CommandGuide/opt>`. .. option:: -pass-remarks=<regex>. Enables optimization remarks from passes whose name match the given (POSIX); regular expression. .. option:: -pass-remarks-missed=<regex>. Enables missed optimization remarks from passes whose name match the given; (POSIX) regular expression. .. option:: -pass-remarks-analysis=<regex>. Enables optimization analysis remarks from passes whose name match the given; (POSIX) regular expression. Serialized remarks; ------------------. While diagnostics are useful during development, it is often more useful to; refer to optimization remarks post-compilation, typically during performance; analysis. For that, LLVM can serialize the remarks produced for each compilation unit to; a file that can be consumed later. By default, the format of the serialized remarks is :ref:`YAML; <yamlremarks>`, and it can be accompanied by a :ref:`section <remarkssection>`; in the object files to easily retrieve it. :doc:`llc <CommandGuide/llc>` and :doc:`opt <CommandGuide/opt>` support the; following options:. ``Basic options``. .. option:: -pass-remarks-output=<filename>. Enables the serialization of remarks to a file specified in <filename>. By default, the output is serialized to :ref:`YAML <yamlremarks>`. .. option:: -pass-remarks-format=<format>. Specifies the output format of the serialized remarks. Supported formats:. * :ref:`yaml <yamlremarks>` (default); * :ref:`yaml-strtab <yamlstrtabremarks>`; * :ref:`bitstream <bitstreamremarks>`. ``Content configuration``. .. option:: -pass-remarks-filter=<regex>. Only pas",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Remarks.rst:2029,optimiz,optimization,2029,interpreter/llvm-project/llvm/docs/Remarks.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Remarks.rst,2,"['optimiz', 'perform']","['optimization', 'performance']"
Performance," Files; --------------------------------. After symbol resolution, the linker tells the LTO shared object which symbols; are needed by native object files. In the example above, the linker reports; that only ``foo1()`` is used by native object files using; ``lto_codegen_add_must_preserve_symbol()``. Next the linker invokes the LLVM; optimizer and code generators using ``lto_codegen_compile()`` which returns a; native object file creating by merging the LLVM bitcode files and applying; various optimization passes. Phase 4 : Symbol Resolution after optimization; ----------------------------------------------. In this phase, the linker reads optimized a native object file and updates the; internal global symbol table to reflect any changes. The linker also collects; information about any changes in use of external symbols by LLVM bitcode; files. In the example above, the linker notes that ``foo4()`` is not used any; more. If dead code stripping is enabled then the linker refreshes the live; symbol information appropriately and performs dead code stripping. After this phase, the linker continues linking as if it never saw LLVM bitcode; files. .. _libLTO:. ``libLTO``; ==========. ``libLTO`` is a shared object that is part of the LLVM tools, and is intended; for use by a linker. ``libLTO`` provides an abstract C interface to use the LLVM; interprocedural optimizer without exposing details of LLVM's internals. The; intention is to keep the interface as stable as possible even when the LLVM; optimizer continues to evolve. It should even be possible for a completely; different compilation technology to provide a different libLTO that works with; their object files and the standard linker tool. ``lto_module_t``; ----------------. A non-native object file is handled via an ``lto_module_t``. The following; functions allow the linker to check if a file (on disk or in a memory buffer) is; a file which libLTO can process:. .. code-block:: c. lto_module_is_object_file(const char*); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst:7877,perform,performs,7877,interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,1,['perform'],['performs']
Performance," Fix - display of labels on X axis with TProfile; 3. Fix - support time display in TMultiGraph; 4. Fix - correctly parse ""optstat"" and ""optfit"" in URL; 5. Fix - correctly update TGraph drawing when X range is changing; 6. Fix - return only TF1/TF2 object when searching function (#158). ## Changes in 5.4.1; 1. Fix - monitoring mode in draw.htm page; 2. Fix - zooming in colz palette; 3. Fix - support both 9.x and 10.x jsdom version in Node.js (#149); 4. Fix - draw axis main line with appropriate attributes (#150); 5. Fix - use axis color when drawing grids lines (#150); 6. Fix - when set pad logx/logy, reset existing user ranges in pad; 7. Fix - avoid too deep calling stack when drawing many graphs or histos (#154); 8. Fix - correctly (re)draw tooltips on canvas with many subpads. ## Changes in 5.4.0; 1. New supported classes:; - TDiamond; - TArc; - TCurlyLine; - TCurlyArc; - TCrown; 2. New draw options:; - ""RX"" and ""RY"" for TGraph to reverse axis; - ""noopt"" for TGraph to disable drawing optimization; - ""CPN"" for TCanvas to create color palette from N last colors; - ""line"" for TGraph2D; 3. New features:; - support LZ4 compression; - tooltips and zooming in TGraphPolar drawings; - TPavesText with multiple underlying paves; - implement all fill styles; - draw borders for TWbox; - draw all objects from TList/TObjArray as they appear in list of primitives; - let enable/disable highlight of extra objects in geometry viewer; - draw axis labels on both sides when pad.fTick[x/y] > 1; - make drawing of TCanvas with many primitives smoother; - add fOptTitle, fOptLogx/y/z fields in JSROOT.gStyle; 4. Behavior changes:; - disable automatic frame adjustment, can be enabled with ""&adjframe"" parameter in URL; - when drawing TH2/TH3 scatter plots, always generate same ""random"" pattern; - use barwidth/baroffset parameters in lego plots; 5. Bug fixes:; - use same number of points to draw lines and markers on the TGraph; - correctly draw filled TArrow endings; - let combine ""L"" or ""C"" TGr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:35830,optimiz,optimization,35830,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['optimiz'],['optimization']
Performance," For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. Once issued, an instruction is moved to ``IssuedInst`` set until it is ready to; retire. :program:`llvm-mca` ensures that writes are committed in-order. However,; an instruction is allowed to commit writes and retire out-of-order if; ``RetireOOO`` property is true for at least one of its writes. Custom Behaviour; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Due to certain instructions not being expressed perfectly within their; scheduling model, :program:`llvm-mca` isn't always able to simulate them; perfectly. Modifying the sched",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:43060,load,load,43060,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,['load'],['load']
Performance," G_FSQRT, G_FFLOOR, G_FRINT, G_FNEARBYINT; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These correspond to the standard C functions of the same name. G_INTRINSIC_TRUNC; ^^^^^^^^^^^^^^^^^. Returns the operand rounded to the nearest integer not larger in magnitude than the operand. G_INTRINSIC_ROUND; ^^^^^^^^^^^^^^^^^. Returns the operand rounded to the nearest integer. G_LROUND, G_LLROUND; ^^^^^^^^^^^^^^^^^^^. Returns the source operand rounded to the nearest integer with ties away from; zero. See the LLVM LangRef entry on '``llvm.lround.*'`` for details on behaviour. .. code-block:: none. %rounded_32:_(s32) = G_LROUND %round_me:_(s64); %rounded_64:_(s64) = G_LLROUND %round_me:_(s64). Vector Specific Operations; --------------------------. G_CONCAT_VECTORS; ^^^^^^^^^^^^^^^^. Concatenate two vectors to form a longer vector. G_BUILD_VECTOR, G_BUILD_VECTOR_TRUNC; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Create a vector from multiple scalar registers. No implicit; conversion is performed (i.e. the result element type must be the; same as all source operands). The _TRUNC version truncates the larger operand types to fit the; destination vector elt type. G_INSERT_VECTOR_ELT; ^^^^^^^^^^^^^^^^^^^. Insert an element into a vector. G_EXTRACT_VECTOR_ELT; ^^^^^^^^^^^^^^^^^^^^. Extract an element from a vector. G_SHUFFLE_VECTOR; ^^^^^^^^^^^^^^^^. Concatenate two vectors and shuffle the elements according to the mask operand.; The mask operand should be an IR Constant which exactly matches the; corresponding mask for the IR shufflevector instruction. Vector Reduction Operations; ---------------------------. These operations represent horizontal vector reduction, producing a scalar result. G_VECREDUCE_SEQ_FADD, G_VECREDUCE_SEQ_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SEQ variants perform reductions in sequential order. The first operand is; an initial scalar accumulator value, and the second operand is the vector to reduce. G_VECREDUCE_FADD, G_VECRED",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:13620,perform,performed,13620,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,1,['perform'],['performed']
Performance," GetZaxis for THStack. - Fix Graph Errorbar Offsets for the new Marker Styles and thick markers. - When the palette width is bigger than the palette height, the palette; is automatically drawn horizontally. - THStack::GetXaxis->SetRange did not auto-zoom Yaxis range. - The Paint method of THStack always redrew the histograms in the sub-pads defined by the; THStack drawing option ""pads"". Like the ""pad dividing"" the ""histograms' drawing"" should be; done only the first time the THStack is painted otherwise any additional graphics objects; added in one of the pads (created by the ""pads"" option) will be removed. - Improve TRatioPlot axes drawing. ## Math Libraries. - `RVec` has been heavily re-engineered in order to add a small buffer optimization and to streamline its internals. The change should provide a small performance boost to; applications that make heavy use of `RVec`s and should otherwise be user-transparent. Please report any issues you should encounter.; - I/O support of `RVec` objects has been optimized. As a side-effect, `RVec`s can now be read back as `std::vector`s and vice-versa.; - Add `ROOT::VecOps::Drop`, an operation that removes `RVec` elements at the specified indices.; - handy aliases `ROOT::RVecI`, `ROOT::RVecD`, `ROOT::RVecF`, ..., have been introduced as short-hands for `RVec<int>`, `RVec<double>`, `RVec<float>`, ...; - Add `VecOps::StableArgsort` and `VecOps::StableSort` operations. ## RooFit Libraries. ### Experimental CUDA support for RooFit's `BatchMode`. RooFit's [`BatchMode`](https://root.cern/doc/master/classRooAbsPdf.html#a8f802a3a93467d5b7b089e3ccaec0fa8) has been around; [since ROOT 6.20](https://root.cern/doc/v620/release-notes.html#fast-function-evaluation-and-vectorisation).; It was further [improved in ROOT 6.24](https://root.cern/doc/v624/release-notes.html#massive-speed-up-of-roofits-batchmode-on-cpus-with-vector-extensions) to use vector extensions of modern CPUs without recompiling ROOT, introducing the new `RooBatchCompute` li",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md:14336,optimiz,optimized,14336,README/ReleaseNotes/v626/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v626/index.md,1,['optimiz'],['optimized']
Performance," If OpenCL, omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than the load; atomic value being; acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; bein",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:366693,load,load,366693,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance," If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - Must happen before; the following; store.; - Ensures that all; global memory; operations have; completed before; performing the; store that is being; released. 2. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt vscnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:356929,load,load,356929,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," If the bit operand value is 1 vectorization is enabled. A value of; 0 disables vectorization:. .. code-block:: llvm. !0 = !{!""llvm.loop.vectorize.enable"", i1 0}; !1 = !{!""llvm.loop.vectorize.enable"", i1 1}. '``llvm.loop.vectorize.predicate.enable``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This metadata selectively enables or disables creating predicated instructions; for the loop, which can enable folding of the scalar epilogue loop into the; main loop. The first operand is the string; ``llvm.loop.vectorize.predicate.enable`` and the second operand is a bit. If; the bit operand value is 1 vectorization is enabled. A value of 0 disables; vectorization:. .. code-block:: llvm. !0 = !{!""llvm.loop.vectorize.predicate.enable"", i1 0}; !1 = !{!""llvm.loop.vectorize.predicate.enable"", i1 1}. '``llvm.loop.vectorize.scalable.enable``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This metadata selectively enables or disables scalable vectorization for the; loop, and only has any effect if vectorization for the loop is already enabled.; The first operand is the string ``llvm.loop.vectorize.scalable.enable``; and the second operand is a bit. If the bit operand value is 1 scalable; vectorization is enabled, whereas a value of 0 reverts to the default fixed; width vectorization:. .. code-block:: llvm. !0 = !{!""llvm.loop.vectorize.scalable.enable"", i1 0}; !1 = !{!""llvm.loop.vectorize.scalable.enable"", i1 1}. '``llvm.loop.vectorize.width``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This metadata sets the target width of the vectorizer. The first; operand is the string ``llvm.loop.vectorize.width`` and the second; operand is an integer specifying the width. For example:. .. code-block:: llvm. !0 = !{!""llvm.loop.vectorize.width"", i32 4}. Note that setting ``llvm.loop.vectorize.width`` to 1 disables; vectorization of the loop. If ``llvm.loop.vectorize.width`` is set to; 0 or if the loop does not have this metadata the width will be; det",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:298595,scalab,scalable,298595,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['scalab'],['scalable']
Performance," In practice, however, dereferencing a ``null`` pointer is; extremely rare in well-behaved Java programs, and typically the null; check can be folded into a nearby memory operation that operates on; the same memory location. The Fault Map Section; =====================. Information about implicit checks generated by LLVM are put in a; special ""fault map"" section. On Darwin this section is named; ``__llvm_faultmaps``. The format of this section is. .. code-block:: none. Header {; uint8 : Fault Map Version (current version is 1); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; FunctionInfo[NumFunctions] {; uint64 : FunctionAddress; uint32 : NumFaultingPCs; uint32 : Reserved (expected to be 0); FunctionFaultInfo[NumFaultingPCs] {; uint32 : FaultKind; uint32 : FaultingPCOffset; uint32 : HandlerPCOffset; }; }. FailtKind describes the reason of expected fault. Currently three kind; of faults are supported:. 1. ``FaultMaps::FaultingLoad`` - fault due to load from memory.; 2. ``FaultMaps::FaultingLoadStore`` - fault due to instruction load and store.; 3. ``FaultMaps::FaultingStore`` - fault due to store to memory. The ``ImplicitNullChecks`` pass; ===============================. The ``ImplicitNullChecks`` pass transforms explicit control flow for; checking if a pointer is ``null``, like:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %ptr_is_null = icmp i32* %ptr, null; br i1 %ptr_is_null, label %is_null, label %not_null, !make.implicit !0. not_null:; %t = load i32, i32* %ptr; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. !0 = !{}. to control flow implicit in the instruction loading or storing through; the pointer being null checked:. .. code-block:: llvm. %ptr = call i32* @get_ptr(); %t = load i32, i32* %ptr ;; handler-pc = label %is_null; br label %do_something_with_t. is_null:; call void @HFC(); unreachable. This transform happens at the ``MachineInstr`` level, not the LLVM IR; level (so t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst:1833,load,load,1833,interpreter/llvm-project/llvm/docs/FaultMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/FaultMaps.rst,1,['load'],['load']
Performance," In this way it's not different; from someone who would check out all the projects with SVN today. If you want to avoid checking out all the sources, you can hide the other; directories using a Git sparse checkout::. git config core.sparseCheckout true; echo /compiler-rt > .git/info/sparse-checkout; git read-tree -mu HEAD. The data for all sub-projects is still in your `.git` directory, but in your; checkout, you only see `compiler-rt`.; Before you push, you'll need to fetch and rebase (`git pull --rebase`) as; usual. Note that when you fetch you'll likely pull in changes to sub-projects you don't; care about. If you are using sparse checkout, the files from other projects; won't appear on your disk. The only effect is that your commit hash changes. You can check whether the changes in the last fetch are relevant to your commit; by running::. git log origin/main@{1}..origin/main -- libcxx. This command can be hidden in a script so that `git llvmpush` would perform all; these steps, fail only if such a dependent change exists, and show immediately; the change that prevented the push. An immediate repeat of the command would; (almost) certainly result in a successful push.; Note that today with SVN or git-svn, this step is not possible since the; ""rebase"" implicitly happens while committing (unless a conflict occurs). Checkout/Clone Multiple Projects, with Commit Access; ----------------------------------------------------. Let's look how to assemble llvm+clang+libcxx at a given revision. Currently; ^^^^^^^^^. ::. svn co https://llvm.org/svn/llvm-project/llvm/trunk llvm -r $REVISION; cd llvm/tools; svn co https://llvm.org/svn/llvm-project/clang/trunk clang -r $REVISION; cd ../projects; svn co https://llvm.org/svn/llvm-project/libcxx/trunk libcxx -r $REVISION. Or using git-svn::. git clone https://llvm.org/git/llvm.git; cd llvm/; git svn init https://llvm.org/svn/llvm-project/llvm/trunk --username=<username>; git config svn-remote.svn.fetch :refs/remotes/origin/main; gi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:14827,perform,perform,14827,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,1,['perform'],['perform']
Performance," Instructions from the critical sequence are expected to significantly impact; performance. By construction, the accuracy of this analysis is strongly; dependent on the simulation and (as always) by the quality of the processor; model in llvm. Bottleneck analysis is currently not supported for processors with an in-order; backend. Extra Statistics to Further Diagnose Performance Issues; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; The ``-all-stats`` command line option enables extra statistics and performance; counters for the dispatch logic, the reorder buffer, the retire control unit,; and the register file. Below is an example of ``-all-stats`` output generated by :program:`llvm-mca`; for 300 iterations of the dot-product example discussed in the previous; sections. .. code-block:: none. Dynamic Dispatch Stall Cycles:; RAT - Register unavailable: 0; RCU - Retire tokens unavailable: 0; SCHEDQ - Scheduler full: 272 (44.6%); LQ - Load queue full: 0; SQ - Store queue full: 0; GROUP - Static restrictions on the dispatch group: 0. Dispatch Logic - number of cycles where we saw N micro opcodes dispatched:; [# dispatched], [# cycles]; 0, 24 (3.9%); 1, 272 (44.6%); 2, 314 (51.5%). Schedulers - number of cycles where we saw N micro opcodes issued:; [# issued], [# cycles]; 0, 7 (1.1%); 1, 306 (50.2%); 2, 297 (48.7%). Scheduler's queue usage:; [1] Resource name.; [2] Average number of used buffer entries.; [3] Maximum number of used buffer entries.; [4] Total number of buffer entries. [1] [2] [3] [4]; JALU01 0 0 20; JFPU01 17 18 18; JLSAGU 0 0 12. Retire Control Unit - number of cycles where we saw N instructions retired:; [# retired], [# cycles]; 0, 109 (17.9%); 1, 102 (16.7%); 2, 399 (65.4%). Total ROB Entries: 64; Max Used ROB Entries: 35 ( 54.7% ); Average Used ROB Entries per cy: 32 ( 50.0% ). Register File statistics:; Total number of mappings created: 900; Max number of mappings used: 35. * Register File #1 -- JFpuPRF:; Number of physical registers: 72; Tot",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:29169,queue,queue,29169,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,['queue'],['queue']
Performance," Interpreter on the Bela Platform <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_; - Jack Armitage 2019; - Cling has been installed on a BeagleBoard to bring live coding to the Bela interactive audio platform.; * - `Implementation of GlobalModuleIndex in ROOT and Cling <https://indico.cern.ch/event/840376/contributions/3525646/attachments/1895398/3127159/GSoC_Presentation__GMI.pdf>`_; - *Arpitha Raghunandan* 2012 Google Summer of Code GSoC; - GlobalModuleIndex can be used for improving ROOT’s and Cling’s performance ; * - `Example project using cling as library <https://github.com/root-project/cling/tree/master/tools/demo>`_; - *Axel Naumann* 2016 GitHub; - This video showcases how to use Cling as a library, and shows how to set up a simple CMake configuration that uses Cling.; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - *Mika* 2015 Youtube; - In this tutorial, a developer tries Cling for the first time by uploading a few simple C++ user-cases onto Cling, involving also the loading of external files; * - `Building an Order Book in C++ <https://www.youtube.com/watch?v=fxN4xEZvrxI>`_; - *Dimitri Nesteruk* 2015 Youtube; - This demo shows how to build a simple order book using C++, CLion, Google Test and, of course, Cling. ; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - Dimitri Nesteruk 2015 Youtube; - This tutorial describes Cling’s general features. You will learn how to start Cling on Ubuntu, how to write a simple expression (N=5, N++) and how to define a Class for calculating body mass index. ; * - `Cling Interactive OpenGL Demo <https://www.youtube.com/watch?v=eoIuqLNvzFs>`_; - *Alexander Penev* 2012 Youtube; - This demo shows how to use Cling for interactive OpenGL. A rotating triangle with changing color, a static figure, and a figure with light effects are created.; ; . .. list-table:: Language Interoperability with Cling:; :widths: 25 25 50; :header-rows:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:4870,load,loading,4870,interpreter/cling/docs/chapters/references.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst,1,['load'],['loading']
Performance," Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare <pointer type>; @llvm.experimental.gc.relocate(token %statepoint_token,; i32 %base_offset,; i32 %pointer_offset). Overview:; """""""""""""""""". A ``gc.relocate`` returns the potentially relocated value of a pointer; at the safepoint. Operands:; """""""""""""""""". The first argument is the ``gc.statepoint`` which starts the; safepoint sequence of which this ``gc.relocation`` is a part.; Despite the typing of this as a generic token, *only* the value defined; by a ``gc.statepoint`` is legal here. The second and third arguments are both indices into operands of the; corresponding statepoint's :ref:`gc-live <ob_gc_live>` operand bundle. The second argument is an index which specifies the allocation for the pointer; being relocated. The associated value must be within the object with which the; pointer being relocated is associated. The optimizer is free to change *which*; interior derived pointer is reported, provided that it does not replace an; actual base pointer with another interior derived pointer. Collectors are; allowed to rely on the base pointer operand remaining an actual base pointer if; so constructed. The third argument is an index which specify the (potentially) derived pointer; being relocated. It is legal for this index to be the same as the second; argument if-and-only-if a base pointer is being relocated. Semantics:; """""""""""""""""""". The return value of ``gc.relocate`` is the potentially relocated value; of the pointer specified by its arguments. It is unspecified how the; value of the returned pointer relates to the argument to the; ``gc.statepoint`` other than that a) it points to the same source; language object with the same offset, and b) the 'based-on'; relationship of the newly relocated pointers is a projection of the; unrelocated pointers. In particular, the integer value of the pointer; returned is unspecified. A ``gc.relocate`` is modeled as a ``readnone`` pure function. It",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:505842,optimiz,optimizer,505842,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizer']
Performance," It is higher performance than global memory. The data store; (DS) instructions can be used to access it. **Private**; The private address space uses the hardware scratch memory support which; automatically allocates memory when it creates a wavefront and frees it when; a wavefronts terminates. The memory accessed by a lane of a wavefront for any; given private address will be different to the memory accessed by another lane; of the same or different wavefront for the same private address. If a kernel dispatch uses scratch, then the hardware allocates memory from a; pool of backing memory allocated by the runtime for each wavefront. The lanes; of the wavefront access this using dword (4 byte) interleaving. The mapping; used from private address to backing memory address is:. ``wavefront-scratch-base +; ((private-address / 4) * wavefront-size * 4) +; (wavefront-lane-id * 4) + (private-address % 4)``. If each lane of a wavefront accesses the same private address, the; interleaving results in adjacent dwords being accessed and hence requires; fewer cache lines to be fetched. There are different ways that the wavefront scratch base address is; determined by a wavefront (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). Scratch memory can be accessed in an interleaved manner using buffer; instructions with the scratch buffer descriptor and per wavefront scratch; offset, by the scratch instructions, or by flat instructions. Multi-dword; access is not supported except by flat and scratch instructions in; GFX9-GFX11. Code that manipulates the stack values in other lanes of a wavefront,; such as by ``addrspacecast``-ing stack pointers to generic ones and taking offsets; that reach other lanes or by explicitly constructing the scratch buffer descriptor,; triggers undefined behavior when it modifies the scratch values of other lanes.; The compiler may assume that such modifications do not occur.; When using code object V5 ``LIBOMPTARGET_STACK_SIZE`` may be used to pro",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:27454,cache,cache,27454,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," JSON format.; 2. Fix small error in dtree.js - one should always set; last sibling (_ls) property while tree can be dynamically changed.; 3. In JSRootCore.js provide central function, which handles different kinds; of XMLHttpRequest. Use only async requests, also when getting file header.; 4. Fully reorganize data management in file/tree/directory/collection hierarchical; display. Now complete description collected in HPainter class and decoupled from; visualization, performed with dTree.js.; 5. Remove all global variables from the code.; 6. Automatic scripts/style loading handled via JSROOT.loadScript() function.; One can specify arbitrary scripts list, which asynchronously loaded by browser.; 7. Method to build simple GUI changed and more simplified :). The example in index.htm.; While loadScript and AssertPrerequisites functions moved to JSROOT, one; can easily build many different kinds of GUIs, reusing provided JSRootCore.js functions.; 8. In example.htm also use AssertPrerequisites to load necessary scripts.; This helps to keep code up-to-date even by big changes in JavaScript code.; 9. Provide monitoring of online THttpServer with similar interface as for ROOT files.; 10. Fix several errors in TKey Streamer, use member names as in ROOT itself.; 11. Keep the only version identifier JSROOT.version for JS code; 12. One can specify in JSROOT.AssertPrerequisites functionality which is required.; One could specify '2d', 'io' (default) or '3d'.; 13. Use new AssertPrerequisites functionality to load only required functionality.; 14. When displaying single element, one could specify draw options and monitor property like:; <http://localhost:8080/Files/job1.root/hpxpy/draw.htm?opt=col&monitor=2000>; Such link is best possibility to integrate display into different HTML pages,; using `<iframe/>` tag like:; `<iframe src=""http://localhost:8080/Files/job1.root/hpx/draw.htm""`; `style=""width: 800px; height:600px""></iframe>`; 15. Remove 'JSROOTIO.' prefix from _typename. Now ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:74832,load,load,74832,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['load'],['load']
Performance," Java; functions for example... > c. How do we get more high-level information into the VM while keeping; > to a low-level VM design?; > o Explicit array references as operands? An alternative is; > to have just an array type, and let the index computations be; > separate 3-operand instructions. C. In the model I was thinking of (subject to change of course), we; would just have an array type (distinct from the pointer; types). This would allow us to have arbitrarily complex index; expressions, while still distinguishing ""load"" from ""Array load"",; for example. Perhaps also, switch jump tables would be first class; types as well? This would allow better reasoning about the program. 5. Support dynamic loading of code from various sources. Already; mentioned above was the example of loading java bytecodes, but we want; to support dynamic loading of VM code as well. This makes the job of; the runtime compiler much more interesting: it can do interprocedural; optimizations that the static compiler can't do, because it doesn't; have all of the required information (for example, inlining from; shared libraries, etc...). 6. Define a set of generally useful annotations to add to the VM; representation. For example, a function can be analysed to see if it; has any sideeffects when run... also, the MOD/REF sets could be; calculated, etc... we would have to determine what is reasonable. This; would generally be used to make IP optimizations cheaper for the; runtime compiler... > o Explicit instructions to handle aliasing, e.g.s:; > -- an instruction to say ""I speculate that these two values are not; > aliased, but check at runtime"", like speculative execution in; > EPIC?; > -- or an instruction to check whether two values are aliased and; > execute different code depending on the answer, somewhat like; > predicated code in EPIC. These are also very good points... if this can be determined at compile; time. I think that an epic style of representation (not the instruction; packi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt:5842,optimiz,optimizations,5842,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,1,['optimiz'],['optimizations']
Performance," LDS operations of a WGP are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; WGP. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations.; Completion of load/store/sample operations are reported to a wavefront in; execution order of other load/store/sample operations performed by that; wavefront.; * The vector memory operations access a vector L0 cache. There is a single L0; cache per CU. Each SIMD of a CU accesses the same L0 cache. Therefore, no; special action is required for coherence between the lanes of a single; wavefront. However, a ``buffer_gl0_inv`` is required for coherence between; wavefronts executing in the same work-group as they may be executing on SIMDs; of different CUs that access different L0s. A ``buffer_gl0_inv`` is also; required for coherence between wavefronts executing in different work-groups; as they may be executing on different WGPs.; * The scalar memory operations access a scalar L0 cache shared by all wavefronts; on a WGP. The scalar and vector L0 caches are not coherent. However, scalar; operations are used in a restricted way so do not impact the memory model. See; :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory L0 caches use an L1 cache shared by all WGPs on; the same SA. Therefore, no special action is required for coherence between; the wavefronts o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:336795,cache,cache,336795,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," LLVM with ``%1``). Again, ``MemoryPhi``\ s don't correspond to any LLVM; Instruction, so the line directly below a ``MemoryPhi`` isn't special. Going from the top down:. - ``6 = MemoryPhi({entry,1},{if.end,4})`` notes that, when entering; ``while.cond``, the reaching definition for it is either ``1`` or ``4``. This; ``MemoryPhi`` is referred to in the textual IR by the number ``6``.; - ``2 = MemoryDef(6)`` notes that ``store i8 0, ptr %p1`` is a definition,; and its reaching definition before it is ``6``, or the ``MemoryPhi`` after; ``while.cond``. (See the `Use and Def optimization`_ and `Precision`_; sections below for why this ``MemoryDef`` isn't linked to a separate,; disambiguated ``MemoryPhi``.); - ``3 = MemoryDef(6)`` notes that ``store i8 0, ptr %p2`` is a definition; its; reaching definition is also ``6``.; - ``5 = MemoryPhi({if.then,2},{if.else,3})`` notes that the clobber before; this block could either be ``2`` or ``3``.; - ``MemoryUse(5)`` notes that ``load i8, ptr %p1`` is a use of memory, and that; it's clobbered by ``5``.; - ``4 = MemoryDef(5)`` notes that ``store i8 2, ptr %p2`` is a definition; its; reaching definition is ``5``.; - ``MemoryUse(1)`` notes that ``load i8, ptr %p3`` is just a user of memory,; and the last thing that could clobber this use is above ``while.cond`` (e.g.; the store to ``%p3``). In memory versioning parlance, it really only depends on; the memory version 1, and is unaffected by the new memory versions generated since; then. As an aside, ``MemoryAccess`` is a ``Value`` mostly for convenience; it's not; meant to interact with LLVM IR. Design of MemorySSA; ===================. ``MemorySSA`` is an analysis that can be built for any arbitrary function. When; it's built, it does a pass over the function's IR in order to build up its; mapping of ``MemoryAccess``\ es. You can then query ``MemorySSA`` for things; like the dominance relation between ``MemoryAccess``\ es, and get the; ``MemoryAccess`` for any given ``Instruction`` .",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:7609,load,load,7609,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['load'],['load']
Performance," MachineMemOperand in addition to explicit; operands. If the result size is larger than the memory size, the; high bits are undefined, sign-extended, or zero-extended respectively. Only G_LOAD is valid if the result is a vector type. If the result is larger; than the memory size, the high elements are undefined (i.e. this is not a; per-element, vector anyextload). Unlike in SelectionDAG, atomic loads are expressed with the same; opcodes as regular loads. G_LOAD, G_SEXTLOAD and G_ZEXTLOAD may all; have atomic memory operands. G_INDEXED_LOAD; ^^^^^^^^^^^^^^. Generic indexed load. Combines a GEP with a load. $newaddr is set to $base + $offset.; If $am is 0 (post-indexed), then the value is loaded from $base; if $am is 1 (pre-indexed); then the value is loaded from $newaddr. G_INDEXED_SEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is sign-extending, as with G_SEXTLOAD. G_INDEXED_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is zero-extending, as with G_ZEXTLOAD. G_STORE; ^^^^^^^. Generic store. Expects a MachineMemOperand in addition to explicit; operands. If the stored value size is greater than the memory size,; the high bits are implicitly truncated. If this is a vector store, the; high elements are discarded (i.e. this does not function as a per-lane; vector, truncating store). G_INDEXED_STORE; ^^^^^^^^^^^^^^^. Combines a store with a GEP. See description of G_INDEXED_LOAD for indexing behaviour. G_ATOMIC_CMPXCHG_WITH_SUCCESS; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic atomic cmpxchg with internal success check. Expects a; MachineMemOperand in addition to explicit operands. G_ATOMIC_CMPXCHG; ^^^^^^^^^^^^^^^^. Generic atomic cmpxchg. Expects a MachineMemOperand in addition to explicit; operands. G_ATOMICRMW_XCHG, G_ATOMICRMW_ADD, G_ATOMICRMW_SUB, G_ATOMICRMW_AND,; G_ATOMICRMW_NAND, G_ATOMICRMW_OR, G_ATOMICRMW_XOR, G_ATOMICRMW_MAX,; G_ATOMICRMW_MIN, G_ATOMICRMW_UMAX, G_ATOMICRMW_UMIN, G_ATOMICRMW_FA",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:16517,load,load,16517,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,2,"['load', 'perform']","['load', 'performed']"
Performance," MakeStruct() { return DeviceS(); }. // Now host and device code can call MakeStruct(). Unfortunately, this idiom isn't compatible with nvcc, because it doesn't allow; you to overload based on the H/D attributes. Here's an idiom that works with; both clang and nvcc:. .. code-block:: c++. struct HostS { ... };; struct DeviceS { ... };. #ifdef __NVCC__; #ifndef __CUDA_ARCH__; __host__ HostS MakeStruct() { return HostS(); }; #else; __device__ DeviceS MakeStruct() { return DeviceS(); }; #endif; #else; __host__ HostS MakeStruct() { return HostS(); }; __device__ DeviceS MakeStruct() { return DeviceS(); }; #endif. // Now host and device code can call MakeStruct(). Hopefully you don't have to do this sort of thing often. Optimizations; =============. Modern CPUs and GPUs are architecturally quite different, so code that's fast; on a CPU isn't necessarily fast on a GPU. We've made a number of changes to; LLVM to make it generate good GPU code. Among these changes are:. * `Straight-line scalar optimizations <https://goo.gl/4Rb9As>`_ -- These; reduce redundancy within straight-line code. * `Aggressive speculative execution; <https://llvm.org/docs/doxygen/html/SpeculativeExecution_8cpp_source.html>`_; -- This is mainly for promoting straight-line scalar optimizations, which are; most effective on code along dominator paths. * `Memory space inference; <https://llvm.org/doxygen/NVPTXInferAddressSpaces_8cpp_source.html>`_ --; In PTX, we can operate on pointers that are in a particular ""address space""; (global, shared, constant, or local), or we can operate on pointers in the; ""generic"" address space, which can point to anything. Operations in a; non-generic address space are faster, but pointers in CUDA are not explicitly; annotated with their address space, so it's up to LLVM to infer it where; possible. * `Bypassing 64-bit divides; <https://llvm.org/docs/doxygen/html/BypassSlowDivision_8cpp_source.html>`_ --; This was an existing optimization that we enabled for the PTX backend.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:18437,optimiz,optimizations,18437,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,1,['optimiz'],['optimizations']
Performance," Making a volume with a given shape in one step; TGeoVolume *vol = gGeoManager->MakeBox(""VNAME"",ptrMed,dx,dy,dz);; TGeoVolume *vol = gGeoManager->MakeTubs(""VNAME"",ptrMed,rmin,rmax,; dz,phi1,phi2);. // See class TGeoManager for the rest of shapes.; // Making a volume with a given shape with a unique prototype; TGeoVolume *vol = gGeoManager->Volume(""VNAME"",""XXXX"",nmed,upar,; npar);. // Where XXXX stands for the first 4 letters of the specific shape; // classes, nmed is the medium number, upar is an Double_t * array; // of the shape parameters and npar is the number of parameters.; // This prototype allows (npar = 0) to define volumes with shape; // defined only at positioning time (volumes defined in this way; // need to be positioned using TGeoManager::Node() method); ```. #### Positioned Volumes (Nodes). Geometrical modeling is a difficult task when the number of different; geometrical objects is 106-108. This is more or less the case for; detector geometries of complex experiments, where a ‘flat' CSG model; description cannot scale with the current CPU performances. This is the; reason why models like GEANT [1] introduced an additional dimension; (depth) in order to reduce the complexity of the problem. This concept; is also preserved by the ROOT modeller and introduces a pure geometrical; constraint between objects (volumes in our case) - containment. This; means in fact that any positioned volume has to be contained by another.; Now what means contained and positioned?. - We will say that a volume `contains` a point if this is inside the; shape associated to the volume. For instance, a volume having a box; shape will contain all points `P=(X,Y,Z)` verifying the conditions:; `Abs(Pi)dXi`. The points on the shape boundaries are considered as; inside the volume. The volume contains a daughter if it contains all; the points contained by the daughter.; - The definition of containment works of course only with points; defined in the local coordinate system of the consid",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:65854,perform,performances,65854,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['perform'],['performances']
Performance," Mask out bits from all three loads.; ```. ###### Preserving the flags while hardening loaded values on Haswell, Zen, and newer processors. Sadly, there are no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of the loaded value. This avoids; increasing register pressure by unfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:27551,load,loaded,27551,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,3,['load'],"['load', 'loaded']"
Performance," MemorySanitizer; -fsanitize-recover=<value>; Enable recovery for specified sanitizers; -fsanitize-stats Enable sanitizer statistics gathering.; -fsanitize-thread-atomics; Enable atomic operations instrumentation in ThreadSanitizer (default); -fsanitize-thread-func-entry-exit; Enable function entry/exit instrumentation in ThreadSanitizer (default); -fsanitize-thread-memory-access; Enable memory access instrumentation in ThreadSanitizer (default); -fsanitize-trap=<value> Enable trapping for specified sanitizers; -fsanitize-undefined-strip-path-components=<number>; Strip (or keep only, if negative) a given number of path components when emitting check metadata.; -fsanitize=<check> Turn on runtime checks for various forms of undefined or suspicious; behavior. See user manual for available checks; -fsplit-lto-unit Enables splitting of the LTO unit.; -fstandalone-debug Emit full debug info for all types used by the program; -fstrict-aliasing	 Enable optimizations based on strict aliasing rules; -fsyntax-only Run the preprocessor, parser and semantic analysis stages; -fwhole-program-vtables Enables whole-program vtable optimization. Requires -flto; -gcodeview-ghash Emit type record hashes in a .debug$H section; -gcodeview Generate CodeView debug information; -gline-directives-only Emit debug line info directives only; -gline-tables-only Emit debug line number tables only; -miamcu Use Intel MCU ABI; -mllvm <value> Additional arguments to forward to LLVM's option processing; -nobuiltininc Disable builtin #include directories; -Qunused-arguments Don't emit warning for unused driver arguments; -R<remark> Enable the specified remark; --target=<value> Generate code for the given target; --version Print version information; -v Show commands to run and use verbose output; -W<warning> Enable the specified warning; -Xclang <arg> Pass <arg> to the clang compiler. The /clang: Option; ^^^^^^^^^^^^^^^^^^. When clang-cl is run with a set of ``/clang:<arg>`` options, it will gather all; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:185311,optimiz,optimizations,185311,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,2,['optimiz'],"['optimization', 'optimizations']"
Performance," More Information on R interpolation; [here](http://stat.ethz.ch/R-manual/R-patched/library/stats/html/approxfun.html). ~~~{.cxx}; #include<TRInterface.h>; #include<TRandom.h>; #include<vector>. void Interpolation(); {; ROOT::R::TRInterface &r=ROOT::R::TRInterface::Instance();; //Creating points; TRandom rg;; std::vector<Double_t> x(10),y(10);; for(int i=0;i<10;i++); {; x[i]=i;; y[i]=rg.Gaus();; }. r[""x""]=x;; r[""y""]=y;. r<<""dev.new()"";//Required to activate new window for plotting; //Plot parameter. Plotting using two rows and one column; r<<""par(mfrow = c(2,1))"";. //plotting the points; r<<""plot(x, y, main = 'approx(.) and approxfun(.)')"";. //The function ""approx"" returns a list with components x and y,; //containing n coordinates which interpolate the given data points according to the method (and rule) desired.; r<<""points(approx(x, y), col = 2, pch = '*')"";; r<<""points(approx(x, y, method = 'constant'), col = 4, pch = '*')"";. //The function ""approxfun"" returns a function performing (linear or constant); //interpolation of the given data.; //For a given set of x values, this function will return the corresponding interpolated values.; r<<""f <- approxfun(x, y)"";. r<<""curve(f(x), 0, 11, col = 'green2')"";; r<<""points(x, y)"";. //using approxfun with const method; r<<""fc <- approxfun(x, y, method = 'const')"";; r<<""curve(fc(x), 0, 10, col = 'darkblue', add = TRUE)"";; // different interpolation on left and right side :; r<<""plot(approxfun(x, y, rule = 2:1), 0, 11,col = 'tomato', add = TRUE, lty = 3, lwd = 2)"";; }; ~~~; The image shows the interpolated function plotted within R:; \image html R_image3.png. ## Integration (Passing vectorized function to R); Numerical integration using R passing the function from ROOT. ~~~{.cxx}; #include<TMath.h>; #include<TRInterface.h>; #include<Math/Integrator.h>; #include<TF1.h>. //To integrate using R the function must be vectorized; //The idea is just to receive a vector like an argument,to evaluate; //every element saving the result",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md:21555,perform,performing,21555,bindings/r/doc/users-guide/ROOTR_Users_Guide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/r/doc/users-guide/ROOTR_Users_Guide.md,1,['perform'],['performing']
Performance," Most layers that derived from IRLayer can rely on this default implementation; of the ``add`` method. These two operations, ``add`` and ``emit``, together constitute the layer; concept: A layer is a way to wrap a part of a compiler pipeline (in this case; the ""opt"" phase of an LLVM compiler) whose API is opaque to ORC with an; interface that ORC can call as needed. The add method takes an; module in some input program representation (in this case an LLVM IR module); and stores it in the target ``JITDylib``, arranging for it to be passed back; to the layer's emit method when any symbol defined by that module is requested.; Each layer can complete its own work by calling the ``emit`` method of its base; layer. For example, in this tutorial our IRTransformLayer calls through to; our IRCompileLayer to compile the transformed IR, and our IRCompileLayer in; turn calls our ObjectLayer to link the object file produced by our compiler. So far we have learned how to optimize and compile our LLVM IR, but we have; not focused on when compilation happens. Our current REPL optimizes and; compiles each function as soon as it is referenced by any other code,; regardless of whether it is ever called at runtime. In the next chapter we; will introduce a fully lazy compilation, in which functions are not compiled; until they are first called at run-time. At this point the trade-offs get much; more interesting: the lazier we are, the quicker we can start executing the; first function, but the more often we will have to pause to compile newly; encountered functions. If we only code-gen lazily, but optimize eagerly, we; will have a longer startup time (as everything is optimized at that time) but; relatively short pauses as each function just passes through code-gen. If we; both optimize and code-gen lazily we can start executing the first function; more quickly, but we will have longer pauses as each function has to be both; optimized and code-gen'd when it is first executed. Things bec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst:10386,optimiz,optimize,10386,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,1,['optimiz'],['optimize']
Performance," Name Description; ======= ======= ================ =========================================; 0:9 10 bits Work-Item Id X Work-item id in X; dimension of work-group for; wavefront lane. Always initialized. 10:19 10 bits Work-Item Id Y Work-item id in Y; dimension of work-group for; wavefront lane. Initialized if enable_vgpr_workitem_id >; 0, otherwise set to 0.; 20:29 10 bits Work-Item Id Z Work-item id in Z; dimension of work-group for; wavefront lane. Initialized if enable_vgpr_workitem_id >; 1, otherwise set to 0.; 30:31 2 bits Reserved, set to 0.; ======= ======= ================ =========================================. The setting of registers is done by GPU CP/ADC/SPI hardware as follows:. 1. SGPRs before the Work-Group Ids are set by CP using the 16 User Data; registers.; 2. Work-group Id registers X, Y, Z are set by ADC which supports any; combination including none.; 3. Scratch Wavefront Offset is set by SPI in a per wavefront basis which is why; its value cannot be included with the flat scratch init value which is per; queue (see :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`).; 4. The VGPRs are set by SPI which only supports specifying either (X), (X, Y); or (X, Y, Z).; 5. Flat Scratch register pair initialization is described in; :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`. The global segment can be accessed either using buffer instructions (GFX6 which; has V# 64-bit address support), flat instructions (GFX7-GFX11), or global; instructions (GFX9-GFX11). If buffer operations are used, then the compiler can generate a V# with the; following properties:. * base address of 0; * no swizzle; * ATC: 1 if IOMMU present (such as APU); * ptr64: 1; * MTYPE set to support memory coherence that matches the runtime (such as CC for; APU and NC for dGPU). .. _amdgpu-amdhsa-kernarg-preload:. Preloaded Kernel Arguments; ++++++++++++++++++++++++++. On hardware that supports this feature, kernel arguments can be preloaded into; User SGPRs, up to the maximum number of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:189741,queue,queue,189741,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['queue'],['queue']
Performance," No 1 − Cost parameter. Tol No 0.01 − Tolerance parameter. MaxIter No 1000 − Maximum number of training loops. Configuration options for MVA method :. Configuration options reference for MVA method: CFMlpANN. Option Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help message. CreateMVAPdfs No False − Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False − Events with negative weights are ignored in the training (but are included for testing and performance evaluation). NCycles No 3000 − Number of training cycles. HiddenLayers No N,N-1 − Specification of hidden layer architecture. Configuration options for MVA method :. Configuration options reference for MVA method: KNN. Option Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help message. CreateMVAPdfs No False − Create PDFs for classifier outputs (signal and background). I",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:9277,perform,performance,9277,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,1,['perform'],['performance']
Performance," No None None, Gauss, LinNeighbors Kernel type used. TargetSelection No Mean Mean, Mpv Target selection method. Configuration options for MVA method :. Configuration options reference for MVA method: TMlpANN. Option Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help message. CreateMVAPdfs No False − Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False − Events with negative weights are ignored in the training (but are included for testing and performance evaluation). NCycles No 200 − Number of training cycles. HiddenLayers No N,N-1 − Specification of hidden layer architecture (N stands for number of variables; any integers may also be used). ValidationFraction No 0.5 − Fraction of events in training tree used for cross validation. LearningMethod No Stochastic Stochastic, Batch, SteepestDescent, RibierePolak, FletcherReeves, BFGS Learning method. Configuration options for setup and tuning of specific fitter :. Configuration options reference for fitting method: Simulated Annealing (SA). Option Array Default value Predefined values Description. MaxCalls No 100000 − Maximum number of minimisation calls. InitialTemp No 1e+06 − Initial temperature. MinTemp No 1e-06 − Mimimum temperature. Eps No 1e-10 − Epsilon. TempScale No 1 − Temperature scale. AdaptiveSpeed No 1 − Adaptive speed. TempAdaptiveStep No 0.009875 − Step made in each generation temperature adaptive. UseDefaultSca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:28695,perform,performance,28695,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,1,['perform'],['performance']
Performance," Note that NotAtomic volatile loads and stores are not properly; atomic; do not try to use them as a substitute. (Per the C/C++ standards,; volatile does provide some limited guarantees around asynchronous signals, but; atomics are generally a better solution.). Notes for optimizers; Introducing loads to shared variables along a codepath where they would not; otherwise exist is allowed; introducing stores to shared variables is not. See; `Optimization outside atomic`_. Notes for code generation; The one interesting restriction here is that it is not allowed to write to; bytes outside of the bytes relevant to a store. This is mostly relevant to; unaligned stores: it is not allowed in general to convert an unaligned store; into two aligned stores of the same width as the unaligned store. Backends are; also expected to generate an i8 store as an i8 store, and not an instruction; which writes to surrounding bytes. (If you are writing a backend for an; architecture which cannot satisfy these restrictions and cares about; concurrency, please send an email to llvm-dev.). Unordered; ---------. Unordered is the lowest level of atomicity. It essentially guarantees that races; produce somewhat sane results instead of having undefined behavior. It also; guarantees the operation to be lock-free, so it does not depend on the data; being part of a special atomic structure or depend on a separate per-process; global lock. Note that code generation will fail for unsupported atomic; operations; if you need such an operation, use explicit locking. Relevant standard; This is intended to match the Java memory model for shared variables. Notes for frontends; This cannot be used for synchronization, but is useful for Java and other; ""safe"" languages which need to guarantee that the generated code never; exhibits undefined behavior. Note that this guarantee is cheap on common; platforms for loads of a native width, but can be expensive or unavailable for; wider loads, like a 64-bit store on",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:7876,concurren,concurrency,7876,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['concurren'],['concurrency']
Performance," Note: Method Thread0 cannot be a virtual member function, since the cast; of `Thread0` to `void(*)` in the **`TThread`** constructor may raise; problems with C++ virtual function table. However, Thread0 may call; another virtual member function virtual void `Myclass::Func0()` which; then can be overridden in a derived class of `Myclass`. (See example; `TMhs3`). Class `Myclass` may also provide a method to stop the running thread:. ``` {.cpp}; Int_t Myclass::Threadstop() {; if (mTh) {; TThread::Delete(mTh);; delete mTh;; mTh=0;; return 0;; }; return 1;; }; ```. Example `TMhs3:` Class **`TThreadframe`**; (`TThreadframe.h, TThreadframe.cxx`) is a simple example of a framework; class managing up to four threaded methods. Class `TMhs3`; (`TMhs3.h, TMhs3.cxx)` inherits from this base class, showing the `mhs3`; example 8.1 `(mhs3.h, mhs3.cxx) `within a class. The `Makefile` of this; example builds the shared libraries `libTThreadframe.so` and; `libTMhs3.so`. These are either loaded or executed by the ROOT script; `TMhs3demo.C,` or are linked against an executable: `TMhs3run.cxx`. ### Known Problems. Parts of the ROOT framework, like the interpreter, are not yet; thread-safe. Therefore, you should use this package with caution. If you; restrict your threads to distinct and \`simple' duties, you will able to; benefit from their use. The **`TThread`** class is available on all; platforms, which provide a POSIX compliant thread implementation. On; Linux, Xavier Leroy's Linux Threads implementation is widely used, but; the **`TThread`** implementation should be usable on all platforms that; provide `pthread`. **Linux Xlib on SMP machines** is not yet thread-safe. This may cause; crashes during threaded graphics operations; this problem is independent; of ROOT. **Object instantiation:** there is no implicit locking mechanism for; memory allocation and global ROOT lists. The user has to explicitly; protect their code when using them. ## The Signals of ROOT. The list of default s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md:16829,load,loaded,16829,documentation/users-guide/Threads.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Threads.md,1,['load'],['loaded']
Performance," Optimizations`_ --- This optional stage consists of a; series of machine-code optimizations that operate on the SSA-form produced by; the instruction selector. Optimizations like modulo-scheduling or peephole; optimization work here. 4. `Register Allocation`_ --- The target code is transformed from an infinite; virtual register file in SSA form to the concrete register file used by the; target. This phase introduces spill code and eliminates all virtual register; references from the program. 5. `Prolog/Epilog Code Insertion`_ --- Once the machine code has been generated; for the function and the amount of stack space required is known (used for; LLVM alloca's and spill slots), the prolog and epilog code for the function; can be inserted and ""abstract stack location references"" can be eliminated.; This stage is responsible for implementing optimizations like frame-pointer; elimination and stack packing. 6. `Late Machine Code Optimizations`_ --- Optimizations that operate on ""final""; machine code can go here, such as spill code scheduling and peephole; optimizations. 7. `Code Emission`_ --- The final stage actually puts out the code for the; current function, either in the target assembler format or in machine; code. The code generator is based on the assumption that the instruction selector will; use an optimal pattern matching selector to create high-quality sequences of; native instructions. Alternative code generator designs based on pattern; expansion and aggressive iterative peephole optimization are much slower. This; design permits efficient compilation (important for JIT environments) and; aggressive optimization (used when generating code offline) by allowing; components of varying levels of sophistication to be used for any step of; compilation. In addition to these stages, target implementations can insert arbitrary; target-specific passes into the flow. For example, the X86 target uses a; special pass to handle the 80x87 floating point stack architecture.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:7110,optimiz,optimizations,7110,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['optimiz'],['optimizations']
Performance," PassManager is set up, we need to make use of it. We do this by; running it after our newly created function is constructed (in; ``FunctionAST::codegen()``), but before it is returned to the client:. .. code-block:: c++. if (Value *RetVal = Body->codegen()) {; // Finish off the function.; Builder.CreateRet(RetVal);. // Validate the generated code, checking for consistency.; verifyFunction(*TheFunction);. // Optimize the function.; TheFPM->run(*TheFunction, *TheFAM);. return TheFunction;; }. As you can see, this is pretty straightforward. The; ``FunctionPassManager`` optimizes and updates the LLVM Function\* in; place, improving (hopefully) its body. With this in place, we can try; our test above again:. ::. ready> def test(x) (1+2+x)*(x+(1+2));; ready> Read function definition:; define double @test(double %x) {; entry:; %addtmp = fadd double %x, 3.000000e+00; %multmp = fmul double %addtmp, %addtmp; ret double %multmp; }. As expected, we now get our nicely optimized code, saving a floating; point add instruction from every execution of this function. LLVM provides a wide variety of optimizations that can be used in; certain circumstances. Some `documentation about the various; passes <../../Passes.html>`_ is available, but it isn't very complete.; Another good source of ideas can come from looking at the passes that; ``Clang`` runs to get started. The ""``opt``"" tool allows you to; experiment with passes from the command line, so you can see if they do; anything. Now that we have reasonable code coming out of our front-end, let's talk; about executing it!. Adding a JIT Compiler; =====================. Code that is available in LLVM IR can have a wide variety of tools; applied to it. For example, you can run optimizations on it (as we did; above), you can dump it out in textual or binary forms, you can compile; the code to an assembly file (.s) for some target, or you can JIT; compile it. The nice thing about the LLVM IR representation is that it; is the ""common curren",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst:8946,optimiz,optimized,8946,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl04.rst,1,['optimiz'],['optimized']
Performance," PyPy with pyproject.toml; * ``std::string`` not converterd to ``str`` on function returns; * Cover more use cases where C string memory can be managed; * Automatic memory management of converted python functions; * Added pyinstaller hooks (https://stackoverflow.com/questions/64406727); * Support for enums in pseudo-constructors of aggregates; * Fixes for overloaded/split-access protected members in cross-inheritance; * Support for deep, mixed, hierarchies for multi-cross-inheritance; * Added tp_iter method to low level views. 2020-11-06: 1.8.6; -----------------. * Fix preprocessor macro of CPyCppyy header for Windows/MSVC. 2020-10-31: 1.8.5; -----------------. * Fix leaks when using vector iterators on Py3/Linux. 2020-10-10: 1.8.4; -----------------. * ``std::string`` globals/data members no longer automatically converted to ``str``; * New methods for std::string to allow ``str`` interchangability; * Added a ``decode`` method to ``std::string``; * Add pythonized ``__contains__`` to ``std::set``; * Fix constructor generation for aggregates with static data; * Fix performance bug when using implicit conversions; * Fix memory overwrite when parsing during sorting of methods; * PyPy pip install again falls back to setup.py install. 2020-09-21: 1.8.3; -----------------. * Add initializer constructors for PODs and aggregates; * Use actual underlying type for enums, where possible; * Enum values remain instances of their type; * Expose enum underlying type name as ``__underlying`` and ``__ctype__``; * Strictly follow C++ enum scoping rules; * Same enum in transparent scope refers to same type; * More detailed enum ``repr()`` printing, where possible; * Fix for (extern) explicit template instantiations in namespaces; * Throw objects from an std::tuple a life line; * Global pythonizors now always run on all classes; * Simplified iteraton over STL-like containers defining ``begin()``/``end()``. 2020-09-08: 1.8.2; -----------------. * Add ``cppyy.set_debug()`` to enable debu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:10004,perform,performance,10004,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,1,['perform'],['performance']
Performance," Python interpreter Application Programming Interfaces (APIs;; the exact same that Python uses itself internally).; If you use a compile-time binder such as `SWIG`_ or `pybind11`_ to bind a C++; class, then what gets compiled is the series of API calls necessary to; construct a Python-side equivalent at `run-time` (when the module gets; loaded), not the Python class object.; In short, whether a binding is created at ""compile-time"" or at run-time has; no measurable bearing on performance. What does affect performance is the overhead to cross the language barrier.; This consists of unboxing Python objects to extract or convert the underlying; objects or data to something that matches what C++ expects; overload; resolution based on the unboxed arguments; offset calculations; and finally; the actual dispatch.; As a practical matter, overload resolution is the most costly part, followed; by the unboxing and conversion.; Best performance is achieved by specialization of the paths through the; run-time: recognize early the case at hand and select an optimized path.; For that reason, `PyPy`_ is so fast: JIT-ed traces operate on unboxed objects; and resolved overloads are baked into the trace, incurring no further cost.; Similarly, this is why pybind11 is so slow: its code generation is the C++; compiler's template engine, so complex path selection and specialization is; very hard to do in a performance-portable way. In cppyy, a great deal of attention has gone into built-in specialization; paths, which drives its performance.; For example, basic inheritance sequentially lines up classes, whereas; multiple (virtual) inheritance usually requires thunks.; Thus, when calling base class methods on a derived instance, the latter; requires offset calculations that depend on that instance, whereas the former; has fixed offsets fully determined by the class definitions themselves.; By labeling classes appropriately, single inheritance classes (by far the; most common case) do not inc",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:2178,perform,performance,2178,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,2,"['optimiz', 'perform']","['optimized', 'performance']"
Performance," ROOT are typically faster from `PyROOT`, whereas loops are typically; slower. When programming in Python, the modus operandi is to consider; performance generally ""good enough"" on the outset, and when it turns out; that, it is not good enough; the performance critical part is converted; into C/C++ in an extension module. The school of thought where; pre-mature optimization is the root of all evil should find this way of; working very satisfying. In addition, if you look at their history, you; will see that many of the standard Python modules have followed this; path. Your code should always make maximum use of ROOT facilities; such that; most of the time is spending in compiled code. This goes even for very; simple things: e.g. do not compute invariant masses in Python, use; **`TLorentzVector`** instead. Moreover, before you start optimizing,; make sure that you have run a profiler to find out where the bottlenecks; are. Some performance, without cost in terms of programmer effort, may; be gained by using `psyco`, see the next link:; <http://psyco.sourceforge.net>, a Python just in time compiler (JIT).; Note, however, that `psyco` is limited to Intel i386 CPUs. Since `psyco`; optimizes Python, not `PyROOT` calls; it generally does not improve; performance that much if most of your code consists of ROOT API calls.; Mathematical computations in Python, on the other hand, benefit a lot. Every call to a Python member function results in a lookup of that; member function and an association of this method with `'self'`.; Furthermore, a temporary object is created during this process that is; discarded after the method call. In inner loops, it may be worth your; while (up to 30%), to short-cut this process by looking up and binding; the method before the loop, and discarding it afterwards. Here is an; example:. ``` {.cpp}; hpx = TH1F('hpx','px',100,-4,4); hpxFill = hpx.Fill # cache bound method; for i in xrange(25000):; px = gRandom.Gaus(); hpxFill(px) # use bound method:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md:23553,perform,performance,23553,documentation/users-guide/PythonRuby.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md,1,['perform'],['performance']
Performance," Recipe. A Recipe; may specify how its ingredients are to be transformed to produce the output IR; instructions; e.g., cloned once, replicated multiple times or widened; according to selected VF. :VPValue:; The base of VPlan's def-use relations class hierarchy. When instantiated, it; models a constant or a live-in Value in VPlan. It has users, which are of type; VPUser, but no operands. :VPUser:; A VPUser represents an entity that uses a number of VPValues as operands.; VPUser is similar in some aspects to LLVM's User class. :VPDef:; A VPDef represents an entity that defines zero, one or multiple VPValues.; It is used to model the fact that recipes in VPlan can define multiple; VPValues. :VPInstruction:; A VPInstruction is both a VPRecipe and a VPUser. It models a single; VPlan-level instruction to be generated if the VPlan is executed, including; its opcode and possibly additional characteristics. It is the basis for; writing instruction-level analyses and optimizations in VPlan as creating,; replacing or moving VPInstructions record both def-use and scheduling; decisions. VPInstructions also extend LLVM IR's opcodes with idiomatic; operations that enrich the Vectorizer's semantics. :VPTransformState:; Stores information used for generating output IR, passed from; LoopVectorizationPlanner to its selected VPlan for execution, and used to pass; additional information down to VPBlocks and VPRecipes. The Planning Process and VPlan Roadmap; ======================================. Transforming the Loop Vectorizer to use VPlan follows a staged approach. First,; VPlan is used to record the final vectorization decisions, and to execute them:; the Hierarchical CFG models the planned control-flow, and Recipes capture; decisions taken inside basic-blocks. Next, VPlan will be used also as the basis; for taking these decisions, effectively turning them into a series of; VPlan-to-VPlan algorithms. Finally, VPlan will support the planning process; itself including cost-based analys",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:7629,optimiz,optimizations,7629,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,1,['optimiz'],['optimizations']
Performance," RooCategory category observable encoding distribution and accept/reject state respectively. See rf701_efficiencyfit.C for details ; RooAbsPdf - Included extended ML term by default in fit if p.d.f is extendable. You can still use Extended() to override default behavior. Do not run MINOS by default anymore if no fit options are provided.; RooProfileLL - Add option to always start minimization from global minimimum (takes more time, but improves reproducibility). Can now profile multi-core paralellized likelihoods as well.; RooRealSumPdf - Enable plotting of component p.d.f.s using same scheme as RooAddPdf, i.e. just use the Components() specified in plotOn().; RooExpensiveObjectCache - New cache manager for sharing and storing of expensive components cached by operator p.d.f.s ; RooMCStudy - Add Silence() argument to constructor to request minimal verbosity during running; RooMinuit - Improve contour() method to return RooPlots rather than drawing TGraphs straight on a canvas; RooWorkspace - Add private expensive object cache to workspace; RooBinningCategory - New real-to-category function that maps values of input RooRealVar to categories with labels that correspond to bins of input RooRealVar. See rf405_realtocatfuncs.C for details . RooStats; This is a new package introduced in this version for statistical tools built on top of RooFit. It is a joint effort between the LHC experiments and the ROOT team (see the RooStats Wiki page).; ; This version contains the interfaces for performing the statistical calculations and dealing with the obtained results and concrete classes implementing the statistical methods.; ; All the classes and functions in RooStats are provided in the namespace RooStats.; ; RooStats interfaces. ConfInterval: interface for describing a confidence interval. ; IntervalCalculator: interface for a statistical tool producing confidence intervals (class ConfInterval).; HypoTestResult: interface for representing results of a hypothesis test; HypoTest",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:9115,cache,cache,9115,roofit/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html,1,['cache'],['cache']
Performance," SS = 0, IL = 0, <...>. This is only available when ``lldb`` is built with XML support.; Where possible the CPU's capabilities are used to decide which; fields are present, however this is not always possible or entirely; accurate. If in doubt, refer to the numerical value. * On Windows, LLDB can now read the thread names. Changes to Sanitizers; ---------------------; * HWASan now defaults to detecting use-after-scope bugs. * `SpecialCaseList <https://clang.llvm.org/docs/SanitizerSpecialCaseList.html#format>`_; used by sanitizer ignore lists (e.g. ``*_ignorelist.txt`` in the Clang; resource directory) now uses glob patterns instead of a variant of POSIX; Extended Regular Expression (where ``*`` is translated to ``.*``) by default.; Search for ``|`` to find patterns that may have different meanings now, and; replace ``a|b`` with ``{a,b}``. Changes to the Profile Runtime; ------------------------------. * Public header ``profile/instr_prof_interface.h`` is added to declare four; API functions to fine tune profile collection. Other Changes; -------------. * The ``Flags`` field of ``llvm::opt::Option`` has been split into ``Flags``; and ``Visibility`` to simplify option sharing between various drivers (such; as ``clang``, ``clang-cl``, or ``flang``) that rely on Clang's Options.td.; Overloads of ``llvm::opt::OptTable`` that use ``FlagsToInclude`` have been; deprecated. There is a script and instructions on how to resolve conflicts -; see https://reviews.llvm.org/D157150 and https://reviews.llvm.org/D157151 for; details. * On Linux, FreeBSD, and NetBSD, setting the environment variable; ``LLVM_ENABLE_SYMBOLIZER_MARKUP`` causes tools to print stacktraces using; :doc:`Symbolizer Markup <SymbolizerMarkupFormat>`.; This works even if the tools have no embedded symbol information (i.e. are; fully stripped); :doc:`llvm-symbolizer <CommandGuide/llvm-symbolizer>` can; symbolize the markup afterwards using ``debuginfod``. External Open Source Projects Using LLVM 15; =============",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst:18173,tune,tune,18173,interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ReleaseNotes.rst,1,['tune'],['tune']
Performance," See McCat/18-imp/ComputeBoundingBoxes for an example. //===---------------------------------------------------------------------===//. Pre-/post- indexed load / stores:. 1) We should not make the pre/post- indexed load/store transform if the base ptr; is guaranteed to be live beyond the load/store. This can happen if the base; ptr is live out of the block we are performing the optimization. e.g. mov r1, r2; ldr r3, [r1], #4; ... vs. ldr r3, [r2]; add r1, r2, #4; ... In most cases, this is just a wasted optimization. However, sometimes it can; negatively impact the performance because two-address code is more restrictive; when it comes to scheduling. Unfortunately, liveout information is currently unavailable during DAG combine; time. 2) Consider spliting a indexed load / store into a pair of add/sub + load/store; to solve #1 (in TwoAddressInstructionPass.cpp). 3) Enhance LSR to generate more opportunities for indexed ops. 4) Once we added support for multiple result patterns, write indexed loads; patterns instead of C++ instruction selection code. 5) Use VLDM / VSTM to emulate indexed FP load / store. //===---------------------------------------------------------------------===//. Implement support for some more tricky ways to materialize immediates. For; example, to get 0xffff8000, we can use:. mov r9, #&3f8000; sub r9, r9, #&400000. //===---------------------------------------------------------------------===//. We sometimes generate multiple add / sub instructions to update sp in prologue; and epilogue if the inc / dec value is too large to fit in a single immediate; operand. In some cases, perhaps it might be better to load the value from a; constantpool instead. //===---------------------------------------------------------------------===//. GCC generates significantly better code for this function. int foo(int StackPtr, unsigned char *Line, unsigned char *Stack, int LineLen) {; int i = 0;. if (StackPtr != 0) {; while (StackPtr != 0 && i < (((LineLen) < (32768",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:9063,load,loads,9063,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,1,['load'],['loads']
Performance," SimplifyLibcalls into; libanalysis' constantfolding logic. This would allow IPSCCP to be able to; handle simple things like this:. static int foo(const char *X) { return strlen(X); }; int bar() { return foo(""abcd""); }. //===---------------------------------------------------------------------===//. function-attrs doesn't know much about memcpy/memset. This function should be; marked readnone rather than readonly, since it only twiddles local memory, but; function-attrs doesn't handle memset/memcpy/memmove aggressively:. struct X { int *p; int *q; };; int foo() {; int i = 0, j = 1;; struct X x, y;; int **p;; y.p = &i;; x.q = &j;; p = __builtin_memcpy (&x, &y, sizeof (int *));; return **p;; }. This can be seen at:; $ clang t.c -S -o - -mkernel -O0 -emit-llvm | opt -function-attrs -S. //===---------------------------------------------------------------------===//. Missed instcombine transformation:; define i1 @a(i32 %x) nounwind readnone {; entry:; %cmp = icmp eq i32 %x, 30; %sub = add i32 %x, -30; %cmp2 = icmp ugt i32 %sub, 9; %or = or i1 %cmp, %cmp2; ret i1 %or; }; This should be optimized to a single compare. Testcase derived from gcc. //===---------------------------------------------------------------------===//. Missed instcombine or reassociate transformation:; int a(int a, int b) { return (a==12)&(b>47)&(b<58); }. The sgt and slt should be combined into a single comparison. Testcase derived; from gcc. //===---------------------------------------------------------------------===//. Missed instcombine transformation:. %382 = srem i32 %tmp14.i, 64 ; [#uses=1]; %383 = zext i32 %382 to i64 ; [#uses=1]; %384 = shl i64 %381, %383 ; [#uses=1]; %385 = icmp slt i32 %tmp14.i, 64 ; [#uses=1]. The srem can be transformed to an and because if %tmp14.i is negative, the; shift is undefined. Testcase derived from 403.gcc. //===---------------------------------------------------------------------===//. This is a range comparison on a divided result (from 403.gcc):. %1337 = sdiv ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:47678,optimiz,optimized,47678,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,1,['optimiz'],['optimized']
Performance," TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_inv and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - generic 1. flat_atomic sc1=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:301078,cache,caches,301078,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['caches']
Performance," The :doc:`AdvancedBuilds` documentation describes the built-in tooling for; generating LLVM profiling information to drive Profile-Guided-Optimization. The; in-tree profiling tests are very limited, and generating the profile takes a; significant amount of time, but it can result in a significant improvement in; the performance of the generated binaries. In addition to PGO profiling we also have limited support in-tree for generating; linker order files. These files provide the linker with a suggested ordering for; functions in the final binary layout. This can measurably speed up clang by; physically grouping functions that are called temporally close to each other.; The current tooling is only available on Darwin systems with ``dtrace(1)``. It; is worth noting that dtrace is non-deterministic, and so the order file; generation using dtrace is also non-deterministic. Options for Reducing Size; =========================. .. warning::; Any steps taken to reduce the binary size will come at a cost of runtime; performance in the generated binaries. The simplest and least significant way to reduce binary size is to set the; *CMAKE_BUILD_TYPE* variable to ``MinSizeRel``, which will set the compiler; optimization level to ``-Os`` which optimizes for binary size. This will have; both the least benefit to size and the least impact on performance. The most impactful way to reduce binary size is to dynamically link LLVM into; all the tools. This reduces code size by decreasing duplication of common code; between the LLVM-based tools. This can be done by setting the following two; CMake options to ``On``: *LLVM_BUILD_LLVM_DYLIB* and *LLVM_LINK_LLVM_DYLIB*. .. warning::; Distributions should never be built using the *BUILD_SHARED_LIBS* CMake; option. (:ref:`See the warning above for more explanation <shared_libs>`.). Relevant CMake Options; ======================. This section provides documentation of the CMake options that are intended to; help construct distributions. This ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:9988,perform,performance,9988,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,1,['perform'],['performance']
Performance," The CoreCLR GC; -------------------------. .. code-block:: c++. F.setGC(""coreclr"");. This GC leverages the ``gc.statepoint`` mechanism to support the; `CoreCLR <https://github.com/dotnet/coreclr>`__ runtime. Support for this GC strategy is a work in progress. This strategy will; differ from; :ref:`statepoint-example GC<statepoint_example_gc>` strategy in; certain aspects like:. * Base-pointers of interior pointers are not explicitly; tracked and reported. * A different format is used for encoding stack maps. * Safe-point polls are only needed before loop-back edges; and before tail-calls (not needed at function-entry). Custom GC Strategies; ====================. If none of the built in GC strategy descriptions met your needs above, you will; need to define a custom GCStrategy and possibly, a custom LLVM pass to perform; lowering. Your best example of where to start defining a custom GCStrategy; would be to look at one of the built in strategies. You may be able to structure this additional code as a loadable plugin library.; Loadable plugins are sufficient if all you need is to enable a different; combination of built in functionality, but if you need to provide a custom; lowering pass, you will need to build a patched version of LLVM. If you think; you need a patched build, please ask for advice on llvm-dev. There may be an; easy way we can extend the support to make it work for your use case without; requiring a custom build. Collector Requirements; ----------------------. You should be able to leverage any existing collector library that includes the following elements:. #. A memory allocator which exposes an allocation function your compiled; code can call. #. A binary format for the stack map. A stack map describes the location; of references at a safepoint and is used by precise collectors to identify; references within a stack frame on the machine stack. Note that collectors; which conservatively scan the stack don't require such a structure. #. A stack craw",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:21899,load,loadable,21899,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['load'],['loadable']
Performance," The caller and callee's return types must match. The caller cannot; be void unless the callee is, too. AArch64 constraints:. * No variable argument lists are used. Example:. Call as ``llc -tailcallopt test.ll``. .. code-block:: llvm. declare fastcc i32 @tailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4). define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {; %l1 = add i32 %in1, %in2; %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1); ret i32 %tmp; }. Implications of ``-tailcallopt``:. To support tail call optimization in situations where the callee has more; arguments than the caller a 'callee pops arguments' convention is used. This; currently causes each ``fastcc`` call that is not tail call optimized (because; one or more of above constraints are not met) to be followed by a readjustment; of the stack. So performance might be worse in such cases. Sibling call optimization; -------------------------. Sibling call optimization is a restricted form of tail call optimization.; Unlike tail call optimization described in the previous section, it can be; performed automatically on any tail calls when ``-tailcallopt`` option is not; specified. Sibling call optimization is currently performed on x86/x86-64 when the; following constraints are met:. * Caller and callee have the same calling convention. It can be either ``c`` or; ``fastcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Caller and callee have matching return type or the callee result is not used. * If any of the callee arguments are being passed in stack, they must be; available in caller's own incoming argument stack and the frame offsets must; be the same. Example:. .. code-block:: llvm. declare i32 @bar(i32, i32). define i32 @foo(i32 %a, i32 %b, i32 %c) {; entry:; %0 = tail call i32 @bar(i32 %a, i32 %b); ret i32 %0; }. The X86 backend; ---------------. The X86 code generator lives in the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:88299,optimiz,optimization,88299,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,2,['optimiz'],['optimization']
Performance," The following is a list of acronyms considered sufficiently useful that the; benefit of using them outweighs the cost of learning them. Acronyms that are; either not on the list or are used to refer to a different type should be; expanded. ============================ =============; Class name Variable name; ============================ =============; DeterministicFiniteAutomaton dfa; DominatorTree dt; LoopInfo li; MachineFunction mf; MachineInstr mi; MachineRegisterInfo mri; ScalarEvolution se; TargetInstrInfo tii; TargetLibraryInfo tli; TargetRegisterInfo tri; ============================ =============. In some cases renaming acronyms to the full type name will result in overly; verbose code. Unlike most classes, a variable's scope is limited and therefore; some of its purpose can implied from that scope, meaning that fewer words are; necessary to give it a clear name. For example, in an optimization pass the reader; can assume that a variable's purpose relates to optimization and therefore an; ``OptimizationRemarkEmitter`` variable could be given the name ``remarkEmitter``; or even ``remarker``. The following is a list of longer class names and the associated shorter; variable name. ========================= =============; Class name Variable name; ========================= =============; BasicBlock block; ConstantExpr expr; ExecutionEngine engine; MachineOperand operand; OptimizationRemarkEmitter remarker; PreservedAnalyses analyses; PreservedAnalysesChecker checker; TargetLowering lowering; TargetMachine machine; ========================= =============. Transition Options; ==================. There are three main options for transitioning:. 1. Keep the current coding standard; 2. Laissez faire; 3. Big bang. Keep the current coding standard; --------------------------------. Proponents of keeping the current coding standard (i.e. not transitioning at; all) question whether the cost of transition outweighs the benefit; [EmersonConcern]_ [ReamesConcern]_ [Bradbur",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst:6626,optimiz,optimization,6626,interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst,2,['optimiz'],['optimization']
Performance," The memory model has been; subsequently adjusted to correct errors in the initial; specification, so LLVM currently intends to implement the version; specified by C++20. (See the `C++20 draft standard; <https://isocpp.org/files/papers/N4860.pdf>`_ or the unofficial; `latest C++ draft <https://eel.is/c++draft/>`_. A `C2x draft; <https://www.open-std.org/jtc1/sc22/wg14/www/docs/n3047.pdf>`_ is; also available, though the text has not yet been updated with the; errata corrected by C++20.). * Proper semantics for Java-style memory, for both ``volatile`` and regular; shared variables. (`Java Specification; <http://docs.oracle.com/javase/specs/jls/se8/html/jls-17.html>`_). * gcc-compatible ``__sync_*`` builtins. (`Description; <https://gcc.gnu.org/onlinedocs/gcc/_005f_005fsync-Builtins.html>`_). * Other scenarios with atomic semantics, including ``static`` variables with; non-trivial constructors in C++. Atomic and volatile in the IR are orthogonal; ""volatile"" is the C/C++ volatile,; which ensures that every volatile load and store happens and is performed in the; stated order. A couple examples: if a SequentiallyConsistent store is; immediately followed by another SequentiallyConsistent store to the same; address, the first store can be erased. This transformation is not allowed for a; pair of volatile stores. On the other hand, a non-volatile non-atomic load can; be moved across a volatile load freely, but not an Acquire load. This document is intended to provide a guide to anyone either writing a frontend; for LLVM or working on optimization passes for LLVM with a guide for how to deal; with instructions with special semantics in the presence of concurrency. This; is not intended to be a precise guide to the semantics; the details can get; extremely complicated and unreadable, and are not usually necessary. .. _Optimization outside atomic:. Optimization outside atomic; ===========================. The basic ``'load'`` and ``'store'`` allow a variety of optimizations, b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:1561,load,load,1561,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,2,"['load', 'perform']","['load', 'performed']"
Performance," The only supported key; value type is a uint32. The only requirement is that the producer and consumer; agree on the hash function. As such, the hash function can is not discussed; further in this document, it is assumed that for a particular instance of a PDB; file hash table, the appropriate hash function is being used. On-Disk Format; ==============. .. code-block:: none. .--------------------.-- +0; | Size |; .--------------------.-- +4; | Capacity |; .--------------------.-- +8; | Present Bit Vector |; .--------------------.-- +N; | Deleted Bit Vector |; .--------------------.-- +M ─╮; | Key | │; .--------------------.-- +M+4 │; | Value | │; .--------------------.-- +M+4+sizeof(Value) │; ... ├─ |Capacity| Bucket entries; .--------------------. │; | Key | │; .--------------------. │; | Value | │; .--------------------. ─╯. - **Size** - The number of values contained in the hash table. - **Capacity** - The number of buckets in the hash table. Producers should; maintain a load factor of no greater than ``2/3*Capacity+1``. - **Present Bit Vector** - A serialized bit vector which contains information; about which buckets have valid values. If the bucket has a value, the; corresponding bit will be set, and if the bucket doesn't have a value (either; because the bucket is empty or because the value is a tombstone value) the bit; will be unset. - **Deleted Bit Vector** - A serialized bit vector which contains information; about which buckets have tombstone values. If the entry in this bucket is; deleted, the bit will be set, otherwise it will be unset. - **Keys and Values** - A list of ``Capacity`` hash buckets, where the first; entry is the key (always a uint32), and the second entry is the value. The; state of each bucket (valid, empty, deleted) can be determined by examining; the present and deleted bit vectors. .. _hash_bit_vectors:. Present and Deleted Bit Vectors; ===============================. The bit vectors indicating the status of each bucket are serialize",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst:1581,load,load,1581,interpreter/llvm-project/llvm/docs/PDB/HashTable.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst,1,['load'],['load']
Performance," The type specified must be a :ref:`first class <t_firstclass>` type of; known size (i.e. not containing an :ref:`opaque structural type <t_opaque>`). If; the ``load`` is marked as ``volatile``, then the optimizer is not allowed to; modify the number or order of execution of this ``load`` with other; :ref:`volatile operations <volatile>`. If the ``load`` is marked as ``atomic``, it takes an extra :ref:`ordering; <ordering>` and optional ``syncscope(""<target-scope>"")`` argument. The; ``release`` and ``acq_rel`` orderings are not valid on ``load`` instructions.; Atomic loads produce :ref:`defined <memmodel>` results when they may see; multiple atomic stores. The type of the pointee must be an integer, pointer, or; floating-point type whose bit width is a power of two greater than or equal to; eight and less than or equal to a target-specific size limit. ``align`` must be; explicitly specified on atomic loads. Note: if the alignment is not greater or; equal to the size of the `<value>` type, the atomic operation is likely to; require a lock and have poor performance. ``!nontemporal`` does not have any; defined semantics for atomic loads. The optional constant ``align`` argument specifies the alignment of the; operation (that is, the alignment of the memory address). It is the; responsibility of the code emitter to ensure that the alignment information is; correct. Overestimating the alignment results in undefined behavior.; Underestimating the alignment may produce less efficient code. An alignment of; 1 is always safe. The maximum possible alignment is ``1 << 32``. An alignment; value higher than the size of the loaded type implies memory up to the; alignment value bytes can be safely loaded without trapping in the default; address space. Access of the high bytes can interfere with debugging tools, so; should not be accessed if the function has the ``sanitize_thread`` or; ``sanitize_address`` attributes. The alignment is only optional when parsing textual IR; for in-m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:413786,perform,performance,413786,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performance']
Performance," The user code does not need to check if the API names are defined, because; these names are automatically replaced by ``(0)`` or the equivalence of noop; if the ``clang`` is not compiling for profile generation. Such replacement can happen because ``clang`` adds one of two macros depending; on the ``-fprofile-generate`` and the ``-fprofile-use`` flags. * ``__LLVM_INSTR_PROFILE_GENERATE``: defined when one of; ``-fprofile[-instr]-generate``/``-fcs-profile-generate`` is in effect.; * ``__LLVM_INSTR_PROFILE_USE``: defined when one of; ``-fprofile-use``/``-fprofile-instr-use`` is in effect. The two macros can be used to provide more flexibiilty so a user program; can execute code specifically intended for profile generate or profile use.; For example, a user program can have special logging during profile generate:. .. code-block:: c. #if __LLVM_INSTR_PROFILE_GENERATE; expensive_logging_of_full_program_state();; #endif. The logging is automatically excluded during a normal build of the program,; hence it does not impact performance during a normal execution. It is advised to use such fine tuning only in a program's cold regions. The weak; symbols can introduce extra control flow (the ``if`` checks), while the macros; (hence declarations they guard in ``profile/instr_prof_interface.h``); can change the control flow of the functions that use them between profile; generation and profile use (which can lead to discarded counters in such; functions). Using these APIs in the program's cold regions introduces less; overhead and leads to more optimized code. Disabling Instrumentation; ^^^^^^^^^^^^^^^^^^^^^^^^^. In certain situations, it may be useful to disable profile generation or use; for specific files in a build, without affecting the main compilation flags; used for the other files in the project. In these cases, you can use the flag ``-fno-profile-instr-generate`` (or; ``-fno-profile-generate``) to disable profile generation, and; ``-fno-profile-instr-use`` (or ``-fno-pr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:114388,perform,performance,114388,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['perform'],['performance']
Performance," ThinLTO and PGO. All were built with `-march=haswell` to give access to BMI2; instructions, and benchmarks were run on large Haswell servers. We collected; data both with an `lfence`-based mitigation and load hardening as presented; here. The summary is that mitigating with load hardening is 1.77x faster than; mitigating with `lfence`, and the overhead of load hardening compared to a; normal program is likely between a 10% overhead and a 50% overhead with most; large applications seeing a 30% overhead or less. | Benchmark | `lfence` | Load Hardening | Mitigated Speedup |; | -------------------------------------- | -------: | -------------: | ----------------: |; | Google microbenchmark suite | -74.8% | -36.4% | **2.5x** |; | Large server QPS (using ThinLTO & PGO) | -62% | -29% | **1.8x** |. Below is a visualization of the microbenchmark suite results which helps show; the distribution of results that is somewhat lost in the summary. The y-axis is; a log-scale speedup ratio of load hardening relative to `lfence` (up -> faster; -> better). Each box-and-whiskers represents one microbenchmark which may have; many different metrics measured. The red line marks the median, the box marks; the first and third quartiles, and the whiskers mark the min and max. ![Microbenchmark result visualization](speculative_load_hardening_microbenchmarks.png). We don't yet have benchmark data on SPEC or the LLVM test suite, but we can; work on getting that. Still, the above should give a pretty clear; characterization of the performance, and specific benchmarks are unlikely to; reveal especially interesting properties. ### Future Work: Fine Grained Control and API-Integration. The performance overhead of this technique is likely to be very significant and; something users wish to control or reduce. There are interesting options here; that impact the implementation strategy used. One particularly appealing option is to allow both opt-in and opt-out of this; mitigation at reasonably fine gra",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:48184,load,load,48184,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['load']
Performance," This is mainly for promoting straight-line scalar optimizations, which are; most effective on code along dominator paths. * `Memory space inference; <https://llvm.org/doxygen/NVPTXInferAddressSpaces_8cpp_source.html>`_ --; In PTX, we can operate on pointers that are in a particular ""address space""; (global, shared, constant, or local), or we can operate on pointers in the; ""generic"" address space, which can point to anything. Operations in a; non-generic address space are faster, but pointers in CUDA are not explicitly; annotated with their address space, so it's up to LLVM to infer it where; possible. * `Bypassing 64-bit divides; <https://llvm.org/docs/doxygen/html/BypassSlowDivision_8cpp_source.html>`_ --; This was an existing optimization that we enabled for the PTX backend. 64-bit integer divides are much slower than 32-bit ones on NVIDIA GPUs.; Many of the 64-bit divides in our benchmarks have a divisor and dividend; which fit in 32-bits at runtime. This optimization provides a fast path for; this common case. * Aggressive loop unrolling and function inlining -- Loop unrolling and; function inlining need to be more aggressive for GPUs than for CPUs because; control flow transfer in GPU is more expensive. More aggressive unrolling and; inlining also promote other optimizations, such as constant propagation and; SROA, which sometimes speed up code by over 10x. (Programmers can force unrolling and inline using clang's `loop unrolling pragmas; <https://clang.llvm.org/docs/AttributeReference.html#pragma-unroll-pragma-nounroll>`_; and ``__attribute__((always_inline))``.). Publication; ===========. The team at Google published a paper in CGO 2016 detailing the optimizations; they'd made to clang/LLVM. Note that ""gpucc"" is no longer a meaningful name:; The relevant tools are now just vanilla clang/LLVM. | `gpucc: An Open-Source GPGPU Compiler <http://dl.acm.org/citation.cfm?id=2854041>`_; | Jingyue Wu, Artem Belevich, Eli Bendersky, Mark Heffernan, Chris Leary, Jacque",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst:19624,optimiz,optimization,19624,interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CompileCudaWithLLVM.rst,1,['optimiz'],['optimization']
Performance," This is particularly useful on indirect; calls; without this we may treat such calls as though the target; is non-convergent. See :doc:`ConvergentOperations` for further details. It is an error to call :ref:`llvm.experimental.convergence.entry; <llvm.experimental.convergence.entry>` from a function that; does not have this attribute.; ``disable_sanitizer_instrumentation``; When instrumenting code with sanitizers, it can be important to skip certain; functions to ensure no instrumentation is applied to them. This attribute is not always similar to absent ``sanitize_<name>``; attributes: depending on the specific sanitizer, code can be inserted into; functions regardless of the ``sanitize_<name>`` attribute to prevent false; positive reports. ``disable_sanitizer_instrumentation`` disables all kinds of instrumentation,; taking precedence over the ``sanitize_<name>`` attributes and other compiler; flags.; ``""dontcall-error""``; This attribute denotes that an error diagnostic should be emitted when a; call of a function with this attribute is not eliminated via optimization.; Front ends can provide optional ``srcloc`` metadata nodes on call sites of; such callees to attach information about where in the source language such a; call came from. A string value can be provided as a note.; ``""dontcall-warn""``; This attribute denotes that a warning diagnostic should be emitted when a; call of a function with this attribute is not eliminated via optimization.; Front ends can provide optional ``srcloc`` metadata nodes on call sites of; such callees to attach information about where in the source language such a; call came from. A string value can be provided as a note.; ``fn_ret_thunk_extern``; This attribute tells the code generator that returns from functions should; be replaced with jumps to externally-defined architecture-specific symbols.; For X86, this symbol's identifier is ``__x86_return_thunk``.; ``""frame-pointer""``; This attribute tells the code generator whether the f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:82148,optimiz,optimization,82148,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimization']
Performance," This problem was; previously discussed; on the mailing list, but no solution was implemented.; (Difficulty: Medium) . Floating-point support.; Currently, the analyzer treats all floating-point values as unknown.; This project would involve adding a new SVal kind; for constant floats, generalizing the constraint manager to handle floats,; and auditing existing code to make sure it doesn't; make incorrect assumptions (most notably, that X == X; is always true, since it does not hold for NaN).; (Difficulty: Medium). Improved loop execution modeling.; The analyzer simply unrolls each loop N times before; dropping the path, for a fixed constant N.; However, that results in lost coverage in cases where the loop always; executes more than N times.; A Google Summer Of Code; project; was completed to make the loop bound parameterizable,; but the widening; problem still remains open. (Difficulty: Hard). Basic function summarization support; The analyzer performs inter-procedural analysis using; either inlining or ""conservative evaluation"" (invalidating all data; passed to the function).; Often, a very simple summary; (e.g. ""this function is pure"") would be; enough to be a large improvement over conservative evaluation.; Such summaries could be obtained either syntactically,; or using a dataflow framework.; (Difficulty: Hard). Implement a dataflow flamework.; The analyzer core; implements a symbolic execution; engine, which performs checks; (use-after-free, uninitialized value read, etc.); over a single program path.; However, many useful properties; (dead code, check-after-use, etc.) require; reasoning over all possible in a program.; Such reasoning requires a; dataflow analysis framework.; Clang already implements; a few dataflow analyses (most notably, liveness),; but they implemented in an ad-hoc fashion.; A proper framework would enable us writing many more useful checkers.; (Difficulty: Hard) . Track type information through casts more precisely.; The DynamicTypePropagat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/open_projects.html:7355,perform,performs,7355,interpreter/llvm-project/clang/www/analyzer/open_projects.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/open_projects.html,1,['perform'],['performs']
Performance," This specification describes ARC as performing specific ``retain`` and; ``release`` operations on retainable object pointers at specific; points during the execution of a program. These operations make up a; non-contiguous subsequence of the computation history of the program.; The portion of this sequence for a particular retainable object; pointer for which a specific function execution is directly; responsible is the :arc-term:`formal local retain history` of the; object pointer. The corresponding actual sequence executed is the; `dynamic local retain history`. However, under certain circumstances, ARC is permitted to re-order and; eliminate operations in a manner which may alter the overall; computation history beyond what is permitted by the general ""as if""; rule of C/C++ and the :ref:`restrictions <arc.objects.retains>` on; the implementation of ``retain`` and ``release``. .. admonition:: Rationale. Specifically, ARC is sometimes permitted to optimize ``release``; operations in ways which might cause an object to be deallocated; before it would otherwise be. Without this, it would be almost; impossible to eliminate any ``retain``/``release`` pairs. For; example, consider the following code:. .. code-block:: objc. id x = _ivar;; [x foo];. If we were not permitted in any event to shorten the lifetime of the; object in ``x``, then we would not be able to eliminate this retain; and release unless we could prove that the message send could not; modify ``_ivar`` (or deallocate ``self``). Since message sends are; opaque to the optimizer, this is not possible, and so ARC's hands; would be almost completely tied. ARC makes no guarantees about the execution of a computation history; which contains undefined behavior. In particular, ARC makes no; guarantees in the presence of race conditions. ARC may assume that any retainable object pointers it receives or; generates are instantaneously valid from that point until a point; which, by the concurrency model of the host la",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:76642,optimiz,optimize,76642,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimize']
Performance," U : Def->uses()) {; MemoryAccess *MA = cast<MemoryAccess>(Use.getUser());; if (auto *MU = cast_of_null<MemoryUse>MA) {; // Process MemoryUse as needed.; }; else {; // Process MemoryDef or MemoryPhi as needed. // As a user can come up twice, as an optimized access and defining; // access, keep a visited list. // Check transitive uses as needed; checkUses (MA); // use a worklist for an iterative algorithm; }; }; }. An example of similar traversals can be found in the DeadStoreElimination pass. Invalidation and updating; -------------------------. Because ``MemorySSA`` keeps track of LLVM IR, it needs to be updated whenever; the IR is updated. ""Update"", in this case, includes the addition, deletion, and; motion of ``Instructions``. The update API is being made on an as-needed basis.; If you'd like examples, ``GVNHoist`` and ``LICM`` are users of ``MemorySSA``\ s; update API.; Note that adding new ``MemoryDef``\ s (by calling ``insertDef``) can be a; time-consuming update, if the new access triggers many ``MemoryPhi`` insertions and; renaming (optimization invalidation) of many ``MemoryAccesses``\ es. Phi placement; ^^^^^^^^^^^^^. ``MemorySSA`` only places ``MemoryPhi``\ s where they're actually; needed. That is, it is a pruned SSA form, like LLVM's SSA form. For; example, consider:. .. code-block:: llvm. define void @foo() {; entry:; %p1 = alloca i8; %p2 = alloca i8; %p3 = alloca i8; ; 1 = MemoryDef(liveOnEntry); store i8 0, ptr %p3; br label %while.cond. while.cond:; ; 3 = MemoryPhi({%0,1},{if.end,2}); br i1 undef, label %if.then, label %if.else. if.then:; br label %if.end. if.else:; br label %if.end. if.end:; ; MemoryUse(1); %1 = load i8, ptr %p1; ; 2 = MemoryDef(3); store i8 2, ptr %p2; ; MemoryUse(1); %2 = load i8, ptr %p3; br label %while.cond; }. Because we removed the stores from ``if.then`` and ``if.else``, a ``MemoryPhi``; for ``if.end`` would be pointless, so we don't place one. So, if you need to; place a ``MemoryDef`` in ``if.then`` or ``if.else``, you'll ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:14613,optimiz,optimization,14613,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['optimiz'],['optimization']
Performance," Unix-like platforms, LLVM requires the presence of GCC's atomic; intrinsics in order to support threaded operation. If you need a; multithreading-capable LLVM on a platform without a suitably modern system; compiler, consider compiling LLVM and LLVM-GCC in single-threaded mode, and; using the resultant compiler to build a copy of LLVM with multithreading; support. .. _shutdown:. Ending Execution with ``llvm_shutdown()``; -----------------------------------------. When you are done using the LLVM APIs, you should call ``llvm_shutdown()`` to; deallocate memory used for internal structures. .. _managedstatic:. Lazy Initialization with ``ManagedStatic``; ------------------------------------------. ``ManagedStatic`` is a utility class in LLVM used to implement static; initialization of static resources, such as the global type tables. In a; single-threaded environment, it implements a simple lazy initialization scheme.; When LLVM is compiled with support for multi-threading, however, it uses; double-checked locking to implement thread-safe lazy initialization. .. _llvmcontext:. Achieving Isolation with ``LLVMContext``; ----------------------------------------. ``LLVMContext`` is an opaque class in the LLVM API which clients can use to; operate multiple, isolated instances of LLVM concurrently within the same; address space. For instance, in a hypothetical compile-server, the compilation; of an individual translation unit is conceptually independent from all the; others, and it would be desirable to be able to compile incoming translation; units concurrently on independent server threads. Fortunately, ``LLVMContext``; exists to enable just this kind of scenario!. Conceptually, ``LLVMContext`` provides isolation. Every LLVM entity; (``Module``\ s, ``Value``\ s, ``Type``\ s, ``Constant``\ s, etc.) in LLVM's; in-memory IR belongs to an ``LLVMContext``. Entities in different contexts; *cannot* interact with each other: ``Module``\ s in different contexts cannot be; linked to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:122380,multi-thread,multi-threading,122380,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['multi-thread'],['multi-threading']
Performance," Unlike XML, the bitstream format is a binary encoding, and unlike XML it; provides a mechanism for the file to self-describe ""abbreviations"", which are; effectively size optimizations for the content. LLVM IR files may be optionally embedded into a `wrapper`_ structure, or in a; `native object file`_. Both of these mechanisms make it easy to embed extra; data along with LLVM IR files. This document first describes the LLVM bitstream format, describes the wrapper; format, then describes the record structure used by LLVM IR files. .. _bitstream container format:. Bitstream Format; ================. The bitstream format is literally a stream of bits, with a very simple; structure. This structure consists of the following concepts:. * A ""`magic number`_"" that identifies the contents of the stream. * Encoding `primitives`_ like variable bit-rate integers. * `Blocks`_, which define nested content. * `Data Records`_, which describe entities within the file. * Abbreviations, which specify compression optimizations for the file. Note that the :doc:`llvm-bcanalyzer <CommandGuide/llvm-bcanalyzer>` tool can be; used to dump and inspect arbitrary bitstreams, which is very useful for; understanding the encoding. .. _magic number:. Magic Numbers; -------------. The first four bytes of a bitstream are used as an application-specific magic; number. Generic bitcode tools may look at the first four bytes to determine; whether the stream is a known stream type. However, these tools should *not*; determine whether a bitstream is valid based on its magic number alone. New; application-specific bitstream formats are being developed all the time; tools; should not reject them just because they have a hitherto unseen magic number. .. _primitives:. Primitives; ----------. A bitstream literally consists of a stream of bits, which are read in order; starting with the least significant bit of each byte. The stream is made up of; a number of primitive values that encode a stream of unsigned inte",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst:1742,optimiz,optimizations,1742,interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BitCodeFormat.rst,1,['optimiz'],['optimizations']
Performance," Wavefront Offset for use as the; flat scratch base in flat memory instructions. .. _amdgpu-amdhsa-kernel-prolog-private-segment-buffer:. Private Segment Buffer; ++++++++++++++++++++++. If the *Target Properties* column of :ref:`amdgpu-processor-table` specifies; *Architected flat scratch* then a Private Segment Buffer is not supported.; Instead the flat SCRATCH instructions are used. Otherwise, Private Segment Buffer SGPR register is used to initialize 4 SGPRs; that are used as a V# to access scratch. CP uses the value provided by the; runtime. It is used, together with Scratch Wavefront Offset as an offset, to; access the private memory space using a segment address. See; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`. The scratch V# is a four-aligned SGPR and always selected for the kernel as; follows:. - If it is known during instruction selection that there is stack usage,; SGPR0-3 is reserved for use as the scratch V#. Stack usage is assumed if; optimizations are disabled (``-O0``), if stack objects already exist (for; locals, etc.), or if there are any function calls. - Otherwise, four high numbered SGPRs beginning at a four-aligned SGPR index; are reserved for the tentative scratch V#. These will be used if it is; determined that spilling is needed. - If no use is made of the tentative scratch V#, then it is unreserved,; and the register count is determined ignoring it.; - If use is made of the tentative scratch V#, then its register numbers; are shifted to the first four-aligned SGPR index after the highest one; allocated by the register allocator, and all uses are updated. The; register count includes them in the shifted location.; - In either case, if the processor has the SGPR allocation bug, the; tentative allocation is not shifted or unreserved in order to ensure; the register count is higher to workaround the bug. .. note::. This approach of using a tentative scratch V# and shifting the register; numbers if used avoids having to perform register a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:198906,optimiz,optimizations,198906,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['optimiz'],['optimizations']
Performance," Wavefronts are executed in native mode with in-order reporting of loads and; sample instructions. In this mode vmcnt reports completion of load, atomic with; return and sample instructions in order, and the vscnt reports the completion of; store and atomic without return in order. See ``MEM_ORDERED`` field in; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`. Wavefronts can be executed in WGP or CU wavefront execution mode:. * In WGP wavefront execution mode the wavefronts of a work-group are executed; on the SIMDs of both CUs of the WGP. Therefore, explicit management of the per; CU L0 caches is required for work-group synchronization. Also accesses to L1; at work-group scope need to be explicitly ordered as the accesses from; different CUs are not ordered.; * In CU wavefront execution mode the wavefronts of a work-group are executed on; the SIMDs of a single CU of the WGP. Therefore, all global memory access by; the work-group access the same L0 which in turn ensures L1 accesses are; ordered and so do not require explicit management of the caches for; work-group synchronization. See ``WGP_MODE`` field in; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table` and; :ref:`amdgpu-target-features`. The code sequences used to implement the memory model for GFX10-GFX11 are defined in; table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx10-gfx11-table`. .. table:: AMDHSA Memory Model Code Sequences GFX10-GFX11; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx10-gfx11-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX10-GFX11; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:342883,cache,caches,342883,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['caches']
Performance," WebAssembly constraints:. * No variable argument lists are used. * The 'tail-call' target attribute is enabled. * The caller and callee's return types must match. The caller cannot; be void unless the callee is, too. AArch64 constraints:. * No variable argument lists are used. Example:. Call as ``llc -tailcallopt test.ll``. .. code-block:: llvm. declare fastcc i32 @tailcallee(i32 inreg %a1, i32 inreg %a2, i32 %a3, i32 %a4). define fastcc i32 @tailcaller(i32 %in1, i32 %in2) {; %l1 = add i32 %in1, %in2; %tmp = tail call fastcc i32 @tailcallee(i32 inreg %in1, i32 inreg %in2, i32 %in1, i32 %l1); ret i32 %tmp; }. Implications of ``-tailcallopt``:. To support tail call optimization in situations where the callee has more; arguments than the caller a 'callee pops arguments' convention is used. This; currently causes each ``fastcc`` call that is not tail call optimized (because; one or more of above constraints are not met) to be followed by a readjustment; of the stack. So performance might be worse in such cases. Sibling call optimization; -------------------------. Sibling call optimization is a restricted form of tail call optimization.; Unlike tail call optimization described in the previous section, it can be; performed automatically on any tail calls when ``-tailcallopt`` option is not; specified. Sibling call optimization is currently performed on x86/x86-64 when the; following constraints are met:. * Caller and callee have the same calling convention. It can be either ``c`` or; ``fastcc``. * The call is a tail call - in tail position (ret immediately follows call and; ret uses value of call or is void). * Caller and callee have matching return type or the callee result is not used. * If any of the callee arguments are being passed in stack, they must be; available in caller's own incoming argument stack and the frame offsets must; be the same. Example:. .. code-block:: llvm. declare i32 @bar(i32, i32). define i32 @foo(i32 %a, i32 %b, i32 %c) {; entry:; %0 = tail ca",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:88190,perform,performance,88190,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['perform'],['performance']
Performance," [2,0] . DeeE-----R . vmulps	%xmm0, %xmm1, %xmm2; [2,1] . D====eeeER . vhaddps	%xmm2, %xmm2, %xmm3; [2,2] . D======eeeER vhaddps	%xmm3, %xmm3, %xmm4. Average Wait times (based on the timeline view):; [0]: Executions; [1]: Average time spent waiting in a scheduler's queue; [2]: Average time spent waiting in a scheduler's queue while ready; [3]: Average time elapsed from WB until retire stage. [0] [1] [2] [3]; 0. 3 1.0 1.0 3.3 vmulps	%xmm0, %xmm1, %xmm2; 1. 3 3.3 0.7 1.0 vhaddps	%xmm2, %xmm2, %xmm3; 2. 3 5.7 0.0 0.0 vhaddps	%xmm3, %xmm3, %xmm4; 3 3.3 0.5 1.4 <total>. The timeline view is interesting because it shows instruction state changes; during execution. It also gives an idea of how the tool processes instructions; executed on the target, and how their timing information might be calculated. The timeline view is structured in two tables. The first table shows; instructions changing state over time (measured in cycles); the second table; (named *Average Wait times*) reports useful timing statistics, which should; help diagnose performance bottlenecks caused by long data dependencies and; sub-optimal usage of hardware resources. An instruction in the timeline view is identified by a pair of indices, where; the first index identifies an iteration, and the second index is the; instruction index (i.e., where it appears in the code sequence). Since this; example was generated using 3 iterations: ``-iterations=3``, the iteration; indices range from 0-2 inclusively. Excluding the first and last column, the remaining columns are in cycles.; Cycles are numbered sequentially starting from 0. From the example output above, we know the following:. * Instruction [1,0] was dispatched at cycle 1.; * Instruction [1,0] started executing at cycle 2.; * Instruction [1,0] reached the write back stage at cycle 4.; * Instruction [1,0] was retired at cycle 10. Instruction [1,0] (i.e., vmulps from iteration #1) does not have to wait in the; scheduler's queue for the operands to become av",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:23360,perform,performance,23360,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,"['bottleneck', 'perform']","['bottlenecks', 'performance']"
Performance," `Merge(...)` interface for the `TFileMerger`. ### RPageSource / Sink; The page source and sink can read and write pages and clusters from and to a storage backend.; There are concrete class implementations for an RNTuple stored in a ROOT file (local or remote), and for an RNTuple stored in a DAOS object store.; There is a virtual page sink for buffered writes, which also groups pages of the same column before flushing them to disk.; There is a virtual page source for aligned friend datasets (horizontal data combination). Page sources and sinks do not operate entry-based but based on pages/indices of columns.; For instance, there is no API in the page sink to write an entry, but only to write pages of columns.; The higher-level APIs, e.g. `RField`, `REntry`, `RNTupleWriter`, take care of presenting the available data as entries where necessary. The page source also gives access to an `RNTupleDescriptor` through a read/write lock guard.; The `RNTupleDescriptor` owned by the page source changes only when new cluster meta-data are loaded.; The header and the cluster group summary information is stable throughout its lifetime (cf. format specification). ### R{NTuple,Field,Column,Cluster,...}Descriptor; The descriptor classes provide read-only access to the on-disk meta-data of an RNTuple.; The meta-data include the schema (fields and columns), information about clusters and the page locations.; The descriptor classes are closely related to the format specification. For normal read and write tasks, access to the descriptor is not necessary.; One notable exception is bulk reading, where the descriptor can be used to determine entry boundaries of clusters.; The descriptors are used internally, e.g. to build an RNTupleModel from the on-disk information.; The descriptors are also useful for inspection purposes. The descriptor classes contain a copy of the meta-data; they are not linked to an open page source.; A descriptor can be used after its originating page source has be",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:6709,load,loaded,6709,tree/ntuple/v7/doc/Architecture.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md,1,['load'],['loaded']
Performance," `PyROOT` isn't; currently aware of, and it is up to the developer to keep at lease one; Python reference alive. See `$ROOTSYS/tutorials/pyroot/zdemo.py`; (available in the latest release) for an example. Alternatively, one can; tell python to give up ownership for individual instances:. ``` {.cpp}; o = ROOT.TObject(); ROOT.SetOwnership( o, False ) # True to own, False to release; ```. #### Memory Management by Hand. If needed, you can explicitly destroy a ROOT object that you own through; its associated **`TClass`**:. ``` {.cpp}; myobject.IsA().Destructor(myobject); ```. which will send out the deletion notification to the system (thus you do; not need to care anymore at this point about Python reference counting,; the object will go, even if it's reference count it non-zero), and free; the memory. ### Performance. The performance of `PyROOT` when programming with ROOT in Python is; similar to that of Cling. Differences occur mainly because of differences; in the respective languages: C++ is much harder to parse, but once; parsed, it is much easier to optimize. Consequently, individual calls to; ROOT are typically faster from `PyROOT`, whereas loops are typically; slower. When programming in Python, the modus operandi is to consider; performance generally ""good enough"" on the outset, and when it turns out; that, it is not good enough; the performance critical part is converted; into C/C++ in an extension module. The school of thought where; pre-mature optimization is the root of all evil should find this way of; working very satisfying. In addition, if you look at their history, you; will see that many of the standard Python modules have followed this; path. Your code should always make maximum use of ROOT facilities; such that; most of the time is spending in compiled code. This goes even for very; simple things: e.g. do not compute invariant masses in Python, use; **`TLorentzVector`** instead. Moreover, before you start optimizing,; make sure that you have run a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md:22568,optimiz,optimize,22568,documentation/users-guide/PythonRuby.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md,1,['optimiz'],['optimize']
Performance," `RooFit::TestStatistics` classes. # RooFit::TestStatistics usage notes. The `RooFit::TestStatistics` namespace contains a major refactoring of the `RooAbsTestStatistic`-`RooAbsOptTestStatistic`-`RooNLLVar` inheritance tree into:. 1. statistics-based classes on the one hand;; 2. calculation/evaluation/optimization based classes on the other hand. The motivation for this refactoring was also twofold:. 1. These test statistics classes make a cleaner separation of concerns than the existing `RooAbsTestStatistic` based tree and are hence more maintainable and future proof.; 2. They provided a place for us to try out new parallelized gradient calculation methods using the `RooFit::MultiProcess` module. See the usage example below on how to use this. ## Statistics; The likelihood is the central unit on the statistics side.; The `RooAbsL` class is implemented for four kinds of likelihoods: binned, unbinned, ""subsidiary"" (an optimization for numerical stability that gathers components like global observables) and ""sum"" (over multiple components of the other types), in the correspondingly named classes `RooBinnedL`, `RooUnbinnedL`, `RooSubsidiaryL` and `RooSumL`.; These classes provide a `evaluatePartition` function that allows for computing them in parallelizable chunks that can be used by the calculator classes as they see fit. On top of the likelihood classes, we also provide for convenience a likelihood builder `buildLikelihood`, as a free function in the namespace.; This function analyzes the `pdf` and automatically constructs the proper likelihood, built; up from the available `RooAbsL` subclasses. The new classes are not per se meant to be used outside of `RooMinimizer`, although they can be.; The main reason is that they do not behave as regular `RooAbsReal` objects, but have their own interface which was kept to the minimum necessary for interacting with `RooMinimizer` as an object that encodes purely the statistics concepts.; However, we do provide the `RooRealL` c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/test_statistics.md:1103,optimiz,optimization,1103,roofit/doc/developers/test_statistics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/test_statistics.md,1,['optimiz'],['optimization']
Performance," ``2`` provide; intermediate behavior between these two extremes. Query for this feature with ``__has_builtin(__builtin_prefetch)``. ``__sync_swap``; ---------------. ``__sync_swap`` is used to atomically swap integers or pointers in memory. **Syntax**:. .. code-block:: c++. type __sync_swap(type *ptr, type value, ...). **Example of Use**:. .. code-block:: c++. int old_value = __sync_swap(&value, new_value);. **Description**:. The ``__sync_swap()`` builtin extends the existing ``__sync_*()`` family of; atomic intrinsics to allow code to atomically swap the current value with the; new value. More importantly, it helps developers write more efficient and; correct code by avoiding expensive loops around; ``__sync_bool_compare_and_swap()`` or relying on the platform specific; implementation details of ``__sync_lock_test_and_set()``. The; ``__sync_swap()`` builtin is a full barrier. ``__builtin_addressof``; -----------------------. ``__builtin_addressof`` performs the functionality of the built-in ``&``; operator, ignoring any ``operator&`` overload. This is useful in constant; expressions in C++11, where there is no other way to take the address of an; object that overloads ``operator&``. Clang automatically adds; ``[[clang::lifetimebound]]`` to the parameter of ``__builtin_addressof``. **Example of use**:. .. code-block:: c++. template<typename T> constexpr T *addressof(T &value) {; return __builtin_addressof(value);; }. ``__builtin_function_start``; -----------------------------. ``__builtin_function_start`` returns the address of a function body. **Syntax**:. .. code-block:: c++. void *__builtin_function_start(function). **Example of use**:. .. code-block:: c++. void a() {}; void *p = __builtin_function_start(a);. class A {; public:; void a(int n);; void a();; };. void A::a(int n) {}; void A::a() {}. void *pa1 = __builtin_function_start((void(A::*)(int)) &A::a);; void *pa2 = __builtin_function_start((void(A::*)()) &A::a);. **Description**:. The ``__builtin_function_st",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:117406,perform,performs,117406,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,1,['perform'],['performs']
Performance," ``MyVar+40``, and the value of; ``%idx2`` is also ``MyVar+40``. Can GEP index into vector elements?; -----------------------------------. This hasn't always been forcefully disallowed, though it's not recommended. It; leads to awkward special cases in the optimizers, and fundamental inconsistency; in the IR. In the future, it will probably be outright disallowed. What effect do address spaces have on GEPs?; -------------------------------------------. None, except that the address space qualifier on the second operand pointer type; always matches the address space qualifier on the result type. How is GEP different from ``ptrtoint``, arithmetic, and ``inttoptr``?; ---------------------------------------------------------------------. It's very similar; there are only subtle differences. With ptrtoint, you have to pick an integer type. One approach is to pick i64;; this is safe on everything LLVM supports (LLVM internally assumes pointers are; never wider than 64 bits in many places), and the optimizer will actually narrow; the i64 arithmetic down to the actual pointer size on targets which don't; support 64-bit arithmetic in most cases. However, there are some cases where it; doesn't do this. With GEP you can avoid this problem. Also, GEP carries additional pointer aliasing rules. It's invalid to take a GEP; from one object, address into a different separately allocated object, and; dereference it. IR producers (front-ends) must follow this rule, and consumers; (optimizers, specifically alias analysis) benefit from being able to rely on; it. See the `Rules`_ section for more information. And, GEP is more concise in common cases. However, for the underlying integer computation implied, there is no; difference. I'm writing a backend for a target which needs custom lowering for GEP. How do I do this?; -----------------------------------------------------------------------------------------. You don't. The integer computation implied by a GEP is target-independent.; Typ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:10042,optimiz,optimizer,10042,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,1,['optimiz'],['optimizer']
Performance," ``__weak`` objects, the current pointee is retained and then released at; the end of the current full-expression. In particular, messaging a ``__weak``; object keeps the object retained until the end of the full expression. .. code-block:: objc. __weak MyObject *weakObj;. void foo() {; // weakObj is retained before the message send and released at the end of; // the full expression.; [weakObj m];; }. This must execute atomically with respect to assignments and to the final; release of the pointee.; * For all other objects, the lvalue is loaded with primitive semantics. :arc-term:`Assignment` occurs when evaluating an assignment operator. The; semantics vary based on the qualification:. * For ``__strong`` objects, the new pointee is first retained; second, the; lvalue is loaded with primitive semantics; third, the new pointee is stored; into the lvalue with primitive semantics; and finally, the old pointee is; released. This is not performed atomically; external synchronization must be; used to make this safe in the face of concurrent loads and stores.; * For ``__weak`` objects, the lvalue is updated to point to the new pointee,; unless the new pointee is an object currently undergoing deallocation, in; which case the lvalue is updated to a null pointer. This must execute; atomically with respect to other assignments to the object, to reads from the; object, and to the final release of the new pointee.; * For ``__unsafe_unretained`` objects, the new pointee is stored into the; lvalue using primitive semantics.; * For ``__autoreleasing`` objects, the new pointee is retained, autoreleased,; and stored into the lvalue using primitive semantics. :arc-term:`Initialization` occurs when an object's lifetime begins, which; depends on its storage duration. Initialization proceeds in two stages:. #. First, a null pointer is stored into the lvalue using primitive semantics.; This step is skipped if the object is ``__unsafe_unretained``.; #. Second, if the object has an initiali",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:38901,perform,performed,38901,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,3,"['concurren', 'load', 'perform']","['concurrent', 'loads', 'performed']"
Performance," ``cmpxchg``), but no other; memory operation can happen on any thread between the load and store. A ``fence`` provides Acquire and/or Release ordering which is not part; of another operation; it is normally used along with Monotonic memory; operations. A Monotonic load followed by an Acquire fence is roughly; equivalent to an Acquire load, and a Monotonic store following a; Release fence is roughly equivalent to a Release; store. SequentiallyConsistent fences behave as both an Acquire and a; Release fence, and additionally provide a total ordering with some; complicated guarantees, see the C++ standard for details. Frontends generating atomic instructions generally need to be aware of the; target to some degree; atomic instructions are guaranteed to be lock-free, and; therefore an instruction which is wider than the target natively supports can be; impossible to generate. .. _Atomic orderings:. Atomic orderings; ================. In order to achieve a balance between performance and necessary guarantees,; there are six levels of atomicity. They are listed in order of strength; each; level includes all the guarantees of the previous level except for; Acquire/Release. (See also `LangRef Ordering <LangRef.html#ordering>`_.). .. _NotAtomic:. NotAtomic; ---------. NotAtomic is the obvious, a load or store which is not atomic. (This isn't; really a level of atomicity, but is listed here for comparison.) This is; essentially a regular load or store. If there is a race on a given memory; location, loads from that location return undef. Relevant standard; This is intended to match shared variables in C/C++, and to be used in any; other context where memory access is necessary, and a race is impossible. (The; precise definition is in `LangRef Memory Model <LangRef.html#memmodel>`_.). Notes for frontends; The rule is essentially that all memory accessed with basic loads and stores; by multiple threads should be protected by a lock or other synchronization;; otherwise, you are",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:5680,perform,performance,5680,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['perform'],['performance']
Performance," ``dest`` is a valid pointer; which has not been registered as a ``__weak`` object. ``dest`` is initialized to be equivalent to ``src``, potentially registering it; with the runtime. ``src`` may then be left in its original state, in which; case this call is equivalent to :ref:`objc_copyWeak; <arc.runtime.objc_copyWeak>`, or it may be left as null. Must be atomic with respect to calls to ``objc_storeWeak`` on ``src``. .. _arc.runtime.objc_release:. ``void objc_release(id value);``; --------------------------------. *Precondition:* ``value`` is null or a pointer to a valid object. If ``value`` is null, this call has no effect. Otherwise, it performs a; release operation exactly as if the object had been sent the ``release``; message. .. _arc.runtime.objc_retain:. ``id objc_retain(id value);``; -----------------------------. *Precondition:* ``value`` is null or a pointer to a valid object. If ``value`` is null, this call has no effect. Otherwise, it performs a retain; operation exactly as if the object had been sent the ``retain`` message. Always returns ``value``. .. _arc.runtime.objc_retainAutorelease:. ``id objc_retainAutorelease(id value);``; ----------------------------------------. *Precondition:* ``value`` is null or a pointer to a valid object. If ``value`` is null, this call has no effect. Otherwise, it performs a retain; operation followed by an autorelease operation. Equivalent to the following; code:. .. code-block:: objc. id objc_retainAutorelease(id value) {; return objc_autorelease(objc_retain(value));; }. Always returns ``value``. .. _arc.runtime.objc_retainAutoreleaseReturnValue:. ``id objc_retainAutoreleaseReturnValue(id value);``; ---------------------------------------------------. *Precondition:* ``value`` is null or a pointer to a valid object. If ``value`` is null, this call has no effect. Otherwise, it performs a retain; operation followed by the operation described in; :ref:`objc_autoreleaseReturnValue <arc.runtime.objc_autoreleaseReturnValue>",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:113614,perform,performs,113614,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['perform'],['performs']
Performance," ``emit``, together constitute the layer; concept: A layer is a way to wrap a part of a compiler pipeline (in this case; the ""opt"" phase of an LLVM compiler) whose API is opaque to ORC with an; interface that ORC can call as needed. The add method takes an; module in some input program representation (in this case an LLVM IR module); and stores it in the target ``JITDylib``, arranging for it to be passed back; to the layer's emit method when any symbol defined by that module is requested.; Each layer can complete its own work by calling the ``emit`` method of its base; layer. For example, in this tutorial our IRTransformLayer calls through to; our IRCompileLayer to compile the transformed IR, and our IRCompileLayer in; turn calls our ObjectLayer to link the object file produced by our compiler. So far we have learned how to optimize and compile our LLVM IR, but we have; not focused on when compilation happens. Our current REPL optimizes and; compiles each function as soon as it is referenced by any other code,; regardless of whether it is ever called at runtime. In the next chapter we; will introduce a fully lazy compilation, in which functions are not compiled; until they are first called at run-time. At this point the trade-offs get much; more interesting: the lazier we are, the quicker we can start executing the; first function, but the more often we will have to pause to compile newly; encountered functions. If we only code-gen lazily, but optimize eagerly, we; will have a longer startup time (as everything is optimized at that time) but; relatively short pauses as each function just passes through code-gen. If we; both optimize and code-gen lazily we can start executing the first function; more quickly, but we will have longer pauses as each function has to be both; optimized and code-gen'd when it is first executed. Things become even more; interesting if we consider interprocedural optimizations like inlining, which; must be performed eagerly. These are comple",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst:10491,optimiz,optimizes,10491,interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/BuildingAJIT2.rst,1,['optimiz'],['optimizes']
Performance," ``id``, or a type equal to the declaring class or a superclass, then it is said; to have a related result type. In this case, when invoked in an explicit; message send, it is assumed to return a type related to the type of the; receiver:. * if it is a class method, and the receiver is a class name ``T``, the message; send expression has type ``T*``; otherwise; * if it is an instance method, and the receiver has type ``T``, the message; send expression has type ``T``; otherwise; * the message send expression has the normal result type of the method. This is a new rule of the Objective-C language and applies outside of ARC. .. admonition:: Rationale. ARC's automatic code emission is more prone than most code to signature; errors, i.e. errors where a call was emitted against one method signature,; but the implementing method has an incompatible signature. Having more; precise type information helps drastically lower this risk, as well as; catching a number of latent bugs. .. _arc.optimization:. Optimization; ============. Within this section, the word :arc-term:`function` will be used to; refer to any structured unit of code, be it a C function, an; Objective-C method, or a block. This specification describes ARC as performing specific ``retain`` and; ``release`` operations on retainable object pointers at specific; points during the execution of a program. These operations make up a; non-contiguous subsequence of the computation history of the program.; The portion of this sequence for a particular retainable object; pointer for which a specific function execution is directly; responsible is the :arc-term:`formal local retain history` of the; object pointer. The corresponding actual sequence executed is the; `dynamic local retain history`. However, under certain circumstances, ARC is permitted to re-order and; eliminate operations in a manner which may alter the overall; computation history beyond what is permitted by the general ""as if""; rule of C/C++ and the :ref:`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:75474,optimiz,optimization,75474,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimization']
Performance," ``llvm.coro.end`` without having first; reached a ``llvm.coro.suspend.retcon`` has undefined behavior. The remainder of this section describes the behavior under switched-resume; lowering. This intrinsic is lowered when a coroutine is split into; the start, resume and destroy parts. In the start part, it is a no-op,; in resume and destroy parts, it is replaced with `ret void` instruction and; the rest of the block containing `coro.end` instruction is discarded.; In landing pads it is replaced with an appropriate instruction to unwind to; caller. The handling of coro.end differs depending on whether the target is; using landingpad or WinEH exception model. For landingpad based exception model, it is expected that frontend uses the; `coro.end`_ intrinsic as follows:. .. code-block:: llvm. ehcleanup:; %InResumePart = call i1 @llvm.coro.end(ptr null, i1 true, token none); br i1 %InResumePart, label %eh.resume, label %cleanup.cont. cleanup.cont:; ; rest of the cleanup. eh.resume:; %exn = load ptr, ptr %exn.slot, align 8; %sel = load i32, ptr %ehselector.slot, align 4; %lpad.val = insertvalue { ptr, i32 } undef, ptr %exn, 0; %lpad.val29 = insertvalue { ptr, i32 } %lpad.val, i32 %sel, 1; resume { ptr, i32 } %lpad.val29. The `CoroSpit` pass replaces `coro.end` with ``True`` in the resume functions,; thus leading to immediate unwind to the caller, whereas in start function it; is replaced with ``False``, thus allowing to proceed to the rest of the cleanup; code that is only needed during initial invocation of the coroutine. For Windows Exception handling model, a frontend should attach a funclet bundle; referring to an enclosing cleanuppad as follows:. .. code-block:: llvm. ehcleanup:; %tok = cleanuppad within none []; %unused = call i1 @llvm.coro.end(ptr null, i1 true, token none) [ ""funclet""(token %tok) ]; cleanupret from %tok unwind label %RestOfTheCleanup. The `CoroSplit` pass, if the funclet bundle is present, will insert; ``cleanupret from %tok unwind to caller`` befor",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:44973,load,load,44973,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['load'],['load']
Performance," ``llvm/lib/ExecutionEngine/``. Libraries for directly executing bitcode at runtime in interpreted and; JIT-compiled scenarios. ``llvm/lib/Support/``. Source code that corresponding to the header files in ``llvm/include/ADT/``; and ``llvm/include/Support/``. ``llvm/bindings``; ----------------------. Contains bindings for the LLVM compiler infrastructure to allow; programs written in languages other than C or C++ to take advantage of the LLVM; infrastructure.; LLVM project provides language bindings for OCaml and Python. ``llvm/projects``; -----------------. Projects not strictly part of LLVM but shipped with LLVM. This is also the; directory for creating your own LLVM-based projects which leverage the LLVM; build system. ``llvm/test``; -------------. Feature and regression tests and other sanity checks on LLVM infrastructure. These; are intended to run quickly and cover a lot of territory without being exhaustive. ``test-suite``; --------------. A comprehensive correctness, performance, and benchmarking test suite; for LLVM. This comes in a ``separate git repository; <https://github.com/llvm/llvm-test-suite>``, because it contains a; large amount of third-party code under a variety of licenses. For; details see the :doc:`Testing Guide <TestingGuide>` document. .. _tools:. ``llvm/tools``; --------------. Executables built out of the libraries; above, which form the main part of the user interface. You can always get help; for a tool by typing ``tool_name -help``. The following is a brief introduction; to the most important tools. More detailed information is in; the `Command Guide <CommandGuide/index.html>`_. ``bugpoint``. ``bugpoint`` is used to debug optimization passes or code generation backends; by narrowing down the given test case to the minimum number of passes and/or; instructions that still cause a problem, whether it is a crash or; miscompilation. See `<HowToSubmitABug.html>`_ for more information on using; ``bugpoint``. ``llvm-ar``. The archiver produces ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst:38215,perform,performance,38215,interpreter/llvm-project/llvm/docs/GettingStarted.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GettingStarted.rst,1,['perform'],['performance']
Performance," ``no-`` prefix, and; ``off`` is specified by including the ``no-`` prefix. The default; if not specified is ``off``. For example:. ``-mcpu=gfx908:xnack+``; Enable the ``xnack`` feature.; ``-mcpu=gfx908:xnack-``; Disable the ``xnack`` feature.; ``-mcumode``; Enable the ``cumode`` feature.; ``-mno-cumode``; Disable the ``cumode`` feature. .. table:: AMDGPU Target Features; :name: amdgpu-target-features-table. =============== ============================ ==================================================; Target Feature Clang Option to Control Description; Name; =============== ============================ ==================================================; cumode - ``-m[no-]cumode`` Control the wavefront execution mode used; when generating code for kernels. When disabled; native WGP wavefront execution mode is used,; when enabled CU wavefront execution mode is used; (see :ref:`amdgpu-amdhsa-memory-model`). sramecc - ``-mcpu`` If specified, generate code that can only be; - ``--offload-arch`` loaded and executed in a process that has a; matching setting for SRAMECC. If not specified for code object V2 to V3, generate; code that can be loaded and executed in a process; with SRAMECC enabled. If not specified for code object V4 or above, generate; code that can be loaded and executed in a process; with either setting of SRAMECC. tgsplit ``-m[no-]tgsplit`` Enable/disable generating code that assumes; work-groups are launched in threadgroup split mode.; When enabled the waves of a work-group may be; launched in different CUs. wavefrontsize64 - ``-m[no-]wavefrontsize64`` Control the wavefront size used when; generating code for kernels. When disabled; native wavefront size 32 is used, when enabled; wavefront size 64 is used. xnack - ``-mcpu`` If specified, generate code that can only be; - ``--offload-arch`` loaded and executed in a process that has a; matching setting for XNACK replay. If not specified for code object V2 to V3, generate; code that can be loaded and execut",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:17260,load,loaded,17260,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loaded']
Performance, ``r600`` AMD GPUs HD2XXX-HD6XXX for graphics and compute shaders.; ``amdgcn`` AMD GPUs GCN GFX6 onwards for graphics and compute shaders.; ============ ==============================================================. .. table:: AMDGPU Vendors; :name: amdgpu-vendor-table. ============ ==============================================================; Vendor Description; ============ ==============================================================; ``amd`` Can be used for all AMD GPU usage.; ``mesa3d`` Can be used if the OS is ``mesa3d``.; ============ ==============================================================. .. table:: AMDGPU Operating Systems; :name: amdgpu-os. ============== ============================================================; OS Description; ============== ============================================================; *<empty>* Defaults to the *unknown* OS.; ``amdhsa`` Compute kernels executed on HSA [HSA]_ compatible runtimes; such as:. - AMD's ROCm™ runtime [AMD-ROCm]_ using the *rocm-amdhsa*; loader on Linux. See *AMD ROCm Platform Release Notes*; [AMD-ROCm-Release-Notes]_ for supported hardware and; software.; - AMD's PAL runtime using the *pal-amdhsa* loader on; Windows. ``amdpal`` Graphic shaders and compute kernels executed on AMD's PAL; runtime using the *pal-amdpal* loader on Windows and Linux; Pro.; ``mesa3d`` Graphic shaders and compute kernels executed on AMD's Mesa; 3D runtime using the *mesa-mesa3d* loader on Linux.; ============== ============================================================. .. table:: AMDGPU Environments; :name: amdgpu-environment-table. ============ ==============================================================; Environment Description; ============ ==============================================================; *<empty>* Default.; ============ ==============================================================. .. _amdgpu-processors:. Processors; ----------. Use the Clang options ``-mcpu=<target-id>`` or ``--offload-arch=<tar,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:2415,load,loader,2415,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loader']
Performance," ``replaceWithNewValue`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This method is a simple helper method that is provided to make clients easier to; use. It is implemented by copying the old analysis information to the new; value, then deleting the old value. This method cannot be overridden by alias; analysis implementations. The ``addEscapingUse`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``addEscapingUse`` method is used when the uses of a pointer value have; changed in ways that may invalidate precomputed analysis information.; Implementations may either use this callback to provide conservative responses; for points whose uses have change since analysis time, or may recompute some or; all of their internal state to continue providing accurate responses. In general, any new use of a pointer value is considered an escaping use, and; must be reported through this callback, *except* for the uses below:. * A ``bitcast`` or ``getelementptr`` of the pointer; * A ``store`` through the pointer (but not a ``store`` *of* the pointer); * A ``load`` through the pointer. Efficiency Issues; -----------------. From the LLVM perspective, the only thing you need to do to provide an efficient; alias analysis is to make sure that alias analysis **queries** are serviced; quickly. The actual calculation of the alias analysis results (the ""run""; method) is only performed once, but many (perhaps duplicate) queries may be; performed. Because of this, try to move as much computation to the run method; as possible (within reason). Limitations; -----------. The AliasAnalysis infrastructure has several limitations which make writing a; new ``AliasAnalysis`` implementation difficult. There is no way to override the default alias analysis. It would be very useful; to be able to do something like ""``opt -my-aa -O2``"" and have it use ``-my-aa``; for all passes which need AliasAnalysis, but there is currently no support for; that, short of changing the source code and recompiling. Similarly, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:16408,load,load,16408,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,1,['load'],['load']
Performance," ``urem`` or ``srem``; instruction.; - The condition operand of a :ref:`br <i_br>` instruction.; - The callee operand of a :ref:`call <i_call>` or :ref:`invoke <i_invoke>`; instruction.; - The parameter operand of a :ref:`call <i_call>` or :ref:`invoke <i_invoke>`; instruction, when the function or invoking call site has a ``noundef``; attribute in the corresponding position.; - The operand of a :ref:`ret <i_ret>` instruction if the function or invoking; call site has a `noundef` attribute in the return value position. Here are some examples:. .. code-block:: llvm. entry:; %poison = sub nuw i32 0, 1 ; Results in a poison value.; %poison2 = sub i32 poison, 1 ; Also results in a poison value.; %still_poison = and i32 %poison, 0 ; 0, but also poison.; %poison_yet_again = getelementptr i32, ptr @h, i32 %still_poison; store i32 0, ptr %poison_yet_again ; Undefined behavior due to; ; store to poison. store i32 %poison, ptr @g ; Poison value stored to memory.; %poison3 = load i32, ptr @g ; Poison value loaded back from memory. %poison4 = load i16, ptr @g ; Returns a poison value.; %poison5 = load i64, ptr @g ; Returns a poison value. %cmp = icmp slt i32 %poison, 0 ; Returns a poison value.; br i1 %cmp, label %end, label %end ; undefined behavior. end:. .. _welldefinedvalues:. Well-Defined Values; -------------------. Given a program execution, a value is *well defined* if the value does not; have an undef bit and is not poison in the execution.; An aggregate value or vector is well defined if its elements are well defined.; The padding of an aggregate isn't considered, since it isn't visible; without storing it into memory and loading it with a different type. A constant of a :ref:`single value <t_single_value>`, non-vector type is well; defined if it is neither '``undef``' constant nor '``poison``' constant.; The result of :ref:`freeze instruction <i_freeze>` is well defined regardless; of its operand. .. _blockaddress:. Addresses of Basic Blocks; -------------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:198867,load,load,198867,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,['load'],"['load', 'loaded']"
Performance," `opcode-index`, `opcode-name` or `snippets-file` must be set. .. option:: --snippets-file=<filename>. Specify the custom code snippet to measure. See example 2 for details.; Either `opcode-index`, `opcode-name` or `snippets-file` must be set. .. option:: --mode=[latency|uops|inverse_throughput|analysis]. Specify the run mode. Note that some modes have additional requirements and options. `latency` mode can be make use of either RDTSC or LBR.; `latency[LBR]` is only available on X86 (at least `Skylake`).; To run in `latency` mode, a positive value must be specified; for `x86-lbr-sample-period` and `--repetition-mode=loop`. In `analysis` mode, you also need to specify at least one of the; `-analysis-clusters-output-file=` and `-analysis-inconsistencies-output-file=`. .. option:: --benchmark-phase=[prepare-snippet|prepare-and-assemble-snippet|assemble-measured-code|measure]. By default, when `-mode=` is specified, the generated snippet will be executed; and measured, and that requires that we are running on the hardware for which; the snippet was generated, and that supports performance measurements.; However, it is possible to stop at some stage before measuring. Choices are:; * ``prepare-snippet``: Only generate the minimal instruction sequence.; * ``prepare-and-assemble-snippet``: Same as ``prepare-snippet``, but also dumps an excerpt of the sequence (hex encoded).; * ``assemble-measured-code``: Same as ``prepare-and-assemble-snippet``. but also creates the full sequence that can be dumped to a file using ``--dump-object-to-disk``.; * ``measure``: Same as ``assemble-measured-code``, but also runs the measurement. .. option:: --x86-lbr-sample-period=<nBranches/sample>. Specify the LBR sampling period - how many branches before we take a sample.; When a positive value is specified for this option and when the mode is `latency`,; we will use LBRs for measuring.; On choosing the ""right"" sampling period, a small value is preferred, but throttling; could occur if the sam",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:10784,perform,performance,10784,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,1,['perform'],['performance']
Performance," `pn1->Align()` will invalidate the pointer to the node `B_1`; in `pn2` object.. The way out is to either call `pn1->Align()` before; the creation of `pn2`, either to use a global method that will correct; all existing physical nodes:. ~~~{.cpp}; void RefreshPhysicalNodes(Bool_t lock = kTRUE); ~~~. The method above will optionally lock the possibility of doing any; further misalignment. \anchor GP06; ## Geometry I/O. Once geometry is successfully built, it can be saved in a root file, as; C++ macro or as GDML file by calling:. ~~~{.cpp}; TGeoManager::Export(const char *filename,const char*keyname="""",; Option_t *opt=""vg""); ~~~. - `Filename` is the name of the file to be written (mandatory).; Depending on the extension of the file, the geometry is exported; either as ,root file or .C(.cxx) macro or GDML file in case; extension is .gdml.; - `keyname`is the name of the key in the file (default """"); - `opt` = `""v""` is an export voxelization (default), otherwise; voxelization is recomputed after loading the geometry, `""g""` this; option (default) is taken into account only for exporting to gdml; file and it ensures compatibility with Geant4 (e.g. it adds extra; plane to incorrectly set polycone, it checks whether offset of Phi; division is in (-360;0\> range, ...), for this gdml export there are; two more option, that are not set by default: `""f""` and `""n""`. If; none of this two options are set, then names of solids and volumes; in resulting gdml file will have incremental suffix (e.g.; TGeoBBox\_0x1, TGeoBBox\_0x2, ...). If `""f""` option is set then then; suffix will contain pointer of object (e.g. TGeoBBox\_0xAAAAA01,; ...). Finally if option `""n""` is set then no suffix will be added,; though in this case uniqueness of the names is not ensured and it can; cause that file will be invalid. Loading geometry from a root file can be done in the same way as for any; other ROOT object, but a static method is also provided:. ~~~{.cpp}; TGeoManager::Import(const char *filename,cons",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:111205,load,loading,111205,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['load'],['loading']
Performance," a CU. Therefore:. * No special action is required for coherence between the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_inv sc0`` is required which will invalidate; the L1 cache. * A ``buffer_inv sc0`` is required to invalidate the L1 cache for coherence; between wavefronts executing in different work-groups as they may be; executing on different CUs. * Atomic read-modify-write instructions implicitly bypass the L1 cache.; Therefore, they do not use the sc0 bit for coherence and instead use it to; indicate if the instruction returns the original value being updated. They; do use sc1 to indicate system or agent scope coherence. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache. * The gfx942 can be configured as a number of smaller agents with each having; a single L2 shared by all CUs on the same agent, or as fewer (possibly one); larger agents with groups of CUs on each agent each sharing separate L2; caches.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel for its associated L2.; Therefore, the vector and scalar memory operations performed by wavefronts; executing with different L1 caches and the same L2 cache can be reordered; relative to each other.; * A ``s_waitcnt vmcnt(0)`` is required to ensure synchronization between; vector memory operations of different CUs. It ensures a previous vector; memory operation has completed before executing a subs",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:287079,cache,caches,287079,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['caches']
Performance," a CU. Therefore:. * No special action is required for coherence between the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_wbinvl1_vol`` is required as described in; the following item. * A ``buffer_wbinvl1_vol`` is required for coherence between wavefronts; executing in different work-groups as they may be executing on different; CUs. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent. * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs), or the same; work-group if executing in tgsplit mode, of an agent can be reordered; relative to each other. A ``s_waitcnt vmcnt(0)`` is required to ensure; synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache of one agent can be kept coherent with other agents by:; using the MTYPE RW (read-write) or MTYPE CC (cache-coherent) with the PTE; C-bit for memory local to the L2; and using the MTYPE NC (non-coherent) with; the PTE C-bit set or MTYPE UC (uncached) for memory not local to the L2. * Any local memory cache lines w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:236895,cache,cache,236895,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," a binary with SSL; support. #### Ubuntu/Debian; On Debian, Ubuntu, Linux Mint, CrunchBang, or any other distro based on Debian; which supports APT package manager, you can install all the required packages by:; ```sh; sudo apt-get update; sudo apt-get install git g++ debhelper devscripts gnupg python; ```; You are not required to do this manually since CPT can do this for you automatically. ###### Setting up:; Make sure GnuPG is properly set up with your correct fingerprint. These; credentials are needed to sign the Debian package and create Debian changelogs.; On a build machine (Electric Commander), make sure the fingerprint is of the; user who is supposed to sign the official uploads. You might also want to; configure GnuPG to not ask for the passphrase while signing the Debian package. The [Ubuntu Packaging Guide] contains a quick guide on creating a GPG key on an; Ubuntu system. To test if you have successfully set up your GnuPG key, use the following command:; ```sh; gpg --fingerprint; ```; Again, all these checks are performed by default when you launch CPT with ```-c``` option.; [Ubuntu Packaging Guide]:http://packaging.ubuntu.com/html/getting-set-up.html#create-your-gpg-key. #### Windows; CPT is meant to be executed on cmd.exe prompt. Make sure you have set the; environment properly before continuing.; Below is a list of required packages for Windows (Win32-x86):. [MSYS Git] for Windows. [Python] for Windows. Microsoft Visual Studio 11 (2012), with Microsoft Visual C++ 2012. [MSYS Git]:http://msysgit.github.io/; [Python]:https://www.python.org/. ###### Setting Up:; Unlike other UNIX-like platforms, Windows requires you to follow some rules.; Do not ignore this section unless you want CPT to fail mid-way with wierd; errors. You should require these instructions only once. * While installing the packages make sure the executable is in a path that; doesn't contain spaces. For example, you should install Python in a path like. ```sh; C:\Python27; ```; rather t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:3390,perform,performed,3390,interpreter/cling/tools/packaging/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md,1,['perform'],['performed']
Performance," a conversion on; values returned from a function for some calling conventions. See `issue; #66803 <https://github.com/llvm/llvm-project/issues/66803>`_.; - Older MIPS versions use the opposite polarity for the quiet/signaling bit, and; LLVM does not correctly represent this. See `issue #60796; <https://github.com/llvm/llvm-project/issues/60796>`_. .. _fastmath:. Fast-Math Flags; ---------------. LLVM IR floating-point operations (:ref:`fneg <i_fneg>`, :ref:`fadd <i_fadd>`,; :ref:`fsub <i_fsub>`, :ref:`fmul <i_fmul>`, :ref:`fdiv <i_fdiv>`,; :ref:`frem <i_frem>`, :ref:`fcmp <i_fcmp>`), :ref:`phi <i_phi>`,; :ref:`select <i_select>` and :ref:`call <i_call>`; may use the following flags to enable otherwise unsafe; floating-point transformations. ``nnan``; No NaNs - Allow optimizations to assume the arguments and result are not; NaN. If an argument is a nan, or the result would be a nan, it produces; a :ref:`poison value <poisonvalues>` instead. ``ninf``; No Infs - Allow optimizations to assume the arguments and result are not; +/-Inf. If an argument is +/-Inf, or the result would be +/-Inf, it; produces a :ref:`poison value <poisonvalues>` instead. ``nsz``; No Signed Zeros - Allow optimizations to treat the sign of a zero; argument or zero result as insignificant. This does not imply that -0.0; is poison and/or guaranteed to not exist in the operation. ``arcp``; Allow Reciprocal - Allow optimizations to use the reciprocal of an; argument rather than perform division. ``contract``; Allow floating-point contraction (e.g. fusing a multiply followed by an; addition into a fused multiply-and-add). This does not enable reassociating; to form arbitrary contractions. For example, ``(a*b) + (c*d) + e`` can not; be transformed into ``(a*b) + ((c*d) + e)`` to create two fma operations. .. _fastmath_afn:. ``afn``; Approximate functions - Allow substitution of approximate calculations for; functions (sin, log, sqrt, etc). See floating-point intrinsic definitions; for places where th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:162051,optimiz,optimizations,162051,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizations']
Performance," a custom streamer nor of any data members marked with //||. Run time performance. We introduced an optimized infrastructure for reading objects using a StreamerInfo. Rather than driving the streaming using a switch statement inside TStreamerInfo::ReadBuffer,; the streaming is now driven using a simple loop over a sequence of configured StreamerInfo actions. This improves run-time performance by allowing a dramatic reduction in function calls and code; branches at the expense of some code duplication. There are 3 versions of this loop implemented in TBufferFile and overloaded in TBufferXML and TBufferSQL:. virtual Int_t ReadSequence(const TStreamerInfoActions::TActionSequence &sequence, void *object);; virtual Int_t ReadSequence(const TStreamerInfoActions::TActionSequence &sequence,; void *start_collection, void *end_collection);; virtual Int_t ReadSequence(const TStreamerInfoActions::TActionSequence &sequence,; void *start_collection, void *end_collection);. The 1st version is optimized to read a single object. The 2nd version is optimized to read the content of TClonesArrays and vectors of pointers to objects. The 3rd version is used to streamed any collections. TBufferXML and TBufferSQL overload the loops to introduce extra code to help the buffer keep track of which streamer element is being streamed (this functionality is not used by TBufferFile.). A TStreamerInfoActions::TActionSequence is an ordered sequence of configured actions. A configured action has both an action which is a free standing function and a configuration object deriving; from TStreamerInfoActions::TConfiguration. The configuration contains information that is specific to the action; but varies from use to use, including the offset from the beginning of the object that needs to be updated.; Other examples of configuration include the number of bits requested for storing a Double32_t or its factor and minimum. When the sequence is intended for a collection, the sequence has a configuration obj",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html:3748,optimiz,optimized,3748,io/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v528/index.html,1,['optimiz'],['optimized']
Performance," a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L0 and L1 caches at the start of each kernel dispatch.; * On dGPU the kernarg backing memory is accessed as MTYPE UC (uncached) to avoid; needing to invalidate the L2 cache.; * On APU the kernarg backing memory is accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC (non-coherent). Since the private address space is only accessed; by a single thread, and is always write-before-read, there is never a need to; invalidate these entries from the L0 or L1 caches. Wavefronts are executed in native mode with in-order reporting of loads and; sample instructions. In this mode vmcnt reports completion of load, atomic with; return and sample instructions in order, and the vscnt reports the completion of; store and atomic without return in order. See ``MEM_ORDERED`` field in; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`. Wavefronts can be executed in WGP or CU wavefront execution mode:. * In WGP wavefront execution mode the wavefronts of a work-group are executed; on the SIMDs of both CUs of the WGP. Therefore, explicit management of the per; CU L0 caches is required for work-group synchronization. Also accesses to L1; at work-group scope need to be explicitly ordered as the accesses from; different CUs are not ordered.; * In CU wavefront execution mode the wavefronts of a work-group are executed on; the SIMDs of a single CU of the WGP. Therefore, all global memory access by; the work-group access the same L0 which in turn ensures L1 accesses are; ordered and so do not require explicit management of the caches for; work-group synchronization. See ``WGP_MODE`` field in; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table` a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:341957,load,load,341957,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance," a hardware-loop instruction.; The result is the conditional value of whether the given count is not zero. '``llvm.test.start.loop.iterations.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. ::. declare {i32, i1} @llvm.test.start.loop.iterations.i32(i32); declare {i64, i1} @llvm.test.start.loop.iterations.i64(i64). Overview:; """""""""""""""""". The '``llvm.test.start.loop.iterations.*``' intrinsics are similar to the; '``llvm.test.set.loop.iterations.*``' and '``llvm.start.loop.iterations.*``'; intrinsics, used to specify the hardware-loop trip count, but also produce a; value identical to the input that can be used as the input to the loop. The; second i1 output controls entry to a while-loop. Arguments:; """""""""""""""""""". The integer operand is the loop trip count of the hardware-loop, and thus; not e.g. the loop back-edge taken count. Semantics:; """""""""""""""""""". The '``llvm.test.start.loop.iterations.*``' intrinsics do not perform any; arithmetic on their operand. It's a hint to the backend that can use this to; set up the hardware-loop count with a target specific instruction, usually a; move of this value to a special register or a hardware-loop instruction.; The result is a pair of the input and a conditional value of whether the; given count is not zero. '``llvm.loop.decrement.reg.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. ::. declare i32 @llvm.loop.decrement.reg.i32(i32, i32); declare i64 @llvm.loop.decrement.reg.i64(i64, i64). Overview:; """""""""""""""""". The '``llvm.loop.decrement.reg.*``' intrinsics are used to lower the loop; iteration counter and return an updated value that will be used in the next; loop test check. Arguments:; """""""""""""""""""". Both arguments must have identical integer types. The first operand is the; loop iteration counter. The second operand is the maximum number of elements; processed in an iteration. Semantics:; """""""""""""""""""". Th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:647293,perform,perform,647293,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance," a list of lists you; make a list of variable names that refer to other lists. For example:. .. code-block:: cmake. set(list_of_lists a b c); set(a 1 2 3); set(b 4 5 6); set(c 7 8 9). With this layout you can iterate through the list of lists printing each value; with the following code:. .. code-block:: cmake. foreach(list_name IN LISTS list_of_lists); foreach(value IN LISTS ${list_name}); message(${value}); endforeach(); endforeach(). You'll notice that the inner foreach loop's list is doubly dereferenced. This is; because the first dereference turns ``list_name`` into the name of the sub-list; (a, b, or c in the example), then the second dereference is to get the value of; the list. This pattern is used throughout CMake, the most common example is the compiler; flags options, which CMake refers to using the following variable expansions:; CMAKE_${LANGUAGE}_FLAGS and CMAKE_${LANGUAGE}_FLAGS_${CMAKE_BUILD_TYPE}. Other Types; -----------. Variables that are cached or specified on the command line can have types; associated with them. The variable's type is used by CMake's UI tool to display; the right input field. A variable's type generally doesn't impact evaluation,; however CMake does have special handling for some variables such as PATH.; You can read more about the special handling in `CMake's set documentation; <https://cmake.org/cmake/help/v3.5/command/set.html#set-cache-entry>`_. Scope; -----. CMake inherently has a directory-based scoping. Setting a variable in a; CMakeLists file, will set the variable for that file, and all subdirectories.; Variables set in a CMake module that is included in a CMakeLists file will be; set in the scope they are included from, and all subdirectories. When a variable that is already set is set again in a subdirectory it overrides; the value in that scope and any deeper subdirectories. The CMake set command provides two scope-related options. PARENT_SCOPE sets a; variable into the parent scope, and not the current scope. The CA",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst:5731,cache,cached,5731,interpreter/llvm-project/llvm/docs/CMakePrimer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CMakePrimer.rst,1,['cache'],['cached']
Performance," a positive, constant integer with; ``%Stride >= <Rows>``. ``%Stride`` is used to compute the column memory; addresses. I.e., for a column ``C``, its start memory addresses is calculated; with ``%Ptr + C * %Stride``. The fourth argument ``<IsVolatile>`` is a boolean; value. The arguments ``<Rows>`` and ``<Cols>`` correspond to the number of rows; and columns, respectively, and must be positive, constant integers. The :ref:`align <attr_align>` parameter attribute can be provided; for the ``%Ptr`` arguments. Half Precision Floating-Point Intrinsics; ----------------------------------------. For most target platforms, half precision floating-point is a; storage-only format. This means that it is a dense encoding (in memory); but does not support computation in the format. This means that code must first load the half-precision floating-point; value as an i16, then convert it to float with; :ref:`llvm.convert.from.fp16 <int_convert_from_fp16>`. Computation can; then be performed on the float value (including extending to double; etc). To store the value back to memory, it is first converted to float; if needed, then converted to i16 with; :ref:`llvm.convert.to.fp16 <int_convert_to_fp16>`, then storing as an; i16 value. .. _int_convert_to_fp16:. '``llvm.convert.to.fp16``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i16 @llvm.convert.to.fp16.f32(float %a); declare i16 @llvm.convert.to.fp16.f64(double %a). Overview:; """""""""""""""""". The '``llvm.convert.to.fp16``' intrinsic function performs a conversion from a; conventional floating-point type to half precision floating-point format. Arguments:; """""""""""""""""""". The intrinsic function contains single argument - the value to be; converted. Semantics:; """""""""""""""""""". The '``llvm.convert.to.fp16``' intrinsic function performs a conversion from a; conventional floating-point format to half precision floating-point format. The; return value is an ``i16`` which contains the converted number. Examples:; """"""""",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:681194,perform,performed,681194,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance," a value against a constant, emit the check using a consistent; comparison type. The GVN pass *will* optimize redundant equalities even if; the type of comparison is inverted, but GVN only runs late in the pipeline.; As a result, you may miss the opportunity to run other important; optimizations. #. Avoid using arithmetic intrinsics unless you are *required* by your source; language specification to emit a particular code sequence. The optimizer; is quite good at reasoning about general control flow and arithmetic, it is; not anywhere near as strong at reasoning about the various intrinsics. If; profitable for code generation purposes, the optimizer will likely form the; intrinsics itself late in the optimization pipeline. It is *very* rarely; profitable to emit these directly in the language frontend. This item; explicitly includes the use of the :ref:`overflow intrinsics <int_overflow>`. #. Avoid using the :ref:`assume intrinsic <int_assume>` until you've; established that a) there's no other way to express the given fact and b); that fact is critical for optimization purposes. Assumes are a great; prototyping mechanism, but they can have negative effects on both compile; time and optimization effectiveness. The former is fixable with enough; effort, but the later is fairly fundamental to their designed purpose. Describing Language Specific Properties; =======================================. When translating a source language to LLVM, finding ways to express concepts; and guarantees available in your source language which are not natively; provided by LLVM IR will greatly improve LLVM's ability to optimize your code.; As an example, C/C++'s ability to mark every add as ""no signed wrap (nsw)"" goes; a long way to assisting the optimizer in reasoning about loop induction; variables and thus generating more optimal code for loops. The LLVM LangRef includes a number of mechanisms for annotating the IR with; additional semantic information. It is *strongly* recommended ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:9535,optimiz,optimization,9535,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['optimiz'],['optimization']
Performance," a; multiple of ``element_size`` bytes wide and aligned at an ``element_size`` boundary. The order of the assignment is unspecified. Only one write is issued to the; destination buffer per element. It is well defined to have concurrent reads and; writes to the destination provided those reads and writes are unordered atomic; when specified. This intrinsic does not provide any additional ordering guarantees over those; provided by a set of unordered stores to the destination. Lowering:; """""""""""""""""". In the most general case call to the '``llvm.memset.element.unordered.atomic.*``' is; lowered to a call to the symbol ``__llvm_memset_element_unordered_atomic_*``. Where '*'; is replaced with an actual element size. The optimizer is allowed to inline the memory assignment when it's profitable to do so. Objective-C ARC Runtime Intrinsics; ----------------------------------. LLVM provides intrinsics that lower to Objective-C ARC runtime entry points.; LLVM is aware of the semantics of these functions, and optimizes based on that; knowledge. You can read more about the details of Objective-C ARC `here; <https://clang.llvm.org/docs/AutomaticReferenceCounting.html>`_. '``llvm.objc.autorelease``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare ptr @llvm.objc.autorelease(ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_autorelease <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#arc-runtime-objc-autorelease>`_. '``llvm.objc.autoreleasePoolPop``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare void @llvm.objc.autoreleasePoolPop(ptr). Lowering:; """""""""""""""""". Lowers to a call to `objc_autoreleasePoolPop <https://clang.llvm.org/docs/AutomaticReferenceCounting.html#void-objc-autoreleasepoolpop-void-pool>`_. '``llvm.objc.autoreleasePoolPush``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; ::. declare ptr @llvm.objc.autoreleasePoolPush(). Lowering:; """""""""""""""""". Lowers to a c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:966252,optimiz,optimizes,966252,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizes']
Performance," abi, align stack slot of argument of type double on 8 byte; boundary to improve performance. //===---------------------------------------------------------------------===//. GCC's ix86_expand_int_movcc function (in i386.c) has a ton of interesting; simplifications for integer ""x cmp y ? a : b"". //===---------------------------------------------------------------------===//. Consider the expansion of:. define i32 @test3(i32 %X) {; %tmp1 = urem i32 %X, 255; ret i32 %tmp1; }. Currently it compiles to:. ...; movl $2155905153, %ecx; movl 8(%esp), %esi; movl %esi, %eax; mull %ecx; ... This could be ""reassociated"" into:. movl $2155905153, %eax; movl 8(%esp), %ecx; mull %ecx. to avoid the copy. In fact, the existing two-address stuff would do this; except that mul isn't a commutative 2-addr instruction. I guess this has; to be done at isel time based on the #uses to mul?. //===---------------------------------------------------------------------===//. Make sure the instruction which starts a loop does not cross a cacheline; boundary. This requires knowning the exact length of each machine instruction.; That is somewhat complicated, but doable. Example 256.bzip2:. In the new trace, the hot loop has an instruction which crosses a cacheline; boundary. In addition to potential cache misses, this can't help decoding as I; imagine there has to be some kind of complicated decoder reset and realignment; to grab the bytes from the next cacheline. 532 532 0x3cfc movb (1809(%esp, %esi), %bl <<<--- spans 2 64 byte lines; 942 942 0x3d03 movl %dh, (1809(%esp, %esi); 937 937 0x3d0a incl %esi; 3 3 0x3d0b cmpb %bl, %dl; 27 27 0x3d0d jnz 0x000062db <main+11707>. //===---------------------------------------------------------------------===//. In c99 mode, the preprocessor doesn't like assembly comments like #TRUNCATE. //===---------------------------------------------------------------------===//. This could be a single 16-bit load. int f(char *p) {; if ((p[0] == 1) & (p[1] == 2)) return 1;;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:10522,cache,cacheline,10522,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,1,['cache'],['cacheline']
Performance," able to query the AST file to find entities stored there. For each Clang data structure that requires direct interaction with the AST; reader logic, there is an abstract class that provides the interface between; the two modules. The ``ASTReader`` class, which handles the loading of an AST; file, inherits from all of these abstract classes to provide lazy; deserialization of Clang's data structures. ``ASTReader`` implements the; following abstract classes:. ``ExternalSLocEntrySource``; This abstract interface is associated with the ``SourceManager`` class, and; is used whenever the :ref:`source manager <pchinternals-sourcemgr>` needs to; load the details of a file, buffer, or macro instantiation. ``IdentifierInfoLookup``; This abstract interface is associated with the ``IdentifierTable`` class, and; is used whenever the program source refers to an identifier that has not yet; been seen. In this case, the AST reader searches for this identifier within; its :ref:`identifier table <pchinternals-ident-table>` to load any top-level; declarations or macros associated with that identifier. ``ExternalASTSource``; This abstract interface is associated with the ``ASTContext`` class, and is; used whenever the abstract syntax tree nodes need to loaded from the AST; file. It provides the ability to de-serialize declarations and types; identified by their numeric values, read the bodies of functions when; required, and read the declarations stored within a declaration context; (either for iteration or for name lookup). ``ExternalSemaSource``; This abstract interface is associated with the ``Sema`` class, and is used; whenever semantic analysis needs to read information from the :ref:`global; method pool <pchinternals-method-pool>`. .. _pchinternals-chained:. Chained precompiled headers; ---------------------------. Chained precompiled headers were initially intended to improve the performance; of IDE-centric operations such as syntax highlighting and code completion while; a par",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst:22772,load,load,22772,interpreter/llvm-project/clang/docs/PCHInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst,1,['load'],['load']
Performance," accesses a different L2 channel. Each L1; quadrant has a separate request queue per L2 channel. Therefore, the vector; and scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different SAs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0) & vscnt(0)`` is; required to ensure synchronization between vector memory operations of; different SAs. It ensures a previous vector memory operation has completed; before executing a subsequent vector memory and so can be used to meet the; requirements of acquire, release and sequential consistency.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence.; * On GFX10.3 and GFX11 a memory attached last level (MALL) cache exists for GPU memory.; The MALL cache is fully coherent with GPU memory and has no impact on system; coherence. All agents (GPU and CPU) access GPU memory through the MALL cache. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:339958,cache,cache,339958,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," actually see any benefits from modules, one first has to introduce module maps for the underlying C standard library and the libraries and headers on which it depends. The section `Modularizing a Platform`_ describes the steps one must take to write these module maps. One can use module maps without modules to check the integrity of the use of header files. To do this, use the ``-fimplicit-module-maps`` option instead of the ``-fmodules`` option, or use ``-fmodule-map-file=`` option to explicitly specify the module map files to load. Compilation model; -----------------; The binary representation of modules is automatically generated by the compiler on an as-needed basis. When a module is imported (e.g., by an ``#include`` of one of the module's headers), the compiler will spawn a second instance of itself [#]_, with a fresh preprocessing context [#]_, to parse just the headers in that module. The resulting Abstract Syntax Tree (AST) is then persisted into the binary representation of the module that is then loaded into translation unit where the module import was encountered. The binary representation of modules is persisted in the *module cache*. Imports of a module will first query the module cache and, if a binary representation of the required module is already available, will load that representation directly. Thus, a module's headers will only be parsed once per language configuration, rather than once per translation unit that uses the module. Modules maintain references to each of the headers that were part of the module build. If any of those headers changes, or if any of the modules on which a module depends change, then the module will be (automatically) recompiled. The process should never require any user intervention. Command-line parameters; -----------------------; ``-fmodules``; Enable the modules feature. ``-fbuiltin-module-map``; Load the Clang builtins module map file. (Equivalent to ``-fmodule-map-file=<resource dir>/include/module.modulemap``)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:13587,load,loaded,13587,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['load'],['loaded']
Performance," added as follows:. ``` {.json}; ""<json-key>"": {; ""class"": ""<C++ class name>"",; ""arguments"": [; ""<json-key of constructor argument #1>"",; ""<json-key of constructor argument #2>"",; ...; ]; }; ```. Similarly, for the exporter, an entry in the; [export keys](https://github.com/root-project/root/blob/master/etc/RooFitHS3_wsexportkeys.json); needs to be added as follows:. ``` {.json}; ""<C++ class name>"": {; ""type"": ""<json-key>"",; ""proxies"": {; ""<name of proxy>"": ""<json-key of this element>"",; ""<name of proxy>"": ""<json-key of this element>"",; ...; }; }; ```. If you don't want to edit the central `json` files containing the; factory expressions or export keys, you can also put your custom; export keys or factory expressions into a different json file and load; that using `RooFit::JSONIO::loadExportKeys(const std::string; &fname)` and `RooFit::JSONIO::loadFactoryExpressions(const; std::string &fname)`. If either the importer or the exporter cannot be created with factory; expressions and export keys, you can instead write a custom `C++`; class to perform the import and export for you. ### Writing your own importers and exporters: Custom `C++` code. In order to implement your own importer or exporter, you can inherit; from the corresponding base classes `RooFit::JSONIO::Importer`; or `RooFit::JSONIO::Exporter`, respectively. You can find; [simple examples](https://github.com/root-project/root/blob/master/roofit/hs3/src/JSONFactories_RooFitCore.cxx); as well as; [more complicated ones](https://github.com/root-project/root/blob/master/roofit/hs3/src/JSONFactories_HistFactory.cxx); in `ROOT`. Any importer should take the following form:. ``` {.cpp}; class MyClassFactory : public RooFit::JSONIO::Importer {; public:; bool importFunction(RooJSONFactoryWSTool *tool, const JSONNode &p) const override; {; std::string name(RooJSONFactoryWSTool::name(p));. // check if the required keys are available in the JSON; if (!p.has_child(""<class member key #1>"")) {; RooJSONFactoryWSTool::error(",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_hs3.md:4721,perform,perform,4721,roofit/doc/developers/roofit_hs3.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/developers/roofit_hs3.md,1,['perform'],['perform']
Performance," added or subtracted. ``` {.cpp}; TGeoTranslation t1;; t1->SetTranslation(-5,10,4);; TGeoTranslation *t2 = new TGeoTranslation(4,3,10);; t2->Subtract(&t1);; ```. - Rotations (**`TGeoRotation`** class) represent a pure rotation. Data; members are `Double_t fRotationMatrix[3*3]`. Rotations can be; defined either by Euler angles, either, by GEANT3 angles:. ``` {.cpp}; TGeoRotation *r1 = new TGeoRotation();; r1->SetAngles(phi,theta,psi); // all angles in degrees; ```. This represents the composition of: first a rotation about Z axis with; angle phi, then a rotation with theta about the rotated X axis, and; finally a rotation with `psi `about the new Z axis. ``` {.cpp}; r1->SetAngles(th1,phi1,th2,phi2,th3,phi3); ```. This is a rotation defined in GEANT3 style. Theta and phi are the; spherical angles of each axis of the rotated coordinate system with; respect to the initial one. This construction allows definition of; malformed rotations, e.g. not orthogonal. A check is performed and an; error message is issued in this case. Specific utilities: determinant, inverse. - Scale transformations (**`TGeoScale`** class) - represent a scaled; shrinking/enlargement, possibly different on all axes. Data members:; `Double_t fScale[3]`. Not implemented yet.; - Combined transformations - represent a rotation followed by a; translation. Data members:; `Double_t fTranslation[3], `**`TGeoRotation *fRotation`.**. ``` {.cpp}; TGeoRotation *rot = new TGeoRotation(""rot"",10,20,30);; TGeoTranslation trans;; ...; TGeoCombiTrans *c1 = new TGeoCombiTrans(trans,rot);; TGeoCombiTrans *c2 = new TGeoCombiTrans(""somename"",10,20,30,rot); ```. - General transformations: (**`TGeoHMatrix`** class) represent; combined transformations in any order.; - Identity transformation: (**`TGeoIdentity`** class) is a generic; identity transformation represented by a singleton class object; **`gGeoIdentity`**. ### Ownership of Geometry Objects. The class **`TGeoManager`** class contains the entire API needed for; build",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:98386,perform,performed,98386,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['perform'],['performed']
Performance," address space cannot; - workgroup be used.*. 1. ds_store; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; atomicrmw monotonic - system - global 1. buffer/global/flat_atomic; - generic sc1=1; atomicrmw monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_atomic; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load sc0=1; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_inv. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load sc0=1; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_inv and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:296030,load,loads,296030,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," after; any preceding; global/generic load; atomic/; atomicrmw-with-return-value; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; atomicrmw-no-return-value; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_gl0_inv.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/; atomicrmw-with-return-value; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; atomicrmw-no-return-value; with an equal or; wider sync scope; and memory ordering; stronger than; unorde",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:352927,load,loads,352927,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to weaken, or strengthen, the memory model. Other limitations are:. * The LSUnit does not know when store-to-load forwarding may occur.; * The LSUnit does not know anything about cache hierarchy and memory types.; * The LSUnit does not know how to identify serializing operations and memory; fences. The LSUnit does not attempt to predict if a load or store hits or misses the L1; cache. It only knows if an instruction ""MayLoad"" and/or ""MayStore."" For; loads, the scheduling model provides an ""optimistic"" load-to-use latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a loa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:41309,load,loads,41309,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,5,"['latency', 'load']","['latency', 'load-to-use', 'loads']"
Performance," all formats except YAML. For example:. ``clang -fsave-optimization-record=bitstream in.c -o out`` will generate. * ``/var/folders/43/9y164hh52tv_2nrdxrj31nyw0000gn/T/a-9be59b.o``. * ``/var/folders/43/9y164hh52tv_2nrdxrj31nyw0000gn/T/a-9be59b.opt.bitstream``. * ``out``. * ``out.dSYM/Contents/Resources/Remarks/out``. Darwin-only: compiling for multiple architectures will use the following; scheme:. ``<base>-<arch>.opt.<format>``. Note that this is incompatible with passing the; :option:`-foptimization-record-file` option. .. option:: -foptimization-record-file. Control the file to which optimization reports are written. This implies; :ref:`-fsave-optimization-record <opt_fsave-optimization-record>`. On Darwin platforms, this is incompatible with passing multiple; ``-arch <arch>`` options. .. option:: -foptimization-record-passes. Only include passes which match a specified regular expression. When optimization reports are being output (see; :ref:`-fsave-optimization-record <opt_fsave-optimization-record>`), this; option controls the passes that will be included in the final report. If this option is not used, all the passes are included in the optimization; record. .. _opt_fdiagnostics-show-hotness:. .. option:: -f[no-]diagnostics-show-hotness. Enable profile hotness information in diagnostic line. This option controls whether Clang prints the profile hotness associated; with diagnostics in the presence of profile-guided optimization information.; This is currently supported with optimization remarks (see; :ref:`Options to Emit Optimization Reports <rpass>`). The hotness information; allows users to focus on the hot optimization remarks that are likely to be; more relevant for run-time performance. For example, in this output, the block containing the callsite of `foo` was; executed 3000 times according to the profile data:. ::. s.c:7:10: remark: foo inlined into bar (hotness: 3000) [-Rpass-analysis=inline]; sum += foo(x, x - 2);; ^. This option is implied when; :ref:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:13458,optimiz,optimization,13458,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,3,['optimiz'],"['optimization', 'optimization-record']"
Performance," all:. #. Each mutable variable becomes a stack allocation.; #. Each read of the variable becomes a load from the stack.; #. Each update of the variable becomes a store to the stack.; #. Taking the address of a variable just uses the stack address; directly. While this solution has solved our immediate problem, it introduced; another one: we have now apparently introduced a lot of stack traffic; for very simple and common operations, a major performance problem.; Fortunately for us, the LLVM optimizer has a highly-tuned optimization; pass named ""mem2reg"" that handles this case, promoting allocas like this; into SSA registers, inserting Phi nodes as appropriate. If you run this; example through the pass, for example, you'll get:. .. code-block:: bash. $ llvm-as < example.ll | opt -passes=mem2reg | llvm-dis; @G = weak global i32 0; @H = weak global i32 0. define i32 @test(i1 %Condition) {; entry:; br i1 %Condition, label %cond_true, label %cond_false. cond_true:; %X.0 = load i32, i32* @G; br label %cond_next. cond_false:; %X.1 = load i32, i32* @H; br label %cond_next. cond_next:; %X.01 = phi i32 [ %X.1, %cond_false ], [ %X.0, %cond_true ]; ret i32 %X.01; }. The mem2reg pass implements the standard ""iterated dominance frontier""; algorithm for constructing SSA form and has a number of optimizations; that speed up (very common) degenerate cases. The mem2reg optimization; pass is the answer to dealing with mutable variables, and we highly; recommend that you depend on it. Note that mem2reg only works on; variables in certain circumstances:. #. mem2reg is alloca-driven: it looks for allocas and if it can handle; them, it promotes them. It does not apply to global variables or heap; allocations.; #. mem2reg only looks for alloca instructions in the entry block of the; function. Being in the entry block guarantees that the alloca is only; executed once, which makes analysis simpler.; #. mem2reg only promotes allocas whose uses are direct loads and stores.; If the address of t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:7176,load,load,7176,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['load'],['load']
Performance," allow checking; of cross-DSO virtual and indirect calls. .. option:: -fsanitize-cfi-icall-generalize-pointers. Generalize pointers in return and argument types in function type signatures; checked by Control Flow Integrity indirect call checking. See; :doc:`ControlFlowIntegrity` for more details. .. option:: -fsanitize-cfi-icall-experimental-normalize-integers. Normalize integers in return and argument types in function type signatures; checked by Control Flow Integrity indirect call checking. See; :doc:`ControlFlowIntegrity` for more details. This option is currently experimental. .. option:: -fstrict-vtable-pointers. Enable optimizations based on the strict rules for overwriting polymorphic; C++ objects, i.e. the vptr is invariant during an object's lifetime.; This enables better devirtualization. Turned off by default, because it is; still experimental. .. option:: -fwhole-program-vtables. Enable whole-program vtable optimizations, such as single-implementation; devirtualization and virtual constant propagation, for classes with; :doc:`hidden LTO visibility <LTOVisibility>`. Requires ``-flto``. .. option:: -f[no]split-lto-unit. Controls splitting the :doc:`LTO unit <LTOVisibility>` into regular LTO and; :doc:`ThinLTO` portions, when compiling with -flto=thin. Defaults to false; unless ``-fsanitize=cfi`` or ``-fwhole-program-vtables`` are specified, in; which case it defaults to true. Splitting is required with ``fsanitize=cfi``,; and it is an error to disable via ``-fno-split-lto-unit``. Splitting is; optional with ``-fwhole-program-vtables``, however, it enables more; aggressive whole program vtable optimizations (specifically virtual constant; propagation). When enabled, vtable definitions and select virtual functions are placed; in the split regular LTO module, enabling more aggressive whole program; vtable optimizations required for CFI and virtual constant propagation.; However, this can increase the LTO link time and memory requirements over; pure ThinLTO, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:80549,optimiz,optimizations,80549,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimizations']
Performance," allow us to have arbitrarily complex index; expressions, while still distinguishing ""load"" from ""Array load"",; for example. Perhaps also, switch jump tables would be first class; types as well? This would allow better reasoning about the program. 5. Support dynamic loading of code from various sources. Already; mentioned above was the example of loading java bytecodes, but we want; to support dynamic loading of VM code as well. This makes the job of; the runtime compiler much more interesting: it can do interprocedural; optimizations that the static compiler can't do, because it doesn't; have all of the required information (for example, inlining from; shared libraries, etc...). 6. Define a set of generally useful annotations to add to the VM; representation. For example, a function can be analysed to see if it; has any sideeffects when run... also, the MOD/REF sets could be; calculated, etc... we would have to determine what is reasonable. This; would generally be used to make IP optimizations cheaper for the; runtime compiler... > o Explicit instructions to handle aliasing, e.g.s:; > -- an instruction to say ""I speculate that these two values are not; > aliased, but check at runtime"", like speculative execution in; > EPIC?; > -- or an instruction to check whether two values are aliased and; > execute different code depending on the answer, somewhat like; > predicated code in EPIC. These are also very good points... if this can be determined at compile; time. I think that an epic style of representation (not the instruction; packing, just the information presented) could be a very interesting model; to use... more later... > o (This one is a difficult but powerful idea.); > A ""thread-id"" field on every instruction that allows the static; > compiler to generate a set of parallel threads, and then have; > the runtime compiler and hardware do what they please with it.; > This has very powerful uses, but thread-id on every instruction; > is expensive in terms of instr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt:6312,optimiz,optimizations,6312,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-11-18-EarlyDesignIdeasResp.txt,1,['optimiz'],['optimizations']
Performance," an OpenCL pipe is passed in; the kernarg. ""Queue""; A global address space pointer; to an OpenCL device enqueue; queue is passed in the; kernarg. ""HiddenGlobalOffsetX""; The OpenCL grid dispatch; global offset for the X; dimension is passed in the; kernarg. ""HiddenGlobalOffsetY""; The OpenCL grid dispatch; global offset for the Y; dimension is passed in the; kernarg. ""HiddenGlobalOffsetZ""; The OpenCL grid dispatch; global offset for the Z; dimension is passed in the; kernarg. ""HiddenNone""; An argument that is not used; by the kernel. Space needs to; be left for it, but it does; not need to be set up. ""HiddenPrintfBuffer""; A global address space pointer; to the runtime printf buffer; is passed in kernarg. Mutually; exclusive with; ""HiddenHostcallBuffer"". ""HiddenHostcallBuffer""; A global address space pointer; to the runtime hostcall buffer; is passed in kernarg. Mutually; exclusive with; ""HiddenPrintfBuffer"". ""HiddenDefaultQueue""; A global address space pointer; to the OpenCL device enqueue; queue that should be used by; the kernel by default is; passed in the kernarg. ""HiddenCompletionAction""; A global address space pointer; to help link enqueued kernels into; the ancestor tree for determining; when the parent kernel has finished. ""HiddenMultiGridSyncArg""; A global address space pointer for; multi-grid synchronization is; passed in the kernarg. ""ValueType"" string Unused and deprecated. This should no longer; be emitted, but is accepted for compatibility. ""PointeeAlign"" integer Alignment in bytes of pointee; type for pointer type kernel; argument. Must be a power; of 2. Only present if; ""ValueKind"" is; ""DynamicSharedPointer"".; ""AddrSpaceQual"" string Kernel argument address space; qualifier. Only present if; ""ValueKind"" is ""GlobalBuffer"" or; ""DynamicSharedPointer"". Values; are:. - ""Private""; - ""Global""; - ""Constant""; - ""Local""; - ""Generic""; - ""Region"". .. TODO::. Is GlobalBuffer only Global; or Constant? Is; DynamicSharedPointer always; Local? Can HCC allow Generic?; How",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:125074,queue,queue,125074,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['queue'],['queue']
Performance," an accelerator library and use ctypes to invoke functions.; * When the ROOT kernel is used, the output is consumed progressively; * Capture unlimited output also when using an IPython Kernel (fixes [ROOT-7960]). ## JavaScript ROOT. - New geometry (TGeo) classes support:; - browsing through volumes hieararchy; - changing visibility flags; - drawing of selected volumes; - support of large (~10M volumes) models, only most significant volumes are shown; - one could activate several clip planes (only with WebGL); - interaction with object browser to change visibility flags or focus on selected volume; - support of floating browser for TGeo objects; - intensive use of HTML Worker to offload computation tasks and keep interactivity; - enable more details when changing camera position/zoom; - Improvements in histograms 3D drawing; - all lego options: lego1..lego4, combined with 'fb', 'bb', '0' or 'z'; - support axis labels on lego plots; - support lego plots for TH1; - Significant (up to factor 10) performance improvement in 3D-graphics; - Implement ROOT6-like color palettes; - Support non-equidistant bins for TH1/TH2 objects.; - Improve TF1 drawing - support exp function in TFormula, fix errors with logx scale, enable zoom-in, (re)calculate function points when zooming; - Introduce many context menus for improving interactivity; - Implement col0 and col0z draw option for TH2 histograms, similar to ROOT6; - Implement box and hbox draw options for TH1 class; - Significant (factor 4) I/O performance improvement; - New 'flex' layout:; - create frames like in Multi Document Interface; - one could move/resize/minimize/maximize such frames. For more details, like the complete change log, the documentation, and very detailed examples, see the [JSROOT home page](https://root.cern.ch/js) and the [JSROOT project github page](https://github.com/linev/jsroot) . ## Tutorials; * New tutorial `treegetval.C` illustrating how to retrieve `TTree` variables in arrays.; * Add script to automa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:26946,perform,performance,26946,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['perform'],['performance']
Performance," an intrinsic function is the; method of choice for LLVM extension. Before you invest a significant amount of effort into a non-trivial extension,; **ask on the list** if what you are looking to do can be done with; already-existing infrastructure, or if maybe someone else is already working on; it. You will save yourself a lot of time and effort by doing so. .. _intrinsic function:. Adding a new intrinsic function; ===============================. Adding a new intrinsic function to LLVM is much easier than adding a new; instruction. Almost all extensions to LLVM should start as an intrinsic; function and then be turned into an instruction if warranted. #. ``llvm/docs/LangRef.html``:. Document the intrinsic. Decide whether it is code generator specific and; what the restrictions are. Talk to other people about it so that you are; sure it's a good idea. #. ``llvm/include/llvm/IR/Intrinsics*.td``:. Add an entry for your intrinsic. Describe its memory access; characteristics for optimization (this controls whether it will be; DCE'd, CSE'd, etc). If any arguments need to be immediates, these; must be indicated with the ImmArg property. Note that any intrinsic; using one of the ``llvm_any*_ty`` types for an argument or return; type will be deemed by ``tblgen`` as overloaded and the; corresponding suffix will be required on the intrinsic's name. #. ``llvm/lib/Analysis/ConstantFolding.cpp``:. If it is possible to constant fold your intrinsic, add support to it in the; ``canConstantFoldCallTo`` and ``ConstantFoldCall`` functions. #. ``llvm/test/*``:. Add test cases for your test cases to the test suite. Once the intrinsic has been added to the system, you must add code generator; support for it. Generally you must do the following steps:. Add support to the .td file for the target(s) of your choice in; ``lib/Target/*/*.td``. This is usually a matter of adding a pattern to the .td file that matches the; intrinsic, though it may obviously require adding the instructions you w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:2250,optimiz,optimization,2250,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,1,['optimiz'],['optimization']
Performance," an optional successor, ``continue``,; which must be the label of another basic block beginning with either a; ``cleanuppad`` or ``catchswitch`` instruction. This unwind destination must; be a legal target with respect to the ``parent`` links, as described in the; `exception handling documentation\ <ExceptionHandling.html#wineh-constraints>`_. Semantics:; """""""""""""""""""". The '``cleanupret``' instruction indicates to the; :ref:`personality function <personalityfn>` that one; :ref:`cleanuppad <i_cleanuppad>` it transferred control to has ended.; It transfers control to ``continue`` or unwinds out of the function. Example:; """""""""""""""". .. code-block:: text. cleanupret from %cleanup unwind to caller; cleanupret from %cleanup unwind label %continue. .. _i_unreachable:. '``unreachable``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. unreachable. Overview:; """""""""""""""""". The '``unreachable``' instruction has no defined semantics. This; instruction is used to inform the optimizer that a particular portion of; the code is not reachable. This can be used to indicate that the code; after a no-return function cannot be reached, and other facts. Semantics:; """""""""""""""""""". The '``unreachable``' instruction has no defined semantics. .. _unaryops:. Unary Operations; -----------------. Unary operators require a single operand, execute an operation on; it, and produce a single value. The operand might represent multiple; data, as is the case with the :ref:`vector <t_vector>` data type. The; result value has the same type as its operand. .. _i_fneg:. '``fneg``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = fneg [fast-math flags]* <ty> <op1> ; yields ty:result. Overview:; """""""""""""""""". The '``fneg``' instruction returns the negation of its operand. Arguments:; """""""""""""""""""". The argument to the '``fneg``' instruction must be a; :ref:`floating-point <t_floating>` or :ref:`vector <t_vector>` of; floating-point values. Semantics:; """""""""""""""""""". The value produced is",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:375194,optimiz,optimizer,375194,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizer']
Performance," an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.umax.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.umax.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated unsigned-integer ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.umax``' intrinsic performs the unsigned-integer ``MAX``; reduction (:ref:`llvm.vector.reduce.umax <int_vector_reduce_umax>`) of the; vector operand ``val`` on each enabled lane, and taking the maximum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``0`` (i.e. having no effect on the reduction operation). If the; vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.umax.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.umax.v4i32(<4 x i32> %masked.a); %also.r = call i32 @llvm.umax.i32(i32 %reduction, i32 %start). .. _int_vp_reduce_umin:. '``llvm.vp.reduce.umin.*``' Intrinsics",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:767939,perform,performs,767939,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.umin.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.umin.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated unsigned-integer ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.umin``' intrinsic performs the unsigned-integer ``MIN``; reduction (:ref:`llvm.vector.reduce.umin <int_vector_reduce_umin>`) of the; vector operand ``val`` on each enabled lane, taking the minimum of that and the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value ``UINT_MAX``, or ``-1`` (i.e. having no effect on the reduction; operation). If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.umin.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>; %reduction = call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %masked.a); %also.r = call i32 @llvm.umin.i32(i32 %reduction, i32 %start). .. _int_vp_reduce_fmax:. '``llvm.vp.reduce.fm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:770007,perform,performs,770007,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," analyses get invalidated, and; which analyses are needed to be run for a pass. An important part of work; is that the ``PassManager`` tracks the exact lifetime of all analysis; results, allowing it to :ref:`free memory; <writing-an-llvm-pass-releaseMemory>` allocated to holding analysis results; as soon as they are no longer needed. #. **Pipeline the execution of passes on the program.** The ``PassManager``; attempts to get better cache and memory usage behavior out of a series of; passes by pipelining the passes together. This means that, given a series; of consecutive :ref:`FunctionPass <writing-an-llvm-pass-FunctionPass>`, it; will execute all of the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` on the first function, then all of the; :ref:`FunctionPasses <writing-an-llvm-pass-FunctionPass>` on the second; function, etc... until the entire program has been run through the passes. This improves the cache behavior of the compiler, because it is only; touching the LLVM program representation for a single function at a time,; instead of traversing the entire program. It reduces the memory consumption; of compiler, because, for example, only one `DominatorSet; <https://llvm.org/doxygen/classllvm_1_1DominatorSet.html>`_ needs to be; calculated at a time. The effectiveness of the ``PassManager`` is influenced directly by how much; information it has about the behaviors of the passes it is scheduling. For; example, the ""preserved"" set is intentionally conservative in the face of an; unimplemented :ref:`getAnalysisUsage <writing-an-llvm-pass-getAnalysisUsage>`; method. Not implementing when it should be implemented will have the effect of; not allowing any analysis results to live across the execution of your pass. The ``PassManager`` class exposes a ``--debug-pass`` command line options that; is useful for debugging pass execution, seeing how things work, and diagnosing; when you should be preserving more analyses than you currently are. (To get; information a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:42313,cache,cache,42313,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['cache'],['cache']
Performance," and earlier, HLSL supported logical operators (and the ternary; operator) on vector types. This behavior required that operators not short; circuit. The non-short circuiting behavior applies to all data types until HLSL; 2021. In HLSL 2021, logical and ternary operators do not support vector types; instead builtin functions ``and``, ``or`` and ``select`` are available, and; operators short circuit matching C behavior. Precise Qualifier; -----------------. HLSL has a ``precise`` qualifier that behaves unlike anything else in the C; language. The support for this qualifier in DXC is buggy, so our bar for; compatibility is low. The ``precise`` qualifier applies in the inverse direction from normal; qualifiers. Rather than signifying that the declaration containing ``precise``; qualifier be precise, it signifies that the operations contributing to the; declaration's value be ``precise``. Additionally, ``precise`` is a misnomer:; values attributed as ``precise`` comply with IEEE-754 floating point semantics,; and are prevented from optimizations which could decrease *or increase*; precision. Differences in Templates; ------------------------. HLSL uses templates to define builtin types and methods, but disallowed; user-defined templates until HLSL 2021. HLSL also allows omitting empty template; parameter lists when all template parameters are defaulted. This is an ambiguous; syntax in C++, but Clang detects the case and issues a diagnostic. This makes; supporting the case in Clang minimally invasive. Vector Extensions; -----------------. HLSL uses the OpenCL vector extensions, and also provides C++-style constructors; for vectors that are not supported by Clang. Standard Library; ----------------. HLSL does not support the C or C++ standard libraries. Like OpenCL, HLSL; describes its own library of built in types, complex data types, and functions. Unsupported C & C++ Features; ----------------------------. HLSL does not support all features of C and C++. In implementing",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HLSL/HLSLSupport.rst:8619,optimiz,optimizations,8619,interpreter/llvm-project/clang/docs/HLSL/HLSLSupport.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HLSL/HLSLSupport.rst,1,['optimiz'],['optimizations']
Performance," and estimate.; ; Macros plot various deviation and correlation quantities.; A new GUI (macros/TMVARegGui.C) collects these macros.; . Improvements of / new features for MVA methods . Linear Discriminant:; Re-implementation of ""Fisher"" method as general linear discriminant (""LD""),; which is also regression capable (so far: single-target only). PDEFoam:; PDE-Foam is a variation of the PDE-RS method using a self-adapting binning; method to divide the multi-dimensional variable space into a finite number; of hyper-rectangles (cells). The binning algorithm adjusts the size and; position of a predefined number of cells such that the variance of the; signal and background densities inside the cells reaches a minimum. BDT:; Introduced gradient boosting and stochastic gradient boosting for ; classification with BDT (as desribed by Friedman 1999). See ""BDTG"" ; example in TMVAClassification.C/cxx. A new option allows to restrict the maximum tree depth. This may be used to; avoid overtraining and often gives better performance than pruning. (The; pruning mechanism needs to be revisited). MLP:; Introduced recognition of convergence via general ConvergenceTest-class for; interrupting computations when convergence is reached. This feature has is; used now in MethodMLP. Improved treatment of event-weights in BFGS training. Implemented random and importance sampling of events in DataSet. Implemented; the usage of this feature for MLP.; ; TMlpANN (interface to TMultiLayerPerceptron) now also uses event weights; and writes standalone C++ class. k-NN:; A new global knn search function has been added to NodekNN that searches for; k-nearest neighbor using event weights instead of raw event counts. ModulekNN; has been modified to allow searches using ""weight"" or ""count"" option, where; ""count"" is default. Added UseWeight option to MethodKNN to allow using of; ""weight"" or ""count"". ; (Work by Rustem Ospanov, CERN). . Likelihood (and general PDF treatment):; Adaptive smoothing the PDF class, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:3041,perform,performance,3041,tmva/doc/v524/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html,1,['perform'],['performance']
Performance," and heap allocations can never alias.; * Globals, stack allocations, and heap allocations never alias the null pointer.; * Different fields of a structure do not alias.; * Indexes into arrays with statically differing subscripts cannot alias.; * Many common standard C library functions `never access memory or only read; memory`_.; * Pointers that obviously point to constant globals ""``pointToConstantMemory``"".; * Function calls can not modify or references stack allocations if they never; escape from the function that allocates them (a common case for automatic; arrays). The ``-globalsmodref-aa`` pass; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This pass implements a simple context-sensitive mod/ref and alias analysis for; internal global variables that don't ""have their address taken"". If a global; does not have its address taken, the pass knows that no pointers alias the; global. This pass also keeps track of functions that it knows never access; memory or never read memory. This allows certain optimizations (e.g. GVN) to; eliminate call instructions entirely. The real power of this pass is that it provides context-sensitive mod/ref; information for call instructions. This allows the optimizer to know that calls; to a function do not clobber or read the value of the global, allowing loads and; stores to be eliminated. .. note::. This pass is somewhat limited in its scope (only support non-address taken; globals), but is very quick analysis. The ``-steens-aa`` pass; ^^^^^^^^^^^^^^^^^^^^^^^. The ``-steens-aa`` pass implements a variation on the well-known ""Steensgaard's; algorithm"" for interprocedural alias analysis. Steensgaard's algorithm is a; unification-based, flow-insensitive, context-insensitive, and field-insensitive; alias analysis that is also very scalable (effectively linear time). The LLVM ``-steens-aa`` pass implements a ""speculatively field-**sensitive**""; version of Steensgaard's algorithm using the Data Structure Analysis framework.; This gives it substantial",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:24923,optimiz,optimizations,24923,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,1,['optimiz'],['optimizations']
Performance," and instructions have lists of types.; That had two flaws: the type and size are redundant, and there was no generic; way of getting a given operand's type (as there was no 1:1 mapping between; instruction types and operands).; We considered putting the type in some variant of MCInstrDesc instead:; See `PR26576 <https://llvm.org/PR26576>`_: [GlobalISel] Generic MachineInstrs; need a type but this increases the memory footprint of the related objects. .. _gmir-regbank:. Register Bank; -------------. A Register Bank is a set of register classes defined by the target. This; definition is rather loose so let's talk about what they can achieve. Suppose we have a processor that has two register files, A and B. These are; equal in every way and support the same instructions for the same cost. They're; just physically stored apart and each instruction can only access registers from; A or B but never a mix of the two. If we want to perform an operation on data; that's in split between the two register files, we must first copy all the data; into a single register file. Given a processor like this, we would benefit from clustering related data; together into one register file so that we minimize the cost of copying data; back and forth to satisfy the (possibly conflicting) requirements of all the; instructions. Register Banks are a means to constrain the register allocator to; use a particular register file for a virtual register. In practice, register files A and B are rarely equal. They can typically store; the same data but there's usually some restrictions on what operations you can; do on each register file. A fairly common pattern is for one of them to be; accessible to integer operations and the other accessible to floating point; operations. To accommodate this, let's rename A and B to GPR (general purpose; registers) and FPR (floating point registers). We now have some additional constraints that limit us. An operation like G_FMUL; has to happen in FPR and G_ADD has",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst:3821,perform,perform,3821,interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,1,['perform'],['perform']
Performance," and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and implementation decisions, LLVM relies on; global data which can end up being duplicated across shared libraries; resulting in bugs. As such this is not a safe way to distribute LLVM or; LLVM-based tools. The simplest example of building a distribution with reasonable performance is; captured in the DistributionExample CMake cache file located at; clang/cmake/caches/DistributionExample.cmake. The following command will perform; and install the distribution build:. .. code-block:: console. $ cmake -G Ninja -C <path to clang>/cmake/caches/DistributionExample.cmake <path to LLVM source>; $ ninja stage2-distribution; $ ninja stage2-install-distribution. Difference between ``install`` and ``install-distribution``; -----------------------------------------------------------. One subtle but important thing to note is the difference between the ``install``; and ``install-distribution`` targets. The ``install`` target is expected to; install every part of LLVM that your build is configured to generate except the; LLVM testing tools. Alternatively the ``install-distribution`` target, which is; recommended for building distributions, only installs specific parts of LLVM as; specified at configuration time by *LLVM_DISTRIBUTION_COMPONENTS*. Additionally by default the ``install`` target w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:2554,perform,performance,2554,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,3,"['cache', 'perform']","['cache', 'caches', 'performance']"
Performance," and return value are floating-point numbers of the same type. Semantics:; """""""""""""""""""". Return the same value as a corresponding libm '``exp10``' function but without; trapping or setting ``errno``. When specified with the fast-math-flag 'afn', the result may be approximated; using a less accurate calculation. '``llvm.ldexp.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.ldexp`` on any; floating point or vector of floating point type. Not all targets support; all types however. ::. declare float @llvm.ldexp.f32.i32(float %Val, i32 %Exp); declare double @llvm.ldexp.f64.i32(double %Val, i32 %Exp); declare x86_fp80 @llvm.ldexp.f80.i32(x86_fp80 %Val, i32 %Exp); declare fp128 @llvm.ldexp.f128.i32(fp128 %Val, i32 %Exp); declare ppc_fp128 @llvm.ldexp.ppcf128.i32(ppc_fp128 %Val, i32 %Exp); declare <2 x float> @llvm.ldexp.v2f32.v2i32(<2 x float> %Val, <2 x i32> %Exp). Overview:; """""""""""""""""". The '``llvm.ldexp.*``' intrinsics perform the ldexp function. Arguments:; """""""""""""""""""". The first argument and the return value are :ref:`floating-point; <t_floating>` or :ref:`vector <t_vector>` of floating-point values of; the same type. The second argument is an integer with the same number; of elements. Semantics:; """""""""""""""""""". This function multiplies the first argument by 2 raised to the second; argument's power. If the first argument is NaN or infinite, the same; value is returned. If the result underflows a zero with the same sign; is returned. If the result overflows, the result is an infinity with; the same sign. .. _int_frexp:. '``llvm.frexp.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.frexp`` on any; floating point or vector of floating point type. Not all targets support; all types however. ::. declare { float, i32 } @llvm.frexp.f32.i32(float %Val); declare { double, i32 } @llvm.frexp.f64.i32(double %Val); declare { x86_fp80, i32 } @llvm.frexp.f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:565143,perform,perform,565143,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance," and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vm/vscnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; following; buffer_gl*_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 4. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrm",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:369339,load,load,369339,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," and the ``zext`` argument is negative, the result; is a poison value. Example:; """""""""""""""". .. code-block:: llvm. %X = zext i32 257 to i64 ; yields i64:257; %Y = zext i1 true to i32 ; yields i32:1; %Z = zext <2 x i16> <i16 8, i16 7> to <2 x i32> ; yields <i32 8, i32 7>. %a = zext nneg i8 127 to i16 ; yields i16 127; %b = zext nneg i8 -1 to i16 ; yields i16 poison. .. _i_sext:. '``sext .. to``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = sext <ty> <value> to <ty2> ; yields ty2. Overview:; """""""""""""""""". The '``sext``' sign extends ``value`` to the type ``ty2``. Arguments:; """""""""""""""""""". The '``sext``' instruction takes a value to cast, and a type to cast it; to. Both types must be of :ref:`integer <t_integer>` types, or vectors of; the same number of integers. The bit size of the ``value`` must be; smaller than the bit size of the destination type, ``ty2``. Semantics:; """""""""""""""""""". The '``sext``' instruction performs a sign extension by copying the sign; bit (highest order bit) of the ``value`` until it reaches the bit size; of the type ``ty2``. When sign extending from i1, the extension always results in -1 or 0. Example:; """""""""""""""". .. code-block:: llvm. %X = sext i8 -1 to i16 ; yields i16 :65535; %Y = sext i1 true to i32 ; yields i32:-1; %Z = sext <2 x i16> <i16 8, i16 7> to <2 x i32> ; yields <i32 8, i32 7>. '``fptrunc .. to``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <result> = fptrunc <ty> <value> to <ty2> ; yields ty2. Overview:; """""""""""""""""". The '``fptrunc``' instruction truncates ``value`` to type ``ty2``. Arguments:; """""""""""""""""""". The '``fptrunc``' instruction takes a :ref:`floating-point <t_floating>`; value to cast and a :ref:`floating-point <t_floating>` type to cast it to.; The size of ``value`` must be larger than the size of ``ty2``. This; implies that ``fptrunc`` cannot be used to make a *no-op cast*. Semantics:; """""""""""""""""""". The '``fptrunc``' instruction casts a ``value`` from a larger; :ref:`floating-poin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:445067,perform,performs,445067,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," and to; support compiler-rt as the reference implementation. Allocator Support; -----------------. GWP-ASan is not a replacement for a traditional allocator. Instead, it works by; inserting stubs into a supporting allocator to redirect allocations to GWP-ASan; when they're chosen to be sampled. These stubs are generally implemented in the; implementation of ``malloc()``, ``free()`` and ``realloc()``. The stubs are; extremely small, which makes using GWP-ASan in most allocators fairly trivial.; The stubs follow the same general pattern (example ``malloc()`` pseudocode; below):. .. code:: cpp. #ifdef INSTALL_GWP_ASAN_STUBS; gwp_asan::GuardedPoolAllocator GWPASanAllocator;; #endif. void* YourAllocator::malloc(..) {; #ifdef INSTALL_GWP_ASAN_STUBS; if (GWPASanAllocator.shouldSample(..)); return GWPASanAllocator.allocate(..);; #endif. // ... the rest of your allocator code here.; }. Then, all the supporting allocator needs to do is compile with; ``-DINSTALL_GWP_ASAN_STUBS`` and link against the GWP-ASan library! For; performance reasons, we strongly recommend static linkage of the GWP-ASan; library. Guarded Allocation Pool; -----------------------. The core of GWP-ASan is the guarded allocation pool. Each sampled allocation is; backed using its own *guarded* slot, which may consist of one or more accessible; pages. Each guarded slot is surrounded by two *guard* pages, which are mapped as; inaccessible. The collection of all guarded slots makes up the *guarded; allocation pool*. Buffer Underflow/Overflow Detection; -----------------------------------. We gain buffer-overflow and buffer-underflow detection through these guard; pages. When a memory access overruns the allocated buffer, it will touch the; inaccessible guard page, causing memory exception. This exception is caught and; handled by the internal crash handler. Because each allocation is recorded with; metadata about where (and by what thread) it was allocated and deallocated, we; can provide information that will",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst:3053,perform,performance,3053,interpreter/llvm-project/llvm/docs/GwpAsan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GwpAsan.rst,1,['perform'],['performance']
Performance," and; completion is reported to a wavefront in execution order. The exception is; that for GFX7-GFX9 ``flat_load/store/atomic`` instructions can report out of; vector memory order if they access LDS memory, and out of LDS operation order; if they access global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore, no special action is required for coherence between the; lanes of a single wavefront, or for coherence between wavefronts in the same; work-group. A ``buffer_wbinvl1_vol`` is required for coherence between; wavefronts executing in different work-groups as they may be executing on; different CUs.; * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0)`` is required to; ensure synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. Th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:208424,cache,cache,208424,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," and; size of the memory access. Currently, the following sequence is used:. .. code-block:: none. // int foo(int *a) { return *a; }; // clang -O2 --target=aarch64-linux-android30 -fsanitize=hwaddress -S -o - load.c; [...]; foo:; stp x30, x20, [sp, #-16]!; adrp x20, :got:__hwasan_shadow // load shadow address from GOT into x20; ldr x20, [x20, :got_lo12:__hwasan_shadow]; bl __hwasan_check_x0_2_short_v2 // call outlined tag check; // (arguments: x0 = address, x20 = shadow base;; // ""2"" encodes the access type and size); ldr w0, [x0] // inline load; ldp x30, x20, [sp], #16; ret. [...]; __hwasan_check_x0_2_short_v2:; sbfx x16, x0, #4, #52 // shadow offset; ldrb w16, [x20, x16] // load shadow tag; cmp x16, x0, lsr #56 // extract address tag, compare with shadow tag; b.ne .Ltmp0 // jump to short tag handler on mismatch; .Ltmp1:; ret; .Ltmp0:; cmp w16, #15 // is this a short tag?; b.hi .Ltmp2 // if not, error; and x17, x0, #0xf // find the address's position in the short granule; add x17, x17, #3 // adjust to the position of the last byte loaded; cmp w16, w17 // check that position is in bounds; b.ls .Ltmp2 // if not, error; orr x16, x0, #0xf // compute address of last byte of granule; ldrb w16, [x16] // load tag from it; cmp x16, x0, lsr #56 // compare with pointer tag; b.eq .Ltmp1 // if matches, continue; .Ltmp2:; stp x0, x1, [sp, #-256]! // save original x0, x1 on stack (they will be overwritten); stp x29, x30, [sp, #232] // create frame record; mov x1, #2 // set x1 to a constant indicating the type of failure; adrp x16, :got:__hwasan_tag_mismatch_v2 // call runtime function to save remaining registers and report error; ldr x16, [x16, :got_lo12:__hwasan_tag_mismatch_v2] // (load address from GOT to avoid potential register clobbers in delay load handler); br x16. Heap; ----. Tagging the heap memory/pointers is done by `malloc`.; This can be based on any malloc that forces all objects to be TG-aligned.; `free` tags the memory with a different tag. Stack; -----. Stack fram",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst:4610,load,loaded,4610,interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,1,['load'],['loaded']
Performance," any new; inputs found by one fuzzer process will be available to the other fuzzer; processes (unless you disable this with the ``-reload=0`` option). This is primarily controlled by the ``-jobs=N`` option, which indicates that; that `N` fuzzing jobs should be run to completion (i.e. until a bug is found or; time/iteration limits are reached). These jobs will be run across a set of; worker processes, by default using half of the available CPU cores; the count of; worker processes can be overridden by the ``-workers=N`` option. For example,; running with ``-jobs=30`` on a 12-core machine would run 6 workers by default,; with each worker averaging 5 bugs by completion of the entire process. Fork mode; ---------. **Experimental** mode ``-fork=N`` (where ``N`` is the number of parallel jobs); enables oom-, timeout-, and crash-resistant; fuzzing with separate processes (using ``fork-exec``, not just ``fork``). The top libFuzzer process will not do any fuzzing itself, but will; spawn up to ``N`` concurrent child processes providing them; small random subsets of the corpus. After a child exits, the top process; merges the corpus generated by the child back to the main corpus. Related flags:. ``-ignore_ooms``; True by default. If an OOM happens during fuzzing in one of the child processes,; the reproducer is saved on disk, and fuzzing continues.; ``-ignore_timeouts``; True by default, same as ``-ignore_ooms``, but for timeouts.; ``-ignore_crashes``; False by default, same as ``-ignore_ooms``, but for all other crashes. The plan is to eventually replace ``-jobs=N`` and ``-workers=N`` with ``-fork=N``. Resuming merge; --------------. Merging large corpora may be time consuming, and it is often desirable to do it; on preemptable VMs, where the process may be killed at any time.; In order to seamlessly resume the merge, use the ``-merge_control_file`` flag; and use ``killall -SIGUSR1 /path/to/fuzzer/binary`` to stop the merge gracefully. Example:. .. code-block:: console. % rm -",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst:7679,concurren,concurrent,7679,interpreter/llvm-project/llvm/docs/LibFuzzer.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LibFuzzer.rst,1,['concurren'],['concurrent']
Performance," application. .. option:: -miphoneos-version-min. When building for iPhone OS, specify the minimum version supported by your; application. .. option:: --print-supported-cpus. Print out a list of supported processors for the given target (specified; through ``--target=<architecture>`` or :option:`-arch` ``<architecture>``). If no; target is specified, the system default target will be used. .. option:: -mcpu=?, -mtune=?. Acts as an alias for :option:`--print-supported-cpus`. .. option:: -mcpu=help, -mtune=help. Acts as an alias for :option:`--print-supported-cpus`. .. option:: -march=<cpu>. Specify that Clang should generate code for a specific processor family; member and later. For example, if you specify -march=i486, the compiler is; allowed to generate instructions that are valid on i486 and later processors,; but which may not exist on earlier ones. Code Generation Options; ~~~~~~~~~~~~~~~~~~~~~~~. .. option:: -O0, -O1, -O2, -O3, -Ofast, -Os, -Oz, -Og, -O, -O4. Specify which optimization level to use:. :option:`-O0` Means ""no optimization"": this level compiles the fastest and; generates the most debuggable code. :option:`-O1` Somewhere between :option:`-O0` and :option:`-O2`. :option:`-O2` Moderate level of optimization which enables most; optimizations. :option:`-O3` Like :option:`-O2`, except that it enables optimizations that; take longer to perform or that may generate larger code (in an attempt to; make the program run faster). :option:`-Ofast` Enables all the optimizations from :option:`-O3` along; with other aggressive optimizations that may violate strict compliance with; language standards. :option:`-Os` Like :option:`-O2` with extra optimizations to reduce code; size. :option:`-Oz` Like :option:`-Os` (and thus :option:`-O2`), but reduces code; size further. :option:`-Og` Like :option:`-O1`. In future versions, this option might; disable different optimizations in order to improve debuggability. :option:`-O` Equivalent to :option:`-O1`. :option:`-O4` an",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst:10482,optimiz,optimization,10482,interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/CommandGuide/clang.rst,1,['optimiz'],['optimization']
Performance," apply button is; pressed, the changes are applied to the edited shape and drawn. The; ""*Undo*"" button becomes active after the first modification has been; applied. It allows restoring the initial parameters of the shape. NOTE: In this version the ""*Undo*"" does not allow restoring an; intermediate state of the parameters that was applied - it will always; restore the parameters at the moment the shape was edited. All material properties changes are undoable. The mixture editor; currently allows adding elements one by one in the mixture composition.; This can be done either by element weight fraction or by number of; atoms. Once an element was added using one method the other method is not; selectable anymore. Summing component fractions up to 1 in the final; mixture is the user responsibility. Adding materials as components of a; mixture is not supported in this version. The elements that were added to the mixture appear in the bottom of the; mixture editor. The operations performed on mixture are not undoable. ### Creation of New Objects. As described above, all geometry object creators are accessible within; the geometry manager editor frame. Generally, if the new object that; needs to be created does not depend on other objects, it will be built; with a set of default parameters. This is the case for all shapes; (except composite shapes) and matrices. For all the other objects the; interface forces the selection of components before creating the object. ### Editing Volumes. Volumes are hierarchical components in the geometry, therefore their; editor is more complex. It provides the following functionalities:. - *General*. This category allows changing the name of the volume and; selecting other shape or medium among existing ones. - *Daughters*. The category allows removing existing daughter nodes or; adding new ones. The button ""*Position*"" allows editing the; positioning matrix of a given node. ![Setting volume properties and modifying volume hierarchy](pictur",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:171722,perform,performed,171722,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['perform'],['performed']
Performance," are currently reserved for user-defined code. The GS-segment is; represented by address space 256, the FS-segment is represented by address space; 257, and the SS-segment is represented by address space 258. Other x86 segments; have yet to be allocated address space numbers. While these address spaces may seem similar to TLS via the ``thread_local``; keyword, and often use the same underlying hardware, there are some fundamental; differences. The ``thread_local`` keyword applies to global variables and specifies that they; are to be allocated in thread-local memory. There are no type qualifiers; involved, and these variables can be pointed to with normal pointers and; accessed with normal loads and stores. The ``thread_local`` keyword is; target-independent at the LLVM IR level (though LLVM doesn't yet have; implementations of it for some configurations). Special address spaces, in contrast, apply to static types. Every load and store; has a particular address space in its address operand type, and this is what; determines which address space is accessed. LLVM ignores these special address; space qualifiers on global variables, and does not provide a way to directly; allocate storage in them. At the LLVM IR level, the behavior of these special; address spaces depends in part on the underlying OS or runtime environment, and; they are specific to x86 (and LLVM doesn't yet handle them correctly in some; cases). Some operating systems and runtime environments use (or may in the future use); the FS/GS-segment registers for various low-level purposes, so care should be; taken when considering them. Instruction naming; ^^^^^^^^^^^^^^^^^^. An instruction name consists of the base name, a default operand size, and a; character per operand with an optional special size. For example:. ::. ADD8rr -> add, 8-bit register, 8-bit register; IMUL16rmi -> imul, 16-bit register, 16-bit memory, 16-bit immediate; IMUL16rmi8 -> imul, 16-bit register, 16-bit memory, 8-bit immediate; MOVSX",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:93068,load,load,93068,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['load'],['load']
Performance," are ignored in the training (but are included for testing and performance evaluation). nkNN No 20 − Number of k-nearest neighbors. BalanceDepth No 6 − Binary tree balance depth. ScaleFrac No 0.8 − Fraction of events used to compute variable width. SigmaFact No 1 − Scale factor for sigma in Gaussian kernel. Kernel No Gaus − Use polynomial (=Poln) or Gaussian (=Gaus) kernel. Trim No False − Use equal number of signal and background events. UseKernel No False − Use polynomial kernel weight. UseWeight No True − Use weight to count kNN events. UseLDA No False − Use local linear discriminant - experimental feature. Configuration options for MVA method :. Configuration options reference for MVA method: BDT. Option Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help message. CreateMVAPdfs No False − Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False − Events with negative weights are ignored in the training (but are included for testing and performance evaluation). NTrees No 800 − Number of trees in the forest. MaxDepth No 3 − Max depth of the decision tree allowed. MinNodeSize No 5% − Minimum percentage of training events required in a leaf node (default: Classification: 5%, Regression: 0.2%). nCuts No 20 − Number of grid points in variable range used in finding optimal cut in node splitting. BoostType No AdaBoost AdaBoost, RealAdaBoost, Bagging, AdaBoostR2, Grad Boosting type",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:11303,perform,performed,11303,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,1,['perform'],['performed']
Performance," are invisible since the current track has not yet reached; its mother. This is not the case when going the other way since the; track has first to exit the extruding node before checking the mother.; In other words, an extrusion behavior is dependent on the track; parameters, which is a highly undesirable effect. B) We will call ***`overlaps`*** only the regions in space contained by; more than one node inside the same container. The owner of such regions; cannot be determined based on hierarchical considerations; therefore; they will be considered as belonging to the node from which the current; track is coming from. When coming from their container, the ownership is totally; unpredictable. Again, the ownership of overlapping regions highly; depends on the current track parameters. We must say that even the overlaps of type A) and B) are allowed in case; the corresponding nodes are created using; **`TGeoVolume`**`::AddNodeOverlap()` method. Navigation is performed in such; cases by giving priority to the non-overlapping nodes. The modeller has; to perform an additional search through the overlapping candidates.; These are detected automatically during the geometry closing procedure; in order to optimize the algorithm, but we will stress that extensive; usage of this feature leads to a drastic deterioration of performance.; In the following we will focus on the non-declared overlaps of type A); and B) since this is the main source of errors during tracking. These; are generally non-intended overlaps due to coding mistakes or bad; geometry design. The checking package is loaded together with the; painter classes and contains an automated overlap checker.**. ![Overlap checking](pictures/030001DF.png). This can be activated both at volume level (checking for illegal; overlaps only one level inside a given volume) and from the geometry; manager level (checking full geometry):. ``` {.cpp}; myVolume->CheckOverlaps(precision, option);; gGeoManager->CheckOverlaps(precision",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:131650,perform,performed,131650,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['perform'],['performed']
Performance," are loaded also. The dependent; libraries are shown in the ROOT reference guide's library dependency; graph. The difference between reference guide `libHist` and; `libHistPainter` is that the former needs to be explicitly linked and; the latter will be loaded automatically at runtime when ROOT needs it,; by means of the Plugin Manager. plugin manager. In the Figure 1-2, the libraries represented by green boxes outside of; the core are loaded via the plugin manager plugin manager or; equivalent techniques, while the white ones are not. Of course, if one; wants to access a plugin library directly, it has to be explicitly; linked. An example of a plugin library is `libMinuit`. To create and; fill histograms you need to link `libHist.so`. If the code has a call; to fit the histogram, the ""fitter"" will dynamically load libMinuit if; it is not yet loaded. #### Plugins: Runtime Library Dependencies for Linking. plugin manager The Plugin Manager **`TPluginManager`** allows; postponing library dependencies to runtime: a plugin library will only; be loaded when it is needed. Non-plugins will need to be linked, and; are thus loaded at start-up. Plugins are defined by a base class (e.g.; **`TFile`**) that will be implemented in a plugin, a tag used to; identify the plugin (e.g. `^rfio:` as part of the protocol string),; the plugin class of which an object will be created; (e.g. **`TRFIOFile`**), the library to be loaded (in short; `libRFIO.so` to RFIO), and the constructor to be called (e.g.; ""`TRFIOFile()`""). This can be specified in the `.rootrc` which already; contains many plugin definitions, or by calls to; `gROOT->GetPluginManager()->AddHandler()`. #### Library AutoLoading. When using a class in Cling, e.g. in an interpreted source file, ROOT; will automatically load the library that defines this class. On; start-up, ROOT parses all files ending on `.rootmap` rootmap that are; in one of the `$LD_LIBRARY_PATH` (or `$DYLD_LIBRARY_PATH` for `MacOS`,; or `$PATH` for `Windows",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:19112,load,loaded,19112,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,1,['load'],['loaded']
Performance," are not the same enable the schema evolution support (in case ROOT; objects; are transferred). . XROOTD. New version 20080621-0000 containing several improvements and fixes; Server:. New daemon 'cmsd' supposed to replace 'olbd' with improved performances; Improved polling strategy; Fix problem with handling writev creating unjustified disconnections ; Fix problem with setrlimit on MacOsX Leopard. Client:; ; Fix a nasty memory leak in XrdClientCacheRead affecting; processing via TChain; Optimized file closing recipe; Fix; potential cache thrashing problem with big blocks requests. Fixes / improvements in the GSI plug-in:; ; support for large (> 32 bits) certificate serial; numbers in CRL handling; support for an external function for DN-to-username; mapping function; provide example for an LDAP based search; fixed a few problem with return code checking. netx. TXNetFile:; . Enable dynamic cache size synchronization; ; Enable per-instance control of the cache parameters; also for RAW files; by; default cache is OFF for these files, but there maybe cases in which the cache can; improve performances.; Remove call to XrdClient::Sync in SysStat. Correctly honor the create/recreate options coming from TFile::Open(); Allow the size of the (written) file to be retrieved after the Close (solves several reported file size mismatches).; . TXNetSystem:; ; Fix problem with GetDirEntry: the entry object was; going out-of-scope so; that the returned string was meaningless.; Reset; the list if dir entries in FreeDirectory.; Fix problem affecting repeated calls. The implementation of TFile throughput and info sending was; just sending 'regular' samples about the activity of the single TFile; instance that happened to trigger an activity in the right moment.; Now TMonaLisaWriter keeps internally track of every; activity; and regularly sends summaries valid for all the files which had; activity in the last time interval.; Additionally, it's now finalized the infrastructure able to; me",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/doc/v520/index.html:1467,cache,cache,1467,net/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v520/index.html,5,"['cache', 'perform']","['cache', 'performances']"
Performance," are represented in memory and in registers. First, a recap. The ""endianness"" of an item affects its representation in memory only. In a register, a number is just a sequence of bits - 64 bits in the case of AArch64 general purpose registers. Memory, however, is a sequence of addressable units of 8 bits in size. Any number greater than 8 bits must therefore be split up into 8-bit chunks, and endianness describes the order in which these chunks are laid out in memory. A ""little endian"" layout has the least significant byte first (lowest in memory address). A ""big endian"" layout has the *most* significant byte first. This means that when loading an item from big endian memory, the lowest 8-bits in memory must go in the most significant 8-bits, and so forth. ``LDR`` and ``LD1``; ===================. .. figure:: ARM-BE-ldr.png; :align: right. Big endian vector load using ``LDR``. A vector is a consecutive sequence of items that are operated on simultaneously. To load a 64-bit vector, 64 bits need to be read from memory. In little endian mode, we can do this by just performing a 64-bit load - ``LDR q0, [foo]``. However if we try this in big endian mode, because of the byte swapping the lane indices end up being swapped! The zero'th item as laid out in memory becomes the n'th lane in the vector. .. figure:: ARM-BE-ld1.png; :align: right. Big endian vector load using ``LD1``. Note that the lanes retain the correct ordering. Because of this, the instruction ``LD1`` performs a vector load but performs byte swapping not on the entire 64 bits, but on the individual items within the vector. This means that the register content is the same as it would have been on a little endian system. It may seem that ``LD1`` should suffice to perform vector loads on a big endian machine. However there are pros and cons to the two approaches that make it less than simple which register format to pick. There are two options:. 1. The content of a vector register is the same *as if* it had been ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst:2787,load,load,2787,interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,1,['load'],['load']
Performance," are subregisters of this class; list<RegisterClass> SubRegClassList = [];. code MethodProtos = [{}]; // to insert arbitrary code; code MethodBodies = [{}];; }. To define a ``RegisterClass``, use the following 4 arguments:. * The first argument of the definition is the name of the namespace. * The second argument is a list of ``ValueType`` register type values that are; defined in ``include/llvm/CodeGen/ValueTypes.td``. Defined values include; integer types (such as ``i16``, ``i32``, and ``i1`` for Boolean),; floating-point types (``f32``, ``f64``), and vector types (for example,; ``v8i16`` for an ``8 x i16`` vector). All registers in a ``RegisterClass``; must have the same ``ValueType``, but some registers may store vector data in; different configurations. For example a register that can process a 128-bit; vector may be able to handle 16 8-bit integer elements, 8 16-bit integers, 4; 32-bit integers, and so on. * The third argument of the ``RegisterClass`` definition specifies the; alignment required of the registers when they are stored or loaded to; memory. * The final argument, ``regList``, specifies which registers are in this class.; If an alternative allocation order method is not specified, then ``regList``; also defines the order of allocation used by the register allocator. Besides; simply listing registers with ``(add R0, R1, ...)``, more advanced set; operators are available. See ``include/llvm/Target/Target.td`` for more; information. In ``SparcRegisterInfo.td``, three ``RegisterClass`` objects are defined:; ``FPRegs``, ``DFPRegs``, and ``IntRegs``. For all three register classes, the; first argument defines the namespace with the string ""``SP``"". ``FPRegs``; defines a group of 32 single-precision floating-point registers (``F0`` to; ``F31``); ``DFPRegs`` defines a group of 16 double-precision registers; (``D0-D15``). .. code-block:: text. // F0, F1, F2, ..., F31; def FPRegs : RegisterClass<""SP"", [f32], 32, (sequence ""F%u"", 0, 31)>;. def DFPRegs : Regist",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:22343,load,loaded,22343,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['load'],['loaded']
Performance," are two variant types. ``BinaryIdsSize``; The byte size of `binary id`_ section. ``NumData``; The number of profile metadata. The byte size of `profile metadata`_ section; could be computed with this field. ``NumCounter``; The number of entries in the profile counter section. The byte size of `counter`_; section could be computed with this field. ``NumBitmapBytes``; The number of bytes in the profile `bitmap`_ section. ``NamesSize``; The number of bytes in the name section. .. _`CountersDelta`:. ``CountersDelta``; This field records the in-memory address difference between the `profile metadata`_; and counter section in the instrumented binary, i.e., ``start(__llvm_prf_cnts) - start(__llvm_prf_data)``. It's used jointly with the `CounterPtr`_ field to compute the counter offset; relative to ``start(__llvm_prf_cnts)``. Check out calculation-of-counter-offset_; for a visualized explanation. .. note::; The ``__llvm_prf_data`` object file section might not be loaded into memory; when instrumented binary runs or might not get generated in the instrumented; binary in the first place. In those cases, ``CountersDelta`` is not used and; other mechanisms are used to match counters with instrumented code. See; `lightweight instrumentation`_ and `binary profile correlation`_ for examples. ``BitmapDelta``; This field records the in-memory address difference between the `profile metadata`_; and bitmap section in the instrumented binary, i.e., ``start(__llvm_prf_bits) - start(__llvm_prf_data)``. It's used jointly with the `BitmapPtr`_ to find the bitmap of a profile data; record, in a similar way to how counters are referenced as explained by; calculation-of-counter-offset_ . Similar to `CountersDelta`_ field, this field may not be used in non-PGO variants; of profiles. ``NamesDelta``; Records the in-memory address of name section. Not used except for raw profile; reader error checking. ``ValueKindLast``; Records the number of value kinds. Macro `VALUE_PROF_KIND`_ defines the val",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrProfileFormat.rst:4661,load,loaded,4661,interpreter/llvm-project/llvm/docs/InstrProfileFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/InstrProfileFormat.rst,1,['load'],['loaded']
Performance," are:. - `tree1.C`: a tree with several simple (integers and floating point); variables. - `tree2.C`: a tree built from a C structure (`struct`). This example; uses the `Geant3` C wrapper as an example of a FORTRAN common block; ported to C with a C structure. - `tree3.C:` in this example, we will show how to extend a tree with a; branch from another tree with the Friends feature. These trees have; branches with variable length arrays. Each entry has a variable; number of tracks, and each track has several variables. - `tree4.C:` a tree with a class (`Event`). The class Event is defined; in `$ROOTSYS/test`. In this example we first encounter the impact of; splitting a branch. Each script contains the main function, with the same name as the file; (i.e. `tree1`), the function to write - `tree1w`, and the function to; read - `tree1r`. If the script is not run in batch mode, it displays the; tree in the browser and tree viewer. To study the example scripts, you; can either execute the main script, or load the script and execute a; specific function. For example:. ``` {.cpp}; // execute the function that writes, reads, shows the tree; root[] x tree1.C; // use ACLiC to build shared library, check syntax, execute; root[] x tree1.C++; // Load the script and select a function to execute; root[] L tree1.C; root[] tree1w(); root[] tree1r(); ```. ## Example 1: A Tree with Simple Variables. This example shows how to write, view, and read a tree with several; simple (integers and floating-point) variables. ### Writing the Tree. Below is the function that writes the tree (`tree1w`). First, the; variables are defined (`px, py, pz,` `random` and `ev`). Then we add a; branch for each of the variables to the tree, by calling the; `TTree::Branch` method for each variable. ``` {.cpp}; void tree1w(){. // create a tree file tree1.root - create the file, the Tree and; // a few branches; TFile f(""tree1.root"",""recreate"");; TTree t1(""t1"",""a simple Tree with simple variables"");; Float_t px, p",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:34472,load,load,34472,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['load'],['load']
Performance," as `llvm_blake3_hasher_finalize`, but with an additional `seek`; parameter for the starting byte position in the output stream. To; efficiently stream a large output without allocating memory, call this; function in a loop, incrementing `seek` by the output length each time. ---. ```c; void llvm_blake3_hasher_reset(; llvm_blake3_hasher *self);; ```. Reset the hasher to its initial state, prior to any calls to; `llvm_blake3_hasher_update`. Currently this is no different from calling; `llvm_blake3_hasher_init` or similar again. However, if this implementation gains; multithreading support in the future, and if `llvm_blake3_hasher` holds (optional); threading resources, this function will reuse those resources. # Building. This implementation is just C and assembly files. ## x86. Dynamic dispatch is enabled by default on x86. The implementation will; query the CPU at runtime to detect SIMD support, and it will use the; widest instruction set available. By default, `blake3_dispatch.c`; expects to be linked with code for five different instruction sets:; portable C, SSE2, SSE4.1, AVX2, and AVX-512. For each of the x86 SIMD instruction sets, four versions are available:; three flavors of assembly (Unix, Windows MSVC, and Windows GNU) and one; version using C intrinsics. The assembly versions are generally; preferred. They perform better, they perform more consistently across; different compilers, and they build more quickly. On the other hand, the; assembly versions are x86\_64-only, and you need to select the right; flavor for your target platform. ## ARM NEON. The NEON implementation is enabled by default on AArch64, but not on; other ARM targets, since not all of them support it. To enable it, set; `BLAKE3_USE_NEON=1`. To explicitiy disable using NEON instructions on AArch64, set; `BLAKE3_USE_NEON=0`. ## Other Platforms. The portable implementation should work on most other architectures. # Multithreading. The implementation doesn't currently support multithreading.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md:7544,perform,perform,7544,interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Support/BLAKE3/README.md,2,['perform'],['perform']
Performance," as a ``<Inner> x <OuterColumns>`` matrix, and; multiplies them. The result matrix is returned in the result vector. Arguments:; """""""""""""""""""". The first vector argument ``%A`` corresponds to a matrix with ``<OuterRows> *; <Inner>`` elements, and the second argument ``%B`` to a matrix with; ``<Inner> * <OuterColumns>`` elements. Arguments ``<OuterRows>``,; ``<Inner>`` and ``<OuterColumns>`` must be positive, constant integers. The; returned vector must have ``<OuterRows> * <OuterColumns>`` elements.; Vectors ``%A``, ``%B``, and the returned vector all have the same float or; integer element type. '``llvm.matrix.column.major.load.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare vectorty @llvm.matrix.column.major.load.*(; ptrty %Ptr, i64 %Stride, i1 <IsVolatile>, i32 <Rows>, i32 <Cols>). Overview:; """""""""""""""""". The '``llvm.matrix.column.major.load.*``' intrinsics load a ``<Rows> x <Cols>``; matrix using a stride of ``%Stride`` to compute the start address of the; different columns. The offset is computed using ``%Stride``'s bitwidth. This; allows for convenient loading of sub matrixes. If ``<IsVolatile>`` is true, the; intrinsic is considered a :ref:`volatile memory access <volatile>`. The result; matrix is returned in the result vector. If the ``%Ptr`` argument is known to; be aligned to some boundary, this can be specified as an attribute on the; argument. Arguments:; """""""""""""""""""". The first argument ``%Ptr`` is a pointer type to the returned vector type, and; corresponds to the start address to load from. The second argument ``%Stride``; is a positive, constant integer with ``%Stride >= <Rows>``. ``%Stride`` is used; to compute the column memory addresses. I.e., for a column ``C``, its start; memory addresses is calculated with ``%Ptr + C * %Stride``. The third Argument; ``<IsVolatile>`` is a boolean value. The fourth and fifth arguments,; ``<Rows>`` and ``<Cols>``, correspond to the number of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:677924,load,load,677924,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," as hardware resource pressure. The analysis and; reporting style were inspired by the IACA tool from Intel. For example, you can compile code with clang, output assembly, and pipe it; directly into :program:`llvm-mca` for analysis:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -S -o - | llvm-mca -mcpu=btver2. Or for Intel syntax:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -masm=intel -S -o - | llvm-mca -mcpu=btver2. (:program:`llvm-mca` detects Intel syntax by the presence of an `.intel_syntax`; directive at the beginning of the input. By default its output syntax matches; that of its input.). Scheduling models are not just used to compute instruction latencies and; throughput, but also to understand what processor resources are available; and how to simulate them. By design, the quality of the analysis conducted by :program:`llvm-mca` is; inevitably affected by the quality of the scheduling models in LLVM. If you see that the performance report is not accurate for a processor,; please `file a bug <https://github.com/llvm/llvm-project/issues>`_; against the appropriate backend. OPTIONS; -------. If ``input`` is ""``-``"" or omitted, :program:`llvm-mca` reads from standard; input. Otherwise, it will read from the specified filename. If the :option:`-o` option is omitted, then :program:`llvm-mca` will send its output; to standard output if the input is from standard input. If the :option:`-o`; option specifies ""``-``"", then the output will also be sent to standard output. .. option:: -help. Print a summary of command line options. .. option:: -o <filename>. Use ``<filename>`` as the output filename. See the summary above for more; details. .. option:: -mtriple=<target triple>. Specify a target triple string. .. option:: -march=<arch>. Specify the architecture for which to analyze the code. It defaults to the; host default target. .. option:: -mcpu=<cpuname>. Specify the processor for which to analyze the code. By default, the cpu name; is autode",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:1819,perform,performance,1819,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['perform'],['performance']
Performance," as if it were an if-block opened by the preceding; part of the statement:. .. code-block:: c++. std::sort(foo.begin(), foo.end(), [&](Foo a, Foo b) -> bool {; if (a.blah < b.blah); return true;; if (a.baz < b.baz); return true;; return a.bam < b.bam;; });. To take best advantage of this formatting, if you are designing an API which; accepts a continuation or single callable argument (be it a function object, or; a ``std::function``), it should be the last argument if at all possible. If there are multiple multi-line lambdas in a statement, or additional; parameters after the lambda, indent the block two spaces from the indent of the; ``[]``:. .. code-block:: c++. dyn_switch(V->stripPointerCasts(),; [] (PHINode *PN) {; // process phis...; },; [] (SelectInst *SI) {; // process selects...; },; [] (LoadInst *LI) {; // process loads...; },; [] (AllocaInst *AI) {; // process allocas...; });. Braced Initializer Lists; """""""""""""""""""""""""""""""""""""""""""""""". Starting from C++11, there are significantly more uses of braced lists to; perform initialization. For example, they can be used to construct aggregate; temporaries in expressions. They now have a natural way of ending up nested; within each other and within function calls in order to build up aggregates; (such as option structs) from local variables. The historically common formatting of braced initialization of aggregate; variables does not mix cleanly with deep nesting, general expression contexts,; function arguments, and lambdas. We suggest new code use a simple rule for; formatting braced initialization lists: act as-if the braces were parentheses; in a function call. The formatting rules exactly match those already well; understood for formatting nested function calls. Examples:. .. code-block:: c++. foo({a, b, c}, {1, 2, 3});. llvm::Constant *Mask[] = {; llvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 0),; llvm::ConstantInt::get(llvm::Type::getInt32Ty(getLLVMContext()), 1),; llvm::ConstantInt::get(llvm::Type:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst:20196,perform,perform,20196,interpreter/llvm-project/llvm/docs/CodingStandards.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodingStandards.rst,1,['perform'],['perform']
Performance," as it skips intermediate; `CMakeLists.txt` files which may be required. - `TEST_SUITE_COLLECT_STATS`. Collect internal LLVM statistics. Appends `-save-stats=obj` when invoking the; compiler and makes the lit runner collect and merge the statistic files. - `TEST_SUITE_RUN_BENCHMARKS`. If this is set to `OFF` then lit will not actually run the tests but just; collect build statistics like compile time and code size. - `TEST_SUITE_USE_PERF`. Use the `perf` tool for time measurement instead of the `timeit` tool that; comes with the test-suite. The `perf` is usually available on linux systems. - `TEST_SUITE_SPEC2000_ROOT`, `TEST_SUITE_SPEC2006_ROOT`, `TEST_SUITE_SPEC2017_ROOT`, ... Specify installation directories of external benchmark suites. You can find; more information about expected versions or usage in the README files in the; `External` directory (such as `External/SPEC/README`). ### Common CMake Flags. - `-GNinja`. Generate build files for the ninja build tool. - `-Ctest-suite/cmake/caches/<cachefile.cmake>`. Use a CMake cache. The test-suite comes with several CMake caches which; predefine common or tricky build configurations. Displaying and Analyzing Results; --------------------------------. The `compare.py` script displays and compares result files. A result file is; produced when invoking lit with the `-o filename.json` flag. Example usage:. - Basic Usage:. ```text; % test-suite/utils/compare.py baseline.json; Warning: 'test-suite :: External/SPEC/CINT2006/403.gcc/403.gcc.test' has No metrics!; Tests: 508; Metric: exec_time. Program baseline. INT2006/456.hmmer/456.hmmer 1222.90; INT2006/464.h264ref/464.h264ref 928.70; ...; baseline; count 506.000000; mean 20.563098; std 111.423325; min 0.003400; 25% 0.011200; 50% 0.339450; 75% 4.067200; max 1222.896800; ```. - Show compile_time or text segment size metrics:. ```bash; % test-suite/utils/compare.py -m compile_time baseline.json; % test-suite/utils/compare.py -m size.__text baseline.json; ```. - Compare two r",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md:7041,cache,caches,7041,interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteGuide.md,2,['cache'],"['cachefile', 'caches']"
Performance," as the first line of the; method. If that still doesn't remove enough, then change the caller of; ``InstCombiner::DoOneIteration``, ``InstCombiner::runOnFunction`` to limit the; number of iterations. You may also find it useful to use ""``-stats``"" now to see what parts of; instcombine are firing. This can guide where to put additional reporting code. At this point, if the amount of transformations is still too large, then; inserting code to limit whether or not to execute the body of the code in the; visit function can be helpful. Add a static counter which is incremented on; every invocation of the function. Then add code which simply returns false on; desired ranges. For example:. .. code-block:: c++. static int calledCount = 0;; calledCount++;; LLVM_DEBUG(if (calledCount < 212) return false);; LLVM_DEBUG(if (calledCount > 217) return false);; LLVM_DEBUG(if (calledCount == 213) return false);; LLVM_DEBUG(if (calledCount == 214) return false);; LLVM_DEBUG(if (calledCount == 215) return false);; LLVM_DEBUG(if (calledCount == 216) return false);; LLVM_DEBUG(dbgs() << ""visitXOR calledCount: "" << calledCount << ""\n"");; LLVM_DEBUG(dbgs() << ""I: ""; I->dump());. could be added to ``visitXOR`` to limit ``visitXor`` to being applied only to; calls 212 and 217. This is from an actual test case and raises an important; point---a simple binary search may not be sufficient, as transformations that; interact may require isolating more than one call. In TargetLowering, use; ``return SDNode();`` instead of ``return false;``. Now that the number of transformations is down to a manageable number, try; examining the output to see if you can figure out which transformations are; being done. If that can be figured out, then do the usual debugging. If which; code corresponds to the transformation being performed isn't obvious, set a; breakpoint after the call count based disabling and step through the code.; Alternatively, you can use ""``printf``"" style debugging to report waypoints.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst:11190,perform,performed,11190,interpreter/llvm-project/llvm/docs/Bugpoint.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Bugpoint.rst,1,['perform'],['performed']
Performance," as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x float> %a, <4 x float> <float 1.0, float 1.0, float 1.0, float 1.0>; %also.r = call float @llvm.vector.reduce.fmul.v4f32(float %start, <4 x float> %masked.a). .. _int_vp_reduce_and:. '``llvm.vp.reduce.and.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.and.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.and.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``AND`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.and``' intrinsic performs the integer ``AND`` reduction; (:ref:`llvm.vector.reduce.and <int_vector_reduce_and>`) of the vector operand; ``val`` on each enabled lane, performing an '``and``' of that with with the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value ``UINT_MAX``, or ``-1`` (i.e. having no effect on the reduction; operation). If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.and.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:757379,perform,performed,757379,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance," as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> <i32 0, i32 0, i32 0, i32 0>; %reduction = call i32 @llvm.vector.reduce.or.v4i32(<4 x i32> %masked.a); %also.r = or i32 %reduction, %start. .. _int_vp_reduce_xor:. '``llvm.vp.reduce.xor.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.xor.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.xor.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated integer ``XOR`` reduction of a vector and a scalar starting value,; returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.xor``' intrinsic performs the integer ``XOR`` reduction; (:ref:`llvm.vector.reduce.xor <int_vector_reduce_xor>`) of the vector operand; ``val`` on each enabled lane, performing an '``xor``' of that with the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``0`` (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.xor.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:761427,perform,performed,761427,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance," at the beginning of; the entry block should be preferred. In particular, place them before any; call instructions. Call instructions might get inlined and replaced with; multiple basic blocks. The end result is that a following alloca instruction; would no longer be in the entry basic block afterward. The SROA (Scalar Replacement Of Aggregates) and Mem2Reg passes only attempt; to eliminate alloca instructions that are in the entry basic block. Given; SSA is the canonical form expected by much of the optimizer; if allocas can; not be eliminated by Mem2Reg or SROA, the optimizer is likely to be less; effective than it could be. Avoid loads and stores of large aggregate type; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. LLVM currently does not optimize well loads and stores of large :ref:`aggregate; types <t_aggregate>` (i.e. structs and arrays). As an alternative, consider; loading individual fields from memory. Aggregates that are smaller than the largest (performant) load or store; instruction supported by the targeted hardware are well supported. These can; be an effective way to represent collections of small packed fields. Prefer zext over sext when legal; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. On some architectures (X86_64 is one), sign extension can involve an extra; instruction whereas zero extension can be folded into a load. LLVM will try to; replace a sext with a zext when it can be proven safe, but if you have; information in your source language about the range of an integer value, it can; be profitable to use a zext rather than a sext. Alternatively, you can :ref:`specify the range of the value using metadata; <range-metadata>` and LLVM can do the sext to zext conversion for you. Zext GEP indices to machine register width; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Internally, LLVM often promotes the width of GEP indices to machine register; width. When it does so, it will default to using sign extension (sext); operations for safety. If your source",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:3333,perform,performant,3333,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,2,"['load', 'perform']","['load', 'performant']"
Performance," atomic/atomicrmw.; - Ensures that; following; loads will not see; stale MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. load atomic acquire - agent - generic 1. flat_load sc1=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load sc0=1 sc1=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; the following; buffer_inv.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_inv.; - Ensures the atomicrmw; has completed; before invalidating; the cache. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:298699,load,load,298699,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vm/vscnt(0). - If CU wavefront execution; mode, omit.; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than the; atomicrmw value; being acquired. 4. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavef",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:363568,load,load,363568,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before; the following; buffer_inv.; - Ensures any; following global; data read is no; older than the; atomicrmw value; being acquired. 4. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If not TgSplit execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_inv and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:318399,load,load,318399,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance," atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; sc0=1 sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. load atomic acquire - agent - generic 1. flat_load sc1=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load sc0=1 sc1=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; the following; buffer_inv.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures tha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:297733,load,loads,297733,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. GFX940, GFX941; buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store; sc0=1; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. buffer_wbl2 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 3. GFX940, GFX941; buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store; sc1=1; store atomic release - system - global 1. buffer_wbl2 sc0=1 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:308331,load,load,308331,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," atomicity of every load and; store operation would be prohibitive and preclude a vast amount of; optimization. ARC may assume that non-ARC code engages in sensible balancing; behavior and does not rely on exact or minimum retain count values; except as guaranteed by ``__strong`` object invariants or +1 transfer; conventions. For example, if an object is provably double-retained; and double-released, ARC may eliminate the inner retain and release;; it does not need to guard against code which performs an unbalanced; release followed by a ""balancing"" retain. .. _arc.optimization.liveness:. Object liveness; ---------------. ARC may not allow a retainable object ``X`` to be deallocated at a; time ``T`` in a computation history if:. * ``X`` is the value stored in a ``__strong`` object ``S`` with; :ref:`precise lifetime semantics <arc.optimization.precise>`, or. * ``X`` is the value stored in a ``__strong`` object ``S`` with; imprecise lifetime semantics and, at some point after ``T`` but; before the next store to ``S``, the computation history features a; load from ``S`` and in some way depends on the value loaded, or. * ``X`` is a value described as being released at the end of the; current full-expression and, at some point after ``T`` but before; the end of the full-expression, the computation history depends; on that value. .. admonition:: Rationale. The intent of the second rule is to say that objects held in normal; ``__strong`` local variables may be released as soon as the value in; the variable is no longer being used: either the variable stops; being used completely or a new value is stored in the variable. The intent of the third rule is to say that return values may be; released after they've been used. A computation history depends on a pointer value ``P`` if it:. * performs a pointer comparison with ``P``,; * loads from ``P``,; * stores to ``P``,; * depends on a pointer value ``Q`` derived via pointer arithmetic; from ``P`` (including an instance-variable o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:79137,load,load,79137,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,2,['load'],"['load', 'loaded']"
Performance," attacker-controlled inputs.; * It does not completely block speculative execution, and merely prevents; *mis*-speculated paths from leaking secrets from memory (and stalls; speculation until this can be determined).; * It is completely general and makes no fundamental assumptions about the; underlying architecture other than the ability to do branchless conditional; data updates and a lack of value prediction.; * It does not require programmers to identify all possible secret data using; static source code annotations or code vulnerable to a variant #1 style; attack. Limitations of this approach:; * It requires re-compiling source code to insert hardening instruction; sequences. Only software compiled in this mode is protected.; * The performance is heavily dependent on a particular architecture's; implementation strategy. We outline a potential x86 implementation below and; characterize its performance.; * It does not defend against secret data already loaded from memory and; residing in registers or leaked through other side-channels in; non-speculative execution. Code dealing with this, e.g cryptographic; routines, already uses constant-time algorithms and code to prevent; side-channels. Such code should also scrub registers of secret data following; [these; guidelines](https://github.com/HACS-workshop/spectre-mitigations/blob/master/crypto_guidelines.md).; * To achieve reasonable performance, many loads may not be checked, such as; those with compile-time fixed addresses. This primarily consists of accesses; at compile-time constant offsets of global and local variables. Code which; needs this protection and intentionally stores secret data must ensure the; memory regions used for secret data are necessarily dynamic mappings or heap; allocations. This is an area which can be tuned to provide more comprehensive; protection at the cost of performance.; * [Hardened loads](#hardening-the-address-of-the-load) may still load data from; _valid_ addresses if not _attack",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:6760,load,loaded,6760,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['loaded']
Performance," attributes.; + ``-Wthread-safety-analysis``: The core analysis.; + ``-Wthread-safety-precise``: Requires that mutex expressions match precisely.; This warning can be disabled for code which has a lot of aliases.; + ``-Wthread-safety-reference``: Checks when guarded members are passed by reference. :ref:`negative` are an experimental feature, which are enabled with:. * ``-Wthread-safety-negative``: Negative capabilities. Off by default. When new features and checks are added to the analysis, they can often introduce; additional warnings. Those warnings are initially released as *beta* warnings; for a period of time, after which they are migrated into the standard analysis. * ``-Wthread-safety-beta``: New features. Off by default. .. _negative:. Negative Capabilities; =====================. Thread Safety Analysis is designed to prevent both race conditions and; deadlock. The GUARDED_BY and REQUIRES attributes prevent race conditions, by; ensuring that a capability is held before reading or writing to guarded data,; and the EXCLUDES attribute prevents deadlock, by making sure that a mutex is; *not* held. However, EXCLUDES is an optional attribute, and does not provide the same; safety guarantee as REQUIRES. In particular:. * A function which acquires a capability does not have to exclude it.; * A function which calls a function that excludes a capability does not; have transitively exclude that capability. As a result, EXCLUDES can easily produce false negatives:. .. code-block:: c++. class Foo {; Mutex mu;. void foo() {; mu.Lock();; bar(); // No warning.; baz(); // No warning.; mu.Unlock();; }. void bar() { // No warning. (Should have EXCLUDES(mu)).; mu.Lock();; // ...; mu.Unlock();; }. void baz() {; bif(); // No warning. (Should have EXCLUDES(mu)).; }. void bif() EXCLUDES(mu);; };. Negative requirements are an alternative EXCLUDES that provide; a stronger safety guarantee. A negative requirement uses the REQUIRES; attribute, in conjunction with the ``!`` operator, to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst:16836,race condition,race conditions,16836,interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/ThreadSafetyAnalysis.rst,1,['race condition'],['race conditions']
Performance," aware that executing stress with 1000; events*will create several files consuming about 100 MB of disk space;*; running stress with 30 events will consume about 20 MB. The disk space; is released once stress is done. There are two ways to run `stress`:. From the system prompt or from the ROOT prompt using the interpreter. ``` {.cpp}; > cd $ROOTSYS/test; > stress // default 1000 events; > stress 30 // test with 30 events; ```. Start ROOT with the batch mode option (-b) to suppress the graphic; output. ``` {.cpp}; > root -b; root[] .L stress.cxx; root[] stress(1000)// test with 1000 events; root[] stress(30)// test with 30 events; ```. The output of stress includes a pass/fail conclusion for each test, the; total number of bytes read and written, and the elapsed real and CPU; time. It also calculates a performance index for your machine relative; to a reference machine a DELL Inspiron 7500 (Pentium III 600 MHz) with; 256 MB of memory and 18GB IDE disk in ROOTMARKS. Higher ROOTMARKS means; better performance. The reference machine has 200 ROOTMARKS, so the; sample run below with 53.7 ROOTMARKS is about four times slower than the; reference machine. Here is a sample run:. ``` {.cpp}; % root -b; root[] .x stress.cxx(30). Test 1 : Functions, Random Numbers, Histogram Fits............. OK; Test 2 : Check size & compression factor of a Root file........ OK; Test 3 : Purge, Reuse of gaps in TFile......................... OK; Test 4 : Test of 2-d histograms, functions, 2-d fits........... OK; Test 5 : Test graphics & PostScript ............................OK; Test 6 : Test subdirectories in a Root file.................... OK; Test 7 : TNtuple, selections, TCutG, TEventList.......... OK; Test 8 : Trees split and compression modes..................... OK; Test 9 : Analyze Event.root file of stress 8................... OK; Test 10 : Create 10 files starting from Event.root.............. OK; Test 11 : Test chains of Trees using the 10 files............... OK; Test 12 : Compare h",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/TutorialsandTests.md:14538,perform,performance,14538,documentation/users-guide/TutorialsandTests.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/TutorialsandTests.md,1,['perform'],['performance']
Performance," be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter.; * To ensure coherence of local memory writes of CUs with different L1 caches; in the same agent a ``buffer_wbl2`` is required. It does nothing if the; agent is configured to have a single L2, or will writeback dirty L2 cache; lines if configured to have multiple L2 caches.; * To ensure coherence of local memory writes of CUs in different agents a; ``buffer_wbl2 sc1`` is required. It will writeback dirty L2 cache lines.; * To ensure coherence of local memory reads of CUs with different L1 caches; in the same agent a ``buffer_inv sc1`` is required. It does nothing if the; agent is configured to have a single L2, or will invalidate non-local L2; cache lines if configured to have multiple L2 caches.; * To ensure coherence of local memory reads of CUs in different agents a; ``buffer_inv sc0 sc1`` is required. It will invalidate non-local L2 cache; lines if configured to have multiple L2 caches. * PCIe access from the GPU to the CPU can be kept coherent by using the MTYPE; UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted bef",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:289621,cache,cache,289621,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['cache'],"['cache', 'caches']"
Performance," be either zero or one without affecting control or; data flow of a program. The BDCE pass removes instructions that only; compute these dead bits. **BURS**; Bottom Up Rewriting System --- A method of instruction selection for code; generation. An example is the `BURG; <http://www.program-transformation.org/Transform/BURG>`_ tool. C; -. **CFI**; This abbreviation has two meanings.; Either:; Call Frame Information. Used in DWARF debug info and in C++ unwind info; to show how the function prolog lays out the stack frame. Or:; Control Flow Integrity. A general term for computer security techniques; that prevent a wide variety of malware attacks from redirecting the flow; of execution (the control flow) of a program. **CIE**; Common Information Entry. A kind of CFI used to reduce the size of FDEs.; The compiler creates a CIE which contains the information common across all; the FDEs. Each FDE then points to its CIE. **CSE**; Common Subexpression Elimination. An optimization that removes common; subexpression computation. For example ``(a+b)*(a+b)`` has two; subexpressions that are the same: ``(a+b)``. This optimization would; perform the addition only once and then perform the multiply (but only if; it's computationally correct/safe). D; -. **DAG**; Directed Acyclic Graph. .. _derived pointer:; .. _derived pointers:. **Derived Pointer**; A pointer to the interior of an object, such that a garbage collector is; unable to use the pointer for reachability analysis. While a derived pointer; is live, the corresponding object pointer must be kept in a root, otherwise; the collector might free the referenced object. With copying collectors,; derived pointers pose an additional hazard that they may be invalidated at; any `safe point`_. This term is used in opposition to `object pointer`_. **DSA**; Data Structure Analysis. **DSE**; Dead Store Elimination. E; -. **ento**; This namespace houses the; `Clang Static Analyzer <https://clang.llvm.org/docs/ClangStaticAnalyzer.html>`_.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Lexicon.rst:2074,optimiz,optimization,2074,interpreter/llvm-project/llvm/docs/Lexicon.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Lexicon.rst,1,['optimiz'],['optimization']
Performance," before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; u",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:227080,cache,cache,227080,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_loa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:246917,load,load,246917,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,"['cache', 'load']","['cache', 'load']"
Performance," behavior is dependent on the track; parameters, which is a highly undesirable effect. *B)* We will call ""overlaps"" only the regions in space contained by; more than one node inside the same container. The owner of such regions; cannot be determined based on hierarchical considerations; therefore; they will be considered as belonging to the node from which the current; track is coming from. When coming from their container, the ownership is totally; unpredictable. Again, the ownership of overlapping regions highly; depends on the current track parameters. We must say that even the overlaps of type *A)* and *B)* are allowed in case; the corresponding nodes are created using; TGeoVolume::AddNodeOverlap() method. Navigation is performed in such; cases by giving priority to the non-overlapping nodes. The modeller has; to perform an additional search through the overlapping candidates.; These are detected automatically during the geometry closing procedure; in order to optimize the algorithm, but we will stress that extensive; usage of this feature leads to a drastic deterioration of performance.; In the following we will focus on the non-declared overlaps of type *A)*; and *B)* since this is the main source of errors during tracking. These; are generally non-intended overlaps due to coding mistakes or bad; geometry design. The checking package is loaded together with the; painter classes and contains an automated overlap checker. \image html geometry008.png ""Overlap checking"". This can be activated both at volume level (checking for illegal; overlaps only one level inside a given volume) and from the geometry; manager level (checking full geometry):. ~~~{.cpp}; myVolume->CheckOverlaps(precision, option);; gGeoManager->CheckOverlaps(precision);; myNode->CheckOverlaps(precision);; ~~~. Here precision represents the desired maximum accepted overlap value in; centimeters (default value is 0.1). This tool checks all possible; significant pairs of candidates inside a given vol",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:92373,optimiz,optimize,92373,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,2,"['optimiz', 'perform']","['optimize', 'performance']"
Performance," bind to the local symbol. That is, the symbol; cannot be overridden by another module. A symbol with ``internal`` or ``private`` linkage must have ``default``; visibility. .. _dllstorageclass:. DLL Storage Classes; -------------------. All Global Variables, Functions and Aliases can have one of the following; DLL storage class:. ``dllimport``; ""``dllimport``"" causes the compiler to reference a function or variable via; a global pointer to a pointer that is set up by the DLL exporting the; symbol. On Microsoft Windows targets, the pointer name is formed by; combining ``__imp_`` and the function or variable name.; ``dllexport``; On Microsoft Windows targets, ""``dllexport``"" causes the compiler to provide; a global pointer to a pointer in a DLL, so that it can be referenced with the; ``dllimport`` attribute. the pointer name is formed by combining ``__imp_``; and the function or variable name. On XCOFF targets, ``dllexport`` indicates; that the symbol will be made visible to other modules using ""exported""; visibility and thus placed by the linker in the loader section symbol table.; Since this storage class exists for defining a dll interface, the compiler,; assembler and linker know it is externally referenced and must refrain from; deleting the symbol. A symbol with ``internal`` or ``private`` linkage cannot have a DLL storage; class. .. _tls_model:. Thread Local Storage Models; ---------------------------. A variable may be defined as ``thread_local``, which means that it will; not be shared by threads (each thread will have a separated copy of the; variable). Not all targets support thread-local variables. Optionally, a; TLS model may be specified:. ``localdynamic``; For variables that are only used within the current shared library.; ``initialexec``; For variables in modules that will not be loaded dynamically.; ``localexec``; For variables defined in the executable and only used within it. If no explicit model is given, the ""general dynamic"" model is used. The m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:25260,load,loader,25260,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loader']
Performance," block, and the; child functions can use '``llvm.localrecover``' to access the escaped allocas.; The '``llvm.localescape``' intrinsic blocks inlining, as inlining changes where; the escaped allocas are allocated, which would break attempts to use; '``llvm.localrecover``'. '``llvm.seh.try.begin``' and '``llvm.seh.try.end``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.seh.try.begin(); declare void @llvm.seh.try.end(). Overview:; """""""""""""""""". The '``llvm.seh.try.begin``' and '``llvm.seh.try.end``' intrinsics mark; the boundary of a _try region for Windows SEH Asynchrous Exception Handling. Semantics:; """""""""""""""""""". When a C-function is compiled with Windows SEH Asynchrous Exception option,; -feh_asynch (aka MSVC -EHa), these two intrinsics are injected to mark _try; boundary and to prevent potential exceptions from being moved across boundary.; Any set of operations can then be confined to the region by reading their leaf; inputs via volatile loads and writing their root outputs via volatile stores. '``llvm.seh.scope.begin``' and '``llvm.seh.scope.end``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.seh.scope.begin(); declare void @llvm.seh.scope.end(). Overview:; """""""""""""""""". The '``llvm.seh.scope.begin``' and '``llvm.seh.scope.end``' intrinsics mark; the boundary of a CPP object lifetime for Windows SEH Asynchrous Exception; Handling (MSVC option -EHa). Semantics:; """""""""""""""""""". LLVM's ordinary exception-handling representation associates EH cleanups and; handlers only with ``invoke``s, which normally correspond only to call sites. To; support arbitrary faulting instructions, it must be possible to recover the current; EH scope for any instruction. Turning every operation in LLVM that could fault; into an ``invoke`` of a new, potentially-throwing intrinsic would require adding a; large number of intrinsics, impede optimization of ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:515906,load,loads,515906,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loads']
Performance," buffer/global/flat_load; nt=1. - volatile. 1. buffer/global/flat_load; sc0=1 sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. GFX940, GFX941; - constant buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store. - !volatile & nontemporal. 1. GFX940, GFX941; buffer/global/flat_store; nt=1 sc0=1 sc1=1; GFX942; buffer/global/flat_store; nt=1. - volatile. 1. buffer/global/flat_store; sc0=1 sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/flat_load; - wavefront - generic; load atomic monotonic - workgroup - global 1. buffer/global/flat_load; - generic sc0=1; load atomic monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_load; load atomic monotonic - agent - global 1. buffer/global/flat_load; - generic sc1=1; load atomic monotonic - system - global 1. buffer/global/flat_load; - generic sc0=1 sc1=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; store atomic monotonic - workgroup - global 1. buffer/global/flat_store; - g",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:293778,load,load,293778,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance," build this file and tree follow the instructions on how to; build the examples in `$ROOTSYS/test`. Execute `Event` and instruct it; to split the object with this command (from the UNIX command line). ``` {.cpp}; > $ROOTSYS/test/Event 400 1 2 1; ```. This creates an `Event.root` file with 400 events, compressed, split,; and filled. See `$ROOTSYS/test/MainEvent.cxx` for more info. The person who designed the tree makes a shared library available to; you, which defines the classes needed. In this case, the classes are; Event, `EventHeader`, and Track and they are defined in the shared; library `libEvent.so`. The designer also gives you the `Event.h` file to; see the definition of the classes. You can locate `Event.h` in; `$ROOTSYS/test`, and if you have not yet built `libEvent.so`, please see; the instructions of how to build it (typing make in \$ROOTSYS/test is; enough). If you have already built it, you can now use it again. ### Creating a Class with MakeClass. First, we load the shared library and open `Event.root`. ``` {.cpp}; root[] .L libEvent.so; root[] TFile *f = new TFile(""Event.root"");; root[] f->ls();; TFile** Event.root TTree benchmark ROOT file; TFile* Event.root TTree benchmark ROOT file; KEY: TH1F htime;1 Real-Time to write versus time; KEY: TTree T;1 An example of a ROOT tree; ```. We can see there is a tree ""`T`"", and just to verify that we are working; with the correct one, we print the tree, which will show us the header; and branches. ``` {.cpp}; root[] T->Print();; ```. From the output of print we can see that the tree has one branch for; each data member of `Event`, `Track`, and `EventHeader`. Now we can use; `TTree::MakeClass` on our tree ""`T`"". `MakeClass` takes one parameter, a; string containing the name of the class to be made. In the command; below, the name of our class will be ""`MyClass`"". ``` {.cpp}; root[] T->MakeClass(""MyClass""); Files: MyClass.h and MyClass.C generated from Tree: T; ```. Cling informs us that it has created two files. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md:123125,load,load,123125,documentation/users-guide/Trees.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Trees.md,1,['load'],['load']
Performance," but is very quick analysis. The ``-steens-aa`` pass; ^^^^^^^^^^^^^^^^^^^^^^^. The ``-steens-aa`` pass implements a variation on the well-known ""Steensgaard's; algorithm"" for interprocedural alias analysis. Steensgaard's algorithm is a; unification-based, flow-insensitive, context-insensitive, and field-insensitive; alias analysis that is also very scalable (effectively linear time). The LLVM ``-steens-aa`` pass implements a ""speculatively field-**sensitive**""; version of Steensgaard's algorithm using the Data Structure Analysis framework.; This gives it substantially more precision than the standard algorithm while; maintaining excellent analysis scalability. .. note::. ``-steens-aa`` is available in the optional ""poolalloc"" module. It is not part; of the LLVM core. The ``-ds-aa`` pass; ^^^^^^^^^^^^^^^^^^^. The ``-ds-aa`` pass implements the full Data Structure Analysis algorithm. Data; Structure Analysis is a modular unification-based, flow-insensitive,; context-**sensitive**, and speculatively field-**sensitive** alias; analysis that is also quite scalable, usually at ``O(n * log(n))``. This algorithm is capable of responding to a full variety of alias analysis; queries, and can provide context-sensitive mod/ref information as well. The; only major facility not implemented so far is support for must-alias; information. .. note::. ``-ds-aa`` is available in the optional ""poolalloc"" module. It is not part of; the LLVM core. The ``-scev-aa`` pass; ^^^^^^^^^^^^^^^^^^^^^. The ``-scev-aa`` pass implements AliasAnalysis queries by translating them into; ScalarEvolution queries. This gives it a more complete understanding of; ``getelementptr`` instructions and loop induction variables than other alias; analyses have. Alias analysis driven transformations; -------------------------------------. LLVM includes several alias-analysis driven transformations which can be used; with any of the implementations above. The ``-adce`` pass; ^^^^^^^^^^^^^^^^^^. The ``-adce`` pass, wh",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst:26416,scalab,scalable,26416,interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AliasAnalysis.rst,1,['scalab'],['scalable']
Performance," by the `Block RThroughput`. Field 'uOps Per Cycle' is computed dividing the total number of simulated micro; opcodes by the total number of cycles. A delta between Dispatch Width and this; field is an indicator of a performance issue. In the absence of loop-carried; data dependencies, the observed 'uOps Per Cycle' should tend to a theoretical; maximum throughput which can be computed by dividing the number of uOps of a; single iteration by the `Block RThroughput`. Field *uOps Per Cycle* is bounded from above by the dispatch width. That is; because the dispatch width limits the maximum size of a dispatch group. Both IPC; and 'uOps Per Cycle' are limited by the amount of hardware parallelism. The; availability of hardware resources affects the resource pressure distribution,; and it limits the number of instructions that can be executed in parallel every; cycle. A delta between Dispatch Width and the theoretical maximum uOps per; Cycle (computed by dividing the number of uOps of a single iteration by the; `Block RThroughput`) is an indicator of a performance bottleneck caused by the; lack of hardware resources.; In general, the lower the Block RThroughput, the better. In this example, ``uOps per iteration/Block RThroughput`` is 1.50. Since there; are no loop-carried dependencies, the observed `uOps Per Cycle` is expected to; approach 1.50 when the number of iterations tends to infinity. The delta between; the Dispatch Width (2.00), and the theoretical maximum uOp throughput (1.50) is; an indicator of a performance bottleneck caused by the lack of hardware; resources, and the *Resource pressure view* can help to identify the problematic; resource usage. The second section of the report is the `instruction info view`. It shows the; latency and reciprocal throughput of every instruction in the sequence. It also; reports extra information related to the number of micro opcodes, and opcode; properties (i.e., 'MayLoad', 'MayStore', and 'HasSideEffects'). Field *RThroughput",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:17893,perform,performance,17893,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,"['bottleneck', 'perform']","['bottleneck', 'performance']"
Performance," by the wavefronts of the work-groups; executing on it. The exception is when in tgsplit execution mode when no LDS; is allocated as wavefronts of the same work-group can be in different CUs.; * All LDS operations of a CU are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that ``flat_load/store/atomic`` instructions can report out of vector memory; order if they access LDS memory, and out of LDS operation order if they access; global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore:. * No special action is required for coherence between the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_inv sc0`` is required which will invalidate; the L1 cache. * A ``buffer_inv sc0`` is required to invalidate the L1 cache for coherence; between wavefronts executing in different work-groups as they may be; executing on different CUs. * Atomic read-modify-write instructions implicitly bypass the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:285701,perform,performed,285701,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performed']
Performance," by the wavefronts of the work-groups; executing on it. The exception is when in tgsplit execution mode when no LDS; is allocated as wavefronts of the same work-group can be in different CUs.; * All LDS operations of a CU are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that ``flat_load/store/atomic`` instructions can report out of vector memory; order if they access LDS memory, and out of LDS operation order if they access; global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore:. * No special action is required for coherence between the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_wbinvl1_vol`` is required as described in; the following item. * A ``buffer_wbinvl1_vol`` is required for coherence between wavefronts; executing in different work-groups as they may be executing on different; CUs. * The scalar memory operations access a scalar L1 cache shared by all wavefronts",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:235553,perform,performed,235553,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performed']
Performance," byte first (lowest in memory address). A ""big endian"" layout has the *most* significant byte first. This means that when loading an item from big endian memory, the lowest 8-bits in memory must go in the most significant 8-bits, and so forth. ``LDR`` and ``LD1``; ===================. .. figure:: ARM-BE-ldr.png; :align: right. Big endian vector load using ``LDR``. A vector is a consecutive sequence of items that are operated on simultaneously. To load a 64-bit vector, 64 bits need to be read from memory. In little endian mode, we can do this by just performing a 64-bit load - ``LDR q0, [foo]``. However if we try this in big endian mode, because of the byte swapping the lane indices end up being swapped! The zero'th item as laid out in memory becomes the n'th lane in the vector. .. figure:: ARM-BE-ld1.png; :align: right. Big endian vector load using ``LD1``. Note that the lanes retain the correct ordering. Because of this, the instruction ``LD1`` performs a vector load but performs byte swapping not on the entire 64 bits, but on the individual items within the vector. This means that the register content is the same as it would have been on a little endian system. It may seem that ``LD1`` should suffice to perform vector loads on a big endian machine. However there are pros and cons to the two approaches that make it less than simple which register format to pick. There are two options:. 1. The content of a vector register is the same *as if* it had been loaded with an ``LDR`` instruction.; 2. The content of a vector register is the same *as if* it had been loaded with an ``LD1`` instruction. Because ``LD1 == LDR + REV`` and similarly ``LDR == LD1 + REV`` (on a big endian system), we can simulate either type of load with the other type of load plus a ``REV`` instruction. So we're not deciding which instructions to use, but which format to use (which will then influence which instruction is best to use). .. The 'clearer' container is required to make the following sect",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst:3296,perform,performs,3296,interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BigEndianNEON.rst,3,"['load', 'perform']","['load', 'performs']"
Performance," bytecode representation:. ISSUES RESOLVED; ---------------. 1. We decided that we shall use a flat namespace to represent our ; variables in SSA form, as opposed to having a two dimensional namespace; of the original variable and the SSA instance subscript. ARGUMENT AGAINST:; * A two dimensional namespace would be valuable when doing alias ; analysis because the extra information can help limit the scope of; analysis. ARGUMENT FOR:; * Including this information would require that all users of the LLVM; bytecode would have to parse and handle it. This would slow down the; common case and inflate the instruction representation with another; infinite variable space. REASONING:; * It was decided that because original variable sources could be; reconstructed from SSA form in linear time, that it would be an; unjustified expense for the common case to include the extra; information for one optimization. Alias analysis itself is typically; greater than linear in asymptotic complexity, so this extra analaysis; would not affect the runtime of the optimization in a significant; way. Additionally, this would be an unlikely optimization to do at; runtime. IDEAS TO CONSIDER; -----------------. 1. Including dominator information in the LLVM bytecode; representation. This is one example of an analysis result that may be; packaged with the bytecodes themselves. As a conceptual implementation ; idea, we could include an immediate dominator number for each basic block; in the LLVM bytecode program. Basic blocks could be numbered according; to the order of occurrence in the bytecode representation. 2. Including loop header and body information. This would facilitate; detection of intervals and natural loops. UNRESOLVED ISSUES ; ----------------- . 1. Will oSUIF provide enough of an infrastructure to support the research; that we will be doing? We know that it has less than stellar; performance, but hope that this will be of little importance for our; static compiler. This could affect",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-12-06-MeetingSummary.txt:1122,optimiz,optimization,1122,interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-12-06-MeetingSummary.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2000-12-06-MeetingSummary.txt,1,['optimiz'],['optimization']
Performance," bytes read from TFiles during the readspeed test (possibly including meta-data).; Uncompressed bytes is the number of bytes processed by reading the branch values in the TTree.; Throughput is calculated as the total number of bytes over the total runtime (including; decompression time) in the uncompressed and compressed cases. ## Interpreting results:. ### There are three possible scenarios when using rootreadspeed, namely:. - The 'Real Time' is significantly lower than your own analysis runtime.; This would imply your actual application code is dominating the runtime of your analysis,; ie. your analysis logic or framework is taking up the time.; The best way to decrease the runtime would be to optimize your code (or the framework's),; parallelize it onto multiple threads if possible (for example with; [RDataFrame](https://root.cern/doc/master/classROOT_1_1RDataFrame.html); and [EnableImplicitMT](https://root.cern/doc/master/namespaceROOT.html#a06f2b8b216b615e5abbc872c9feff40f)); or switch to a machine with a more performant CPU.; - The 'Real Time' is significantly higher than 'CPU Time / number of threads'*.; If the real time is higher than the CPU time per core it implies the reading of data is the; bottleneck, as the CPU cores are wasting time waiting for data to arrive from your disk/drive; or network connection in order to decompress it.; The best way to decrease your runtime would be transferring the data you need onto a faster; storage medium (ie. a faster disk/drive such as an SSD, or connecting to a faster network; for remote file access), or to use a compression algorithm with a higher compression ratio,; possibly at the cost of the decompression rate.; Changing the number of threads is unlikely to help, and in fact using too many threads may; degrade performance if they make requests to different regions of your local storage. ; * If no '--threads' argument was provided this is 1, otherwise it is the minimum of the value; provided and the number of threa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/readspeed/README.md:1646,perform,performant,1646,tree/readspeed/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/readspeed/README.md,1,['perform'],['performant']
Performance," caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L0 and L1 caches at the start of each kernel dispatch.; * On dGPU the kernarg backing memory is accessed as MTYPE UC (uncached) to avoid; needing to invalidate the L2 cache.; * On APU the kernarg backing memory is accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC (non-coherent). Since the private address space is only accessed; by a single thread, and is always write-before-read, there is never a need to; invalidate these entries from the L0 or L1 caches. Wavefronts are executed in native mode with in-order reporting of loads and; sample instructions. In this mode vmcnt reports completion of load, atomic with; return and sample instructions in order, and the vscnt reports the completion of; store and atomic without return in order. See ``MEM_ORDERED`` field in; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`. Wavefronts can be executed in WGP or CU wavefront execution mode:. * In WGP wavefront execution mode the wavefronts of a work-group ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:341372,cache,cache,341372,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," can be accessed via normal web server. From the browser side, JSROOT could regularly read the specified objects and update their drawings. But such solution has three major caveats. First of all, one need to store the data of all objects, which only potentially could be displayed in the browser. In case of 10 objects it does not matter, but for 1000 or 100000 objects this will be a major performance penalty. With such big amount of data one will never achieve higher update rate. The second problem is I/O. To read the first object from the ROOT file, one need to perform several (about 5) file-reading operations via http protocol.; There is no http file locking mechanism (at least not for standard web servers),; therefore there is no guarantee that the file content is not changed/replaced between consequent read operations. Therefore, one should expect frequent I/O failures while trying to monitor data from ROOT binary files. There is a workaround for the problem - one could load the file completely and exclude many partial I/O operations by this. To achieve this with JSROOT, one should add ""+"" sign at the end of the file name. Of course, it only could work for small files. If somebody still wants to use monitoring of data from ROOT files, could try link like:. - <https://root.cern/js/latest/?nobrowser&file=../files/hsimple.root+&item=hpx;1&monitoring=2000>. In this particular case, the histogram is not changing. ## JSROOT API. JSROOT can be used in arbitrary HTML pages to display data, produced with or without ROOT-based applications. Many different examples of JSROOT API usage can be found on [JSROOT API examples](https://root.cern/js/latest/api.htm) page. ### Import JSROOT functionality. Major JSROOT functions are located in `main.mjs` module and can be imported like:. ```javascript; <script type='module'>; import { openFile, draw } from 'https://root.cern/js/latest/modules/main.mjs';; let filename = ""https://root.cern/js/files/hsimple.root"";; let file = await ope",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md:33363,load,load,33363,documentation/JSROOT/JSROOT.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/JSROOT/JSROOT.md,1,['load'],['load']
Performance," can be asked for at a given moment, but; rather represented by the combination: current node/current global; matrix. However, physical nodes have unique ID's that can be retrieved; for a given modeller state. These can be fed back to the modeller in; order to force a physical node to become current. The advantage of this; comes from the fact that all navigation queries check first the current; node; therefore the location of a point in the geometry can be saved as; a starting state for later use. Nodes can be declared as `overlapping` in case they do overlap with; other nodes inside the same container or extrude this container (see; also ‘Checking the Geometry'). Non-overlapping nodes can be created; with:. ~~~{.cpp}; TGeoVolume::AddNode(TGeoVolume *daughter,Int_t copy_No,; TGeoMatrix *matr);; ~~~. The creation of overlapping nodes can be done with a similar prototype:. ~~~{.cpp}; TGeoVolume::AddNodeOverlap(/*same arguments*/);; ~~~. When closing the geometry, overlapping nodes perform a check of possible; overlaps with their neighbors. These are stored and checked all the time; during navigation; therefore, navigation is slower when embedding such; nodes into geometry. Nodes have visualization attributes as the volume; has. When undefined by users, painting a node on a pad will take the; corresponding volume attributes. \anchor GP01b; ### Creating and Positioning Volumes. \anchor GP01ba; #### Making Volumes. As mentioned before, volumes are the basic objects used in building the; geometrical hierarchy. They represent objects that are not positioned,; but store all information about the placement of the other volumes they; may contain. Therefore a volume can be replicated several times in the; geometry. As it was explained, in order to create a volume, one has to; put together a shape and a medium, which are already defined. Volumes have to be named by users at creation time. Every different name; may represent a unique volume object, but may also represent more; ge",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:23282,perform,perform,23282,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['perform']
Performance," can be retrieved; using ``getParamElementType()``. This attribute is required in cases where; the intrinsic does not naturally encode a needed element type. This is also; used for inline assembly. Note that some of the methods mentioned above only exist to support both typed; and opaque pointers at the same time, and will be dropped once the migration; has completed. For example, ``isOpaqueOrPointeeTypeEquals()`` becomes; meaningless once all pointers are opaque. While direct usage of pointer element types is immediately apparent in code,; there is a more subtle issue that opaque pointers need to contend with: A lot; of code assumes that pointer equality also implies that the used load/store; type or GEP source element type is the same. Consider the following examples; with typed and opaque pointers:. .. code-block:: llvm. define i32 @test(i32* %p) {; store i32 0, i32* %p; %bc = bitcast i32* %p to i64*; %v = load i64, i64* %bc; ret i64 %v; }. define i32 @test(ptr %p) {; store i32 0, ptr %p; %v = load i64, ptr %p; ret i64 %v; }. Without opaque pointers, a check that the pointer operand of the load and; store are the same also ensures that the accessed type is the same. Using a; different type requires a bitcast, which will result in distinct pointer; operands. With opaque pointers, the bitcast is not present, and this check is no longer; sufficient. In the above example, it could result in store to load forwarding; of an incorrect type. Code making such assumptions needs to be adjusted to; check the accessed type explicitly:; ``LI->getType() == SI->getValueOperand()->getType()``. Frontends; ---------. Frontends need to be adjusted to track pointee types independently of LLVM,; insofar as they are necessary for lowering. For example, clang now tracks the; pointee type in the ``Address`` structure. Frontends using the C API through an FFI interface should be aware that a; number of C API functions are deprecated and will be removed as part of the; opaque pointer transi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OpaquePointers.rst:9097,load,load,9097,interpreter/llvm-project/llvm/docs/OpaquePointers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/OpaquePointers.rst,1,['load'],['load']
Performance," can be very impactful. #. Use fast-math flags on floating point operations if legal. If you don't; need strict IEEE floating point semantics, there are a number of additional; optimizations that can be performed. This can be highly impactful for; floating point intensive computations. Describing Aliasing Properties; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. #. Add noalias/align/dereferenceable/nonnull to function arguments and return; values as appropriate. #. Use pointer aliasing metadata, especially tbaa metadata, to communicate; otherwise-non-deducible pointer aliasing facts. #. Use inbounds on geps. This can help to disambiguate some aliasing queries. Undefined Values; ^^^^^^^^^^^^^^^^. #. Use poison values instead of undef values whenever possible. #. Tag function parameters with the noundef attribute whenever possible. Modeling Memory Effects; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Mark functions as readnone/readonly/argmemonly or noreturn/nounwind when; known. The optimizer will try to infer these flags, but may not always be; able to. Manual annotations are particularly important for external; functions that the optimizer can not analyze. #. Use the lifetime.start/lifetime.end and invariant.start/invariant.end; intrinsics where possible. Common profitable uses are for stack like data; structures (thus allowing dead store elimination) and for describing; life times of allocas (thus allowing smaller stack sizes). #. Mark invariant locations using !invariant.load and TBAA's constant flags. Pass Ordering; ^^^^^^^^^^^^^. One of the most common mistakes made by new language frontend projects is to; use the existing -O2 or -O3 pass pipelines as is. These pass pipelines make a; good starting point for an optimizing compiler for any language, but they have; been carefully tuned for C and C++, not your target language. You will almost; certainly need to use a custom pass order to achieve optimal performance. A; couple specific suggestions:. #. For languages with numerous rarely executed ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:11801,optimiz,optimizer,11801,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['optimiz'],['optimizer']
Performance," can cause the; state to change, resulting in a new node in the ExplodedGraph with an; updated program point and an updated state. A bug is found by hitting; a node that satisfies some ""bug condition"" (basically a violation of a; checking invariant). The analyzer traces out multiple paths by reasoning about branches and; then bifurcating the state: on the true branch the conditions of the; branch are assumed to be true and on the false branch the conditions; of the branch are assumed to be false. Such ""assumptions"" create; constraints on the values of the program, and those constraints are; recorded in the ProgramState object (and are manipulated by the; ConstraintManager). If assuming the conditions of a branch would; cause the constraints to be unsatisfiable, the branch is considered; infeasible and that path is not taken. This is how we get; path-sensitivity. We reduce exponential blow-up by caching nodes. If; a new node with the same state and program point as an existing node; would get generated, the path ""caches out"" and we simply reuse the; existing node. Thus the ExplodedGraph is not a DAG; it can contain; cycles as paths loop back onto each other and cache out. ProgramState and ExplodedNodes are basically immutable once created. Once; one creates a ProgramState, you need to create a new one to get a new; ProgramState. This immutability is key since the ExplodedGraph represents; the behavior of the analyzed program from the entry point. To; represent these efficiently, we use functional data structures (e.g.,; ImmutableMaps) which share data between instances. Finally, individual Checkers work by also manipulating the analysis; state. The analyzer engine talks to them via a visitor interface.; For example, the PreVisitCallExpr() method is called by ExprEngine; to tell the Checker that we are about to analyze a CallExpr, and the; checker is asked to check for any preconditions that might not be; satisfied. The checker can do nothing, or it can generate a new;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/README.txt:2554,cache,caches,2554,interpreter/llvm-project/clang/lib/StaticAnalyzer/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/lib/StaticAnalyzer/README.txt,1,['cache'],['caches']
Performance," can use ``llvm.ssub.with.overflow``; on any integer bit width or vectors of integers. ::. declare {i16, i1} @llvm.ssub.with.overflow.i16(i16 %a, i16 %b); declare {i32, i1} @llvm.ssub.with.overflow.i32(i32 %a, i32 %b); declare {i64, i1} @llvm.ssub.with.overflow.i64(i64 %a, i64 %b); declare {<4 x i32>, <4 x i1>} @llvm.ssub.with.overflow.v4i32(<4 x i32> %a, <4 x i32> %b). Overview:; """""""""""""""""". The '``llvm.ssub.with.overflow``' family of intrinsic functions perform; a signed subtraction of the two arguments, and indicate whether an; overflow occurred during the signed subtraction. Arguments:; """""""""""""""""""". The arguments (%a and %b) and the first element of the result structure; may be of integer types of any bit width, but they must have the same; bit width. The second element of the result structure must be of type; ``i1``. ``%a`` and ``%b`` are the two values that will undergo signed; subtraction. Semantics:; """""""""""""""""""". The '``llvm.ssub.with.overflow``' family of intrinsic functions perform; a signed subtraction of the two arguments. They return a structure --- the; first element of which is the subtraction, and the second element of; which is a bit specifying if the signed subtraction resulted in an; overflow. Examples:; """""""""""""""""". .. code-block:: llvm. %res = call {i32, i1} @llvm.ssub.with.overflow.i32(i32 %a, i32 %b); %sum = extractvalue {i32, i1} %res, 0; %obit = extractvalue {i32, i1} %res, 1; br i1 %obit, label %overflow, label %normal. '``llvm.usub.with.overflow.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". This is an overloaded intrinsic. You can use ``llvm.usub.with.overflow``; on any integer bit width or vectors of integers. ::. declare {i16, i1} @llvm.usub.with.overflow.i16(i16 %a, i16 %b); declare {i32, i1} @llvm.usub.with.overflow.i32(i32 %a, i32 %b); declare {i64, i1} @llvm.usub.with.overflow.i64(i64 %a, i64 %b); declare {<4 x i32>, <4 x i1>} @llvm.usub.with.overflow.v4i32(<4 x i32> %a, <4 x i32> %b). Overview:; """""""""""""""""".",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:605217,perform,perform,605217,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['perform']
Performance," can use llvm.is.constant with any argument type. ::. declare i1 @llvm.is.constant.i32(i32 %operand) nounwind memory(none); declare i1 @llvm.is.constant.f32(float %operand) nounwind memory(none); declare i1 @llvm.is.constant.TYPENAME(TYPE %operand) nounwind memory(none). Overview:; """""""""""""""""". The '``llvm.is.constant``' intrinsic will return true if the argument; is known to be a manifest compile-time constant. It is guaranteed to; fold to either true or false before generating machine code. Semantics:; """""""""""""""""""". This intrinsic generates no code. If its argument is known to be a; manifest compile-time constant value, then the intrinsic will be; converted to a constant true value. Otherwise, it will be converted to; a constant false value. In particular, note that if the argument is a constant expression; which refers to a global (the address of which _is_ a constant, but; not manifest during the compile), then the intrinsic evaluates to; false. The result also intentionally depends on the result of optimization; passes -- e.g., the result can change depending on whether a; function gets inlined or not. A function's parameters are; obviously not constant. However, a call like; ``llvm.is.constant.i32(i32 %param)`` *can* return true after the; function is inlined, if the value passed to the function parameter was; a constant. .. _int_ptrmask:. '``llvm.ptrmask``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare ptrty llvm.ptrmask(ptrty %ptr, intty %mask) speculatable memory(none). Arguments:; """""""""""""""""""". The first argument is a pointer or vector of pointers. The second argument is; an integer or vector of integers with the same bit width as the index type; size of the first argument. Overview:; """""""""""""""""""". The ``llvm.ptrmask`` intrinsic masks out bits of the pointer according to a mask.; This allows stripping data from tagged pointers without converting them to an; integer (ptrtoint/inttoptr). As a consequence, we can preserve more informat",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:953506,optimiz,optimization,953506,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimization']
Performance," can; cause code to be executed with data inputs that never occur in correct; executions, making checks against malicious inputs ineffective and allowing; attackers to use malicious data inputs to leak secret data. Here is an example,; extracted and simplified from the Project Zero paper:; ```; struct array {; unsigned long length;; unsigned char data[];; };; struct array *arr1 = ...; // small array; struct array *arr2 = ...; // array of size 0x400; unsigned long untrusted_offset_from_caller = ...;; if (untrusted_offset_from_caller < arr1->length) {; unsigned char value = arr1->data[untrusted_offset_from_caller];; unsigned long index2 = ((value&1)*0x100)+0x200;; unsigned char value2 = arr2->data[index2];; }; ```. The key of the attack is to call this with `untrusted_offset_from_caller` that; is far outside of the bounds when the branch predictor will predict that it; will be in-bounds. In that case, the body of the `if` will be executed; speculatively, and may read secret data into `value` and leak it via a; cache-timing side channel when a dependent access is made to populate `value2`. ## High Level Mitigation Approach. While several approaches are being actively pursued to mitigate specific; branches and/or loads inside especially risky software (most notably various OS; kernels), these approaches require manual and/or static analysis aided auditing; of code and explicit source changes to apply the mitigation. They are unlikely; to scale well to large applications. We are proposing a comprehensive; mitigation approach that would apply automatically across an entire program; rather than through manual changes to the code. While this is likely to have a; high performance cost, some applications may be in a good position to take this; performance / security tradeoff. The specific technique we propose is to cause loads to be checked using; branchless code to ensure that they are executing along a valid control flow; path. Consider the following C-pseudo-code representi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:2245,cache,cache-timing,2245,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['cache'],['cache-timing']
Performance," canvas as PNG; 4. TGraph drawing optimization - limit number of drawn points; 5. Implement painter for TPolyMarker3D; 6. Improve drawing and update of TMultiGraph; 7. Reorganize 3D drawing of TH2/TH3 histograms, allow to mix 2D and 3D display together; 8. Support overlay of 3D graphic over SVG canvas (used for IE); 9. Fix problems and improve flex(ible) layout. ## Changes in 4.0; 1. New TGeo classes support:; - browsing through volumes hierarchy; - changing visibility flags; - drawing of selected volumes; 2. New 'flex' layout:; - create frames like in Multi Document Interface; - one could move/resize/minimize/maximize such frames; 3. Significant (factor 4) I/O performance improvement:; - use ArrayBuffer class in HTTP requests instead of String; - use native arrays (like Int32Array) for array data members; - highly optimize streamer infos handling; 4. TH2 drawing optimization:; - if there are too many non-empty bins, combine them together; - when zoom-in, all original bins will be displayed separately; - let draw big TH2 histogram faster than in 1 sec; - optimization can be disabled by providing '&optimize=0' in URL; 5. TF1 drawing optimization:; - function 'compiled' only once; 6. Reorganize scripts structure:; - move all math functions to JSRootMath.js; - TH2, TF1, THStack and TMultiGraph painters moved into JSRootPainter.more.js script; - reduce size of scripts required for default functionality; 7. Update all basic libraries:; - d3.js - v3.5.9,; - jquery.js - v2.1.4,; - jquery-ui.js - v1.11.4,; - three.js - r73; 8. Implement ROOT6-like color palettes:; - all palettes in range 51...112 are implemented; - by default palette 57 is used; - one could change default palette with '&palette=111' in URL; - or palette can be specified in draw option like '&opt=colz,pal77'. ## Changes in 3.9; 1. Support non-equidistant bins for TH1/TH2 objects.; 2. Display entries count from histo.fEntries member, only when not set use computed value; 3. Support italic and bold text when u",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:59946,optimiz,optimization,59946,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,3,['optimiz'],"['optimization', 'optimize']"
Performance," capability to 2.1</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>sm_30</td>`; :raw-html:`<td align=""left"">Set shader model/compute capability to 3.0</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>sm_35</td>`; :raw-html:`<td align=""left"">Set shader model/compute capability to 3.5</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>ptx30</td>`; :raw-html:`<td align=""left"">Target PTX 3.0</td>`; :raw-html:`</tr>`; :raw-html:`<tr>`; :raw-html:`<td>ptx31</td>`; :raw-html:`<td align=""left"">Target PTX 3.1</td>`; :raw-html:`</tr>`; :raw-html:`</table>`. The extended Berkeley Packet Filter (eBPF) backend; --------------------------------------------------. Extended BPF (or eBPF) is similar to the original (""classic"") BPF (cBPF) used; to filter network packets. The; `bpf() system call <http://man7.org/linux/man-pages/man2/bpf.2.html>`_; performs a range of operations related to eBPF. For both cBPF and eBPF; programs, the Linux kernel statically analyzes the programs before loading; them, in order to ensure that they cannot harm the running system. eBPF is; a 64-bit RISC instruction set designed for one to one mapping to 64-bit CPUs.; Opcodes are 8-bit encoded, and 87 instructions are defined. There are 10; registers, grouped by function as outlined below. ::. R0 return value from in-kernel functions; exit value for eBPF program; R1 - R5 function call arguments to in-kernel functions; R6 - R9 callee-saved registers preserved by in-kernel functions; R10 stack frame pointer (read only). Instruction encoding (arithmetic and jump); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; eBPF is reusing most of the opcode encoding from classic to simplify conversion; of classic BPF to eBPF. For arithmetic and jump instructions the 8-bit 'code'; field is divided into three parts:. ::. +----------------+--------+--------------------+; | 4 bits | 1 bit | 3 bits |; | operation code | source | instruction class |; +----------------+--------+--------------------+; (MSB)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:102891,load,loading,102891,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['load'],['loading']
Performance," case when going the other way since the; track has first to exit the extruding node before checking the mother.; In other words, an extrusion behavior is dependent on the track; parameters, which is a highly undesirable effect. B) We will call ***`overlaps`*** only the regions in space contained by; more than one node inside the same container. The owner of such regions; cannot be determined based on hierarchical considerations; therefore; they will be considered as belonging to the node from which the current; track is coming from. When coming from their container, the ownership is totally; unpredictable. Again, the ownership of overlapping regions highly; depends on the current track parameters. We must say that even the overlaps of type A) and B) are allowed in case; the corresponding nodes are created using; **`TGeoVolume`**`::AddNodeOverlap()` method. Navigation is performed in such; cases by giving priority to the non-overlapping nodes. The modeller has; to perform an additional search through the overlapping candidates.; These are detected automatically during the geometry closing procedure; in order to optimize the algorithm, but we will stress that extensive; usage of this feature leads to a drastic deterioration of performance.; In the following we will focus on the non-declared overlaps of type A); and B) since this is the main source of errors during tracking. These; are generally non-intended overlaps due to coding mistakes or bad; geometry design. The checking package is loaded together with the; painter classes and contains an automated overlap checker.**. ![Overlap checking](pictures/030001DF.png). This can be activated both at volume level (checking for illegal; overlaps only one level inside a given volume) and from the geometry; manager level (checking full geometry):. ``` {.cpp}; myVolume->CheckOverlaps(precision, option);; gGeoManager->CheckOverlaps(precision);; myNode->CheckOverlaps(precision);; ```. Here precision represents the desired maxim",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:131745,perform,perform,131745,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['perform'],['perform']
Performance," cause control flow to transfer to; a specified function, with its incoming arguments bound to the specified; values. Upon a '``ret``' instruction in the called function, control; flow continues with the instruction after the function call, and the; return value of the function is bound to the result argument. Example:; """""""""""""""". .. code-block:: llvm. %retval = call i32 @test(i32 %argc); call i32 (ptr, ...) @printf(ptr %msg, i32 12, i8 42) ; yields i32; %X = tail call i32 @foo() ; yields i32; %Y = tail call fastcc i32 @foo() ; yields i32; call void %foo(i8 signext 97). %struct.A = type { i32, i8 }; %r = call %struct.A @foo() ; yields { i32, i8 }; %gr = extractvalue %struct.A %r, 0 ; yields i32; %gr1 = extractvalue %struct.A %r, 1 ; yields i8; %Z = call void @foo() noreturn ; indicates that %foo never returns normally; %ZZ = call zeroext i32 @bar() ; Return value is %zero extended. llvm treats calls to some functions with names and arguments that match; the standard C99 library as being the C99 library functions, and may; perform optimizations or generate code for them under that assumption.; This is something we'd like to change in the future to provide better; support for freestanding environments and non-C-based languages. .. _i_va_arg:. '``va_arg``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. <resultval> = va_arg <va_list*> <arglist>, <argty>. Overview:; """""""""""""""""". The '``va_arg``' instruction is used to access arguments passed through; the ""variable argument"" area of a function call. It is used to implement; the ``va_arg`` macro in C. Arguments:; """""""""""""""""""". This instruction takes a ``va_list*`` value and the type of the; argument. It returns a value of the specified argument type and; increments the ``va_list`` to point to the next argument. The actual; type of ``va_list`` is target specific. Semantics:; """""""""""""""""""". The '``va_arg``' instruction loads an argument of the specified type; from the specified ``va_list`` and causes the ``va_list`` to",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:478818,perform,perform,478818,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,"['optimiz', 'perform']","['optimizations', 'perform']"
Performance," chapter (see; ""Linear Algebra in ROOT""). `SMatrix` is a C++ package, for high; performance vector and matrix computations. It has been introduced in; ROOT v5.08. It is optimized for describing small matrices and vectors; and It can be used only in problems when the size of the matrices is; known at compile time, like in the tracking reconstruction of physics; experiments. It is based on a C++ technique, called expression; templates, to achieve an high level optimization. The C++ templates can; be used to implement vector and matrix expressions such that these; expressions can be transformed at compile time to code which is; equivalent to hand optimized code in a low-level language like FORTRAN; or C (see for example T. Veldhuizen, Expression Templates, C++ Report,; 1995). The `SMatrix` has been developed initially by T. Glebe in; Max-Planck-Institut, Heidelberg, as part of the `HeraB` analysis; framework. A subset of the original package has been now incorporated in; the ROOT distribution, with the aim to provide a stand-alone and high; performance matrix package. The API of the current package differs from; the original one, in order to be compliant to the ROOT coding; conventions. `SMatrix` contains the generic **`ROOT::Math::SMatrix`** and; **`ROOT::Math::SVector`** classes for describing matrices and vectors of; arbitrary dimensions and of arbitrary type. The classes are templated on; the scalar type and on the size, like number of rows and columns for a; matrix . Therefore, the matrix/vector dimension has to be known at; compile time. An advantage of using the dimension as template parameters; is that the correctness of dimension in the matrix/vector operations can; be checked at compile time. `SMatrix` supports, since ROOT v5.10, symmetric matrices using a storage; class (**`ROOT::Math::MatRepSym`**) which contains only the `N*(N+1)/2`; independent element of a `NxN` symmetric matrix. It is not in the; mandate of this package to provide complete linear algebr",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md:100039,perform,performance,100039,documentation/users-guide/MathLibraries.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/MathLibraries.md,1,['perform'],['performance']
Performance, clang-tools-extra/clang-tidy/objc/SuperSelfCheck.cpp; clang-tools-extra/clang-tidy/objc/SuperSelfCheck.h; clang-tools-extra/clang-tidy/openmp/ExceptionEscapeCheck.cpp; clang-tools-extra/clang-tidy/openmp/ExceptionEscapeCheck.h; clang-tools-extra/clang-tidy/openmp/OpenMPTidyModule.cpp; clang-tools-extra/clang-tidy/openmp/UseDefaultNoneCheck.cpp; clang-tools-extra/clang-tidy/openmp/UseDefaultNoneCheck.h; clang-tools-extra/clang-tidy/performance/FasterStringFindCheck.cpp; clang-tools-extra/clang-tidy/performance/ForRangeCopyCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientAlgorithmCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientAlgorithmCheck.h; clang-tools-extra/clang-tidy/performance/InefficientStringConcatenationCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientStringConcatenationCheck.h; clang-tools-extra/clang-tidy/performance/MoveConstArgCheck.cpp; clang-tools-extra/clang-tidy/performance/MoveConstArgCheck.h; clang-tools-extra/clang-tidy/performance/MoveConstructorInitCheck.cpp; clang-tools-extra/clang-tidy/performance/MoveConstructorInitCheck.h; clang-tools-extra/clang-tidy/performance/NoAutomaticMoveCheck.cpp; clang-tools-extra/clang-tidy/performance/NoAutomaticMoveCheck.h; clang-tools-extra/clang-tidy/performance/NoexceptMoveConstructorCheck.cpp; clang-tools-extra/clang-tidy/performance/NoexceptMoveConstructorCheck.h; clang-tools-extra/clang-tidy/performance/NoIntToPtrCheck.cpp; clang-tools-extra/clang-tidy/performance/NoIntToPtrCheck.h; clang-tools-extra/clang-tidy/performance/PerformanceTidyModule.cpp; clang-tools-extra/clang-tidy/performance/TriviallyDestructibleCheck.cpp; clang-tools-extra/clang-tidy/performance/TriviallyDestructibleCheck.h; clang-tools-extra/clang-tidy/performance/TypePromotionInMathFnCheck.cpp; clang-tools-extra/clang-tidy/performance/TypePromotionInMathFnCheck.h; clang-tools-extra/clang-tidy/performance/UnnecessaryCopyInitialization.cpp; clang-tools-extra/clang-tidy/performance/UnnecessaryValueP,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:65267,perform,performance,65267,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['perform'],['performance']
Performance, clang-tools-extra/clang-tidy/performance/InefficientAlgorithmCheck.h; clang-tools-extra/clang-tidy/performance/InefficientStringConcatenationCheck.cpp; clang-tools-extra/clang-tidy/performance/InefficientStringConcatenationCheck.h; clang-tools-extra/clang-tidy/performance/MoveConstArgCheck.cpp; clang-tools-extra/clang-tidy/performance/MoveConstArgCheck.h; clang-tools-extra/clang-tidy/performance/MoveConstructorInitCheck.cpp; clang-tools-extra/clang-tidy/performance/MoveConstructorInitCheck.h; clang-tools-extra/clang-tidy/performance/NoAutomaticMoveCheck.cpp; clang-tools-extra/clang-tidy/performance/NoAutomaticMoveCheck.h; clang-tools-extra/clang-tidy/performance/NoexceptMoveConstructorCheck.cpp; clang-tools-extra/clang-tidy/performance/NoexceptMoveConstructorCheck.h; clang-tools-extra/clang-tidy/performance/NoIntToPtrCheck.cpp; clang-tools-extra/clang-tidy/performance/NoIntToPtrCheck.h; clang-tools-extra/clang-tidy/performance/PerformanceTidyModule.cpp; clang-tools-extra/clang-tidy/performance/TriviallyDestructibleCheck.cpp; clang-tools-extra/clang-tidy/performance/TriviallyDestructibleCheck.h; clang-tools-extra/clang-tidy/performance/TypePromotionInMathFnCheck.cpp; clang-tools-extra/clang-tidy/performance/TypePromotionInMathFnCheck.h; clang-tools-extra/clang-tidy/performance/UnnecessaryCopyInitialization.cpp; clang-tools-extra/clang-tidy/performance/UnnecessaryValueParamCheck.cpp; clang-tools-extra/clang-tidy/performance/UnnecessaryValueParamCheck.h; clang-tools-extra/clang-tidy/plugin/ClangTidyPlugin.cpp; clang-tools-extra/clang-tidy/portability/PortabilityTidyModule.cpp; clang-tools-extra/clang-tidy/portability/RestrictSystemIncludesCheck.cpp; clang-tools-extra/clang-tidy/portability/SIMDIntrinsicsCheck.cpp; clang-tools-extra/clang-tidy/readability/AvoidConstParamsInDecls.h; clang-tools-extra/clang-tidy/readability/BracesAroundStatementsCheck.cpp; clang-tools-extra/clang-tidy/readability/BracesAroundStatementsCheck.h; clang-tools-extra/clang-tidy/readability/Cons,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:65877,perform,performance,65877,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['perform'],['performance']
Performance," clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to; be enabled for all methods (for those parameters where; optimization is applicable).; . BDT node splitting: While Decision Trees; typically have only univariate splits, in TMVA one can now; also opt for multivariate splits that use a ""Fisher; Discriminant"" (option: UseFisherCuts), built from all; observables that show correlations larger than some threshold; (MinLinCorrForFisher). The training will then test at each; split a cut on this fisher discriminant in addition to all; univariate cuts on the variables (or only on those variables; that have not been used in the Fisher discriminant, option; UseExcusiveVars). No obvious improvement betwen very simple; decision trees after boosting has been observed so far, but; only a limited number of studies has been performed concerning; potiential benenfit of these simple multivariate splits.; . Bug fixes. A problem in the BDTG has been fixed, leading to a much; improved regression performance.; A problem in the TMVA::Reader has been fixed.; With the new ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:2280,optimiz,optimization,2280,tmva/doc/v528/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html,2,['optimiz'],['optimization']
Performance," code for this function at -O2 or -Os:. void foo(signed char* p) {; if (*p == 3); bar();; else if (*p == 4); baz();; else if (*p == 5); quux();; }. llvm decides it's a good idea to turn the repeated if...else into a; binary tree, as if it were a switch; the resulting code requires -1; compare-and-branches when *p<=2 or *p==5, the same number if *p==4; or *p>6, and +1 if *p==3. So it should be a speed win; (on balance). However, the revised code is larger, with 4 conditional; branches instead of 3. More seriously, there is a byte->word extend before; each comparison, where there should be only one, and the condition codes; are not remembered when the same two values are compared twice. //===---------------------------------------------------------------------===//. More LSR enhancements possible:. 1. Teach LSR about pre- and post- indexed ops to allow iv increment be merged; in a load / store.; 2. Allow iv reuse even when a type conversion is required. For example, i8; and i32 load / store addressing modes are identical. //===---------------------------------------------------------------------===//. This:. int foo(int a, int b, int c, int d) {; long long acc = (long long)a * (long long)b;; acc += (long long)c * (long long)d;; return (int)(acc >> 32);; }. Should compile to use SMLAL (Signed Multiply Accumulate Long) which multiplies; two signed 32-bit values to produce a 64-bit value, and accumulates this with; a 64-bit value. We currently get this with both v4 and v6:. _foo:; smull r1, r0, r1, r0; smull r3, r2, r3, r2; adds r3, r3, r1; adc r0, r2, r0; bx lr. //===---------------------------------------------------------------------===//. This:; #include <algorithm>; std::pair<unsigned, bool> full_add(unsigned a, unsigned b); { return std::make_pair(a + b, a + b < a); }; bool no_overflow(unsigned a, unsigned b); { return !full_add(a, b).second; }. Should compile to:. _Z8full_addjj:; 	adds	r2, r1, r2; 	movcc	r1, #0; 	movcs	r1, #1; 	str	r2, [r0, #0]; 	strb	r1, [r0, #4]",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt:12623,load,load,12623,interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/ARM/README.txt,1,['load'],['load']
Performance," code from the original to the instrumentation version; by tracing the LLVM-to-Machine code basic block map and then copying; each machine code basic block we think is in the hot region into the; trace cache. Then we instrument that code. The process is similar for; generating the final optimized trace; we copy the same basic blocks; because we might need to put in fixup code for exit BBs. LLVM basic blocks are not typically used in the Reoptimizer except; for the mapping information. We are restricted to using single instructions to branch between the; original code, trace, and instrumented code. So we have to keep the; code copies in memory near the original code (they can't be far enough; away that a single pc-relative branch would not work.) Malloc() or; data region space is too far away. this impacts the design of the ; trace cache. We use a dummy function that is full of a bunch of for loops which we; overwrite with trace-cache code. The trace manager keeps track of; whether or not we have enough space in the trace cache, etc. The trace insertion routine takes an original start address, a vector; of machine instructions representing the trace, index of branches and; their corresponding absolute targets, and index of calls and their; corresponding absolute targets. The trace insertion routine is responsible for inserting branches from; the beginning of the original code to the beginning of the optimized; trace. This is because at some point the trace cache may run out of; space and it may have to evict a trace, at which point the branch to; the trace would also have to be removed. It uses a round-robin; replacement policy; we have found that this is almost as good as LRU; and better than random (especially because of problems fitting the new; trace in.). We cannot deal with discontiguous trace cache areas. The trace cache; is supposed to be cache-line-aligned, but it is not page-aligned. We generate instrumentation traces and optimized traces into separate; trac",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2003-06-25-Reoptimizer1.txt:4909,cache,cache,4909,interpreter/llvm-project/llvm/docs/HistoricalNotes/2003-06-25-Reoptimizer1.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2003-06-25-Reoptimizer1.txt,1,['cache'],['cache']
Performance," code with ""clang; -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. unsigned a(unsigned long long x) {return 40 * (x >> 1);}; Should combine to ""20 * (((unsigned)x) & -2)"". Currently not; optimized with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int g(int x) { return (x - 10) < 0; }; Should combine to ""x <= 9"" (the sub has nsw). Currently not; optimized with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int g(int x) { return (x + 10) < 0; }; Should combine to ""x < -10"" (the add has nsw). Currently not; optimized with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. int f(int i, int j) { return i < j + 1; }; int g(int i, int j) { return j > i - 1; }; Should combine to ""i <= j"" (the add/sub has nsw). Currently not; optimized with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. unsigned f(unsigned x) { return ((x & 7) + 1) & 15; }; The & 15 part should be optimized away, it doesn't change the result. Currently; not optimized with ""clang -emit-llvm-bc | opt -O3"". //===---------------------------------------------------------------------===//. This was noticed in the entryblock for grokdeclarator in 403.gcc:. %tmp = icmp eq i32 %decl_context, 4 ; %decl_context_addr.0 = select i1 %tmp, i32 3, i32 %decl_context ; %tmp1 = icmp eq i32 %decl_context_addr.0, 1 ; %decl_context_addr.1 = select i1 %tmp1, i32 0, i32 %decl_context_addr.0. tmp1 should be simplified to something like:; (!tmp || decl_context == 1). This allows recursive simplifications, tmp1 is used all over the place in; the function, e.g. by:. %tmp23 = icmp eq i32 %decl_context_addr.1, 0 ; <i1> [#uses=1]; %tmp24 = xor i1 %tmp1, true ; <i1> [#uses=1]; %or.cond8 = and i1 %tmp23, %tmp24 ; <i1> [#us",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt:27266,optimiz,optimized,27266,interpreter/llvm-project/llvm/lib/Target/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/README.txt,1,['optimiz'],['optimized']
Performance," code-block:: c++. template<typename T> T twice(T t) {; return 2 * t;; }. #pragma clang optimize off; template<typename T> T thrice(T t) {; return 3 * t;; }. int container(int a, int b) {; return twice(a) + thrice(b);; }; #pragma clang optimize on. In this example, the definition of the template function ``twice`` is outside; the pragma region, whereas the definition of ``thrice`` is inside the region.; The ``container`` function is also in the region and will not be optimized, but; it causes the instantiation of ``twice`` and ``thrice`` with an ``int`` type; of; these two instantiations, ``twice`` will be optimized (because its definition; was outside the region) and ``thrice`` will not be optimized. Clang also implements MSVC's range-based pragma,; ``#pragma optimize(""[optimization-list]"", on | off)``. At the moment, Clang only; supports an empty optimization list, whereas MSVC supports the arguments, ``s``,; ``g``, ``t``, and ``y``. Currently, the implementation of ``pragma optimize`` behaves; the same as ``#pragma clang optimize``. All functions; between ``off`` and ``on`` will be decorated with the ``optnone`` attribute. .. code-block:: c++. #pragma optimize("""", off); // This function will be decorated with optnone.; void f1() {}. #pragma optimize("""", on); // This function will be optimized with whatever was specified on; // the commandline.; void f2() {}. // This will warn with Clang's current implementation.; #pragma optimize(""g"", on); void f3() {}. For MSVC, an empty optimization list and ``off`` parameter will turn off; all optimizations, ``s``, ``g``, ``t``, and ``y``. An empty optimization and; ``on`` parameter will reset the optimizations to the ones specified on the; commandline. .. list-table:: Parameters (unsupported by Clang). * - Parameter; - Type of optimization; * - g; - Deprecated; * - s or t; - Short or fast sequences of machine code; * - y; - Enable frame pointers. Extensions for loop hint optimizations; ======================================. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:161286,optimiz,optimize,161286,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,2,['optimiz'],['optimize']
Performance," code-block:: llvm. entry:; ..; br i1 true, label %foo, label %bar; foo:; ..; bar:; ; Dead code; .. Therefore, it is recommended that ``NVVMReflect`` is executed early in the; optimization pipeline before dead-code elimination. The NVPTX TargetMachine knows how to schedule ``NVVMReflect`` at the beginning; of your pass manager; just use the following code when setting up your pass; manager and the PassBuilder will use ``registerPassBuilderCallbacks`` to let; NVPTXTargetMachine::registerPassBuilderCallbacks add the pass to the; pass manager:. .. code-block:: c++. std::unique_ptr<TargetMachine> TM = ...;; PassBuilder PB(TM);; ModulePassManager MPM;; PB.parsePassPipeline(MPM, ...);. Reflection Parameters; ---------------------. The libdevice library currently uses the following reflection parameters to; control code generation:. ==================== ======================================================; Flag Description; ==================== ======================================================; ``__CUDA_FTZ=[0,1]`` Use optimized code paths that flush subnormals to zero; ==================== ======================================================. The value of this flag is determined by the ""nvvm-reflect-ftz"" module flag.; The following sets the ftz flag to 1. .. code-block:: llvm. !llvm.module.flag = !{!0}; !0 = !{i32 4, !""nvvm-reflect-ftz"", i32 1}. (``i32 4`` indicates that the value set here overrides the value in another; module we link with. See the `LangRef <LangRef.html#module-flags-metadata>`; for details.). Executing PTX; =============. The most common way to execute PTX assembly on a GPU device is to use the CUDA; Driver API. This API is a low-level interface to the GPU driver and allows for; JIT compilation of PTX code to native GPU machine code. Initializing the Driver API:. .. code-block:: c++. CUdevice device;; CUcontext context;. // Initialize the driver API; cuInit(0);; // Get a handle to the first compute device; cuDeviceGet(&device, 0);; // Create a ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NVPTXUsage.rst:10697,optimiz,optimized,10697,interpreter/llvm-project/llvm/docs/NVPTXUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NVPTXUsage.rst,1,['optimiz'],['optimized']
Performance," code. .. code-block:: text. a: store undef -> %X; b: store %X -> undef; Safe:; a: <deleted> (if the stored value in %X is provably not poison); b: unreachable. A store *of* an undefined value can be assumed to not have any effect;; we can assume that the value is overwritten with bits that happen to; match what was already there. This argument is only valid if the stored value; is provably not ``poison``. However, a store *to* an undefined; location could clobber arbitrary memory, therefore, it has undefined; behavior. Branching on an undefined value is undefined behavior.; This explains optimizations that depend on branch conditions to construct; predicates, such as Correlated Value Propagation and Global Value Numbering.; In case of switch instruction, the branch condition should be frozen, otherwise; it is undefined behavior. .. code-block:: llvm. Unsafe:; br undef, BB1, BB2 ; UB. %X = and i32 undef, 255; switch %X, label %ret [ .. ] ; UB. store undef, ptr %ptr; %X = load ptr %ptr ; %X is undef; switch i8 %X, label %ret [ .. ] ; UB. Safe:; %X = or i8 undef, 255 ; always 255; switch i8 %X, label %ret [ .. ] ; Well-defined. %X = freeze i1 undef; br %X, BB1, BB2 ; Well-defined (non-deterministic jump). .. _poisonvalues:. Poison Values; -------------. A poison value is a result of an erroneous operation.; In order to facilitate speculative execution, many instructions do not; invoke immediate undefined behavior when provided with illegal operands,; and return a poison value instead.; The string '``poison``' can be used anywhere a constant is expected, and; operations such as :ref:`add <i_add>` with the ``nsw`` flag can produce; a poison value. Most instructions return '``poison``' when one of their arguments is; '``poison``'. A notable exception is the :ref:`select instruction <i_select>`.; Propagation of poison can be stopped with the; :ref:`freeze instruction <i_freeze>`. It is correct to replace a poison value with an; :ref:`undef value <undefvalues>` or any valu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:196452,load,load,196452,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," coherence and instead use it to; indicate if the instruction returns the original value being updated. They; do use sc1 to indicate system or agent scope coherence. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache. * The gfx942 can be configured as a number of smaller agents with each having; a single L2 shared by all CUs on the same agent, or as fewer (possibly one); larger agents with groups of CUs on each agent each sharing separate L2; caches.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel for its associated L2.; Therefore, the vector and scalar memory operations performed by wavefronts; executing with different L1 caches and the same L2 cache can be reordered; relative to each other.; * A ``s_waitcnt vmcnt(0)`` is required to ensure synchronization between; vector memory operations of different CUs. It ensures a previous vector; memory operation has completed before executing a subsequent vector memory; or LDS operation and so can be used to meet the requirements of acquire and; release.; * An L2 cache can be kept coherent with other L2 caches by using the MTYPE RW; (read-write) for memory local to the L2, and MTYPE NC (non-coherent) with; the PTE C-bit set for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by the PTE C-bit.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter.; * To ensure co",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:287752,perform,performed,287752,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,3,"['cache', 'perform']","['cache', 'caches', 'performed']"
Performance," command option; ``-all-stats`` or ``-dispatch-stats``. The next table, *Schedulers*, presents a histogram displaying a count,; representing the number of micro opcodes issued on some number of cycles. In; this case, of the 610 simulated cycles, single opcodes were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU instructions.; * JFPU01 - A scheduler floating point operations.; * JLSAGU - A scheduler for address generation. The dot-product is a kernel of three floating point instructions (a vector; multiply followed by two horizontal adds). That explains why only the floating; point scheduler appears to be used. A full scheduler queue is either caused by data dependency chains or by a; sub-optimal usage of hardware resources. Sometimes, resource pressure can be; mitigated by rewriting the kernel using different instructions that consume; different scheduler resources. Schedulers with a small queue are less resilient; to bottlenecks caused by the presence of long data dependencies. The scheduler; statistics are displayed by using the command option ``-all-stats`` or; ``-scheduler-stats``. The next table, *Retire Control Unit*, presents a histogram displaying a count,; representing the number of instructions retired on some number of cycles. In; this case, of the 610 simulated cycles, two instructions were retired during the; same cycle 399 times (65.4%) and there were 109 cycles where no instructions; were retired. The retire statistics are displayed by using the command option; ``-all-stats`` or ``-retire-stats``. The last table presented is *Register File statistics*. Each physical register; file (PRF) used by the pipeline is presented in this tabl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:31910,queue,queue,31910,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['queue'],['queue']
Performance," commands at the shell prompt and in the; interactive ROOT shell, respectively:. ``` {.cpp}; > root conductivity_experiment.root; Attaching file conductivity_experiment.root as _file0...; root [0] cond_data->Draw(""Current:Potential""); ```. You just produced a correlation plot with one single line of code!. Try to extend the syntax typing for example. ``` {.cpp}; root [1] cond_data->Draw(""Current:Potential"",""Temperature<270""); ```. What do you obtain ?. Now try. ``` {.cpp}; root [2] cond_data->Draw(""Current/Potential:Temperature""); ```. It should have become clear from these examples how to navigate in such; a multi-dimensional space of variables and unveil relations between; variables using n-tuples. ### Reading N-tuples. For completeness, you find here a small macro to read the data back from; a ROOT n-tuple. ``` {.cpp}; @ROOT_INCLUDE_FILE macros/read_ntuple_from_file.C; ```. The macro shows the easiest way of accessing the content of a n-tuple:; after loading the n-tuple, its branches are assigned to variables and; `GetEntry(long)` automatically fills them with the content for a; specific row. By doing so, the logic for reading the n-tuple and the; code to process it can be split and the source code remains clear. ### Storing Arbitrary N-tuples ###. It is also possible to write n-tuples of arbitrary type by using ROOT's; `TBranch` class. This is especially important as `TNtuple::Fill()`; accepts only floats. The following macro creates the same n-tuple as; before but the branches are booked directly. The `Fill()` function then; fills the current values of the connected variables to the tree. ``` {.cpp}; @ROOT_INCLUDE_FILE macros/write_ntuple_to_file_advanced.C; ```. The `Branch()` function requires a pointer to a variable and a; definition of the variable type. The following table lists some of the possible; values.; Please note that ROOT is not checking the input and mistakes are likely; to result in serious problems. This holds especially if values are read; as a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md:4229,load,loading,4229,documentation/primer/filio.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/primer/filio.md,1,['load'],['loading']
Performance," compiler when the a definition of; a symbol is needed. ORC is actually fully language agnostic: LLVM IR is not; treated specially, and is supported via the same wrapper mechanism (the; ``MaterializationUnit`` class) that is used for custom compilers. **Concurrent JIT'd code** and **Concurrent Compilation**; JIT'd code may be executed in multiple threads, may spawn new threads, and may; re-enter the ORC (e.g. to request lazy compilation) concurrently from multiple; threads. Compilers launched my ORC can run concurrently (provided the client; sets up an appropriate dispatcher). Built-in dependency tracking ensures that; ORC does not release pointers to JIT'd code or data until all dependencies; have also been JIT'd and they are safe to call or use. **Removable Code**; Resources for JIT'd program representations. **Orthogonality** and **Composability**; Each of the features above can be used independently. It is possible to put; ORC components together to make a non-lazy, in-process, single threaded JIT; or a lazy, out-of-process, concurrent JIT, or anything in between. LLJIT and LLLazyJIT; ===================. ORC provides two basic JIT classes off-the-shelf. These are useful both as; examples of how to assemble ORC components to make a JIT, and as replacements; for earlier LLVM JIT APIs (e.g. MCJIT). The LLJIT class uses an IRCompileLayer and RTDyldObjectLinkingLayer to support; compilation of LLVM IR and linking of relocatable object files. All operations; are performed eagerly on symbol lookup (i.e. a symbol's definition is compiled; as soon as you attempt to look up its address). LLJIT is a suitable replacement; for MCJIT in most cases (note: some more advanced features, e.g.; JITEventListeners are not supported yet). The LLLazyJIT extends LLJIT and adds a CompileOnDemandLayer to enable lazy; compilation of LLVM IR. When an LLVM IR module is added via the addLazyIRModule; method, function bodies in that module will not be compiled until they are first; called. LLL",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst:3516,concurren,concurrent,3516,interpreter/llvm-project/llvm/docs/ORCv2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst,1,['concurren'],['concurrent']
Performance," completed before; performing the; following; fence-paired-atomic. fence release - system *none* 1. buffer_wbl2. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acq_rel - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:265662,load,load,265662,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," computed dividing the total number of simulated instructions by the total; number of cycles. Field *Block RThroughput* is the reciprocal of the block throughput. Block; throughput is a theoretical quantity computed as the maximum number of blocks; (i.e. iterations) that can be executed per simulated clock cycle in the absence; of loop carried dependencies. Block throughput is superiorly limited by the; dispatch rate, and the availability of hardware resources. In the absence of loop-carried data dependencies, the observed IPC tends to a; theoretical maximum which can be computed by dividing the number of instructions; of a single iteration by the `Block RThroughput`. Field 'uOps Per Cycle' is computed dividing the total number of simulated micro; opcodes by the total number of cycles. A delta between Dispatch Width and this; field is an indicator of a performance issue. In the absence of loop-carried; data dependencies, the observed 'uOps Per Cycle' should tend to a theoretical; maximum throughput which can be computed by dividing the number of uOps of a; single iteration by the `Block RThroughput`. Field *uOps Per Cycle* is bounded from above by the dispatch width. That is; because the dispatch width limits the maximum size of a dispatch group. Both IPC; and 'uOps Per Cycle' are limited by the amount of hardware parallelism. The; availability of hardware resources affects the resource pressure distribution,; and it limits the number of instructions that can be executed in parallel every; cycle. A delta between Dispatch Width and the theoretical maximum uOps per; Cycle (computed by dividing the number of uOps of a single iteration by the; `Block RThroughput`) is an indicator of a performance bottleneck caused by the; lack of hardware resources.; In general, the lower the Block RThroughput, the better. In this example, ``uOps per iteration/Block RThroughput`` is 1.50. Since there; are no loop-carried dependencies, the observed `uOps Per Cycle` is expected to; approa",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:17186,throughput,throughput,17186,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,1,['throughput'],['throughput']
Performance," consecutive; floating-point numbers ``a`` and ``b``, without being equal to one; of them, then ``ulp(x) = |b - a|``, otherwise ``ulp(x)`` is the; distance between the two non-equal finite floating-point numbers; nearest ``x``. Moreover, ``ulp(NaN)`` is ``NaN``. The metadata node shall consist of a single positive float type number; representing the maximum relative error, for example:. .. code-block:: llvm. !0 = !{ float 2.5 } ; maximum acceptable inaccuracy is 2.5 ULPs. .. _range-metadata:. '``range``' Metadata; ^^^^^^^^^^^^^^^^^^^^. ``range`` metadata may be attached only to ``load``, ``call`` and ``invoke`` of; integer or vector of integer types. It expresses the possible ranges the loaded; value or the value returned by the called function at this call site is in. If; the loaded or returned value is not in the specified range, a poison value is; returned instead. The ranges are represented with a flattened list of integers.; The loaded value or the value returned is known to be in the union of the ranges; defined by each consecutive pair. Each pair has the following properties:. - The type must match the scalar type of the instruction.; - The pair ``a,b`` represents the range ``[a,b)``.; - Both ``a`` and ``b`` are constants.; - The range is allowed to wrap.; - The range should not represent the full or empty set. That is,; ``a!=b``. In addition, the pairs must be in signed order of the lower bound and; they must be non-contiguous. For vector-typed instructions, the range is applied element-wise. Examples:. .. code-block:: llvm. %a = load i8, ptr %x, align 1, !range !0 ; Can only be 0 or 1; %b = load i8, ptr %y, align 1, !range !1 ; Can only be 255 (-1), 0 or 1; %c = call i8 @foo(), !range !2 ; Can only be 0, 1, 3, 4 or 5; %d = invoke i8 @bar() to label %cont; unwind label %lpad, !range !3 ; Can only be -2, -1, 3, 4 or 5; %e = load <2 x i8>, ptr %x, !range 0 ; Can only be <0 or 1, 0 or 1>; ...; !0 = !{ i8 0, i8 2 }; !1 = !{ i8 255, i8 2 }; !2 = !{ i8 0, i8 2, i8 ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:285184,load,loaded,285184,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['loaded']
Performance," constant folding for nodes that take the same number; of arguments as your new node. #. ``lib/CodeGen/SelectionDAG/LegalizeDAG.cpp``:. Add code to `legalize, promote, and expand; <CodeGenerator.html#selectiondag_legalize>`_ the node as necessary. At a; minimum, you will need to add a case statement for your node in; ``LegalizeOp`` which calls LegalizeOp on the node's operands, and returns a; new node if any of the operands changed as a result of being legalized. It; is likely that not all targets supported by the SelectionDAG framework will; natively support the new node. In this case, you must also add code in your; node's case statement in ``LegalizeOp`` to Expand your node into simpler,; legal operations. The case for ``ISD::UREM`` for expanding a remainder into; a divide, multiply, and a subtract is a good example. #. ``lib/CodeGen/SelectionDAG/LegalizeDAG.cpp``:. If targets may support the new node being added only at certain sizes, you; will also need to add code to your node's case statement in ``LegalizeOp``; to Promote your node's operands to a larger size, and perform the correct; operation. You will also need to add code to ``PromoteOp`` to do this as; well. For a good example, see ``ISD::BSWAP``, which promotes its operand to; a wider size, performs the byteswap, and then shifts the correct bytes right; to emulate the narrower byteswap in the wider type. #. ``lib/CodeGen/SelectionDAG/LegalizeDAG.cpp``:. Add a case for your node in ``ExpandOp`` to teach the legalizer how to; perform the action represented by the new node on a value that has been split; into high and low halves. This case will be used to support your node with a; 64 bit operand on a 32 bit target. #. ``lib/CodeGen/SelectionDAG/DAGCombiner.cpp``:. If your node can be combined with itself, or other existing nodes in a; peephole-like fashion, add a visit function for it, and call that function; from. There are several good examples for simple combines you can do;; ``visitFABS`` and ``visitSR",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst:5489,perform,perform,5489,interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ExtendingLLVM.rst,1,['perform'],['perform']
Performance," contain all; class definitions from the `atlfast.root` file. The necessary `makefile`; to build a shared library are also created, and since the '++' is; appended, the shared library is also loaded. ``` {.cpp}; root[] f.MakeProject(""MyProject"",""*"", ""recreate++""); MakeProject has generated 0 classes in MyProject; MyProject/MAKE file has been generated; Shared lib MyProject/MyProject.so has been generated; Shared lib MyProject/MyProject.so has been dynamically linked; ```. The contents of `MyProject`:. ``` {.cpp}; root[] .! ls MyProject; ATLFCluster.h ATLFJet.h ATLFMiscMaker.h ATLFTrack.h; TMCParticle.h ATLFClusterMaker.h ATLFJetMaker.h ATLFMuon.h; ATLFElectron.h ATLFMCMaker.h ATLFMuonMaker.h ATLFElectronMaker.h; ATLFMaker.h ATLFPhoton.h ATLFHistBrowser.h ATLFMisc.h; ATLFPhotonMaker.h ATLFTrackMaker.h ATLFTrigger.h ATLFTriggerMaker.h; LinkDef.h MAKE MyProject.so MyProjectProjectDict.h; MyProjectProjectDict.cxx MyProjectProjectDict.o; ```. Now you can load the shared library in any consecutive root session to; use the `atlfast` classes. ``` {.cpp}; root[]gSystem->Load(""MyProject/MyProject""); root[]ATLFMuon muon; ```. This is an example of a generated header file:. ``` {.cpp}; //////////////////////////////////////////////////////////; // This class has been generated by TFile::MakeProject; // (Thu Apr 5 10:18:37 2001 by ROOT version 3.00/06); // from the TStreamerInfo in file atlfast.root; //////////////////////////////////////////////////////////; #ifndef ATLFMuon_h; #define ATLFMuon_h; #include ""TObject.h""; #include ""TAtt3D.h""; class ATLFMuon : public TObject , public TAtt3D {; public:; Int_t m_KFcode; //Muon KF-code; Int_t m_MCParticle; //Muon position in MCParticles list; Int_t m_KFmother; //Muon mother KF-code; Int_t m_UseFlag; //Muon energy usage flag; Int_t m_Isolated; //Muon isolation (1 for isolated); Float_t m_Eta; //Eta coordinate; Float_t m_Phi; //Phi coordinate; Float_t m_PT; //Transverse energy; Int_t m_Trigger; //Result of trigger; ATLFMuon() {;}; virtua",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:90321,load,load,90321,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,1,['load'],['load']
Performance," correct. Overestimating the alignment results in undefined behavior.; Underestimating the alignment may produce less efficient code. An alignment of; 1 is always safe. The maximum possible alignment is ``1 << 32``. An alignment; value higher than the size of the loaded type implies memory up to the; alignment value bytes can be safely loaded without trapping in the default; address space. Access of the high bytes can interfere with debugging tools, so; should not be accessed if the function has the ``sanitize_thread`` or; ``sanitize_address`` attributes. The alignment is only optional when parsing textual IR; for in-memory IR, it is; always present. An omitted ``align`` argument means that the operation has the; ABI alignment for the target. The optional ``!nontemporal`` metadata must reference a single metadata; name ``<nontemp_node>`` corresponding to a metadata node with one ``i32`` entry; of value 1. The existence of the ``!nontemporal`` metadata on the instruction; tells the optimizer and code generator that this load is not expected to; be reused in the cache. The code generator may select special; instructions to save cache bandwidth, such as the ``MOVNT`` instruction on; x86. The optional ``!invariant.group`` metadata must reference a; single metadata name ``<empty_node>``. See ``invariant.group`` metadata. Semantics:; """""""""""""""""""". The contents of memory are updated to contain ``<value>`` at the; location specified by the ``<pointer>`` operand. If ``<value>`` is; of scalar type then the number of bytes written does not exceed the; minimum number of bytes needed to hold all bits of the type. For; example, storing an ``i24`` writes at most three bytes. When writing a; value of a type like ``i20`` with a size that is not an integral number; of bytes, it is unspecified what happens to the extra bits that do not; belong to the type, but they will typically be overwritten.; If ``<value>`` is of aggregate type, padding is filled with; :ref:`undef <undefvalues>`.; If",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:422174,optimiz,optimizer,422174,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,3,"['cache', 'load', 'optimiz']","['cache', 'load', 'optimizer']"
Performance," correct. Overestimating the alignment results in undefined behavior.; Underestimating the alignment may produce less efficient code. An alignment of; 1 is always safe. The maximum possible alignment is ``1 << 32``. An alignment; value higher than the size of the loaded type implies memory up to the; alignment value bytes can be safely loaded without trapping in the default; address space. Access of the high bytes can interfere with debugging tools, so; should not be accessed if the function has the ``sanitize_thread`` or; ``sanitize_address`` attributes. The alignment is only optional when parsing textual IR; for in-memory IR, it is; always present. An omitted ``align`` argument means that the operation has the; ABI alignment for the target. The optional ``!nontemporal`` metadata must reference a single; metadata name ``<nontemp_node>`` corresponding to a metadata node with one; ``i32`` entry of value 1. The existence of the ``!nontemporal``; metadata on the instruction tells the optimizer and code generator; that this load is not expected to be reused in the cache. The code; generator may select special instructions to save cache bandwidth, such; as the ``MOVNT`` instruction on x86. The optional ``!invariant.load`` metadata must reference a single; metadata name ``<empty_node>`` corresponding to a metadata node with no; entries. If a load instruction tagged with the ``!invariant.load``; metadata is executed, the memory location referenced by the load has; to contain the same value at all points in the program where the; memory location is dereferenceable; otherwise, the behavior is; undefined. The optional ``!invariant.group`` metadata must reference a single metadata name; ``<empty_node>`` corresponding to a metadata node with no entries.; See ``invariant.group`` metadata :ref:`invariant.group <md_invariant.group>`. The optional ``!nonnull`` metadata must reference a single; metadata name ``<empty_node>`` corresponding to a metadata node with no; entries. The exis",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:415088,optimiz,optimizer,415088,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,3,"['cache', 'load', 'optimiz']","['cache', 'load', 'optimizer']"
Performance," corresponding static methods.; Fitting Classes: improve in general all classes in view of using them in the histogram and graph fitting routines. Few bugs have been as well fixed (see the cvs log for details). The fitter class, ROOT::Fit::Fitter is used now to implement the fit functionality of the Hist library (i.e. TH1::Fit, TGraph::Fit/; ; The Fitter class has been changed to retain a pointer to the Minimizer and Objective function of the last fit. The objective function depends on a reference to the data and the model function, therefore the objective function pointer is valid as far the data and the model function are maintained alive.; ; The library provides the implementation of standard objective function like the Chi2 function, the Poisson likelihood function (for binned likelihood fits) and the loh likelihood function (for unbinned fits). These standard objective functions can be created with or without gradient functionality. In the first case the minimization will be performed using the gradient provided by the function. These functions can also be used in specialized fitting methods like Fumili or the GSL non-linear least square.; . MathCore. Fixed a bug in setting the VEGAS integration mode in the GSLMCIntegrator class.; . Fumili. Add implementation of Minimizer interface using TFumili.; ; Minuit. In TMinuitMinimizer: do not delete the contained TMinuit reference, but maintain it alive, and accessible outside as gMinuit. It can then be used after fitting, for example for drawing contour plots. Add also support for Scan and Contour plots.; ; TLinearMinimizer: add support for robust fitting; . Minuit2. Add support to perform parallel minimization using a thread for each gradient calculation with openMP. In the ROOT environment the Minuit2 library can be built using openMP ( -fopenmp compilation flag for gcc) if the environment variables USE_PARALLEL_MINUIT2 and USE_OPENMP are set.; In the Minuit2 standalone built libraries (using autoconf) support for o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/math/doc/v522/index.html:2447,perform,performed,2447,math/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/math/doc/v522/index.html,1,['perform'],['performed']
Performance," count:. .. code-block:: c++. #pragma clang loop vectorize_width(2) interleave_count(2); for(...) {; ...; }. See the Clang; `language extensions; <https://clang.llvm.org/docs/LanguageExtensions.html#extensions-for-loop-hint-optimizations>`_; for details. Diagnostics; -----------. Many loops cannot be vectorized including loops with complicated control flow,; unvectorizable types, and unvectorizable calls. The loop vectorizer generates; optimization remarks which can be queried using command line options to identify; and diagnose loops that are skipped by the loop-vectorizer. Optimization remarks are enabled using:. ``-Rpass=loop-vectorize`` identifies loops that were successfully vectorized. ``-Rpass-missed=loop-vectorize`` identifies loops that failed vectorization and; indicates if vectorization was specified. ``-Rpass-analysis=loop-vectorize`` identifies the statements that caused; vectorization to fail. If in addition ``-fsave-optimization-record`` is; provided, multiple causes of vectorization failure may be listed (this behavior; might change in the future). Consider the following loop:. .. code-block:: c++. #pragma clang loop vectorize(enable); for (int i = 0; i < Length; i++) {; switch(A[i]) {; case 0: A[i] = i*2; break;; case 1: A[i] = i; break;; default: A[i] = 0;; }; }. The command line ``-Rpass-missed=loop-vectorize`` prints the remark:. .. code-block:: console. no_switch.cpp:4:5: remark: loop not vectorized: vectorization is explicitly enabled [-Rpass-missed=loop-vectorize]. And the command line ``-Rpass-analysis=loop-vectorize`` indicates that the; switch statement cannot be vectorized. .. code-block:: console. no_switch.cpp:4:5: remark: loop not vectorized: loop contains a switch statement [-Rpass-analysis=loop-vectorize]; switch(A[i]) {; ^. To ensure line and column numbers are produced include the command line options; ``-gline-tables-only`` and ``-gcolumn-info``. See the Clang `user manual; <https://clang.llvm.org/docs/UsersManual.html#options-to-e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:3173,optimiz,optimization-record,3173,interpreter/llvm-project/llvm/docs/Vectorizers.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst,1,['optimiz'],['optimization-record']
Performance," created for each assignment, recording the; variable's new location. Compared with the ``llvm.dbg.declare`` intrinsic:. * A dbg.value terminates the effect of any preceding dbg.values for (any; overlapping fragments of) the specified variable.; * The dbg.value's position in the IR defines where in the instruction stream; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a state that would never have existed; in the execution of the unoptimized program, given the same input. Doing so; risks misleading the developer by reporting a state that does not exist,; damaging their understanding of the optimized program and undermining their; trust in the debugger. Sometimes perfectly preserving variable locations is not possible, often when a; redundant calculation is optimized out. In such cases, a ``llvm.dbg.value``; with operand ``poison`` should be used, to terminate earlier variable locations; and let the debugger present ``optimized out`` to the developer. Withholding; these potentially stale variable values from the developer diminishes the; amount of available debug information, but increases the reliability of the; remaining information. To illustrate some potential issues, consider the following example:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); br i1 %cond, label %truebr, label %falsebr; truebr:; %tval = add i32 %bar, 1; call @llvm.dbg.value(metadata i32 %tval, metadata !1, metadata !2); %g1 = call i32 @gazonk(); br label %exit; falsebr:; %fval = add i3",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:19294,optimiz,optimized,19294,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['optimiz'],['optimized']
Performance," creates JSON code for the; TCanvas with all drawn objects inside. Allows to store current canvas state; 2. Support ""item=img:file.png"" parameter to insert images in existing layout (#151); 3. Support TTree drawing into TGraph (#153), thanks @cozzyd; 4. Let configure ""&toolbar=right"" in URL to change position of tool buttons; 5. Let configure ""&divsize=500x400"" in URL of size of main div element (default - full browser); 6. Implement ""optstat1001"" and ""optfit101"" draw options for histograms; 7. Remove ""autocol"" options - standard ""plc"" should be used instead; 8. Provide drawing of artificial ""$legend"" item - it creates TLegend for all primitives in pad; Can be used when several histograms or several graphs superimposed; 9. Let configure ""&toolbar=vert"" in URL to change orientation of tool buttons; 10. Improve markers and error bars drawing for TH1/TProfile. ## Changes in 5.4.3; 1. Fix - draw functions also when histogram ""same"" option used (#159); 2. Fix - when draw histogram as markers improve optimization algorithm; 3. Fix - correct histogram Y-axis range selection in logarithmic scale; 4. Fix - for TH2 draw options allow combination ""colztext"" (#162); 5. Fix - PNG file generation with 3D drawings inside. ## Changes in 5.4.2; 1. Fix - take into account extra quotes in multipart http reply (#157); 2. Fix - display of labels on X axis with TProfile; 3. Fix - support time display in TMultiGraph; 4. Fix - correctly parse ""optstat"" and ""optfit"" in URL; 5. Fix - correctly update TGraph drawing when X range is changing; 6. Fix - return only TF1/TF2 object when searching function (#158). ## Changes in 5.4.1; 1. Fix - monitoring mode in draw.htm page; 2. Fix - zooming in colz palette; 3. Fix - support both 9.x and 10.x jsdom version in Node.js (#149); 4. Fix - draw axis main line with appropriate attributes (#150); 5. Fix - use axis color when drawing grids lines (#150); 6. Fix - when set pad logx/logy, reset existing user ranges in pad; 7. Fix - avoid too deep calling sta",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:34517,optimiz,optimization,34517,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['optimiz'],['optimization']
Performance," creates as in; ""new"", in addition if the directory does exist, all existing files; are deleted before creating the new files. - ""`update`"" The new classes are added to the existing directory and; the existing classes are replaced with the new definition. If the; directory does not exist, it creates it as in ""new"". - ""+"": This option can be used in combination with the other three. It; will create the necessary files to easily build a shared library; containing the class definitions.Specifically it will:. - Generate a script called `MAKE` that builds the shared library; containing the definition of all classes in the directory. - Generate a `LinkDef.h `files to use with `rootcling` in `MAKE`. - Run `rootcling` to generate a `<dirname>ProjectDict.cxx` file. - Compile the \<`dirname>ProjectDict.cxx `with the current options in; `compiledata.h`. - Build a shared library` <dirname>.so`. - ""++"":This option can be used instead of the single ""+"". It does; everything the single ""+"" does, and dynamically loads the shared; library `<dirname>.so`. This example makes a directory called `MyProject` that will contain all; class definitions from the `atlfast.root` file. The necessary `makefile`; to build a shared library are also created, and since the '++' is; appended, the shared library is also loaded. ``` {.cpp}; root[] f.MakeProject(""MyProject"",""*"", ""recreate++""); MakeProject has generated 0 classes in MyProject; MyProject/MAKE file has been generated; Shared lib MyProject/MyProject.so has been generated; Shared lib MyProject/MyProject.so has been dynamically linked; ```. The contents of `MyProject`:. ``` {.cpp}; root[] .! ls MyProject; ATLFCluster.h ATLFJet.h ATLFMiscMaker.h ATLFTrack.h; TMCParticle.h ATLFClusterMaker.h ATLFJetMaker.h ATLFMuon.h; ATLFElectron.h ATLFMCMaker.h ATLFMuonMaker.h ATLFElectronMaker.h; ATLFMaker.h ATLFPhoton.h ATLFHistBrowser.h ATLFMisc.h; ATLFPhotonMaker.h ATLFTrackMaker.h ATLFTrigger.h ATLFTriggerMaker.h; LinkDef.h MAKE MyProject.so MyProjectProjec",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md:89256,load,loads,89256,documentation/users-guide/InputOutput.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/InputOutput.md,1,['load'],['loads']
Performance," currently filled.; By default, this limit is set to twice the compressed target cluster size when compression is used,; and to the cluster target size for uncompressed data.; Initially, and after flushing, all columns use small pages,; just big enough to hold the configurable minimum number of elements (64 by default).; Page sizes are doubled as more data is filled into them.; When a page reaches the maximum page size (see above), it is flushed.; When the overall page budget is reached,; pages larger than the page at hand are flushed before the page at hand is flushed.; For the parallel writer, every fill context maintains the page memory budget independently. Note that the total amount of memory consumed for writing is usually larger than the write page budget.; For instance, if buffered writing is used (the default), additional memory is required.; Use RNTupleModel::EstimateWriteMemoryUsage() for the total estimated memory use for writing. The default values are tuned for a total write memory of around 300 MB per writer resp. fill context.; In order to decrease the memory consumption,; users should decrease the target cluster size before tuning more intricate memory settings. Notes; =====. Approximation of the compressed cluster size; --------------------------------------------. The estimator for the compressed cluster size uses the average compression factor; of the so far written clusters.; This has been choosen as a simple, yet expectedly accurate enough estimator (to be validated).; The following alternative strategies were discussed:. - The average compression factor of all so-far written pages.; Easy to implement.; It would better prevent outlier clusters from skewing the estimate of the successor clusters.; It would be slower though in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking. - The average over a window of the last $k$ clusters, possibly with exponential smoothing.;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md:2878,tune,tuned,2878,tree/ntuple/v7/doc/tuning.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md,1,['tune'],['tuned']
Performance," data flow analysis to identify an output; parameter. The refactoring can be safely done when the data flow algorithm; computes a normal state with all of the fields proven to be overwritten in the; exit basic block of the function. ```c++; struct Customer {; int account_id;; std::string name;; };. void GetCustomer(Customer* c) {; // Overwritten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; c->name = ...; // Overwritten: {c->account_id, c->name}; } else {; c->name = ...; // Overwritten: {c->account_id, c->name}; }; // Overwritten: {c->account_id, c->name}; }; ```. When the data flow algorithm computes a normal state, but not all fields are; proven to be overwritten we can't perform the refactoring. ```c++; void target(bool b, Customer* c) {; // Overwritten: {}; if (b) {; c->account_id = 42; // Overwritten: {c->account_id}; } else {; c->name = ""Konrad""; // Overwritten: {c->name}; }; // Overwritten: {}; }; ```. Similarly, when the data flow algorithm computes a failure state, we also can't; perform the refactoring. ```c++; Customer* kGlobalCustomer;. void GetCustomer(Customer* c) {; // Overwritten: {}; c->account_id = ...; // Overwritten: {c->account_id}; if (...) {; print(c->name); // Unsafe read; } else {; kGlobalCustomer = c; // Pointer escape; }; // Unsafe read, Pointer escape; }; ```. ## Example: finding dead stores. Let's say we want to find redundant stores, because they indicate potential; bugs. ```c++; x = GetX();; x = GetY();; ```. The first store to `x` is never read, probably there is a bug. The implementation of dead store analysis is very similar to output parameter; analysis: we need to track stores and loads, and find stores that were never; read. [Liveness analysis](https://en.wikipedia.org/wiki/Live_variable_analysis) is a; generalization of this idea, which is often used to answer many related; questions, for example:. * finding dead stores,; * finding uninitialized variables,; * finding a good point to deallocate memory,; *",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md:19320,perform,perform,19320,interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/DataFlowAnalysisIntro.md,1,['perform'],['perform']
Performance," data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:226089,load,load,226089,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," data symbol, the associated section is loaded into memory; and the symbol is stored in a symbol table map data structure. When the; iteration is complete, a section is emitted for the common symbols. Next, RuntimeDyldImpl::loadObject iterates through the sections in the; object image and for each section iterates through the relocations for; that sections. For each relocation, it calls the format-specific; processRelocationRef method, which will examine the relocation and store; it in one of two data structures, a section-based relocation list map and; an external symbol relocation map. .. image:: MCJIT-load-object.png. When RuntimeDyldImpl::loadObject returns, all of the code and data; sections for the object will have been loaded into memory allocated by the; memory manager and relocation information will have been prepared, but the; relocations have not yet been applied and the generated code is still not; ready to be executed. [Currently (as of August 2013) the MCJIT engine will immediately apply; relocations when loadObject completes. However, this shouldn't be; happening. Because the code may have been generated for a remote target,; the client should be given a chance to re-map the section addresses before; relocations are applied. It is possible to apply relocations multiple; times, but in the case where addresses are to be re-mapped, this first; application is wasted effort.]. Address Remapping; =================. At any time after initial code has been generated and before; finalizeObject is called, the client can remap the address of sections in; the object. Typically this is done because the code was generated for an; external process and is being mapped into that process' address space.; The client remaps the section address by calling MCJIT::mapSectionAddress.; This should happen before the section memory is copied to its new; location. When MCJIT::mapSectionAddress is called, MCJIT passes the call on to; RuntimeDyldImpl (via its Dyld member). RuntimeD",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst:5545,load,loadObject,5545,interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,1,['load'],['loadObject']
Performance," debug information for the data types defined in the AST. Tools built on top of; libclang that do not need debug information may also produce raw AST files that; only contain the serialized AST. The ``clangast`` section is organized into several different blocks, each of; which contains the serialized representation of a part of Clang's internal; representation. Each of the blocks corresponds to either a block or a record; within `LLVM's bitstream format <https://llvm.org/docs/BitCodeFormat.html>`_.; The contents of each of these logical blocks are described below. .. image:: PCHLayout.png. The ``llvm-objdump`` utility provides a ``-raw-clang-ast`` option to extract the; binary contents of the AST section from an object file container. The `llvm-bcanalyzer <https://llvm.org/docs/CommandGuide/llvm-bcanalyzer.html>`_; utility can be used to examine the actual structure of the bitstream for the AST; section. This information can be used both to help understand the structure of; the AST section and to isolate areas where the AST representation can still be; optimized, e.g., through the introduction of abbreviations. Metadata Block; ^^^^^^^^^^^^^^. The metadata block contains several records that provide information about how; the AST file was built. This metadata is primarily used to validate the use of; an AST file. For example, a precompiled header built for a 32-bit x86 target; cannot be used when compiling for a 64-bit x86 target. The metadata block; contains information about:. Language options; Describes the particular language dialect used to compile the AST file,; including major options (e.g., Objective-C support) and more minor options; (e.g., support for ""``//``"" comments). The contents of this record correspond to; the ``LangOptions`` class. Target architecture; The target triple that describes the architecture, platform, and ABI for; which the AST file was generated, e.g., ``i386-apple-darwin9``. AST version; The major and minor version numbers of the AST fi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst:7376,optimiz,optimized,7376,interpreter/llvm-project/clang/docs/PCHInternals.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/PCHInternals.rst,1,['optimiz'],['optimized']
Performance," debug information"")));. This definition defines an enumerated command line variable of type ""``enum; DebugLev``"", which works exactly the same way as before. The difference here is; just the interface exposed to the user of your program and the help output by; the ""``-help``"" option:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -debug_level - Set the debugging level:; =none - disable debug information; =quick - enable quick debug information; =detailed - enable detailed debug information; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. Again, the only structural difference between the debug level declaration and; the optimization level declaration is that the debug level declaration includes; an option name (``""debug_level""``), which automatically changes how the library; processes the argument. The CommandLine library supports both forms so that you; can choose the form most appropriate for your application. .. _lists:. Parsing a list of options; -------------------------. Now that we have the standard run-of-the-mill argument types out of the way,; lets get a little wild and crazy. Lets say that we want our optimizer to accept; a **list** of optimizations to perform, allowing duplicates. For example, we; might want to run: ""``compiler -dce -instsimplify -inline -dce -strip``"". In this; case, the order of the arguments and the number of appearances is very; important. This is what the ""``cl::list``"" template is for. First, start by; defining an enum of the optimizations that you would like to perform:. .. code-block:: c++. enum Opts {; // 'inline' is a C++ keyword, so name it 'inlining'; dce, instsimplify, inlining, strip; };. Then define your """,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:18757,optimiz,optimization,18757,interpreter/llvm-project/llvm/docs/CommandLine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst,1,['optimiz'],['optimization']
Performance," declare float @llvm.vp.reduce.fmax.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, float <vector_length>); declare double @llvm.vp.reduce.fmax.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmax``' intrinsic performs the floating-point ``MAX``; reduction (:ref:`llvm.vector.reduce.fmax <int_vector_reduce_fmax>`) of the; vector operand ``val`` on each enabled lane, taking the maximum of that and the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. The neutral value is dependent on the :ref:`fast-math flags <fastmath>`. If no; flags are set, the neutral value is ``-QNAN``. If ``nnan`` and ``ninf`` are; both set, then the neutral value is the smallest floating-point value for the; result type. If only ``nnan`` is set then the neutral value is ``-Infinity``. This instruction has the same comparison semantics as the; :ref:`llvm.vector.reduce.fmax <int_vector_reduce_fmax>` intrinsic (and thus the; '``llvm.maxnum.*``' intrinsic). That is, the result will always be a number; unless all elements of the vector and the starting value are ``NaN``. For a; vector with maximum e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:772123,perform,performs,772123,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," declare float @llvm.vp.reduce.fmin.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, float <vector_length>); declare double @llvm.vp.reduce.fmin.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fmin``' intrinsic performs the floating-point ``MIN``; reduction (:ref:`llvm.vector.reduce.fmin <int_vector_reduce_fmin>`) of the; vector operand ``val`` on each enabled lane, taking the minimum of that and the; scalar ``start_value``. Disabled lanes are treated as containing the neutral; value (i.e. having no effect on the reduction operation). If the vector length; is zero, the result is the start value. The neutral value is dependent on the :ref:`fast-math flags <fastmath>`. If no; flags are set, the neutral value is ``+QNAN``. If ``nnan`` and ``ninf`` are; both set, then the neutral value is the largest floating-point value for the; result type. If only ``nnan`` is set then the neutral value is ``+Infinity``. This instruction has the same comparison semantics as the; :ref:`llvm.vector.reduce.fmin <int_vector_reduce_fmin>` intrinsic (and thus the; '``llvm.minnum.*``' intrinsic). That is, the result will always be a number; unless all elements of the vector and the starting value are ``NaN``. For a; vector with maximum el",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:774997,perform,performs,774997,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," declare i32 @llvm.nvvm.read.ptx.sreg.tid.x() readnone nounwind; ; libdevice function; declare float @__nv_powf(float, float). define void @kernel(float addrspace(1)* %A,; float addrspace(1)* %B,; float addrspace(1)* %C) {; entry:; ; What is my ID?; %id = tail call i32 @llvm.nvvm.read.ptx.sreg.tid.x() readnone nounwind. ; Compute pointers into A, B, and C; %ptrA = getelementptr float, float addrspace(1)* %A, i32 %id; %ptrB = getelementptr float, float addrspace(1)* %B, i32 %id; %ptrC = getelementptr float, float addrspace(1)* %C, i32 %id. ; Read A, B; %valA = load float, float addrspace(1)* %ptrA, align 4; %valB = load float, float addrspace(1)* %ptrB, align 4. ; Compute C = pow(A, B); %valC = call float @__nv_powf(float %valA, float %valB). ; Store back to C; store float %valC, float addrspace(1)* %ptrC, align 4. ret void; }. !nvvm.annotations = !{!0}; !0 = !{void (float addrspace(1)*,; float addrspace(1)*,; float addrspace(1)*)* @kernel, !""kernel"", i32 1}. To compile this kernel, we perform the following steps:. 1. Link with libdevice; 2. Internalize all but the public kernel function; 3. Run ``NVVMReflect`` and set ``__CUDA_FTZ`` to 0; 4. Optimize the linked module; 5. Codegen the module. These steps can be performed by the LLVM ``llvm-link``, ``opt``, and ``llc``; tools. In a complete compiler, these steps can also be performed entirely; programmatically by setting up an appropriate pass configuration (see; :ref:`libdevice`). .. code-block:: text. # llvm-link t2.bc libdevice.compute_20.10.bc -o t2.linked.bc; # opt -internalize -internalize-public-api-list=kernel -nvvm-reflect-list=__CUDA_FTZ=0 -nvvm-reflect -O3 t2.linked.bc -o t2.opt.bc; # llc -mcpu=sm_20 t2.opt.bc -o t2.ptx. .. note::. The ``-nvvm-reflect-list=_CUDA_FTZ=0`` is not strictly required, as any; undefined variables will default to zero. It is shown here for evaluation; purposes. This gives us the following PTX (excerpt):. .. code-block:: text. //; // Generated by LLVM NVPTX Back-End; //. .version 3.1",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NVPTXUsage.rst:25006,perform,perform,25006,interpreter/llvm-project/llvm/docs/NVPTXUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/NVPTXUsage.rst,1,['perform'],['perform']
Performance," derived pointer. By default RewriteStatepointsForGC passes in ``0xABCDEF00`` as the statepoint; ID and ``0`` as the number of patchable bytes to the newly constructed; ``gc.statepoint``. These values can be configured on a per-callsite; basis using the attributes ``""statepoint-id""`` and; ``""statepoint-num-patch-bytes""``. If a call site is marked with a; ``""statepoint-id""`` function attribute and its value is a positive; integer (represented as a string), then that value is used as the ID; of the newly constructed ``gc.statepoint``. If a call site is marked; with a ``""statepoint-num-patch-bytes""`` function attribute and its; value is a positive integer, then that value is used as the 'num patch; bytes' parameter of the newly constructed ``gc.statepoint``. The; ``""statepoint-id""`` and ``""statepoint-num-patch-bytes""`` attributes; are not propagated to the ``gc.statepoint`` call or invoke if they; could be successfully parsed. In practice, RewriteStatepointsForGC should be run much later in the pass; pipeline, after most optimization is already done. This helps to improve; the quality of the generated code when compiled with garbage collection support. .. _RewriteStatepointsForGC_intrinsic_lowering:. RewriteStatepointsForGC intrinsic lowering; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. As a part of lowering to the explicit model of relocations; RewriteStatepointsForGC performs GC specific lowering for the following; intrinsics:. * ``gc.get.pointer.base``; * ``gc.get.pointer.offset``; * ``llvm.memcpy.element.unordered.atomic.*``; * ``llvm.memmove.element.unordered.atomic.*``. There are two possible lowerings for the memcpy and memmove operations:; GC leaf lowering and GC parseable lowering. If a call is explicitly marked with; ""gc-leaf-function"" attribute the call is lowered to a GC leaf call to; '``__llvm_memcpy_element_unordered_atomic_*``' or; '``__llvm_memmove_element_unordered_atomic_*``' symbol. Such a call can not; take a safepoint. Otherwise, the call is made G",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:29082,optimiz,optimization,29082,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,1,['optimiz'],['optimization']
Performance," description of the `ROOT::Fit` classes and how to use them.; Using these classes instead of the interface provided directly in the ROOT data objects, like `TH1::Fit` allow are more fine control; to configure and customise the fits. For example, using these classes a combined fit of several histograms can be performed. To understand how these class work, let's go through a simple example, such as fitting an histogram. When fitting an histogram, instead of using `TH1::Fit` we will show in the following hot wo use the `ROOT::Fit` classes.; We will show how to perform the following different type of fits with the histogram data:; * a least square fit using the observed errors (Neyman chi-squared);; * a least square fit using the expected errors from the function (Pearson chi-squared);; * a binned likelihood fit;; * an extended unbinned likelihood fits, if the histogram has been set to store in the buffer the original data used to fill it. Let's go through all the steps required for performing these fits using the `ROOT::Fit::Fitter` class.; These steps are:; 1. Create the input fit data object.; 2. Create the input model function.; 3. Configure the fit.; 4. Perform the data fitting.; 5. Examine the result. ### Creating the input fit data. We have two types of input data, binned data (class `ROOT::Fit::BinData`) used for least square (chi-square) fits of histograms or `TGraph` objects; or un-binned data (class `ROOT::Fit::UnBinData`) used for; fitting vectors of data points (e.g. from a `TTree`). #### Using Binned data. Let's suppose we have an histogram, represented as a **`TH1`** type object (it can be one or multi-dimensional). The following shows how to create and; fill a `ROOT:Fit::BinData` object. ``` {.cpp}; ROOT::Fit::DataOptions opt;; opt.fIntegral = true;; ROOT::Fit::BinData data(opt);; // fill the bin data using the histogram; // we can do this using the following helper function from the Hist library; TH1 * h1 = (TH1*) gDirectory->Get(""myHistogram"");; ROOT::F",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md:29346,perform,performing,29346,documentation/users-guide/FittingHistograms.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/FittingHistograms.md,1,['perform'],['performing']
Performance," determine volume size. KernelEstimator No Box Box, Sphere, Teepee, Gauss, Sinc3, Sinc5, Sinc7, Sinc9, Sinc11, Lanczos2, Lanczos3, Lanczos5, Lanczos8, Trim Kernel estimation function. DeltaFrac No 3 − nEventsMin/Max for minmax and rms volume range. NEventsMin No 100 − nEventsMin for adaptive volume range. NEventsMax No 200 − nEventsMax for adaptive volume range. MaxVIterations No 150 − MaxVIterations for adaptive volume range. InitialScale No 0.99 − InitialScale for adaptive volume range. GaussSigma No 0.1 − Width (wrt volume size) of Gaussian kernel estimator. NormTree No False − Normalize binary search tree. Configuration options for MVA method :. Configuration options reference for MVA method: FDA. Option Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLevel below - overrides the latter one). VerbosityLevel No Default Default, Debug, Verbose, Info, Warning, Error, Fatal Verbosity level. VarTransform No None − List of variable transformations performed before training, e.g., D_Background,P_Signal,G,N_AllClasses for: Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed). H No False − Print method-specific help message. CreateMVAPdfs No False − Create PDFs for classifier outputs (signal and background). IgnoreNegWeightsInTraining No False − Events with negative weights are ignored in the training (but are included for testing and performance evaluation). Formula No (0) − The discrimination formula. ParRanges No () − Parameter ranges. FitMethod No MINUIT MC, GA, SA, MINUIT Optimisation Method. Converger No None None, MINUIT FitMethod uses Converger to improve result. Configuration options for MVA method :. Configuration options reference for MVA method: LD. Option Array Default value Predefined values Description. V No False − Verbose output (short form of VerbosityLe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html:5455,perform,performed,5455,documentation/tmva/UsersGuide/optionRef.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/optionRef.html,1,['perform'],['performed']
Performance," dev; 1. Let use custom time zone for time display, support '&utc' and '&cet' in URL parameters; 2. Support gStyle.fLegendFillStyle; 3. Let change histogram min/max values via context menu; 4. Support Z-scale zooming with TScatter; 5. Implement ""haxis"" draw option for histogram to draw only axes for hbar; 6. Implement ""axisg"" and ""haxisg"" to draw axes with grids; 7. Support TH1 marker, text and line drawing superimposed with ""haxis""; 8. Support `TBox`, `TLatex`, `TLine`, `TMarker` drawing on ""frame"", support drawing on swapped axes; 9. `TProfile` and `TProfile2D` projections https://github.com/root-project/root/issues/15851; 10. Draw total histogram from TEfficiency when draw option starts with 'b'; 11. Let redraw TEfficiency, THStack and TMultiGraph with different draw options via hist context menu; 12. Support 'pads' draw options for TMultiGraph, support context menu for it; 13. Let drop object on sub-pads; 14. Properly loads ES6 modules for web canvas; 15. Improve performance of TH3/RH3 drawing by using THREE.InstancedMesh; 16. Implement batch mode with '&batch' URL parameter to create SVG/PNG images with default GUI; 17. Adjust node.js implementation to produce identical output with normal browser; 18. Create necessary infrastructure for testing with 'puppeteer'; 19. Support inject of ES6 modules via '&inject=path.mjs'; 20. Using importmap for 'jsroot' in all major HTML files and in demos; 21. Implement `settings.CutAxisLabels` flag to remove labels which may exceed graphical range; 22. Let disable usage of TAxis custom labels via context menu; 23. Let configure default draw options via context menu, they can be preserved in the local storage; 24. Let save canvas as JSON file from context menu, object as JSON from inspector; 25. Upgrade three.js r162 -> r168, use r162 only in node.js because of ""gl"" module; 26. Create unified svg2pdf/jspdf ES6 modules, integrate in jsroot builds; 27. Let create multipage PDF document - in TWebCanvas batch mode; 28. Let add extern",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:1015,perform,performance,1015,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['perform'],['performance']
Performance," devices; - Provide simple layout, making it default; - Allow to open ROOT files in online session (via url parameter); - One could monitor simultaneously objects from server and root files; - Implement 'autocol' draw option - when superimposing histograms,; their line colors will be automatically assigned; - Implement 'nostat' draw option - disabled stat drawing; - Using '_same_' identifier in item name, one can easily draw or superimpose; similar items from different files. Could be used in URL like:; `...&files=[file1.root,file2.root]&items=[file1.root/hpx, file2.root/_same_]`; `...&files=[file1.root,file2.root]&item=file1.root/hpx+file2.root/_same_`; Main limitation - file names should have similar length.; - When 'autozoom' specified in draw options, histogram zoomed into; non-empty content. Same command available via context menu.; - Item of 'Text' kind can be created. It is displayed as; lain text in the browser. If property 'mathjax' specified,; MathJax.js library will be loaded and used for rendering.; See tutorials/http/httpcontrol.C macro for example.; - When using foreignObject, provide workaround for absolute positioning; problem in Chrome/Safari, see <http://bit.ly/1wjqCQ9>; - Support usage of minimized versions of .js and .css files.; Minimized scripts used by default on web servers.; - Implement JSROOT.extend instead of jQuery.extend, reduce; usage of jquery.js in core JSROOT classes; - Implement main graphics without jquery at all,; such mode used in `nobrowser` mode.; - Provide optional latex drawing with MathJax SVG.; TMathText always drawn with MathJax,; other classes require `mathjax` option in URL; - Improve drawing of different text classes, correctly handle; their alignment and scaling, special handling for IE. ## TTree Libraries. ### TTree Behavior change. #### Merging. Added fast cloning support to TTree::MergeTrees and TTree::Merge(TCollection*,Option_t*). #### TTreeCache. The TTreeCache is now enabled by default. The default size of the TT",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md:11611,load,loaded,11611,README/ReleaseNotes/v604/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v604/index.md,1,['load'],['loaded']
Performance," diagnostic may or many not have an associated category, if it; has one, it is listed in the diagnostic categorization field of the; diagnostic line (in the []'s). For example, a format string warning will produce these three; renditions based on the setting of this option:. ::. t.c:3:11: warning: conversion specifies type 'char *' but the argument has type 'int' [-Wformat]; t.c:3:11: warning: conversion specifies type 'char *' but the argument has type 'int' [-Wformat,1]; t.c:3:11: warning: conversion specifies type 'char *' but the argument has type 'int' [-Wformat,Format String]. This category can be used by clients that want to group diagnostics; by category, so it should be a high level category. We want dozens; of these, not hundreds or thousands of them. .. _opt_fsave-optimization-record:. .. option:: -f[no-]save-optimization-record[=<format>]. Enable optimization remarks during compilation and write them to a separate; file. This option, which defaults to off, controls whether Clang writes; optimization reports to a separate file. By recording diagnostics in a file,; users can parse or sort the remarks in a convenient way. By default, the serialization format is YAML. The supported serialization formats are:. - .. _opt_fsave_optimization_record_yaml:. ``-fsave-optimization-record=yaml``: A structured YAML format. - .. _opt_fsave_optimization_record_bitstream:. ``-fsave-optimization-record=bitstream``: A binary format based on LLVM; Bitstream. The output file is controlled by :option:`-foptimization-record-file`. In the absence of an explicit output file, the file is chosen using the; following scheme:. ``<base>.opt.<format>``. where ``<base>`` is based on the output file of the compilation (whether; it's explicitly specified through `-o` or not) when used with `-c` or `-S`.; For example:. * ``clang -fsave-optimization-record -c in.c -o out.o`` will generate; ``out.opt.yaml``. * ``clang -fsave-optimization-record -c in.c`` will generate; ``in.opt.yaml``. When",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:11013,optimiz,optimization,11013,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,1,['optimiz'],['optimization']
Performance," diagnostics from Clang's; `static analyzer <https://clang-analyzer.llvm.org>`_ can also be; influenced by the user via changes to the source code. See the available; `annotations <https://clang-analyzer.llvm.org/annotations.html>`_ and the; analyzer's `FAQ; page <https://clang-analyzer.llvm.org/faq.html#exclude_code>`_ for more; information. .. _usersmanual-precompiled-headers:. Precompiled Headers; -------------------. `Precompiled headers <https://en.wikipedia.org/wiki/Precompiled_header>`_; are a general approach employed by many compilers to reduce compilation; time. The underlying motivation of the approach is that it is common for; the same (and often large) header files to be included by multiple; source files. Consequently, compile times can often be greatly improved; by caching some of the (redundant) work done by a compiler to process; headers. Precompiled header files, which represent one of many ways to; implement this optimization, are literally files that represent an; on-disk cache that contains the vital information necessary to reduce; some of the work needed to process a corresponding header file. While; details of precompiled headers vary between compilers, precompiled; headers have been shown to be highly effective at speeding up program; compilation on systems with very large system headers (e.g., macOS). Generating a PCH File; ^^^^^^^^^^^^^^^^^^^^^. To generate a PCH file using Clang, one invokes Clang with the; `-x <language>-header` option. This mirrors the interface in GCC; for generating PCH files:. .. code-block:: console. $ gcc -x c-header test.h -o test.h.gch; $ clang -x c-header test.h -o test.h.pch. Using a PCH File; ^^^^^^^^^^^^^^^^. A PCH file can then be used as a prefix header when a ``-include-pch``; option is passed to ``clang``:. .. code-block:: console. $ clang -include-pch test.h.pch test.c -o test. The ``clang`` driver will check if the PCH file ``test.h.pch`` is; available; if so, the contents of ``test.h`` (and the files i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst:46186,optimiz,optimization,46186,interpreter/llvm-project/clang/docs/UsersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/UsersManual.rst,2,"['cache', 'optimiz']","['cache', 'optimization']"
Performance," directory. The appropriate sub-directory should be selected (see the; :doc:`Testing Guide <TestingGuide>` for details). * Test cases should be written in :doc:`LLVM assembly language <LangRef>`. * Test cases, especially for regressions, should be reduced as much as possible,; by :doc:`bugpoint <Bugpoint>` or manually. It is unacceptable to place an; entire failing program into ``llvm/test`` as this creates a *time-to-test*; burden on all developers. Please keep them short. * Avoid adding links to resources that are not available to the entire; community, such as links to private bug trackers, internal corporate; documentation, etc. Instead, add sufficient comments to the test to provide; the context behind such links. Note that llvm/test and clang/test are designed for regression and small feature; tests only. More extensive test cases (e.g., entire applications, benchmarks,; etc) should be added to the ``llvm-test`` test suite. The llvm-test suite is; for coverage (correctness, performance, etc) testing, not feature or regression; testing. Release Notes; -------------. Many projects in LLVM communicate important changes to users through release; notes, typically found in ``docs/ReleaseNotes.rst`` for the project. Changes to; a project that are user-facing, or that users may wish to know about, should be; added to the project's release notes at the author's or code reviewer's; discretion, preferably as part of the commit landing the changes. Examples of; changes that would typically warrant adding a release note (this list is not; exhaustive):. * Adding, removing, or modifying command-line options.; * Adding, removing, or regrouping a diagnostic.; * Fixing a bug that potentially has significant user-facing impact (please link; to the issue fixed in the bug database).; * Adding or removing optimizations that have widespread impact or enables new; programming paradigms.; * Modifying a C stable API.; * Notifying users about a potentially disruptive change expected to ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:10718,perform,performance,10718,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['perform'],['performance']
Performance," dispatch width for the processor. The dispatch width; defaults to field 'IssueWidth' in the processor scheduling model. If width is; zero, then the default dispatch width is used. .. option:: -register-file-size=<size>. Specify the size of the register file. When specified, this flag limits how; many physical registers are available for register renaming purposes. A value; of zero for this flag means ""unlimited number of physical registers"". .. option:: -iterations=<number of iterations>. Specify the number of iterations to run. If this flag is set to 0, then the; tool sets the number of iterations to a default value (i.e. 100). .. option:: -noalias=<bool>. If set, the tool assumes that loads and stores don't alias. This is the; default behavior. .. option:: -lqueue=<load queue size>. Specify the size of the load queue in the load/store unit emulated by the tool.; By default, the tool assumes an unbound number of entries in the load queue.; A value of zero for this flag is ignored, and the default load queue size is; used instead. .. option:: -squeue=<store queue size>. Specify the size of the store queue in the load/store unit emulated by the; tool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By; default, the number of cycles is set to 80. .. option:: -resource-pressure. Enable the resource pressure view. This is enabled by default. .. option:: -register-file-stats. Enable register file usage statistics. .. option:: -dispatch-stats. Enable extra dispatch statistics. This view collects and analy",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:4363,load,load,4363,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,"['load', 'queue']","['load', 'queue']"
Performance," document covers; useful features of the LLVM build system as well as best practices and general; information about packaging LLVM. If you are new to CMake you may find the :doc:`CMake` or :doc:`CMakePrimer`; documentation useful. Some of the things covered in this document are the inner; workings of the builds described in the :doc:`AdvancedBuilds` document. General Distribution Guidance; =============================. When building a distribution of a compiler it is generally advised to perform a; bootstrap build of the compiler. That means building a ""stage 1"" compiler with; your host toolchain, then building the ""stage 2"" compiler using the ""stage 1""; compiler. This is done so that the compiler you distribute benefits from all the; bug fixes, performance optimizations and general improvements provided by the; new compiler. In deciding how to build your distribution there are a few trade-offs that you; will need to evaluate. The big two are:. #. Compile time of the distribution against performance of the built compiler. #. Binary size of the distribution against performance of the built compiler. The guidance for maximizing performance of the generated compiler is to use LTO,; PGO, and statically link everything. This will result in an overall larger; distribution, and it will take longer to generate, but it provides the most; opportunity for the compiler to optimize. The guidance for minimizing distribution size is to dynamically link LLVM and; Clang libraries into the tools to reduce code duplication. This will come at a; substantial performance penalty to the generated binary both because it reduces; optimization opportunity, and because dynamic linking requires resolving symbols; at process launch time, which can be very slow for C++ code. .. _shared_libs:. .. warning::; One very important note: Distributions should never be built using the; *BUILD_SHARED_LIBS* CMake option. That option exists for optimizing developer; workflow only. Due to design and impleme",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst:1297,perform,performance,1297,interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/BuildingADistribution.rst,1,['perform'],['performance']
Performance," does not offer v_dot4_i32_i8, and rather offers; v_dot4_i32_iu8 which has operands to hold the signedness of the; vector operands. Thus, this intrinsic lowers to the signed version; of this instruction for gfx11 targets. llvm.amdgcn.sdot8 Provides direct access to v_dot8_u32_u4 across targets which; support such instructions. This performs signed dot product; with two i32 operands (holding a vector of 8 4bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output.; When applicable (i.e. no clamping / operand modifiers), this is lowered; into v_dot8c_i32_i4 for targets which support it.; RDNA3 does not offer v_dot8_i32_i4, and rather offers; v_dot4_i32_iu4 which has operands to hold the signedness of the; vector operands. Thus, this intrinsic lowers to the signed version; of this instruction for gfx11 targets. llvm.amdgcn.sudot4 Provides direct access to v_dot4_i32_iu8 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 4 8bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sudot8 Provides direct access to v_dot8_i32_iu4 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU in",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:41694,perform,performs,41694,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performs']
Performance," does not; itself cause dependence, but since generally the optimizer will not; be able to prove that the function doesn't depend on that parameter,; it will be forced to conservatively assume it does. Dependency propagates to values loaded from a pointer because those; values might be invalidated by deallocating the object. For; example, given the code ``__strong id x = p->ivar;``, ARC must not; move the release of ``p`` to between the load of ``p->ivar`` and the; retain of that value for storing into ``x``. Dependency does not propagate through stores of dependent pointer; values because doing so would allow dependency to outlive the; full-expression which produced the original value. For example, the; address of an instance variable could be written to some global; location and then freely accessed during the lifetime of the local,; or a function could return an inner pointer of an object and store; it to a local. These cases would be potentially impossible to; reason about and so would basically prevent any optimizations based; on imprecise lifetime. There are also uncommon enough to make it; reasonable to require the precise-lifetime annotation if someone; really wants to rely on them. Dependency does propagate through return values of pointer type.; The compelling source of need for this rule is a property accessor; which returns an un-autoreleased result; the calling function must; have the chance to operate on the value, e.g. to retain it, before; ARC releases the original pointer. Note again, however, that; dependence does not survive a store, so ARC does not guarantee the; continued validity of the return value past the end of the; full-expression. .. _arc.optimization.object_lifetime:. No object lifetime extension; ----------------------------. If, in the formal computation history of the program, an object ``X``; has been deallocated by the time of an observable side-effect, then; ARC must cause ``X`` to be deallocated by no later than the occurrence; of",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:81729,optimiz,optimizations,81729,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimizations']
Performance," dominate specific; uses. It is not meant for general use, only for building temporary; renaming forms that require value splits at certain points. .. _type.test:. '``llvm.type.test``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare i1 @llvm.type.test(ptr %ptr, metadata %type) nounwind memory(none). Arguments:; """""""""""""""""""". The first argument is a pointer to be tested. The second argument is a; metadata object representing a :doc:`type identifier <TypeMetadata>`. Overview:; """""""""""""""""". The ``llvm.type.test`` intrinsic tests whether the given pointer is associated; with the given type identifier. .. _type.checked.load:. '``llvm.type.checked.load``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare {ptr, i1} @llvm.type.checked.load(ptr %ptr, i32 %offset, metadata %type) nounwind memory(argmem: read). Arguments:; """""""""""""""""""". The first argument is a pointer from which to load a function pointer. The; second argument is the byte offset from which to load the function pointer. The; third argument is a metadata object representing a :doc:`type identifier; <TypeMetadata>`. Overview:; """""""""""""""""". The ``llvm.type.checked.load`` intrinsic safely loads a function pointer from a; virtual table pointer using type metadata. This intrinsic is used to implement; control flow integrity in conjunction with virtual call optimization. The; virtual call optimization pass will optimize away ``llvm.type.checked.load``; intrinsics associated with devirtualized calls, thereby removing the type; check in cases where it is not needed to enforce the control flow integrity; constraint. If the given pointer is associated with a type metadata identifier, this; function returns true as the second element of its return value. (Note that; the function may also return true if the given pointer is not associated; with a type metadata identifier.) If the function's return value's second; element is true, the following rules apply to the first element",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:938049,load,load,938049,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," don't; need strict IEEE floating point semantics, there are a number of additional; optimizations that can be performed. This can be highly impactful for; floating point intensive computations. Describing Aliasing Properties; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. #. Add noalias/align/dereferenceable/nonnull to function arguments and return; values as appropriate. #. Use pointer aliasing metadata, especially tbaa metadata, to communicate; otherwise-non-deducible pointer aliasing facts. #. Use inbounds on geps. This can help to disambiguate some aliasing queries. Undefined Values; ^^^^^^^^^^^^^^^^. #. Use poison values instead of undef values whenever possible. #. Tag function parameters with the noundef attribute whenever possible. Modeling Memory Effects; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Mark functions as readnone/readonly/argmemonly or noreturn/nounwind when; known. The optimizer will try to infer these flags, but may not always be; able to. Manual annotations are particularly important for external; functions that the optimizer can not analyze. #. Use the lifetime.start/lifetime.end and invariant.start/invariant.end; intrinsics where possible. Common profitable uses are for stack like data; structures (thus allowing dead store elimination) and for describing; life times of allocas (thus allowing smaller stack sizes). #. Mark invariant locations using !invariant.load and TBAA's constant flags. Pass Ordering; ^^^^^^^^^^^^^. One of the most common mistakes made by new language frontend projects is to; use the existing -O2 or -O3 pass pipelines as is. These pass pipelines make a; good starting point for an optimizing compiler for any language, but they have; been carefully tuned for C and C++, not your target language. You will almost; certainly need to use a custom pass order to achieve optimal performance. A; couple specific suggestions:. #. For languages with numerous rarely executed guard conditions (e.g. null; checks, type checks, range checks) consider adding an extra ex",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:11953,optimiz,optimizer,11953,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['optimiz'],['optimizer']
Performance," drawing.; 15. In main index.htm page browser can be disabled (nobrowser parameter) and; page can be used to display only specified items from the file; 16. Add support of TPolyMarker3D in binary I/O. ### September 2014; 1. First try to handle resize of the browser,; for the moment works only with collapsible layout; 2. Also first try to interactively move separation line between; browser and drawing field.; 3. Small fix of minor ticks drawing on the axis; 4. Introduce display class for MDI drawing. Provide two implementations -; 'collapsible' for old kind and 'tabs' for new kinds.; 5. Adjust size of color palette drawing when labels would take more place as provided.; 6. Add correct filling of statistic for TProfile,; fix small problem with underflow/overflow bins.; 7. Provide way to select display kind ('collapsible', 'tabs') in the simple GUI.; 8. Implement 'grid' display, one could specify any number of division like; 'grid 3x3' or 'grid 4x2'.; 9. MDI display object created at the moment when first draw is performed.; 10. Introduce painter class for TCanvas, support resize and update of canvas drawing; 11. Resize almost works for all layouts and all objects kinds.; 12. Implement JSROOT.GetUrlOption to extract options from document URL.; 13. Provide example fileitem.htm how read and display item from ROOT file.; 14. In default index.htm page one could specify 'file', 'layout',; 'item' and 'items' parameters like:; <http://root.cern.ch/js/3.0/index.htm?file=../files/hsimple.root&layout=grid3x2&item=hpx;1>; 15. Support direct reading of objects from sub-sub-directories.; 16. Introduce demo.htm, which demonstrates online usage of JSROOT.; 17. One could use demo.htm directly with THttpServer providing address like:; <http://localhost:8080/jsrootsys/demo/demo.htm?addr=../../Files/job1.root/hpx/root.json.gz&layout=3x3>; 18. Also for online server process url options like 'item', 'items', 'layout'; 19. Possibility to generate URL, which reproduces opened page with layout",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/js/changes.md:72758,perform,performed,72758,js/changes.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/js/changes.md,1,['perform'],['performed']
Performance," due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on in its; processing. Maybe that would stop things in time for the misspeculated path to; fail to leak any secrets. This doesn't end up working because the processor is; fundamentally out-of-order, even in its speculative domain. As a consequence,; the attacker could cause the initial address computation itself to stall and; allow an arbitrary number of unrelated loads (including attacked loads of; secret data) to pass through. #### Interprocedural Checking. Modern x86 processors may speculate into called functions and out of functions; to their return address. As a consequence, we need a way to check loads that; occur after a misspeculated predicate but where the load and the misspeculated; predicate are in different functions. In essence, we need some interprocedural; generalization of the predicate state tracking. A primary challenge to passing; the predicate state between functions is that we would like to not require a; change to the ABI or calling convention in order to make this mitigation more; deployable, and further would like code mitigated in this way to be easily; mixed with code not mitigated in this way and without completely losing the; value of the mitigation. ##### Embed the predicate state into the high bit(s) of the stack pointer. We can use the same technique that allows hardening pointers to pass the; predicate state into and out of functions. The stack pointer is trivially; passed between functions and we can test for it having the high bits set to; detect when it has been marked due to misspeculation. The callsite instruction; sequence looks like (assuming a misspeculated state value of `-1`):; ```; ..",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:37949,load,loads,37949,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,2,['load'],"['load', 'loads']"
Performance," due to importing all C++ Modules at startup; we see overhead which depends on the number of preloaded modules. For; ROOT it is between 40-60 MB depending on the concrete configuration.; When the workload increases we notice that the overall memory performance; decreases in number of cases.; * Execution times -- likewise we have an execution overhead. For ; workflows which take ms the slowdown can be 2x. Increasing of the work; to seconds shows 50-60% slowdowns. The performance is dependent on many factors such as configuration of ROOT and; workflow. You can read more at our Intel IPCC-ROOT Showcase presentation; here (pp 25-33)[[8]]. #### Loading C++ Modules on Demand. In long term, we should optimize the preloading of modules to be a no-op and; avoid recursive behavior based on identifier lookup callbacks. Unfortunately,; at the moment the loading of C++ modules on demand shows significantly better; performance results. You can visit our continuous performance monitoring tool where we compare; the performance of ROOT against ROOT with a PCH [[9]].; *Note: if you get error 400, clean your cache or open a private browser session.*. ## How to use; C++ Modules in ROOT are default since v6.20 (Unix) and v6.22 (OSX). Enjoy. To disable C++ Modules in ROOT use `-Druntime_cxxmodules=Off`. ## Citing ROOT's C++ Modules; ```latex; % Peer-Reviewed Publication; %; % 22nd International Conference on Computing in High Energy and Nuclear Physics (CHEP); % 8-14 October, 2016, San Francisco, USA; %; @inproceedings{Vassilev_ROOTModules,; author = {Vassilev,V.},; title = {{Optimizing ROOT's Performance Using C++ Modules}},; journal = {Journal of Physics: Conference Series},; year = 2017,; month = {oct},; volume = {898},; number = {7},; pages = {072023},; doi = {10.1088/1742-6596/898/7/072023},; url = {https://iopscience.iop.org/article/10.1088/1742-6596/898/7/072023/pdf},; publisher = {{IOP} Publishing}; }; ```; ; # Acknowledgement. We would like to thank the ROOT team. We would like ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md:19169,perform,performance,19169,README/README.CXXMODULES.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/README.CXXMODULES.md,2,['perform'],['performance']
Performance," elided. .. code-block:: llvm. entry:; %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null); %need.dyn.alloc = call i1 @llvm.coro.alloc(token %id); br i1 %need.dyn.alloc, label %dyn.alloc, label %coro.begin; dyn.alloc:; %size = call i32 @llvm.coro.size.i32(); %alloc = call ptr @CustomAlloc(i32 %size); br label %coro.begin; coro.begin:; %phi = phi ptr [ null, %entry ], [ %alloc, %dyn.alloc ]; %hdl = call noalias ptr @llvm.coro.begin(token %id, ptr %phi). In the cleanup block, we will make freeing the coroutine frame conditional on; `coro.free`_ intrinsic. If allocation is elided, `coro.free`_ returns `null`; thus skipping the deallocation code:. .. code-block:: llvm. cleanup:; %mem = call ptr @llvm.coro.free(token %id, ptr %hdl); %need.dyn.free = icmp ne ptr %mem, null; br i1 %need.dyn.free, label %dyn.free, label %if.end; dyn.free:; call void @CustomFree(ptr %mem); br label %if.end; if.end:; ... With allocations and deallocations represented as described as above, after; coroutine heap allocation elision optimization, the resulting main will be:. .. code-block:: llvm. define i32 @main() {; entry:; call void @print(i32 4); call void @print(i32 5); call void @print(i32 6); ret i32 0; }. Multiple Suspend Points; -----------------------. Let's consider the coroutine that has more than one suspend point:. .. code-block:: c++. void *f(int n) {; for(;;) {; print(n++);; <suspend>; print(-n);; <suspend>; }; }. Matching LLVM code would look like (with the rest of the code remaining the same; as the code in the previous section):. .. code-block:: llvm. loop:; %n.addr = phi i32 [ %n, %entry ], [ %inc, %loop.resume ]; call void @print(i32 %n.addr) #4; %2 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %2, label %suspend [i8 0, label %loop.resume; i8 1, label %cleanup]; loop.resume:; %inc = add nsw i32 %n.addr, 1; %sub = xor i32 %n.addr, -1; call void @print(i32 %sub); %3 = call i8 @llvm.coro.suspend(token none, i1 false); switch i8 %3, label %suspend",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst:17783,optimiz,optimization,17783,interpreter/llvm-project/llvm/docs/Coroutines.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Coroutines.rst,1,['optimiz'],['optimization']
Performance," ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 3. buffer/global_atomic; 4. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 5. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - global 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and L2 writeback; have completed before; performing the; a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:320671,load,load,320671,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," equivalent to an Acquire load, and a Monotonic store following a; Release fence is roughly equivalent to a Release; store. SequentiallyConsistent fences behave as both an Acquire and a; Release fence, and additionally provide a total ordering with some; complicated guarantees, see the C++ standard for details. Frontends generating atomic instructions generally need to be aware of the; target to some degree; atomic instructions are guaranteed to be lock-free, and; therefore an instruction which is wider than the target natively supports can be; impossible to generate. .. _Atomic orderings:. Atomic orderings; ================. In order to achieve a balance between performance and necessary guarantees,; there are six levels of atomicity. They are listed in order of strength; each; level includes all the guarantees of the previous level except for; Acquire/Release. (See also `LangRef Ordering <LangRef.html#ordering>`_.). .. _NotAtomic:. NotAtomic; ---------. NotAtomic is the obvious, a load or store which is not atomic. (This isn't; really a level of atomicity, but is listed here for comparison.) This is; essentially a regular load or store. If there is a race on a given memory; location, loads from that location return undef. Relevant standard; This is intended to match shared variables in C/C++, and to be used in any; other context where memory access is necessary, and a race is impossible. (The; precise definition is in `LangRef Memory Model <LangRef.html#memmodel>`_.). Notes for frontends; The rule is essentially that all memory accessed with basic loads and stores; by multiple threads should be protected by a lock or other synchronization;; otherwise, you are likely to run into undefined behavior. If your frontend is; for a ""safe"" language like Java, use Unordered to load and store any shared; variable. Note that NotAtomic volatile loads and stores are not properly; atomic; do not try to use them as a substitute. (Per the C/C++ standards,; volatile does provide som",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:6006,load,load,6006,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['load'],['load']
Performance," exactly the way you; want them. Write extensive tests to check that you're getting good; diagnostics for mistakes and that you can use various forms of; subexpressions with your expression.; * When type-checking a type or subexpression, make sure to first check; whether the type is ""dependent"" (``Type::isDependentType()``) or whether a; subexpression is type-dependent (``Expr::isTypeDependent()``). If any of; these return ``true``, then you're inside a template and you can't do much; type-checking now. That's normal, and your AST node (when you get there); will have to deal with this case. At this point, you can write tests that; use your expression within templates, but don't try to instantiate the; templates.; * For each subexpression, be sure to call ``Sema::CheckPlaceholderExpr()``; to deal with ""weird"" expressions that don't behave well as subexpressions.; Then, determine whether you need to perform lvalue-to-rvalue conversions; (``Sema::DefaultLvalueConversions``) or the usual unary conversions; (``Sema::UsualUnaryConversions``), for places where the subexpression is; producing a value you intend to use.; * Your ``BuildXXX`` function will probably just return ``ExprError()`` at; this point, since you don't have an AST. That's perfectly fine, and; shouldn't impact your testing. #. Introduce an AST node for your new expression. This starts with declaring; the node in ``include/Basic/StmtNodes.td`` and creating a new class for your; expression in the appropriate ``include/AST/Expr*.h`` header. It's best to; look at the class for a similar expression to get ideas, and there are some; specific things to watch for:. * If you need to allocate memory, use the ``ASTContext`` allocator to; allocate memory. Never use raw ``malloc`` or ``new``, and never hold any; resources in an AST node, because the destructor of an AST node is never; called.; * Make sure that ``getSourceRange()`` covers the exact source range of your; expression. This is needed for diagnostics and for ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:147524,perform,perform,147524,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['perform'],['perform']
Performance," execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must ha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:247323,load,load,247323,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,"['cache', 'load']","['cache', 'load']"
Performance," execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If not TgSplit execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_inv and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. buffer_wbl2 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:318984,perform,performing,318984,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance," execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If not TgSplit execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:268471,perform,performing,268471,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance," execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. fence acq_rel - system *none* 1. buffer_wbl2. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:276984,load,load,276984,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,"['cache', 'load']","['cache', 'load']"
Performance," expected value of ``val`` with probability(or confidence) ``prob``, which can; be used by optimizers. Arguments:; """""""""""""""""""". The ``llvm.expect.with.probability`` intrinsic takes three arguments. The first; argument is a value. The second argument is an expected value. The third; argument is a probability. Semantics:; """""""""""""""""""". This intrinsic is lowered to the ``val``. .. _int_assume:. '``llvm.assume``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void @llvm.assume(i1 %cond). Overview:; """""""""""""""""". The ``llvm.assume`` allows the optimizer to assume that the provided; condition is true. This information can then be used in simplifying other parts; of the code. More complex assumptions can be encoded as; :ref:`assume operand bundles <assume_opbundles>`. Arguments:; """""""""""""""""""". The argument of the call is the condition which the optimizer may assume is; always true. Semantics:; """""""""""""""""""". The intrinsic allows the optimizer to assume that the provided condition is; always true whenever the control flow reaches the intrinsic call. No code is; generated for this intrinsic, and instructions that contribute only to the; provided condition are not used for code generation. If the condition is; violated during execution, the behavior is undefined. Note that the optimizer might limit the transformations performed on values; used by the ``llvm.assume`` intrinsic in order to preserve the instructions; only used to form the intrinsic's input argument. This might prove undesirable; if the extra information provided by the ``llvm.assume`` intrinsic does not cause; sufficient overall improvement in code quality. For this reason,; ``llvm.assume`` should not be used to document basic mathematical invariants; that the optimizer can otherwise deduce or facts that are of little use to the; optimizer. .. _int_ssa_copy:. '``llvm.ssa.copy``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare type @llvm.ssa.copy(type returned %operand)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:935599,optimiz,optimizer,935599,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizer']
Performance," explanation about what we mean.; These features are:. End-User Features:. Fast compiles and low memory use; Expressive diagnostics; GCC compatibility. Utility and Applications:. Library based architecture; Support diverse clients; Integration with IDEs; Use the LLVM 'BSD' License. Internal Design and Implementation:. A real-world, production quality compiler; A simple and hackable code base; A single unified parser for C, Objective C, C++,; and Objective C++; Conformance with C/C++/ObjC and their; variants. End-User Features. Fast compiles and Low Memory Use. A major focus of our work on clang is to make it fast, light and scalable.; The library-based architecture of clang makes it straight-forward to time and; profile the cost of each layer of the stack, and the driver has a number of; options for performance analysis. Many detailed benchmarks can be found online.; Compile time performance is important, but when using clang as an API, often; memory use is even more so: the less memory the code takes the more code you can; fit into memory at a time (useful for whole program analysis tools, for; example).; In addition to being efficient when pitted head-to-head against GCC in batch; mode, clang is built with a library based; architecture that makes it relatively easy to adapt it and build new tools; with it. This means that it is often possible to apply out-of-the-box thinking; and novel techniques to improve compilation in various ways. Expressive Diagnostics. In addition to being fast and functional, we aim to make Clang extremely user; friendly. As far as a command-line compiler goes, this basically boils down to; making the diagnostics (error and warning messages) generated by the compiler; be as useful as possible. There are several ways that we do this, but the; most important are pinpointing exactly what is wrong in the program,; highlighting related information so that it is easy to understand at a glance,; and making the wording as clear as possible.; Here ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/features.html:1041,perform,performance,1041,interpreter/llvm-project/clang/www/features.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/features.html,1,['perform'],['performance']
Performance," express the unpredictability of control; flow. Similar to the llvm.expect intrinsic, it may be used to alter; optimizations related to compare and branch instructions. The metadata; is treated as a boolean value; if it exists, it signals that the branch; or switch that it is attached to is completely unpredictable. .. _md_dereferenceable:. '``dereferenceable``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The existence of the ``!dereferenceable`` metadata on the instruction; tells the optimizer that the value loaded is known to be dereferenceable,; otherwise the behavior is undefined.; The number of bytes known to be dereferenceable is specified by the integer; value in the metadata node. This is analogous to the ''dereferenceable''; attribute on parameters and return values. .. _md_dereferenceable_or_null:. '``dereferenceable_or_null``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The existence of the ``!dereferenceable_or_null`` metadata on the; instruction tells the optimizer that the value loaded is known to be either; dereferenceable or null, otherwise the behavior is undefined.; The number of bytes known to be dereferenceable is specified by the integer; value in the metadata node. This is analogous to the ''dereferenceable_or_null''; attribute on parameters and return values. .. _llvm.loop:. '``llvm.loop``'; ^^^^^^^^^^^^^^^. It is sometimes useful to attach information to loop constructs. Currently,; loop metadata is implemented as metadata attached to the branch instruction; in the loop latch block. The loop metadata node is a list of; other metadata nodes, each representing a property of the loop. Usually,; the first item of the property node is a string. For example, the; ``llvm.loop.unroll.count`` suggests an unroll factor to the loop; unroller:. .. code-block:: llvm. br i1 %exitcond, label %._crit_edge, label %.lr.ph, !llvm.loop !0; ...; !0 = !{!0, !1, !2}; !1 = !{!""llvm.loop.unroll.enable""}; !2 = !{!""llvm.loop.unroll.count"", i32 4}. For legacy reason",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:293245,optimiz,optimizer,293245,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,2,"['load', 'optimiz']","['loaded', 'optimizer']"
Performance," expression or statement needs to be introduced, along; with patterns to follow to ensure that the new expression or statement works; well across all of the C languages. We focus on expressions, but statements; are similar. #. Introduce parsing actions into the parser. Recursive-descent parsing is; mostly self-explanatory, but there are a few things that are worth keeping; in mind:. * Keep as much source location information as possible! You'll want it later; to produce great diagnostics and support Clang's various features that map; between source code and the AST.; * Write tests for all of the ""bad"" parsing cases, to make sure your recovery; is good. If you have matched delimiters (e.g., parentheses, square; brackets, etc.), use ``Parser::BalancedDelimiterTracker`` to give nice; diagnostics when things go wrong. #. Introduce semantic analysis actions into ``Sema``. Semantic analysis should; always involve two functions: an ``ActOnXXX`` function that will be called; directly from the parser, and a ``BuildXXX`` function that performs the; actual semantic analysis and will (eventually!) build the AST node. It's; fairly common for the ``ActOnCXX`` function to do very little (often just; some minor translation from the parser's representation to ``Sema``'s; representation of the same thing), but the separation is still important:; C++ template instantiation, for example, should always call the ``BuildXXX``; variant. Several notes on semantic analysis before we get into construction; of the AST:. * Your expression probably involves some types and some subexpressions.; Make sure to fully check that those types, and the types of those; subexpressions, meet your expectations. Add implicit conversions where; necessary to make sure that all of the types line up exactly the way you; want them. Write extensive tests to check that you're getting good; diagnostics for mistakes and that you can use various forms of; subexpressions with your expression.; * When type-checking a type",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst:145872,perform,performs,145872,interpreter/llvm-project/clang/docs/InternalsManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/InternalsManual.rst,1,['perform'],['performs']
Performance," fMyInt3; Char_t fMyCode[4]; };"" );. from ROOT import MyStruct; mystruct = MyStruct(); f = TFile('mytree.root','RECREATE'); tree = TTree('T','Just A Tree'); tree.Branch('myints',mystruct,'MyInt1/I:MyInt2:MyInt3'); tree.Branch('mycode',AddressOf(mystruct,'fMyCode'),'MyCode/C'); for i in range(0,10):; mystruct.fMyInt1 = i; mystruct.fMyInt2 = i*i; mystruct.fMyInt3 = i*i*i; mystruct.fMyCode = ""%03d"" % i # note string assignment. tree.Fill(). f.Write(); f.Close(); ```. The C++ class is defined through the `gROOT.ProcessLine()` call, and; note how the `AddressOf()` function is used for data members of built-in; type. Most of the above is for ROOT version 5.02 and later only. For; older releases, and without further support, here is an example as to; how you can get hold of a pointer-to-pointer to a ROOT object:. ``` {.cpp}; h = TH1F(); addressofobject = array('i',[h.IsA().DynamicCast(h.IsA(),h)]); ```. ### Using Your Own Classes. A user's own classes can be accessed after loading, either directly or; indirectly, the library that contains the dictionary. One easy way of; obtaining such a library, is by using ACLiC:. ``` {.cpp}; $ cat MyClass.C; class MyClass {; public:. MyClass(int value = 0) {; m_value = value;; }. void SetValue(int value) {; m_value = value;; }. int GetValue() {; return m_value;; }. private:; int m_value;; };. $ echo .L MyClass.C+ | root.exe -b; [...]; Info in <TUnixSystem::ACLiC>: creating shared library [..]/./MyClass_C.so; $; ```. Then you can use it, for example, like so:. ``` {.cpp}; from ROOT import gSystem. # load library with MyClass dictionary; gSystem.Load('MyClass_C'). # get MyClass from ROOT; from ROOT import MyClass; # use MyClass; m = MyClass(42); print(m.GetValue()); ```. You can also load a macro directly, but if you do not use ACLiC, you; will be restricted to use the default constructor of your class, which; is otherwise fully functional. For example:. ``` {.cpp}; from ROOT import gROOT. # load MyClass definition macro (append '+' to us",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md:32569,load,loading,32569,documentation/users-guide/PythonRuby.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/PythonRuby.md,1,['load'],['loading']
Performance," fast selectors share the :ref:`pipeline`, and targets can; configure that pipeline to better suit their needs. Design and Implementation Reference; ===================================. More information on the design and implementation of GlobalISel can be found in; the following sections. .. toctree::; :maxdepth: 1. GMIR; GenericOpcode; MIRPatterns; Pipeline; Porting; Resources. More information on specific passes can be found in the following sections:. .. toctree::; :maxdepth: 1. IRTranslator; Legalizer; RegBankSelect; InstructionSelect; KnownBits. .. _progress:. Progress and Future Work; ========================. The initial goal is to replace FastISel on AArch64. The next step will be to; replace SelectionDAG as the optimized ISel. ``NOTE``:; While we iterate on GlobalISel, we strive to avoid affecting the performance of; SelectionDAG, FastISel, or the other MIR passes. For instance, the types of; :ref:`gmir-gvregs` are stored in a separate table in ``MachineRegisterInfo``,; that is destroyed after :ref:`instructionselect`. .. _progress-fastisel:. FastISel Replacement; --------------------. For the initial FastISel replacement, we intend to fallback to SelectionDAG on; selection failures. Currently, compile-time of the fast pipeline is within 1.5x of FastISel.; We're optimistic we can get to within 1.1/1.2x, but beating FastISel will be; challenging given the multi-pass approach.; Still, supporting all IR (via a complete legalizer) and avoiding the fallback; to SelectionDAG in the worst case should enable better amortized performance; than SelectionDAG+FastISel. ``NOTE``:; We considered never having a fallback to SelectionDAG, instead deciding early; whether a given function is supported by GlobalISel or not. The decision would; be based on :ref:`milegalizer` queries.; We abandoned that for two reasons:; a) on IR inputs, we'd need to basically simulate the :ref:`irtranslator`;; b) to be robust against unforeseen failures and to enable iterative; improvements.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst:2832,perform,performance,2832,interpreter/llvm-project/llvm/docs/GlobalISel/index.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst,1,['perform'],['performance']
Performance," faster than the usual; shape-to-shape comparison. For a 100% reliability, one can perform the; check at the level of a single volume by using `option`=""`d`"" or; `option`=""`d<number>`"" to perform overlap checking by sampling the; volume with \<`number`\> random points (default 1 million). This; produces also a picture showing in red the overlapping region and; estimates the volume of the overlaps. An extrusion *A)* is declared in any of the following cases:. - At least one of the vertices of the daughter mesh representation is; outside the mother volume (in fact its shape) and having a safety; distance to the mother greater than the desired value;; - At least one of the mother vertices is contained also by one of its; daughters, in the same conditions. An overlap *B)* is declared if:. - At least one vertex of a positioned volume mesh is contained (having; a safety bigger than the accepted maximum value) by other positioned; volume inside the same container. The check is performed also by; inverting the candidates. The code is highly optimized to avoid checking candidates that are far; away in space by performing a fast check on their bounding boxes. Once; the checking tool is fired-up inside a volume or at top level, the list; of overlaps (visible as Illegal overlaps inside a TBrowser) held; by the manager class will be filled with TGeoOverlap objects; containing a full description of the detected overlaps. The list is; sorted in the decreasing order of the overlapping distance, extrusions; coming first. An overlap object name represents the full description of; the overlap, containing both candidate node names and a letter; (x-extrusion, o-overlap) representing the type. Double-clicking an; overlap item in a TBrowser produces a picture of the overlap; containing only the two overlapping nodes (one in blue and one in green); and having the critical vertices represented by red points. The picture; can be rotated/zoomed or drawn in X3d as any other view. Calling; gGeo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:94662,perform,performed,94662,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['performed']
Performance," faster, because we are using a ""smarter"" IR (SSA based). > BTW, about SGI, ""borrowing"" SSA-based optimizations from one compiler and; > putting it into another is not necessarily easier than re-doing it.; > Optimization code is usually heavily tied in to the specific IR they use. Understood. The only reason that I brought this up is because SGI's IR is; more similar to LLVM than it is different in many respects (SSA based,; relatively low level, etc), and could be easily adapted. Also their; optimizations are written in C++ and are actually somewhat; structured... of course it would be no walk in the park, but it would be; much less time consuming to adapt, say, SSA-PRE than to rewrite it. > But your larger point is valid that adding SSA based optimizations is; > feasible and should be fun. (Again, link time cost is the issue.). Assuming linktime cost wasn't an issue, the question is: ; Does using GCC's backend buy us anything?. > It also occurs to me that GCC is probably doing quite a bit of back-end; > optimization (step 16 in your list). Do you have a breakdown of that?. Not really. The irritating part of GCC is that it mixes it all up and; doesn't have a clean separation of concerns. A lot of the ""back end; optimization"" happens right along with other data optimizations (ie, CSE; of machine specific things). As far as REAL back end optimizations go, it looks something like this:. 1. Instruction combination: try to make CISCy instructions, if available; 2. Register movement: try to get registers in the right places for the; architecture to avoid register to register moves. For example, try to get; the first argument of a function to naturally land in %o0 for sparc.; 3. Instruction scheduling: 'nuff said :); 4. Register class preferencing: ??; 5. Local register allocation; 6. global register allocation; 7. Spilling; 8. Local regalloc; 9. Jump optimization; 10. Delay slot scheduling; 11. Branch shorting for CISC machines; 12. Instruction selection & peephole optim",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt:1877,optimiz,optimization,1877,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-06-01-GCCOptimizations2.txt,1,['optimiz'],['optimization']
Performance," faster, to push eax on entry and to; pop into a dummy register instead of using addl/subl of esp. Just don't pop ; into any return registers :). //===---------------------------------------------------------------------===//. The X86 backend should fold (branch (or (setcc, setcc))) into multiple ; branches. We generate really poor code for:. double testf(double a) {; return a == 0.0 ? 0.0 : (a > 0.0 ? 1.0 : -1.0);; }. For example, the entry BB is:. _testf:; subl $20, %esp; pxor %xmm0, %xmm0; movsd 24(%esp), %xmm1; ucomisd %xmm0, %xmm1; setnp %al; sete %cl; testb %cl, %al; jne LBB1_5 # UnifiedReturnBlock; LBB1_1: # cond_true. it would be better to replace the last four instructions with:. 	jp LBB1_1; 	je LBB1_5; LBB1_1:. We also codegen the inner ?: into a diamond:. cvtss2sd LCPI1_0(%rip), %xmm2; cvtss2sd LCPI1_1(%rip), %xmm3; ucomisd %xmm1, %xmm0; ja LBB1_3 # cond_true; LBB1_2: # cond_true; movapd %xmm3, %xmm2; LBB1_3: # cond_true; movapd %xmm2, %xmm0; ret. We should sink the load into xmm3 into the LBB1_2 block. This should; be pretty easy, and will nuke all the copies. //===---------------------------------------------------------------------===//. This:; #include <algorithm>; inline std::pair<unsigned, bool> full_add(unsigned a, unsigned b); { return std::make_pair(a + b, a + b < a); }; bool no_overflow(unsigned a, unsigned b); { return !full_add(a, b).second; }. Should compile to:; 	addl	%esi, %edi; 	setae	%al; 	movzbl	%al, %eax; 	ret. on x86-64, instead of the rather stupid-looking:; 	addl	%esi, %edi; 	setb	%al; 	xorb	$1, %al; 	movzbl	%al, %eax; 	ret. //===---------------------------------------------------------------------===//. The following code:. bb114.preheader:		; preds = %cond_next94; 	%tmp231232 = sext i16 %tmp62 to i32		; <i32> [#uses=1]; 	%tmp233 = sub i32 32, %tmp231232		; <i32> [#uses=1]; 	%tmp245246 = sext i16 %tmp65 to i32		; <i32> [#uses=1]; 	%tmp252253 = sext i16 %tmp68 to i32		; <i32> [#uses=1]; 	%tmp254 = sub i32 32, %tmp252253		; <i32> [#use",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:14444,load,load,14444,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,1,['load'],['load']
Performance," fields. * ``string FilterClass``. The table will have one entry for each record; that derives from this class. * ``string FilterClassField``. This is an optional field of ``FilterClass``; which should be `bit` type. If specified, only those records with this field; being true will have corresponding entries in the table. This field won't be; included in generated C++ fields if it isn't included in ``Fields`` list. * ``string CppTypeName``. The name of the C++ struct/class type of the; table that holds the entries. If unspecified, the ``FilterClass`` name is; used. * ``list<string> Fields``. A list of the names of the fields *in the; collected records* that contain the data for the table entries. The order of; this list determines the order of the values in the C++ initializers. See; below for information about the types of these fields. * ``list<string> PrimaryKey``. The list of fields that make up the; primary key. * ``string PrimaryKeyName``. The name of the generated C++ function; that performs a lookup on the primary key. * ``bit PrimaryKeyEarlyOut``. See the third example below. TableGen attempts to deduce the type of each of the table fields so that it; can format the C++ initializers in the emitted table. It can deduce ``bit``,; ``bits<n>``, ``string``, ``Intrinsic``, and ``Instruction``. These can be; used in the primary key. Any other field types must be specified; explicitly; this is done as shown in the second example below. Such fields; cannot be used in the primary key. One special case of the field type has to do with code. Arbitrary code is; represented by a string, but has to be emitted as a C++ initializer without; quotes. If the code field was defined using a code literal (``[{...}]``),; then TableGen will know to emit it without quotes. However, if it was; defined using a string literal or complex string expression, then TableGen; will not know. In this case, you can force TableGen to treat the field as; code by including the following line in the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst:24211,perform,performs,24211,interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGen/BackEnds.rst,1,['perform'],['performs']
Performance," file of source code). So the first thing we need to do is; construct one for our fib.ks file. DWARF Emission Setup; ====================. Similar to the ``IRBuilder`` class we have a; `DIBuilder <https://llvm.org/doxygen/classllvm_1_1DIBuilder.html>`_ class; that helps in constructing debug metadata for an LLVM IR file. It; corresponds 1:1 similarly to ``IRBuilder`` and LLVM IR, but with nicer names.; Using it does require that you be more familiar with DWARF terminology than; you needed to be with ``IRBuilder`` and ``Instruction`` names, but if you; read through the general documentation on the; `Metadata Format <https://llvm.org/docs/SourceLevelDebugging.html>`_ it; should be a little more clear. We'll be using this class to construct all; of our IR level descriptions. Construction for it takes a module so we; need to construct it shortly after we construct our module. We've left it; as a global static variable to make it a bit easier to use. Next we're going to create a small container to cache some of our frequent; data. The first will be our compile unit, but we'll also write a bit of; code for our one type since we won't have to worry about multiple typed; expressions:. .. code-block:: c++. static std::unique_ptr<DIBuilder> DBuilder;. struct DebugInfo {; DICompileUnit *TheCU;; DIType *DblTy;. DIType *getDoubleTy();; } KSDbgInfo;. DIType *DebugInfo::getDoubleTy() {; if (DblTy); return DblTy;. DblTy = DBuilder->createBasicType(""double"", 64, dwarf::DW_ATE_float);; return DblTy;; }. And then later on in ``main`` when we're constructing our module:. .. code-block:: c++. DBuilder = std::make_unique<DIBuilder>(*TheModule);. KSDbgInfo.TheCU = DBuilder->createCompileUnit(; dwarf::DW_LANG_C, DBuilder->createFile(""fib.ks"", "".""),; ""Kaleidoscope Compiler"", false, """", 0);. There are a couple of things to note here. First, while we're producing a; compile unit for a language called Kaleidoscope we used the language; constant for C. This is because a debugger wouldn't necess",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst:6740,cache,cache,6740,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl09.rst,1,['cache'],['cache']
Performance," file. CASE 3 : autof = 0; The AutoFlush mechanism is disabled. Flushing the buffers at regular intervals optimize the location of; consecutive entries on the disk. Changed the default value of AutoSave from 10 to 30 MBytes. New class TTreePerfStats; This new class is an important tool to measure the I/O performance of a Tree.; It shows the locations in the file when reading a Tree. In particular it is easy; to see the performance of the Tree Cache. The results can be:. drawn in a canvas.; printed on standard output.; saved to a file for processing later. Example of use; {; TFile *f = TFile::Open(""RelValMinBias-GEN-SIM-RECO.root"");; T = (TTree*)f->Get(""Events"");; Long64_t nentries = T->GetEntries();; T->SetCacheSize(10000000);; T->AddBranchToCache(""*"");. TTreePerfStats *ps= new TTreePerfStats(""ioperf"",T);. for (Int_t i=0;i<nentries;i++) {; T->GetEntry(i);; }; ps->SaveAs(""atlas_perf.root"");; }. then, in a root interactive session, one can do:. root > TFile f(""atlas_perf.root"");; root > ioperf->Draw();; root > ioperf->Print();. The Draw or Print functions print the following information:. TreeCache = TTree cache size in MBytes; N leaves = Number of leaves in the TTree; ReadTotal = Total number of zipped bytes read; ReadUnZip = Total number of unzipped bytes read; ReadCalls = Total number of disk reads; ReadSize = Average read size in KBytes; Readahead = Readahead size in KBytes; Readextra = Readahead overhead in percent; Real Time = Real Time in seconds; CPU Time = CPU Time in seconds; Disk Time = Real Time spent in pure raw disk IO; Disk IO = Raw disk IO speed in MBytes/second; ReadUZRT = Unzipped MBytes per RT second; ReadUZCP = Unipped MBytes per CP second; ReadRT = Zipped MBytes per RT second; ReadCP = Zipped MBytes per CP second. The Figure below shows the result for an original non optimized file when; the Tree Cache is not used. The Figure below shows the result for the above data file written with the; new version of ROOT and when the Tree cache is activated. ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:8067,cache,cache,8067,tree/doc/v526/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html,3,"['cache', 'optimiz']","['cache', 'optimized']"
Performance," file. You should also write; additional code for a subclass of the ``TargetRegisterInfo`` class that; represents the class register file data used for register allocation and also; describes the interactions between registers. * Describe the instruction set of the target. Use TableGen to generate code; for target-specific instructions from target-specific versions of; ``TargetInstrFormats.td`` and ``TargetInstrInfo.td``. You should write; additional code for a subclass of the ``TargetInstrInfo`` class to represent; machine instructions supported by the target machine. * Describe the selection and conversion of the LLVM IR from a Directed Acyclic; Graph (DAG) representation of instructions to native target-specific; instructions. Use TableGen to generate code that matches patterns and; selects instructions based on additional information in a target-specific; version of ``TargetInstrInfo.td``. Write code for ``XXXISelDAGToDAG.cpp``,; where ``XXX`` identifies the specific target, to perform pattern matching and; DAG-to-DAG instruction selection. Also write code in ``XXXISelLowering.cpp``; to replace or remove operations and data types that are not supported; natively in a SelectionDAG. * Write code for an assembly printer that converts LLVM IR to a GAS format for; your target machine. You should add assembly strings to the instructions; defined in your target-specific version of ``TargetInstrInfo.td``. You; should also write code for a subclass of ``AsmPrinter`` that performs the; LLVM-to-assembly conversion and a trivial subclass of ``TargetAsmInfo``. * Optionally, add support for subtargets (i.e., variants with different; capabilities). You should also write code for a subclass of the; ``TargetSubtarget`` class, which allows you to use the ``-mcpu=`` and; ``-mattr=`` command-line options. * Optionally, add JIT support and create a machine code emitter (subclass of; ``TargetJITInfo``) that is used to emit binary code directly into memory. In the ``.cpp`` and ``.h``.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:4662,perform,perform,4662,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['perform'],['perform']
Performance," files opened even further. Update hadd and TFileMerger so that they prefix all their information message; with their names (when running hadd, the TFileMerger message are prefixed by hadd):. $ hadd -v 0 -f output.root input1.root input2.root; $ hadd -v 1 -f output.root input1.root input2.root; hadd merged 2 input files in output.root.; $ hadd -v 2 -f output.root input1.root input2.root; hadd target file: output.root; hadd Source file 1: input1.root; hadd Source file 2: input2.root; hadd Target path: output.root:/. Introduce non-static version of TFile::Cp allows the copy of; an existing TFile object. Introduce new explicit interface for providing reseting; capability after a merge. If a class has a method with; the name and signature:. void ResetAfterMerge(TFileMergeInfo*);. it will be used by a TMemFile to reset its objects after; a merge operation has been done. If this method does not exist, the TClass will use; a method with the name and signature:. void Reset(Optiont_t *);. TClass now provides a quick access to these merging; function via TClass::GetResetAfterMerge. The wrapper function; is automatically created by rootcint and can be installed; via TClass::SetResetAfterMerge. The wrapper function should have; the signature/type ROOT::ResetAfterMergeFunc_t:. void (*)(void *thisobj, TFileMergeInfo*);. ResetAfterMerge functions were added to the following classes:; TDirectoryFile, TMemFile, TTree, TChain, TBranch, TBranchElement,; TBranchClones, TBranchObject and TBranchRef. Avoid leaking the inner object in a container like vector<vector<MyClass*> > ; and vector<vector<MyClass*> *> . Put in place the infrastructure to optimize the I/O writes in the same way we optimized the I/O reads. Add the function TBuffer::AutoExpand to centralize the automatic; buffer extension policy. This enable the ability to tweak it later; (for example instead of always doubling the size, increasing by; only at most 2Mb or take hints from the number of entries already; in a TBasket). ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/io/doc/v532/index.html:9408,optimiz,optimize,9408,io/doc/v532/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/io/doc/v532/index.html,2,['optimiz'],"['optimize', 'optimized']"
Performance," first-level; instrumentation, by making sure that the number of times we took an; exit edge from the hot trace is less than 10% of the number of; iterations. LLC has been taught to recognize llvm_first_trigger() calls and NOT; generate saves and restores of caller-saved registers around these; calls. Phase behavior; --------------. We turn off llvm_first_trigger() calls with NOPs, but this would hide; phase behavior from us (when some funcs/traces stop being hot and; others become hot.). We have a SIGALRM timer that counts time for us. Every time we get a; SIGALRM we look at our priority queue of locations where we have; removed llvm_first_trigger() calls. Each location is inserted along; with a time when we will next turn instrumentation back on for that; call site. If the time has arrived for a particular call site, we pop; that off the prio. queue and turn instrumentation back on for that; call site. Generating traces; -----------------. When we finally generate an optimized trace we first copy the code; into the trace cache. This leaves us with 3 copies of the code: the; original code, the instrumented code, and the optimized trace. The; optimized trace does not have instrumentation. The original code and; the instrumented code are modified to have a branch to the trace; cache, where the optimized traces are kept. We copy the code from the original to the instrumentation version; by tracing the LLVM-to-Machine code basic block map and then copying; each machine code basic block we think is in the hot region into the; trace cache. Then we instrument that code. The process is similar for; generating the final optimized trace; we copy the same basic blocks; because we might need to put in fixup code for exit BBs. LLVM basic blocks are not typically used in the Reoptimizer except; for the mapping information. We are restricted to using single instructions to branch between the; original code, trace, and instrumented code. So we have to keep the; code copies in memo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2003-06-25-Reoptimizer1.txt:3504,optimiz,optimized,3504,interpreter/llvm-project/llvm/docs/HistoricalNotes/2003-06-25-Reoptimizer1.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2003-06-25-Reoptimizer1.txt,2,"['cache', 'optimiz']","['cache', 'optimized']"
Performance," fixed-width vectors is still to use a shufflevector, as that may allow for more; optimization opportunities. For example:. .. code-block:: text. llvm.experimental.vector.splice(<A,B,C,D>, <E,F,G,H>, 1); ==> <B, C, D, E> index; llvm.experimental.vector.splice(<A,B,C,D>, <E,F,G,H>, -3); ==> <B, C, D, E> trailing elements. Arguments:; """""""""""""""""""". The first two operands are vectors with the same type. The start index is imm; modulo the runtime number of elements in the source vector. For a fixed-width; vector <N x eltty>, imm is a signed integer constant in the range; -N <= imm < N. For a scalable vector <vscale x N x eltty>, imm is a signed; integer constant in the range -X <= imm < X where X=vscale_range_min * N. '``llvm.experimental.stepvector``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This is an overloaded intrinsic. You can use ``llvm.experimental.stepvector``; to generate a vector whose lane values comprise the linear sequence; <0, 1, 2, ...>. It is primarily intended for scalable vectors. ::. declare <vscale x 4 x i32> @llvm.experimental.stepvector.nxv4i32(); declare <vscale x 8 x i16> @llvm.experimental.stepvector.nxv8i16(). The '``llvm.experimental.stepvector``' intrinsics are used to create vectors; of integers whose elements contain a linear sequence of values starting from 0; with a step of 1. This experimental intrinsic can only be used for vectors; with integer elements that are at least 8 bits in size. If the sequence value; exceeds the allowed limit for the element type then the result for that lane is; undefined. These intrinsics work for both fixed and scalable vectors. While this intrinsic; is marked as experimental, the recommended way to express this operation for; fixed-width vectors is still to generate a constant vector instead. Arguments:; """""""""""""""""""". None. '``llvm.experimental.get.vector.length``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:672621,scalab,scalable,672621,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['scalab'],['scalable']
Performance," fixes and improvements in the PROOF system occured since the release of 5.34/00 are available both in the latest 5.34 tags and in 6.00/00.; The following is a summary of the major modifications since 5.34 . ### New developments/functionality. - Several improvements in the merging phase; in particular:; - Modification of output sending protocol to control memory usage, significantly reducing the memory footprint on the master, in particular when merging; large numbers of histograms.; - Use an hash table for the output list to significantly speed up names lookups during merging.; - Add support for dynamic addition of workers to a currently running process (currently supported by the unit packetizer).; - Automatization of the usage of file-based technology to handle outputs.; - [Improved dataset management model](https://root.cern/doc/v628/classTDataSetManagerAliEn.html); where the PROOF (ROOT) dataset manager is a light frontend to the experiment file catalogs; TDataSetManagerFile is still; used as local cache of the experiment information or to store the work-in-progress status of the dataset manager daemon. This model addresses the scalability issues observed at ALICE AFs.; - Improvements in [TProofBench](https://root.cern.ch/doc/master/classTProofBench.html):; - Recording and display of the maximum rate during query, CPU efficiency calculation for PROOF-Lite runs, better measurement of wall time.; - Support for dynamic startup mode. - Test program xpdtest to test the status of xproofd (see also man page under $ROOTSYS/man/man1):. ``` {.sh}; $ xpdtest [options]; --help, -h; Gives a short list of options avaliable, and exit; -t <test>; type of test to be run:; 0 ping the daemon (includes process existence check if pid specified; see below); 1 ping the daemon and check connection for default user; 2 ping the daemon and check connection for the default user and all recent users; ...; ```; - Interface with **igprof** for fast statistic profiling. Like valgrind, it can b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md:1043,cache,cache,1043,proof/doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v600/index.md,1,['cache'],['cache']
Performance," float> poison. .. _int_vp_roundeven:. '``llvm.vp.roundeven.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.roundeven.v16f32 (<16 x float> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.roundeven.nxv4f32 (<vscale x 4 x float> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.roundeven.v256f64 (<256 x double> <op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point roundeven of a vector of floating-point values. Arguments:; """""""""""""""""""". The first operand and the result have the same vector of floating-point type.; The second operand is the vector mask and has the same number of elements as the; result vector type. The third operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.roundeven``' intrinsic performs floating-point roundeven; (:ref:`roundeven <int_roundeven>`) of the first vector operand on each enabled; lane. The result on disabled lanes is a :ref:`poison value <poisonvalues>`. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x float> @llvm.vp.roundeven.v4f32(<4 x float> %a, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x float> @llvm.roundeven.v4f32(<4 x float> %a); %also.r = select <4 x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_roundtozero:. '``llvm.vp.roundtozero.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.roundtozero.v16f32 (<16 x float> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.roundtozero.nxv4f32 (<vscale x 4 x float> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.roundtozero.v256f64 (<256 x double> <op>, <256 x i1> <mask>, i32 <vector_length>). Overview",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:829308,perform,performs,829308,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," following C-pseudo-code representing the core idea of a; predicate guarding potentially invalid loads:; ```; void leak(int data);; void example(int* pointer1, int* pointer2) {; if (condition) {; // ... lots of code ...; leak(*pointer1);; } else {; // ... more code ...; leak(*pointer2);; }; }; ```. This would get transformed into something resembling the following:; ```; uintptr_t all_ones_mask = std::numerical_limits<uintptr_t>::max();; uintptr_t all_zeros_mask = 0;; void leak(int data);; void example(int* pointer1, int* pointer2) {; uintptr_t predicate_state = all_ones_mask;; if (condition) {; // Assuming ?: is implemented using branchless logic...; predicate_state = !condition ? all_zeros_mask : predicate_state;; // ... lots of code ...; //; // Harden the pointer so it can't be loaded; pointer1 &= predicate_state;; leak(*pointer1);; } else {; predicate_state = condition ? all_zeros_mask : predicate_state;; // ... more code ...; //; // Alternative: Harden the loaded value; int value2 = *pointer2 & predicate_state;; leak(value2);; }; }; ```. The result should be that if the `if (condition) {` branch is mis-predicted,; there is a *data* dependency on the condition used to zero out any pointers; prior to loading through them or to zero out all of the loaded bits. Even; though this code pattern may still execute speculatively, *invalid* speculative; executions are prevented from leaking secret data from memory (but note that; this data might still be loaded in safe ways, and some regions of memory are; required to not hold secrets, see below for detailed limitations). This; approach only requires the underlying hardware have a way to implement a; branchless and unpredicted conditional update of a register's value. All modern; architectures have support for this, and in fact such support is necessary to; correctly implement constant time cryptographic primitives. Crucial properties of this approach:; * It is not preventing any particular side-channel from working. This ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:4163,load,loaded,4163,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['loaded']
Performance," following MIR:. .. code-block:: text. %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; DBG_VALUE %7, $noreg, !5, !6. In this circumstance LLVM would leave the MIR as shown above. Were we to move; the DBG_VALUE of virtual register %7 upwards with the SUB32rr, we would re-order; assignments and introduce a new state of the program. Whereas with the solution; above, the debugger will see one fewer combination of variable values, because; ``!3`` and ``!5`` will change value at the same time. This is preferred over; misrepresenting the original program. In comparison, if one sunk the MOV32rm, LLVM would produce the following:. .. code-block:: text. DBG_VALUE $noreg, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; DBG_VALUE %7, $noreg, !5, !6; %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2. Here, to avoid presenting a state in which the first assignment to ``!1``; disappears, the DBG_VALUE at the top of the block assigns the variable the; undefined location, until its value is available at the end of the block where; an additional DBG_VALUE is added. Were any other DBG_VALUE for ``!1`` to occur; in the instructions that the MOV32rm was sunk past, the DBG_VALUE for ``%1``; would be dropped and the debugger would never observe it in the variable. This; accurately reflects that the value is not available during the corresponding; portion of the original program. Variable locations during Register Allocation; ---------------------------------------------. To avoid debug instructions interfering with the register allocator, the; LiveDebugVariables pass extracts variable locations from a MIR function a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:34922,load,load,34922,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['load'],['load']
Performance," following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before inv",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:247467,load,load,247467,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. GFX940, GFX941; - wavefront - generic buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store. store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. GFX940, GFX941; buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store; sc0=1; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. buffer_wbl2 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:307460,perform,performing,307460,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance," following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:227731,load,load,227731,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol.; - Ensures the atomicrmw; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; fol",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:248469,cache,caches,248469,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['caches']
Performance," foo2(void);; extern void foo4(void);. --- a.c ---; #include ""a.h"". static signed int i = 0;. void foo2(void) {; i = -1;; }. static int foo3() {; foo4();; return 10;; }. int foo1(void) {; int data = 0;. if (i < 0); data = foo3();. data = data + 42;; return data;; }. --- main.c ---; #include <stdio.h>; #include ""a.h"". void foo4(void) {; printf(""Hi\n"");; }. int main() {; return foo1();; }. To compile, run:. .. code-block:: console. % clang -flto -c a.c -o a.o # <-- a.o is LLVM bitcode file; % clang -c main.c -o main.o # <-- main.o is native object file; % clang -flto a.o main.o -o main # <-- standard link command with -flto. * In this example, the linker recognizes that ``foo2()`` is an externally; visible symbol defined in LLVM bitcode file. The linker completes its usual; symbol resolution pass and finds that ``foo2()`` is not used; anywhere. This information is used by the LLVM optimizer and it; removes ``foo2()``. * As soon as ``foo2()`` is removed, the optimizer recognizes that condition ``i; < 0`` is always false, which means ``foo3()`` is never used. Hence, the; optimizer also removes ``foo3()``. * And this in turn, enables linker to remove ``foo4()``. This example illustrates the advantage of tight integration with the; linker. Here, the optimizer can not remove ``foo3()`` without the linker's; input. Alternative Approaches; ----------------------. **Compiler driver invokes link time optimizer separately.**; In this model the link time optimizer is not able to take advantage of; information collected during the linker's normal symbol resolution phase.; In the above example, the optimizer can not remove ``foo2()`` without the; linker's input because it is externally visible. This in turn prohibits the; optimizer from removing ``foo3()``. **Use separate tool to collect symbol information from all object files.**; In this model, a new, separate, tool or library replicates the linker's; capability to collect information for link time optimization. Not only is; thi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst:2839,optimiz,optimizer,2839,interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LinkTimeOptimization.rst,1,['optimiz'],['optimizer']
Performance," for comments. > The configuration file is automatically checked at each loop: this; > means you can change configuration without restarting the daemon or; > stopping your current transfers. A detailed description of each directive follows. set *VARIABLE=value*; : This statement will substitute every occurrence of `$VARIABLE` with; its *value* in the rest of the configuration file. You can have; multiple `set` statements. xpd.stagereqrepo [dir:]*directory*; : This directive is shared with PROOF: *directory* is the full path to; the dataset repository. **Defaults to empty:** without this; directive the daemon is not operative. The `dir:` prefix is optional. dsmgrd.purgenoopds *true|false*; : Set it to *true* **(default is false)** to remove a dataset when no file to stage; is found. If no file to stage is found, but corrupted files exist, the; dataset is kept to signal failures. Used in combination with `xpd.stagereqrepo`; makes it ""disposable"": only the datasets effectively needed for signaling; the staging status will be kept, improving scalability and stability. dsmgrd.urlregex *regex* *subst*; : Each source URL present in the datasets will be matched to *regex*; and substituted to *subst*. *regex* supports grouping using; parentheses, and groups can be referenced in order using the dollar; sign with a number (`$1` for instance) in *subst*. Matching and substitution for multiple URL schemas are supported by; using in addition directives `dsmgrd.urlregex2` up to; `dsmgrd.urlregex4` which have the same syntax of this one. Example of URL translation via regexp:. > - Configuration line:; >; > dsmgrd.urlregex alien://(.*)$ root://xrd.cern.ch/$1; >; > - Source URL:; >; > alien:///alice/data/2012/LHC12b/000178209/ESDs/pass1/12000178209061.17/AliESDs.root; >; > - Resulting URL:; >; > root://xrd.cern.ch//alice/data/2012/LHC12b/000178209/ESDs/pass1/12000178209061.17/AliESDs.root; >; dsmgrd.sleepsecs *secs*; : Seconds to sleep between each loop. The dataset stager checks at; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:2384,scalab,scalability,2384,proof/doc/confman/DatasetStager.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md,1,['scalab'],['scalability']
Performance," for example, by LICM before hoisting an; operation. * ``mayReadFromMemory()``/``mayWriteToMemory()``: Existing predicate, but note; that they return true for any operation which is volatile or at least; Monotonic. * ``isStrongerThan`` / ``isAtLeastOrStrongerThan``: These are predicates on; orderings. They can be useful for passes that are aware of atomics, for; example to do DSE across a single atomic access, but not across a; release-acquire pair (see MemoryDependencyAnalysis for an example of this). * Alias analysis: Note that AA will return ModRef for anything Acquire or; Release, and for the address accessed by any Monotonic operation. To support optimizing around atomic operations, make sure you are using the; right predicates; everything should work if that is done. If your pass should; optimize some atomic operations (Unordered operations in particular), make sure; it doesn't replace an atomic load or store with a non-atomic operation. Some examples of how optimizations interact with various kinds of atomic; operations:. * ``memcpyopt``: An atomic operation cannot be optimized into part of a; memcpy/memset, including unordered loads/stores. It can pull operations; across some atomic operations. * LICM: Unordered loads/stores can be moved out of a loop. It just treats; monotonic operations like a read+write to a memory location, and anything; stricter than that like a nothrow call. * DSE: Unordered stores can be DSE'ed like normal stores. Monotonic stores can; be DSE'ed in some cases, but it's tricky to reason about, and not especially; important. It is possible in some case for DSE to operate across a stronger; atomic operation, but it is fairly tricky. DSE delegates this reasoning to; MemoryDependencyAnalysis (which is also used by other passes like GVN). * Folding a load: Any atomic load from a constant global can be constant-folded,; because it cannot be observed. Similar reasoning allows sroa with; atomic loads and stores. Atomics and Codegen; ===========",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:17108,optimiz,optimizations,17108,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['optimiz'],['optimizations']
Performance," for i32. llvm.amdgcn.udot2 Provides direct access to v_dot2_u32_u16 across targets which; support such instructions. This performs unsigned dot product; with two v2i16 operands, summed with the third i32 operand. The; i1 fourth operand is used to clamp the output. llvm.amdgcn.udot4 Provides direct access to v_dot4_u32_u8 across targets which; support such instructions. This performs unsigned dot product; with two i32 operands (holding a vector of 4 8bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output. llvm.amdgcn.udot8 Provides direct access to v_dot8_u32_u4 across targets which; support such instructions. This performs unsigned dot product; with two i32 operands (holding a vector of 8 4bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output. llvm.amdgcn.sdot2 Provides direct access to v_dot2_i32_i16 across targets which; support such instructions. This performs signed dot product; with two v2i16 operands, summed with the third i32 operand. The; i1 fourth operand is used to clamp the output.; When applicable (e.g. no clamping), this is lowered into; v_dot2c_i32_i16 for targets which support it. llvm.amdgcn.sdot4 Provides direct access to v_dot4_i32_i8 across targets which; support such instructions. This performs signed dot product; with two i32 operands (holding a vector of 4 8bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output.; When applicable (i.e. no clamping / operand modifiers), this is lowered; into v_dot4c_i32_i8 for targets which support it.; RDNA3 does not offer v_dot4_i32_i8, and rather offers; v_dot4_i32_iu8 which has operands to hold the signedness of the; vector operands. Thus, this intrinsic lowers to the signed version; of this instruction for gfx11 targets. llvm.amdgcn.sdot8 Provides direct access to v_dot8_u32_u4 across targets which; support such instructions. This performs signed dot product; with two i32 o",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:40085,perform,performs,40085,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performs']
Performance," for those lanes. %masked.a = select <4 x i1> %mask, <4 x i32> %a, <4 x i32> zeroinitializer; %reduction = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %masked.a); %also.r = add i32 %reduction, %start. .. _int_vp_reduce_fadd:. '``llvm.vp.reduce.fadd.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare float @llvm.vp.reduce.fadd.v4f32(float <start_value>, <4 x float> <val>, <4 x i1> <mask>, i32 <vector_length>); declare double @llvm.vp.reduce.fadd.nxv8f64(double <start_value>, <vscale x 8 x double> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point ``ADD`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; floating-point type equal to the result type. The second operand is the vector; on which the reduction is performed and must be a vector of floating-point; values whose element type is the result/start type. The third operand is the; vector mask and is a vector of boolean values with the same number of elements; as the vector operand. The fourth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.fadd``' intrinsic performs the floating-point ``ADD``; reduction (:ref:`llvm.vector.reduce.fadd <int_vector_reduce_fadd>`) of the; vector operand ``val`` on each enabled lane, adding it to the scalar; ``start_value``. Disabled lanes are treated as containing the neutral value; ``-0.0`` (i.e. having no effect on the reduction operation). If no lanes are; enabled, the resulting value will be equal to ``start_value``. To ignore the start value, the neutral value can be used. See the unpredicated version (:ref:`llvm.vector.reduce.fadd; <int_vector_reduce_fadd>`) for more detail on the semantics of the reduction. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call float",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:751002,perform,performed,751002,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance," for. The query either returns the element; matching the ID or it returns an opaque ID that indicates where insertion should; take place. Construction of the ID usually does not require heap traffic. Because FoldingSet uses intrusive links, it can support polymorphic objects in; the set (for example, you can have SDNode instances mixed with LoadSDNodes).; Because the elements are individually allocated, pointers to the elements are; stable: inserting or removing elements does not invalidate any pointers to other; elements. .. _dss_set:. <set>; ^^^^^. ``std::set`` is a reasonable all-around set class, which is decent at many; things but great at nothing. std::set allocates memory for each element; inserted (thus it is very malloc intensive) and typically stores three pointers; per element in the set (thus adding a large amount of per-element space; overhead). It offers guaranteed log(n) performance, which is not particularly; fast from a complexity standpoint (particularly if the elements of the set are; expensive to compare, like strings), and has extremely high constant factors for; lookup, insertion and removal. The advantages of std::set are that its iterators are stable (deleting or; inserting an element from the set does not affect iterators or pointers to other; elements) and that iteration over the set is guaranteed to be in sorted order.; If the elements in the set are large, then the relative overhead of the pointers; and malloc traffic is not a big deal, but if the elements of the set are small,; std::set is almost never a good choice. .. _dss_setvector:. llvm/ADT/SetVector.h; ^^^^^^^^^^^^^^^^^^^^. LLVM's ``SetVector<Type>`` is an adapter class that combines your choice of a; set-like container along with a :ref:`Sequential Container <ds_sequential>` The; important property that this provides is efficient insertion with uniquing; (duplicate elements are ignored) with iteration support. It implements this by; inserting elements into both a set-like container",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst:83559,perform,performance,83559,interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ProgrammersManual.rst,1,['perform'],['performance']
Performance," frame and resume program execution using the information; provided by the stack map. For example, execution may resume in an; interpreter or a recompiled version of the same function. This usage restricts LLVM optimization. Clearly, LLVM must not move; stores across a stack map. However, loads must also be handled; conservatively. If the load may trigger an exception, hoisting it; above a stack map could be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site as ""readonly"". In the future we may; also allow meta-data to be added to the intrinsic call to express; aliasing, thereby allowing optimizations to hoist certain loads above; stack maps. Direct Stack Map Entries; ^^^^^^^^^^^^^^^^^^^^^^^^. As shown in :ref:`stackmap-section`, a Direct stack map location; records the address of frame index. This address is itself the value; that the runtime requested. This differs from Indirect locations,; which refer to a stack locations from which the requested values must; be loaded. Direct locations can communicate the address if an alloca,; while Indirect locations handle register spills. For example:. .. code-block:: none. entry:; %a = alloca i64...",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:18650,load,load,18650,interpreter/llvm-project/llvm/docs/StackMaps.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst,1,['load'],['load']
Performance," frame expansion. When representing function; scoped variables or locations, placing alloca instructions at the beginning of; the entry block should be preferred. In particular, place them before any; call instructions. Call instructions might get inlined and replaced with; multiple basic blocks. The end result is that a following alloca instruction; would no longer be in the entry basic block afterward. The SROA (Scalar Replacement Of Aggregates) and Mem2Reg passes only attempt; to eliminate alloca instructions that are in the entry basic block. Given; SSA is the canonical form expected by much of the optimizer; if allocas can; not be eliminated by Mem2Reg or SROA, the optimizer is likely to be less; effective than it could be. Avoid loads and stores of large aggregate type; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. LLVM currently does not optimize well loads and stores of large :ref:`aggregate; types <t_aggregate>` (i.e. structs and arrays). As an alternative, consider; loading individual fields from memory. Aggregates that are smaller than the largest (performant) load or store; instruction supported by the targeted hardware are well supported. These can; be an effective way to represent collections of small packed fields. Prefer zext over sext when legal; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. On some architectures (X86_64 is one), sign extension can involve an extra; instruction whereas zero extension can be folded into a load. LLVM will try to; replace a sext with a zext when it can be proven safe, but if you have; information in your source language about the range of an integer value, it can; be profitable to use a zext rather than a sext. Alternatively, you can :ref:`specify the range of the value using metadata; <range-metadata>` and LLVM can do the sext to zext conversion for you. Zext GEP indices to machine register width; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Internally, LLVM often promotes the width of GEP indices to machine register; width",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:3248,load,loading,3248,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['load'],['loading']
Performance," frame of the current volume and to; compute the distance to exit its shape from inside. The returned value; is again compared to the maximum allowed step (the proposed one) and in; case the distance is safe no other action is performed and the proposed; step is approved. In case the boundary is closer, the computed distance; is taken as maximum allowed step. For optimization purposed, for; particles starting very close to the current volume boundary (less than; 0.01 microns) and exiting the algorithm stops here. After computing the distance to exit the current node, the distance to; the daughter of the current volume which is crossed next is computed by; **`TGeoManager`**`::FindNextDaughterBoundary().` This computes the; distance to all daughter candidates that can be possibly crossed by; using volume voxelization. The algorithm is efficient in average only in; case the number of daughters is greater than 4. For fewer nodes, a; simple loop is performed and the minimum distance (from a point outside; each shape) is taken and compared to the maximum allowed step. The step; value is again updated if `step<stepmax` . A special case is when the current node is declared as possibly; overlapping with something else. If this is the case, the distance is; computed for all possibly overlapping candidates, taking into account; the overlapping priorities (see also: "" Overlapping volumes ""). The global matrix describing the next crossed physical node is; systematically computed in case the value of the proposed step is; negative. In this case, one can subsequently call; `TGeoManager::ComputeNormalFast()` to get the normal vector to the; crossed surface, after propagating the current point with the; `TGeoManager::GetStep()` value. This propagation can be done like:. ``` {.cpp}; Double_t *current_point = gGeoManager->GetCurrentPoint();; Double_t *current_dir = gGeoManager->GetCurrentDirection();; for (Int_t i=0; i<3; i++); current_point[i] += step * current_dir[I];; ```. Note: Th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:163532,perform,performed,163532,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['perform'],['performed']
Performance," from a function:. 1. VGPR0-31 and SGPR4-29 are used to pass function result arguments as; described below. Any registers used are considered clobbered registers.; 2. The following registers are preserved and have the same value as on entry:. * FLAT_SCRATCH; * EXEC; * GFX6-GFX8: M0; * All SGPR registers except the clobbered registers of SGPR4-31.; * VGPR40-47; * VGPR56-63; * VGPR72-79; * VGPR88-95; * VGPR104-111; * VGPR120-127; * VGPR136-143; * VGPR152-159; * VGPR168-175; * VGPR184-191; * VGPR200-207; * VGPR216-223; * VGPR232-239; * VGPR248-255. .. note::. Except the argument registers, the VGPRs clobbered and the preserved; registers are intermixed at regular intervals in order to keep a; similar ratio independent of the number of allocated VGPRs. * GFX90A: All AGPR registers except the clobbered registers AGPR0-31.; * Lanes of all VGPRs that are inactive at the call site. For the AMDGPU backend, an inter-procedural register allocation (IPRA); optimization may mark some of clobbered SGPR and VGPR registers as; preserved if it can be determined that the called function does not change; their value. 2. The PC is set to the RA provided on entry.; 3. MODE register: *TBD*.; 4. All other registers are clobbered.; 5. Any necessary ``s_waitcnt`` has been performed to ensure memory accessed by; function is available to the caller. .. TODO::. - How are function results returned? The address of structured types is passed; by reference, but what about other types?. The function input arguments are made up of the formal arguments explicitly; declared by the source language function plus the implicit input arguments used; by the implementation. The source language input arguments are:. 1. Any source language implicit ``this`` or ``self`` argument comes first as a; pointer type.; 2. Followed by the function formal arguments in left to right source order. The source language result arguments are:. 1. The function result argument. The source language input or result struct type argu",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:391172,optimiz,optimization,391172,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['optimiz'],['optimization']
Performance," from the program. 5. `Prolog/Epilog Code Insertion`_ --- Once the machine code has been generated; for the function and the amount of stack space required is known (used for; LLVM alloca's and spill slots), the prolog and epilog code for the function; can be inserted and ""abstract stack location references"" can be eliminated.; This stage is responsible for implementing optimizations like frame-pointer; elimination and stack packing. 6. `Late Machine Code Optimizations`_ --- Optimizations that operate on ""final""; machine code can go here, such as spill code scheduling and peephole; optimizations. 7. `Code Emission`_ --- The final stage actually puts out the code for the; current function, either in the target assembler format or in machine; code. The code generator is based on the assumption that the instruction selector will; use an optimal pattern matching selector to create high-quality sequences of; native instructions. Alternative code generator designs based on pattern; expansion and aggressive iterative peephole optimization are much slower. This; design permits efficient compilation (important for JIT environments) and; aggressive optimization (used when generating code offline) by allowing; components of varying levels of sophistication to be used for any step of; compilation. In addition to these stages, target implementations can insert arbitrary; target-specific passes into the flow. For example, the X86 target uses a; special pass to handle the 80x87 floating point stack architecture. Other; targets with unusual requirements can be supported with custom passes as needed. Using TableGen for target description; -------------------------------------. The target description classes require a detailed description of the target; architecture. These target descriptions often have a large amount of common; information (e.g., an ``add`` instruction is almost identical to a ``sub``; instruction). In order to allow the maximum amount of commonality to be; factored ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst:7556,optimiz,optimization,7556,interpreter/llvm-project/llvm/docs/CodeGenerator.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeGenerator.rst,1,['optimiz'],['optimization']
Performance," function, Security Remarks. #include <windows.h>. void test() {; STARTUPINFO si;; PROCESS_INFORMATION pi;; CreateProcess(NULL, TEXT(""C:\\Program Files\\App -L -S""),; NULL, NULL, TRUE, 0, NULL, NULL, &si, π);; // warn; }. WinAPI.LoadLibrary; (C); The SearchPath() function is used to retrieve a path to a DLL for; a subsequent LoadLibrary() call.; Source: ; MSDN: LoadLibrary function, Security Remarks. #include <windows.h>. HINSTANCE test() {; char filePath[100];; SearchPath(NULL, ""file.dll"", NULL, 100, filePath, NULL);; return LoadLibrary(filePath); // warn; }. WinAPI.WideCharToMultiByte; (C); Buffer overrun while calling WideCharToMultiByte(). The size of; the input buffer equals the number of characters in the Unicode string, while; the size of the output buffer equals the number of bytes.; Source: ; MSDN: WideCharToMultiByte function. #include <windows.h>. void test() {; wchar_t ws[] = L""abc"";; char s[3];; WideCharToMultiByte(CP_UTF8, 0, ws, -1, s,; 3, NULL, NULL); // warn; }. optimization. Name, DescriptionExampleProgress. optimization.PassConstObjByValue; (C, C++); Optimization: It is more effective to pass constant parameter by reference to; avoid unnecessary object copying. struct A {};. void f(const struct A a); // warn. optimization.PostfixIncIter; (C++); Optimization: It is more effective to use prefix increment operator with; iterator.; Source: Scott Meyers ""More Effective C++"", item 6:; Distinguish between prefix and postfix forms of increment and decrement; operators. #include <vector>. void test() {; std::vector<int> v;; std::vector<int>::const_iterator it;; for(it = v.begin();; it != v.end(); it++) {}; // warn; }. optimization.MultipleCallsStrlen; (C); Optimization: multiple calls to strlen() for a string in an; expression. It is more effective to hold a value returned; from strlen() in a temporary variable. #include <string.h>. void test(const char* s) {; if (strlen(s) > 0 &&; strlen(s) < 7) {}; // warn; }. optimization.StrLengthCalculation; (C++); Op",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html:27216,optimiz,optimization,27216,interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/potential_checkers.html,1,['optimiz'],['optimization']
Performance," function; ``__jit_debug_register_code`` that the debugger knows about. When the debugger; attaches to a process, it puts a breakpoint in this function and associates a; special handler with it. Once MCJIT calls the registration function, the; debugger catches the breakpoint signal, loads the new object file from the; inferior's memory and resumes execution. This way it can obtain debug; information for pure in-memory object files. GDB Version; ===========. In order to debug code JIT-ed by LLVM, you need GDB 7.0 or newer, which is; available on most modern distributions of Linux. The version of GDB that; Apple ships with Xcode has been frozen at 6.3 for a while. LLDB Version; ============. Due to a regression in release 6.0, LLDB didn't support JITed code debugging for; a while. The bug was fixed in mainline recently, so that debugging JITed ELF; objects should be possible again from the upcoming release 12.0 on. On macOS the; feature must be enabled explicitly using the ``plugin.jit-loader.gdb.enable``; setting. Debugging MCJIT-ed code; =======================. The emerging MCJIT component of LLVM allows full debugging of JIT-ed code with; GDB. This is due to MCJIT's ability to use the MC emitter to provide full; DWARF debugging information to GDB. Note that lli has to be passed the ``--jit-kind=mcjit`` flag to JIT the code; with MCJIT instead of the newer ORC JIT. Example; -------. Consider the following C code (with line numbers added to make the example; easier to follow):. ..; FIXME:; Sphinx has the ability to automatically number these lines by adding; :linenos: on the line immediately following the `.. code-block:: c`, but; it looks like garbage; the line numbers don't even line up with the; lines. Is this a Sphinx bug, or is it a CSS problem?. .. code-block:: c. 1 int compute_factorial(int n); 2 {; 3 if (n <= 1); 4 return 1;; 5; 6 int f = n;; 7 while (--n > 1); 8 f *= n;; 9 return f;; 10 }; 11; 12; 13 int main(int argc, char** argv); 14 {; 15 if (argc < 2); 1",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst:1898,load,loader,1898,interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DebuggingJITedCode.rst,1,['load'],['loader']
Performance," generate flamegraphs for; visualizing your instrumented invocations. The tool does not generate the graphs; themselves, but instead generates a format that can be used with Brendan Gregg's; FlameGraph tool, currently available on `github; <https://github.com/brendangregg/FlameGraph>`_. To generate output for a flamegraph, a few more options are necessary. - ``--all-stacks`` - Emits all of the stacks.; - ``--stack-format`` - Choose the flamegraph output format 'flame'.; - ``--aggregation-type`` - Choose the metric to graph. You may pipe the command output directly to the flamegraph tool to obtain an; svg file. ::. $ llvm-xray stack xray-log.llc.5rqxkU --instr_map=./bin/llc --stack-format=flame --aggregation-type=time --all-stacks | \; /path/to/FlameGraph/flamegraph.pl > flamegraph.svg. If you open the svg in a browser, mouse events allow exploring the call stacks. Chrome Trace Viewer Visualization; ---------------------------------. We can also generate a trace which can be loaded by the Chrome Trace Viewer; from the same generated trace:. ::. $ llvm-xray convert --symbolize --instr_map=./bin/llc \; --output-format=trace_event xray-log.llc.5rqxkU \; | gzip > llc-trace.txt.gz. From a Chrome browser, navigating to ``chrome:///tracing`` allows us to load; the ``sample-trace.txt.gz`` file to visualize the execution trace. Further Exploration; -------------------. The ``llvm-xray`` tool has a few other subcommands that are in various stages; of being developed. One interesting subcommand that can highlight a few; interesting things is the ``graph`` subcommand. Given for example the following; toy program that we build with XRay instrumentation, we can see how the; generated graph may be a helpful indicator of where time is being spent for the; application. .. code-block:: c++. // sample.cc; #include <iostream>; #include <thread>. [[clang::xray_always_instrument]] void f() {; std::cerr << '.';; }. [[clang::xray_always_instrument]] void g() {; for (int i = 0; i < 1 << 10; +",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst:13460,load,loaded,13460,interpreter/llvm-project/llvm/docs/XRayExample.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst,1,['load'],['loaded']
Performance," generators; -----------------------------------------------------------------------. This transformation is designed for use by code generators which do not yet; support stack unwinding. This pass converts ``invoke`` instructions to; ``call`` instructions, so that any exception-handling ``landingpad`` blocks; become dead code (which can be removed by running the ``-simplifycfg`` pass; afterwards). ``lowerswitch``: Lower ``SwitchInst``\ s to branches; ----------------------------------------------------. Rewrites switch instructions with a sequence of branches, which allows targets; to get away with not implementing the switch instruction until it is; convenient. .. _passes-mem2reg:. ``mem2reg``: Promote Memory to Register; ---------------------------------------. This file promotes memory references to be register references. It promotes; alloca instructions which only have loads and stores as uses. An ``alloca`` is; transformed by using dominator frontiers to place phi nodes, then traversing; the function in depth-first order to rewrite loads and stores as appropriate.; This is just the standard SSA construction algorithm to construct ""pruned"" SSA; form. ``memcpyopt``: MemCpy Optimization; ----------------------------------. This pass performs various transformations related to eliminating ``memcpy``; calls, or transforming sets of stores into ``memset``\ s. ``mergefunc``: Merge Functions; ------------------------------. This pass looks for equivalent functions that are mergeable and folds them. Total-ordering is introduced among the functions set: we define comparison; that answers for every two functions which of them is greater. It allows to; arrange functions into the binary tree. For every new function we check for equivalent in tree. If equivalent exists we fold such functions. If both functions are overridable,; we move the functionality into a new internal function and leave two; overridable thunks to it. If there is no equivalent, then we add this functio",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:30751,load,loads,30751,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,1,['load'],['loads']
Performance," get a big win for the compilation time in O0. But with optimizations, things are different:. (we omit ``code generation`` part for each end due to the limited space). .. code-block:: none. ├-------- frontend ---------┼--------------- middle end --------------------┼------ backend ----┤; │ │ │ │; └--- parsing ---- sema -----┴--- optimizations --- IPO ---- optimizations---┴--- optimizations -┘. ┌-----------------------------------------------------------------------------------------------┐; │ │; │ source file │; │ │; └-----------------------------------------------------------------------------------------------┘; ┌---------------------------------------┐; │ │; │ │; │ imported code │; │ │; │ │; └---------------------------------------┘. It would be very unfortunate if we end up with worse performance after using modules.; The main concern is that when we compile a source file, the compiler needs to see the function body; of imported module units so that it can perform IPO (InterProcedural Optimization, primarily inlining; in practice) to optimize functions in current source file with the help of the information provided by; the imported module units.; In other words, the imported code would be processed again and again in importee units; by optimizations (including IPO itself).; The optimizations before IPO and the IPO itself are the most time-consuming part in whole compilation process.; So from this perspective, we might not be able to get the improvements described in the theory.; But we could still save the time for optimizations after IPO and the whole backend. Overall, at ``O0`` the implementations of functions defined in a module will not impact module users,; but at higher optimization levels the definitions of such functions are provided to user compilations for the; purposes of optimization (but definitions of these functions are still not included in the use's object file)-; this means the build speedup at higher optimization levels may be lower than expe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst:42315,perform,perform,42315,interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/StandardCPlusPlusModules.rst,2,"['optimiz', 'perform']","['optimize', 'perform']"
Performance," given); >>> c.callit(c); called Concrete::abstract_method; >>>. `Static methods`; ----------------. Class static functions are treated the same way as free functions, except; that they are accessible either through the class or through an instance,; just like Python's ``staticmethod``. `Instance methods`; ------------------. For class methods, see the :ref:`methods section <sec-methods-label>` under; the :doc:`classes heading<classes>`. `Lambda's`; ----------. C++ lambda functions are supported by first binding to a ``std::function``,; then providing a proxy to that on the Python side.; Example::. >>> cppyy.cppdef(""""""\; ... auto create_lambda(int a) {; ... return [a](int b) { return a+b; };; ... }""""""); True; >>> l = cppyy.gbl.create_lambda(4); >>> type(l); <class cppyy.gbl.std.function<int(int)> at 0x11505b830>; >>> l(2); 6; >>> . `Operators`; -----------. Globally defined operators are found lazily (ie. can resolve after the class; definition by loading the global definition or by defining them interactively); and are mapped onto a Python equivalent when possible.; See the :ref:`operators section <sec-operators-label>` under the; :doc:`classes heading<classes>` for more details. `Templates`; -----------. Templated functions (and class methods) can either be called using square; brackets (``[]``) to provide the template arguments explicitly, or called; directly, through automatic lookup.; The template arguments may either be a string of type names (this results; in faster code, as it needs no further lookup/verification) or a list of; the actual types to use (which tends to be more convenient). **Note**: the Python type ``float`` maps to the C++ type ``float``, even; as Python uses a C ``double`` as its internal representation.; The motivation is that doing so makes the Python code more readable (and; Python may anyway change its internal representation in the future).; The same has been true for Python ``int``, which used to be a C ``long``; internally. Examples, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:3238,load,loading,3238,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,1,['load'],['loading']
Performance," global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; - system; atomicrmw monotonic - singlethread - local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load glc=1. - If CU wavefront execution; mode, omit glc=1. 2. s_waitcnt vmcnt(0). - If CU wavefront execution; mode, omit.; - Must happen before; the following buffer_gl0_inv; and before any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; the following buffer_gl0_inv; and before any following; global/generic load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If CU wavefront execution; mode, omit glc=1. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If CU wavefront execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_gl0_inv and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1 dlc=1. - If GF",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:346846,load,load,346846,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," global <identifiers>` is used and always have; :ref:`pointer <t_pointer>` type. For example, the following is a legal LLVM; file:. .. code-block:: llvm. @X = global i32 17; @Y = global i32 42; @Z = global [2 x ptr] [ ptr @X, ptr @Y ]. .. _undefvalues:. Undefined Values; ----------------. The string '``undef``' can be used anywhere a constant is expected, and; indicates that the user of the value may receive an unspecified; bit-pattern. Undefined values may be of any type (other than '``label``'; or '``void``') and be used anywhere a constant is permitted. .. note::. A '``poison``' value (described in the next section) should be used instead of; '``undef``' whenever possible. Poison values are stronger than undef, and; enable more optimizations. Just the existence of '``undef``' blocks certain; optimizations (see the examples below). Undefined values are useful because they indicate to the compiler that; the program is well defined no matter what value is used. This gives the; compiler more freedom to optimize. Here are some examples of; (potentially surprising) transformations that are valid (in pseudo IR):. .. code-block:: llvm. %A = add %X, undef; %B = sub %X, undef; %C = xor %X, undef; Safe:; %A = undef; %B = undef; %C = undef. This is safe because all of the output bits are affected by the undef; bits. Any output bit can have a zero or one depending on the input bits. .. code-block:: llvm. %A = or %X, undef; %B = and %X, undef; Safe:; %A = -1; %B = 0; Safe:; %A = %X ;; By choosing undef as 0; %B = %X ;; By choosing undef as -1; Unsafe:; %A = undef; %B = undef. These logical operations have bits that are not always affected by the; input. For example, if ``%X`` has a zero bit, then the output of the; '``and``' operation will always be a zero for that bit, no matter what; the corresponding bit from the '``undef``' is. As such, it is unsafe to; optimize or assume that the result of the '``and``' is '``undef``'.; However, it is safe to assume that all bits of the '`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:191476,optimiz,optimize,191476,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimize']
Performance," global/generic store; atomic/; atomicrmw-no-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; local load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - s_waitcnt vscnt(0); Must happen after; preceding; global/generic store; atomic/; atomi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:377470,load,load,377470,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance," global/generic store; atomic/; atomicrmw-no-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; - agent all instructions even; - system for OpenCL.*; ============ ============ ============== ========== ================================. .. _amdgpu-amdhsa-trap-handler-abi:. Trap Handler ABI; ~~~~~~~~~~~~~~~~. For code objects generated by the AMDGPU backend for HSA [HSA]_ compatible; runtimes (see :ref:`amdgpu-os`), the runtime installs a trap handler that; supports the ``s_trap`` instructi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:379433,load,load,379433,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance," green and blue values for the component; adjusted via the sliders. You can apply this adjustment to the shape; itself, or to all shapes sharing a common ‘family'. Shapes of the same; family have external objects with the same **`TObject`** name string.; You can also adjust the ‘Opacity' and ‘Shine' for the shapes materials; via the sliders. #### Geometry. Viewer Controls Pane ‘Geometry' tab. Review and modify the shapes X/Y/Z center and scaling factors via the; edit boxes. Selection and editing of shapes is not available via the API; at present. #### Outputting Viewer Contents. The current viewer rendering can be output to an external `EPS` or; `PDF`, using the options under the ‘File' menu on the top menu bar. The; file is named ‘`viewer.eps`' or ‘`viewer.pdf`' and written to the; current ROOT directory. ### The X3D Viewer. The X3D viewer is a fairly simple and limited viewer, capable of showing; basic lines and polygons. It lacks the quality, performance and more; advanced features of the GL Viewer, and additionally is not supported on; Windows. It is not actively developed and you are encouraged to use the; GL Viewer out of preference. The below table presents the main; interactions - these are repeated in the Help dialog of the viewer. Action KeyActionKey. Wireframe Mode wRotate about xx a. Hidden Line Mode eRotate about yy b. Hidden Surface Mode rRotate about zz c. Move object down uAuto-rotate about x1 2 3. Move object up iAuto-rotate about y4 5 6. Move object left lAuto-rotate about z7 8 9. Move object right hToggle controls styleo. Move object forward jToggle stereo displays. Move object backward kToggle blue stereo viewd. Adjust focus (stereo mode) [ ] { }Toggle double bufferf. Rotate object Left mouse button down + move. ### Common 3D Viewer Architecture. The 3D Viewer Architecture provides a common mechanism for viewer; clients to publish 3D objects to it. It enables:. - Decoupling of producers (geometry packages etc) who model collection; of 3D objects f",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md:121198,perform,performance,121198,documentation/users-guide/Graphics.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Graphics.md,1,['perform'],['performance']
Performance," group does not exist in the Z dimension. ""hidden_grid_dims""; The grid dispatch dimensionality. This is the same value; as the AQL dispatch packet dimensionality. Must be a value; between 1 and 3. ""hidden_heap_v1""; A global address space pointer to an initialized memory; buffer that conforms to the requirements of the malloc/free; device library V1 version implementation. ""hidden_dynamic_lds_size""; Size of the dynamically allocated LDS memory is passed in the kernarg. ""hidden_private_base""; The high 32 bits of the flat addressing private aperture base.; Only used by GFX8 to allow conversion between private segment; and flat addresses. See :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`. ""hidden_shared_base""; The high 32 bits of the flat addressing shared aperture base.; Only used by GFX8 to allow conversion between shared segment; and flat addresses. See :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`. ""hidden_queue_ptr""; A global memory address space pointer to the ROCm runtime; ``struct amd_queue_t`` structure for the HSA queue of the; associated dispatch AQL packet. It is only required for pre-GFX9; devices for the trap handler ABI (see :ref:`amdgpu-amdhsa-trap-handler-abi`). ====================== ============== ========= ================================. .. Kernel Dispatch; ~~~~~~~~~~~~~~~. The HSA architected queuing language (AQL) defines a user space memory interface; that can be used to control the dispatch of kernels, in an agent independent; way. An agent can have zero or more AQL queues created for it using an HSA; compatible runtime (see :ref:`amdgpu-os`), in which AQL packets (all of which; are 64 bytes) can be placed. See the *HSA Platform System Architecture; Specification* [HSA]_ for the AQL queue mechanics and packet layouts. The packet processor of a kernel agent is responsible for detecting and; dispatching HSA kernels from the AQL queues associated with it. For AMD GPUs the; packet processor is implemented by the hardware command processor (CP),",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:148576,queue,queue,148576,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['queue'],['queue']
Performance," handled together, for different possible reasons. One; of these is that the structure has to be replicated in several parts of; the geometry, or it may simply happen that they really represent a; single object, too complex to be described by a primitive shape. Usually handling structures like these can be easily done by positioning; all components in the same container volume, then positioning the; container itself. However, there are many practical cases when defining; such a container is not straightforward or even possible without; generating overlaps with the rest of the geometry. There are few ways; out of this:. - Defining the container for the structure as ""overlapping"" (see also; ""Overlapping Volumes""); - Representing the container as a composite shape - the Boolean union; of all components (see also ""Composite Shapes""); - Using an assembly volume - this will be described in the following. The first two approaches have the disadvantage of penalizing the; navigation performance with a factor increasing more than linear of the; number of components in the structure. The best solution is the third; one because it uses all volume-related navigation optimizations. The; class TGeoVolumeAssembly represents an assembly volume. Its shape; is represented by TGeoShapeAssembly class that is the union of all; components. It uses volume voxelization to perform navigation tasks. An assembly volume creates a hierarchical level and it geometrically; insulates the structure from the rest (as a normal volume). Physically,; a point that is INSIDE a TGeoShapeAssembly is always inside one of; the components, so a TGeoVolumeAssembly does not need to have a; medium. Due to the self-containment of assemblies, they are very; practical to use when a container is hard to define due to possible; overlaps during positioning. For instance, it is very easy creating; honeycomb structures. A very useful example for creating and using; assemblies can be found at: assembly.C. Creation of an a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md:49420,perform,performance,49420,geom/geom/doc/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/geom/geom/doc/index.md,1,['perform'],['performance']
Performance," has shown us there is no point in partitioning to more than; one variable. It simply generates more IR, and optimizations still; have to query something to disambiguate further anyway. As a result, LLVM partitions to one variable. Precision in practice; ^^^^^^^^^^^^^^^^^^^^^. In practice, there are implementation details in LLVM that also affect the; results' precision provided by ``MemorySSA``. For example, AliasAnalysis has various; caps, or restrictions on looking through phis which can affect what ``MemorySSA``; can infer. Changes made by different passes may make MemorySSA either ""overly; optimized"" (it can provide a more accurate result than if it were recomputed; from scratch), or ""under optimized"" (it could infer more if it were recomputed).; This can lead to challenges to reproduced results in isolation with a single pass; when the result relies on the state acquired by ``MemorySSA`` due to being updated by; multiple subsequent passes.; Passes that use and update ``MemorySSA`` should do so through the APIs provided by the; ``MemorySSAUpdater``, or through calls on the Walker.; Direct optimizations to ``MemorySSA`` are not permitted.; There is currently a single, narrowly scoped exception where DSE (DeadStoreElimination); updates an optimized access of a store, after a traversal that guarantees the; optimization is correct. This is solely allowed due to the traversals and inferences; being beyond what ``MemorySSA`` does and them being ""free"" (i.e. DSE does them anyway).; This exception is set under a flag (""-dse-optimize-memoryssa"") and can be disabled to; help reproduce optimizations in isolation. LLVM Developers Meeting presentations; -------------------------------------. - `2016 LLVM Developers' Meeting: G. Burgess - MemorySSA in Five Minutes <https://www.youtube.com/watch?v=bdxWmryoHak>`_.; - `2020 LLVM Developers' Meeting: S. Baziotis & S. Moll - Finding Your Way Around the LLVM Dependence Analysis Zoo <https://www.youtube.com/watch?v=1e5y6WDbXCQ>`_; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:19334,optimiz,optimizations,19334,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,5,['optimiz'],"['optimization', 'optimizations', 'optimize-memoryssa', 'optimized']"
Performance," has the same number of; elements as the result. The third argument is the explicit vector length of; the operation. Semantics:; """""""""""""""""""". This intrinsic reverses the order of the first ``evl`` elements in a vector.; The lanes in the result vector disabled by ``mask`` are ``poison``. The; elements past ``evl`` are poison. .. _int_vp_load:. '``llvm.vp.load``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <4 x float> @llvm.vp.load.v4f32.p0(ptr %ptr, <4 x i1> %mask, i32 %evl); declare <vscale x 2 x i16> @llvm.vp.load.nxv2i16.p0(ptr %ptr, <vscale x 2 x i1> %mask, i32 %evl); declare <8 x float> @llvm.vp.load.v8f32.p1(ptr addrspace(1) %ptr, <8 x i1> %mask, i32 %evl); declare <vscale x 1 x i64> @llvm.vp.load.nxv1i64.p6(ptr addrspace(6) %ptr, <vscale x 1 x i1> %mask, i32 %evl). Overview:; """""""""""""""""". The '``llvm.vp.load.*``' intrinsic is the vector length predicated version of; the :ref:`llvm.masked.load <int_mload>` intrinsic. Arguments:; """""""""""""""""""". The first operand is the base pointer for the load. The second operand is a; vector of boolean values with the same number of elements as the return type.; The third is the explicit vector length of the operation. The return type and; underlying type of the base pointer are the same vector types. The :ref:`align <attr_align>` parameter attribute can be provided for the first; operand. Semantics:; """""""""""""""""""". The '``llvm.vp.load``' intrinsic reads a vector from memory in the same way as; the '``llvm.masked.load``' intrinsic, where the mask is taken from the; combination of the '``mask``' and '``evl``' operands in the usual VP way.; Certain '``llvm.masked.load``' operands do not have corresponding operands in; '``llvm.vp.load``': the '``passthru``' operand is implicitly ``poison``; the; '``alignment``' operand is taken as the ``align`` parameter attribute, if; provided. The default alignment is taken as the ABI alignment of the return; type as speci",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:783533,load,load,783533,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," have exited the loop.; abort();; }; if (c3) {; // The unreachable allows the compiler to assume that this will not rejoin the loop.; do_something();; __builtin_unreachable();; }; if (c4) {; // This statically infinite loop is not nested because control-flow will not continue with the for-loop.; while(true) {; do_something();; }; }; }. * There is no requirement for the control flow to eventually leave the; loop, i.e. a loop can be infinite. A **statically infinite loop** is a; loop that has no exiting edges. A **dynamically infinite loop** has; exiting edges, but it is possible to be never taken. This may happen; only under some circumstances, such as when n == UINT_MAX in the code; below. .. code-block:: C. for (unsigned i = 0; i <= n; ++i); body(i);. It is possible for the optimizer to turn a dynamically infinite loop; into a statically infinite loop, for instance when it can prove that the; exiting condition is always false. Because the exiting edge is never; taken, the optimizer can change the conditional branch into an; unconditional one. If a is loop is annotated with; :ref:`llvm.loop.mustprogress <langref_llvm_loop_mustprogress>` metadata,; the compiler is allowed to assume that it will eventually terminate, even; if it cannot prove it. For instance, it may remove a mustprogress-loop; that does not have any side-effect in its body even though the program; could be stuck in that loop forever. Languages such as C and; `C++ <https://eel.is/c++draft/intro.progress#1>`_ have such; forward-progress guarantees for some loops. Also see the; :ref:`mustprogress <langref_mustprogress>` and; :ref:`willreturn <langref_willreturn>` function attributes, as well as; the older :ref:`llvm.sideeffect <llvm_sideeffect>` intrinsic. * The number of executions of the loop header before leaving the loop is; the **loop trip count** (or **iteration count**). If the loop should; not be executed at all, a **loop guard** must skip the entire loop:. .. image:: ./loop-guard.svg; :width: 50",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst:7362,optimiz,optimizer,7362,interpreter/llvm-project/llvm/docs/LoopTerminology.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LoopTerminology.rst,1,['optimiz'],['optimizer']
Performance," header0:; ...; br i1 %cmp, label %t1, label %t2, !irr_loop !0. ...; !0 = !{""loop_header_weight"", i64 100}. Irreducible loop header weights are typically based on profile data. .. _md_invariant.group:. '``invariant.group``' Metadata; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The experimental ``invariant.group`` metadata may be attached to; ``load``/``store`` instructions referencing a single metadata with no entries.; The existence of the ``invariant.group`` metadata on the instruction tells; the optimizer that every ``load`` and ``store`` to the same pointer operand; can be assumed to load or store the same; value (but see the ``llvm.launder.invariant.group`` intrinsic which affects; when two pointers are considered the same). Pointers returned by bitcast or; getelementptr with only zero indices are considered the same. Examples:. .. code-block:: llvm. @unknownPtr = external global i8; ...; %ptr = alloca i8; store i8 42, ptr %ptr, !invariant.group !0; call void @foo(ptr %ptr). %a = load i8, ptr %ptr, !invariant.group !0 ; Can assume that value under %ptr didn't change; call void @foo(ptr %ptr). %newPtr = call ptr @getPointer(ptr %ptr); %c = load i8, ptr %newPtr, !invariant.group !0 ; Can't assume anything, because we only have information about %ptr. %unknownValue = load i8, ptr @unknownPtr; store i8 %unknownValue, ptr %ptr, !invariant.group !0 ; Can assume that %unknownValue == 42. call void @foo(ptr %ptr); %newPtr2 = call ptr @llvm.launder.invariant.group.p0(ptr %ptr); %d = load i8, ptr %newPtr2, !invariant.group !0 ; Can't step through launder.invariant.group to get value of %ptr. ...; declare void @foo(ptr); declare ptr @getPointer(ptr); declare ptr @llvm.launder.invariant.group.p0(ptr). !0 = !{}. The invariant.group metadata must be dropped when replacing one pointer by; another based on aliasing information. This is because invariant.group is tied; to the SSA value of the pointer operand. .. code-block:: llvm. %v = load i8, ptr %x, !invariant.group !0; ; if %x mustalia",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:316631,load,load,316631,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," higher; pointer bits for other purposes.; * May require changes in the OS kernels (e.g. Linux seems to dislike; tagged pointers passed from address space:; https://www.kernel.org/doc/Documentation/arm64/tagged-pointers.txt).; * **Does not require redzones to detect buffer overflows**,; but the buffer overflow detection is probabilistic, with roughly; `1/(2**TS)` chance of missing a bug (6.25% or 0.39% with 4 and 8-bit TS; respectively).; * **Does not require quarantine to detect heap-use-after-free,; or stack-use-after-return**.; The detection is similarly probabilistic. The memory overhead of HWASAN is expected to be much smaller; than that of AddressSanitizer:; `1/TG` extra memory for the shadow; and some overhead due to `TG`-aligning all objects. Supported architectures; =======================; HWASAN relies on `Address Tagging`_ which is only available on AArch64.; For other 64-bit architectures it is possible to remove the address tags; before every load and store by compiler instrumentation, but this variant; will have limited deployability since not all of the code is; typically instrumented. On x86_64, HWASAN utilizes page aliasing to place tags in userspace address; bits. Currently only heap tagging is supported. The page aliases rely on; shared memory, which will cause heap memory to be shared between processes if; the application calls ``fork()``. Therefore x86_64 is really only safe for; applications that do not fork. HWASAN does not currently support 32-bit architectures since they do not; support `Address Tagging`_ and the address space is too constrained to easily; implement page aliasing. Related Work; ============; * `SPARC ADI`_ implements a similar tool mostly in hardware.; * `Effective and Efficient Memory Protection Using Dynamic Tainting`_ discusses; similar approaches (""lock & key"").; * `Watchdog`_ discussed a heavier, but still somewhat similar; ""lock & key"" approach.; * *TODO: add more ""related work"" links. Suggestions are welcome.*. .. _W",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst:10604,load,load,10604,interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,1,['load'],['load']
Performance," highly tuned and; well tested support for this, though the way it works is a bit; unexpected for some. Why is this a hard problem?; ===========================. To understand why mutable variables cause complexities in SSA; construction, consider this extremely simple C example:. .. code-block:: c. int G, H;; int test(_Bool Condition) {; int X;; if (Condition); X = G;; else; X = H;; return X;; }. In this case, we have the variable ""X"", whose value depends on the path; executed in the program. Because there are two different possible values; for X before the return instruction, a PHI node is inserted to merge the; two values. The LLVM IR that we want for this example looks like this:. .. code-block:: llvm. @G = weak global i32 0 ; type of @G is i32*; @H = weak global i32 0 ; type of @H is i32*. define i32 @test(i1 %Condition) {; entry:; br i1 %Condition, label %cond_true, label %cond_false. cond_true:; %X.0 = load i32, i32* @G; br label %cond_next. cond_false:; %X.1 = load i32, i32* @H; br label %cond_next. cond_next:; %X.2 = phi i32 [ %X.1, %cond_false ], [ %X.0, %cond_true ]; ret i32 %X.2; }. In this example, the loads from the G and H global variables are; explicit in the LLVM IR, and they live in the then/else branches of the; if statement (cond\_true/cond\_false). In order to merge the incoming; values, the X.2 phi node in the cond\_next block selects the right value; to use based on where control flow is coming from: if control flow comes; from the cond\_false block, X.2 gets the value of X.1. Alternatively, if; control flow comes from cond\_true, it gets the value of X.0. The intent; of this chapter is not to explain the details of SSA form. For more; information, see one of the many `online; references <http://en.wikipedia.org/wiki/Static_single_assignment_form>`_. The question for this article is ""who places the phi nodes when lowering; assignments to mutable variables?"". The issue here is that LLVM; *requires* that its IR be in SSA form: there is no ""non-ss",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:2281,load,load,2281,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['load'],['load']
Performance," histogram, the ""fitter"" will dynamically load libMinuit if; it is not yet loaded. #### Plugins: Runtime Library Dependencies for Linking. plugin manager The Plugin Manager **`TPluginManager`** allows; postponing library dependencies to runtime: a plugin library will only; be loaded when it is needed. Non-plugins will need to be linked, and; are thus loaded at start-up. Plugins are defined by a base class (e.g.; **`TFile`**) that will be implemented in a plugin, a tag used to; identify the plugin (e.g. `^rfio:` as part of the protocol string),; the plugin class of which an object will be created; (e.g. **`TRFIOFile`**), the library to be loaded (in short; `libRFIO.so` to RFIO), and the constructor to be called (e.g.; ""`TRFIOFile()`""). This can be specified in the `.rootrc` which already; contains many plugin definitions, or by calls to; `gROOT->GetPluginManager()->AddHandler()`. #### Library AutoLoading. When using a class in Cling, e.g. in an interpreted source file, ROOT; will automatically load the library that defines this class. On; start-up, ROOT parses all files ending on `.rootmap` rootmap that are; in one of the `$LD_LIBRARY_PATH` (or `$DYLD_LIBRARY_PATH` for `MacOS`,; or `$PATH` for `Windows`). They contain class names and the library; names that the class depends on. After reading them, ROOT knows which; classes are available, and which libraries to load for them. When `TSystem::Load(""ALib"")` is called, ROOT uses this information to; determine which libraries `libALib.so` depends on. It will load these; libraries first. Otherwise, loading the requested library could cause; a system (dynamic loader) error due to unresolved symbols. ### \$ROOTSYS/tutorials. tutorials The tutorials directory contains many example example; scripts. They assume some basic knowledge of ROOT, and for the new; user we recommend reading the chapters: ""Histograms"" and; ""Input/Output"" before trying the examples. The more experienced user; can jump to chapter ""The Tutorials and Tests",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md:19843,load,load,19843,documentation/users-guide/Introduction.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Introduction.md,1,['load'],['load']
Performance," i32 %X, 8; ret i32 %Y; }. _test1:; movl 4(%esp), %eax; movl %eax, %ecx; sarl $31, %ecx; shrl $29, %ecx; addl %ecx, %eax; sarl $3, %eax; ret. GCC knows several different ways to codegen it, one of which is this:. _test1:; movl 4(%esp), %eax; cmpl $-1, %eax; leal 7(%eax), %ecx; cmovle %ecx, %eax; sarl $3, %eax; ret. which is probably slower, but it's interesting at least :). //===---------------------------------------------------------------------===//. We are currently lowering large (1MB+) memmove/memcpy to rep/stosl and rep/movsl; We should leave these as libcalls for everything over a much lower threshold,; since libc is hand tuned for medium and large mem ops (avoiding RFO for large; stores, TLB preheating, etc). //===---------------------------------------------------------------------===//. Optimize this into something reasonable:; x * copysign(1.0, y) * copysign(1.0, z). //===---------------------------------------------------------------------===//. Optimize copysign(x, *y) to use an integer load from y. //===---------------------------------------------------------------------===//. The following tests perform worse with LSR:. lambda, siod, optimizer-eval, ackermann, hash2, nestedloop, strcat, and Treesor. //===---------------------------------------------------------------------===//. Adding to the list of cmp / test poor codegen issues:. int test(__m128 *A, __m128 *B) {; if (_mm_comige_ss(*A, *B)); return 3;; else; return 4;; }. _test:; 	movl 8(%esp), %eax; 	movaps (%eax), %xmm0; 	movl 4(%esp), %eax; 	movaps (%eax), %xmm1; 	comiss %xmm0, %xmm1; 	setae %al; 	movzbl %al, %ecx; 	movl $3, %eax; 	movl $4, %edx; 	cmpl $0, %ecx; 	cmove %edx, %eax; 	ret. Note the setae, movzbl, cmpl, cmove can be replaced with a single cmovae. There; are a number of issues. 1) We are introducing a setcc between the result of the; intrisic call and select. 2) The intrinsic is expected to produce a i32 value; so a any extend (which becomes a zero extend) is added. We probably need",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt:5346,load,load,5346,interpreter/llvm-project/llvm/lib/Target/X86/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README.txt,1,['load'],['load']
Performance," i32> @llvm.bitreverse.v4i32(<4 x i32> %a); %also.r = select <4 x i1> %mask, <4 x i32> %t, <4 x i32> poison. .. _int_vp_bswap:. '``llvm.vp.bswap.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x i32> @llvm.vp.bswap.v16i32 (<16 x i32> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x i32> @llvm.vp.bswap.nxv4i32 (<vscale x 4 x i32> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x i64> @llvm.vp.bswap.v256i64 (<256 x i64> <op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated bswap of a vector of integers. Arguments:; """""""""""""""""""". The first operand and the result have the same vector of integer type. The; second operand is the vector mask and has the same number of elements as the; result vector type. The third operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.bswap``' intrinsic performs bswap (:ref:`bswap <int_bswap>`) of the first operand on each; enabled lane. The result on disabled lanes is a :ref:`poison value <poisonvalues>`. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x i32> @llvm.vp.bswap.v4i32(<4 x i32> %a, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x i32> @llvm.bswap.v4i32(<4 x i32> %a); %also.r = select <4 x i1> %mask, <4 x i32> %t, <4 x i32> poison. .. _int_vp_ctpop:. '``llvm.vp.ctpop.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x i32> @llvm.vp.ctpop.v16i32 (<16 x i32> <op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x i32> @llvm.vp.ctpop.nxv4i32 (<vscale x 4 x i32> <op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x i64> @llvm.vp.ctpop.v256i64 (<256 x i64> <op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated ctpop of a vector of integers. Arguments:; """""""""""""""""""". The fi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:833560,perform,performs,833560,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; atomicrmw release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/at",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:261034,load,load,261034,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," if the; called function requires the struct to be in memory, for example because its; address is taken, then the function body is responsible for allocating a stack; location and copying the field arguments into it. Clang terms this *direct; struct*. The source language input struct type arguments that are greater than 16 bytes,; are passed by reference. The caller is responsible for allocating a stack; location to make a copy of the struct value and pass the address as the input; argument. The called function is responsible to perform the dereference when; accessing the input argument. Clang terms this *by-value struct*. A source language result struct type argument that is greater than 16 bytes, is; returned by reference. The caller is responsible for allocating a stack location; to hold the result value and passes the address as the last input argument; (before the implicit input arguments). In this case there are no result; arguments. The called function is responsible to perform the dereference when; storing the result value. Clang terms this *structured return (sret)*. *TODO: correct the ``sret`` definition.*. .. TODO::. Is this definition correct? Or is ``sret`` only used if passing in registers, and; pass as non-decomposed struct as stack argument? Or something else? Is the; memory location in the caller stack frame, or a stack memory argument and so; no address is passed as the caller can directly write to the argument stack; location? But then the stack location is still live after return. If an; argument stack location is it the first stack argument or the last one?. Lambda argument types are treated as struct types with an implementation defined; set of fields. .. TODO::. Need to specify the ABI for lambda types for AMDGPU. For AMDGPU backend all source language arguments (including the decomposed; struct type arguments) are passed in VGPRs unless marked ``inreg`` in which case; they are passed in SGPRs. The AMDGPU backend walks the function call graph ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:393383,perform,perform,393383,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['perform']
Performance," in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol.; - Ensures the atomicrmw; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; -",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:248625,load,loads,248625,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," in ``XXXInstrInfo.td`` files; according to the target-specific instruction set. Relation models are defined; using ``InstrMapping`` class as a base. TableGen parses all the models; and generates instruction relation maps using the specified information.; Relation maps are emitted as tables in the ``XXXGenInstrInfo.inc`` file; along with the functions to query them. For the detailed information on how to; use this feature, please refer to :doc:`HowToUseInstrMappings`. Implement a subclass of ``TargetInstrInfo``; -------------------------------------------. The final step is to hand code portions of ``XXXInstrInfo``, which implements; the interface described in ``TargetInstrInfo.h`` (see :ref:`TargetInstrInfo`).; These functions return ``0`` or a Boolean or they assert, unless overridden.; Here's a list of functions that are overridden for the SPARC implementation in; ``SparcInstrInfo.cpp``:. * ``isLoadFromStackSlot`` --- If the specified machine instruction is a direct; load from a stack slot, return the register number of the destination and the; ``FrameIndex`` of the stack slot. * ``isStoreToStackSlot`` --- If the specified machine instruction is a direct; store to a stack slot, return the register number of the destination and the; ``FrameIndex`` of the stack slot. * ``copyPhysReg`` --- Copy values between a pair of physical registers. * ``storeRegToStackSlot`` --- Store a register value to a stack slot. * ``loadRegFromStackSlot`` --- Load a register value from a stack slot. * ``storeRegToAddr`` --- Store a register value to memory. * ``loadRegFromAddr`` --- Load a register value from memory. * ``foldMemoryOperand`` --- Attempt to combine instructions of any load or; store instruction for the specified operand(s). Branch Folding and If Conversion; --------------------------------. Performance can be improved by combining instructions or by eliminating; instructions that are never reached. The ``analyzeBranch`` method in; ``XXXInstrInfo`` may be implemented to exam",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:46103,load,load,46103,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,1,['load'],['load']
Performance," in an anonymous namespace --- this reflects the fact that passes; are self contained units that do not need external interfaces (although they; can have them) to be useful. Running a pass with ``opt``; ---------------------------. Now that you have a brand new shiny shared object file, we can use the; :program:`opt` command to run an LLVM program through your pass. Because you; registered your pass with ``RegisterPass``, you will be able to use the; :program:`opt` tool to access it, once loaded. To test it, follow the example at the end of the :doc:`GettingStarted` to; compile ""Hello World"" to LLVM. We can now run the bitcode file (hello.bc) for; the program through our transformation like this (or course, any bitcode file; will work):. .. code-block:: console. $ opt -load lib/LLVMHello.so -hello < hello.bc > /dev/null; Hello: __main; Hello: puts; Hello: main. The :option:`-load` option specifies that :program:`opt` should load your pass; as a shared object, which makes ""``-hello``"" a valid command line argument; (which is one reason you need to :ref:`register your pass; <writing-an-llvm-pass-registration>`). Because the Hello pass does not modify; the program in any interesting way, we just throw away the result of; :program:`opt` (sending it to ``/dev/null``). To see what happened to the other string you registered, try running; :program:`opt` with the :option:`-help` option:. .. code-block:: console. $ opt -load lib/LLVMHello.so -help; OVERVIEW: llvm .bc -> .bc modular optimizer and analysis printer. USAGE: opt [subcommand] [options] <input bitcode file>. OPTIONS:; Optimizations available:; ...; -guard-widening - Widen guards; -gvn - Global Value Numbering; -gvn-hoist - Early GVN Hoisting of Expressions; -hello - Hello World Pass; -indvars - Induction Variable Simplification; -inferattrs - Infer set function attributes; ... The pass name gets added as the information string for your pass, giving some; documentation to users of :program:`opt`. Now that you have a",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:8357,load,load,8357,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,2,['load'],['load']
Performance," in highly predictable terminators into their successor blocks.; If a hot successor block contains instructions which can be vectorized; with the duplicated ones, this can provide a noticeable throughput; improvement. Note that this is not always profitable and does involve a; potentially large increase in code size. #. When checking a value against a constant, emit the check using a consistent; comparison type. The GVN pass *will* optimize redundant equalities even if; the type of comparison is inverted, but GVN only runs late in the pipeline.; As a result, you may miss the opportunity to run other important; optimizations. #. Avoid using arithmetic intrinsics unless you are *required* by your source; language specification to emit a particular code sequence. The optimizer; is quite good at reasoning about general control flow and arithmetic, it is; not anywhere near as strong at reasoning about the various intrinsics. If; profitable for code generation purposes, the optimizer will likely form the; intrinsics itself late in the optimization pipeline. It is *very* rarely; profitable to emit these directly in the language frontend. This item; explicitly includes the use of the :ref:`overflow intrinsics <int_overflow>`. #. Avoid using the :ref:`assume intrinsic <int_assume>` until you've; established that a) there's no other way to express the given fact and b); that fact is critical for optimization purposes. Assumes are a great; prototyping mechanism, but they can have negative effects on both compile; time and optimization effectiveness. The former is fixable with enough; effort, but the later is fairly fundamental to their designed purpose. Describing Language Specific Properties; =======================================. When translating a source language to LLVM, finding ways to express concepts; and guarantees available in your source language which are not natively; provided by LLVM IR will greatly improve LLVM's ability to optimize your code.; As an example, C",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:9109,optimiz,optimizer,9109,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,2,['optimiz'],"['optimization', 'optimizer']"
Performance," in order to fix the bug described here:; https://savannah.cern.ch/bugs/?41423 .; The simple following macro was enough to show the problem:. {; TH1D h(""h"", ""h"", 10., 0., 1.); h.Fill(.5);; THStack s(""s"", ""s""); s.Add(&h);; TCanvas canvas(""canvas"");; frame = canvas.DrawFrame(-1., 0., 2., 2.);; frame.SetLabelSize(0.05, ""XY"");; frame.Draw(); s.Draw(""same"");; }. Make the data member fHistogram persistent in order to save the; axis attributes which may have been changed during a root session (like,; for instance, the axis titles).; When a THStack is drawn with the option ""pads"", the number of lines is; now optimized to make sure there is no empty line. . TUnfold. Introduces this new class for solving inverse problems:. data histograms with Gaussian errors are decomposed into; several template distributions (""generator level"" bins). The result are new normalisation constants for the template; distributions (the unfolded ""generator level"" distribution). The solution can be tuned by properly adjusting the; regularisation parameter tau. A standard method, the L-curve scan is; implemented to help finding a good choice of this parameter. Two example tutorials are included to show the usage of this class: tutorials/math/testUnfiold1.C and tutorials/math/testUnfiold2.C. FitPanel; Add a new revised version of the Fit Panel with the following functionality:. Add support now for fitting, in addition to the TH1 and TGraph; also for TH2, TH3, TMultiGraph and TGraph2D and TTree (with un-binned; fits); Add possibility to select the data object directly from the Fit; panel. The Fit Panel can also be open directly from the TCanvas menu; (under Tools); Improve the function selection by having the possibility to; support user defined function, predefined functions and functions; used before for fitting. ; Allow the opening of the parameter dialog in case of linear; fitter. This is needed for example for fixing some of the; parameters; Improve minimization panel by adding some extra methods, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v522/index.html:7672,tune,tuned,7672,hist/doc/v522/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/hist/doc/v522/index.html,1,['tune'],['tuned']
Performance," in the ``@llvm.used`` list, then the compiler, assembler,; and linker are required to treat the symbol as if there is a reference to the; symbol that it cannot see (which is why they have to be named). For example, if; a variable has internal linkage and no references other than that from the; ``@llvm.used`` list, it cannot be deleted. This is commonly used to represent; references from inline asms and other things the compiler cannot ""see"", and; corresponds to ""``attribute((used))``"" in GNU C. On some targets, the code generator must emit a directive to the; assembler or object file to prevent the assembler and linker from; removing the symbol. .. _gv_llvmcompilerused:. The '``llvm.compiler.used``' Global Variable; --------------------------------------------. The ``@llvm.compiler.used`` directive is the same as the ``@llvm.used``; directive, except that it only prevents the compiler from touching the; symbol. On targets that support it, this allows an intelligent linker to; optimize references to the symbol without being impeded as it would be; by ``@llvm.used``. This is a rare construct that should only be used in rare circumstances,; and should not be exposed to source languages. .. _gv_llvmglobalctors:. The '``llvm.global_ctors``' Global Variable; -------------------------------------------. .. code-block:: llvm. %0 = type { i32, ptr, ptr }; @llvm.global_ctors = appending global [1 x %0] [%0 { i32 65535, ptr @ctor, ptr @data }]. The ``@llvm.global_ctors`` array contains a list of constructor; functions, priorities, and an associated global or function.; The functions referenced by this array will be called in ascending order; of priority (i.e. lowest first) when the module is loaded. The order of; functions with the same priority is not defined. If the third field is non-null, and points to a global variable; or function, the initializer function will only run if the associated; data from the current module is not discarded.; On ELF the referenced global varia",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:352321,optimiz,optimize,352321,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimize']
Performance," in the logging stream. It should; always be possible for the symbolizing filter to be implemented as a single pass; over the raw logging stream, accumulating context and massaging text as it goes. ``{{{reset}}}``. This should be output before any other contextual element. The need for this; contextual element is to support implementations that handle logs coming from; multiple processes. Such implementations might not know when a new process; starts or ends. Because some identifying information (like process IDs) might; be the same between old and new processes, a way is needed to distinguish two; processes with such identical identifying information. This element informs; such implementations to reset the state of a filter so that information from a; previous process's contextual elements is not assumed for new process that; just happens have the same identifying information. ``{{{module:%i:%s:%s:...}}}``. This element represents a so-called ""module"". A ""module"" is a single linked; binary, such as a loaded ELF file. Usually each module occupies a contiguous; range of memory. Here ``%i`` is the module ID which is used by other contextual elements to; refer to this module. The first ``%s`` is a human-readable identifier for the; module, such as an ELF ``DT_SONAME`` string or a file name; but it might be; empty. It's only for casual information. Only the module ID is used to refer; to this module in other contextual elements, never the ``%s`` string. The; ``module`` element defining a module ID must always be emitted before any; other elements that refer to that module ID, so that a filter never needs to; keep track of dangling references. The second ``%s`` is the module type and it; determines what the remaining fields are. The following module types are; supported:. * ``elf:%x``. Here ``%x`` encodes an ELF Build ID. The Build ID should refer to a single; linked binary. The Build ID string is the sole way to identify the binary from; which this module was loaded. Ex",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:19055,load,loaded,19055,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,1,['load'],['loaded']
Performance," in total and per thread. ## Compressed vs Uncompressed Throughput:. Throughput speeds are provided as compressed and uncompressed - ROOT files are usually; saved in compressed format, so these will often differ. Compressed bytes is the total; number of bytes read from TFiles during the readspeed test (possibly including meta-data).; Uncompressed bytes is the number of bytes processed by reading the branch values in the TTree.; Throughput is calculated as the total number of bytes over the total runtime (including; decompression time) in the uncompressed and compressed cases. ## Interpreting results:. ### There are three possible scenarios when using rootreadspeed, namely:. - The 'Real Time' is significantly lower than your own analysis runtime.; This would imply your actual application code is dominating the runtime of your analysis,; ie. your analysis logic or framework is taking up the time.; The best way to decrease the runtime would be to optimize your code (or the framework's),; parallelize it onto multiple threads if possible (for example with; [RDataFrame](https://root.cern/doc/master/classROOT_1_1RDataFrame.html); and [EnableImplicitMT](https://root.cern/doc/master/namespaceROOT.html#a06f2b8b216b615e5abbc872c9feff40f)); or switch to a machine with a more performant CPU.; - The 'Real Time' is significantly higher than 'CPU Time / number of threads'*.; If the real time is higher than the CPU time per core it implies the reading of data is the; bottleneck, as the CPU cores are wasting time waiting for data to arrive from your disk/drive; or network connection in order to decompress it.; The best way to decrease your runtime would be transferring the data you need onto a faster; storage medium (ie. a faster disk/drive such as an SSD, or connecting to a faster network; for remote file access), or to use a compression algorithm with a higher compression ratio,; possibly at the cost of the decompression rate.; Changing the number of threads is unlikely to help, and",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/tree/readspeed/README.md:1320,optimiz,optimize,1320,tree/readspeed/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/readspeed/README.md,1,['optimiz'],['optimize']
Performance," including section, symbol and relocation information. RuntimeDyldImpl::loadObject then iterates through the symbols in the; image. Information about common symbols is collected for later use. For; each function or data symbol, the associated section is loaded into memory; and the symbol is stored in a symbol table map data structure. When the; iteration is complete, a section is emitted for the common symbols. Next, RuntimeDyldImpl::loadObject iterates through the sections in the; object image and for each section iterates through the relocations for; that sections. For each relocation, it calls the format-specific; processRelocationRef method, which will examine the relocation and store; it in one of two data structures, a section-based relocation list map and; an external symbol relocation map. .. image:: MCJIT-load-object.png. When RuntimeDyldImpl::loadObject returns, all of the code and data; sections for the object will have been loaded into memory allocated by the; memory manager and relocation information will have been prepared, but the; relocations have not yet been applied and the generated code is still not; ready to be executed. [Currently (as of August 2013) the MCJIT engine will immediately apply; relocations when loadObject completes. However, this shouldn't be; happening. Because the code may have been generated for a remote target,; the client should be given a chance to re-map the section addresses before; relocations are applied. It is possible to apply relocations multiple; times, but in the case where addresses are to be re-mapped, this first; application is wasted effort.]. Address Remapping; =================. At any time after initial code has been generated and before; finalizeObject is called, the client can remap the address of sections in; the object. Typically this is done because the code was generated for an; external process and is being mapped into that process' address space.; The client remaps the section address by calling MCJIT::",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst:5161,load,loadObject,5161,interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MCJITDesignAndImplementation.rst,2,['load'],"['loadObject', 'loaded']"
Performance," independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vm/vscnt(0). - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; following; buffer_gl*_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 4. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vm/vscnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Use vmcnt(0) if atomic with; return and vscnt",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:368088,load,loads,368088,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," indicated by the register *id*.; hwreg(<*name*>) All bits of a register indicated by the register *name*.; hwreg({0..63}, {0..31}, {1..32}) Register bits indicated by the register *id*, first bit *offset* and *size*.; hwreg(<*name*>, {0..31}, {1..32}) Register bits indicated by the register *name*, first bit *offset* and *size*.; ==================================== ===============================================================================. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Predefined register *names* include:. ============================== ==========================================; Name Description; ============================== ==========================================; HW_REG_MODE Shader writable mode bits.; HW_REG_STATUS Shader read-only status.; HW_REG_TRAPSTS Trap status.; HW_REG_HW_ID1 Id of wave, simd, compute unit, etc.; HW_REG_HW_ID2 Id of queue, pipeline, etc.; HW_REG_GPR_ALLOC Per-wave SGPR and VGPR allocation.; HW_REG_LDS_ALLOC Per-wave LDS allocation.; HW_REG_IB_STS Counters of outstanding instructions.; HW_REG_SH_MEM_BASES Memory aperture.; HW_REG_TBA_LO tba_lo register.; HW_REG_TBA_HI tba_hi register.; HW_REG_TMA_LO tma_lo register.; HW_REG_TMA_HI tma_hi register.; HW_REG_FLAT_SCR_LO flat_scratch_lo register.; HW_REG_FLAT_SCR_HI flat_scratch_hi register.; HW_REG_POPS_PACKER pops_packer register.; HW_REG_SHADER_CYCLES Current graphics clock counter value.; ============================== ==========================================. Examples:. .. parsed-literal::. reg = 1; offset = 2; size = 4; hwreg_enc = reg | (offset << 6) | ((size - 1) << 11). s_getreg_b32 s2, 0x1881; s_getreg_b32 s2, hwreg_enc // the same as above; s_getreg_b32 s2, hwreg(1, 2, 4) // the same as above; s_getreg_b32 s2, hwreg(reg, offset, size) // the same as above. s_getreg_b32 s2, hwreg(15); s_getreg_b32 s2, hwreg(51, 1, 31); s_getreg_b32 s2, hwre",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_hwreg.rst:2141,queue,queue,2141,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_hwreg.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_hwreg.rst,1,['queue'],['queue']
Performance," indicated by the register *id*.; hwreg(<*name*>) All bits of a register indicated by the register *name*.; hwreg({0..63}, {0..31}, {1..32}) Register bits indicated by the register *id*, first bit *offset* and *size*.; hwreg(<*name*>, {0..31}, {1..32}) Register bits indicated by the register *name*, first bit *offset* and *size*.; ==================================== ===============================================================================. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Predefined register *names* include:. ============================== ==========================================; Name Description; ============================== ==========================================; HW_REG_MODE Shader writable mode bits.; HW_REG_STATUS Shader read-only status.; HW_REG_TRAPSTS Trap status.; HW_REG_HW_ID1 Id of wave, simd, compute unit, etc.; HW_REG_HW_ID2 Id of queue, pipeline, etc.; HW_REG_GPR_ALLOC Per-wave SGPR and VGPR allocation.; HW_REG_LDS_ALLOC Per-wave LDS allocation.; HW_REG_IB_STS Counters of outstanding instructions.; HW_REG_SH_MEM_BASES Memory aperture.; HW_REG_TBA_LO tba_lo register.; HW_REG_TBA_HI tba_hi register.; HW_REG_TMA_LO tma_lo register.; HW_REG_TMA_HI tma_hi register.; HW_REG_FLAT_SCR_LO flat_scratch_lo register.; HW_REG_FLAT_SCR_HI flat_scratch_hi register.; HW_REG_XNACK_MASK xnack_mask register.; HW_REG_POPS_PACKER pops_packer register.; ============================== ==========================================. Examples:. .. parsed-literal::. reg = 1; offset = 2; size = 4; hwreg_enc = reg | (offset << 6) | ((size - 1) << 11). s_getreg_b32 s2, 0x1881; s_getreg_b32 s2, hwreg_enc // the same as above; s_getreg_b32 s2, hwreg(1, 2, 4) // the same as above; s_getreg_b32 s2, hwreg(reg, offset, size) // the same as above. s_getreg_b32 s2, hwreg(15); s_getreg_b32 s2, hwreg(51, 1, 31); s_getreg_b32 s2, hwreg(HW_REG_LDS_ALLOC, ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_hwreg.rst:2139,queue,queue,2139,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_hwreg.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_hwreg.rst,1,['queue'],['queue']
Performance," information as they; perform aggressive optimizations. This means that, with effort, the LLVM; optimizers could optimize debug code just as well as non-debug code. * LLVM debug information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining), but you might lose the ability to modify the program; and call functions which were optimized out of the program, or inlined away; completely. The :doc:`LLVM test-suite <TestSuiteMakefileGuide>` provides a framework to; test the optimizer's handling of debugging information. It can be run like; this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=dbgopt. This will test impact of debugging information on optimization passes. If; debugging information influences optimization passes then it will be reported; as a failure. See :doc:`TestingGuide` for more information on LLVM test; infrastructure and how to run various tests. .. _format:. Debugging information format; ============================. LLVM debugging information has been carefully designed to make it possible for; the optimizer to optimize the program and debugging information without; necessarily having to know anything about debugging information. In; particular, the use of metadata avoids dupli",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:5619,optimiz,optimized,5619,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['optimiz'],['optimized']
Performance," information on what and how to install is provided below,; but the recommended (and much easier) way is to use the following command which; performs the required checks automatically and displays useful suggestions too; specific to your platform.; ```sh; cd tools/packaging/; ./cpt.py --check-requirements; ```; or; ```sh; cd tools/packaging/; ./cpt.py -c; ```; Regardless of the platform and operating system, make sure to call the cpt script; with Python 3.; CPT uses some features and modules which are not a part of older versions of Python.; The same holds true for the versions of GCC/Clang you have on your machine. Older; compilers do not support c++11 features and thus you can expect a build error if you; choose not to update them. All pre-compiled binaries of Python ship with built-in support for SSL. However if; the Python on your system was compiled by you manually, chances are that it doesn't; have SSL support. This is very likely if you had performed a minimal installation; of Scientific Linux CERN which doesn't include OpenSSL development package. In such; a case, you should install ```openssl-devel```, re-compile Python and ```configure```; will automatically link against the required libraries and produce a binary with SSL; support. #### Ubuntu/Debian; On Debian, Ubuntu, Linux Mint, CrunchBang, or any other distro based on Debian; which supports APT package manager, you can install all the required packages by:; ```sh; sudo apt-get update; sudo apt-get install git g++ debhelper devscripts gnupg python; ```; You are not required to do this manually since CPT can do this for you automatically. ###### Setting up:; Make sure GnuPG is properly set up with your correct fingerprint. These; credentials are needed to sign the Debian package and create Debian changelogs.; On a build machine (Electric Commander), make sure the fingerprint is of the; user who is supposed to sign the official uploads. You might also want to; configure GnuPG to not ask for the passphrase",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md:2077,perform,performed,2077,interpreter/cling/tools/packaging/README.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/tools/packaging/README.md,1,['perform'],['performed']
Performance," instantiate any_cast<int>:; int boost::any_cast(boost::any&& operand) =>; wrapexcept<boost::bad_any_cast>: boost::bad_any_cast: failed conversion using boost::any_cast; >>> extract = boost.any_cast[std.vector[int]](val) # correct cast; >>> type(extract) is std.vector[int]; True; >>> extract += xrange(100); >>> len(extract); 100; >>> val.__assign__(std.move(extract)) # move forced; <cppyy.gbl.boost.any object at 0xf6a8a0>; >>> len(extract) # now empty (or invalid); 0; >>> extract = boost.any_cast[std.vector[int]](val); >>> list(extract); [0, 1, 2, 3, 4, 5, 6, ..., 97, 98, 99]; >>>. Of course, there is no reason to use Boost from Python (in fact, this example; calls out for :doc:`pythonizations <pythonizations>`), but it shows that; cppyy seamlessly supports many advanced C++ features. cppyy is available for both `CPython`_ (v2 and v3) and `PyPy`_, reaching; C++-like performance with the latter.; It makes judicious use of precompiled headers, dynamic loading, and lazy; instantiation, to support C++ programs consisting of millions of lines of; code and many thousands of classes.; cppyy minimizes dependencies to allow its use in distributed, heterogeneous,; development environments. .. _Cling: https://github.com/vgvassilev/cling; .. _tutorial: https://github.com/wlav/cppyy/blob/master/doc/tutorial/CppyyTutorial.ipynb; .. _`PyHPC'16 paper`: http://wlav.web.cern.ch/wlav/Cppyy_LavrijsenDutta_PyHPC16.pdf; .. _`CAAS presentation`: https://www.youtube.com/watch?v=stMD7VDWlVU; .. _`Jason Turner's`: https://www.youtube.com/watch?v=TL83P77vZ1k; .. _`Boost`: http://www.boost.org/; .. _`CPython`: http://python.org; .. _`PyPy`: http://pypy.org. .. only: not latex. Contents:. .. toctree::; :maxdepth: 1. changelog; license. .. toctree::; :caption: Getting Started; :maxdepth: 1. installation; starting; examples; bugs. .. toctree::; :caption: Features; :maxdepth: 1. toplevel; basic_types; strings; classes; functions; type_conversions; stl; exceptions; python; numba; cuda; lowlevel; mi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:4416,load,loading,4416,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst,1,['load'],['loading']
Performance," instruction; requiring REX prefix. However, divb and mulb both produce results in AH. If isel; emits a CopyFromReg which gets turned into a movb and that can be allocated a; r8b - r15b. To get around this, isel emits a CopyFromReg from AX and then right shift it; down by 8 and truncate it. It's not pretty but it works. We need some register; allocation magic to make the hack go away (e.g. putting additional constraints; on the result of the movb). //===---------------------------------------------------------------------===//. The x86-64 ABI for hidden-argument struct returns requires that the; incoming value of %rdi be copied into %rax by the callee upon return. The idea is that it saves callers from having to remember this value,; which would often require a callee-saved register. Callees usually; need to keep this value live for most of their body anyway, so it; doesn't add a significant burden on them. We currently implement this in codegen, however this is suboptimal; because it means that it would be quite awkward to implement the; optimization for callers. A better implementation would be to relax the LLVM IR rules for sret; arguments to allow a function with an sret argument to have a non-void; return type, and to have the front-end to set up the sret argument value; as the return value of the function. The front-end could more easily; emit uses of the returned struct value to be in terms of the function's; lowered return value, and it would free non-C frontends from a; complication only required by a C-based ABI. //===---------------------------------------------------------------------===//. We get a redundant zero extension for code like this:. int mask[1000];; int foo(unsigned x) {; if (x < 10); x = x * 45;; else; x = x * 78;; return mask[x];; }. _foo:; LBB1_0:	## entry; 	cmpl	$9, %edi; 	jbe	LBB1_3	## bb; LBB1_1:	## bb1; 	imull	$78, %edi, %eax; LBB1_2:	## bb2; 	movl	%eax, %eax <----; 	movq	_mask@GOTPCREL(%rip), %rcx; 	movl	(%rcx,%rax,4), %eax; 	ret; LBB",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-X86-64.txt:2259,optimiz,optimization,2259,interpreter/llvm-project/llvm/lib/Target/X86/README-X86-64.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-X86-64.txt,1,['optimiz'],['optimization']
Performance," instructions in the; linked section to narrow down the bug so that the person who fixes it will be; able to find the problem more easily. Once you have a reduced test-case, go to `the LLVM Bug Tracking System; <https://github.com/llvm/llvm-project/issues>`_ and fill out the form with the; necessary details (note that you don't need to pick a label, just use if you're; not sure). The bug description should contain the following information:. * All information necessary to reproduce the problem.; * The reduced test-case that triggers the bug.; * The location where you obtained LLVM (if not from our Git; repository). Thanks for helping us make LLVM better!. .. _crashes the compiler:. Crashing Bugs; =============. More often than not, bugs in the compiler cause it to crash---often due to; an assertion failure of some sort. The most important piece of the puzzle; is to figure out if it is crashing in the Clang front-end or if it is one of; the LLVM libraries (e.g. the optimizer or code generator) that has; problems. To figure out which component is crashing (the front-end, middle-end; optimizer, or backend code generator), run the ``clang`` command line as you; were when the crash occurred, but with the following extra command line; options:. * ``-emit-llvm -Xclang -disable-llvm-passes``: If ``clang`` still crashes when; passed these options (which disable the optimizer and code generator), then; the crash is in the front-end. Jump ahead to :ref:`front-end bugs; <frontend-crash>`. * ``-emit-llvm``: If ``clang`` crashes with this option (which disables; the code generator), you found a middle-end optimizer bug. Jump ahead to; :ref:`middle-end bugs <middleend-crash>`. * Otherwise, you have a backend code generator crash. Jump ahead to :ref:`code; generator bugs <backend-crash>`. .. _frontend-crash:. Front-end bugs; --------------. On a ``clang`` crash, the compiler will dump a preprocessed file and a script; to replay the ``clang`` command. For example, you should see some",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst:1692,optimiz,optimizer,1692,interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HowToSubmitABug.rst,1,['optimiz'],['optimizer']
Performance," interpretations: the full; tag interpretation (where the pointer tag is between 1 and `TG-1` and the; last byte of the granule is ordinary data) and the short tag interpretation; (where the pointer tag is stored in the granule). When HWASAN detects an error near a memory tag between 1 and `TG-1`, it; will show both the memory tag and the last byte of the granule. Currently,; it is up to the user to disambiguate the two possibilities. Instrumentation; ===============. Memory Accesses; ---------------; In the majority of cases, memory accesses are prefixed with a call to; an outlined instruction sequence that verifies the tags. The code size; and performance overhead of the call is reduced by using a custom calling; convention that. * preserves most registers, and; * is specialized to the register containing the address, and the type and; size of the memory access. Currently, the following sequence is used:. .. code-block:: none. // int foo(int *a) { return *a; }; // clang -O2 --target=aarch64-linux-android30 -fsanitize=hwaddress -S -o - load.c; [...]; foo:; stp x30, x20, [sp, #-16]!; adrp x20, :got:__hwasan_shadow // load shadow address from GOT into x20; ldr x20, [x20, :got_lo12:__hwasan_shadow]; bl __hwasan_check_x0_2_short_v2 // call outlined tag check; // (arguments: x0 = address, x20 = shadow base;; // ""2"" encodes the access type and size); ldr w0, [x0] // inline load; ldp x30, x20, [sp], #16; ret. [...]; __hwasan_check_x0_2_short_v2:; sbfx x16, x0, #4, #52 // shadow offset; ldrb w16, [x20, x16] // load shadow tag; cmp x16, x0, lsr #56 // extract address tag, compare with shadow tag; b.ne .Ltmp0 // jump to short tag handler on mismatch; .Ltmp1:; ret; .Ltmp0:; cmp w16, #15 // is this a short tag?; b.hi .Ltmp2 // if not, error; and x17, x0, #0xf // find the address's position in the short granule; add x17, x17, #3 // adjust to the position of the last byte loaded; cmp w16, w17 // check that position is in bounds; b.ls .Ltmp2 // if not, error; orr x16, x0, #0xf //",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst:3771,load,load,3771,interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/HardwareAssistedAddressSanitizerDesign.rst,1,['load'],['load']
Performance," into a single executable (which is fairly common in large apps).; Having a single malloc would just not suffice, and instead would simply; complicate the picture further because it adds an extra variant in; addition to the one each language provides. Instead, providing a default library version of malloc and free; (and perhaps a malloc_gc with garbage collection instead of free); would make a good implementation available to anyone who wants it. I don't recall all your arguments in favor so let's discuss this again,; and soon. o 'alloca' on the other hand sounds like a good idea, and the; implementation seems fairly language-independent so it doesn't have the; problems with malloc listed above. o About indirect call:; Your option #2 sounded good to me. I'm not sure I understand your; concern about an explicit 'icall' instruction?. o A pair of important synchronization instr'ns to think about:; load-linked; store-conditional. o Other classes of instructions that are valuable for pipeline performance:; conditional-move		 ; predicated instructions. o I believe tail calls are relatively easy to identify; do you know why; .NET has a tailcall instruction?. o I agree that we need a static data space. Otherwise, emulating global; data gets unnecessarily complex. o About explicit parallelism:. We once talked about adding a symbolic thread-id field to each; instruction. (It could be optional so single-threaded codes are; not penalized.) This could map well to multi-threaded architectures; while providing easy ILP for single-threaded onces. But it is probably; too radical an idea to include in a base version of LLVM. Instead, it; could a great topic for a separate study. What is the semantics of the IA64 stop bit?. o And finally, another thought about the syntax for arrays :-). Although this syntax:; 	 array <dimension-list> of <type>; is verbose, it will be used only in the human-readable assembly code so; size should not matter. I think we should consider it because I find i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveComments.txt:3442,perform,performance,3442,interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveComments.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/HistoricalNotes/2001-02-09-AdveComments.txt,1,['perform'],['performance']
Performance," into memory at arbitrary locations,; and set bias to the offset between the original and the new counter location,; at which point every subsequent counter access will be to the new location,; which allows updating profile directly akin to the continuous mode. The advantage of this approach is that doesn't require any special OS support.; The disadvantage is the extra overhead due to additional instructions required; for each counter access (overhead both in terms of binary size and performance); plus duplication of counters (i.e. one copy in the binary itself and another; copy that's mapped into memory). This implementation can be also enabled for; other platforms by passing the ``-runtime-counter-relocation`` option to the; backend during compilation. For a program such as the `Lit <https://llvm.org/docs/CommandGuide/lit.html>`_; testing tool which invokes other programs, it may be necessary to set; ``LLVM_PROFILE_FILE`` for each invocation. The pattern strings ""%p"" or ""%Nm""; may help to avoid corruption due to concurrency. Note that ""%p"" is also a Lit; token and needs to be escaped as ""%%p"". .. code-block:: console. % clang++ -fprofile-instr-generate -fcoverage-mapping -mllvm -runtime-counter-relocation foo.cc -o foo. Creating coverage reports; =========================. Raw profiles have to be **indexed** before they can be used to generate; coverage reports. This is done using the ""merge"" tool in ``llvm-profdata``; (which can combine multiple raw profiles and index them at the same time):. .. code-block:: console. # Step 3(a): Index the raw profile.; % llvm-profdata merge -sparse foo.profraw -o foo.profdata. For an example of merging multiple profiles created by testing,; see the LLVM `coverage build script <https://github.com/llvm/llvm-zorg/blob/main/zorg/jenkins/jobs/jobs/llvm-coverage>`_. There are multiple different ways to render coverage reports. The simplest; option is to generate a line-oriented report:. .. code-block:: console. # Step 3(b): Create a l",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst:5635,concurren,concurrency,5635,interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/SourceBasedCodeCoverage.rst,1,['concurren'],['concurrency']
Performance," into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; foll",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:218857,load,loads,218857,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - system *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the followin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:255197,load,loads,255197,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," intrinsic. ::. declare <16 x float> @llvm.vp.fma.v16f32 (<16 x float> <left_op>, <16 x float> <middle_op>, <16 x float> <right_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.fma.nxv4f32 (<vscale x 4 x float> <left_op>, <vscale x 4 x float> <middle_op>, <vscale x 4 x float> <right_op>, <vscale x 4 x i1> <mask>, i32 <vector_length>); declare <256 x double> @llvm.vp.fma.v256f64 (<256 x double> <left_op>, <256 x double> <middle_op>, <256 x double> <right_op>, <256 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated floating-point fused multiply-add of two vectors of floating-point values. Arguments:; """""""""""""""""""". The first three operands and the result have the same vector of floating-point type. The; fourth operand is the vector mask and has the same number of elements as the; result vector type. The fifth operand is the explicit vector length of the; operation. Semantics:; """""""""""""""""""". The '``llvm.vp.fma``' intrinsic performs floating-point fused multiply-add (:ref:`llvm.fma <int_fma>`); of the first, second, and third vector operand on each enabled lane. The result on; disabled lanes is a :ref:`poison value <poisonvalues>`. The operation is; performed in the default floating-point environment. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call <4 x float> @llvm.vp.fma.v4f32(<4 x float> %a, <4 x float> %b, <4 x float> %c, <4 x i1> %mask, i32 %evl); ;; For all lanes below %evl, %r is lane-wise equivalent to %also.r. %t = call <4 x float> @llvm.fma(<4 x float> %a, <4 x float> %b, <4 x float> %c); %also.r = select <4 x i1> %mask, <4 x float> %t, <4 x float> poison. .. _int_vp_fmuladd:. '``llvm.vp.fmuladd.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare <16 x float> @llvm.vp.fmuladd.v16f32 (<16 x float> <left_op>, <16 x float> <middle_op>, <16 x float> <right_op>, <16 x i1> <mask>, i32 <vector_length>); declare <vscale x 4 x float> @llvm.vp.fmuladd.nx",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:745549,perform,performs,745549,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," intrinsics treat ``%A`` as a ``<OuterRows> x; <Inner>`` matrix, ``%B`` as a ``<Inner> x <OuterColumns>`` matrix, and; multiplies them. The result matrix is returned in the result vector. Arguments:; """""""""""""""""""". The first vector argument ``%A`` corresponds to a matrix with ``<OuterRows> *; <Inner>`` elements, and the second argument ``%B`` to a matrix with; ``<Inner> * <OuterColumns>`` elements. Arguments ``<OuterRows>``,; ``<Inner>`` and ``<OuterColumns>`` must be positive, constant integers. The; returned vector must have ``<OuterRows> * <OuterColumns>`` elements.; Vectors ``%A``, ``%B``, and the returned vector all have the same float or; integer element type. '``llvm.matrix.column.major.load.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare vectorty @llvm.matrix.column.major.load.*(; ptrty %Ptr, i64 %Stride, i1 <IsVolatile>, i32 <Rows>, i32 <Cols>). Overview:; """""""""""""""""". The '``llvm.matrix.column.major.load.*``' intrinsics load a ``<Rows> x <Cols>``; matrix using a stride of ``%Stride`` to compute the start address of the; different columns. The offset is computed using ``%Stride``'s bitwidth. This; allows for convenient loading of sub matrixes. If ``<IsVolatile>`` is true, the; intrinsic is considered a :ref:`volatile memory access <volatile>`. The result; matrix is returned in the result vector. If the ``%Ptr`` argument is known to; be aligned to some boundary, this can be specified as an attribute on the; argument. Arguments:; """""""""""""""""""". The first argument ``%Ptr`` is a pointer type to the returned vector type, and; corresponds to the start address to load from. The second argument ``%Stride``; is a positive, constant integer with ``%Stride >= <Rows>``. ``%Stride`` is used; to compute the column memory addresses. I.e., for a column ``C``, its start; memory addresses is calculated with ``%Ptr + C * %Stride``. The third Argument; ``<IsVolatile>`` is a boolean value. The fourth and fif",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:677903,load,load,677903,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," is already zero ; extended in the 32-bit stack slot IIRC. For signed short, it should also be; save, as a really-signed value would be undefined for pslld. //===---------------------------------------------------------------------===//. #include <math.h>; int t1(double d) { return signbit(d); }. This currently compiles to:; 	subl	$12, %esp; 	movsd	16(%esp), %xmm0; 	movsd	%xmm0, (%esp); 	movl	4(%esp), %eax; 	shrl	$31, %eax; 	addl	$12, %esp; 	ret. We should use movmskp{s|d} instead. //===---------------------------------------------------------------------===//. CodeGen/X86/vec_align.ll tests whether we can turn 4 scalar loads into a single; (aligned) vector load. This functionality has a couple of problems. 1. The code to infer alignment from loads of globals is in the X86 backend,; not the dag combiner. This is because dagcombine2 needs to be able to see; through the X86ISD::Wrapper node, which DAGCombine can't really do.; 2. The code for turning 4 x load into a single vector load is target ; independent and should be moved to the dag combiner.; 3. The code for turning 4 x load into a vector load can only handle a direct ; load from a global or a direct load from the stack. It should be generalized; to handle any load from P, P+4, P+8, P+12, where P can be anything.; 4. The alignment inference code cannot handle loads from globals in non-static; mode because it doesn't look through the extra dyld stub load. If you try; vec_align.ll without -relocation-model=static, you'll see what I mean. //===---------------------------------------------------------------------===//. We should lower store(fneg(load p), q) into an integer load+xor+store, which; eliminates a constant pool load. For example, consider:. define i64 @ccosf(float %z.0, float %z.1) nounwind readonly {; entry:; %tmp6 = fsub float -0.000000e+00, %z.1		; <float> [#uses=1]; %tmp20 = tail call i64 @ccoshf( float %tmp6, float %z.0 ) nounwind readonly; ret i64 %tmp20; }; declare i64 @ccoshf(float %z.0, float %z.1",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt:11781,load,load,11781,interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/X86/README-SSE.txt,2,['load'],['load']
Performance," is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.smax.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.smax.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated signed-integer ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.smax``' intrinsic performs the signed-integer ``MAX``; reduction (:ref:`llvm.vector.reduce.smax <int_vector_reduce_smax>`) of the; vector operand ``val`` on each enabled lane, and taking the maximum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``INT_MIN`` (i.e. having no effect on the reduction operation).; If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i8 @llvm.vp.reduce.smax.v4i8(i8 %start, <4 x i8> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i8> %a, <4 x i8> <i8 -128, i8 -128, i8 -128, i8 -128>; %reduction = call i8 @llvm.vector.reduce.smax.v4i8(<4 x i8> %masked.a); %also.r = call i8 @llvm.smax.i8(i8 %reduction, i8 %start). .. _int_vp_reduce_smin:. '``llvm.vp.reduce.smin.*``' Intrinsics",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:763811,perform,performs,763811,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.smin.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.smin.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated signed-integer ``MIN`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.smin``' intrinsic performs the signed-integer ``MIN``; reduction (:ref:`llvm.vector.reduce.smin <int_vector_reduce_smin>`) of the; vector operand ``val`` on each enabled lane, and taking the minimum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``INT_MAX`` (i.e. having no effect on the reduction operation).; If the vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i8 @llvm.vp.reduce.smin.v4i8(i8 %start, <4 x i8> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equal to %evl; ; are treated as though %mask were false for those lanes. %masked.a = select <4 x i1> %mask, <4 x i8> %a, <4 x i8> <i8 127, i8 127, i8 127, i8 127>; %reduction = call i8 @llvm.vector.reduce.smin.v4i8(<4 x i8> %masked.a); %also.r = call i8 @llvm.smin.i8(i8 %reduction, i8 %start). .. _int_vp_reduce_umax:. '``llvm.vp.reduce.umax.*``' Intrinsics; ^^",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:765876,perform,performs,765876,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performs']
Performance," is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:5325,perform,performance,5325,interpreter/llvm-project/llvm/docs/TestingGuide.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst,1,['perform'],['performance']
Performance," is combined with poison-generating metadata like ``!nonnull``,; violation of that metadata constraint will also result in undefined behavior. Semantics:; """""""""""""""""""". The location of memory pointed to is loaded. If the value being loaded; is of scalar type then the number of bytes read does not exceed the; minimum number of bytes needed to hold all bits of the type. For; example, loading an ``i24`` reads at most three bytes. When loading a; value of a type like ``i20`` with a size that is not an integral number; of bytes, the result is undefined if the value was not originally; written using a store of the same type.; If the value being loaded is of aggregate type, the bytes that correspond to; padding may be accessed but are ignored, because it is impossible to observe; padding from the loaded aggregate value.; If ``<pointer>`` is not a well-defined value, the behavior is undefined. Examples:; """""""""""""""""". .. code-block:: llvm. %ptr = alloca i32 ; yields ptr; store i32 3, ptr %ptr ; yields void; %val = load i32, ptr %ptr ; yields i32:val = i32 3. .. _i_store:. '``store``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. store [volatile] <ty> <value>, ptr <pointer>[, align <alignment>][, !nontemporal !<nontemp_node>][, !invariant.group !<empty_node>] ; yields void; store atomic [volatile] <ty> <value>, ptr <pointer> [syncscope(""<target-scope>"")] <ordering>, align <alignment> [, !invariant.group !<empty_node>] ; yields void; !<nontemp_node> = !{ i32 1 }; !<empty_node> = !{}. Overview:; """""""""""""""""". The '``store``' instruction is used to write to memory. Arguments:; """""""""""""""""""". There are two arguments to the ``store`` instruction: a value to store and an; address at which to store it. The type of the ``<pointer>`` operand must be a; pointer to the :ref:`first class <t_firstclass>` type of the ``<value>``; operand. If the ``store`` is marked as ``volatile``, then the optimizer is not; allowed to modify the number or order of execution of this ``store`` with other",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:418965,load,load,418965,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," is equivalent to calling ``func`` with the same argument list,; but with ``nval`` used for the missing ``nest`` argument. If, after; calling ``llvm.init.trampoline``, the memory pointed to by ``tramp`` is; modified, then the effect of any later call to the returned function; pointer is undefined. .. _int_at:. '``llvm.adjust.trampoline``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare ptr @llvm.adjust.trampoline(ptr <tramp>). Overview:; """""""""""""""""". This performs any required machine-specific adjustment to the address of; a trampoline (passed as ``tramp``). Arguments:; """""""""""""""""""". ``tramp`` must point to a block of memory which already has trampoline; code filled in by a previous call to; :ref:`llvm.init.trampoline <int_it>`. Semantics:; """""""""""""""""""". On some architectures the address of the code to be executed needs to be; different than the address where the trampoline is actually stored. This; intrinsic returns the executable address corresponding to ``tramp``; after performing the required machine specific adjustments. The pointer; returned can then be :ref:`bitcast and executed <int_trampoline>`. .. _int_vp:. Vector Predication Intrinsics; -----------------------------; VP intrinsics are intended for predicated SIMD/vector code. A typical VP; operation takes a vector mask and an explicit vector length parameter as in:. ::. <W x T> llvm.vp.<opcode>.*(<W x T> %x, <W x T> %y, <W x i1> %mask, i32 %evl). The vector mask parameter (%mask) always has a vector of `i1` type, for example; `<32 x i1>`. The explicit vector length parameter always has the type `i32` and; is an unsigned integer value. The explicit vector length parameter (%evl) is in; the range:. ::. 0 <= %evl <= W, where W is the number of vector elements. Note that for :ref:`scalable vector types <t_vector>` ``W`` is the runtime; length of the vector. The VP intrinsic has undefined behavior if ``%evl > W``. The explicit vector; length (%evl) creates a mask, %EVLmask, with all e",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:691467,perform,performing,691467,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performing']
Performance," is evaluated in; the context of the calling frame. *It may be used to determine the value of arguments on entry to the current; call frame provided they are not clobbered.*. It has two operands. The first is an unsigned LEB128 integer S. The second; is a block of bytes, with a length equal S, interpreted as a DWARF; operation expression E. E is evaluated with the current context, except the result kind is; unspecified, the call frame is the one that called the current frame, the; program location is the call site in the calling frame, the object is; unspecified, and the initial stack is empty. The calling frame information; is obtained by virtually unwinding the current call frame using the call; frame information (see :ref:`amdgpu-dwarf-call-frame-information`). If the result of E is a location description L (see; :ref:`amdgpu-dwarf-register-location-description-operations`), and the last; operation executed by E is a ``DW_OP_reg*`` for register R with a target; architecture specific base type of T, then the contents of the register are; retrieved as if a ``DW_OP_deref_type DR`` operation was performed where DR; is the offset of a hypothetical debug information entry in the current; compilation unit for T. The resulting value V s pushed on the stack. *Using* ``DW_OP_reg*`` *provides a more compact form for the case where the; value was in a register on entry to the subprogram.*. .. note::. It is unclear how this provides a more compact expression, as; ``DW_OP_regval_type`` could be used which is marginally larger. If the result of E is a value V, then V is pushed on the stack. Otherwise, the DWARF expression is ill-formed. *The* ``DW_OP_entry_value`` *operation is deprecated as its main usage is; provided by other means. DWARF Version 5 added the*; ``DW_TAG_call_site_parameter`` *debugger information entry for call sites; that has* ``DW_AT_call_value``\ *,* ``DW_AT_call_data_location``\ *, and*; ``DW_AT_call_data_value`` *attributes that provide DWARF expressions t",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:96544,perform,performed,96544,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['perform'],['performed']
Performance," is inconvenient and wasteful for every front-end to; have to reproduce this logic. Memory in LLVM; ==============. The 'trick' here is that while LLVM does require all register values to; be in SSA form, it does not require (or permit) memory objects to be in; SSA form. In the example above, note that the loads from G and H are; direct accesses to G and H: they are not renamed or versioned. This; differs from some other compiler systems, which do try to version memory; objects. In LLVM, instead of encoding dataflow analysis of memory into; the LLVM IR, it is handled with `Analysis; Passes <../../WritingAnLLVMPass.html>`_ which are computed on demand. With this in mind, the high-level idea is that we want to make a stack; variable (which lives in memory, because it is on the stack) for each; mutable object in a function. To take advantage of this trick, we need; to talk about how LLVM represents stack variables. In LLVM, all memory accesses are explicit with load/store instructions,; and it is carefully designed not to have (or need) an ""address-of""; operator. Notice how the type of the @G/@H global variables is actually; ""i32\*"" even though the variable is defined as ""i32"". What this means is; that @G defines *space* for an i32 in the global data area, but its; *name* actually refers to the address for that space. Stack variables; work the same way, except that instead of being declared with global; variable definitions, they are declared with the `LLVM alloca; instruction <../../LangRef.html#alloca-instruction>`_:. .. code-block:: llvm. define i32 @example() {; entry:; %X = alloca i32 ; type of %X is i32*.; ...; %tmp = load i32, i32* %X ; load the stack value %X from the stack.; %tmp2 = add i32 %tmp, 1 ; increment it; store i32 %tmp2, i32* %X ; store it back; ... This code shows an example of how you can declare and manipulate a stack; variable in the LLVM IR. Stack memory allocated with the alloca; instruction is fully general: you can pass the address of the stac",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:4374,load,load,4374,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['load'],['load']
Performance," is inferred from the target triple and autodetected to; the current architecture. For a list of available CPUs, use:. .. code-block:: none. llvm-as < /dev/null | llc -march=xyz -mcpu=help. .. option:: -filetype=<output file type>. Specify what kind of output ``llc`` should generated. Options are: ``asm``; for textual assembly ( ``'.s'``), ``obj`` for native object files (``'.o'``); and ``null`` for not emitting anything (for performance testing). Note that not all targets support all options. .. option:: -mattr=a1,+a2,-a3,... Override or control specific attributes of the target, such as whether SIMD; operations are enabled or not. The default set of attributes is set by the; current CPU. For a list of available attributes, use:. .. code-block:: none. llvm-as < /dev/null | llc -march=xyz -mattr=help. .. option:: --frame-pointer. Specify effect of frame pointer elimination optimization (all,non-leaf,none). .. option:: --disable-excess-fp-precision. Disable optimizations that may produce excess precision for floating point.; Note that this option can dramatically slow down code on some systems; (e.g. X86). .. option:: --enable-no-infs-fp-math. Enable optimizations that assume no Inf values. .. option:: --enable-no-nans-fp-math. Enable optimizations that assume no NAN values. .. option:: --enable-no-signed-zeros-fp-math. Enable FP math optimizations that assume the sign of 0 is insignificant. .. option:: --enable-no-trapping-fp-math. Enable setting the FP exceptions build attribute not to use exceptions. .. option:: --enable-unsafe-fp-math. Enable optimizations that make unsafe assumptions about IEEE math (e.g. that; addition is associative) or may not work for all input ranges. These; optimizations allow the code generator to make use of some instructions which; would otherwise not be usable (such as ``fsin`` on X86). .. option:: --stats. Print statistics recorded by code-generation passes. .. option:: --time-passes. Record the amount of time needed for each pass and",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst:3239,optimiz,optimizations,3239,interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llc.rst,1,['optimiz'],['optimizations']
Performance," is inverted, but GVN only runs late in the pipeline.; As a result, you may miss the opportunity to run other important; optimizations. #. Avoid using arithmetic intrinsics unless you are *required* by your source; language specification to emit a particular code sequence. The optimizer; is quite good at reasoning about general control flow and arithmetic, it is; not anywhere near as strong at reasoning about the various intrinsics. If; profitable for code generation purposes, the optimizer will likely form the; intrinsics itself late in the optimization pipeline. It is *very* rarely; profitable to emit these directly in the language frontend. This item; explicitly includes the use of the :ref:`overflow intrinsics <int_overflow>`. #. Avoid using the :ref:`assume intrinsic <int_assume>` until you've; established that a) there's no other way to express the given fact and b); that fact is critical for optimization purposes. Assumes are a great; prototyping mechanism, but they can have negative effects on both compile; time and optimization effectiveness. The former is fixable with enough; effort, but the later is fairly fundamental to their designed purpose. Describing Language Specific Properties; =======================================. When translating a source language to LLVM, finding ways to express concepts; and guarantees available in your source language which are not natively; provided by LLVM IR will greatly improve LLVM's ability to optimize your code.; As an example, C/C++'s ability to mark every add as ""no signed wrap (nsw)"" goes; a long way to assisting the optimizer in reasoning about loop induction; variables and thus generating more optimal code for loops. The LLVM LangRef includes a number of mechanisms for annotating the IR with; additional semantic information. It is *strongly* recommended that you become; highly familiar with this document. The list below is intended to highlight a; couple of items of particular interest, but is by no means exhaust",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:9663,optimiz,optimization,9663,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,1,['optimiz'],['optimization']
Performance," is irrelevant; it's perfectly; valid to compute arbitrary element indices, as the computation only depends on; the size of the array element, not the number of elements. Note that zero-sized; arrays are not a special case here. This sense is unconnected with ``inbounds`` keyword. The ``inbounds`` keyword is; designed to describe low-level pointer arithmetic overflow conditions, rather; than high-level array indexing rules. Analysis passes which wish to understand array indexing should not assume that; the static array type bounds are respected. The second sense of being out of bounds is computing an address that's beyond; the actual underlying allocated object. With the ``inbounds`` keyword, the result value of the GEP is ``poison`` if the; address is outside the actual underlying allocated object and not the address; one-past-the-end. Without the ``inbounds`` keyword, there are no restrictions on computing; out-of-bounds addresses. Obviously, performing a load or a store requires an; address of allocated and sufficiently aligned memory. But the GEP itself is only; concerned with computing addresses. Can array indices be negative?; ------------------------------. Yes. This is basically a special case of array indices being out of bounds. Can I compare two values computed with GEPs?; --------------------------------------------. Yes. If both addresses are within the same allocated object, or; one-past-the-end, you'll get the comparison result you expect. If either is; outside of it, integer arithmetic wrapping may occur, so the comparison may not; be meaningful. Can I do GEP with a different pointer type than the type of the underlying object?; ----------------------------------------------------------------------------------. Yes. There are no restrictions on bitcasting a pointer value to an arbitrary; pointer type. The types in a GEP serve only to define the parameters for the; underlying integer computation. They need not correspond with the actual type of; the un",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst:14033,perform,performing,14033,interpreter/llvm-project/llvm/docs/GetElementPtr.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GetElementPtr.rst,2,"['load', 'perform']","['load', 'performing']"
Performance," is painted the same way in GL and non-GL mode.; The mismatch was reported in [this post](https://root-forum.cern.ch/t/how-to-specify-the-level-value-in-isosurface-drawing-with-tf3-and-gl/32179). ## Geometry Libraries. ## Database Libraries. The CMake module `FindOracle.cmake` was updated to support version 18.x; of the Oracle client libraries. ## Networking Libraries. ## GUI Libraries. ## Montecarlo Libraries. ## PROOF Libraries. ## Language Bindings. ## JavaScript ROOT. ### New functionality from 5.7.0 release. - Add support of `TProfile2Poly` class; - Add support of `TGeoOverlap` class; - Add support of `TGeoHalfSpace` for composites; - Implement update of `TF2` drawings, see `tutorials/graphics/anim.C`; - Improve windows handling in flex(ible) layout; - Provide special widget for object inspector; - Use `requestAnimationFrame` when do monitoring, improves performance; - Better position for text in `TH2Poly` drawings; - Support eve7 geometry viewer - render data generated in ROOT itself; - Provide initial WebVR support, thanks to Diego Marcos; - Use `gStyle` attributes to draw histogram title; - Enable projections drawing also with `TH2` lego plots; - Many adjustment with new `TWebCanvas` - interactivity, attributes/position updates, context menus; - Upgrade three.js 86 -> 102, use `SoftwareRenderer` instead of `CanvasRenderer`; - Upgrade d3.js 4.4.4 -> 5.7.0; - Fix - support clipping for tracks and points in geo painter; - Fix - drawing of TGeoNode with finder; - Fix - key press events processed only in active pad (ROOT-9128); - Fix - use X0/Y0 in xtru shape, thanks to @altavir. ### New files location. JSROOT sources were moved from `etc/http/` into `js/` subfolder in ROOT sources tree.; OpenUI5 files were moved to `ui5/` subfolder. After ROOT compilation they can be found in; `$ROOTSYS/js/` and `$ROOTSYS/ui5/` subfolders respectively. ## Tutorials; - Add `RSqliteDS` examples.; - Make RCsvDS and RLazyDS tutorials standalone, i.e. downloading input csv directly us",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md:20715,perform,performance,20715,README/ReleaseNotes/v618/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v618/index.md,1,['perform'],['performance']
Performance," is the minimum remaining bit storage size of L which is defined as; follows. LS is the location storage and LO is the location bit offset; specified by a single location description SL of L. The remaining bit; storage size RBSS of SL is the bit size of LS minus LO. *rbss(L)* is the; minimum RBSS of each single location description SL of L. The DWARF expression is ill-formed if *rbss(BL)* is less than BO plus BS. If BS is 0, then the operation pushes BL. If BO is 0 and BS equals *rbss(BL)*, then the operation pushes OL. Otherwise, the operation is equivalent to performing the following steps to; push a composite location description. *The composite location description is conceptually the base location; description BL with the overlay location description OL positioned as an; overlay starting at the overlay offset BO and covering overlay bit size BS.*. 1. If BO is not 0 then push BL followed by performing the ``DW_OP_bit_piece; BO, 0`` operation.; 2. Push OL followed by performing the ``DW_OP_bit_piece BS, 0`` operation.; 3. If *rbss(BL)* is greater than BO plus BS, push BL followed by performing; the ``DW_OP_bit_piece (rbss(BL) - BO - BS), (BO + BS)`` operation.; 4. Perform the ``DW_OP_LLVM_piece_end`` operation. .. _amdgpu-dwarf-location-list-expressions:. A.2.5.5 DWARF Location List Expressions; +++++++++++++++++++++++++++++++++++++++. .. note::. This section replaces DWARF Version 5 section 2.6.2. *To meet the needs of recent computer architectures and optimization techniques,; debugging information must be able to describe the location of an object whose; location changes over the object’s lifetime, and may reside at multiple; locations during parts of an object's lifetime. Location list expressions are; used in place of operation expressions whenever the object whose location is; being described has these requirements.*. A location list expression consists of a series of location list entries. Each; location list entry is one of the following kinds:. *Bounded ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:142056,perform,performing,142056,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,1,['perform'],['performing']
Performance," is their defining or optimized; access.; Traditionally ``MemorySSA`` optimized ``MemoryUse``\ s at build-time, up to a; given threshold.; Specifically, the operand of every ``MemoryUse`` was optimized to point to the; actual clobber of said ``MemoryUse``. This can be seen in the above example; the; second ``MemoryUse`` in ``if.end`` has an operand of ``1``, which is a; ``MemoryDef`` from the entry block. This is done to make walking,; value numbering, etc, faster and easier.; As of `this revision <https://reviews.llvm.org/D121381>`_, the default was; changed to not optimize uses at build time, in order to provide the option to; reduce compile-time if the walking is not necessary in a pass. Most users call; the new API ``ensureOptimizedUses()`` to keep the previous behavior and do a; one-time optimization of ``MemoryUse``\ s, if this was not done before.; New pass users are recommended to call ``ensureOptimizedUses()``. Initially it was not possible to optimize ``MemoryDef``\ s in the same way, as we; restricted ``MemorySSA`` to one operand per access.; This was changed and ``MemoryDef``\ s now keep two operands.; The first one, the defining access, is; always the previous ``MemoryDef`` or ``MemoryPhi`` in the same basic block, or; the last one in a dominating predecessor if the current block doesn't have any; other accesses writing to memory. This is needed for walking Def chains.; The second operand is the optimized access, if there was a previous call on the; walker's ``getClobberingMemoryAccess(MA)``. This API will cache information; as part of ``MA``.; Optimizing all ``MemoryDef``\ s has quadratic time complexity and is not done; by default. A walk of the uses for any MemoryDef can find the accesses that were optimized; to it.; A code snippet for such a walk looks like this:. .. code-block:: c++. MemoryDef *Def; // find who's optimized or defining for this MemoryDef; for (auto& U : Def->uses()) {; MemoryAccess *MA = cast<MemoryAccess>(Use.getUser());; if (auto *",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst:12016,optimiz,optimize,12016,interpreter/llvm-project/llvm/docs/MemorySSA.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/MemorySSA.rst,1,['optimiz'],['optimize']
Performance," is unresponsive with `SIGKILL`).; Defaults to **0 (no timeout)**. dsmgrd.corruptafterfails *n*; : Set this to a number above zero to tell the daemon to mark files as; corrupted after a certain number of either download or verification; failures. A value of **0 (default)** tells the daemon to retry; forever. Configuring the MonALISA monitoring plugin; ------------------------------------------. The Dataset Stager supports generic monitoring plugins. The only plugin; distributed with the stager is the MonALISA monitoring plugin. dsmgrd.notifyplugin */path/to/libafdsmgrd\_notify\_apmon.so*; : Set it to the path of the MonALISA plugin shared object. By default,; notification plugin is disabled. dsmgrd.apmonurl *apmon://apmon.cern.ch*; : This variable tells the ApMon notification plugin how to contact one; or more MonALISA server(s) to activate monitoring via ApMon. It; supports two kinds of URLs:. - `http[s]://host/path/configuration_file.conf` (a remote file; where to fetch the list of servers from). - `apmon://[:password@]monalisahost[:8884]` (a single server to; contact directly). If the variable is not set, yet the plugin is loaded, MonALISA; monitoring is inhibited until a valid configuration variable is; provided. dsmgrd.apmonprefix *MY::CLUSTER::PREFIX*; : Since MonALISA organizes information in ""clusters"" and ""hosts"", here; you can specify what to use as cluster prefix for monitoring; datasets information and daemon status. If this variable is not set,; MonALISA monitoring is inhibited. Please note that the suffix; `_datasets` or `_status` is appended for each of the two types of; monitoring. A sample configuration file; ---------------------------. xpd.stagereqrepo /opt/aaf/var/proof/datasets; dsmgrd.purgenoopds true; dsmgrd.urlregex alien://(.*)$ /storage$1; dsmgrd.sleepsecs 20; dsmgrd.scandseveryloops 30; dsmgrd.parallelxfrs 10; dsmgrd.stagecmd /opt/aaf/bin/af-xrddm-verify.sh ""$URLTOSTAGE"" ""$TREENAME""; dsmgrd.cmdtimeoutsecs 3600; dsmgrd.corruptafterfails 0; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md:5551,load,loaded,5551,proof/doc/confman/DatasetStager.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/confman/DatasetStager.md,1,['load'],['loaded']
Performance," is unsafe to; optimize or assume that the result of the '``and``' is '``undef``'.; However, it is safe to assume that all bits of the '``undef``' could be; 0, and optimize the '``and``' to 0. Likewise, it is safe to assume that; all the bits of the '``undef``' operand to the '``or``' could be set,; allowing the '``or``' to be folded to -1. .. code-block:: llvm. %A = select undef, %X, %Y; %B = select undef, 42, %Y; %C = select %X, %Y, undef; Safe:; %A = %X (or %Y); %B = 42 (or %Y); %C = %Y (if %Y is provably not poison; unsafe otherwise); Unsafe:; %A = undef; %B = undef; %C = undef. This set of examples shows that undefined '``select``' (and conditional; branch) conditions can go *either way*, but they have to come from one; of the two operands. In the ``%A`` example, if ``%X`` and ``%Y`` were; both known to have a clear low bit, then ``%A`` would have to have a; cleared low bit. However, in the ``%C`` example, the optimizer is; allowed to assume that the '``undef``' operand could be the same as; ``%Y`` if ``%Y`` is provably not '``poison``', allowing the whole '``select``'; to be eliminated. This is because '``poison``' is stronger than '``undef``'. .. code-block:: llvm. %A = xor undef, undef. %B = undef; %C = xor %B, %B. %D = undef; %E = icmp slt %D, 4; %F = icmp gte %D, 4. Safe:; %A = undef; %B = undef; %C = undef; %D = undef; %E = undef; %F = undef. This example points out that two '``undef``' operands are not; necessarily the same. This can be surprising to people (and also matches; C semantics) where they assume that ""``X^X``"" is always zero, even if; ``X`` is undefined. This isn't true for a number of reasons, but the; short answer is that an '``undef``' ""variable"" can arbitrarily change; its value over its ""live range"". This is true because the variable; doesn't actually *have a live range*. Instead, the value is logically; read from arbitrary registers that happen to be around when needed, so; the value is not necessarily consistent over time. In fact, ``%A`",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:193252,optimiz,optimizer,193252,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizer']
Performance," is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic. atomicrmw acq_rel - workgroup - local 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - g",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:223564,perform,performing,223564,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance," is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acq_rel - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures tha",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:266086,perform,performing,266086,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['perform'],['performing']
Performance," is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. fence release - system *none* 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; ato",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:315228,perform,performing,315228,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance," is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. fence release - system *none* 1. buffer_wbl2. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:264668,perform,performing,264668,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance," it has loaded the shared; object. The most foolproof way of doing this is to set a breakpoint in; ``PassManager::run`` and then run the process with the arguments you want:. .. code-block:: console. $ (gdb) break llvm::PassManager::run; Breakpoint 1 at 0x2413bc: file Pass.cpp, line 70.; (gdb) run test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Starting program: opt test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Breakpoint 1, PassManager::run (this=0xffbef174, M=@0x70b298) at Pass.cpp:70; 70 bool PassManager::run(Module &M) { return PM->run(M); }; (gdb). Once the :program:`opt` stops in the ``PassManager::run`` method you are now; free to set breakpoints in your pass so that you can trace through execution or; do other standard debugging stuff. Miscellaneous Problems; ^^^^^^^^^^^^^^^^^^^^^^. Once you have the basics down, there are a couple of problems that GDB has,; some with solutions, some without. * Inline functions have bogus stack information. In general, GDB does a pretty; good job getting stack traces and stepping through inline functions. When a; pass is dynamically loaded however, it somehow completely loses this; capability. The only solution I know of is to de-inline a function (move it; from the body of a class to a ``.cpp`` file). * Restarting the program breaks breakpoints. After following the information; above, you have succeeded in getting some breakpoints planted in your pass.; Next thing you know, you restart the program (i.e., you type ""``run``"" again),; and you start getting errors about breakpoints being unsettable. The only; way I have found to ""fix"" this problem is to delete the breakpoints that are; already set in your pass, run the program, and re-set the breakpoints once; execution stops in ``PassManager::run``. Hopefully these tips will help with common case debugging situations. If you'd; like to contribute some tips of your own, just contact `Chris; <mailto:sabre@nondot.org>`_.; ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:54548,load,loaded,54548,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,1,['load'],['loaded']
Performance," it may simply happen that they really represent a; single object, too complex to be described by a primitive shape. Usually handling structures like these can be easily done by positioning; all components in the same container volume, then positioning the; container itself. However, there are many practical cases when defining; such a container is not straightforward or even possible without; generating overlaps with the rest of the geometry. There are few ways; out of this:. - Defining the container for the structure as ""overlapping"" (see also; "" Overlapping Volumes **""**); - Representing the container as a composite shape - the Boolean union; of all components (see also "" Composite Shapes ""); - Using an assembly volume - this will be described in the following. The first two approaches have the disadvantage of penalizing the; navigation performance with a factor increasing more than linear of the; number of components in the structure. The best solution is the third; one because it uses all volume-related navigation optimizations. The; class **`TGeoVolumeAssembly`** represents an assembly volume. Its shape; is represented by **`TGeoShapeAssembly`** class that is the union of all; components. It uses volume voxelization to perform navigation tasks. An assembly volume creates a hierarchical level and it geometrically; insulates the structure from the rest (as a normal volume). Physically,; a point that is INSIDE a **`TGeoShapeAssembly`** is always inside one of; the components, so a **`TGeoVolumeAssembly`** does not need to have a; medium. Due to the self-containment of assemblies, they are very; practical to use when a container is hard to define due to possible; overlaps during positioning. For instance, it is very easy creating; honeycomb structures. A very useful example for creating and using; assemblies can be found at:; <http://root.cern.ch/root/html/examples/assembly.C.html>`.`. Creation of an assembly is very easy: one has just to create a; **`TGeoVolumeAss",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md:89226,optimiz,optimizations,89226,documentation/users-guide/Geometry.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/users-guide/Geometry.md,1,['optimiz'],['optimizations']
Performance," it must retain the power to decrease the lifetime of an object.; Unfortunately, while it's generally poor style for the destruction; of objects to have arbitrary side-effects, it's certainly possible.; Hence the caveat. .. _arc.optimization.precise:. Precise lifetime semantics; --------------------------. In general, ARC maintains an invariant that a retainable object pointer held in; a ``__strong`` object will be retained for the full formal lifetime of the; object. Objects subject to this invariant have :arc-term:`precise lifetime; semantics`. By default, local variables of automatic storage duration do not have precise; lifetime semantics. Such objects are simply strong references which hold; values of retainable object pointer type, and these values are still fully; subject to the optimizations on values under local control. .. admonition:: Rationale. Applying these precise-lifetime semantics strictly would be prohibitive.; Many useful optimizations that might theoretically decrease the lifetime of; an object would be rendered impossible. Essentially, it promises too much. A local variable of retainable object owner type and automatic storage duration; may be annotated with the ``objc_precise_lifetime`` attribute to indicate that; it should be considered to be an object with precise lifetime semantics. .. admonition:: Rationale. Nonetheless, it is sometimes useful to be able to force an object to be; released at a precise time, even if that object does not appear to be used.; This is likely to be uncommon enough that the syntactic weight of explicitly; requesting these semantics will not be burdensome, and may even make the code; clearer. .. _arc.misc:. Miscellaneous; =============. .. _arc.misc.special_methods:. Special methods; ---------------. .. _arc.misc.special_methods.retain:. Memory management methods; ^^^^^^^^^^^^^^^^^^^^^^^^^. A program is ill-formed if it contains a method definition, message send, or; ``@selector`` expression for any of the followin",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:84196,optimiz,optimizations,84196,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimizations']
Performance," iterate over the category states.; - The `HybridCalculatorOriginal` and `HypoTestInverterOriginal` classes in RooStats that were deprecated for a very long time aleady are removed. Please use `HybridCalculator` and `HypoTestInverter`.; - The `RooSimPdfBuilder` that was deprecated in ROOT 5.20 and replaced by the `RooSimWSTool` is removed.; - The RDataFrame factory functions `MakeNumpyDataFrame`, `MakeCsvDataFrame`, `MakeArrowDataFrame`, `MakeNTupleDataFrame` and `MakeSqliteDataFrame` are now deprecated in favor of `FromNumpy`, `FromCSV`, `FromArrow`, `FromRNTuple` and `FromSqlite` respectively. - The build option `alien` has been removed.; - The build options `gfal`, `gsl_shared`, `jemalloc`, `monalisa`, `pyroot_legacy`, `tcmalloc`, and `xproofd` have been deprecated. Please complain with root-dev@cern.ch should you still need one!. ## rootreadspeed. This version adds the new `rootreadspeed` CLI tool. This tool can be used to help identify bottlenecks in analysis runtimes, by providing time and throughput measurements when reading ROOT files via file systems or XRootD. More detailed information can be found in the tool's help information. To see help information, install and source a recent enough version of ROOT, and run the command `rootreadspeed --help` in your terminal. ### Example usage of the tool:. ```console; $ rootreadspeed --files <local-folder>/File1.root xrootd://<url-folder>/File2.root --trees Events --all-branches --threads 8; ```. ## Core Libraries. ### Interpreter. #### Support for profiling/debugging interpreted/JITted code. This version of ROOT adds an LLVM JIT event listener to create perf map files; during runtime. This allows profiling of interpreted/JITted code generated by; cling. Instead of function addresses, the perf data will contain full function; names. In addition, stack frame pointers are enabled in JITted code, so full; stack traces can be generated. Debugging is aided by switching off optimisations; and adding frame pointers for bett",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md:4991,bottleneck,bottlenecks,4991,README/ReleaseNotes/v628/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v628/index.md,2,"['bottleneck', 'throughput']","['bottlenecks', 'throughput']"
Performance," its operand %reg1039 is the result of the; PHI node. We should treat it as a two-address code and make sure the ADDri is; scheduled after any node that reads %reg1039. //===---------------------------------------------------------------------===//. Use local info (i.e. register scavenger) to assign it a free register to allow; reuse:; ldr r3, [sp, #+4]; add r3, r3, #3; ldr r2, [sp, #+8]; add r2, r2, #2; ldr r1, [sp, #+4] <==; add r1, r1, #1; ldr r0, [sp, #+4]; add r0, r0, #2. //===---------------------------------------------------------------------===//. LLVM aggressively lift CSE out of loop. Sometimes this can be negative side-; effects:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; load [i + R1]; ...; load [i + R2]; ...; load [i + R3]. Suppose there is high register pressure, R1, R2, R3, can be spilled. We need; to implement proper re-materialization to handle this:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; R1 = X + 4 @ re-materialized; load [i + R1]; ...; R2 = X + 7 @ re-materialized; load [i + R2]; ...; R3 = X + 15 @ re-materialized; load [i + R3]. Furthermore, with re-association, we can enable sharing:. R1 = X + 4; R2 = X + 7; R3 = X + 15. loop:; T = i + X; load [T + 4]; ...; load [T + 7]; ...; load [T + 15]; //===---------------------------------------------------------------------===//. It's not always a good idea to choose rematerialization over spilling. If all; the load / store instructions would be folded then spilling is cheaper because; it won't require new live intervals / registers. See 2003-05-31-LongShifts for; an example. //===---------------------------------------------------------------------===//. With a copying garbage collector, derived pointers must not be retained across; collector safe points; the collector could move the objects and invalidate the; derived pointer. This is bad enough in the first place, but safe points can; crop up unpredictably. Consider:. %array = load { i32, [0 x %obj] }** %array_addr; %nth_el = getelementptr { i",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt:2061,load,load,2061,interpreter/llvm-project/llvm/lib/CodeGen/README.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/CodeGen/README.txt,1,['load'],['load']
Performance," keep the state as small as possible.; When file pointers ""escape"" (are used in a way that the analyzer can no longer; track them), mark them as such. This prevents false positives in the cases where; the analyzer cannot be sure whether the file was closed or not. These events that will be used for each of these actions are, respectively, PreCall,; PostCall,; DeadSymbols,; and PointerEscape.; The high-level structure of the checker's class is thus:. class SimpleStreamChecker : public Checker<check::PreCall,; check::PostCall,; check::DeadSymbols,; check::PointerEscape> {; public:. void checkPreCall(const CallEvent &Call, CheckerContext &C) const;. void checkPostCall(const CallEvent &Call, CheckerContext &C) const;. void checkDeadSymbols(SymbolReaper &SR, CheckerContext &C) const;. ProgramStateRef checkPointerEscape(ProgramStateRef State,; const InvalidatedSymbols &Escaped,; const CallEvent *Call,; PointerEscapeKind Kind) const;; };. Custom Program States; Checkers often need to keep track of information specific to the checks they; perform. However, since checkers have no guarantee about the order in which the; program will be explored, or even that all possible paths will be explored, this; state information cannot be kept within individual checkers. Therefore, if; checkers need to store custom information, they need to add new categories of; data to the ProgramState. The preferred way to do so is to use one of; several macros designed for this purpose. They are:. REGISTER_TRAIT_WITH_PROGRAMSTATE:; Used when the state information is a single value. The methods available for; state types declared with this macro are get, set, and; remove.; REGISTER_LIST_WITH_PROGRAMSTATE:; Used when the state information is a list of values. The methods available for; state types declared with this macro are add, get,; remove, and contains.; REGISTER_SET_WITH_PROGRAMSTATE:; Used when the state information is a set of values. The methods available for; state types declared with this m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html:12122,perform,perform,12122,interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/checker_dev_manual.html,1,['perform'],['perform']
Performance," known retain-agnostic. An expression is :arc-term:`known retain-agnostic` if it is:. * an Objective-C string literal,; * a load from a ``const`` system global variable of :ref:`C retainable pointer; type <arc.misc.c-retainable>`, or; * a null pointer constant. An expression is :arc-term:`known unretained` if it is an rvalue of :ref:`C; retainable pointer type <arc.misc.c-retainable>` and it is:. * a direct call to a function, and either that function has the; ``cf_returns_not_retained`` attribute or it is an :ref:`audited; <arc.misc.c-retainable.audit>` function that does not have the; ``cf_returns_retained`` attribute and does not follow the create/copy naming; convention,; * a message send, and the declared method either has the; ``cf_returns_not_retained`` attribute or it has neither the; ``cf_returns_retained`` attribute nor a :ref:`selector family; <arc.method-families>` that implies a retained result, or; * :when-revised:`[beginning LLVM 3.6]` :revision:`a load from a` ``const``; :revision:`non-system global variable.`. An expression is :arc-term:`known retained` if it is an rvalue of :ref:`C; retainable pointer type <arc.misc.c-retainable>` and it is:. * a message send, and the declared method either has the; ``cf_returns_retained`` attribute, or it does not have the; ``cf_returns_not_retained`` attribute but it does have a :ref:`selector; family <arc.method-families>` that implies a retained result. Furthermore:. * a comma expression is classified according to its right-hand side,; * a statement expression is classified according to its result expression, if; it has one,; * an lvalue-to-rvalue conversion applied to an Objective-C property lvalue is; classified according to the underlying message send, and; * a conditional operator is classified according to its second and third; operands, if they agree in classification, or else the other if one is known; retain-agnostic. If the cast operand is known retained, the conversion is treated as a; ``__bridge_trans",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:26987,load,load,26987,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['load'],['load']
Performance," lanes. %masked.a = select <4 x i1> %mask, <4 x i8> %a, <4 x i8> <i8 127, i8 127, i8 127, i8 127>; %reduction = call i8 @llvm.vector.reduce.smin.v4i8(<4 x i8> %masked.a); %also.r = call i8 @llvm.smin.i8(i8 %reduction, i8 %start). .. _int_vp_reduce_umax:. '``llvm.vp.reduce.umax.*``' Intrinsics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """"""""""""""; This is an overloaded intrinsic. ::. declare i32 @llvm.vp.reduce.umax.v4i32(i32 <start_value>, <4 x i32> <val>, <4 x i1> <mask>, i32 <vector_length>); declare i16 @llvm.vp.reduce.umax.nxv8i16(i16 <start_value>, <vscale x 8 x i16> <val>, <vscale x 8 x i1> <mask>, i32 <vector_length>). Overview:; """""""""""""""""". Predicated unsigned-integer ``MAX`` reduction of a vector and a scalar starting; value, returning the result as a scalar. Arguments:; """""""""""""""""""". The first operand is the start value of the reduction, which must be a scalar; integer type equal to the result type. The second operand is the vector on; which the reduction is performed and must be a vector of integer values whose; element type is the result/start type. The third operand is the vector mask and; is a vector of boolean values with the same number of elements as the vector; operand. The fourth operand is the explicit vector length of the operation. Semantics:; """""""""""""""""""". The '``llvm.vp.reduce.umax``' intrinsic performs the unsigned-integer ``MAX``; reduction (:ref:`llvm.vector.reduce.umax <int_vector_reduce_umax>`) of the; vector operand ``val`` on each enabled lane, and taking the maximum of that and; the scalar ``start_value``. Disabled lanes are treated as containing the; neutral value ``0`` (i.e. having no effect on the reduction operation). If the; vector length is zero, the result is the start value. To ignore the start value, the neutral value can be used. Examples:; """""""""""""""""". .. code-block:: llvm. %r = call i32 @llvm.vp.reduce.umax.v4i32(i32 %start, <4 x i32> %a, <4 x i1> %mask, i32 %evl); ; %r is equivalent to %also.r, where lanes greater than or equ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:767584,perform,performed,767584,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['perform'],['performed']
Performance," language which; supports garbage collection. **Note that LLVM itself does not provide a; garbage collector.** You must provide your own. Quick Start; ============. First, you should pick a collector strategy. LLVM includes a number of built; in ones, but you can also implement a loadable plugin with a custom definition.; Note that the collector strategy is a description of how LLVM should generate; code such that it interacts with your collector and runtime, not a description; of the collector itself. Next, mark your generated functions as using your chosen collector strategy.; From c++, you can call:. .. code-block:: c++. F.setGC(<collector description name>);. This will produce IR like the following fragment:. .. code-block:: llvm. define void @foo() gc ""<collector description name>"" { ... }. When generating LLVM IR for your functions, you will need to:. * Use ``@llvm.gcread`` and/or ``@llvm.gcwrite`` in place of standard load and; store instructions. These intrinsics are used to represent load and store; barriers. If you collector does not require such barriers, you can skip; this step. * Use the memory allocation routines provided by your garbage collector's; runtime library. * If your collector requires them, generate type maps according to your; runtime's binary interface. LLVM is not involved in the process. In; particular, the LLVM type system is not suitable for conveying such; information though the compiler. * Insert any coordination code required for interacting with your collector.; Many collectors require running application code to periodically check a; flag and conditionally call a runtime function. This is often referred to; as a safepoint poll. You will need to identify roots (i.e. references to heap objects your collector; needs to know about) in your generated IR, so that LLVM can encode them into; your final stack maps. Depending on the collector strategy chosen, this is; accomplished by using either the ``@llvm.gcroot`` intrinsics or an; ``gc.s",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst:1224,load,load,1224,interpreter/llvm-project/llvm/docs/GarbageCollection.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GarbageCollection.rst,1,['load'],['load']
Performance," language with; LLVM <index.html>`_"" tutorial. In chapters 1 through 6, we've built a; very respectable, albeit simple, `functional programming; language <http://en.wikipedia.org/wiki/Functional_programming>`_. In our; journey, we learned some parsing techniques, how to build and represent; an AST, how to build LLVM IR, and how to optimize the resultant code as; well as JIT compile it. While Kaleidoscope is interesting as a functional language, the fact; that it is functional makes it ""too easy"" to generate LLVM IR for it. In; particular, a functional language makes it very easy to build LLVM IR; directly in `SSA; form <http://en.wikipedia.org/wiki/Static_single_assignment_form>`_.; Since LLVM requires that the input code be in SSA form, this is a very; nice property and it is often unclear to newcomers how to generate code; for an imperative language with mutable variables. The short (and happy) summary of this chapter is that there is no need; for your front-end to build SSA form: LLVM provides highly tuned and; well tested support for this, though the way it works is a bit; unexpected for some. Why is this a hard problem?; ===========================. To understand why mutable variables cause complexities in SSA; construction, consider this extremely simple C example:. .. code-block:: c. int G, H;; int test(_Bool Condition) {; int X;; if (Condition); X = G;; else; X = H;; return X;; }. In this case, we have the variable ""X"", whose value depends on the path; executed in the program. Because there are two different possible values; for X before the return instruction, a PHI node is inserted to merge the; two values. The LLVM IR that we want for this example looks like this:. .. code-block:: llvm. @G = weak global i32 0 ; type of @G is i32*; @H = weak global i32 0 ; type of @H is i32*. define i32 @test(i1 %Condition) {; entry:; br i1 %Condition, label %cond_true, label %cond_false. cond_true:; %X.0 = load i32, i32* @G; br label %cond_next. cond_false:; %X.1 = load i3",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst:1306,tune,tuned,1306,interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/tutorial/MyFirstLanguageFrontend/LangImpl07.rst,1,['tune'],['tuned']
Performance," last Python; reference to the proxy disappears.; You can check/change the ownership with the __python_owns__ flag that every; bound instance carries.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> c = Concrete(); >>> c.__python_owns__ # True: object created in Python; True; >>>. * ``__creates__``: a flag that every C++ overload carries and determines; whether the return value is owned by C++ or Python: if ``True``, Python owns; the return value, otherwise C++. * ``__set_lifeline__``: a flag that every C++ overload carries and determines; whether the return value should place a back-reference on ``self``, to; prevent the latter from going out of scope before the return value does.; The default is ``False``, but will be automatically set at run-time if a; return value's address is a C++ object pointing into the memory of ``this``,; or if ``self`` is a by-value return. * ``__release_gil__``: a flag that every C++ overload carries and determines; whether the Global Interpreter Lock (GIL) should be released during the C++; call to allow multi-threading.; The default is ``False``. * ``__useffi__``: a flag that every C++ overload carries and determines; whether generated wrappers or direct foreign functions should be used.; This is for PyPy only; the flag has no effect on CPython. * ``__sig2exc__``: a flag that every C++ overload carries and determines; whether C++ signals (such as SIGABRT) should be converted into Python; exceptions. * ``__cpp_name__``: a string that every C++ bound class carries and contains; the actual C++ name (as opposed to ``__name__`` which has the Python name).; This can be useful for template instantiations, documentation, etc. * ``__cpp_template__``: a back-reference to the template used to instantiate; a templated class.; This variable only exists if the class was dynamically instantiated from; Python at least once. `STL algorithms`; ----------------. It is usually easier to use a Python equivalent or code up the eff",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst:2095,multi-thread,multi-threading,2095,bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,1,['multi-thread'],['multi-threading']
Performance," latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand regis",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42362,load,load,42362,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,2,['load'],['load']
Performance," level:""),; cl::values(; clEnumVal(g , ""No optimizations, enable debugging""),; clEnumVal(O1, ""Enable trivial optimizations""),; clEnumVal(O2, ""Enable default optimizations""),; clEnumVal(O3, ""Enable expensive optimizations"")));. ...; if (OptimizationLevel >= O2) doPartialRedundancyElimination(...);; ... This declaration defines a variable ""``OptimizationLevel``"" of the; ""``OptLevel``"" enum type. This variable can be assigned any of the values that; are listed in the declaration. The CommandLine library enforces that; the user can only specify one of the options, and it ensure that only valid enum; values can be specified. The ""``clEnumVal``"" macros ensure that the command; line arguments matched the enum values. With this option added, our help output; now is:. ::. USAGE: compiler [options] <input file>. OPTIONS:; Choose optimization level:; -g - No optimizations, enable debugging; -O1 - Enable trivial optimizations; -O2 - Enable default optimizations; -O3 - Enable expensive optimizations; -f - Enable binary output on terminals; -help - display available options (-help-hidden for more); -o <filename> - Specify output filename; -quiet - Don't print informational messages. In this case, it is sort of awkward that flag names correspond directly to enum; names, because we probably don't want an enum definition named ""``g``"" in our; program. Because of this, we can alternatively write this example like this:. .. code-block:: c++. enum OptLevel {; Debug, O1, O2, O3; };. cl::opt<OptLevel> OptimizationLevel(cl::desc(""Choose optimization level:""),; cl::values(; clEnumValN(Debug, ""g"", ""No optimizations, enable debugging""),; clEnumVal(O1 , ""Enable trivial optimizations""),; clEnumVal(O2 , ""Enable default optimizations""),; clEnumVal(O3 , ""Enable expensive optimizations"")));. ...; if (OptimizationLevel == Debug) outputDebugInfo(...);; ... By using the ""``clEnumValN``"" macro instead of ""``clEnumVal``"", we can directly; specify the name that the flag should get. In general a direct m",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst:15571,optimiz,optimization,15571,interpreter/llvm-project/llvm/docs/CommandLine.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandLine.rst,5,['optimiz'],"['optimization', 'optimizations']"
Performance," lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with me",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:279599,load,loads,279599,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_atomic; sc0=1 sc1=1; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. buffer_wbl2 sc1=1. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address spac",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:313380,load,load,313380,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance, libc/include/llvm-libc-types/imaxdiv_t.h; libc/include/llvm-libc-types/jmp_buf.h; libc/include/llvm-libc-types/ldiv_t.h; libc/include/llvm-libc-types/lldiv_t.h; libc/include/llvm-libc-types/mode_t.h; libc/include/llvm-libc-types/mtx_t.h; libc/include/llvm-libc-types/off_t.h; libc/include/llvm-libc-types/once_flag.h; libc/include/llvm-libc-types/size_t.h; libc/include/llvm-libc-types/ssize_t.h; libc/include/llvm-libc-types/struct_sigaction.h; libc/include/llvm-libc-types/struct_tm.h; libc/include/llvm-libc-types/thrd_start_t.h; libc/include/llvm-libc-types/thrd_t.h; libc/include/llvm-libc-types/time_t.h; libc/include/llvm-libc-types/__atexithandler_t.h; libc/include/llvm-libc-types/__bsearchcompare_t.h; libc/include/llvm-libc-types/__call_once_func_t.h; libc/include/llvm-libc-types/__futex_word.h; libc/include/llvm-libc-types/__mutex_type.h; libc/include/llvm-libc-types/__qsortcompare_t.h; libc/include/llvm-libc-types/__sighandler_t.h; libc/loader/linux/aarch64/start.cpp; libc/loader/linux/x86_64/start.cpp; libc/src/assert/__assert_fail.h; libc/src/ctype/isalnum.cpp; libc/src/ctype/isalnum.h; libc/src/ctype/isalpha.cpp; libc/src/ctype/isalpha.h; libc/src/ctype/isascii.cpp; libc/src/ctype/isascii.h; libc/src/ctype/isblank.cpp; libc/src/ctype/isblank.h; libc/src/ctype/iscntrl.cpp; libc/src/ctype/iscntrl.h; libc/src/ctype/isdigit.cpp; libc/src/ctype/isdigit.h; libc/src/ctype/isgraph.cpp; libc/src/ctype/isgraph.h; libc/src/ctype/islower.cpp; libc/src/ctype/islower.h; libc/src/ctype/isprint.cpp; libc/src/ctype/isprint.h; libc/src/ctype/ispunct.cpp; libc/src/ctype/ispunct.h; libc/src/ctype/isspace.cpp; libc/src/ctype/isspace.h; libc/src/ctype/isupper.cpp; libc/src/ctype/isupper.h; libc/src/ctype/isxdigit.cpp; libc/src/ctype/isxdigit.h; libc/src/ctype/toascii.cpp; libc/src/ctype/toascii.h; libc/src/ctype/tolower.cpp; libc/src/ctype/tolower.h; libc/src/ctype/toupper.cpp; libc/src/ctype/toupper.h; libc/src/errno/dummy_errno.cpp; libc/src/errno/dummy_errno.h; libc/src/errno/e,MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt:132281,load,loader,132281,interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/tools/clang-formatted-files.txt,1,['load'],['loader']
Performance," limiting the transformation of; releases, this rule requires ARC to eliminate retains and release; only in pairs. ARC's power to reorder the destruction of objects is critical to its; ability to do any optimization, for essentially the same reason that; it must retain the power to decrease the lifetime of an object.; Unfortunately, while it's generally poor style for the destruction; of objects to have arbitrary side-effects, it's certainly possible.; Hence the caveat. .. _arc.optimization.precise:. Precise lifetime semantics; --------------------------. In general, ARC maintains an invariant that a retainable object pointer held in; a ``__strong`` object will be retained for the full formal lifetime of the; object. Objects subject to this invariant have :arc-term:`precise lifetime; semantics`. By default, local variables of automatic storage duration do not have precise; lifetime semantics. Such objects are simply strong references which hold; values of retainable object pointer type, and these values are still fully; subject to the optimizations on values under local control. .. admonition:: Rationale. Applying these precise-lifetime semantics strictly would be prohibitive.; Many useful optimizations that might theoretically decrease the lifetime of; an object would be rendered impossible. Essentially, it promises too much. A local variable of retainable object owner type and automatic storage duration; may be annotated with the ``objc_precise_lifetime`` attribute to indicate that; it should be considered to be an object with precise lifetime semantics. .. admonition:: Rationale. Nonetheless, it is sometimes useful to be able to force an object to be; released at a precise time, even if that object does not appear to be used.; This is likely to be uncommon enough that the syntactic weight of explicitly; requesting these semantics will not be burdensome, and may even make the code; clearer. .. _arc.misc:. Miscellaneous; =============. .. _arc.misc.special_methods:",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst:84038,optimiz,optimizations,84038,interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AutomaticReferenceCounting.rst,1,['optimiz'],['optimizations']
Performance," linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining), but you might lose the ability to modify the program; and call functions which were optimized out of the program, or inlined away; completely. The :doc:`LLVM test-suite <TestSuiteMakefileGuide>` provides a framework to; test the optimizer's handling of debugging information. It can be run like; this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=dbgopt. This will test impact of debugging information on optimization passes. If; debugging information influences optimization passes then it will be reported; as a failure. See :doc:`TestingGuide` for more information on LLVM test; infrastructure and how to run various tests. .. _format:. Debugging information format; ============================. LLVM debugging information has been carefully designed to make it possible for; the optimizer to optimize the program and debugging information without; necessarily having to know anything about debugging information. In; particular, the use of metadata avoids duplicated debugging information from; the beginning, and the global dead code elimination pass automatically deletes; debugging information for a function if it decides to delete the function. To do this, most of the debugging information (descriptors for types,; variables, functions, source files, etc) is inserted by the language front-end; in the form of LLVM metadata. Debug information is designed to be agnostic about the target debugger and; debugging information representation (e.g. DWARF/Stabs/etc). I",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:6064,optimiz,optimization,6064,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,1,['optimiz'],['optimization']
Performance," load atomic acquire - workgroup - global 1. buffer/global_load; load atomic acquire - workgroup - local 1. ds/flat_load; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - workgroup - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/lo",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:215230,cache,cache,215230,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vm/vscnt(0). - If CU wavefront execution; mode, omit.; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; the following buffer_gl0_inv; and before any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - workgroup - local 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than the local; atomicrmw value; being acquired. 3. buffer_gl0_inv. - If OpenCL omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - workgroup - generic 1. flat_atomic; 2. s_waitcnt lgkmcnt(0) &; vm/vscnt(0). - If CU wavefront execution; mode, omit vm/vscnt(0).; - If OpenCL, omit lgkmcnt(0).; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vm/vscnt(0). - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; following; buffer_gl*_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:349543,load,loads,349543,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," load/store has this alignment, or; it is undefined behavior’. This means that the back end is free to emit; instructions that rely on that alignment (and mid-level optimizers are free to; perform transforms that require that alignment). For x86, it doesn’t make; much difference, as almost all instructions are alignment-independent. For; MIPS, it can make a big difference. Note that if your loads and stores are atomic, the backend will be unable to; lower an under aligned access into a sequence of natively aligned accesses.; As a result, alignment is mandatory for atomic loads and stores. Other Things to Consider; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Use ptrtoint/inttoptr sparingly (they interfere with pointer aliasing; analysis), prefer GEPs. #. Prefer globals over inttoptr of a constant address - this gives you; dereferencability information. In MCJIT, use getSymbolAddress to provide; actual address. #. Be wary of ordered and atomic memory operations. They are hard to optimize; and may not be well optimized by the current optimizer. Depending on your; source language, you may consider using fences instead. #. If calling a function which is known to throw an exception (unwind), use; an invoke with a normal destination which contains an unreachable; instruction. This form conveys to the optimizer that the call returns; abnormally. For an invoke which neither returns normally or requires unwind; code in the current function, you can use a noreturn call instruction if; desired. This is generally not required because the optimizer will convert; an invoke with an unreachable unwind destination to a call instruction. #. Use profile metadata to indicate statically known cold paths, even if; dynamic profiling information is not available. This can make a large; difference in code placement and thus the performance of tight loops. #. When generating code for loops, try to avoid terminating the header block of; the loop earlier than necessary. If the terminator of the loop header; bl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:6357,optimiz,optimize,6357,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,3,['optimiz'],"['optimize', 'optimized', 'optimizer']"
Performance," load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load sc0=1; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_inv and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; sc0=1 sc1=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. load atomic acquire - agent - generic 1. flat_load sc1=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load sc0=1 sc1=1; 2. s_waitcnt vmcnt(0)",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:297381,load,load,297381,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['load']
Performance," loads from before an Acquire; operation to after it. Notes for code generation; Architectures with weak memory ordering (essentially everything relevant today; except x86 and SPARC) require some sort of fence to maintain the Acquire; semantics. The precise fences required varies widely by architecture, but for; a simple implementation, most architectures provide a barrier which is strong; enough for everything (``dmb`` on ARM, ``sync`` on PowerPC, etc.). Putting; such a fence after the equivalent Monotonic operation is sufficient to; maintain Acquire semantics for a memory operation. Release; -------. Release is similar to Acquire, but with a barrier of the sort necessary to; release a lock. Relevant standard; This corresponds to the C++/C ``memory_order_release``. Notes for frontends; If you are writing a frontend which uses this directly, use with caution.; Release only provides a semantic guarantee when paired with an Acquire; operation. Notes for optimizers; Optimizers not aware of atomics can treat this like a nothrow call. It is; also possible to move loads from after a Release store or read-modify-write; operation to before it, and move non-Release stores from after a Release; operation to before it. Notes for code generation; See the section on Acquire; a fence before the relevant operation is usually; sufficient for Release. Note that a store-store fence is not sufficient to; implement Release semantics; store-store fences are generally not exposed to; IR because they are extremely difficult to use correctly. AcquireRelease; --------------. AcquireRelease (``acq_rel`` in IR) provides both an Acquire and a Release; barrier (for fences and operations which both read and write memory). Relevant standard; This corresponds to the C++/C ``memory_order_acq_rel``. Notes for frontends; If you are writing a frontend which uses this directly, use with caution.; Acquire only provides a semantic guarantee when paired with a Release; operation, and vice versa. Notes for",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst:13089,optimiz,optimizers,13089,interpreter/llvm-project/llvm/docs/Atomics.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Atomics.rst,1,['optimiz'],['optimizers']
Performance," local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. buffer_wbl2 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 3. buffer/global_atomic; 4. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 5. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - global 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:320379,perform,performing,320379,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['perform'],['performing']
Performance," local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:225492,load,load,225492,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,2,['load'],['load']
Performance," local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release.; - Must happen before; the following; buffer_inv.; - Ensures that the; acquire-fence-paired; atomic has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; acquire-fence-paired-atomic. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acq_rel - agent *none* 1. buffer_wbl2 sc1=1. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:326596,cache,cache,326596,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," lowering function, using; templated functions. For example:. // lib/Target/Mips/MipsISelLowering.cpp; SDValue MipsTargetLowering::; lowerJumpTable(SDValue Op, SelectionDAG &DAG) const. calls. template <class NodeTy> // lib/Target/Mips/MipsISelLowering.h; SDValue getAddrLocal(NodeTy *N, const SDLoc &DL, EVT Ty,; SelectionDAG &DAG, bool IsN32OrN64) const. which calls the overloaded function:. // lib/Target/Mips/MipsISelLowering.h; SDValue getTargetNode(JumpTableSDNode *N, EVT Ty, SelectionDAG &DAG,; unsigned Flag) const;. 2. Generic address nodes are lowered to some combination of target; independent and machine specific SDNodes (for example:; MipsISD::{Highest, Higher, Hi, Lo}) depending upon relocation model,; ABI, and compilation options. The choice of specific instructions that are to be used is delegated; to ISel which in turn relies on TableGen patterns to choose subtarget; specific instructions. For example, in getAddrLocal, the pseudo-code; generated is:. (add (load (wrapper $gp, %got(sym)), %lo(sym)). where ""%lo"" represents an instance of an SDNode with opcode; ""MipsISD::Lo"", ""wrapper"" indicates one with opcode ""MipsISD::Wrapper"",; and ""%got"" the global table pointer ""getGlobalReg(...)"". The ""add"" is; ""ISD::ADD"", not a target dependent one. 3. A TableGen multiclass pattern ""MipsHiLoRelocs"" is used to define a; template pattern parameterized over the load upper immediate; instruction, add operation, the zero register, and register class.; Here the instantiation of MipsHiLoRelocs in MipsInstrInfo.td is used; to MIPS32 to compute addresses for the static relocation model. // lib/Target/Mips/MipsInstrInfo.td; multiclass MipsHiLoRelocs<Instruction Lui, Instruction Addiu,; Register ZeroReg, RegisterOperand GPROpnd> {; def : MipsPat<(MipsHi tglobaladdr:$in), (Lui tglobaladdr:$in)>;; ...; def : MipsPat<(MipsLo tglobaladdr:$in), (Addiu ZeroReg, tglobaladdr:$in)>;; ...; def : MipsPat<(add GPROpnd:$hi, (MipsLo tglobaladdr:$lo)),; (Addiu GPROpnd:$hi, tglobaladdr:$lo)>;;",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/Relocation.txt:1530,load,load,1530,interpreter/llvm-project/llvm/lib/Target/Mips/Relocation.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/Mips/Relocation.txt,1,['load'],['load']
Performance," mask; 4. lvsl slot + x; vperm to rotate result into correct slot; 5. vsel result together. //===----------------------------------------------------------------------===//. Should codegen branches on vec_any/vec_all to avoid mfcr. Two examples:. #include <altivec.h>; int f(vector float a, vector float b); {; int aa = 0;; if (vec_all_ge(a, b)); aa |= 0x1;; if (vec_any_ge(a,b)); aa |= 0x2;; return aa;; }. vector float f(vector float a, vector float b) { ; if (vec_any_eq(a, b)) ; return a; ; else ; return b; ; }. //===----------------------------------------------------------------------===//. We should do a little better with eliminating dead stores.; The stores to the stack are dead since %a and %b are not needed. ; Function Attrs: nounwind; define <16 x i8> @test_vpmsumb() #0 {; entry:; %a = alloca <16 x i8>, align 16; %b = alloca <16 x i8>, align 16; store <16 x i8> <i8 1, i8 2, i8 3, i8 4, i8 5, i8 6, i8 7, i8 8, i8 9, i8 10, i8 11, i8 12, i8 13, i8 14, i8 15, i8 16>, <16 x i8>* %a, align 16; store <16 x i8> <i8 113, i8 114, i8 115, i8 116, i8 117, i8 118, i8 119, i8 120, i8 121, i8 122, i8 123, i8 124, i8 125, i8 126, i8 127, i8 112>, <16 x i8>* %b, align 16; %0 = load <16 x i8>* %a, align 16; %1 = load <16 x i8>* %b, align 16; %2 = call <16 x i8> @llvm.ppc.altivec.crypto.vpmsumb(<16 x i8> %0, <16 x i8> %1); ret <16 x i8> %2; }. ; Function Attrs: nounwind readnone; declare <16 x i8> @llvm.ppc.altivec.crypto.vpmsumb(<16 x i8>, <16 x i8>) #1. Produces the following code with -mtriple=powerpc64-unknown-linux-gnu:; # %bb.0: # %entry; addis 3, 2, .LCPI0_0@toc@ha; addis 4, 2, .LCPI0_1@toc@ha; addi 3, 3, .LCPI0_0@toc@l; addi 4, 4, .LCPI0_1@toc@l; lxvw4x 0, 0, 3; addi 3, 1, -16; lxvw4x 35, 0, 4; stxvw4x 0, 0, 3; ori 2, 2, 0; lxvw4x 34, 0, 3; addi 3, 1, -32; stxvw4x 35, 0, 3; vpmsumb 2, 2, 3; blr; .long 0; .quad 0. The two stxvw4x instructions are not needed.; With -mtriple=powerpc64le-unknown-linux-gnu, the associated permutes; are present too. //===---------------------",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt:6509,load,load,6509,interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/lib/Target/PowerPC/README_ALTIVEC.txt,2,['load'],['load']
Performance," matcher would be as follows:. .. code-block:: text. CHECK: Name: foo; CHECK: Value:; CHECK-SAME: {{ 1$}}. This verifies that the *next* time ""``Value:``"" appears in the output, it has; the value ``1``. Note: a ""``CHECK-SAME:``"" cannot be the first directive in a file. The ""CHECK-EMPTY:"" directive; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~. If you need to check that the next line has nothing on it, not even whitespace,; you can use the ""``CHECK-EMPTY:``"" directive. .. code-block:: llvm. declare void @foo(). declare void @bar(); ; CHECK: foo; ; CHECK-EMPTY:; ; CHECK-NEXT: bar. Just like ""``CHECK-NEXT:``"" the directive will fail if there is more than one; newline before it finds the next blank line, and it cannot be the first; directive in a file. The ""CHECK-NOT:"" directive; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ""``CHECK-NOT:``"" directive is used to verify that a string doesn't occur; between two matches (or before the first match, or after the last match). For; example, to verify that a load is removed by a transformation, a test like this; can be used:. .. code-block:: llvm. define i8 @coerce_offset0(i32 %V, i32* %P) {; store i32 %V, i32* %P. %P2 = bitcast i32* %P to i8*; %P3 = getelementptr i8* %P2, i32 2. %A = load i8* %P3; ret i8 %A; ; CHECK: @coerce_offset0; ; CHECK-NOT: load; ; CHECK: ret i8; }. The ""CHECK-COUNT:"" directive; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~. If you need to match multiple lines with the same pattern over and over again; you can repeat a plain ``CHECK:`` as many times as needed. If that looks too; boring you can instead use a counted check ""``CHECK-COUNT-<num>:``"", where; ``<num>`` is a positive decimal number. It will match the pattern exactly; ``<num>`` times, no more and no less. If you specified a custom check prefix,; just use ""``<PREFIX>-COUNT-<num>:``"" for the same effect.; Here is a simple example:. .. code-block:: text. Loop at depth 1; Loop at depth 1; Loop at depth 1; Loop at depth 1; Loop at depth 2; Loop at depth 3. ; CHECK-COUNT-6: Loop at depth {{[0-9]+}",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst:16806,load,load,16806,interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/FileCheck.rst,1,['load'],['load']
Performance," may compute intermediate; results (""derived pointers"") which point outside of the allocation or; even into the middle of another allocation. The eventual use of this; intermediate value must yield an address within the bounds of the; allocation, but such ""exterior derived pointers"" may be visible to the; collector. Given this, a garbage collector can not safely rely on the; runtime value of an address to indicate the object it is associated; with. If the garbage collector wishes to move any object, the; compiler must provide a mapping, for each pointer, to an indication of; its allocation. To simplify the interaction between a collector and the compiled code,; most garbage collectors are organized in terms of three abstractions:; load barriers, store barriers, and safepoints. #. A load barrier is a bit of code executed immediately after the; machine load instruction, but before any use of the value loaded.; Depending on the collector, such a barrier may be needed for all; loads, merely loads of a particular type (in the original source; language), or none at all. #. Analogously, a store barrier is a code fragment that runs; immediately before the machine store instruction, but after the; computation of the value stored. The most common use of a store; barrier is to update a 'card table' in a generational garbage; collector. #. A safepoint is a location at which pointers visible to the compiled; code (i.e. currently in registers or on the stack) are allowed to; change. After the safepoint completes, the actual pointer value; may differ, but the 'object' (as seen by the source language); pointed to will not. Note that the term 'safepoint' is somewhat overloaded. It refers to; both the location at which the machine state is parsable and the; coordination protocol involved in bring application threads to a; point at which the collector can safely use that information. The; term ""statepoint"" as used in this document refers exclusively to the; former. This document focus",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:2774,load,loads,2774,interpreter/llvm-project/llvm/docs/Statepoints.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst,2,['load'],['loads']
Performance," mem is automatically freed at this point */; }. **Description**:. ``__builtin_alloca_with_align`` is meant to be used to allocate a dynamic amount of memory; on the stack. It is similar to ``__builtin_alloca`` but accepts a second; argument whose value is the alignment constraint, as a power of 2 in *bits*. Query for this feature with ``__has_builtin(__builtin_alloca_with_align)``. .. _langext-__builtin_assume:. ``__builtin_assume``; --------------------. ``__builtin_assume`` is used to provide the optimizer with a boolean; invariant that is defined to be true. **Syntax**:. .. code-block:: c++. __builtin_assume(bool). **Example of Use**:. .. code-block:: c++. int foo(int x) {; __builtin_assume(x != 0);; // The optimizer may short-circuit this check using the invariant.; if (x == 0); return do_something();; return do_something_else();; }. **Description**:. The boolean argument to this function is defined to be true. The optimizer may; analyze the form of the expression provided as the argument and deduce from; that information used to optimize the program. If the condition is violated; during execution, the behavior is undefined. The argument itself is never; evaluated, so any side effects of the expression will be discarded. Query for this feature with ``__has_builtin(__builtin_assume)``. .. _langext-__builtin_assume_separate_storage:. ``__builtin_assume_separate_storage``; -------------------------------------. ``__builtin_assume_separate_storage`` is used to provide the optimizer with the; knowledge that its two arguments point to separately allocated objects. **Syntax**:. .. code-block:: c++. __builtin_assume_separate_storage(const volatile void *, const volatile void *). **Example of Use**:. .. code-block:: c++. int foo(int *x, int *y) {; __builtin_assume_separate_storage(x, y);; *x = 0;; *y = 1;; // The optimizer may optimize this to return 0 without reloading from *x.; return *x;; }. **Description**:. The arguments to this function are assumed to point into se",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst:99142,optimiz,optimizer,99142,interpreter/llvm-project/clang/docs/LanguageExtensions.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/LanguageExtensions.rst,2,['optimiz'],"['optimize', 'optimizer']"
Performance," memory can be accomplished with the `LLVM-EXEGESIS-MEM-DEF`; and `LLVM-EXEGESIS-MEM-MAP` annotations. To execute the following snippet:. .. code-block:: none. movq $8192, %rax; movq (%rax), %rdi. We need to have at least eight bytes of memory allocated starting `0x2000`.; We can create the necessary execution environment with the following; annotations added to the snippet:. .. code-block:: none. # LLVM-EXEGESIS-MEM-DEF test1 4096 7fffffff; # LLVM-EXEGESIS-MEM-MAP test1 8192. movq $8192, %rax; movq (%rax), %rdi. EXAMPLE 4: analysis; -------------------. Assuming you have a set of benchmarked instructions (either latency or uops) as; YAML in file `/tmp/benchmarks.yaml`, you can analyze the results using the; following command:. .. code-block:: bash. $ llvm-exegesis --mode=analysis \; --benchmarks-file=/tmp/benchmarks.yaml \; --analysis-clusters-output-file=/tmp/clusters.csv \; --analysis-inconsistencies-output-file=/tmp/inconsistencies.html. This will group the instructions into clusters with the same performance; characteristics. The clusters will be written out to `/tmp/clusters.csv` in the; following format:. .. code-block:: none. cluster_id,opcode_name,config,sched_class; ...; 2,ADD32ri8_DB,,WriteALU,1.00; 2,ADD32ri_DB,,WriteALU,1.01; 2,ADD32rr,,WriteALU,1.01; 2,ADD32rr_DB,,WriteALU,1.00; 2,ADD32rr_REV,,WriteALU,1.00; 2,ADD64i32,,WriteALU,1.01; 2,ADD64ri32,,WriteALU,1.01; 2,MOVSX64rr32,,BSWAP32r_BSWAP64r_MOVSX64rr32,1.00; 2,VPADDQYrr,,VPADDBYrr_VPADDDYrr_VPADDQYrr_VPADDWYrr_VPSUBBYrr_VPSUBDYrr_VPSUBQYrr_VPSUBWYrr,1.02; 2,VPSUBQYrr,,VPADDBYrr_VPADDDYrr_VPADDQYrr_VPADDWYrr_VPSUBBYrr_VPSUBDYrr_VPSUBQYrr_VPSUBWYrr,1.01; 2,ADD64ri8,,WriteALU,1.00; 2,SETBr,,WriteSETCC,1.01; ... :program:`llvm-exegesis` will also analyze the clusters to point out; inconsistencies in the scheduling information. The output is an html file. For; example, `/tmp/inconsistencies.html` will contain messages like the following :. .. image:: llvm-exegesis-analysis.png; :align: center. Note that ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst:7976,perform,performance,7976,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-exegesis.rst,1,['perform'],['performance']
Performance," memory order if they access LDS memory, and out of LDS operation order; if they access global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore, no special action is required for coherence between the; lanes of a single wavefront, or for coherence between wavefronts in the same; work-group. A ``buffer_wbinvl1_vol`` is required for coherence between; wavefronts executing in different work-groups as they may be executing on; different CUs.; * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0)`` is required to; ensure synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:208593,queue,queue,208593,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['queue'],['queue']
Performance," mismatches).; . TXNetSystem:; ; Fix problem with GetDirEntry: the entry object was; going out-of-scope so; that the returned string was meaningless.; Reset; the list if dir entries in FreeDirectory.; Fix problem affecting repeated calls. The implementation of TFile throughput and info sending was; just sending 'regular' samples about the activity of the single TFile; instance that happened to trigger an activity in the right moment.; Now TMonaLisaWriter keeps internally track of every; activity; and regularly sends summaries valid for all the files which had; activity in the last time interval.; Additionally, it's now finalized the infrastructure able to; measure; and keep track of the file Open latency. A packet is sent for each; successful Open, sending the measures of the latencies for the; various phases of the open. Currently exploited fully by TAlienFile; and TXNetFile. Easy to report from other TFiles too.; Now, the hook for the Close() func triggers sending of a; packet containing various information about the performance related to; that file only.; Added support also for performance monitoring when writing. RGLITE: A ROOT GRID interface. RGLite plug-in - a ROOT plug-in module, which implements the ROOT Grid; interface and offers to ROOT users possibilities to perform a number of; operations using gLite middleware from within ROOT. Supported features:. Workload Management System operations:; ; job submission – normal, DAG and parametric; jobs (gLite; WMProxy API), ; smart look-up algorithm for WMP-Endpoints, ; job status querying (gLite LB API), ; job output retrieving (Globus GridFTP). . File Catalog operations (gLite/LCG LFC API):; ; smart session manager, ; set/query the current working catalog directory, ; list files, directories and their stats, ; add/remove files in a catalog namespace, ; add/remove directories, ; add/remove replicas from a given file. . An executive logging. ; Support of an external XML configuration file with; according XML; schema.",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/net/doc/v520/index.html:2933,perform,performance,2933,net/doc/v520/index.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/net/doc/v520/index.html,1,['perform'],['performance']
Performance," mitigation strategy works is that it establishes a; data-flow check on the loaded address. However, this means that if the address; itself was already loaded using a checked load, there is no need to check a; dependent load provided it is within the same basic block as the checked load,; and therefore has no additional predicates guarding it. Consider code like the; following:; ```; ... .LBB0_4: # %danger; movq (%rcx), %rdi; movl (%rdi), %edx; ```. This will get transformed into:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; orq %rax, %rcx # Mask the pointer if misspeculating.; movq (%rcx), %rdi # Hardened load.; movl (%rdi), %edx # Unhardened load due to dependent addr.; ```. This doesn't check the load through `%rdi` as that pointer is dependent on a; checked load already. ###### Protect large, load-heavy blocks with a single lfence. It may be worth using a single `lfence` instruction at the start of a block; which begins with a (very) large number of loads that require independent; protection *and* which require hardening the address of the load. However, this; is unlikely to be profitable in practice. The latency hit of the hardening; would need to exceed that of an `lfence` when *correctly* speculatively; executed. But in that case, the `lfence` cost is a complete loss of speculative; execution (at a minimum). So far, the evidence we have of the performance cost; of using `lfence` indicates few if any hot code patterns where this trade off; would make sense. ###### Tempting optimizations that break the security model. Several optimizations were considered which didn't pan out due to failure to; uphold the security model. One in particular is worth discussing as many others; will reduce to it. We wondered whether only the *first* load in a basic block could be checked. If; the check works as intended, it forms an invalid pointer that doesn't even; virtual-address translate in the hardware. It should fault very early on",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:36353,load,loads,36353,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,2,['load'],"['load', 'loads']"
Performance," modeling a sequence of output instructions using; a ""Recipe"", which is responsible for computing its cost and generating its; code. 6. Encapsulate Single-Entry Single-Exit regions (SESE). During vectorization; such regions may need to be, for example, predicated and linearized, or; replicated VF*UF times to handle scalarized and predicated instructions.; Innerloops are also modelled as SESE regions. 7. Support instruction-level analysis and transformation, as part of Planning; Step 2.b: During vectorization instructions may need to be traversed, moved,; replaced by other instructions or be created. For example, vector idiom; detection and formation involves searching for and optimizing instruction; patterns. Definitions; ===========; The low-level design of VPlan comprises of the following classes. :LoopVectorizationPlanner:; A LoopVectorizationPlanner is designed to handle the vectorization of a loop; or a loop nest. It can construct, optimize and discard one or more VPlans,; each VPlan modelling a distinct way to vectorize the loop or the loop nest.; Once the best VPlan is determined, including the best VF and UF, this VPlan; drives the generation of output IR. :VPlan:; A model of a vectorized candidate for a given input IR loop or loop nest. This; candidate is represented using a Hierarchical CFG. VPlan supports estimating; the cost and driving the generation of the output IR code it represents. :Hierarchical CFG:; A control-flow graph whose nodes are basic-blocks or Hierarchical CFG's. The; Hierarchical CFG data structure is similar to the Tile Tree [5]_, where; cross-Tile edges are lifted to connect Tiles instead of the original; basic-blocks as in Sharir [6]_, promoting the Tile encapsulation. The terms; Region and Block are used rather than Tile [5]_ to avoid confusion with loop; tiling. :VPBlockBase:; The building block of the Hierarchical CFG. A pure-virtual base-class of; VPBasicBlock and VPRegionBlock, see below. VPBlockBase models the hierarchical; cont",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:4185,optimiz,optimize,4185,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,1,['optimiz'],['optimize']
Performance," module allows the compiler to build the ``std`` module as a standalone entity, and having the mapping from header names to (sub)modules allows the automatic translation of ``#include`` directives to module imports. Module maps are specified as separate files (each named ``module.modulemap``) alongside the headers they describe, which allows them to be added to existing software libraries without having to change the library headers themselves (in most cases [#]_). The actual `Module map language`_ is described in a later section. .. note::. To actually see any benefits from modules, one first has to introduce module maps for the underlying C standard library and the libraries and headers on which it depends. The section `Modularizing a Platform`_ describes the steps one must take to write these module maps. One can use module maps without modules to check the integrity of the use of header files. To do this, use the ``-fimplicit-module-maps`` option instead of the ``-fmodules`` option, or use ``-fmodule-map-file=`` option to explicitly specify the module map files to load. Compilation model; -----------------; The binary representation of modules is automatically generated by the compiler on an as-needed basis. When a module is imported (e.g., by an ``#include`` of one of the module's headers), the compiler will spawn a second instance of itself [#]_, with a fresh preprocessing context [#]_, to parse just the headers in that module. The resulting Abstract Syntax Tree (AST) is then persisted into the binary representation of the module that is then loaded into translation unit where the module import was encountered. The binary representation of modules is persisted in the *module cache*. Imports of a module will first query the module cache and, if a binary representation of the required module is already available, will load that representation directly. Thus, a module's headers will only be parsed once per language configuration, rather than once per translation ",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst:13097,load,load,13097,interpreter/llvm-project/clang/docs/Modules.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/Modules.rst,1,['load'],['load']
Performance," months of change to Clang itself.; New checker for C++ leaks is turned on by default.; Added various small checks and bug fixes.; Added experimental checkers for Objective-C:. New localizability checks:; ; Checker warning about uses of non-localized NSStrings passed to UI methods expecting localized strings.; Checker warning when the comment argument is missing from NSLocalizedString macros.; These can be enabled by passing the following command to scan-build:.   -enable-checker alpha.osx.cocoa.NonLocalizedStringChecker,alpha.osx.cocoa.EmptyLocalizationContextChecker. New checks for _Nonnull type qualifiers. These can be enabled with:.   -enable-checker nullability.NullPassedToNonnull,nullability.NullReturnedFromNonnull; New checks for misuse of Objective-C generics. These can be enabled with -enable-checker alpha.osx.cocoa.ObjCGenerics. Support for cf_returns_retained and cf_returns_not_retained attributes in out-parameters.; The analyzer now creates one state for a range switch case instead of multiple, resulting in performance improvements.; Now requires OS X 10.7 or later.; 	; checker-276; built: February 19, 2014; download: checker-276.tar.bz2; highlights:. Includes about 9 months of change to Clang itself (improved C++11/14 support, etc.); More precise modeling of Objective-C properties, which enables the analyzer to find more bugs.; Includes a new ""missing call to super"" warning, which looks for common pattern in iOS/OSX APIs that require chaining a call to a super class's implementation of a method.; Accepts -arch arm64 (which may be passed by Xcode 5.0), but for the time being analyzes code in such cases as -arch armv7s.; Many sundry fixes, improvements to C++ support, etc. checker-275; built: May 23, 2013; download: checker-275.tar.bz2; highlights:. Xcode: Includes a new arrow layout algorithm for issue presentation within Xcode. The goal is for interprocedural bug reports to look cleaner and less busy (and easier to read). Feedback appreciated.; Xcode: B",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html:2836,perform,performance,2836,interpreter/llvm-project/clang/www/analyzer/release_notes.html,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/www/analyzer/release_notes.html,1,['perform'],['performance']
Performance," must agree). If a new patch; does not address all outstanding feedback, the author should explicitly state; that when providing the updated patch. When using the web-based code-review; tool, such notes can be provided in the ""Diff"" description (which is different; from the description of the ""Differential Revision"" as a whole used for the; commit message). If you suggest changes in a code review, but don't wish the suggestion to be; interpreted this strongly, please state so explicitly. Aim to Make Efficient Use of Everyone's Time; --------------------------------------------. Aim to limit the number of iterations in the review process. For example, when; suggesting a change, if you want the author to make a similar set of changes at; other places in the code, please explain the requested set of changes so that; the author can make all of the changes at once. If a patch will require; multiple steps prior to approval (e.g., splitting, refactoring, posting data; from specific performance tests), please explain as many of these up front as; possible. This allows the patch author and reviewers to make the most efficient; use of their time. LGTM - How a Patch Is Accepted; ------------------------------. A patch is approved to be committed when a reviewer accepts it, and this is; almost always associated with a message containing the text ""LGTM"" (which; stands for Looks Good To Me). Only approval from a single reviewer is required. When providing an unqualified LGTM (approval to commit), it is the; responsibility of the reviewer to have reviewed all of the discussion and; feedback from all reviewers ensuring that all feedback has been addressed and; that all other reviewers will almost surely be satisfied with the patch being; approved. If unsure, the reviewer should provide a qualified approval, (e.g.,; ""LGTM, but please wait for @someone, @someone_else""). You may also do this if; you are fairly certain that a particular community member will wish to review,; even if th",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst:6237,perform,performance,6237,interpreter/llvm-project/llvm/docs/CodeReview.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CodeReview.rst,1,['perform'],['performance']
Performance," must have alignment greater than or; equal to the size in memory of the operand. Semantics:; """""""""""""""""""". The contents of memory at the location specified by the '``<pointer>``' operand; is read and compared to '``<cmp>``'; if the values are equal, '``<new>``' is; written to the location. The original value at the location is returned,; together with a flag indicating success (true) or failure (false). If the cmpxchg operation is marked as ``weak`` then a spurious failure is; permitted: the operation may not write ``<new>`` even if the comparison; matched. If the cmpxchg operation is strong (the default), the i1 value is 1 if and only; if the value loaded equals ``cmp``. A successful ``cmpxchg`` is a read-modify-write instruction for the purpose of; identifying release sequences. A failed ``cmpxchg`` is equivalent to an atomic; load with an ordering parameter determined the second ordering parameter. Example:; """""""""""""""". .. code-block:: llvm. entry:; %orig = load atomic i32, ptr %ptr unordered, align 4 ; yields i32; br label %loop. loop:; %cmp = phi i32 [ %orig, %entry ], [%value_loaded, %loop]; %squared = mul i32 %cmp, %cmp; %val_success = cmpxchg ptr %ptr, i32 %cmp, i32 %squared acq_rel monotonic ; yields { i32, i1 }; %value_loaded = extractvalue { i32, i1 } %val_success, 0; %success = extractvalue { i32, i1 } %val_success, 1; br i1 %success, label %done, label %loop. done:; ... .. _i_atomicrmw:. '``atomicrmw``' Instruction; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. atomicrmw [volatile] <operation> ptr <pointer>, <ty> <value> [syncscope(""<target-scope>"")] <ordering>[, align <alignment>] ; yields ty. Overview:; """""""""""""""""". The '``atomicrmw``' instruction is used to atomically modify memory. Arguments:; """""""""""""""""""". There are three arguments to the '``atomicrmw``' instruction: an; operation to apply, an address whose value to modify, an argument to the; operation. The operation must be one of the following keywords:. - xchg; - add; - sub; - and; - nand; - or; -",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:428574,load,load,428574,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['load'],['load']
Performance," must pass the ``llvm/test`` test suite. #. The code must not cause regressions on a reasonable subset of llvm-test,; where ""reasonable"" depends on the contributor's judgement and the scope of; the change (more invasive changes require more testing). A reasonable subset; might be something like ""``llvm-test/MultiSource/Benchmarks``"". #. Ensure that links in source code and test files point to publicly available; resources and are used primarily to add additional information rather than; to supply critical context. The surrounding comments should be sufficient; to provide the context behind such links. Additionally, the committer is responsible for addressing any problems found in; the future that the change is responsible for. For example:. * The code should compile cleanly on all supported platforms. * The changes should not cause any correctness regressions in the ``llvm-test``; suite and must not cause any major performance regressions. * The change set should not cause performance or correctness regressions for the; LLVM tools. * The changes should not cause performance or correctness regressions in code; compiled by LLVM on all applicable targets. * You are expected to address any `GitHub Issues <https://github.com/llvm/llvm-project/issues>`_ that; result from your change. We prefer for this to be handled before submission but understand that it isn't; possible to test all of this for every submission. Our build bots and nightly; testing infrastructure normally finds these problems. A good rule of thumb is; to check the nightly testers for regressions the day after your change. Build; bots will directly email you if a group of commits that included yours caused a; failure. You are expected to check the build bot messages to see if they are; your fault and, if so, fix the breakage. Commits that violate these quality standards (e.g. are very broken) may be; reverted. This is necessary when the change blocks other developers from making; progress. The developer is",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst:13706,perform,performance,13706,interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DeveloperPolicy.rst,1,['perform'],['performance']
Performance," mutually exclusive to the existing local storage; qualifiers auto, register, and static. [testme] Variables qualified by; ``__block`` act as if they were in allocated storage and this storage; is automatically recovered after last use of said variable. An; implementation may choose an optimization where the storage is; initially automatic and only ""moved"" to allocated (heap) storage upon; a Block_copy of a referencing Block. Such variables may be mutated as; normal variables are. In the case where a ``__block`` variable is a Block one must assume; that the ``__block`` variable resides in allocated storage and as such; is assumed to reference a Block that is also in allocated storage; (that it is the result of a ``Block_copy`` operation). Despite this; there is no provision to do a ``Block_copy`` or a ``Block_release`` if; an implementation provides initial automatic storage for Blocks. This; is due to the inherent race condition of potentially several threads; trying to update the shared variable and the need for synchronization; around disposing of older values and copying new ones. Such; synchronization is beyond the scope of this language specification. Control Flow; ============. The compound statement of a Block is treated much like a function body; with respect to control flow in that goto, break, and continue do not; escape the Block. Exceptions are treated *normally* in that when; thrown they pop stack frames until a catch clause is found. Objective-C Extensions; ======================. Objective-C extends the definition of a Block reference type to be; that also of id. A variable or expression of Block type may be; messaged or used as a parameter wherever an id may be. The converse is; also true. Block references may thus appear as properties and are; subject to the assign, retain, and copy attribute logic that is; reserved for objects. All Blocks are constructed to be Objective-C objects regardless of; whether the Objective-C runtime is operational in the",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst:8066,race condition,race condition,8066,interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/BlockLanguageSpec.rst,1,['race condition'],['race condition']
Performance," name. GradBaggingFraction --> BaggedSampleFraction. in an attempt to consolidate and avoid idential duplicate code; ; The option UseWeightedTrees has been removed and set to ""true"", as was default; anyway, as a measure of further consolidation. Removed the option NNodesMax --> This should be replaced by specifying MaxDepth; instead (limiting the maximum tree depth also limits the number of possible nodes!). b) Added a trial version of a new ""cost sensitive"" boosting algorithem according to; Wei Fan and Salvatore J. Stolfo, {\em AdaCost: misclassification cost-sensitive boosting}, Proceedings of the 16th International conference on machine learning (ICML 1999)}. With the currently; chosen DEFAULT settings (all costs equal and set to ""one""), it is equivalent to the ""real-AdaBoost"" (i.e. using the option !UseYesNoLeaf (which uses the leave node purity rather than a signal or background attribute in the leaf node of each individual tree). Unfortunatly, no reasonable performance has been achieved yet when choosing different cost parameters. c) BDT's with little tree depth (as favoured for good performance) do not *like* it if; there are very clean signal and background separation cuts available, which however ; have NOT been applied yet as preselection. Now there is a possibility to choose the option; ""DoPreselection"" that looks for suitable preselection cuts and applies them prior to ; the Decision Tree training. While that works fine, this clearly gives ""sharp"" peaks at +1 (-1); for the MVA output distribution and therefore the ""smoothing"" of this distribution used to; produce the ROC curve and efficiency estimates are somewhat thwarted.; ; --> It's better if you do these preselection cuts YOURSELF when defining training and test; sample!. d) Removed completely the (hopefully never used) option of treating negative events weights; via: PairNegWeightsInNode. e) Renamed option: IgnoreNegEvents --> IgnoreNegEventsInTraining; and removed the IDENTICAL option NoNegeventsInT",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/ReleaseNotes4.2.0.txt:2482,perform,performance,2482,documentation/tmva/UsersGuide/ReleaseNotes4.2.0.txt,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/documentation/tmva/UsersGuide/ReleaseNotes4.2.0.txt,1,['perform'],['performance']
Performance," need a runtime library for JIT'd code. This would include things like; TLS registration, reentry functions, registration code for language runtimes; (e.g. Objective C and Swift) and other JIT specific runtime code. This should; be built in a similar manner to compiler-rt (possibly even as part of it). 2. **Remote jit_dlopen / jit_dlclose**. To more fully mimic the environment that static programs operate in we would; like JIT'd code to be able to ""dlopen"" and ""dlclose"" JITDylibs, running all of; their initializers/deinitializers on the current thread. This would require; support from the runtime library described above. 3. **Debugging support**. ORC currently supports the GDBRegistrationListener API when using RuntimeDyld; as the underlying JIT linker. We will need a new solution for JITLink based; platforms. Further Future Work; -------------------. 1. **Speculative Compilation**. ORC's support for concurrent compilation allows us to easily enable; *speculative* JIT compilation: compilation of code that is not needed yet,; but which we have reason to believe will be needed in the future. This can be; used to hide compile latency and improve JIT throughput. A proof-of-concept; example of speculative compilation with ORC has already been developed (see; ``llvm/examples/SpeculativeJIT``). Future work on this is likely to focus on; re-using and improving existing profiling support (currently used by PGO) to; feed speculation decisions, as well as built-in tools to simplify use of; speculative compilation. .. [1] Formats/architectures vary in terms of supported features. MachO and; ELF tend to have better support than COFF. Patches very welcome!. .. [2] The ``LazyEmittingLayer``, ``RemoteObjectClientLayer`` and; ``RemoteObjectServerLayer`` do not have counterparts in the new; system. In the case of ``LazyEmittingLayer`` it was simply no longer; needed: in ORCv2, deferring compilation until symbols are looked up is; the default. The removal of ``RemoteObjectClientLayer``",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst:37043,concurren,concurrent,37043,interpreter/llvm-project/llvm/docs/ORCv2.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/ORCv2.rst,1,['concurren'],['concurrent']
Performance," needed for Cling; to be able to parse templates' instantiations and for some autoloading; functionalities.; - One (or more) libraries sections. These sections describe the ensamble of; the autoload keys related to one or more shared libraries. An autoload key; can be a class name, a namespace name, a typedef or alias or a header file name.; - Single line comments, which start with a ""#"" character. At ROOT startup, a check is performed on autoload keys. If the same key (which is not a template instantiation) refers to two different libraries (or sets of libraries) a warning is issued.; A typical Rootmap file look like:; ``` {.cpp}; { decls }; fwd declaration 1;; fwd declaration 2;; [...]; fwd declaration N;. [ libraryName1 libraryName2 ... ]; class className1; class className2; ...; typedef typedefName1; typedef typedefName2; ...; header headerName1; header headerName2; ... ```. ### TROOT. The list returned by `GetListOfTypes` is no longer filled when the dictionary; are loaded but instead are filled on demand, when the user explicitly (directly; or indirectly) request each typedef. In particular this means that. ``` {.cpp}; gROOT->GetListOfTypes()->ls(); // or Print(); ```. no longer prints the list of all available typedef but instead list only the; typedefs that have been previously accessed throught the list (plus the builtins; types). ### ACliC. ACLiC has the following backward incompatibilities:. - Since rootcling no longer re-\#defines the private and protected; keyword to public, the code compiled by ACLIC no longer has access; to protected and private members of a class (except where allowed by; the C++ standard). ### Collection. New collection `TListOfTypes` that implements on demand creation; of the `TDataType` describing a typedef. ### TUnixSystem. - Simplify `Setenv` coding.; - Implement `Unsetenv` using the system function `unsetenv`. ### TMacOSXSystem. - The file descriptors' management improved/fixed. ### TColor. - 5 new predefined palettes with 255 c",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/core/doc/v600/index.md:10731,load,loaded,10731,core/doc/v600/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/core/doc/v600/index.md,1,['load'],['loaded']
Performance," needs to follow certain conventions that; make it possible for a runtime function to patch over it later.; The exact effect of this attribute depends on its string value,; for which there currently is one legal possibility:. * ``""prologue-short-redirect""`` - This style of patchable; function is intended to support patching a function prologue to; redirect control away from the function in a thread safe; manner. It guarantees that the first instruction of the; function will be large enough to accommodate a short jump; instruction, and will be sufficiently aligned to allow being; fully changed via an atomic compare-and-swap instruction.; While the first requirement can be satisfied by inserting large; enough NOP, LLVM can and will try to re-purpose an existing; instruction (i.e. one that would have to be emitted anyway) as; the patchable instruction larger than a short jump. ``""prologue-short-redirect""`` is currently only supported on; x86-64. This attribute by itself does not imply restrictions on; inter-procedural optimizations. All of the semantic effects the; patching may have to be separately conveyed via the linkage type.; ``""probe-stack""``; This attribute indicates that the function will trigger a guard region; in the end of the stack. It ensures that accesses to the stack must be; no further apart than the size of the guard region to a previous; access of the stack. It takes one required string value, the name of; the stack probing function that will be called. If a function that has a ``""probe-stack""`` attribute is inlined into; a function with another ``""probe-stack""`` attribute, the resulting; function has the ``""probe-stack""`` attribute of the caller. If a; function that has a ``""probe-stack""`` attribute is inlined into a; function that has no ``""probe-stack""`` attribute at all, the resulting; function has the ``""probe-stack""`` attribute of the callee.; ``""stack-probe-size""``; This attribute controls the behavior of stack probes: either; the ``""probe-stack",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:97906,optimiz,optimizations,97906,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimizations']
Performance," never auto generated and thus requires explicit request of the dictionary for each std::tuple class template instantiation used, like most other class templates.; * Custom streamers need to #include TBuffer.h explicitly (see [section Core Libraries](#core-libs)); * Check and flag short reads as errors in the xroot plugins. This fixes [ROOT-3341].; * Added support for AWS temporary security credentials to TS3WebFile by allowing the security token to be given.; * Resolve an issue when space is freed in a large `ROOT` file and a TDirectory is updated and stored the lower (less than 2GB) freed portion of the file [ROOT-8055]. - ##### TBufferJSON:; + support data members with `//[fN]` comment; + preliminary support of STL containers; + JSON data can be produced with `TObject::SaveAs()` method. ## TTree Libraries. * TChains can now be histogrammed without any C++ code, using the command line tool `rootdrawtree`. It is based on the new class `TSimpleAnalysis`.; * Do not automatically setup read cache during `TTree::Fill()`. This fixes [ROOT-8031].; * Make sure the option ""PARA"" in `TTree::Draw` is used with at least tow variables [ROOT-8196].; * The with `goff` option one can use as many variables as needed. There no more; limitation, like with the options `para`and `candle`.; * Fix detection of errors that appears in nested TTreeFormula [ROOT-8218]; * Better basket size optimization by taking into account meta data and rounding up to next 512 bytes, ensuring a complete cluster fits into a single basket. ### Fast Cloning. We added a cache specifically for the fast option of the TTreeCloner to significantly reduce the run-time when fast-cloning remote files to address [ROOT-5078]. It can be controlled from the `TTreeCloner`, `TTree::CopyEntries` or `hadd` interfaces. The new cache is enabled by default, to update the size of the cache or disable it from `TTreeCloner` use: `TTreeCloner::SetCacheSize`. To do the same from `TTree::CopyEntries` add to the option string ""cachesi",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md:8944,cache,cache,8944,README/ReleaseNotes/v608/index.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/README/ReleaseNotes/v608/index.md,1,['cache'],['cache']
Performance," never be stale in L2 due to; the memory probes. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - generic 1. buffer_wbl2. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that al",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:272499,cache,cache,272499,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['cache'],['cache']
Performance," new :program:`lit` testing implementation, or extending an existing one. :program:`lit` proper is primarily an infrastructure for discovering and running; arbitrary tests, and to expose a single convenient interface to these; tests. :program:`lit` itself doesn't know how to run tests, rather this logic is; defined by *test suites*. TEST SUITES; ~~~~~~~~~~~. As described in :ref:`test-discovery`, tests are always located inside a *test; suite*. Test suites serve to define the format of the tests they contain, the; logic for finding those tests, and any additional information to run the tests. :program:`lit` identifies test suites as directories containing ``lit.cfg`` or; ``lit.site.cfg`` files (see also :option:`--config-prefix`). Test suites are; initially discovered by recursively searching up the directory hierarchy for; all the input files passed on the command line. You can use; :option:`--show-suites` to display the discovered test suites at startup. Once a test suite is discovered, its config file is loaded. Config files; themselves are Python modules which will be executed. When the config file is; executed, two important global variables are predefined:. **lit_config**. The global **lit** configuration object (a *LitConfig* instance), which defines; the builtin test formats, global configuration parameters, and other helper; routines for implementing test configurations. **config**. This is the config object (a *TestingConfig* instance) for the test suite,; which the config file is expected to populate. The following variables are also; available on the *config* object, some of which must be set by the config and; others are optional or predefined:. **name** *[required]* The name of the test suite, for use in reports and; diagnostics. **test_format** *[required]* The test format object which will be used to; discover and run tests in the test suite. Generally this will be a builtin test; format available from the *lit.formats* module. **test_source_root** T",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst:14834,load,loaded,14834,interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/lit.rst,1,['load'],['loaded']
Performance," new; `DIAssignID` attachments each. In other words, treat the split stores as; separate assignments. For partial DSE (e.g. shortening a memset), we do the; same except that `llvm.dbg.assign` for the dead fragment gets an `Undef`; `Address`. **Promoting** allocas and store/loads: `llvm.dbg.assign` intrinsics implicitly; describe joined values in memory locations at CFG joins, but this is not; necessarily the case after promoting (or partially promoting) the; variable. Passes that promote variables are responsible for inserting; `llvm.dbg.assign` intrinsics after the resultant PHIs generated during; promotion. `mem2reg` already has to do this (with `llvm.dbg.value`) for; `llvm.dbg.declare`s. Where a store has no linked intrinsic, the store is; assumed to represent an assignment for variables stored at the destination; address. #### Debug intrinsic updates. **Moving** a debug intrinsic: avoid moving `llvm.dbg.assign` intrinsics where; possible, as they represent a source-level assignment, whose position in the; program should not be affected by optimization passes. **Deleting** a debug intrinsic: Nothing new to do. Just like for conventional; debug intrinsics, unless it is unreachable, it’s almost always incorrect to; delete a `llvm.dbg.assign` intrinsic. ### Lowering `llvm.dbg.assign` to MIR. To begin with only SelectionDAG ISel will be supported. `llvm.dbg.assign`; intrinsics are lowered to MIR `DBG_INSTR_REF` instructions. Before this happens; we need to decide where it is appropriate to use memory locations and where we; must use a non-memory location (or no location) for each variable. In order to; make those decisions we run a standard fixed-point dataflow analysis that makes; the choice at each instruction, iteratively joining the results for each block. ### TODO list. As this is an experimental work in progress so there are some items we still need; to tackle:. * As mentioned in test llvm/test/DebugInfo/assignment-tracking/X86/diamond-3.ll,; the analysis shoul",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md:8640,optimiz,optimization,8640,interpreter/llvm-project/llvm/docs/AssignmentTracking.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AssignmentTracking.md,1,['optimiz'],['optimization']
Performance," no useful instructions on x86 that apply a mask to all 64 bits; without touching the flag registers. However, we can harden loaded values that; are narrower than a word (fewer than 32-bits on 32-bit systems and fewer than; 64-bits on 64-bit systems) by zero-extending the value to the full word size; and then shifting right by at least the number of original bits using the BMI2; `shrx` instruction:; ```; ... .LBB0_4: # %danger; cmovneq %r8, %rax # Conditionally update predicate state.; addl (%rsi), %edi # Load and accumulate 32 bits of data.; shrxq %rax, %rdi, %rdi # Shift out all 32 bits loaded.; ```. Because on x86 the zero-extend is free, this can efficiently harden the loaded; value. ##### Hardening the address of the load. When hardening the loaded value is inapplicable, most often because the; instruction directly leaks information (like `cmp` or `jmpq`), we switch to; hardening the _address_ of the load instead of the loaded value. This avoids; increasing register pressure by unfolding the load or paying some other high; cost. To understand how this works in practice, we need to examine the exact; semantics of the x86 addressing modes which, in its fully general form, looks; like `(%base,%index,scale)offset`. Here `%base` and `%index` are 64-bit; registers that can potentially be any value, and may be attacker controlled,; and `scale` and `offset` are fixed immediate values. `scale` must be `1`, `2`,; `4`, or `8`, and `offset` can be any 32-bit sign extended value. The exact; computation performed to find the address is then: `%base + (scale * %index) +; offset` under 64-bit 2's complement modular arithmetic. One issue with this approach is that, after hardening, the `%base + (scale *; %index)` subexpression will compute a value near zero (`-1 + (scale * -1)`) and; then a large, positive `offset` will index into memory within the first two; gigabytes of address space. While these offsets are not attacker controlled,; the attacker could chose to attack a load w",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md:27806,load,load,27806,interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SpeculativeLoadHardening.md,1,['load'],['load']
Performance," no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/; atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_inv and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the; value read by the; fence-paired-atomic. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; b",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:303724,load,loads,303724,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
Performance," node is also used as LoopID (``Loop::getLoopID()``), i.e.; the loop effectively gets a new identifier. For instance,; ``llvm.mem.parallel_loop_access`` references the LoopID. Therefore, if; the parallel access property is to be preserved after adding/removing; loop attributes, any ``llvm.mem.parallel_loop_access`` reference must be; updated to the new LoopID. Transformation Metadata Structure; =================================. Some attributes describe code transformations (unrolling, vectorizing,; loop distribution, etc.). They can either be a hint to the optimizer; that a transformation might be beneficial, instruction to use a specific; option, , or convey a specific request from the user (such as; ``#pragma clang loop`` or ``#pragma omp simd``). If a transformation is forced but cannot be carried-out for any reason,; an optimization-missed warning must be emitted. Semantic information; such as a transformation being safe (e.g.; ``llvm.mem.parallel_loop_access``) can be unused by the optimizer; without generating a warning. Unless explicitly disabled, any optimization pass may heuristically; determine whether a transformation is beneficial and apply it. If; metadata for another transformation was specified, applying a different; transformation before it might be inadvertent due to being applied on a; different loop or the loop not existing anymore. To avoid having to; explicitly disable an unknown number of passes, the attribute; ``llvm.loop.disable_nonforced`` disables all optional, high-level,; restructuring transformations. The following example avoids the loop being altered before being; vectorized, for instance being unrolled. .. code-block:: llvm. br i1 %exitcond, label %for.exit, label %for.header, !llvm.loop !0; ...; !0 = distinct !{!0, !1, !2}; !1 = !{!""llvm.loop.vectorize.enable"", i1 true}; !2 = !{!""llvm.loop.disable_nonforced""}. After a transformation is applied, follow-up attributes are set on the; transformed and/or new loop(s). This allows additiona",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:2729,optimiz,optimizer,2729,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst,1,['optimiz'],['optimizer']
Performance," nodes defined in this graph.; External symbols will still have null addresses. #. Phase 2. #. Run post-allocation passes. These passes are run on the graph after working and target memory have; been allocated, but before the ``JITLinkContext`` is notified of the; final addresses of the symbols in the graph. This gives these passes a; chance to set up data structures associated with target addresses before; any JITLink clients (especially ORC queries for symbol resolution) can; attempt to access them. Notable use cases: Setting up mappings between target addresses and; JIT data structures, such as a mapping between ``__dso_handle`` and; ``JITDylib*``. #. Notify the ``JITLinkContext`` of the assigned symbol addresses. Calls ``JITLinkContext::notifyResolved`` on the link graph, allowing; clients to react to the symbol address assignments made for this graph.; In ORC this is used to notify any pending queries for *resolved* symbols,; including pending queries from concurrently running JITLink instances that; have reached the next step and are waiting on the address of a symbol in; this graph to proceed with their link. #. Identify external symbols and resolve their addresses asynchronously. Calls the ``JITLinkContext`` to resolve the target address of any external; symbols in the graph. #. Phase 3. #. Apply external symbol resolution results. This updates the addresses of all external symbols. At this point all; nodes in the graph have their final target addresses, however node; content still points back to the original data in the object file. #. Run pre-fixup passes. These passes are called on the graph after all nodes have been assigned; their final target addresses, but before node content is copied into; working memory and fixed up. Passes run at this stage can make late; optimizations to the graph and content based on address layout. Notable use cases: GOT and PLT relaxation, where GOT and PLT accesses are; bypassed for fixup targets that are directly accessible u",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst:20533,concurren,concurrently,20533,interpreter/llvm-project/llvm/docs/JITLink.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/JITLink.rst,1,['concurren'],['concurrently']
Performance," nodes tie a :ref:`DIGlobalVariable` together; with a :ref:`DIExpression`. .. code-block:: text. @lower = global i32, !dbg !0; @upper = global i32, !dbg !1; !0 = !DIGlobalVariableExpression(; var: !2,; expr: !DIExpression(DW_OP_LLVM_fragment, 0, 32); ); !1 = !DIGlobalVariableExpression(; var: !2,; expr: !DIExpression(DW_OP_LLVM_fragment, 32, 32); ); !2 = !DIGlobalVariable(name: ""split64"", linkageName: ""split64"", scope: !3,; file: !4, line: 8, type: !5, declaration: !6). All global variable expressions should be referenced by the `globals:` field of; a :ref:`compile unit <DICompileUnit>`. .. _DISubprogram:. DISubprogram; """""""""""""""""""""""". ``DISubprogram`` nodes represent functions from the source language. A distinct; ``DISubprogram`` may be attached to a function definition using ``!dbg``; metadata. A unique ``DISubprogram`` may be attached to a function declaration; used for call site debug info. The ``retainedNodes:`` field is a list of; :ref:`variables <DILocalVariable>` and :ref:`labels <DILabel>` that must be; retained, even if their IR counterparts are optimized out of the IR. The; ``type:`` field must point at an :ref:`DISubroutineType`. .. _DISubprogramDeclaration:. When ``spFlags: DISPFlagDefinition`` is not present, subprograms describe a; declaration in the type tree as opposed to a definition of a function. In this; case, the ``declaration`` field must be empty. If the scope is a composite type; with an ODR ``identifier:`` and that does not set ``flags: DIFwdDecl``, then; the subprogram declaration is uniqued based only on its ``linkageName:`` and; ``scope:``. .. code-block:: text. define void @_Z3foov() !dbg !0 {; ...; }. !0 = distinct !DISubprogram(name: ""foo"", linkageName: ""_Zfoov"", scope: !1,; file: !2, line: 7, type: !3,; spFlags: DISPFlagDefinition | DISPFlagLocalToUnit,; scopeLine: 8, containingType: !4,; virtuality: DW_VIRTUALITY_pure_virtual,; virtualIndex: 10, flags: DIFlagPrototyped,; isOptimized: true, unit: !5, templateParams: !6,; declaration: !",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst:257912,optimiz,optimized,257912,interpreter/llvm-project/llvm/docs/LangRef.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/LangRef.rst,1,['optimiz'],['optimized']
Performance," not returned from the function or; stored in a global. This pass is implemented as a bottom-up traversal of the; call-graph. ``globaldce``: Dead Global Elimination; --------------------------------------. This transform is designed to eliminate unreachable internal globals from the; program. It uses an aggressive algorithm, searching out globals that are known; to be alive. After it finds all of the globals which are needed, it deletes; whatever is left over. This allows it to delete recursive chunks of the; program which are unreachable. ``globalopt``: Global Variable Optimizer; ----------------------------------------. This pass transforms simple global variables that never have their address; taken. If obviously true, it marks read/write globals as constant, deletes; variables only stored to, etc. ``gvn``: Global Value Numbering; -------------------------------. This pass performs global value numbering to eliminate fully and partially; redundant instructions. It also performs redundant load elimination. .. _passes-indvars:. ``indvars``: Canonicalize Induction Variables; ---------------------------------------------. This transformation analyzes and transforms the induction variables (and; computations derived from them) into simpler forms suitable for subsequent; analysis and transformation. This transformation makes the following changes to each loop with an; identifiable induction variable:. * All loops are transformed to have a *single* canonical induction variable; which starts at zero and steps by one.; * The canonical induction variable is guaranteed to be the first PHI node in; the loop header block.; * Any pointer arithmetic recurrences are raised to use array subscripts. If the trip count of a loop is computable, this pass also makes the following; changes:. * The exit condition for the loop is canonicalized to compare the induction; value against the exit value. This turns loops like:. .. code-block:: c++. for (i = 7; i*i < 1000; ++i). into. .. code-bl",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst:17479,perform,performs,17479,interpreter/llvm-project/llvm/docs/Passes.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Passes.rst,2,"['load', 'perform']","['load', 'performs']"
Performance," not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - Howe",MatchSource.DOCS,root-project,root,v6-32-06,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:251781,load,loads,251781,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,1,['load'],['loads']
