quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8144?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@20409d9`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8144 +/- ##; ================================================; Coverage ? 86.238% ; Complexity ? 35194 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17794 ; ================================================; Hits ? 142332 ; Misses ? 16387 ; Partials ? 6326 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8144#issuecomment-1371289099:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8144#issuecomment-1371289099,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8150?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@6f2e75a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8150 +/- ##; ================================================; Coverage ? 84.446% ; Complexity ? 34169 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17793 ; ================================================; Hits ? 139374 ; Misses ? 19292 ; Partials ? 6379 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8150#issuecomment-1376340935:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8150#issuecomment-1376340935,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8153?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@498a4a6`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8153 +/- ##; ================================================; Coverage ? 85.905% ; Complexity ? 35059 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17793 ; ================================================; Hits ? 141782 ; Misses ? 16981 ; Partials ? 6282 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8153#issuecomment-1378671783:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8153#issuecomment-1378671783,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8155?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@700dacd`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8155 +/- ##; ================================================; Coverage ? 67.594% ; Complexity ? 26719 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17794 ; ================================================; Hits ? 111561 ; Misses ? 48033 ; Partials ? 5451 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8155#issuecomment-1378826600:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8155#issuecomment-1378826600,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8156?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@c15e5fc`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8156 +/- ##; ================================================; Coverage ? 86.177% ; Complexity ? 35138 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17794 ; ================================================; Hits ? 142231 ; Misses ? 16470 ; Partials ? 6344 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8156#issuecomment-1379689850:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8156#issuecomment-1379689850,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8157?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@9cf8021`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8157 +/- ##; ================================================; Coverage ? 86.184% ; Complexity ? 35511 ; ================================================; Files ? 2191 ; Lines ? 166339 ; Branches ? 17900 ; ================================================; Hits ? 143358 ; Misses ? 16593 ; Partials ? 6388 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8157#issuecomment-1380564322:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8157#issuecomment-1380564322,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8162?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@fedb320`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8162 +/- ##; ================================================; Coverage ? 86.243% ; Complexity ? 35202 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17793 ; ================================================; Hits ? 142340 ; Misses ? 16380 ; Partials ? 6325 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8162#issuecomment-1382239483:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8162#issuecomment-1382239483,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8165?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@8a7b95d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8165 +/- ##; ================================================; Coverage ? 86.215% ; Complexity ? 35195 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17793 ; ================================================; Hits ? 142293 ; Misses ? 16420 ; Partials ? 6332 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8165#issuecomment-1397478481:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8165#issuecomment-1397478481,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8168?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@9cf8021`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8168 +/- ##; ================================================; Coverage ? 86.247% ; Complexity ? 35199 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17794 ; ================================================; Hits ? 142347 ; Misses ? 16374 ; Partials ? 6324 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8168#issuecomment-1400871943:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8168#issuecomment-1400871943,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8169?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@e706dc0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8169 +/- ##; ================================================; Coverage ? 86.219% ; Complexity ? 35515 ; ================================================; Files ? 2191 ; Lines ? 166339 ; Branches ? 17901 ; ================================================; Hits ? 143416 ; Misses ? 16543 ; Partials ? 6380 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8169#issuecomment-1400896867:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8169#issuecomment-1400896867,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8170?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@d1a6df3`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 5d5908f differs from pull request most recent head e137c8c. Consider uploading reports for the commit e137c8c to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8170 +/- ##; ================================================; Coverage ? 86.218% ; Complexity ? 35514 ; ================================================; Files ? 2191 ; Lines ? 166339 ; Branches ? 17901 ; ================================================; Hits ? 143414 ; Misses ? 16544 ; Partials ? 6381 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8170#issuecomment-1401219057:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8170#issuecomment-1401219057,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8172?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@9cf8021`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8172 +/- ##; ================================================; Coverage ? 86.245% ; Complexity ? 35202 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17793 ; ================================================; Hits ? 142343 ; Misses ? 16377 ; Partials ? 6325 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8172#issuecomment-1402434980:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8172#issuecomment-1402434980,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8173?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@50f4af6`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8173 +/- ##; ================================================; Coverage ? 86.247% ; Complexity ? 35199 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17794 ; ================================================; Hits ? 142347 ; Misses ? 16374 ; Partials ? 6324 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8173#issuecomment-1402439098:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8173#issuecomment-1402439098,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8176?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@31c3a02`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8176 +/- ##; ================================================; Coverage ? 86.246% ; Complexity ? 35198 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17794 ; ================================================; Hits ? 142345 ; Misses ? 16375 ; Partials ? 6325 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8176#issuecomment-1405870732:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8176#issuecomment-1405870732,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8178?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@e706dc0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 9b6b4fa differs from pull request most recent head 8e375d8. Consider uploading reports for the commit 8e375d8 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8178 +/- ##; ================================================; Coverage ? 86.247% ; Complexity ? 35198 ; ================================================; Files ? 2173 ; Lines ? 165045 ; Branches ? 17794 ; ================================================; Hits ? 142347 ; Misses ? 16373 ; Partials ? 6325 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8178#issuecomment-1409174687:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8178#issuecomment-1409174687,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8182?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@5b34ade`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8182 +/- ##; ================================================; Coverage ? 85.857% ; Complexity ? 35511 ; ================================================; Files ? 2194 ; Lines ? 167012 ; Branches ? 18001 ; ================================================; Hits ? 143392 ; Misses ? 17233 ; Partials ? 6387 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8182#issuecomment-1414516070:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8182#issuecomment-1414516070,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8184?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@39070f0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8184 +/- ##; ================================================; Coverage ? 86.218% ; Complexity ? 35518 ; ================================================; Files ? 2191 ; Lines ? 166339 ; Branches ? 17900 ; ================================================; Hits ? 143414 ; Misses ? 16544 ; Partials ? 6381 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8184#issuecomment-1416270346:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8184#issuecomment-1416270346,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8187?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@d07e773`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8187 +/- ##; ================================================; Coverage ? 86.181% ; Complexity ? 35508 ; ================================================; Files ? 2191 ; Lines ? 166339 ; Branches ? 17901 ; ================================================; Hits ? 143352 ; Misses ? 16601 ; Partials ? 6386 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8187#issuecomment-1419548583:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8187#issuecomment-1419548583,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8188?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@31c3a02`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8188 +/- ##; ================================================; Coverage ? 51.610% ; Complexity ? 26737 ; ================================================; Files ? 2191 ; Lines ? 166351 ; Branches ? 17903 ; ================================================; Hits ? 85854 ; Misses ? 75037 ; Partials ? 5460 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8188#issuecomment-1419590366:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8188#issuecomment-1419590366,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8190?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@fedb320`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8190 +/- ##; ================================================; Coverage ? 85.709% ; Complexity ? 35194 ; ================================================; Files ? 2191 ; Lines ? 166158 ; Branches ? 17793 ; ================================================; Hits ? 142413 ; Misses ? 17435 ; Partials ? 6310 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8190#issuecomment-1419925811:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8190#issuecomment-1419925811,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8191?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0c48d6d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 2d6c381 differs from pull request most recent head 90d3e3f. Consider uploading reports for the commit 90d3e3f to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8191 +/- ##; ================================================; Coverage ? 84.437% ; Complexity ? 34485 ; ================================================; Files ? 2191 ; Lines ? 166339 ; Branches ? 17901 ; ================================================; Hits ? 140452 ; Misses ? 19452 ; Partials ? 6435 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8191#issuecomment-1419999334:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8191#issuecomment-1419999334,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8193?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@d07e773`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8193 +/- ##; ================================================; Coverage ? 86.219% ; Complexity ? 35519 ; ================================================; Files ? 2191 ; Lines ? 166339 ; Branches ? 17900 ; ================================================; Hits ? 143416 ; Misses ? 16543 ; Partials ? 6380 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8193#issuecomment-1423309454:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8193#issuecomment-1423309454,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8200?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@d07e773`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8200 +/- ##; ================================================; Coverage ? 79.183% ; Complexity ? 33607 ; ================================================; Files ? 2191 ; Lines ? 166339 ; Branches ? 17900 ; ================================================; Hits ? 131713 ; Misses ? 28399 ; Partials ? 6227 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8200#issuecomment-1428533144:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8200#issuecomment-1428533144,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8202?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@ac04b54`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8202 +/- ##; ================================================; Coverage ? 85.888% ; Complexity ? 35518 ; ================================================; Files ? 2194 ; Lines ? 167012 ; Branches ? 18001 ; ================================================; Hits ? 143444 ; Misses ? 17187 ; Partials ? 6381 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8202#issuecomment-1429860891:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8202#issuecomment-1429860891,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8206?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@6f747d0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8206 +/- ##; ================================================; Coverage ? 85.814% ; Complexity ? 35456 ; ================================================; Files ? 2194 ; Lines ? 167015 ; Branches ? 18002 ; ================================================; Hits ? 143323 ; Misses ? 17292 ; Partials ? 6400 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8206#issuecomment-1432090725:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8206#issuecomment-1432090725,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8207?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@5b34ade`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8207 +/- ##; ================================================; Coverage ? 84.116% ; Complexity ? 34488 ; ================================================; Files ? 2194 ; Lines ? 167012 ; Branches ? 18001 ; ================================================; Hits ? 140484 ; Misses ? 20093 ; Partials ? 6435 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8207#issuecomment-1432118430:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8207#issuecomment-1432118430,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8210?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@ac04b54`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head b78e14c differs from pull request most recent head 977aec0. Consider uploading reports for the commit 977aec0 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8210 +/- ##; ================================================; Coverage ? 85.484% ; Complexity ? 35314 ; ================================================; Files ? 2194 ; Lines ? 167012 ; Branches ? 18000 ; ================================================; Hits ? 142768 ; Misses ? 17893 ; Partials ? 6351 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8210#issuecomment-1433521735:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8210#issuecomment-1433521735,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8216?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@1ce13b3`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8216 +/- ##; ================================================; Coverage ? 85.475% ; Complexity ? 35309 ; ================================================; Files ? 2194 ; Lines ? 167012 ; Branches ? 18000 ; ================================================; Hits ? 142754 ; Misses ? 17906 ; Partials ? 6352 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8216#issuecomment-1440250246:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8216#issuecomment-1440250246,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8220?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@fdbaa14`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8220 +/- ##; ================================================; Coverage ? 85.884% ; Complexity ? 35513 ; ================================================; Files ? 2194 ; Lines ? 167012 ; Branches ? 18001 ; ================================================; Hits ? 143436 ; Misses ? 17195 ; Partials ? 6381 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8220#issuecomment-1442592799:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8220#issuecomment-1442592799,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8225?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0014005`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8225 +/- ##; ================================================; Coverage ? 85.885% ; Complexity ? 35518 ; ================================================; Files ? 2194 ; Lines ? 167012 ; Branches ? 18000 ; ================================================; Hits ? 143438 ; Misses ? 17194 ; Partials ? 6380 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8225#issuecomment-1448458604:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8225#issuecomment-1448458604,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8229?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@6d41adf`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8229 +/- ##; ================================================; Coverage ? 83.987% ; Complexity ? 34800 ; ================================================; Files ? 2194 ; Lines ? 167016 ; Branches ? 18003 ; ================================================; Hits ? 140271 ; Misses ? 20518 ; Partials ? 6227 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8229#issuecomment-1450934113:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8229#issuecomment-1450934113,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8230?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@3a7f6e2`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8230 +/- ##; ================================================; Coverage ? 85.837% ; Complexity ? 35510 ; ================================================; Files ? 2194 ; Lines ? 167039 ; Branches ? 18004 ; ================================================; Hits ? 143382 ; Misses ? 17269 ; Partials ? 6388 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8230#issuecomment-1450446401:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8230#issuecomment-1450446401,1,['learn'],['learn']
Usability,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8236?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@5645e88`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8236 +/- ##; ================================================; Coverage ? 85.694% ; Complexity ? 35399 ; ================================================; Files ? 2194 ; Lines ? 167039 ; Branches ? 18004 ; ================================================; Hits ? 143142 ; Misses ? 17505 ; Partials ? 6392 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8236#issuecomment-1458701401:293,learn,learn,293,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8236#issuecomment-1458701401,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8282?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0f24625`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8282 +/- ##; ================================================; Coverage ? 86.097% ; Complexity ? 35607 ; ================================================; Files ? 2197 ; Lines ? 167119 ; Branches ? 18007 ; ================================================; Hits ? 143884 ; Misses ? 16802 ; Partials ? 6433 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8282#issuecomment-1520851049:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8282#issuecomment-1520851049,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8295?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0b4e305`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8295 +/- ##; ================================================; Coverage ? 86.188% ; Complexity ? 35524 ; ================================================; Files ? 2192 ; Lines ? 166470 ; Branches ? 17917 ; ================================================; Hits ? 143478 ; Misses ? 16606 ; Partials ? 6386 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8295#issuecomment-1520727759:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8295#issuecomment-1520727759,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8301?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0f24625`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8301 +/- ##; ================================================; Coverage ? 76.562% ; Complexity ? 21800 ; ================================================; Files ? 1390 ; Lines ? 83084 ; Branches ? 13237 ; ================================================; Hits ? 63611 ; Misses ? 14308 ; Partials ? 5165 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8301#issuecomment-1529211297:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8301#issuecomment-1529211297,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8312?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@928ffe9`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8312 +/- ##; ================================================; Coverage ? 86.193% ; Complexity ? 35520 ; ================================================; Files ? 2192 ; Lines ? 166470 ; Branches ? 17918 ; ================================================; Hits ? 143485 ; Misses ? 16600 ; Partials ? 6385 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8312#issuecomment-1544190557:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8312#issuecomment-1544190557,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8316?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@6a0b1a4`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 1104159 differs from pull request most recent head 20463d5. Consider uploading reports for the commit 20463d5 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8316 +/- ##; ================================================; Coverage ? 79.161% ; Complexity ? 33612 ; ================================================; Files ? 2192 ; Lines ? 166470 ; Branches ? 17917 ; ================================================; Hits ? 131780 ; Misses ? 28458 ; Partials ? 6232 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8316#issuecomment-1545955543:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8316#issuecomment-1545955543,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8321?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@ebe4835`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8321 +/- ##; ================================================; Coverage ? 85.819% ; Complexity ? 35381 ; ================================================; Files ? 2193 ; Lines ? 166544 ; Branches ? 17929 ; ================================================; Hits ? 142926 ; Misses ? 17273 ; Partials ? 6345 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8321#issuecomment-1547837528:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8321#issuecomment-1547837528,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8322?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@fe981fa`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 86da2fb differs from pull request most recent head 6008c58. Consider uploading reports for the commit 6008c58 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8322 +/- ##; ================================================; Coverage ? 42.495% ; Complexity ? 24044 ; ================================================; Files ? 2193 ; Lines ? 166544 ; Branches ? 17930 ; ================================================; Hits ? 70773 ; Misses ? 90620 ; Partials ? 5151 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8322#issuecomment-1548080149:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8322#issuecomment-1548080149,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8324?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@c575ff8`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 8aea303 differs from pull request most recent head 6c21de9. Consider uploading reports for the commit 6c21de9 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8324 +/- ##; ================================================; Coverage ? 16.773% ; Complexity ? 4707 ; ================================================; Files ? 1391 ; Lines ? 83142 ; Branches ? 13184 ; ================================================; Hits ? 13945 ; Misses ? 67132 ; Partials ? 2065 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8324#issuecomment-1550371424:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8324#issuecomment-1550371424,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8325?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@e3f2d8a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8325 +/- ##; ================================================; Coverage ? 86.155% ; Complexity ? 35517 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17926 ; ================================================; Hits ? 143481 ; Misses ? 16674 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8325#issuecomment-1550378961:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8325#issuecomment-1550378961,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8326?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@b64a252`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8326 +/- ##; ================================================; Coverage ? 86.193% ; Complexity ? 35521 ; ================================================; Files ? 2192 ; Lines ? 166470 ; Branches ? 17918 ; ================================================; Hits ? 143485 ; Misses ? 16601 ; Partials ? 6384 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8326#issuecomment-1551765161:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8326#issuecomment-1551765161,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8330?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@fe981fa`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8330 +/- ##; ================================================; Coverage ? 86.155% ; Complexity ? 35524 ; ================================================; Files ? 2193 ; Lines ? 166544 ; Branches ? 17929 ; ================================================; Hits ? 143486 ; Misses ? 16670 ; Partials ? 6388 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8330#issuecomment-1558063589:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8330#issuecomment-1558063589,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8334?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@40947ed`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8334 +/- ##; ================================================; Coverage ? 84.259% ; Complexity ? 34805 ; ================================================; Files ? 2193 ; Lines ? 166537 ; Branches ? 17924 ; ================================================; Hits ? 140323 ; Misses ? 19984 ; Partials ? 6230 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8334#issuecomment-1557679635:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8334#issuecomment-1557679635,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8336?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@85205fc`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 4fd48f7 differs from pull request most recent head 464e594. Consider uploading reports for the commit 464e594 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8336 +/- ##; ================================================; Coverage ? 86.086% ; Complexity ? 35457 ; ================================================; Files ? 2193 ; Lines ? 166541 ; Branches ? 17928 ; ================================================; Hits ? 143368 ; Misses ? 16765 ; Partials ? 6408 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8336#issuecomment-1557856438:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8336#issuecomment-1557856438,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8343?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@55a471a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8343 +/- ##; ================================================; Coverage ? 85.976% ; Complexity ? 35405 ; ================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17928 ; ================================================; Hits ? 143199 ; Misses ? 16965 ; Partials ? 6393 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8343#issuecomment-1561893562:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8343#issuecomment-1561893562,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8344?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0feb524`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8344 +/- ##; ================================================; Coverage ? 86.121% ; Complexity ? 35510 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17926 ; ================================================; Hits ? 143425 ; Misses ? 16723 ; Partials ? 6390 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8344#issuecomment-1563346001:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8344#issuecomment-1563346001,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8348?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0b41b51`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8348 +/- ##; ================================================; Coverage ? 86.159% ; Complexity ? 35516 ; ================================================; Files ? 2193 ; Lines ? 166537 ; Branches ? 17924 ; ================================================; Hits ? 143486 ; Misses ? 16666 ; Partials ? 6385 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8348#issuecomment-1568779341:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8348#issuecomment-1568779341,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8350?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@a191f2d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8350 +/- ##; ================================================; Coverage ? 86.155% ; Complexity ? 35517 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17926 ; ================================================; Hits ? 143481 ; Misses ? 16673 ; Partials ? 6384 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8350#issuecomment-1577427313:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8350#issuecomment-1577427313,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8360?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@5b72ceb`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8360 +/- ##; ================================================; Coverage ? 86.156% ; Complexity ? 35518 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17926 ; ================================================; Hits ? 143483 ; Misses ? 16672 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8360#issuecomment-1588172867:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8360#issuecomment-1588172867,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8365?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@1dafc33`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8365 +/- ##; ================================================; Coverage ? 86.155% ; Complexity ? 35517 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17926 ; ================================================; Hits ? 143481 ; Misses ? 16673 ; Partials ? 6384 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8365#issuecomment-1591745229:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8365#issuecomment-1591745229,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8374?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@af4f273`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8374 +/- ##; ================================================; Coverage ? 86.158% ; Complexity ? 35518 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17926 ; ================================================; Hits ? 143485 ; Misses ? 16670 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8374#issuecomment-1601747660:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8374#issuecomment-1601747660,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8375?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@90aa0fd`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 96b13ac differs from pull request most recent head 16fbf89. Consider uploading reports for the commit 16fbf89 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8375 +/- ##; ================================================; Coverage ? 86.155% ; Complexity ? 35517 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17926 ; ================================================; Hits ? 143481 ; Misses ? 16674 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8375#issuecomment-1603090906:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8375#issuecomment-1603090906,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8376?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@1ce25db`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8376 +/- ##; ================================================; Coverage ? 86.155% ; Complexity ? 35521 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17925 ; ================================================; Hits ? 143481 ; Misses ? 16674 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8376#issuecomment-1603277688:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8376#issuecomment-1603277688,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8377?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@37fe914`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8377 +/- ##; ================================================; Coverage ? 86.155% ; Complexity ? 35517 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17926 ; ================================================; Hits ? 143481 ; Misses ? 16674 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8377#issuecomment-1603168821:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8377#issuecomment-1603168821,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8379?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@90aa0fd`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8379 +/- ##; ================================================; Coverage ? 76.504% ; Complexity ? 21795 ; ================================================; Files ? 1392 ; Lines ? 83134 ; Branches ? 13184 ; ================================================; Hits ? 63601 ; Misses ? 14369 ; Partials ? 5164 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8379#issuecomment-1603351488:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8379#issuecomment-1603351488,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8388?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@901644f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head c92dbdd differs from pull request most recent head e3308ca. Consider uploading reports for the commit e3308ca to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8388 +/- ##; ================================================; Coverage ? 86.155% ; Complexity ? 35521 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17925 ; ================================================; Hits ? 143481 ; Misses ? 16674 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8388#issuecomment-1610169170:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8388#issuecomment-1610169170,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8392?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@90aa0fd`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8392 +/- ##; ================================================; Coverage ? 86.088% ; Complexity ? 35461 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17925 ; ================================================; Hits ? 143370 ; Misses ? 16767 ; Partials ? 6401 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8392#issuecomment-1612198935:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8392#issuecomment-1612198935,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8399?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@09989de`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8399 +/- ##; ================================================; Coverage ? 86.160% ; Complexity ? 35524 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17925 ; ================================================; Hits ? 143489 ; Misses ? 16665 ; Partials ? 6384 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8399#issuecomment-1615122400:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8399#issuecomment-1615122400,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8401?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@e90d90e`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8401 +/- ##; ================================================; Coverage ? 84.260% ; Complexity ? 34807 ; ================================================; Files ? 2194 ; Lines ? 166538 ; Branches ? 17926 ; ================================================; Hits ? 140325 ; Misses ? 19983 ; Partials ? 6230 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8401#issuecomment-1621702563:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8401#issuecomment-1621702563,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8404?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@60581fe`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8404 +/- ##; =======================================================; Coverage ? 86.161% ; Complexity ? 35519 ; =======================================================; Files ? 2194 ; Lines ? 166533 ; Branches ? 17926 ; =======================================================; Hits ? 143487 ; Misses ? 16663 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1625475765:305,learn,learn,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1625475765,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8412?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@5580ca0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8412 +/- ##; ================================================; Coverage ? 86.162% ; Complexity ? 35523 ; ================================================; Files ? 2194 ; Lines ? 166533 ; Branches ? 17925 ; ================================================; Hits ? 143488 ; Misses ? 16663 ; Partials ? 6382 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8412#issuecomment-1631098665:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8412#issuecomment-1631098665,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8422?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@da60534`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8422 +/- ##; =======================================================; Coverage ? 44.447% ; Complexity ? 24788 ; =======================================================; Files ? 2194 ; Lines ? 166533 ; Branches ? 17925 ; =======================================================; Hits ? 74019 ; Misses ? 87209 ; Partials ? 5305 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8422#issuecomment-1638661867:305,learn,learn,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8422#issuecomment-1638661867,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8423?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@7a144d3`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 4e40c14 differs from pull request most recent head 26fa502. Consider uploading reports for the commit 26fa502 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8423 +/- ##; ================================================; Coverage ? 16.791% ; Complexity ? 4708 ; ================================================; Files ? 1392 ; Lines ? 83169 ; Branches ? 13248 ; ================================================; Hits ? 13965 ; Misses ? 67144 ; Partials ? 2060 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8423#issuecomment-1638762697:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8423#issuecomment-1638762697,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8424?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@7a144d3`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8424 +/- ##; ================================================; Coverage ? 86.151% ; Complexity ? 35524 ; ================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17927 ; ================================================; Hits ? 143491 ; Misses ? 16683 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8424#issuecomment-1638931132:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8424#issuecomment-1638931132,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8426?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@154bee2`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head f2867f5 differs from pull request most recent head 9321715. Consider uploading reports for the commit 9321715 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8426 +/- ##; ================================================; Coverage ? 79.133% ; Complexity ? 33606 ; ================================================; Files ? 2194 ; Lines ? 166533 ; Branches ? 17926 ; ================================================; Hits ? 131783 ; Misses ? 28520 ; Partials ? 6230 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8426#issuecomment-1640973922:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8426#issuecomment-1640973922,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8429?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@260c334`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head bb8dc75 differs from pull request most recent head b95a16b. Consider uploading reports for the commit b95a16b to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8429 +/- ##; =======================================================; Coverage ? 86.152% ; Complexity ? 35525 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17927 ; =======================================================; Hits ? 143493 ; Misses ? 16682 ; Partials ? 6382 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8429#issuecomment-1644346011:305,learn,learn,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8429#issuecomment-1644346011,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8433?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@154bee2`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head aef01b7 differs from pull request most recent head 2f49bf3. Consider uploading reports for the commit 2f49bf3 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8433 +/- ##; ================================================; Coverage ? 86.152% ; Complexity ? 35524 ; ================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17927 ; ================================================; Hits ? 143493 ; Misses ? 16681 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8433#issuecomment-1648453095:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8433#issuecomment-1648453095,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8434?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@f44e924`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8434 +/- ##; =======================================================; Coverage ? 86.152% ; Complexity ? 35521 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17928 ; =======================================================; Hits ? 143493 ; Misses ? 16682 ; Partials ? 6382 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8434#issuecomment-1648724092:305,learn,learn,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8434#issuecomment-1648724092,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8437?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@d37e34b`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8437 +/- ##; ================================================; Coverage ? 84.375% ; Complexity ? 34492 ; ================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17928 ; ================================================; Hits ? 140533 ; Misses ? 19588 ; Partials ? 6436 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8437#issuecomment-1650218483:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8437#issuecomment-1650218483,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8441?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@295bfbd`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8441 +/- ##; =======================================================; Coverage ? 85.977% ; Complexity ? 35409 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17927 ; =======================================================; Hits ? 143201 ; Misses ? 16965 ; Partials ? 6391 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8441#issuecomment-1654080894:305,learn,learn,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8441#issuecomment-1654080894,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8444?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@576423f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8444 +/- ##; =======================================================; Coverage ? 79.127% ; Complexity ? 33613 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17927 ; =======================================================; Hits ? 131792 ; Misses ? 28536 ; Partials ? 6229 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8444#issuecomment-1658465758:305,learn,learn,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8444#issuecomment-1658465758,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8446?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@d0eaafe`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head d699778 differs from pull request most recent head 0211678. Consider uploading reports for the commit 0211678 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8446 +/- ##; =======================================================; Coverage ? 86.154% ; Complexity ? 35521 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17928 ; =======================================================; Hits ? 143495 ; Misses ? 16680 ; Partials ? 6382 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8446#issuecomment-1660633770:305,learn,learn,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8446#issuecomment-1660633770,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8448?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@d488339`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8448 +/- ##; =======================================================; Coverage ? 86.151% ; Complexity ? 35524 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17927 ; =======================================================; Hits ? 143491 ; Misses ? 16683 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8448#issuecomment-1661011654:305,learn,learn,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8448#issuecomment-1661011654,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8449?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@5a9d64a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8449 +/- ##; =======================================================; Coverage ? 86.152% ; Complexity ? 35524 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17927 ; =======================================================; Hits ? 143493 ; Misses ? 16681 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8449#issuecomment-1661006980:305,learn,learn,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8449#issuecomment-1661006980,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8451?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@5a9d64a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8451 +/- ##; =======================================================; Coverage ? 86.085% ; Complexity ? 35463 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17927 ; =======================================================; Hits ? 143380 ; Misses ? 16775 ; Partials ? 6402 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8451#issuecomment-1662329609:305,learn,learn,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8451#issuecomment-1662329609,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8452?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@58a7756`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8452 +/- ##; =======================================================; Coverage ? 86.155% ; Complexity ? 35524 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17928 ; =======================================================; Hits ? 143498 ; Misses ? 16677 ; Partials ? 6382 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8452#issuecomment-1664274127:305,learn,learn,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8452#issuecomment-1664274127,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8454?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@1685694`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8454 +/- ##; =======================================================; Coverage ? 86.154% ; Complexity ? 35523 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17928 ; =======================================================; Hits ? 143496 ; Misses ? 16678 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8454#issuecomment-1666193340:305,learn,learn,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8454#issuecomment-1666193340,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8457?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@20e5496`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8457 +/- ##; =======================================================; Coverage ? 86.155% ; Complexity ? 35524 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17928 ; =======================================================; Hits ? 143498 ; Misses ? 16677 ; Partials ? 6382 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8457#issuecomment-1668684607:305,learn,learn,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8457#issuecomment-1668684607,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8459?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@6cc161c`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## ah_var_store #8459 +/- ##; ================================================; Coverage ? 86.052% ; Complexity ? 35407 ; ================================================; Files ? 2194 ; Lines ? 166374 ; Branches ? 17820 ; ================================================; Hits ? 143168 ; Misses ? 16816 ; Partials ? 6390 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8459#issuecomment-1670225203:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8459#issuecomment-1670225203,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8465?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@f839eb0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8465 +/- ##; ================================================; Coverage ? 86.154% ; Complexity ? 35523 ; ================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17928 ; ================================================; Hits ? 143496 ; Misses ? 16678 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8465#issuecomment-1673782679:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8465#issuecomment-1673782679,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8469?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@d8bc38d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8469 +/- ##; =======================================================; Coverage ? 86.121% ; Complexity ? 35516 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17928 ; =======================================================; Hits ? 143440 ; Misses ? 16727 ; Partials ? 6390 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8469#issuecomment-1674793264:305,learn,learn,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8469#issuecomment-1674793264,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8471?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@f839eb0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8471 +/- ##; ================================================; Coverage ? 86.154% ; Complexity ? 35523 ; ================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17928 ; ================================================; Hits ? 143496 ; Misses ? 16678 ; Partials ? 6383 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8471#issuecomment-1675482821:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8471#issuecomment-1675482821,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8478?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@c1efb6f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8478 +/- ##; =======================================================; Coverage ? 85.979% ; Complexity ? 35409 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17928 ; =======================================================; Hits ? 143204 ; Misses ? 16961 ; Partials ? 6392 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8478#issuecomment-1680714556:305,learn,learn,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8478#issuecomment-1680714556,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8480?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@c1efb6f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8480 +/- ##; =======================================================; Coverage ? 85.978% ; Complexity ? 35410 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17927 ; =======================================================; Hits ? 143202 ; Misses ? 16962 ; Partials ? 6393 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8480#issuecomment-1680729482:305,learn,learn,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8480#issuecomment-1680729482,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8487?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@6cc161c`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 92d2629 differs from pull request most recent head eb060d8. Consider uploading reports for the commit eb060d8 to get more accurate results. ```diff; @@ Coverage Diff @@; ## ah_var_store #8487 +/- ##; ================================================; Coverage ? 86.051% ; Complexity ? 35406 ; ================================================; Files ? 2194 ; Lines ? 166374 ; Branches ? 17820 ; ================================================; Hits ? 143166 ; Misses ? 16817 ; Partials ? 6391 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8487#issuecomment-1696195651:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8487#issuecomment-1696195651,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8488?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@f839eb0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head cfe9df2 differs from pull request most recent head b162855. Consider uploading reports for the commit b162855 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8488 +/- ##; =======================================================; Coverage ? 86.086% ; Complexity ? 35464 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17927 ; =======================================================; Hits ? 143382 ; Misses ? 16774 ; Partials ? 6401 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8488#issuecomment-1686937041:305,learn,learn,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8488#issuecomment-1686937041,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8491?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@dc1b3e9`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8491 +/- ##; =======================================================; Coverage ? 62.505% ; Complexity ? 17244 ; =======================================================; Files ? 1392 ; Lines ? 83169 ; Branches ? 13248 ; =======================================================; Hits ? 51985 ; Misses ? 26001 ; Partials ? 5183 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8491#issuecomment-1690577393:305,learn,learn,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8491#issuecomment-1690577393,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8493?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`bulk_ingest_staging@dc1b3e9`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## bulk_ingest_staging #8493 +/- ##; =======================================================; Coverage ? 86.086% ; Complexity ? 35460 ; =======================================================; Files ? 2194 ; Lines ? 166557 ; Branches ? 17928 ; =======================================================; Hits ? 143382 ; Misses ? 16774 ; Partials ? 6401 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8493#issuecomment-1691609046:305,learn,learn,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8493#issuecomment-1691609046,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8507?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@3a2adec`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 883fc2e differs from pull request most recent head 9387e9a. Consider uploading reports for the commit 9387e9a to get more accurate results. ```diff; @@ Coverage Diff @@; ## ah_var_store #8507 +/- ##; ================================================; Coverage ? 70.645% ; Complexity ? 28786 ; ================================================; Files ? 2195 ; Lines ? 166413 ; Branches ? 17828 ; ================================================; Hits ? 117563 ; Misses ? 43183 ; Partials ? 5667 ; ```. :loudspeaker: Thoughts on this report? [Let us know!](https://about.codecov.io/pull-request-comment-report/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8507#issuecomment-1699284129:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8507#issuecomment-1699284129,1,['learn'],['learn']
Usability,## [Codecov](https://app.codecov.io/gh/broadinstitute/gatk/pull/8509?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@a4bed50`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head c9e4c3f differs from pull request most recent head 85b7a3b. Consider uploading reports for the commit 85b7a3b to get more accurate results. ```diff; @@ Coverage Diff @@; ## ah_var_store #8509 +/- ##; ================================================; Coverage ? 85.524% ; Complexity ? 39841 ; ================================================; Files ? 2420 ; Lines ? 189649 ; Branches ? 20685 ; ================================================; Hits ? 162196 ; Misses ? 20184 ; Partials ? 7269 ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8509#issuecomment-1702911638:298,learn,learn,298,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8509#issuecomment-1702911638,1,['learn'],['learn']
Usability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8175?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@8217073`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8175 +/- ##; ================================================; Coverage ? 85.880% ; Complexity ? 35515 ; ================================================; Files ? 2194 ; Lines ? 167029 ; Branches ? 18006 ; ================================================; Hits ? 143444 ; Misses ? 17204 ; Partials ? 6381 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8175#issuecomment-1405736974:294,learn,learn,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8175#issuecomment-1405736974,1,['learn'],['learn']
Usability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8197?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@4a1c203`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8197 +/- ##; ================================================; Coverage ? 83.979% ; Complexity ? 34803 ; ================================================; Files ? 2194 ; Lines ? 167039 ; Branches ? 18005 ; ================================================; Hits ? 140278 ; Misses ? 20534 ; Partials ? 6227 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8197#issuecomment-1441167372:294,learn,learn,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8197#issuecomment-1441167372,1,['learn'],['learn']
Usability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8205?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@d07e773`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8205 +/- ##; ================================================; Coverage ? 83.980% ; Complexity ? 34807 ; ================================================; Files ? 2194 ; Lines ? 167039 ; Branches ? 18004 ; ================================================; Hits ? 140279 ; Misses ? 20533 ; Partials ? 6227 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8205#issuecomment-1431939059:294,learn,learn,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8205#issuecomment-1431939059,1,['learn'],['learn']
Usability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8214?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@d07e773`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8214 +/- ##; ================================================; Coverage ? 85.887% ; Complexity ? 35515 ; ================================================; Files ? 2194 ; Lines ? 167012 ; Branches ? 18001 ; ================================================; Hits ? 143442 ; Misses ? 17190 ; Partials ? 6380 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8214#issuecomment-1439187114:294,learn,learn,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8214#issuecomment-1439187114,1,['learn'],['learn']
Usability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8250?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@291bfd0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head f840dcb differs from pull request most recent head f8fb2ec. Consider uploading reports for the commit f8fb2ec to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8250 +/- ##; ================================================; Coverage ? 85.467% ; Complexity ? 35312 ; ================================================; Files ? 2194 ; Lines ? 167039 ; Branches ? 18004 ; ================================================; Hits ? 142764 ; Misses ? 17923 ; Partials ? 6352 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8250#issuecomment-1476982396:294,learn,learn,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8250#issuecomment-1476982396,1,['learn'],['learn']
Usability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8254?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@291bfd0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8254 +/- ##; ================================================; Coverage ? 85.700% ; Complexity ? 35403 ; ================================================; Files ? 2194 ; Lines ? 167039 ; Branches ? 18004 ; ================================================; Hits ? 143152 ; Misses ? 17496 ; Partials ? 6391 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8254#issuecomment-1477885334:294,learn,learn,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8254#issuecomment-1477885334,1,['learn'],['learn']
Usability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8260?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@bb6806b`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8260 +/- ##; ================================================; Coverage ? 16.665% ; Complexity ? 4707 ; ================================================; Files ? 1392 ; Lines ? 83713 ; Branches ? 13263 ; ================================================; Hits ? 13951 ; Misses ? 67697 ; Partials ? 2065 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8260#issuecomment-1480347954:294,learn,learn,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8260#issuecomment-1480347954,1,['learn'],['learn']
Usability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8261?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@291bfd0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8261 +/- ##; ================================================; Coverage ? 85.873% ; Complexity ? 35517 ; ================================================; Files ? 2194 ; Lines ? 167039 ; Branches ? 18005 ; ================================================; Hits ? 143442 ; Misses ? 17216 ; Partials ? 6381 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8261#issuecomment-1481911828:294,learn,learn,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8261#issuecomment-1481911828,1,['learn'],['learn']
Usability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8262?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@c0535f2`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8262 +/- ##; ================================================; Coverage ? 85.875% ; Complexity ? 35516 ; ================================================; Files ? 2194 ; Lines ? 167039 ; Branches ? 18005 ; ================================================; Hits ? 143444 ; Misses ? 17214 ; Partials ? 6381 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8262#issuecomment-1482752379:294,learn,learn,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8262#issuecomment-1482752379,1,['learn'],['learn']
Usability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8268?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@0f24625`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8268 +/- ##; ================================================; Coverage ? 86.097% ; Complexity ? 35609 ; ================================================; Files ? 2197 ; Lines ? 167119 ; Branches ? 18006 ; ================================================; Hits ? 143884 ; Misses ? 16800 ; Partials ? 6435 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8268#issuecomment-1487572354:294,learn,learn,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8268#issuecomment-1487572354,1,['learn'],['learn']
Usability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8269?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@17afee4`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8269 +/- ##; ================================================; Coverage ? 42.749% ; Complexity ? 23842 ; ================================================; Files ? 2197 ; Lines ? 167119 ; Branches ? 18006 ; ================================================; Hits ? 71442 ; Misses ? 90265 ; Partials ? 5412 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8269#issuecomment-1489046738:294,learn,learn,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8269#issuecomment-1489046738,1,['learn'],['learn']
Usability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8274?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@2dd76f7`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 7f8aebc differs from pull request most recent head f968453. Consider uploading reports for the commit f968453 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8274 +/- ##; ================================================; Coverage ? 85.874% ; Complexity ? 35522 ; ================================================; Files ? 2194 ; Lines ? 167046 ; Branches ? 18005 ; ================================================; Hits ? 143449 ; Misses ? 17216 ; Partials ? 6381 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8274#issuecomment-1489429332:294,learn,learn,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8274#issuecomment-1489429332,1,['learn'],['learn']
Usability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8278?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@8217073`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8278 +/- ##; ================================================; Coverage ? 85.882% ; Complexity ? 35522 ; ================================================; Files ? 2194 ; Lines ? 167029 ; Branches ? 18005 ; ================================================; Hits ? 143448 ; Misses ? 17200 ; Partials ? 6381 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8278#issuecomment-1496591221:294,learn,learn,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8278#issuecomment-1496591221,1,['learn'],['learn']
Usability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8281?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@23a64a7`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8281 +/- ##; ================================================; Coverage ? 85.845% ; Complexity ? 35511 ; ================================================; Files ? 2194 ; Lines ? 167029 ; Branches ? 18005 ; ================================================; Hits ? 143386 ; Misses ? 17254 ; Partials ? 6389 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8281#issuecomment-1501927327:294,learn,learn,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8281#issuecomment-1501927327,1,['learn'],['learn']
Usability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8284?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@e2b2e5c`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8284 +/- ##; ================================================; Coverage ? 86.098% ; Complexity ? 35610 ; ================================================; Files ? 2197 ; Lines ? 167119 ; Branches ? 18006 ; ================================================; Hits ? 143886 ; Misses ? 16799 ; Partials ? 6434 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8284#issuecomment-1504030123:294,learn,learn,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8284#issuecomment-1504030123,1,['learn'],['learn']
Usability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8286?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@ce3a5c7`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8286 +/- ##; ================================================; Coverage ? 86.096% ; Complexity ? 35609 ; ================================================; Files ? 2197 ; Lines ? 167119 ; Branches ? 18006 ; ================================================; Hits ? 143882 ; Misses ? 16802 ; Partials ? 6435 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8286#issuecomment-1505472967:294,learn,learn,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8286#issuecomment-1505472967,1,['learn'],['learn']
Usability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8289?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@4ab6bde`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8289 +/- ##; ================================================; Coverage ? 86.096% ; Complexity ? 35605 ; ================================================; Files ? 2197 ; Lines ? 167119 ; Branches ? 18007 ; ================================================; Hits ? 143882 ; Misses ? 16802 ; Partials ? 6435 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8289#issuecomment-1507734807:294,learn,learn,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8289#issuecomment-1507734807,1,['learn'],['learn']
Usability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8298?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@a2ffeb8`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8298 +/- ##; ================================================; Coverage ? 86.096% ; Complexity ? 35609 ; ================================================; Files ? 2197 ; Lines ? 167119 ; Branches ? 18006 ; ================================================; Hits ? 143882 ; Misses ? 16802 ; Partials ? 6435 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8298#issuecomment-1523456501:294,learn,learn,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8298#issuecomment-1523456501,1,['learn'],['learn']
Usability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8300?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@daeae13`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8300 +/- ##; ================================================; Coverage ? 84.201% ; Complexity ? 34893 ; ================================================; Files ? 2197 ; Lines ? 167119 ; Branches ? 18007 ; ================================================; Hits ? 140716 ; Misses ? 20123 ; Partials ? 6280 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8300#issuecomment-1527978078:294,learn,learn,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8300#issuecomment-1527978078,1,['learn'],['learn']
Usability,## [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/8303?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) Report; > :exclamation: No coverage uploaded for pull request base (`ah_var_store@daeae13`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## ah_var_store #8303 +/- ##; ================================================; Coverage ? 44.523% ; Complexity ? 24872 ; ================================================; Files ? 2197 ; Lines ? 167119 ; Branches ? 18006 ; ================================================; Hits ? 74407 ; Misses ? 87356 ; Partials ? 5356 ; ```. </details>,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8303#issuecomment-1529946227:294,learn,learn,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8303#issuecomment-1529946227,1,['learn'],['learn']
Usability,"#### Guidelines for converting arguments to kebab case. We're not following an external spec doc, so here some guidelines to follow instead. Keep in mind that the main thing we're going for here is readability and consistency across tools, not absolute purity, so feel free to raise discussion on any cases where you feel the guidelines should be relaxed. Some things are more negotiable than others. . 1. Use all lower-case (yes, even for file formats).; 2. Use only dash (`-`) as separator, no underscores (because lots of newbies struggle to differentiate the two, and underscores take more effort to type than dashes).; 3. Separate words rather than smushing them together, eg use `--do-this-thing` rather than `--dothisthing` (this is really important for readability, especially for non-native English speakers).; 4. Avoid cryptic abbreviations and acronyms; eg use `--do-this-thing` rather than `--dtt`; 5. If you end up with `--really-long-argument-names-that-take-up-half-a-line`, please reach out and ask for a consult; maybe we can find a more succinct way of expressing what you need.; 6. If you run into any situation not covered above, please bring it up in this thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346190915:111,guid,guidelines,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346190915,2,['guid'],['guidelines']
Usability,"#### Hiding / deprecating tools and their docs. @samuelklee To add to @sooheelee's answer, if there are any tools that you definitely want gone and already have a replacement for, I would encourage you to kill them off (ie delete from the code) before the 4.0 launch. While we're still in beta we can remove anything at the drop of a hat. Once 4.0 is out, we'll have a deprecation policy (exact details TBD) that will allow us to prune unwanted tools over time, but it will be less trivial. And as Soo Hee said, everything that's in the current code release MUST be documented. We used to hide tools/docs in the past and it caused us more headaches than not. . That being said, as part of that TBD deprecation policy it will probably make sense to make a ""Deprecated"" program group where tools go to die. If there are tools you plan to kill but don't want to do it before 4.0 is released for whatever reason, you could put them there. Documentation standards can be less stringent for tools in that bucket. To be clear I think the deprecation group name should be generic, ie not named to match any particular use case or functionality. That will help us avoid seeing deprecation buckets proliferate for each variant class/ use case. Does that sound like a reasonable compromise?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346189138:1013,clear,clear,1013,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346189138,1,['clear'],['clear']
Usability,"#6119 has these changes (and more), but this PR has a set of simple changes that should be easy to merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6145#issuecomment-530311878:61,simpl,simple,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6145#issuecomment-530311878,1,['simpl'],['simple']
Usability,"#; ===============================================; + Coverage 76.262% 76.279% +0.018% ; - Complexity 10880 10891 +11 ; ===============================================; Files 752 752 ; Lines 39590 39590 ; Branches 6925 6925 ; ===============================================; + Hits 30192 30199 +7 ; + Misses 6776 6768 -8 ; - Partials 2622 2623 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2531?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...nder/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2531?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nRW5naW5lLmphdmE=) | `49.123% <100%> (+2.632%)` | `41 <0> (+9)` | :arrow_up: |; | [...ols/walkers/genotyper/MinimalGenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2531?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9NaW5pbWFsR2Vub3R5cGluZ0VuZ2luZS5qYXZh) | `27.273% <0%> (ø)` | `4% <0%> (+1%)` | :arrow_up: |; | [...lbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2531?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzLmphdmE=) | `78.175% <0%> (+0.179%)` | `176% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2531?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2531?src=pr&el=footer). Last update [a85e0ff...985628d](https://codecov.io/gh/broadinstitute/gatk/pull/2531?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2531#issuecomment-289150335:2002,learn,learn,2002,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2531#issuecomment-289150335,1,['learn'],['learn']
Usability,"#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9XaW5kb3dTb3J0ZXIuamF2YQ==) | `100% <100%> (ø)` | `5 <5> (?)` | |; | [...bender/tools/spark/sv/AlignedAssemblyOrExcuse.java](https://codecov.io/gh/broadinstitute/gatk/pull/2444?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9BbGlnbmVkQXNzZW1ibHlPckV4Y3VzZS5qYXZh) | `11.299% <11.299%> (ø)` | `4 <4> (?)` | |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2444?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `40.469% <17.742%> (-18.009%)` | `28 <1> (ø)` | |; | [.../hellbender/tools/spark/sv/BreakpointEvidence.java](https://codecov.io/gh/broadinstitute/gatk/pull/2444?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9CcmVha3BvaW50RXZpZGVuY2UuamF2YQ==) | `81.463% <40%> (-2.293%)` | `24 <0> (ø)` | |; | [...titute/hellbender/tools/spark/sv/ReadMetadata.java](https://codecov.io/gh/broadinstitute/gatk/pull/2444?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkTWV0YWRhdGEuamF2YQ==) | `82.278% <44.231%> (-6.409%)` | `22 <1> (ø)` | |; | ... and [24 more](https://codecov.io/gh/broadinstitute/gatk/pull/2444?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2444?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2444?src=pr&el=footer). Last update [f91f7ac...553ba12](https://codecov.io/gh/broadinstitute/gatk/pull/2444?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2444#issuecomment-285180830:4071,learn,learn,4071,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2444#issuecomment-285180830,1,['learn'],['learn']
Usability,(Note that the failure in the cloud tests is expected due to an ongoing GCS bucket region migration -- it should clear up next week),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8318#issuecomment-1546280764:113,clear,clear,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8318#issuecomment-1546280764,1,['clear'],['clear']
Usability,") will **increase** coverage by `-0.005%`. ```diff; @@ Coverage Diff @@; ## master #2388 +/- ##; ===============================================; - Coverage 76.379% 76.374% -0.005% ; - Complexity 0 10845 +10845 ; ===============================================; Files 748 748 ; Lines 39325 39325 ; Branches 6849 6849 ; ===============================================; - Hits 30036 30034 -2 ; - Misses 6695 6697 +2 ; Partials 2594 2594; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2388?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...ca6c34e559073d30d05b624da48cfcbfd53f160a?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `85.593% <ø> (-1.476%)` | `45 <ø> (+45)` | |; | [...stitute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...ca6c34e559073d30d05b624da48cfcbfd53f160a?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `91.667% <100%> (-0.194%)` | `24 <1> (+24)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2388?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2388?src=pr&el=footer). Last update [14f73e2...ca6c34e](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...ca6c34e559073d30d05b624da48cfcbfd53f160a?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2388#issuecomment-277262598:1785,learn,learn,1785,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2388#issuecomment-277262598,1,['learn'],['learn']
Usability,"* If you are planning to add more allele specific annotations (other than the ones listed [here](https://github.com/Intel-HLS/GenomicsDB/blob/master/src/main/java/com/intel/genomicsdb/importer/Constants.java)), then I can provide more example code in GATK showing how to set the type and length descriptors.; * If you simply wish to change the combine operation for existing annotations, the example code in this PR should suffice",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4993#issuecomment-415611462:318,simpl,simply,318,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4993#issuecomment-415611462,1,['simpl'],['simply']
Usability,"+1 ; =============================================; + Hits 30028 30036 +8 ; + Misses 6693 6689 -4 ; + Partials 2594 2592 -2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2379?src=pr&el=tree) | Coverage Δ | |; |---|---|---|; | [...adinstitute/hellbender/tools/spark/sv/SVUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...20a2c012125731780810c4f8a0075be745b2925a?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TVlV0aWxzLmphdmE=) | `32.184% <ø> (-0.757%)` | :x: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...20a2c012125731780810c4f8a0075be745b2925a?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `76.389% <ø> (+2.083%)` | :white_check_mark: |; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...20a2c012125731780810c4f8a0075be745b2925a?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `82.707% <ø> (+3.759%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2379?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2379?src=pr&el=footer). Last update [8a42977...20a2c01](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...20a2c012125731780810c4f8a0075be745b2925a?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2379#issuecomment-276752112:2070,learn,learn,2070,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2379#issuecomment-276752112,1,['learn'],['learn']
Usability,"+1 from me too. This is a problem with tools that read from genomics DB; when run on large sample sets. On Mon, Apr 9, 2018, 5:06 PM jamesemery <notifications@github.com> wrote:. > I have noticed that running print reads with a stringent filter which I; > expect to only return a handful of reads results in the progress meter; > never printing any progress. This makes it look like the gatk has hung; > despite the fact it is chugging away and filtering every read it passes; > over. This should be updated to include an indication of how many reads; > have been filtered. Additionally, it should be improved to use a second; > thread to make periodic updates based on execution time incase the tool; > really has hung in order to make it clearer to the user what is going on.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4641>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdLWElMXIsQZBXUpJLA6XHlVP-qd6ks5tm801gaJpZM4TNOh8>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4641#issuecomment-380086823:740,clear,clearer,740,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4641#issuecomment-380086823,1,['clear'],['clearer']
Usability,"+1, lgtm! looks great to delete/simplify so much!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1068#issuecomment-152042390:32,simpl,simplify,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1068#issuecomment-152042390,1,['simpl'],['simplify']
Usability,"+1MOn Sat, Feb 28, 2015 at 1:14 PM, ldgauthier notifications@github.com wrote: It would be wonderful to be able to use SelectVariants with a query like -select ""AF > 0.1"" on a VCF containing multiallelics and have it filter multiallelics by the allele with the highest AF. (Possibly conversely for ""AF < X""queries. Right now it crashes unless you use a crazy JEXL or pull out the multiallelics. Maybe we could make a maxAF/minAF in htsjdk/JEXLmap.java which equals AF for biallelics?. Internally, it might be nice to have a Map with the AF (or AC) for each allele for the SelectVariants issue and to simplify some of the crazy logic already in VariantAnnotator to deal with different allele ordering. As part of this task, we should also make 100% sure that allele ordering is preserved so that AF/AC array ordering is preserved during VC reading/writing/manipulation. —Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/241#issuecomment-76543438:600,simpl,simplify,600,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/241#issuecomment-76543438,1,['simpl'],['simplify']
Usability,", et al. Nature. 2022 Jul;607(7920):732-740. doi: 10.1038/s41586-022-04965-x. Epub 2022 Jul 20.PMID: 35859178. On page 69+ of this pdf, they describe the problem and how they cleverly worked around it. ; ; https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-022-04965-x/MediaObjects/41586_2022_4965_MOESM1_ESM.pdf. _It should be noted that running GATK out of the box will cause every job to read the entire; gVCF index file (.tbi) for each of the 150,119 samples. The average size of the index files is ; 4.15MB, so each job would have to read 4.15*150,126 = 623GB of data on top of the actual; gVCF slice data. For 60,000 jobs, this would amount to 623GB*60,000 = 37PB or 25.2GB/sec; of additional read overhead if the jobs are run on 20,000 cores in 17 days. This read; overhead will definitely prevent 20,000 cores from being used simultaneously. However,; this problem was avoided by pre-processing the .tbi files and modifying the software; reading the gVCF files from the central storage in a similar fashion as we did for GraphTyper; and the CRAM index files (.crai)._. This explains why chr1 requires more memory than chr22 despite running on the same number of samples. The larger chr1 tbi index is the source of the memory problem. The Decode solution is too limit the reading of the tbi index to the part that indexes the scattered region. There is a long pause at the beginning of the running GenotypeGVCFs which I never understood. GATK must be the reading of all the sample's gvcfs tbi into memory during that pause. So the reblocking of the gvcfs above reduced the memory foot print by decreasing the tbi size. Decode reduced it by chopping up the index so for each scattered region, GATK could only read a small subset of the index needed for that region. The combination of reblocking and chopping up the tbi would help with the memory requirements even more. However, it is clear that GATK's present reading of the full tbi is not scalable given the memory requirements.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1374348579:1632,pause,pause,1632,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1374348579,3,"['clear', 'pause']","['clear', 'pause']"
Usability,- [ ] Not sure if UniqueAltReadCount.java's acronym is actually UNIQ_ALT_READ_COUNT.; - [x] Not clear what VariantOverlapAnnotator.java does and whether it actually should be tagged. `NO`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-344704534:96,clear,clear,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-344704534,1,['clear'],['clear']
Usability,"-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9jbHVzdGVyaW5nL1NvbWF0aWNDbHVzdGVyaW5nTW9kZWwuamF2YQ==) | `99.35% <100%> (ø)` | `65 <1> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5827/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...e/hellbender/engine/filters/ReadFilterLibrary.java](https://codecov.io/gh/broadinstitute/gatk/pull/5827/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9SZWFkRmlsdGVyTGlicmFyeS5qYXZh) | `94.56% <0%> (-0.95%)` | `1% <0%> (ø)` | |; | [...nder/engine/filters/ReadFilterLibraryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5827/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9SZWFkRmlsdGVyTGlicmFyeVVuaXRUZXN0LmphdmE=) | `100% <0%> (ø)` | `59% <0%> (+1%)` | :arrow_up: |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5827/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5827?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5827?src=pr&el=footer). Last update [fb2b5a2...6cc5267](https://codecov.io/gh/broadinstitute/gatk/pull/5827?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5827#issuecomment-475644133:4370,learn,learn,4370,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5827#issuecomment-475644133,1,['learn'],['learn']
Usability,"-insertions_default_quality 45 --deletions_default_quality 45 --low_quality_tail 2 --quantizing_levels 16 --interval_set_rule UNION --interval_padding 0 --bqsrBAQGapOpenPenalty 40.0 --preserve_qscores_less_than 6 --useOriginalQualities false --defaultBaseQualities -1 --runner LOCAL --client_secret client-secrets.json --help false --version false --VERBOSITY INFO --QUIET false; [June 1, 2015 5:51:02 PM EDT] Executing as pgrosu@eofe5 on Linux 2.6.32-358.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_05-b13; Version: Version:version-unknown-SNAPSHOT JdkDeflater; 17:51:02.969 [main] INFO org.broadinstitute.hellbender.dev.tools.walkers.bqsr.BaseRecalibratorDataflow - Initializing engine; 17:51:02.970 [main] INFO org.broadinstitute.hellbender.dev.tools.walkers.bqsr.BaseRecalibratorDataflow - Done initializing engine; 17:51:03.123 [main] INFO org.broadinstitute.hellbender.dev.tools.walkers.bqsr.BaseRecalibratorDataflow - Shutting down engine; [June 1, 2015 5:51:03 PM EDT] org.broadinstitute.hellbender.dev.tools.walkers.bqsr.BaseRecalibratorDataflow done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=1077936128; Exception in thread ""main"" java.lang.NoSuchMethodError: com.google.common.collect.Sets.newConcurrentHashSet()Ljava/util/Set;; at com.google.cloud.dataflow.sdk.options.PipelineOptionsFactory.<clinit>(PipelineOptionsFactory.java:426); at org.broadinstitute.hellbender.engine.dataflow.DataflowCommandLineProgram.doWork(DataflowCommandLineProgram.java:77); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:97); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:150); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:71); at org.broadinstitute.hellbender.Main.main(Main.java:86); ```. I don't have a billing-enabled GCS account, so I did this test to see if I could make it run with my `client-secrets.json` file. Any guidance would be appreciated. Thank you,; Paul",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107730499:5862,guid,guidance,5862,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107730499,1,['guid'],['guidance']
Usability,". I think any upstream padding doesnt matter. If you have a multi-nucleotide polymorphism that starts upstream of 1050 but spans 1050, this job wouldnt be responsible for calling that. The prior job, which has an interval set upstream of this one should call it. I think GenomicsDbImport's behavior is fine here. If you have a multi-NT variant that starts within 1050-1150, but extends outside (i.e. deletion or insertion starting at 1148), this could be a problem. The GenomicsDB workspace created with the interval 1:1050-1150 lacks the information to score that, right? The workspace created using the more permissive SelectVariants->GenomicsDBImport contains that downstream information and presumably would make the same call as if GenotypeGVCFs was given the intact chromosome as input, right?. However, it seems that if I simply create the workspace with a reasonably padded interval (adding 1kb should be more than enough for Illumina, right?), and then run GenotypeGVCFs with the original, unpassed interval, then the resulting workspace should contain all available information and GenotypeGVCFs should be able to make the same call as if it was given a whole-chromosome workspace as input. . Does that logic seem right? . ```; # The Input gVCF; 1	1040	.	A	<NON_REF>	.	.	END=1046	GT:DP:GQ:MIN_DP:PL	0/0:15:24:14:0,24,360; 1	1047	.	T	<NON_REF>	.	.	END=1047	GT:DP:GQ:MIN_DP:PL	0/0:14:4:14:0,4,418; 1	1048	.	G	<NON_REF>	.	.	END=1141	GT:DP:GQ:MIN_DP:PL	0/0:19:26:12:0,26,411; 1	1142	.	C	T,<NON_REF>	115.64	.	BaseQRankSum=-2.237;DP=19;MQRankSum=-2.312;RAW_GT_COUNT=0,1,0;RAW_MQandDP=43640,19;ReadPosRankSum=0.851	GT:AD:DP:GQ:PGT:PID:PL:PS:SB	0|1:15,4,0:19:99:0|1:1142_C_T:123,0,551,168,563,731:1142:9,6,2,2; 1	1143	.	G	<NON_REF>	.	.	END=1168	GT:DP:GQ:MIN_DP:PL	0/0:17:37:16:0,37,475; 1	1169	.	G	A,<NON_REF>	123.64	.	BaseQRankSum=-1.808;DP=18;MQRankSum=-1.313;RAW_GT_COUNT=0,1,0;RAW_MQandDP=30190,18;ReadPosRankSum=1.331	GT:AD:DP:GQ:PGT:PID:PL:PS:SB	0|1:14,4,0:18:99:0|1:1142_C_T:131,0,455,168,46",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1221558244:2069,simpl,simply,2069,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1221558244,1,['simpl'],['simply']
Usability,".01%`.; > The diff coverage is `n/a`. [![Impacted file tree graph](https://codecov.io/gh/broadinstitute/gatk/pull/5565/graphs/tree.svg?width=650&token=7RuX7LsQVf&height=150&src=pr)](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=tree). ```diff; @@ Coverage Diff @@; ## master #5565 +/- ##; ============================================; - Coverage 87.09% 87.08% -0.01% ; + Complexity 31524 31522 -2 ; ============================================; Files 1930 1930 ; Lines 145231 145231 ; Branches 16095 16095 ; ============================================; - Hits 126482 126479 -3 ; - Misses 12900 12901 +1 ; - Partials 5849 5851 +2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5565/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.77% <0%> (-0.95%)` | `33% <0%> (-1%)` | |; | [...lotypecaller/readthreading/ReadThreadingGraph.java](https://codecov.io/gh/broadinstitute/gatk/pull/5565/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9yZWFkdGhyZWFkaW5nL1JlYWRUaHJlYWRpbmdHcmFwaC5qYXZh) | `88.6% <0%> (-0.26%)` | `144% <0%> (-1%)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=footer). Last update [f9a2e5c...18a9e40](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5565#issuecomment-452841810:1911,learn,learn,1911,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5565#issuecomment-452841810,1,['learn'],['learn']
Usability,".267% <0%> (-1.635%)` | `36% <0%> (+4%)` | |; | [...notyper/GenotypeCalculationArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...5a67eb67b78c6fe2a8ccab54b4b257099fa1b3a5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwZUNhbGN1bGF0aW9uQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `100% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...5a67eb67b78c6fe2a8ccab54b4b257099fa1b3a5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `86.911% <0%> (+0.244%)` | `83% <0%> (+38%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...5a67eb67b78c6fe2a8ccab54b4b257099fa1b3a5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `75.385% <0%> (+1.774%)` | `49% <0%> (+13%)` | :arrow_up: |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/2452?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2452?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2452?src=pr&el=footer). Last update [dfa9cf1...5a67eb6](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...5a67eb67b78c6fe2a8ccab54b4b257099fa1b3a5?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2452#issuecomment-285786533:4276,learn,learn,4276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2452#issuecomment-285786533,1,['learn'],['learn']
Usability,"/FindBreakpointEvidenceSpark.java; - input coverage-scaled thresholds, convert to absolute internally. Allow thresholds to be double instead of int; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointDensityFilter.java; - getter functions added to calculate properties for XGBoostEvidenceFilter. Also fromStringRep() and helper constructors added for testing; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointEvidence.java; - updates to tests reflecting changes to these interfaces; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointDensityFilterTest.java; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/FindBreakpointEvidenceSparkUnitTest.java; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/integration/FindBreakpointEvidenceSparkIntegrationTest.java; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/integration/SVIntegrationTestDataProvider.java. 4. Added code; - factory to call appropriate BreakpointEvidence filter; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointFilterFactory.java; - simple helper class to hold feature vectors for classifier; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/EvidenceFeatures.java; - implement classifier-based BreakpointEvidence filter; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/XGBoostEvidenceFilter.java; - unit test for classifier filter; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/XGBoostEvidenceFilterUnitTest.java. 5. Added resources; - Genome tracts; src/main/resources/large/hg38_centromeres.txt.gz; src/main/resources/large/hg38_gaps.txt.gz; src/main/resources/large/hg38_umap_s100.txt.gz; - Classifier binary file; src/main/resources/large/sv_evidence_classifier.bin; - Data used for validation of performance in unit tests; src/test/resources/sv_classifier_test_data.json; src/test/resources/sv_features_test_data.json",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-389218477:2364,simpl,simple,2364,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-389218477,1,['simpl'],['simple']
Usability,"01413230/document This method uses a low-rank approximation to the kernel to obtain an approximate segmentation in linear complexity in time and space. In practice, performance is actually quite impressive!. The implementation is relatively straightforward, clocking in at ~100 lines of python. Time complexity is O(log(maximum number of segments) * number of data points) and space complexity is O(number of data points * dimension of the kernel approximation), which makes use for WGS feasible. Segmentation of 10^6 simulated points with 100 segments takes about a minute and tends to recover segments accurately. Compare this with CBS, where segmentation of a WGS sample with ~700k points takes ~10 minutes---and note that these ~700k points are split up amongst ~20 chromosomes to start!. There are a small number of parameters that can affect the segmentation, but we can probably find good defaults in practice. What's also nice is that this method can find changepoints in moments of the distribution other than the mean, which means that it can straightforwardly be used for alternate-allele fraction segmentation. For example, all segments were recovered in the following simulated multimodal data, even though all of the segments have zero mean:. ![baf](https://user-images.githubusercontent.com/11076296/29100464-ad687946-7c79-11e7-99e4-962ab93709b4.png). Replacing the SNP segmentation in ACNV (which performs expensive maximum-likelihood estimation of the allele-fraction model) with this method would give a significant speedup there. Joint segmentation is straightforward and is simply given by addition of the kernels. However, complete data is still required. Given such a fast heuristic, I'm more amenable to augmenting this method with additional heuristics to clean up or improve the segmentation if necessary. We can also use it to initialize our more sophisticated HMM models, as well. @LeeTL1220 @mbabadi @davidbenjamin I'd be interested to hear your thoughts, if you have any.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-321121666:1703,simpl,simply,1703,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-321121666,1,['simpl'],['simply']
Usability,"03%`.; > The diff coverage is `63.636%`. ```diff; @@ Coverage Diff @@; ## master #2491 +/- ##; ===============================================; + Coverage 76.274% 76.277% +0.003% ; Complexity 10867 10867 ; ===============================================; Files 750 750 ; Lines 39560 39560 ; Branches 6915 6916 +1 ; ===============================================; + Hits 30174 30175 +1 ; + Misses 6767 6765 -2 ; - Partials 2619 2620 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2491?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ellbender/tools/walkers/annotator/RankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...76fde41e8aa0dab8fcdd10c875f7b62d9faddd21?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9SYW5rU3VtVGVzdC5qYXZh) | `77.778% <63.636%> (-2.778%)` | `13 <0> (ø)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...76fde41e8aa0dab8fcdd10c875f7b62d9faddd21?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2491?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2491?src=pr&el=footer). Last update [e1e71d7...76fde41](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...76fde41e8aa0dab8fcdd10c875f7b62d9faddd21?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2491#issuecomment-287865370:1821,learn,learn,1821,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2491#issuecomment-287865370,1,['learn'],['learn']
Usability,0739000 109323.8; 19:37:15.543 INFO ProgressMeter - GL000224.1:65537 281.3 30758000 109324.9; 19:37:25.847 INFO ProgressMeter - GL000248.1:21736 281.5 30768000 109293.8; 19:37:25.906 INFO FilterMutectCalls - Finished pass 0 through the variants; 19:50:04.590 INFO FilterMutectCalls - Shutting down engine; [9 January 2020 7:50:04 PM] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 294.19 minutes.; Runtime.totalMemory()=14966849536; java.lang.IllegalArgumentException: Values in probability array sum to a negative number NaN; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:731); 	at org.broadinstitute.hellbender.utils.MathUtils.normalizeSumToOne(MathUtils.java:731); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.performEMIteration(SomaticClusteringModel.java:336); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:306); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:158); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:159); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:44); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitute.hellbender.Main.main(Main,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6202#issuecomment-572799341:4618,learn,learnAndClearAccumulatedData,4618,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6202#issuecomment-572799341,1,['learn'],['learnAndClearAccumulatedData']
Usability,"1. @nalinigans It's a very reasonable question. It's true, the --avoid-nio flag is technically redundant. You can recreate it with a combination of other flags. I added it because ; a) I didn't realize that was the when I started adding it. ; b) The combination of flags was kind of complicated so it was helpful to have something that gave you clear instructions about what you needed to enable. I think we could merge them, although I think there is one sanity check we do even when -bypass-feature-reader is turned on, that we need to turn off. I basically added ""something that works for Megan's project right now."" . 2. Yes, the various cases were getting complicated and I had a bug when -V was enabled so I just disabled it as an option. It would make sense to add -V support for azure files. I just didn't do it because I was in a rush and I figured it was better to disable it than to have it potentially be wrong. . 3. Yeah, that's the error I saw. It's definitely better than nothing. It would be great if it could be propagated back up to the java layer as a Java exception though. It currently ends the program with SIGABORT I think which doesn't play that nicely with various reporting and retry mechanisms. No super high priority, but nice if you have the cycles.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8632#issuecomment-1865021020:345,clear,clear,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8632#issuecomment-1865021020,1,['clear'],['clear']
Usability,"1. For spark - cloud dataproc works well; 2. For non-spark, the simplest setup seems to create a master-only dataproc cluster because it comes with a bunch of software already pre-installed. . Maybe that's all we need.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1610#issuecomment-211932533:64,simpl,simplest,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1610#issuecomment-211932533,1,['simpl'],['simplest']
Usability,"22:45:33 INFO YarnScheduler:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool; 2019-06-03 22:45:33 INFO DAGScheduler:54 - Job 0 finished: runJob at SparkHadoopWriter.scala:78, took 302.340057 s; 2019-06-03 22:45:35 INFO SparkHadoopWriter:54 - Job job_20190603224030_0014 committed.; 2019-06-03 22:45:35 INFO AbstractConnector:318 - Stopped Spark@6be766d1{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 2019-06-03 22:45:35 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4040; 2019-06-03 22:45:35 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-06-03 22:45:35 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-06-03 22:45:35 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-06-03 22:45:35 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-06-03 22:45:35 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-06-03 22:45:35 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-06-03 22:45:35 INFO MemoryStore:54 - MemoryStore cleared; 2019-06-03 22:45:35 INFO BlockManager:54 - BlockManager stopped; 2019-06-03 22:45:35 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-06-03 22:45:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-06-03 22:45:35 INFO SparkContext:54 - Successfully stopped SparkContext; 22:45:35.933 INFO PrintReadsSpark - Shutting down engine; [June 3, 2019 10:45:35 PM EDT] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 5.79 minutes.; Runtime.totalMemory()=4147118080; 2019-06-03 22:45:35 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-06-03 22:45:35 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-423d02dc-cbc1-4c83-907d-ca315ca231bc; 2019-06-03 22:45:35 INFO ShutdownHookMa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370:8913,clear,cleared,8913,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370,1,['clear'],['cleared']
Usability,"23:00:06 INFO YarnScheduler:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool; 2019-06-03 23:00:06 INFO DAGScheduler:54 - Job 0 finished: runJob at SparkHadoopWriter.scala:78, took 375.304795 s; 2019-06-03 23:00:08 INFO SparkHadoopWriter:54 - Job job_20190603225351_0015 committed.; 2019-06-03 23:00:09 INFO AbstractConnector:318 - Stopped Spark@6be766d1{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 2019-06-03 23:00:09 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4040; 2019-06-03 23:00:09 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-06-03 23:00:09 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-06-03 23:00:09 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-06-03 23:00:09 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-06-03 23:00:09 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-06-03 23:00:09 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-06-03 23:00:09 INFO MemoryStore:54 - MemoryStore cleared; 2019-06-03 23:00:09 INFO BlockManager:54 - BlockManager stopped; 2019-06-03 23:00:09 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-06-03 23:00:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-06-03 23:00:09 INFO SparkContext:54 - Successfully stopped SparkContext; 23:00:09.356 INFO PrintReadsSpark - Shutting down engine; [June 3, 2019 11:00:09 PM EDT] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 7.01 minutes.; Runtime.totalMemory()=4327997440; 2019-06-03 23:00:09 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-06-03 23:00:09 INFO ShutdownHookManager:54 - Deleting directory /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/tmp/spark-73067845-b641-4212-9c81-51e8d6aa9f31; 2019-06-03 23:00:09 INFO ShutdownHookMa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370:15699,clear,cleared,15699,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-498502370,1,['clear'],['cleared']
Usability,"29978 29989 +11 ; + Misses 6802 6791 -11 ; Partials 2592 2592; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2396?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...efe544dd515af5f5f25f6c73e8d54726fceca914?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `87.2% <ø> (ø)` | `37 <ø> (ø)` | :x: |; | [...institute/hellbender/engine/FeatureDataSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...efe544dd515af5f5f25f6c73e8d54726fceca914?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZURhdGFTb3VyY2UuamF2YQ==) | `77.477% <ø> (+0.901%)` | `38% <ø> (+1%)` | :white_check_mark: |; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...efe544dd515af5f5f25f6c73e8d54726fceca914?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `79.747% <ø> (+6.329%)` | `22% <ø> (+4%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2396?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2396?src=pr&el=footer). Last update [3c10554...efe544d](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...efe544dd515af5f5f25f6c73e8d54726fceca914?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2396#issuecomment-278174747:2155,learn,learn,2155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2396#issuecomment-278174747,1,['learn'],['learn']
Usability,"32...a28ecfd6f409451b9ecf1b8ca6da1e803462c50e?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `64.286% <85.714%> (-7.666%)` | `28 <12> (+1)` | |; | [...roadinstitute/hellbender/utils/SimpleInterval.java](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...a28ecfd6f409451b9ecf1b8ca6da1e803462c50e?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9TaW1wbGVJbnRlcnZhbC5qYXZh) | `94.048% <ø> (-1.19%)` | `46% <ø> (-1%)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...a28ecfd6f409451b9ecf1b8ca6da1e803462c50e?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <ø> (+1.429%)` | `24% <ø> (+1%)` | :white_check_mark: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...a28ecfd6f409451b9ecf1b8ca6da1e803462c50e?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <ø> (+3.333%)` | `10% <ø> (ø)` | :x: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2350?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2350?src=pr&el=footer). Last update [fcd103c...a28ecfd](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...a28ecfd6f409451b9ecf1b8ca6da1e803462c50e?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2350#issuecomment-274847005:2925,learn,learn,2925,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2350#issuecomment-274847005,1,['learn'],['learn']
Usability,"3592?src=pr&el=tree). ```diff; @@ Coverage Diff @@; ## master #3592 +/- ##; ============================================; - Coverage 79.73% 79.73% -0.01% ; - Complexity 18148 18149 +1 ; ============================================; Files 1217 1217 ; Lines 66602 66602 ; Branches 10429 10429 ; ============================================; - Hits 53106 53104 -2 ; - Misses 9289 9292 +3 ; + Partials 4207 4206 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...stitute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `91% <100%> (ø)` | `30 <0> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `76.62% <0%> (-1.95%)` | `39% <0%> (ø)` | |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `88.88% <0%> (+0.46%)` | `52% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=footer). Last update [58108d0...c374339](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330691059:2141,learn,learn,2141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330691059,1,['learn'],['learn']
Usability,"3Rpb24uamF2YQ==) | `100% <0%> (ø)` | `4% <0%> (+2%)` | :arrow_up: |; | [...efaultGATKVariantAnnotationArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vRGVmYXVsdEdBVEtWYXJpYW50QW5ub3RhdGlvbkFyZ3VtZW50Q29sbGVjdGlvbi5qYXZh) | `100% <0%> (ø)` | `11% <0%> (+6%)` | :arrow_up: |; | [...titute/hellbender/tools/walkers/GenotypeGVCFs.java](https://codecov.io/gh/broadinstitute/gatk/pull/4844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0dlbm90eXBlR1ZDRnMuamF2YQ==) | `90.55% <0%> (+0.46%)` | `50% <0%> (+3%)` | :arrow_up: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `90.47% <0%> (+0.68%)` | `25% <0%> (+11%)` | :arrow_up: |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `84.17% <0%> (+1.01%)` | `40% <0%> (+15%)` | :arrow_up: |; | ... and [10 more](https://codecov.io/gh/broadinstitute/gatk/pull/4844/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4844?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4844?src=pr&el=footer). Last update [7628cc9...fc61689](https://codecov.io/gh/broadinstitute/gatk/pull/4844?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4844#issuecomment-393939720:4463,learn,learn,4463,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4844#issuecomment-393939720,1,['learn'],['learn']
Usability,"4); at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeFromLogToLinearSpace(NaturalLogUtils.java:27); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:93); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:140); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSomaticVariant(SomaticClusteringModel.java:146); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.performEMIteration(SomaticClusteringModel.java:345); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:330); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:153); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:165); at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:44); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1095); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```; Updating the stats file to a non 1.0, 1.1 value allows the filtering to proceed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7276#issuecomment-1293969047:2060,learn,learnParameters,2060,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7276#issuecomment-1293969047,1,['learn'],['learnParameters']
Usability,"588a4?src=pr&el=desc) will **increase** coverage by `-0.015%`. ```diff; @@ Coverage Diff @@; ## master #2392 +/- ##; ===============================================; - Coverage 76.157% 76.141% -0.015% ; + Complexity 10823 10820 -3 ; ===============================================; Files 748 748 ; Lines 39361 39361 ; Branches 6855 6855 ; ===============================================; - Hits 29976 29970 -6 ; - Misses 6798 6801 +3 ; - Partials 2587 2590 +3; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2392?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/compare/99e0b84c600d27cbe0a3016de0fe969f69b588a4...aeeaff8b188fb8b5f487a54ab615b0cbc3d0118d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `74.839% <ø> (-3.226%)` | `18% <ø> (-2%)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/99e0b84c600d27cbe0a3016de0fe969f69b588a4...aeeaff8b188fb8b5f487a54ab615b0cbc3d0118d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `90% <ø> (-1.429%)` | `23% <ø> (-1%)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2392?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2392?src=pr&el=footer). Last update [99e0b84...aeeaff8](https://codecov.io/gh/broadinstitute/gatk/compare/99e0b84c600d27cbe0a3016de0fe969f69b588a4...aeeaff8b188fb8b5f487a54ab615b0cbc3d0118d?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2392#issuecomment-277394788:1765,learn,learn,1765,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2392#issuecomment-277394788,1,['learn'],['learn']
Usability,"5qYXZh) | `73.68% <77.14%> (-1.32%)` | `41 <17> (+1)` | |; | [...ools/walkers/validation/InfoConcordanceRecord.java](https://codecov.io/gh/broadinstitute/gatk/pull/5175/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vSW5mb0NvbmNvcmRhbmNlUmVjb3JkLmphdmE=) | `93.93% <93.93%> (ø)` | `8 <8> (?)` | |; | [...n/EvaluateInfoFieldConcordanceIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5175/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vRXZhbHVhdGVJbmZvRmllbGRDb25jb3JkYW5jZUludGVncmF0aW9uVGVzdC5qYXZh) | `96% <96%> (ø)` | `3 <3> (?)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5175/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5175/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | ... and [2 more](https://codecov.io/gh/broadinstitute/gatk/pull/5175/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5175?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5175?src=pr&el=footer). Last update [ce669d1...65d0edd](https://codecov.io/gh/broadinstitute/gatk/pull/5175?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5175#issuecomment-423756354:4201,learn,learn,4201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5175#issuecomment-423756354,1,['learn'],['learn']
Usability,"77 +/- ##; ============================================; + Coverage 79.07% 79.08% +<.01% ; - Complexity 16594 16595 +1 ; ============================================; Files 1050 1050 ; Lines 59969 59969 ; Branches 9831 9831 ; ============================================; + Hits 47419 47424 +5 ; + Misses 8741 8738 -3 ; + Partials 3809 3807 -2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4377?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4377/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0FsaWdubWVudEludGVydmFsLmphdmE=) | `89.65% <0%> (+0.76%)` | `72% <0%> (+1%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4377/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+1.29%)` | `39% <0%> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4377/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+10%)` | `3% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4377?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4377?src=pr&el=footer). Last update [1221e03...403ff93](https://codecov.io/gh/broadinstitute/gatk/pull/4377?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4377#issuecomment-364188060:2205,learn,learn,2205,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4377#issuecomment-364188060,1,['learn'],['learn']
Usability,"85 13181 -4 ; - Partials 5915 5916 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5826?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...nder/engine/filters/ReadFilterLibraryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5826/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9SZWFkRmlsdGVyTGlicmFyeVVuaXRUZXN0LmphdmE=) | `100% <100%> (ø)` | `59 <1> (+1)` | :arrow_up: |; | [...e/hellbender/engine/filters/ReadFilterLibrary.java](https://codecov.io/gh/broadinstitute/gatk/pull/5826/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9SZWFkRmlsdGVyTGlicmFyeS5qYXZh) | `94.56% <66.66%> (-0.95%)` | `1 <0> (ø)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5826/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+10%)` | `3% <0%> (ø)` | :arrow_down: |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5826/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `90% <0%> (+30%)` | `2% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5826?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5826?src=pr&el=footer). Last update [fb2b5a2...e5bcca0](https://codecov.io/gh/broadinstitute/gatk/pull/5826?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5826#issuecomment-475632849:2529,learn,learn,2529,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5826#issuecomment-475632849,1,['learn'],['learn']
Usability,8; 19:37:15.543 INFO ProgressMeter - GL000224.1:65537 281.3 30758000 109324.9; 19:37:25.847 INFO ProgressMeter - GL000248.1:21736 281.5 30768000 109293.8; 19:37:25.906 INFO FilterMutectCalls - Finished pass 0 through the variants; 19:50:04.590 INFO FilterMutectCalls - Shutting down engine; [9 January 2020 7:50:04 PM] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 294.19 minutes.; Runtime.totalMemory()=14966849536; java.lang.IllegalArgumentException: Values in probability array sum to a negative number NaN; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:731); 	at org.broadinstitute.hellbender.utils.MathUtils.normalizeSumToOne(MathUtils.java:731); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.performEMIteration(SomaticClusteringModel.java:336); 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:306); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:158); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:159); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:44); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitute.hellbender.Main.main(Main.java:292); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6202#issuecomment-572799341:4769,learn,learnParameters,4769,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6202#issuecomment-572799341,1,['learn'],['learnParameters']
Usability,:+1: Much clearer now I think. Squash and merge.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1621#issuecomment-201330553:10,clear,clearer,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1621#issuecomment-201330553,1,['clear'],['clearer']
Usability,":54 - Removed TaskSet 13.0, whose tasks have all completed, from pool; 2019-05-19 19:09:41 INFO DAGScheduler:54 - ResultStage 13 (foreach at BwaMemIndexCache.java:84) finished in 2.117 s; 2019-05-19 19:09:41 INFO DAGScheduler:54 - Job 9 finished: foreach at BwaMemIndexCache.java:84, took 2.128154 s; 2019-05-19 19:09:41 INFO AbstractConnector:318 - Stopped Spark@42576db9{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 2019-05-19 19:09:41 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4040; 2019-05-19 19:09:41 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-05-19 19:09:41 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-05-19 19:09:41 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-05-19 19:09:41 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-05-19 19:09:41 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-05-19 19:09:41 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-05-19 19:09:41 INFO MemoryStore:54 - MemoryStore cleared; 2019-05-19 19:09:41 INFO BlockManager:54 - BlockManager stopped; 2019-05-19 19:09:41 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-05-19 19:09:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-05-19 19:09:41 INFO SparkContext:54 - Successfully stopped SparkContext; 19:09:41.578 INFO StructuralVariationDiscoveryPipelineSpark - Shutting down engine; [May 19, 2019 7:09:41 PM EDT] org.broadinstitute.hellbender.tools.spark.sv.StructuralVariationDiscoveryPipelineSpark done. Elapsed time: 44.89 minutes.; Runtime.totalMemory()=21646802944; htsjdk.samtools.util.RuntimeIOException: Error opening file: file:///restricted/projectnb/casa/wgs.hg38/pipelines/sv/gatk.sv/temp/A-ACT-AC000014-BL-NCR-15AD78694.hg38.realign.bqsr.contig-sam-file.sam; at htsjdk.samtools.SAMFileWr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-494014590:4121,clear,cleared,4121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-494014590,1,['clear'],['cleared']
Usability,"=====; + Hits 30163 30192 +29 ; Misses 6772 6772 ; - Partials 2618 2619 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2524?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/compare/78f4f61435bef501879e9a4cccb9a978fd484a6b...fc03f04a1347287d8121f018019fc422322b9f2c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `66.667% <0%> (-1.102%)` | `4 <0> (ø)` | |; | [...der/tools/walkers/annotator/RMSMappingQuality.java](https://codecov.io/gh/broadinstitute/gatk/compare/78f4f61435bef501879e9a4cccb9a978fd484a6b...fc03f04a1347287d8121f018019fc422322b9f2c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9STVNNYXBwaW5nUXVhbGl0eS5qYXZh) | `98% <96.552%> (-2%)` | `23 <9> (+9)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/78f4f61435bef501879e9a4cccb9a978fd484a6b...fc03f04a1347287d8121f018019fc422322b9f2c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2524?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2524?src=pr&el=footer). Last update [78f4f61...fc03f04](https://codecov.io/gh/broadinstitute/gatk/compare/78f4f61435bef501879e9a4cccb9a978fd484a6b...fc03f04a1347287d8121f018019fc422322b9f2c?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2524#issuecomment-288804022:2183,learn,learn,2183,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2524#issuecomment-288804022,1,['learn'],['learn']
Usability,"==========; + Hits 120162 120170 +8 ; + Misses 12760 12758 -2 ; Partials 5551 5551; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5290?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/5290/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `82.19% <100%> (+0.37%)` | `68 <0> (ø)` | :arrow_down: |; | [...ls/spark/BaseRecalibratorSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5290/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `40.54% <100%> (+1.09%)` | `5 <0> (ø)` | :arrow_down: |; | [...va/org/broadinstitute/hellbender/GATKBaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5290/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9HQVRLQmFzZVRlc3QuamF2YQ==) | `100% <100%> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5290/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `73.97% <0%> (+2.73%)` | `11% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5290?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5290?src=pr&el=footer). Last update [158f7f7...2cb7fd4](https://codecov.io/gh/broadinstitute/gatk/pull/5290?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5290#issuecomment-427852825:2471,learn,learn,2471,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5290#issuecomment-427852825,1,['learn'],['learn']
Usability,"====================; + Hits 30189 30196 +7 ; - Misses 6774 6802 +28 ; - Partials 2621 2626 +5; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2527?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2527?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `58.479% <0%> (ø)` | `28 <0> (ø)` | :arrow_down: |; | [...tute/hellbender/tools/spark/sv/ReadClassifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/2527?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkQ2xhc3NpZmllci5qYXZh) | `82.813% <100%> (ø)` | `30 <0> (ø)` | :arrow_down: |; | [.../hellbender/tools/spark/sv/BreakpointEvidence.java](https://codecov.io/gh/broadinstitute/gatk/pull/2527?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9CcmVha3BvaW50RXZpZGVuY2UuamF2YQ==) | `83.756% <100%> (ø)` | `24 <0> (ø)` | :arrow_down: |; | [...titute/hellbender/tools/spark/sv/ReadMetadata.java](https://codecov.io/gh/broadinstitute/gatk/pull/2527?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkTWV0YWRhdGEuamF2YQ==) | `77.778% <38.462%> (-10.91%)` | `25 <5> (+3)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2527?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2527?src=pr&el=footer). Last update [47d8c52...f2df0f7](https://codecov.io/gh/broadinstitute/gatk/pull/2527?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2527#issuecomment-288844391:2265,learn,learn,2265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2527#issuecomment-288844391,1,['learn'],['learn']
Usability,"==========================; + Hits 30054 30059 +5 ; - Misses 6754 6759 +5 ; - Partials 2617 2618 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2440?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...oadinstitute/hellbender/utils/tsv/TableReader.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...f53692e637725d29f957ffdec11a96d8caeb74f5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvVGFibGVSZWFkZXIuamF2YQ==) | `75% <71.429%> (-1.543%)` | `35 <3> (+2)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...f53692e637725d29f957ffdec11a96d8caeb74f5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `73.611% <0%> (-2.083%)` | `36% <0%> (ø)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...f53692e637725d29f957ffdec11a96d8caeb74f5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2440?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2440?src=pr&el=footer). Last update [92cb860...f53692e](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...f53692e637725d29f957ffdec11a96d8caeb74f5?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2440#issuecomment-284888102:2167,learn,learn,2167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2440#issuecomment-284888102,1,['learn'],['learn']
Usability,"==============================; + Hits 30163 30164 +1 ; + Misses 6772 6770 -2 ; - Partials 2618 2619 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2526?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...tute/hellbender/tools/BwaMemIndexImageCreator.java](https://codecov.io/gh/broadinstitute/gatk/compare/78f4f61435bef501879e9a4cccb9a978fd484a6b...c122c345d26c17d97c759c81b4fcf825dfaecb9e?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Cd2FNZW1JbmRleEltYWdlQ3JlYXRvci5qYXZh) | `71.429% <ø> (ø)` | `2 <0> (?)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/78f4f61435bef501879e9a4cccb9a978fd484a6b...c122c345d26c17d97c759c81b4fcf825dfaecb9e?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `90% <0%> (-1.429%)` | `23% <0%> (-1%)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/78f4f61435bef501879e9a4cccb9a978fd484a6b...c122c345d26c17d97c759c81b4fcf825dfaecb9e?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2526?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2526?src=pr&el=footer). Last update [78f4f61...c122c34](https://codecov.io/gh/broadinstitute/gatk/compare/78f4f61435bef501879e9a4cccb9a978fd484a6b...c122c345d26c17d97c759c81b4fcf825dfaecb9e?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2526#issuecomment-288832482:2147,learn,learn,2147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2526#issuecomment-288832482,1,['learn'],['learn']
Usability,"> (+2%)` | :white_check_mark: |; | [...tools/walkers/genotyper/AlleleSubsettingUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...09a6f249352cd17f9214fccb5a4b3ac2c31f2cce?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9BbGxlbGVTdWJzZXR0aW5nVXRpbHMuamF2YQ==) | `87.037% <ø> (+0.926%)` | `40% <ø> (+1%)` | :white_check_mark: |; | [...ark/pipelines/metrics/MeanQualityByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...09a6f249352cd17f9214fccb5a4b3ac2c31f2cce?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9NZWFuUXVhbGl0eUJ5Q3ljbGVTcGFyay5qYXZh) | `91.667% <ø> (+1.042%)` | `10% <ø> (ø)` | :x: |; | [...ute/hellbender/utils/test/IntegrationTestSpec.java](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...09a6f249352cd17f9214fccb5a4b3ac2c31f2cce?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0ludGVncmF0aW9uVGVzdFNwZWMuamF2YQ==) | `74.194% <ø> (+1.075%)` | `26% <ø> (+1%)` | :white_check_mark: |; | ... and [3 more](https://codecov.io/gh/broadinstitute/gatk/pull/2404/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2404?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2404?src=pr&el=footer). Last update [30365e7...09a6f24](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...09a6f249352cd17f9214fccb5a4b3ac2c31f2cce?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2404#issuecomment-279082842:4986,learn,learn,4986,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2404#issuecomment-279082842,1,['learn'],['learn']
Usability,"> . @lbergelson Yes the error was from a previous version as I didn't have the new error recorded. I ran it again and here is the code and error. Just for clarity, I simplified the code paste here, removed long paths and stuff but some of those are shown in the error. Thanks!. `java -jar /home/apps/software/picard/2.27.5-Java-1.8.0_201/picard.jar CollectInsertSizeMetrics \; I=HG03125.final.cram \; O=insertSize_metrics.txt \; H=insertSize_hist.pdf \; R=GRCh38_full_analysis_set_plus_decoy_hla.fa \; M=0.5`. `[Thu Feb 02 13:05:04 CST 2023] picard.analysis.CollectInsertSizeMetrics HISTOGRAM_FILE=results/bowtie2/assembly/Read-Prep/Bowtie/Aligned/stats/HG03125_insertSize_hist.pdf MINIMUM_PCT=0.5 INPUT=./crams/AFR/HG03125.final.cram OUTPUT=results/bowtie2/assembly/Read-Prep/Bowtie/Aligned/stats/HG03125_insertSize_metrics.txt REFERENCE_SEQUENCE=/home/groups/h3abionet/RefGraph/data/genomes/human/GRCh38/GRCh38_full_analysis_set_plus_decoy_hla.fa DEVIATIONS=10.0 METRIC_ACCUMULATION_LEVEL=[ALL_READS] INCLUDE_DUPLICATES=false ASSUME_SORTED=true STOP_AFTER=0 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json; [Thu Feb 02 13:05:04 CST 2023] Executing as valizad2@compute-5-1 on Linux 4.18.0-348.23.1.el8_5.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_201-b09; Picard version: 2.9.0-1-gf5b9f50-SNAPSHOT; INFO	2023-02-02 13:05:15	SinglePassSamProgram	Processed 1,000,000 records. Elapsed time: 00:00:11s. Time for last 1,000,000: 6s. Last read position: chr1:3,185,445; INFO	2023-02-02 13:05:20	SinglePassSamProgram	Processed 2,000,000 records. Elapsed time: 00:00:16s. Time for last 1,000,000: 5s. Last read position: chr1:6,814,058; INFO	2023-02-02 13:05:25	SinglePassSamProgram	Processed 3,000,000 records. Elapsed time: 00:00:21s. Time for last 1,000,000: 4s. Last read position: chr1:10,463,599; INFO	2023-02-02 13:05:30	SinglePassSamProgram	Processed 4,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414237417:166,simpl,simplified,166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414237417,1,['simpl'],['simplified']
Usability,"> @dror27 - can you remind me what we decided to do with this fix? I kind of remember that we decided to not change the definition... But I may be confused. @ilyasoifer I believe that this has to ""simply"" be merged.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8442#issuecomment-1803378571:197,simpl,simply,197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8442#issuecomment-1803378571,1,['simpl'],['simply']
Usability,"> @ilyasoifer do you have the means to quickly run minimap2? I would recommend simply realigning src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam with minimap2 and making a quick ""are tests consistent with pervious versions"" test with a checked in vcf output. I don't know how to wrangle minimap2 to handle mates correctly however so i don't know if this is easy. Added test like this",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8337#issuecomment-1560517319:79,simpl,simply,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8337#issuecomment-1560517319,1,['simpl'],['simply']
Usability,"> @nalinigans For AD, I don't think we care about the distinction between '.' and 0. If AD is the only problematic field, and we're not seeing any issues with PL or any other attribute, then I'd advocate for a simple '.' -> 0 translation (for AD only!) within GenomicsDB, if such a thing is possible. @ldgauthier do you agree?. Missing values will appear in all fields whose lengths are of type A, R or G (so PL field also). I'm assuming that missing values in allele specific annotation fields are handled gracefullyby GATK.; As you likely gathered from the previous comments, the primary issue is that for multi-allelic sites a given sample may have only one allele - so, the PL, AD values corresponding to the ""missing"" alleles for that sample are missing (no <NON_REF> alleles exist). I think I followed the convention that [bcftools merge used](https://github.com/samtools/hts-specs/issues/232#issuecomment-322108548).; We may be able to replace missing values with 'quiet' values (such as 0) - but need some guidance on what makes sense.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6744#issuecomment-676549083:210,simpl,simple,210,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6744#issuecomment-676549083,2,"['guid', 'simpl']","['guidance', 'simple']"
Usability,"> Any guidance on pushing the variant's gatk docker?. Nope! That has not changed, not sure it will either since we're basically piggybacking on the GATK team's work for that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8791#issuecomment-2073173237:6,guid,guidance,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8791#issuecomment-2073173237,1,['guid'],['guidance']
Usability,"> At the very least we should add a unit test that generates the evidenceIndexBySampleIndex cache, then calls marginalize() (both types) and asserts that we have emptied the cache. I would do the same for appendEvidence() and addMissingAlleles(). It's simpler than this because allele operations such as `marginalize()` and `addMissingAlleles` don't modify the evidence list. While they require care with the likelihoods arrays they don't require anything at all from the evidence-to-index caches. As I mentioned above, I left the cache updating in `appendEvidence` as it was because it was so simple. I will try to write the test for removing evidence tomorrow. Tempting to try tonight, but I'm trying to accept the reality that working until 2 am is a bad idea.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6593#issuecomment-633180869:252,simpl,simpler,252,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6593#issuecomment-633180869,2,['simpl'],"['simple', 'simpler']"
Usability,"> First off, SOAPsnp has the same equations we do, lacking the 2x factor on het genotypes: http://genome.cshlp.org/content/19/6/1124.full#sec-14. True, but because they consider only calling of single-sample diploid SNPs they can absorb the combinatorial factor in their very simple prior. I'm not saying they _do_ this (they don't really justify their priors), but I'm saying that in principle they could. And for all I know maybe we do the same in the exact model. In the new AF model, however, the most natural place for this factor is in the genotype likelihoods, not in the prior.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2019#issuecomment-234558814:276,simpl,simple,276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2019#issuecomment-234558814,1,['simpl'],['simple']
Usability,"> Have since learned external tools can separate out mixed-type records into biallelic records. Hi, I am also facing the same issue, would you mind to share what type of external tools you used for the separation?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1537#issuecomment-583977235:13,learn,learned,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1537#issuecomment-583977235,1,['learn'],['learned']
Usability,"> Hi Kevin, our team would like to get this merged into `ah_var_store` soon per VS-1254. I'm aware of only a handful of outstanding issues:; > ; > * The failing PGEN tests. I'm happy to help here in any way I can though right now I don't have a sense of what could be causing this beyond the platform differences you suggested.; > ; > * The `10` vs `10.0` change we discussed recently to avoid division by zero.; > ; > * We'll want to merge / rebase from `ah_var_store` and then build a new GATK Docker image which would be entered into `GetToolVersions` in `GvsUtils.wdl`. I'm happy to take on building this image once the merge / rebase is ready. Hi Miguel, sorry about the delay. I'm working on the failing tests issue this afternoon. I know what the issue is, so I just have to implement a fix, which I think should be fairly simple. Once I have that ready and have confirmed the tests aren't failing anymore, I'll do the rebase and then let you know.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8708#issuecomment-2004517723:830,simpl,simple,830,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8708#issuecomment-2004517723,1,['simpl'],['simple']
Usability,"> How can F be a probability when it takes on negative values?. It's the probability of alleles being IBD *provided that inbreeding is the only source of deviation from HWE* and in the limit of infinite sample size washing out statistical noise. Under these assumptions it's always positive. How about I rewrite the docs to be much, much clearer about this?. > Also, I've never heard of it being called the Fixation Score. I hadn't heard of it, either, but Wikipedia told me so: https://en.wikipedia.org/wiki/F-statistics",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5768#issuecomment-470249511:338,clear,clearer,338,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5768#issuecomment-470249511,1,['clear'],['clearer']
Usability,"> I've looked through at a high level although I'd prefer not to do a line-by-line code review until you think this is ready to be merged). Here are some comments on your proposed algorithm description:. Answer: thanks for looking! That's what I intended as I'm not sure if the algorithm itself would face strong critics. If that's the case, time spent on coding is not worth it IMO. In fact ideally I'd like to write a design doc or something similar, and only code after the design is agreed on. --------. > I would of course prefer not to have to have a hard filter on length. This would mean we would never call a large inversion even if it exists. . Answer: Totally agree. Now looking back, it get clearer to me that this proposal contains two parts: the filtering part, and the breakpoint linking part, separated into two major classes `InversionBreakendPreFilter` and `LinkedInversionBreakpointsInference`. That being said, it doesn't make much sense to separate them into two PRs because _currently_ the filtering part is designed around the linking part, i.e. it is trying to check which BND's are suitable to the logic implemented in the linking part, and if the logic isn't applicable to an BND, the BND simply slips through without generating any new interpretations. So `InversionBreakendPreFilter` is a filter and a classifier at the same time, it function is really diverting different BND's to be handled by different logics, and it definitely should be improved.; If you buy this argument, I am also fully aware of the code design issue that it is preferable to NOT divert&mdash;gather&mdash;send through different handlers like it currently is for calling variants from the assembly contigs, instead it should be a single stream pass through all the BND's. I'll try to follow the preferred design. > What about some other filters more specifically aimed at the artifacts that cause these false large calls? I think it's a good idea to check annotations -- ie. do the mates lie at two",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4789#issuecomment-406483929:703,clear,clearer,703,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4789#issuecomment-406483929,1,['clear'],['clearer']
Usability,"> If it's in a critical haplotype caller hotspot you might want to actually write a for loop instead of the stream. They're faster. I know, having learned that lesson several times. Given that this is O(# of haplotypes) [each haplotype vs ref] and not O(# of haplotypes^2) [i.e. every haplotype vs every haplotype] or O(# of reads) I'm not expecting it to matter, but I will definitely profile.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5459#issuecomment-442902925:147,learn,learned,147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5459#issuecomment-442902925,1,['learn'],['learned']
Usability,"> Just curious, why no last modified checks? Was it to keep the code simpler?. Mostly because I couldn't readily think of a scenario where I would actually want this to call cache, but I could easily imagine call caching leading to undesired clobbering of previously generated results. We can certainly revisit this decision if it turns out we're using the script in ways where we really would want call caching.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8002#issuecomment-1227739990:69,simpl,simpler,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8002#issuecomment-1227739990,1,['simpl'],['simpler']
Usability,"> Perhaps we want that the author certifies it is in a usable state for its intended use?. It's good that the author certifies it, but we are going to be tearing the tools apart and rebuilding them without necessarily understanding the details of the output. We need to have tests that will tell us if we've broken them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/382#issuecomment-93804346:55,usab,usable,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/382#issuecomment-93804346,1,['usab'],['usable']
Usability,"> Thanks Kevin! I've built the updated GATK Docker so I would change line 76 of `GvsUtils.wdl` to say; > ; > ```; > String gatk_docker = ""us.gcr.io/broad-dsde-methods/broad-gatk-snapshots:varstore_2024_03_19_dfd45f6""; > ```. Okay awesome, I just pushed that change. Am I clear to merge, or is there anything else that needs doing before that?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8708#issuecomment-2007913072:271,clear,clear,271,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8708#issuecomment-2007913072,1,['clear'],['clear']
Usability,"> The four test failures in `ExtractCohortToPgenTest` appear to be real:; > ; > ```; > 2024-03-12T20:53:02.3169070Z Gradle suite > Gradle test > org.broadinstitute.hellbender.tools.gvs.extract.ExtractCohortToPgenTest > testFinalVQSRLitePgenfromRangesAvro �[31mFAILED�[39m�[0K; > 2024-03-12T20:53:02.3171276Z java.lang.AssertionError: expected [-1] but found [13570]�[0K; > 2024-03-12T20:53:02.3172934Z at org.testng.Assert.fail(Assert.java:97); > 2024-03-12T20:53:02.3173927Z at org.testng.Assert.assertEqualsImpl(Assert.java:136); > 2024-03-12T20:53:02.3174922Z at org.testng.Assert.assertEquals(Assert.java:118); > 2024-03-12T20:53:02.3175853Z at org.testng.Assert.assertEquals(Assert.java:729); > 2024-03-12T20:53:02.3176775Z at org.testng.Assert.assertEquals(Assert.java:739); > 2024-03-12T20:53:02.3178703Z at org.broadinstitute.hellbender.tools.gvs.extract.ExtractCohortToPgenTest.testFinalVQSRLitePgenfromRangesAvro(ExtractCohortToPgenTest.java:78); > ```. That's weird, because it looks like it's succeeding in the other test tasks where it's running. The place it's failing is an extremely simple equality assertion of two compressed files, though. I wonder if there's something about operating system differences that can change the compression slightly. I'll see if I can find a better way to do that check",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8708#issuecomment-2000109415:1099,simpl,simple,1099,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8708#issuecomment-2000109415,1,['simpl'],['simple']
Usability,"> This Python scripts could use some docs (and perhaps tests?); it's not clear to me when / how one would use them. yes, that's fair. I modified the doc I created (CREATING_WEIGHTED_BED_FILES_ORIGINAL.md). In truth, ""original"" may be a misnomer. It's the information in the github issue ALONG WITH updated instructions for when to use the new python files. Given the feedback, I further updated the document with a comment at the top saying when they should be run (TL;DR, on a new genome or a new reference... so basically extremely rarely). Given this, I don't think unit test or extensive documentation are needed for them. The files are small, the inputs are few, and the code is commented. We are likely to not need to run them for again for years, so I don't consider extra documentation or testing to be worth the effort at the moment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8507#issuecomment-1717680203:73,clear,clear,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8507#issuecomment-1717680203,2,"['clear', 'feedback']","['clear', 'feedback']"
Usability,"> Two questions:; > ; > `getMaxClusterableStartingPositionWithParams` in `CanonicalSVLinkage` uses the `window` to determine the max clusterable position. Will setting the value to 10MB make everything look clusterable to this method, potentially bogging down the algorithm for large callsets?. `getMaxClusterableStartingPositionWithParams` should be smart enough to use enough both the window and reciprocal overlap to calculate the max position, taking the min of the two if both are required. Effectively we're just disabling the window requirement so the RO will always be used I think. > Is there a reason to keep the keep the old code around if this is the intended way to disable the proximity check (setting the window very large)? Seems like an opportunity to simplify if you don't want to support that special case anymore. I was thinking of doing that, but we're probably also going to start doing some experimenting with new clustering strategies in the near future so I wanted to keep it in just in case. I'll add a comment noting that the AND vs OR functionality is not used anymore.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8962#issuecomment-2343727259:769,simpl,simplify,769,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8962#issuecomment-2343727259,1,['simpl'],['simplify']
Usability,"> [ ""${variants_for_contamination}"" == *.vcf ] does not allow *.vcf.gz files. It should accept either. I'm about to fix this in a PR. > Script calls for a Picard jar. I don't mind specifying this because I like controlling for the Picard version I use. However, users may want to call the Picard version within the GATK jar. I cannot fathom a simple way to allow switching this out in the script, but perhaps something like the gatk_override option could work. The goal would be to call the Picard tool from a Docker. This better enables provenance. The same PR is also going to call Picard from the gatk.; > (But again, my vote is for removing the M2 template!); ; I agree with @samuelklee about the template. > I just noticed the script doesn't run CollectSequencingArtifactMetrics nor GetPileupSummaries on the matched normal. . I should definitely use the normal for contamination. @sooheelee What's the case for CollectSequencingArtifactMetrics on the normal?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358481510:343,simpl,simple,343,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358481510,1,['simpl'],['simple']
Usability,> the choice of prior for mixed sites will be clear because we're evaluating per-allele. @ldgauthier I don't recall whether we've discussed this but the new model does handle mixed sites very naturally by assigning separate indel/SNP pseudocountsto indel/SNP alleles in the Dirichlet prior on allele frequencies.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1697#issuecomment-242794037:46,clear,clear,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1697#issuecomment-242794037,1,['clear'],['clear']
Usability,">> interval_list. > this will need to be a parameter (but can be optional and have a default) in order to have our integration tests run GvsJointVariantCalling.wdl on exomes. Genomes too, the integration test specifies a 20/X/Y interval list. >> filter_set_name; >> extract_table_prefix. > these two can just default to the call_set_identifier with weird characters parsed out. Yeah I think that would work for the integration test(s), each variation goes into a different BQ dataset anyway. @RoriCremer can correct me if I'm wrong, but I thought the raison d'être of the beta WDL was specifically to hardcode away as many parameters as possible (even optional ones with defaults) to present a simplified interface for non-expert users. I agree we'll probably have to allow some additional parameters for testability (`gatk_override` at a minimum), but do we really want to add all of these?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1634248008:694,simpl,simplified,694,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1634248008,1,['simpl'],['simplified']
Usability,"@@ Coverage Diff @@; ## master #5628 +/- ##; ============================================; - Coverage 87.03% 87.03% -0.01% ; Complexity 31726 31726 ; ============================================; Files 1943 1943 ; Lines 146193 146193 ; Branches 16141 16141 ; ============================================; - Hits 127242 127239 -3 ; - Misses 13065 13067 +2 ; - Partials 5886 5887 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5628?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...nder/tools/walkers/vqsr/FilterVariantTranches.java](https://codecov.io/gh/broadinstitute/gatk/pull/5628/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvRmlsdGVyVmFyaWFudFRyYW5jaGVzLmphdmE=) | `92.24% <ø> (ø)` | `42 <0> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5628/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.23% <0%> (-2.74%)` | `11% <0%> (ø)` | |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5628/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.29% <0%> (-0.48%)` | `33% <0%> (ø)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5628?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5628?src=pr&el=footer). Last update [78df6b2...8c3a18d](https://codecov.io/gh/broadinstitute/gatk/pull/5628?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5628#issuecomment-459742796:2171,learn,learn,2171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5628#issuecomment-459742796,1,['learn'],['learn']
Usability,"@DuyDN This is a known issue in BQSR -- see https://github.com/broadinstitute/gatk/issues/6242. Sorry for the inconvenience! We hope to be able to develop a fix within the next several months. The fact that you ran into this error indicates that there may not actually be any usable reads in that particular read group -- they were likely all filtered out by one of the BQSR filters, which filter out malformed, low mapping quality, unmapped, and secondary alignments. You could likely avoid the error by filtering out that read group using the `ReadGroupBlackListReadFilter` in GATK while running ApplyBQSR (`--read-filter ReadGroupBlackListReadFilter`)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7549#issuecomment-963494490:276,usab,usable,276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7549#issuecomment-963494490,1,['usab'],['usable']
Usability,"@EdwardDixon I did not know that! In that case master does already require AVX. If it only impacts this tool and we provide sufficient warning and instructions, I think the single intel-optimized conda environment will be so much easier to test and maintain. Users who don't have AVX can simply install an older tensorflow in their environment, but GATK doesn't need to worry about it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-429142837:288,simpl,simply,288,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-429142837,1,['simpl'],['simply']
Usability,"@LeeTL1220 Can we clarify what is needed for FC? If this is as simple as making the normal optional in the pair WDL, let's just do that. @sooheelee take note.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3983#issuecomment-362673469:63,simpl,simple,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3983#issuecomment-362673469,1,['simpl'],['simple']
Usability,"@LeeTL1220 sounds good. Your ideal output format seems like what we should be doing. To be clear, though, `ANNOTATION1=4;ANNOTATION2=Foo;ANNOTATION3=Car` would be funcotations in the Funcotation field?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4792#issuecomment-400763404:91,clear,clear,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4792#issuecomment-400763404,1,['clear'],['clear']
Usability,"@SHuang-Broad . I'm happy to update the documentation more and/or rename things to make them more clear, but I'm not sure what the best way to do it is. A couple of thoughts:. - Sorry about the erroneous mention of `BreakpointEvidence.getStrand` in the comment for `StrandedInterval`. This was renamed to `BreakpointEvidence.isEvidenceUpstreamOfBreakpoint` when the previous PR was being reviewed. I've updated the comment now. . - The comment for `BreakpointEvidence.getDistalTargets` currently reads:. ```; /**; * Returns the distal interval implicated as a candidate adjacency to the breakpoint by this piece of evidence.; * For example, in the case of a discordant read pair, this would be the region adjacent to the mate of the current; * read. Returns null if the evidence does not specify or support a possible targeted region (for example, the case; * of an read with an unmapped mate). Strands of the intervals indicate whether the distal target intervals are; * upstream or downstream of their proposed breakpoints: true indicates that the breakpoint is upstream of the interval; * start position; false indicates that the breakpoint is downstream of the interval end position; */; ```. What else would you like to see documented there? . - The use of the word strand in this case is largely driven by a mapping of these data structures to the BEDPE format, which is the older format for representing breakpoints implied by paired-end mapping data without assembly. If you only consider read pair mappings, strand has the natural interpretation of being the strand to which reads aligned. For example, a deletion's two intervals have strands `+` and `-` because the `+` reads align at left breakpoint and `-` reads align near the right breakpoint. Extending the concept to supplementary mappings of split reads muddies the concept a bit, which made me change the definition of strand to the existing one: whether the evidence suggests a breakpoint upstream of the interval start or downstrea",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3628#issuecomment-333857471:98,clear,clear,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3628#issuecomment-333857471,1,['clear'],['clear']
Usability,"@SHuang-Broad I see. So the conversion to SAM and back when we write the file actually changes the results (or at least their annotations). It makes me a little nervous that in one version of the pipeline the records go through `BwaMemAlignmentUtils.applyAlignment` and in the other they don't, since that method has some complex logic. Right now we have two possible paths:. `AlignedAssemblyOrExcuse -> SAMRecord -> writeToFile -> GATKRead -> AlignmentRegion`. or . `AlignedAssemblyOrExcuse -> AlignmentRegion`. What if we always converted to `SAMRecord`? It's a little more expensive but it would cut down on alternate code paths and conversion code, and IMO would make the code a lot simpler to read if I didn't have to think about which code path I was in. I'm also worried that the different conversions could lead to bugs that will be hard to debug since you have to know the code path that generated them. @tedsharpe what do you think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2595#issuecomment-294168022:687,simpl,simpler,687,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2595#issuecomment-294168022,1,['simpl'],['simpler']
Usability,@SHuang-Broad done with review for now. I think it would get a lot simpler if you can simplify that list-of-maps data structure. Let's talk in person about it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1566#issuecomment-196365569:67,simpl,simpler,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1566#issuecomment-196365569,2,['simpl'],"['simpler', 'simplify']"
Usability,"@SHuang-Broad just a simple class rename and a method rename, so basically this just about whether you agree.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3617#issuecomment-332337282:21,simpl,simple,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3617#issuecomment-332337282,1,['simpl'],['simple']
Usability,"@SaraAlthubaiti It's unlikely that you would get reasonable results with DetermineGermlineContigPloidy with a single sample, so we explicitly disallow it. This is because we typically require multiple samples to learn a model for per-contig biases.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6162#issuecomment-543996187:212,learn,learn,212,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6162#issuecomment-543996187,1,['learn'],['learn']
Usability,"@SebastianHollizeck I believe the bug is not in `FilterMutectCalls` but upstream in `LearnReadOrientationModel` in the edge case of 3-base contexts that have no data in some of the samples. It's strange because we have an integration test for this already, and I would appreciate getting your input files to `LearnReadOrientationModel` for debugging. I think the following quick fix will work: untar your artifact priors, delete all but sample b, and re-tar, then run `FilterMutectCalls` as before. Is there a reason why all samples except b have very little data, and have no data at all for most 3-base contexts? To be clear, we want to fix the bug even if the data are weird, but I want to double-check that this is expected.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6202#issuecomment-597735514:621,clear,clear,621,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6202#issuecomment-597735514,1,['clear'],['clear']
Usability,"@Sun-shan - I recently published a simple toolkit, ReadTools, for standardizing formats into an unmapped BAM that follow the specifications, starting from different FASTQ inputs (and others): single-end, pair-end, Illumina-legacy names, Casava read names, etc. Check it out in the [ReadTools documentation page](http://magicdgs.github.io/ReadTools/).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4081#issuecomment-356201563:35,simpl,simple,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4081#issuecomment-356201563,1,['simpl'],['simple']
Usability,"@TedBrookings is correct that we can simply waive the check. We could check for an empty region upstream in Mutect2, but we would also have to do it for HaplotypeCaller, which would be annoying. There's basically no cost to running PairHMM on an empty set of reads once we have already assembled, so I don't see a good reason to treat this as a special case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-466277823:37,simpl,simply,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-466277823,1,['simpl'],['simply']
Usability,@U201412486 Thanks for reporting this! It looks like the issue was the `--read-name-regex null` not working with spark. I have a patch to fix it but in the meantime you should be able to run without nulling out the regex and it should fail gracefully and simply ignore counting OpticalDuplicates for reads that don't conform to the default regex.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7001#issuecomment-745356226:255,simpl,simply,255,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001#issuecomment-745356226,1,['simpl'],['simply']
Usability,@U201412486 Unfortunately it will still try to call OpticalDuplicates in that case correct (unless the regex doesn't apply to the reads correctly). Optical duplicate marking does not change the regular duplicate marking behavior and primarily gets included in the metrics so it should be possible to simply ignore the outputs. If you really want no reported Optical Duplicates you could also set the optical duplicates pixel distance to 0 (or -1) which should prevent anything from being marked as such since nothing will be in range to be counted.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7001#issuecomment-746495396:300,simpl,simply,300,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001#issuecomment-746495396,1,['simpl'],['simply']
Usability,"@V-Z Would you mind sharing your GVCF, or just the offending chunk, with me so I can debug? I'm pretty sure it's a finite precision error and have a simple fix in mind but I would like to confirm on real data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-402199745:149,simpl,simple,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-402199745,1,['simpl'],['simple']
Usability,"@Vzzarr Don't worry, these things are complicated and take time to learn! You can use whatever you want, I just know more gradle than maven so it's easier for me to help with that. . I'm having trouble reproducing the error you're having. Is your project on github? Or at a minimum could you paste your pom file here? . In the meantime, could you try cloning https://github.com/lbergelson/gatk-downstream-test and seeing if `mvn compile` completes successfully?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339761069:67,learn,learn,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339761069,1,['learn'],['learn']
Usability,@abalter Having `-F` default to all the fields in the VCF is a good suggestion -- the current behavior is definitely not intuitive.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7677#issuecomment-1050083846:121,intuit,intuitive,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7677#issuecomment-1050083846,1,['intuit'],['intuitive']
Usability,"@abalter The complete list of fields should be present in the VCF header, but unfortunately I don't know of a convenient way to extract them apart from the manual method. It would be pretty simple to write a script or GATK tool to parse the VCF header and list all the fields, but the best solution would be to patch the `VariantToTable` to default `-F` to all the fields, as discussed above.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7677#issuecomment-1061060581:190,simpl,simple,190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7677#issuecomment-1061060581,1,['simpl'],['simple']
Usability,"@adaykin The difference between the chr1, chr2, etc. convention and the 1, 2, etc. convention is more than just a difference in naming. Different versions of the human reference use different naming schemes. For example the b37 reference uses 1, 2, etc., while the hg38 reference uses chr1, chr2, etc. For this reason, it is not safe to simply translate the contig names on-the-fly. You need to do a proper liftover from one reference to another using a tool such as `LiftoverVcf`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7538#issuecomment-963507876:337,simpl,simply,337,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7538#issuecomment-963507876,1,['simpl'],['simply']
Usability,"@akiezun @droazen @lbergelson Found the issue with FTZ being cleared. The FTZ setting only applies to the thread where FTZ is set. When running tests in gradle/testng, each test is run in a new thread. However, the pairHMM native library is only loaded for the first HaplotypeCaller test, since code in `VectorLoglessPairHMM.java` prevents the library from being loaded more than once in the same JVM. This means only the first test uses FTZ. A code change that loads the pairHMM native library for each test resolves the issue, and all `HaplotypeCallerIntegrationTest` tests pass. Another option to explore is setting FTZ in `main`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1771#issuecomment-216259701:61,clear,cleared,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1771#issuecomment-216259701,1,['clear'],['cleared']
Usability,"@akiezun Could you take a look at this? . It's adding a mechanism for automatically switching in the appropriate argument collection based on whether a tool overrides `requiresReference` and it's ilk. It plays nicely with help and command line parsing in a way that it didn't before. . Unfortunately, it adds a bunch of really repetitive code. I think it's worth the extra Optional/Required classes, since they're pretty simple and they ideally shouldn't have to be touched at all. (Although if we end up making complicated additions to them it might be worth a revisit.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/440#issuecomment-96059672:421,simpl,simple,421,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/440#issuecomment-96059672,1,['simpl'],['simple']
Usability,"@akiezun Do we really need both `onTraversalDone()` and `onTraversalSuccess()`? This could be a major source of confusion. Is there any tool that overrides `onTraversalSuccess()` but not `onTraversalDone()`? Maybe we should just rename `onTraversalSuccess()` back to `onTraversalDone()`, put it in the finally block, and keep things simple?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1743#issuecomment-212591053:333,simpl,simple,333,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1743#issuecomment-212591053,1,['simpl'],['simple']
Usability,"@akiezun I believe that BAQ was only introduced into BQSR to handle indels... which we are dropping. I think you should tie out to GATK3 with BAQ included, remove BAQ completely, and then it should be simple to show that the BAQ-less results are barely any different (esp. if we enable binning). (@yfarjoun on cc)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1460#issuecomment-180910563:201,simpl,simple,201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1460#issuecomment-180910563,1,['simpl'],['simple']
Usability,"@akiezun I have switched a lot so far; currently I'm stuck on `GenotypeLikelihoodCalculator`, which relies on `GenotypeLikelihoods` in htsjdk, which is log10. I could write a simple wrapper class to present a natural log interface. Is there a better solution?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/917#issuecomment-149321469:175,simpl,simple,175,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/917#issuecomment-149321469,1,['simpl'],['simple']
Usability,"@akiezun I think there's a case to be made for having the ability to separate closure of resources from generation of final output on success, even if it's not currently needed -- I'd be ok with keeping both methods provided we can settle on the right names to avoid confusion, and provided we update the docs to make it clear when each method should be overridden. @lbergelson's suggestion of `onTraversalSuccess()` and `cleanup()` seems reasonable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1743#issuecomment-212629504:321,clear,clear,321,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1743#issuecomment-212629504,1,['clear'],['clear']
Usability,"@akiezun I've given feedback on it in person. @lbergelson may want to have a glance over it, though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1827#issuecomment-223698253:20,feedback,feedback,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1827#issuecomment-223698253,1,['feedback'],['feedback']
Usability,"@akiezun Instead of adding these overloads would we see the same speedup if we cached the result of isUnmapped and isPaired in the adapter? That would have the downside of complicating the adapter but it might avoid adding these strange methods to the interface. . If caching seems like a bad alternative, I think maybe these methods should have names that make it clear that they're some sort of performance hack and you should generally prefer the standard ones. 'getContigUnsafe` for instance.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235101307:365,clear,clear,365,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235101307,1,['clear'],['clear']
Usability,"@akiezun The goal is to use a genome mask, like for example Heng's low complexity sequence mask, which has many small intervals from the reference to be masked out. To that end I've tried using both the -XL exclude regions arg and -L with a 'complement' version of the mask. I was running on custom 10X tools in one of my branches but the problem exists with simpler tools like PrintReadsSpark. . For example running like this on a bam subset of 1MB of the reference is fine:. ```; time /humgen/gsa-scr1/cwhelan/GATK/gatk/gatk-launch PrintReadsSpark --input test_in.bam -O test_out.bam -- --sparkRunner LOCAL; real 0m49.678s; user 5m10.396s; sys 0m14.556s; ```. But add the complemented mask:. ```; $ time /humgen/gsa-scr1/cwhelan/GATK/gatk/gatk-launch PrintReadsSpark --input test_in.bam -O test_out.bam -L /humgen/gsa-hpprojects/dev/cwhelan/gatk-sv/hs37d5LCRs.complement.bed -- -- sparkRunner LOCAL; ```. And it's still running 35+ minutes later. Similar results observed using the original mask and XL argument:. ```; $ time /humgen/gsa-scr1/cwhelan/GATK/gatk/gatk-launch PrintReadsSpark --input test_in.bam -O test_out.bam -XL /humgen/gsa-hpprojects/dev/cwhelan/gatk-sv/hs37d5LCRs.bed -- --sparkRunner LOCAL; ```. Let me know if I can provide more details.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1532#issuecomment-209056610:359,simpl,simpler,359,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1532#issuecomment-209056610,1,['simpl'],['simpler']
Usability,"@akiezun This should be fixed now. I think we're hitting a bug in git-lfs, but I found a simple workaround so once it passes I'm going to merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1378#issuecomment-169100605:89,simpl,simple,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1378#issuecomment-169100605,1,['simpl'],['simple']
Usability,"@akiezun Yes, it's true that there's no way to prevent that, short of doing deep copies every time a read is wrapped in an adapter. But we can make it clear in the GATKRead contract that the backing reads should not be directly modified after wrapping within an adapter, and if they are they need to be re-wrapped in a new adapter.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235291718:151,clear,clear,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235291718,1,['clear'],['clear']
Usability,"@akiezun thanks. I think this is ready for review now. It would be good to merge something that works, even if there are future performance and usability improvements we can do later.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1750#issuecomment-219460978:144,usab,usability,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1750#issuecomment-219460978,1,['usab'],['usability']
Usability,"@asmirnov239 I've borrowed the CopyNumberTestUtils class from #7889 into which you moved the method for detecting deltas in the doubles. I'm going to merge this PR once tests pass, so just be aware of this when rebasing your branch if you make any further changes. We might consider adding a simple test of the test method itself. I'll let you do it in your branch, or we can file an issue and tackle it after everything is merged.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7652#issuecomment-1165717972:292,simpl,simple,292,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7652#issuecomment-1165717972,1,['simpl'],['simple']
Usability,"@bbimber @mlathara Here is a pretty good article for optimizing the GenomicsDBImport [https://gatk.broadinstitute.org/hc/en-us/articles/360056138571-GDBI-usage-and-performance-guidelines] There is some advice about handling many small contigs that may be useful. . To troubleshoot the GenomicsDBImport high memory issue my script have, I reran the script on chr1 to narrow down the source of the high memory issue. These are running on reblocked gvcfs. . 1. Without --bypass-feature-reader and -consolidate; 2. With --bypass-feature-reader; 3. With --consolidate without --bypass-feature-reader (This ended up on a node with 384gb.) The other ran on 256GB nodes. . Test 2 ran the fastest with the lowest memory requirements (Wall clock 76 hours); Test 1 ran slower and required more memory 40-50% of 256GB (Wall Clock 94 hours); Test 3 ran initially faster with less memory than test 1 but by batch 65 it was using 75% of 384 GB. This job has not finished and appears stuck on importing batch 65. So the consolidate option appears to have a memory leak or using just requiring too much memory. The -consolidate option was the culprit. So rerunning chr1-3 with just the --bypass-feature-reader option (test2) ran fine without lots of memory being used. Below is the time output from chr1. The output shows the Maximum resident set size (kbytes): **2630440**. Using GATK jar /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar defined in environment variable GATK_LOCAL_JAR; ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx200g -Xms16g -jar /share/pkg.7/gatk/4.2.6.1/install/gatk-4.2.6.1/gatk-package-4.2.6.1-local.jar GenomicsDBImport --sample-name-map sample_map.chr1 --genomicsdb-workspace-path genomicsDB.rb.bypass.time.chr1 --genomicsdb-shared-posixfs-optimizations True --tmp-dir tmp --bypass-feature-reader --L chr1 --batch-size 50 --reade",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1252598687:176,guid,guidelines,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1252598687,1,['guid'],['guidelines']
Usability,"@bbimber Good questions all. Whenever we do these ports we have to strike a balance between minimizing the changes and updating to GATK4 standards. Generally, though, we want the code to conform to GATK4. This PR is large and likely to require some iteration so I'd be ok with starting with just the minimal ""porting"" changes to keep things simple, and then doing a code hygiene pass at the end. The ""porting"" changes should include things like updated javadoc, GATK4-style command line arguments, updating of outdated GATK3 terminology such as ""ROD"", Utils.nonNull assertions, etc. The finals and curly braces can wait for a separate pass (we will want to do those in this PR though). If you're not sure what to include or not just ask. I like the idea of keeping the GATK3 tests working as we go along. We should make a clear distinction between the old and new tests though. Ideally the GATK3 tests would be in a separate commit that we can just delete at the end, but that can get unwieldy if the files in the commit need to change as we go along. Alternatively you could isolate them into a separate directory. They should either be disabled or made dependent on a test method (see the `@Test` annotation properties `enabled` and `dependsOn`) that is easily toggled so they can be run locally, but don't run on the CI server. Otherwise the CI server build will always fail. In general, its really helpful to have the first commit in the PR contain the completely unmodified GATK3 source files. It makes it much easier for the reviewer to see what changed for the port. I noticed that you have 2 new plugins included in this. I'm not sure if that was suggested by someone on the GATK team (I'm wondering if we want to go down that path...) but I can tell you that the existing plugins required an enormous amount of test development and review iteration. If we do decide to make them plugins, I think it would be a good idea to do so in a separate PR. Also, if we choose to make an AbstractPlugin ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407089352:341,simpl,simple,341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407089352,2,"['clear', 'simpl']","['clear', 'simple']"
Usability,"@bbimber Unfortunately it's not so simple -- some of the GATK3 test data cannot be shared externally at all due to, eg., IRB restrictions. Someone will have to look at the test data in question to make sure that it can be shared. We'll update you once we've done this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/616#issuecomment-358032795:35,simpl,simple,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616#issuecomment-358032795,1,['simpl'],['simple']
Usability,"@bbimber We believe that this should be fixed by https://github.com/broadinstitute/gatk/pull/7670, which will go out in the next GATK release. If you're able to test with that patch and give feedback on whether it resolves the error for you, that would be helpful!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7687#issuecomment-1048160591:191,feedback,feedback,191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7687#issuecomment-1048160591,1,['feedback'],['feedback']
Usability,@bbimber can you open another ticket for your comment about -L? That is a reasonable complaint about the tool usability that would be worth addressing and we should make another issue to track this.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6617#issuecomment-640720086:110,usab,usability,110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6617#issuecomment-640720086,1,['usab'],['usability']
Usability,"@bensprung So I thought this would be a trivial change. It turns out that encoding the Genotype as something like `1/1` is done way down in the depths of the VCF encoder and isn't exposed in an accessible way. It's going to need a (hopefully simple) change to the underlying htsjdk library to expose that machinery. It shouldn't be hard, it just means it will take a bit longer to get to than I expected.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8160#issuecomment-1397695685:242,simpl,simple,242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8160#issuecomment-1397695685,1,['simpl'],['simple']
Usability,"@bhandsaker Thanks for chiming in with your thoughts/concerns. Under this proposal, the various classes in htsjdk that read and return `SAMRecords` (eg., `SAMReader` & co.) would continue to put the header inside of the records, so we would not be imposing an additional burden on direct clients of htsjdk to check for null headers any more than they do currently. The only difference is that if downstream consumers of `SAMRecords` (like hellbender) choose to strip the header from the records, there would be an explicit contract governing the behavior of headerless `SAMRecords` (as opposed to the status quo, in which the header may be null but behavior is totally undocumented and in some cases inconsistent -- eg., the reference name and index in a headerless `SAMRecord` can get out-of-sync in some cases). . In addition to documenting/clarifying the behavior of headerless `SAMRecords` and fixing any consistency-related bugs we find when operating without a header, we would also make an effort to document when a class in htsjdk that consumes `SAMRecords` requires that a header be present in the records (such as the various writer classes). Does this sound reasonable? It's actually a much more conservative proposal than it may have initially sounded :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-142020109:669,undo,undocumented,669,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-142020109,1,['undo'],['undocumented']
Usability,"@bhanugandham @fleharty this issue touches upon our discussion of https://gatkforums.broadinstitute.org/gatk/discussion/24335/loh-detection-using-gatk4s-somatic-cnv-workflow. We might consider just a simple modification of the genotyping step (e.g., keeping all ROHs longer than a hard threshold) to start, which would probably cover the most common use cases with minimal effort. Can use 100% HCC1143 in tumor-only mode as an initial test, but it would be good to collect other examples.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3915#issuecomment-531833700:200,simpl,simple,200,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3915#issuecomment-531833700,1,['simpl'],['simple']
Usability,"@bhanugandham I just looked at a few at random by searching the source, and most seem to *redirect* ok, though some of the documents seem to be deprecated or out of date. Some do seem to be broken though, i.e., `LikelihoodRankSumTest` contains this broken link `http://www.broadinstitute.org/gatk/guide/article?id=473`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6382#issuecomment-652022539:297,guid,guide,297,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6382#issuecomment-652022539,1,['guid'],['guide']
Usability,@bhanugandham This might be a relatively simple thing for you to get started with.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5420#issuecomment-439188100:41,simpl,simple,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5420#issuecomment-439188100,1,['simpl'],['simple']
Usability,"@byoo Thanks for reporting these issues. I'm going to move the R issue into a separate ticket, since its a bigger change than the python fix. I'm not sure I understand this part, though:. > Unzipping the package file locates both files in the same directory and, to me, it is natural to create the conda environment in the directory. There should be no need to manually unzip the package archive (maybe you did this as part of the workaround for bad path in the .yml ?). And you should be able to direct conda to create the env wherever you want it - we just suggested the simplest possible default case. Let me know if I'm misunderstanding your suggestion.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359064404:573,simpl,simplest,573,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359064404,1,['simpl'],['simplest']
Usability,"@byoo Wonderful, we really appreciate your feedback!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360577196:43,feedback,feedback,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360577196,1,['feedback'],['feedback']
Usability,"@ccastane9 The command you show is on the right track. Couple of things:; - Since you are apparently using whole genome you'll want to figure out areas of the reference genome that have consecutive `N`s and start/end your intervals there (as stated in the link @nalinigans posted); - You have the `chr` prefix in your intervals but that may or may not be needed based on what your reference and vcfs expect for the contigs. From the naming of your interval folders, I would assume the `chr` prefix should not be included but I may be wrong. For completeness, I'll note that you don't necessarily have to have a single interval per workspace (though you may want to for scatter gather parallelism). You can specify multiple intervals per workspace. In your case, that could look something like `-L 3:1-40450000 -L 3:40450001-80000000 -L 3:80000001-121351753 -imr OVERLAPPING_ONLY`. Note that I picked the interval endpoints in an ad hoc fashion -- you'll want to use the consecutive `N`s as your guideline instead. Also, the `-imr OVERLAPPING_ONLY` is important in this case with multiple abutting intervals in order to ensure that the intervals don't get merged. Otherwise, the tool will merge the abutting intervals and only output a single interval...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-762497251:995,guid,guideline,995,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-762497251,1,['guid'],['guideline']
Usability,"@chandrans @davidbenjamin I'm not actually objecting to the idea of taking `Mutect2` out of beta, for the record. I'm just trying to get people used to the idea that removing the `@BetaFeature` tag is actually a ""big step"" that requires careful evaluation, since it can't be undone. It's not just something that affects tool documentation -- it affects our entire release and development process now that we're out of beta. If a tool is marked stable, it needs to be kept in a constantly releasable state in master, and major changes to stable tools need to be done in such a way that existing functionality is not compromised. If the latest master version of `Mutect2` has been run through and passed whatever evaluation criteria/scripts your team relies on @davidbenjamin, and you are comfortable at this point with the additional restrictions that come with doing development on a stable tool, then by all means take it out of beta!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4384#issuecomment-365646387:275,undo,undone,275,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4384#issuecomment-365646387,1,['undo'],['undone']
Usability,@chapmanb Thanks for the report. That's unexpected. Hopefully it was something simple that we can fix quickly.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3725#issuecomment-339423572:79,simpl,simple,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3725#issuecomment-339423572,1,['simpl'],['simple']
Usability,@chatchawit You're correct - you have the latest version. I just wanted to double-check. I think your intuition is correct about it only happening for certain variants. Are you able to share your file somehow? I can see where it's happening but having some variants that cause the issue would be helpful to debug.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-386195260:102,intuit,intuition,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-386195260,1,['intuit'],['intuition']
Usability,"@chlangley One thing we could potentially do to attract attention to this issue and solicit feedback from the community would be to feature it on the GATK blog. If you were to write a concise case study detailing the impact of the problem on your results, others may be motivated to look at their own results, and if it causes problems there, add their voices to yours. We're willing to bring this to public attention, we just don't have the bandwidth to do the legwork.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/269#issuecomment-283549213:92,feedback,feedback,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/269#issuecomment-283549213,1,['feedback'],['feedback']
Usability,"@cmnbroad - yes, missed one expected file after subsetting the data. tests passed. is seeing the status something i could have seen by myself? in travis i only see the projects I own, with no clear way to look up this unless i'm linked from the PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-432261666:192,clear,clear,192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-432261666,1,['clear'],['clear']
Usability,"@cmnbroad : first - would it be possible to kick off travis tests? i refactored this and dont seem to be able to do that. Second, yes, I was trying to reorder and condense the commits but clearly didnt work. I think the problem was trying to put your GATK3 commit first (which would seem to make sense). in any case, I just recreated this, putting a pristine GATK3 first, following a consolidated set of my commits with 1) the limited core changes, 2) the meat of the VariantEval port, and 3) A separate commit with a port of GATK3 VariantEvalIntegrationTest which is useful for validation but should not be merged. To your points:. 1) I substantially cut down the incoming large files, mostly by limiting the intervals of new large VCFs. 2) On the plugin: this was discussed above, and I initially also pointed out this should ultimately go into Barclay. You are actually the one who proposed staging it in GATK. I am not entirely sure I understand the reticence on plugins; however, my goal is to get VariantEval ported by touching as little of it as possible. This is already sucking up a ton of time. I flipped VariantEvalUtils to gather a list of classes from the appropriate package instead of a full-on plugin. That should satisfy that concern?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-431913735:188,clear,clearly,188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-431913735,1,['clear'],['clearly']
Usability,"@cmnbroad After thinking about this I went ahead and created VariantEvalEngine. Doing this in one PR will simplify some of the sticking points around what is a final change vs. what it expected to be fixed later. With this change, the goal is to strip most logic from VariantEval into the engine. This engine can be constructed with a VariantEvalArgumentCollection, and any kind of GATKTool as the owner. I tried to minimize the amount of context the VariantEvalEngine needed to hang on to. This means all the child classes have visibility on the VariantEvalEngine, but are no longer directly exposed to either the walker class or the argument collection. . All the logic around gathering the arguments to form DrivingVariants is moved to a static method in VariantEvalEngine. . I also rebased and fixed conflicts.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-750428516:106,simpl,simplify,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-750428516,1,['simpl'],['simplify']
Usability,@cmnbroad Can you have a look at this when you get a chance and provide high-level feedback related to eventual integration with the `PythonScriptExecutor` and any dependency-related issues? Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-344692455:83,feedback,feedback,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-344692455,1,['feedback'],['feedback']
Usability,"@cmnbroad How about we detect the common case of filters composed using only AND, and use simplified output in that case, and revert back to the complex output when filters are composed in more complex ways? That would resolve the problem in practice, since (as far as I know) all of the filters we actually use are composed using only AND.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3520#issuecomment-367072562:90,simpl,simplified,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3520#issuecomment-367072562,1,['simpl'],['simplified']
Usability,"@cmnbroad I figured I'd bump an old issue rather than create a new one, but my group would also appreciate if more gatk tools supported stdin / stdout. I've noticed that several of the Picard versions of tools support reading from stdin, but the Spark gatk replacements do not. MarkDuplicates is a big one, MarkDuplicates accepts /dev/stdin as input, but MarkDuplicateSpark does not. For the spark tools, this may be more work because they are chunking the file and splitting it across threads / processes, but it would be great if there were a solution for GATKPath / HtsPath to identify that we're operating on stdin / stdout and not use Files.newInputStream, and instead did something like wrap System.in in a BufferedReader if that's more appropriate. I realize that not all tools will be able to do this, because clearly you can't get random I/O to a file through a pipe, but there are plenty of tools that just read a single large file once through. There's a collection of older issues around better stdin/stdout support or at the least documentation around this:; https://github.com/broadinstitute/gatk/issues/5779; https://github.com/broadinstitute/gatk/issues/2236",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6749#issuecomment-1092237787:818,clear,clearly,818,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6749#issuecomment-1092237787,1,['clear'],['clearly']
Usability,"@cmnbroad I have a question regarding `getDefaultInstances()`. Why the return type is a `List<Object>` and not a `List<T>`. That will make simpler for me using it, if not maybe we require the changes in my PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2362#issuecomment-276023533:139,simpl,simpler,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2362#issuecomment-276023533,1,['simpl'],['simpler']
Usability,"@cmnbroad I haven't actually looked at the code yet, but we don't necessarily have to match GATK3 output. In the expected file at 20:10004769 where there's a deletion and then each position within the deletion reported out again with exactly the same attributes I'm not married to that representation. Furthermore, I don't know what SelectVariants will do if you ask for e.g. 20: 10004772 -- should you get the deletion? The deletion and the *-only context at the requested position _without_ the previous positions in the deletion? Does it make things any simpler if you don't have to output *-only sites?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5219#issuecomment-424376478:557,simpl,simpler,557,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5219#issuecomment-424376478,1,['simpl'],['simpler']
Usability,"@cmnbroad I refactored the training java wrapper into separate wrappers to write tensors (CNNVariantWriteTensors.java) and to train (CNNVariantTrain.java) I think this simplified the meaning/necessity of many of the arguments, which was unclear when all those tools were rolled together. . I'm working on a release-style integration test that chains all the tools together, like @droazen discussed a few meetings ago, but for this PR I think I will have to do something simpler. Because of some issues with the GSA5 environment and GPU, I still have to write in a Python2/3 agnostic way, which precludes the use of type hints. I would like to update, but I'm blocked by BITs in the short term.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432:168,simpl,simplified,168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432,2,['simpl'],"['simpler', 'simplified']"
Usability,"@cmnbroad I think this proposal is good provided that the error message people get clearly explains what they need to do to resolve things when this happens (eg., explains which dependencies have changed and how to mark the changes as ""ok"")",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2592#issuecomment-300897729:83,clear,clearly,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2592#issuecomment-300897729,1,['clear'],['clearly']
Usability,"@cmnbroad I understand that I could have retained a bunch of single-use text files, but it seemed like the more permutations one adds, the less it makes sense to have a separate, very redundant, static text file to check each scenario. There's a ton of VariantContext-related tests that parse the output VCF to test some feature as opposed to checking in a bunch of VCF text files.... While I'll grant the 4th test case I added (where we pass chr 2) isnt especially compelling over just testing chr 1, one could argue more breadth is a good thing here. if you want clarity, pulling that VariantEval report parsing code into a method called extractUniqueContigsFromEvalReport(), or simply adding a comment line, supports this goal. Anyway, I'm checking in slightly clarified version of this now, simply to get tests running. If you respond to the above, maybe we go with that. In the interest of time, I'll stage and check in the version which restores the text files and goes that route.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7238#issuecomment-831459741:681,simpl,simply,681,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7238#issuecomment-831459741,2,['simpl'],['simply']
Usability,"@cmnbroad I've implemented a compromise approach in `ReservoirDownsampler.consumeFinalizedItems()` that I think satisfies both of our concerns:. * If `consumeFinalizedItems()` is called after end of input has been signaled, it always clears state (including the end of input flag itself), regardless of whether there are any finalized items; * If `consumeFinalizedItems()` is called before end of input has been signaled, it returns an empty List and does not clear state, since in that case the downsampling process is still ongoing and we want to preserve pending items. I've also added tests to verify this new behavior. Let me know what you think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-458679171:234,clear,clears,234,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-458679171,2,['clear'],"['clear', 'clears']"
Usability,"@cmnbroad If this approach was used, I think it would make sense to make the MultiVariantWalker use generics in some form, so we call apply() on either VariantContext or FeatureAwareVariantContext. . Nonetheless, I think I have two other simpler proposals, either: #7219 or #7220. Each of these are limited in the scope of change, and should only populate the source of the VC in limited situations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-824224605:238,simpl,simpler,238,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-824224605,1,['simpl'],['simpler']
Usability,"@cmnbroad It's not clear that I will at this point, but the SV Spark tool takes multiple passes, and what I'm goofing around with right now will be a part of that (or son of that).; I just thought it might be helpful to have this alternative available. It's not worth spending a lot of time on.; What's nice is that the engine puts you in charge, for once. You get to make any number of traversals if, as, and when you need them. It relieved me of the necessity to stuff my object with a bunch of transient state. And the ReadDataSource can be managed by a try with resources, so that looks a lot more bullet-proof than the current design, too. (For example, the TwoPassReadWalker leaks the first ReadDataSource when it reinitializes for the second pass.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5985#issuecomment-499230776:19,clear,clear,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5985#issuecomment-499230776,1,['clear'],['clear']
Usability,"@cmnbroad OK - what about this proposal? I just added a protected getter and fixed the typo in 'annotation'? We could expose a constructor based way to set PedigreeValidationType, but if you dont really want to expose more of the guts of PedigreeAnnotation to subclasses prior to splitting apart founderIds and pedigree, what about keeping this as simple and minimal as possible?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7277#issuecomment-855970929:348,simpl,simple,348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7277#issuecomment-855970929,1,['simpl'],['simple']
Usability,"@cmnbroad Sorry I should have been clearer. I meant unzipping the gatk release file. Unzipping the gatk release file places both files in the sample directory as below. I tried to create the gatk conda environment in the directory, which was failed due to the path issue.; ```; $ unzip src/gatk-4.0.0.0.zip; Archive: src/gatk-4.0.0.0.zip; creating: gatk-4.0.0.0/; inflating: gatk-4.0.0.0/gatk-package-4.0.0.0-local.jar; inflating: gatk-4.0.0.0/gatk-package-4.0.0.0-spark.jar; inflating: gatk-4.0.0.0/gatk; inflating: gatk-4.0.0.0/README.md; inflating: gatk-4.0.0.0/gatk-completion.sh; inflating: gatk-4.0.0.0/gatkcondaenv.yml; inflating: gatk-4.0.0.0/gatkPythonPackageArchive.zip; $ cd gatk-4.0.0.0; $ conda env create -n gatk -f gatkcondaenv.yml; ```. It appears simpler to have conda manage both Python and R dependencies. I am not sure if it's easily possible to move away from R-3.2.5 though. Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359073267:35,clear,clearer,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359073267,2,"['clear', 'simpl']","['clearer', 'simpler']"
Usability,"@cmnbroad Sorry for the very long delay before reviewing this. I think this is a good solution. I think the test is a bit weird at the moment, but it's a weird thing to try and test. . 1: Could you make `setLoggingLevel` a static method in `Utils`, and give it a clear comment saying that it changes the global logging level (it does change the global logging level yes? Do I misunderstand what's happening? ) . 2: Could you then move the test to `UtilsUnitTest` run through all 4 levels of logging in the test, and then reset it to the initial state (if that's possible..) . Thanks for figuring this out and sorry for delay.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/603#issuecomment-122420930:263,clear,clear,263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/603#issuecomment-122420930,1,['clear'],['clear']
Usability,"@cmnbroad This clears about 50mb of memory, probably not enough to make a difference but it might help reduce error rates.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6085#issuecomment-521280086:15,clear,clears,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6085#issuecomment-521280086,1,['clear'],['clears']
Usability,@cmnbroad Would you mind profiling `setHeaderStrict()` against `setHeader()` when you get a chance to determine whether the former is more costly than the latter? We've seen a spike in our test suite runtimes today and I want to rule this out as a potential cause. A simple loop that calls each method on each read in a bam + the unix time command should suffice.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1541#issuecomment-191873209:267,simpl,simple,267,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1541#issuecomment-191873209,1,['simpl'],['simple']
Usability,"@cmnbroad asking:. > I had the same thought as @lbergelson. How does obtaining a Path from the File and delegating to the > Path overload change the semantics ?. OK so I checked again (it's been a long time since I first checked) and now I see that they go to `createCommonSAMWriterFromFactory` which then go to the same place. So it appears this isn't true anymore and the semantics would be the same. With this in mind, then, we can simplify createCommonSAMWriter as well as createSAMWriter.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-340898638:435,simpl,simplify,435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-340898638,1,['simpl'],['simplify']
Usability,"@cmnbroad could the failing WDL test simply be due to some Spark configuration issue, rather than memory? Locally, for both 1) the WDL test within the Docker and 2) CreateReadCountPanelOfNormalsIntegrationTest using 17.0.3 without the Docker, I seem to hit the exception discussed here: https://stackoverflow.com/questions/72724816/running-unit-tests-with-spark-3-3-0-on-java-17-fails-with-illegalaccesserror-cl. Not sure why CreateReadCountPanelOfNormalsIntegrationTest seems to pass in the CI environments, but perhaps it'll be more obvious to you?. Just for context, note that this tool relies on the Spark MLlib implementation of PCA.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1409180990:37,simpl,simply,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1409180990,1,['simpl'],['simply']
Usability,"@cmnbroad hopefully a simple update, it compiles fine but we'll see if tests pass....",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3962#issuecomment-351552151:22,simpl,simple,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3962#issuecomment-351552151,1,['simpl'],['simple']
Usability,"@cmnbroad thanks for the additional info. Some more detail from my side in case others stumble upon the same problem... * My input file comes from gnomad (`gs://gnomad-public/release/2.0.2/vcf/genomes/gnomad.genomes.r2.0.2.sites.chr18.vcf.bgz`). I editied it only to turn chromosome ""18"" into ""chr18"". * bcftools handles the duplicate INFO correctly and it fixes it! In case someone find it useful this is the command I used to retain only the AF tag and discard missing values:. ```; bcftools annotate -O z -i 'INFO/AF > 0' -x ^INFO/AF gnomad.r2.0.2.biallelic.hg38.chr18.vcf.gz > gnomad.r2.0.2.simple.hg38.chr18.vcf.gz; ```. * Unrelated to this particular issue, `gatk GetPileupSummaries` (next command in my workflow) doesn't like tags with missing values, I get a NumberFormatException error (I think, I don't have the logs). Hence the option `INFO/AF > 0` in bcftools.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-365640704:595,simpl,simple,595,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-365640704,1,['simpl'],['simple']
Usability,"@cmnbroad thanks for the review. I think addressed all comments except the arguments/weights simplification, which I would prefer to save for the PEP8 refactor we discussed. Back to you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5175#issuecomment-426366833:93,simpl,simplification,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5175#issuecomment-426366833,1,['simpl'],['simplification']
Usability,"@cmnbroad 👍 to adding an advanced command line option for it. . @magicDGS Our goal is to make it unnecessary for normal users to ever need to see a stacktrace. We're definitely not at the point yet where every UserException produces either a) the complete information necessary to debug, or even b) the correct information. We're trying to fix all those cases, but there's a lot of possible failure modes between cloud access, spark, filesystem plugins, etc, so it's going to be an issue for a while. . I don't think it will hurt the user experience to have an extra commandline argument for it. Printing the stacktrace when debug is on isn't a bad idea, but I think it's better to have finer grained control over it. . The other issue is that it's easier to explain to an unsophisticated user how to set an extra commmand line argument rather than trying to get them to set the environment variable which well be helpful for our support team when they're trying to debug someone's problem. (especially since setting the environment variables may be different on a spark cluster than on a local run).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2443#issuecomment-285390394:534,user experience,user experience,534,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2443#issuecomment-285390394,1,['user experience'],['user experience']
Usability,"@cmnbroad, that's not wholly unreasonable, but i'd like to push back on a number of these points. . 1) First - would GATK consider simply letting us take over VariantEval and maintain as a GATK4-based tool in another repo? My understanding from GATK4 issues is that plan was to never migrate VariantEval (i think in favor of other picard/gatk QC tools). There is a bit of a conflict between keeping a lean core engine and having all these tools built off it. I would think there's an argument for keeping your core engine and the many tools built off it separated (GATK3 seemed to include some dead tools, for example). I appreciate we're the ones pushing this migration, but I hope on the other side you can appreciate the bar is pretty significant on our time. . 2) What new plugins are you talking about? VariantStratification and VariantEvaluator are part of GATK3's VariantEval? Yeah, I wrote a base PluginDescriptor class patterned on how ReadFilters work. It probably should exist in a more core position in code. While there's some good ideas in the argument-parsing/plugin code of GATK/Barlcay, frankly seems like much of it isnt fully developed yet, which is why I kept this separated at the moment. . 3) Be aware, the GATK3 tests depend on ~30GB of files. I dont know the limits of git lfs, but I did not currently have plans to check those in. I assumed I would convert these to use GATK4 chr20/21 data for a final commit, but felt there was a lot of value in using unaltered GATK3 data to confirm parity (and it was during the migration).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407123968:131,simpl,simply,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407123968,1,['simpl'],['simply']
Usability,"@cwhelan , the tool, because of the Spark 2.0 bug, is not workable. But all changes has been reflected in the branch `sh_rewind_refactor`, which has the same output as branch `sh_master_formatter` which itself is simply a change of output format from the master version of the tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2258#issuecomment-262379027:213,simpl,simply,213,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2258#issuecomment-262379027,1,['simpl'],['simply']
Usability,"@cwhelan . Thanks for the review!; I've incorporated most of your review suggestions, with the fowling exception because I need to think about what need to be done to make less review rounds. > This logic does more than detect variants, though.. it also annotates existing variants with the imprecise evidence. I'm also a little hesitant to move this all into its own separate class -- we really should be moving towards a model where we look at all three sources of evidence (breakpoint assemblies, imprecise evidence clusters, and coverage) simultaneously for eg @mwalker174 's work, and splitting handling of imprecise evidence into its own class seems like a step in the wrong direction. I agree. That's what I'm thinking about for complex inversions as well. So what about the following in this particular PR:. 1. move `StructuralVariationDiscoveryPipelineSpark.makeEvidenceLinkTree()` into `ImpreciseVariantDetector`;; 2. drop `ImpreciseVariantDetector.detectImpreciseVariantsAndAddReadAnnotations()` considering it really only delegates to `processEvidenceTargetLinks()`; 3. rename `ImpreciseVariantDetector` as `EvidenceTargetLinkHandler`; 4. reduce the work of `DiscoverVariantsFromContigAlignmentsSAMSpark.discoverVariantsAndWriteVCF()` into detecting only simple variants based on assemblies and name it `discoverSimpleVariants()`; 5. let `StructuralVariationDiscoveryPipelineSpark` call into `EvidenceTargetLinkHandler.processEvidenceTargetLinks()` to get back VariantContexts, then write VCF . `processEvidenceTargetLinks()` really does two things at the moment: annotation on breakpoints and call imprecise deletions; preferably, we should go the all-evidence-at-the-same-time approach and decouple the two but I am trying to not mess with it right now. If you agree, I'll implement it in a separate commit.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3934#issuecomment-357345426:1267,simpl,simple,1267,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3934#issuecomment-357345426,1,['simpl'],['simple']
Usability,"@cwhelan Here you go.; Just cleaned up and renamed this batch of series of PR that should enable us to call ALL types of SV based on alignment signature alone.; Now we just need to wait for feedback on if the call format makes sense/is intuitive or not, and go from there.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3752#issuecomment-343285150:190,feedback,feedback,190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3752#issuecomment-343285150,2,"['feedback', 'intuit']","['feedback', 'intuitive']"
Usability,"@cwhelan Is there any chance you could run an SV pipeline with this change and see if it works? We added the classpath setting a long time ago for mysterious reasons, and have been afraid to remove it because we don't have good automated tests that run on the actual dataproc environment. I ran our very simple tests with this change but I want to check that it doesn't have negative consequences for your tools. I would really like to merge this if we can because it's recommended that you don't use this option unless you absolutely have to.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3946#issuecomment-357066967:304,simpl,simple,304,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3946#issuecomment-357066967,1,['simpl'],['simple']
Usability,"@cwhelan Thanks for the review! And I apologize for not clearly stating what problem is getting fixed here. I've addressed the comments in separate commit, changed the implementation, made more improvements that were discovered while reviewing the variants ; (https://github.com/SHuang-Broad/GATK-SV-callset-regressionTest/tree/master/Evaluation/Analysis/masterVSfeature/notes.xlsx); The implemented fixes are:; * for removing the hard-coded/explicit mentioning of ""chr"" in non-canonical versions, it is now fixed in 5eff782e4d582d516004fba2cee7535d984b1540; * for contigs whose alignments paint ambiguous picture, i.e. multiple alignment configurations offer equally good explanation:; 	1. if only one configuration has all alignment with MQ above a specified threshold, it is favored; this is implemented in ecc31f5fbec4e524b401fc9474a3a1b7ab08c561; 	2. if one configuration has alignment to non-canonical chromosome that explains the contig better than would-be-event-inducing mappings to canonical chromosomes, the canonical mappings are saved but the better non-canonical mappings are saved as SA tag as in SAM spec, and the VCF record produced is annotated accordingly; this is implemented in 65cdb523a2f9fa2026334713fed45381d76ffc82; * fixed a bug where sometimes an assembly contig as several alignments, only one of which has non-mediocre MQ but at the sametime this alignment contains a large gap, such contigs were previously incorrectly filtered away, they are now salvaged by commit b6b2f197b112981e00efd9d415f010c024d31b36. So, for the FN variants (FN in the sense that they are captured in the stable version of our interpretation tool but now goes missing in the experimental interpretation tool); that were curated in the above-mentioned review, only the following ones are not salvaged, with plans or comments attached. ```; asm012854:tig00000	missing	classified as ""incomplete""; fixable by finishing the last TODO in AssemblyContigAlignmentSignatureClassifier (same problem as face ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522:56,clear,clearly,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522,1,['clear'],['clearly']
Usability,@cwhelan thanks for the clear up on the tests! Just updated with some fix and the output is now the same as master up to some formatting changes.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2258#issuecomment-261665373:24,clear,clear,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2258#issuecomment-261665373,1,['clear'],['clear']
Usability,@cxfustc We have no plans for now to Sparkify Mutect2 because it is trivially parallelizable. In our wdl we simply scatter over disjoint intervals and merge the resulting vcfs. Is there an argument in favor of Spark over this approach?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4325#issuecomment-368387079:108,simpl,simply,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4325#issuecomment-368387079,1,['simpl'],['simply']
Usability,@damiencarol Thanks for the release! . I don't know if we'll be able to give you feedback about this until after the holidays. I believe @tomwhite is on vacation and he's the one most involved with hadoop-bam.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1326#issuecomment-166679112:81,feedback,feedback,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1326#issuecomment-166679112,1,['feedback'],['feedback']
Usability,@daquang -- Sam (@lucidtronix ) has already merged the code to run the model inference for his simpler 1D model architecture. I think src/main/resources/org/broadinstitute/hellbender/tools/walkers/vqsr/cnn_1d_annotations.hd5 is what you're looking for. He currently has a PR in review (https://github.com/broadinstitute/gatk/pull/4245) to add the more sophisticated 2D model and a GATK walker to do the training (CNNVariantTrain). That PR should get finalized and merged any day now.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4511#issuecomment-371836412:95,simpl,simpler,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4511#issuecomment-371836412,1,['simpl'],['simpler']
Usability,"@davidadamsphd Have a look at this one and let me know whether you think it's doable as a 20% project. @tomwhite should be able to offer guidance on how to implement this, since he contributed the reference version of this in https://github.com/samtools/htsjdk/pull/308",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1426#issuecomment-170688961:137,guid,guidance,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1426#issuecomment-170688961,1,['guid'],['guidance']
Usability,"@davidadamsphd Sure, here is a quick guide to the code:. -`BaseRecalibratorSpark` is the standalone BQSR tool, and calls into the `BaseRecalibratorSparkFn` (which is also called from `ReadsPipelineSpark`). -`ApplyBQSRSpark` is the standalone ApplyBQSR tool, and calls into the `ApplyBQSRSparkFn` (also called from `ReadsPipelineSpark`). -Integration tests for the above are in `BaseRecalibratorSparkIntegrationTest` and `ApplyBQSRSparkIntegrationTest`. -Almost all other changes in the branch are related to the BQSR engine refactoring, which I summarize below:; - We pulled out the guts of the walker `BaseRecalibrator` tool, combined it with all of the code from the former `RecalibrationEngine` class (now deleted) to make a new `BaseRecalibrationEngine` class under `utils/recalibration`.; - We stripped out all copies of the code in `BaseRecalibrationEngine` from the walker, dataflow, and spark versions of BQSR, and modified them to call into `BaseRecalibrationEngine`.; - We moved all auxiliary classes needed by the `BaseRecalibrationEngine` (eg., the covariates, etc.) into `utils/recalibration`.; - We refactored the argument collections. Now there is a single shared `RecalibrationArgumentCollection` that contains **only** the parameters for the `BaseRecalibrationEngine` itself, and this argument collection is exposed by all 3 versions of the tool. Input/output arguments have been removed from this argument collection and put into the individual implementations of BQSR, since they vary between the walker, dataflow, and spark versions of the tool. This eliminates awkward problems such as having both a `knownSites` argument AND a `BQSRKnownVariants` exposed at the same time, with only 1 of them usable for a given version of a tool. The dataflow-only `BaseRecalibrationArgumentCollection` has been deleted completely as no longer needed.; - We tweaked the names of some tool arguments to enforce consistency between the 3 versions of the tool as well as the rest of hellbender (eg.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/911#issuecomment-142340073:37,guid,guide,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/911#issuecomment-142340073,1,['guid'],['guide']
Usability,@davidbenjamin @fleharty This seems like a simple mistake in the code for `FragmentUtils` (we're using the insertion qualities where we should be using the deletion qualities) -- can you confirm and open a PR to fix this if you agree?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6801#issuecomment-692225024:43,simpl,simple,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6801#issuecomment-692225024,1,['simpl'],['simple']
Usability,"@davidbenjamin Actually, digging a bit deeper into the code, doesn't `AssemblyBasedCallerUtils.finalizeRegion()` replace the reads in the original `AssemblyRegion` with the clipped reads when it calls:. ```; region.clearReads();; region.addAll(readsToUse);; ```. And therefore the later call to `trim()` on the original region is actually seeing the clipped reads after all?. Have you checked your original hypothesis in a debugger?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6686#issuecomment-652524496:215,clear,clearReads,215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6686#issuecomment-652524496,1,['clear'],['clearReads']
Usability,"@davidbenjamin As discussed in person, it's my hope that the `AssemblyRegionWalker` changes in https://github.com/broadinstitute/gatk/commit/1ef09b3ca265209e0777c77a8519da74480908ce (which have now been merged into master!) will address `Mutect2` memory usage, and make these somewhat confusing new downsampling arguments unnecessary. That patch reduces the number of reads stored in memory at once by the engine by roughly an order of magnitude without doing any extra downsampling at all. I suggest that we do an evaluation to test whether this really resolves the issues you encountered. `Mutect2` is already hooked up to the new, lower-memory traversal code in the latest gatk/master, so all you have to do is re-run your benchmarking test. I'd suggest that you:. 1. Run with default settings in the latest master, and see if that alone does the trick!. 2. If not, try turning up the existing downsampling a bit. Eg., run with `--maxReadsPerAlignmentStart 10` instead of the default of 50. 3. If that still doesn't resolve the problem, we can revisit this PR and consider a simplified version of the downsampling args here for merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-325073233:1078,simpl,simplified,1078,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-325073233,1,['simpl'],['simplified']
Usability,@davidbenjamin As per offline conversation and that this code is actually simpler.... feel free to merge.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4851#issuecomment-395186239:74,simpl,simpler,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4851#issuecomment-395186239,1,['simpl'],['simpler']
Usability,@davidbenjamin Can you craft a simple unit test for these annotations to make sure this stays fixed?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2239#issuecomment-257574869:31,simpl,simple,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2239#issuecomment-257574869,1,['simpl'],['simple']
Usability,"@davidbenjamin Can you implement a simple integration test for this arg, to ensure it doesn't break again?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4128#issuecomment-357045030:35,simpl,simple,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4128#issuecomment-357045030,1,['simpl'],['simple']
Usability,@davidbenjamin Can you look at the test? I didn't want to check in a file with the old erroneous behavior so its hard to demonstrate what this fixed but i tried to make it clear in the comments.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7740#issuecomment-1082335904:172,clear,clear,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7740#issuecomment-1082335904,1,['clear'],['clear']
Usability,@davidbenjamin Could you take a look at this? @TedBrookings thinks it might be as simple as changing the check to allow 0 length reads when initializing the pairHmm. Neither of us are sure that that's a great solution though. . It seems like if you have no read bases you can't do any useful calculation. Should there be an earlier check in mutect that avoids assembling a region if there aren't any reads with bases?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-465193131:82,simpl,simple,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-465193131,1,['simpl'],['simple']
Usability,"@davidbenjamin I figured out that particular case we talked about earlier. The case (`depth = 0` but `PileupElement` is not empty) happens when all the reads have deletion at the locus. Instead of logging a message, now I simply skip such a locus.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3721#issuecomment-348321755:222,simpl,simply,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3721#issuecomment-348321755,1,['simpl'],['simply']
Usability,@davidbenjamin I have refactored this branch to account for changes to the codebase adjacent to this code. In the interest of not possibly harming any of the old results I have made this a toggle and I have also made the setting apply symmetrically to tails and heads and added a few simple tests in the existing framework.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6113#issuecomment-640870830:284,simpl,simple,284,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6113#issuecomment-640870830,1,['simpl'],['simple']
Usability,"@davidbenjamin I made the changes you requested, plus some additional cleanup. Since this function takes a `normalizedTable` it only ever actually sees tables whose sums are less than 400. The smallest p-value we'd expect given that we can't have entries that are larger than 400 is around 1e-120. Therefore we don't actually have to take the log of the probability and normalize it, we can just take the probability straight from `HypergeometricDistribution`. We also don't need `relErr`. . Also given this, I didn't make the changes @lh3 described, although this would clearly be a good way to reduce the computation needed for calculating the p-value with larger tables. . If you think it would be useful to keep these numerical stability features, I can add them back in, but removing them feels more readable to me given that we are only calculating small tables.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-266828114:571,clear,clearly,571,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-266828114,1,['clear'],['clearly']
Usability,@davidbenjamin I think that this issue will be addressed by the AFCalculator refactoring one way or another (e.g. by lifting up the max-alt-allele restrictions or simply avoid adding the NON-REF allele before calling the AFCalculator).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1858#issuecomment-221770394:163,simpl,simply,163,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1858#issuecomment-221770394,1,['simpl'],['simply']
Usability,@davidbenjamin I think this must be a fairly degenerate case that would trigger this in the KBestHaplotypeFinder but I can show you a simple example demonstrating this.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5907#issuecomment-494106970:134,simpl,simple,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5907#issuecomment-494106970,1,['simpl'],['simple']
Usability,"@davidbenjamin I thought you had implemented something a little more sophisticated initially, but then reverted to the ReCapSeg caller for some reason?. Anything that is relatively simple to implement yet sufficiently more principled than the ReCapSeg caller would be reasonable for this rewrite. Thought you might've had something that fit the bill originally, but maybe I'm remembering wrong. If so, then we can try leaving it as is for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-324142206:181,simpl,simple,181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-324142206,1,['simpl'],['simple']
Usability,"@davidbenjamin We could easily add in `ReadWalker` downsampling, yes -- it would be simple to add alignment-start-based downsampling like GATK3 ReadWalkers had (and the GATK4 HaplotypeCaller currently has) using a `ReadsDownsamplingIterator` + a `PositionalDownsampler`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5075#issuecomment-443864289:84,simpl,simple,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5075#issuecomment-443864289,1,['simpl'],['simple']
Usability,"@davidbenjamin mind reviewing? @LeeTL1220 take note for the style guide, if necessary.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4193#issuecomment-358454879:66,guid,guide,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4193#issuecomment-358454879,1,['guid'],['guide']
Usability,"@davidbenjamin sorry to bug, but we're really hoping to get this resolved. see my last post - while i think it's clear GATK wasnt pruning alleles in any kind of force-output/output-all case, my latest changes add this and also add test cases around it. i'm now using one of the pre-existing gVCFs as test data, which improves the test coverage as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-578837930:113,clear,clear,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-578837930,1,['clear'],['clear']
Usability,"@davidbenjamin, et al. I have two recommendations:. 1) Though I prefer to work symbolically and through proofs, it might be nice to first expand on the validation by proof in the JavaDoc - including for the specific function's header - and anywhere else where necessary across the GATK code, just for sanity's sake, and for tying things together neatly and properly. This process of always going through the mathematical steps alerts me when I code that I have not missed anything. . 2) When dealing with multiple levels of transformations, it probably would be good to formulate a collection of complete set of simple tests. Since like you mentioned {phased} is a subset (⊂) of {unphased}, then the paths of phased genotypes one works with would also be ideal to test on. Does this function have any validation tests confirming the correct likelihoods, which would be performed for both phased and unphased genotypes? These can be generated tests, if original files do not exists. Hope it helps,; Paul",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2019#issuecomment-236759221:612,simpl,simple,612,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2019#issuecomment-236759221,1,['simpl'],['simple']
Usability,"@davidbernick Since you set up the jenkins tests for us, would you be able to help us out with this ticket? We've gotten weary of catching Spark regressions post-merge with jenkins, and want to set up fast dataproc-based tests in travis that run on every pull request, and just run simple Spark tools like PrintReadsSpark to try to catch at least the most basic kinds of breakage before a branch is merged.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2298#issuecomment-286240726:282,simpl,simple,282,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2298#issuecomment-286240726,1,['simpl'],['simple']
Usability,"@droazen - Still some questions about integration tests (on the comment with your suggestion, but here too):. * I am not sure if the test that you are proposing will work with all the implementations of `createTempFile`: depends on how it is handle, as a `File` or as a `Path`; * I think that this depends a lot on the parts of the codebase that we are looking at, so maybe before accepting this a pass should be done for the usages and how the `java.io.tmpdir` is used. Waiting for your feedback before doing something that does not make sense...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-385942269:488,feedback,feedback,488,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-385942269,1,['feedback'],['feedback']
Usability,"@droazen - can you have a look to this one? It is quite simple, for organizing argument constants better (it will be super helpful for me for transition to the kebab-case arguments, which is a hight priority for me at the moment). Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4103#issuecomment-359751419:56,simpl,simple,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4103#issuecomment-359751419,1,['simpl'],['simple']
Usability,"@droazen - note also that a simple fix would be to add --smith-waterman as an option for FilterAlignmentArtifacts. Right now it is hard-coded in FilterAlignmentArtifacts, but that would at least allow a work-around using --smith-waterman JAVA",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781716483:28,simpl,simple,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781716483,1,['simpl'],['simple']
Usability,@droazen -- is there a way to simply list all the possible fields in the header? Then I could use that list to create an input for the `-F` flag.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7677#issuecomment-1056507950:30,simpl,simply,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7677#issuecomment-1056507950,1,['simpl'],['simply']
Usability,"@droazen :+1: for requiring a BAM index (once we verify that it indeed solves all of our problems). @jean-philippe-martin said exactly the same thing yesterday to me. So, I think for GATK 4 that's probably the right solution. It's not a problem of block boundaries. It's a problem of finding the first record within a BGZF block. A record from the previous block _can_ trail onto the next block with no clear indication of how much is left. That requires ""guessing"" for where the next record starts.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1098#issuecomment-156166699:403,clear,clear,403,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1098#issuecomment-156166699,1,['clear'],['clear']
Usability,"@droazen @cmnbroad @mbabadi I generally agree with the sentiments expressed in #4127, except that I think it's OK to require a conda environment (or even use of the Docker) for these particular tools. How we should validate this requirement is another question. We can discuss more with @vdauwera. @stefandiederich Hopefully once you get the conda environment set up you will be able to run the tools. We would definitely appreciate any feedback you might be able to provide. Note that the gCNV model is relatively sophisticated, so there may be some parameters (which control the priors for the model as well as how inference is performed) that you will need to adjust for your data. Depending on the number of intervals/bins you are using and your memory constraints, you may also need to scatter across multiple GermlineCNVCaller runs; see how things are done in the WDLs here: https://github.com/broadinstitute/gatk/tree/master/scripts/cnv_wdl/germline. As you noted, this pipeline is still in beta. We are currently running several evaluations and hope to soon release some Best Practices recommendations for the aforementioned parameter values that should work well for various data types generated at the Broad. We will also have some blog or forum posts that explain the new CNV pipelines in more detail coming soon---stay tuned!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357034364:437,feedback,feedback,437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357034364,1,['feedback'],['feedback']
Usability,"@droazen @ldgauthier @eitanbanks @tfenne the issue with `GenotypeGvcfs` outputting the wrong phase will still exist, even if @tfenne makes the change to `HaplotypeCaller` (@tfenne: could you move further discussion of that fix to https://github.com/broadinstitute/gatk/pull/5772). While the above example is fairly simple to understand, since `GenotypeGvcfs` run on a single sample will simply re-capitulate the genotype from the gVCF. In this case, could we just compare the `PGT` field and the `GT` field to ensure they agree, and if they don't, swap the alleles in the `GT` field (for hets only)? . This brings up an other issue: what happens with multiple samples? If the genotype is changed for a sample, how is phasing information affected (in the PGT/PID fields too)? I couldn't find a place where the phasing information is updated when re-genotyping (`PGT/PID` are fixed). I think this is beyond my ability to fix and determine (i.e. understanding how the `GenotypingEngine` works), but unfortunately, this is still a bug. Presumably the `PGT/PID` fields are correct, as they have been used in large call-sets (ex. Exac/Gnomad) without any bug reports, so is there a simple workaround like the above single-sample case?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-471038038:315,simpl,simple,315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-471038038,3,['simpl'],"['simple', 'simply']"
Usability,@droazen I can do it. It will be gratifying to complete a ticket made much simpler by the removal of the old `AFCalculator`.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2522#issuecomment-288813318:75,simpl,simpler,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2522#issuecomment-288813318,1,['simpl'],['simpler']
Usability,@droazen I have a clear picture of what's happening in GATK 4 `GenotypeGVCFs`. Now I need to trace the code in GATK 3.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2674#issuecomment-300196976:18,clear,clear,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2674#issuecomment-300196976,1,['clear'],['clear']
Usability,"@droazen I think I see how #4801 could introduce a rounding error that creates an extremely small positive log10 probability, which triggers the error. The old code was ; ```; log10PNoVariant += log10GenotypePosteriors[HOM_REF_GENOTYPE_INDEX]; ```. and the new code to handle spanning deletion is; ```; log10PNoVariant += MathUtils.log10SumLog10(nonVariantLog10Posteriors); ```; where `nonVariantLog10Posteriors` includes but the hom ref posterior *and* the posteriors of ref / span del het genotypes. So instead of A, where A is the log 10 hom ref posterior, we have log10(10^A + 10^B), where B is the ref/span del het log10 posterior. This latter quantity should never be positive, but the `log10SumLog10` method it relies on doesn't know that and has finite precision. Given that the problematic number is truly miniscule, `2.559797571100845E-21`, my money is on that explanation. I think a reasonable solution is just to replace it by zero, because we know that's where it comes from. That is, the code should become; ```; log10PNoVariant += Math.min(MathUtils.log10SumLog10(nonVariantLog10Posteriors), 0);; ```. If there is a way for me to debug without having to learn to use GenomicsDB I would like to confirm this myself. Otherwise, @sooheelee can I give you a jar to try out on the tutorial data where you spotted the problem earlier?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4975#issuecomment-402175972:1169,learn,learn,1169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4975#issuecomment-402175972,1,['learn'],['learn']
Usability,"@droazen I think suppressing progress meter is the way to go. It won't be particularly easy to surface the locus information, and I also think that would be misleading. . For instance, say a user is importing 3 intervals (for simplicity, chr 1, 2 and 3) in parallel. The progress meter will immediately start showing that the import process is at chr3 suggesting that it is roughly 2/3 of the way through. And of course it'll seem to be going a lot slower after that point. Could also get weird (and this is likely) if the furthest interval completes before the others.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7222#issuecomment-832426880:226,simpl,simplicity,226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7222#issuecomment-832426880,1,['simpl'],['simplicity']
Usability,"@droazen I'm not sure this is an improvement. We want the fundamental unit of spark tool to be the transform, not the cli wrapper around it. If we do this then we're pushing more of the contract of the transform outside of itself, i.e. see the newly duplicated bqsr code. I think that it was a deliberate decision to lift all reads into the initial rdd and then filter them in the transforms to what was needed by that transform. This is paying some performance cost in multi-stage pipelines which will potentially apply the same filters over and over again, but it simplifies the code because the filters can be baked into the transform and the pipeline writer doesn't have to think about them. It would be nice if we had a mechanism for adding metadata to an RDD so we can say ""this is a sorted RDD filtered with X,Y,and Z filters"", so we could intelligently avoid re-filtering.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1159#issuecomment-158168856:566,simpl,simplifies,566,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1159#issuecomment-158168856,1,['simpl'],['simplifies']
Usability,@droazen I've change to using the suggested simple `if`.; Please take a look again. Thanks!. __EDIT__; sorry didn't see your comments minutes ago. Will change.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3794#issuecomment-342261037:44,simpl,simple,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3794#issuecomment-342261037,1,['simpl'],['simple']
Usability,"@droazen We can keep this on ice until after the tie outs are complete, it's not a problem. . @ronlevine This looks good to me but we'll hold off of merging until @droazen gives us the all-clear.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2314#issuecomment-267113820:189,clear,clear,189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2314#issuecomment-267113820,1,['clear'],['clear']
Usability,"@droazen Yes, I simply re-cloned the GATK GitHub repository and executed `./gradlew bundle` as always. I used a 16 cores with 110 GB RAM VM",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4479#issuecomment-370001808:16,simpl,simply,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4479#issuecomment-370001808,1,['simpl'],['simply']
Usability,"@droazen [OSU Open Source Lab](http://osuosl.org/services/powerdev) provides the POWER8 cluster for open-source projects. Is it usable for your testing on PPC? Many open-source projects are using it. . With the source tree in a single repo that I propose, changes that are specific to AVX will be made only for the files under ""avx/"" directory, which are not used for building the PPC binary. For example, build.gradle will specify ""avx/"" when building the binary on x86_64 (""power8/"" on ppc64le). If the files under ""common/"" are changed (e.g., the package name is renamed from hellbender to gatk4), the changes should work on PPC if the tests don't fail on x86_64.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-215324733:128,usab,usable,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-215324733,1,['usab'],['usable']
Usability,"@droazen and @cmnbroad: i completely understand that this is outside the main GATK dev cycle and priorities; however, do you have any guess as to when you might be able to review? I dont know how active development is, but I'd especially like to get that change in VariantWalker and MultiVariantWalker (which are currently really simple refactors) in before other development on them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-378318089:330,simpl,simple,330,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-378318089,1,['simpl'],['simple']
Usability,"@droazen exactly, the artifact will depend on `BigQueryUtils` which would be in a `gvs` package to hopefully make clear that the contents are currently fairly specific to GVS and probably not ideal for more general use in their present form.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8375#issuecomment-1604900043:114,clear,clear,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8375#issuecomment-1604900043,1,['clear'],['clear']
Usability,"@droazen isn't this a simple case of using another command line argument to specify the index path? And if that's necessary for DRS files, won't it be the same for all tools?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7487#issuecomment-947038206:22,simpl,simple,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7487#issuecomment-947038206,1,['simpl'],['simple']
Usability,@droazen one comment. I think we should consider the naming of our jars in the final packages though. I think a folder with `gatk.jar` and `gatk-for-spark.jar` is clearer to users than `gatk-shadow.jar` and `gatk-spark.jar`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2090#issuecomment-239881149:163,clear,clearer,163,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2090#issuecomment-239881149,1,['clear'],['clearer']
Usability,"@droazen please review this one, should be pretty simple :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1814#issuecomment-218598366:50,simpl,simple,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1814#issuecomment-218598366,1,['simpl'],['simple']
Usability,"@droazen re: your earlier question, I think it's preferable to use the same base command and add a qualifier -- we may add other output format shortcuts in future, and I find it more intuitive to specify the format as an extra arg rather than a different target altogether.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311473535:183,intuit,intuitive,183,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311473535,1,['intuit'],['intuitive']
Usability,"@droazen thanks for the quick response! Just to be clear, my concerns were about testing that I didn't somehow screw up the original behavior through the exposure, not just testing that *some* behavior was exposed. But message received---will keep things on the simple side!. Also, please see the plots in #5564 to get an idea of the effect on outputs, if you haven't already. Would appreciate any thoughts you might have on that thread!. Will try to get this done in the next day or two, thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-896328697:51,clear,clear,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-896328697,2,"['clear', 'simpl']","['clear', 'simple']"
Usability,"@droazen thanks for the review. I have now addressed all of your feedback, with the main changes being; - Revert the change to ShardBoundary that uses the padded interval as its interval, and use an anonymous class instead.; - Add a new join strategy (OVERLAPS_PARTITIONER) so that running BQSR can be done using the old way still.; - Add a check for overly long read sizes. If exceeded the job will fail with an exception.; - Be more conservative about the partition end point by using the maximum read length, rather than just the length of the read that happens the start the next partition.; - Rather than making a field in FeatureManager transient, do a better job of reinstating the field that is not serializable (a logger).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2190#issuecomment-257368260:65,feedback,feedback,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2190#issuecomment-257368260,1,['feedback'],['feedback']
Usability,"@droazen, I opened this new PR for the handling of multiple-samples in the ReadPileup. It is a very simple patch, instead of some implementation based on caching the spliting.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1774#issuecomment-214595508:100,simpl,simple,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1774#issuecomment-214595508,1,['simpl'],['simple']
Usability,"@droazen, I was thinking about changing to the more general implementation described in the first part of the discussion, because I think it will be more useful for other API clients. Because I would like to make it as much efficient as possible, I would like to know if using `ReadWindow` instead of `ReadsContext` will be better, and use a similar approach as the `ReadWindowWalker` for construct the windows. I will wait to address your comments to your feedback about this, to close this PR and open a new one or just update this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1528#issuecomment-205412784:457,feedback,feedback,457,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1528#issuecomment-205412784,1,['feedback'],['feedback']
Usability,"@droazen, I will address this in #2041. As you suggested this when I implemented `LocusWalker`, I would like to have some idea about why `DownsamplingMethod` is used as a parameter in the constructor. I think that this is misleading, because independently of the method for downsampling the one that is used by `SamplePartitioner` is a `ReservoirDownsampler` (if downsampling is performed), so API users could think that they are performing a different downsampling in LIBS that the actual one. I will keep the constructor in the PR, but I would like some feedback for this either here or in #2041.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1879#issuecomment-235530006:556,feedback,feedback,556,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1879#issuecomment-235530006,1,['feedback'],['feedback']
Usability,"@droazen,. Apologies for the delay in getting back to you. Given the nature of our work, it's essential that we address and remove any high and critical vulnerabilities, regardless of their real-world threat level. Ensuring our system remains secure is our top priority. Here is the pull request with the modifications to address the high and critical vulnerabilities: [#8950](https://github.com/broadinstitute/gatk/pull/8950). Please review and let me know if you have any feedback.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-2285999993:474,feedback,feedback,474,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-2285999993,1,['feedback'],['feedback']
Usability,@eitanbanks @droazen @jamesemery @ldgauthier Shelving this pending guidance on implementation.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8616#issuecomment-1850825136:67,guid,guidance,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8616#issuecomment-1850825136,1,['guid'],['guidance']
Usability,@ekiernan and @kcibul thank you for your feedback!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7903#issuecomment-1161927602:41,feedback,feedback,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7903#issuecomment-1161927602,1,['feedback'],['feedback']
Usability,"@fpbarthel In that case, I would not average the bins---I'd simply take the total integer count across them, which you can then use with the rest of the pipeline and should decrease the noise as you describe. You can still use CollectReadCounts, but it will be up to you whether you want to 1) collect counts on manually merged bins, or 2) collect counts on the initial bins and manually sum the counts for the merged bins. Another option might be to use PreprocessIntervals to create 10kb bins across the genome and then manually intersect that with your list of exons (i.e., keeping only the bins that overlap with your exons) before collecting counts. There are multiple ways one might define such merged bins, which makes it hard to come up with a single tool to cover every possibility. Fortunately, it should be relatively easy for users to put together their own custom script for merging bins. For these reasons, I think it makes sense to not focus too much CNV-team development effort on adding features like this---our philosophy is to leave such pre/postprocessing steps to the user, and focus on CNV-specific algorithms such as denoising, segmentation, etc. Hopefully that makes sense!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5432#issuecomment-439916142:60,simpl,simply,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5432#issuecomment-439916142,1,['simpl'],['simply']
Usability,"@frank-y-liu Something has gone slightly wrong in this branch git-wise -- it looks like you've duplicated some commits from master, and the merge commits in your history imply that your git workflow needs some tweaking. In general, you want to always `rebase` rather than `merge` or `pull` (and avoid mixing the two, which can cause problems), since `rebase` produces a much cleaner history. Since you're working in a fork, you should create an ""upstream"" remote if you haven't already:. `git remote add upstream https://github.com/broadinstitute/gatk.git`. Then when you're working in a branch to which you've made one or more commits, and you want to update your branch with the latest changes from our master, do this:. `git fetch upstream`; `git rebase -i upstream/master`. This will bring up a screen allowing you to ""squash"" (combine) your work into a single commit that is suitable for merging into our master branch. If you do this with the current version of your branch, and select ""squash"" for all but the top commit, I believe you'll succeed in repairing your git history. . Note that after each `rebase`, when you want to push your changes to github you'll need to do a `git push -f` instead of a simple `git push`, since `rebase` changes your commit history. Try it out and let me know how it goes!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1776#issuecomment-215474210:1210,simpl,simple,1210,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1776#issuecomment-215474210,1,['simpl'],['simple']
Usability,@gbggrant do you have a link to your failed run of `DuplicateAnnotations`? The query escapes look okay to me and nothing else jumps out as being wrong but something clearly is...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8175#issuecomment-1419403209:165,clear,clearly,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8175#issuecomment-1419403209,1,['clear'],['clearly']
Usability,@gbrandt6 Here's another GATK ticket that might be suitable for learning GATK development.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7516#issuecomment-969238889:64,learn,learning,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7516#issuecomment-969238889,1,['learn'],['learning']
Usability,"@gbrandt6 Here's another one that would make a good ""learn GATK development"" ticket",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7548#issuecomment-963496528:53,learn,learn,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7548#issuecomment-963496528,1,['learn'],['learn']
Usability,"@gbrandt6 So now the protocol is that you wait for tests to pass (although it's unlikely this could break them...) and then you can merge with ""squash and merge"". You can edit the commit message in the browser to make sure it is clear. `Fix typo in --tmp-dir argument in GenomicsDB docs` is a pretty good description for this one though :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6785#issuecomment-684939263:229,clear,clear,229,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6785#issuecomment-684939263,1,['clear'],['clear']
Usability,"@gevro The `--interval-padding` argument is a GATK-wide argument shared by all tools that simply adds the specified amount of padding to each `-L` interval. The `--assembly-region-padding` argument is a `HaplotypeCaller`-specific argument that adds padding to both the `-L` intervals and the assembly regions created within the intervals. It allows the `HaplotypeCaller` to keep track of which regions are part of the main intervals for calling and which are just padding regions. So with `--assembly-region-padding` you shouldn't get variant calls in your VCF that are entirely contained within the padding regions, whereas with `--interval-padding` you would, since `--interval-padding` transforms the intervals before the `HaplotypeCaller` even sees them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6071#issuecomment-517398776:90,simpl,simply,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6071#issuecomment-517398776,1,['simpl'],['simply']
Usability,"@gspowley The directory layout seems a bit strange to me. I would have naturally put it into `src/main/cpp`, but I guess gradle considers it to be a separate component that doesn't belong in main? Do you think it would be more or less confusing to move it? There's definitely something to be said for leaving it in the default location, but it seems very non-intuitive to me.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-186431033:359,intuit,intuitive,359,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-186431033,1,['intuit'],['intuitive']
Usability,"@igordot It used to exist because `AssemblyBasedCallerArgumentCollection` used to extend `StandardCallerArgumentCollection`, causing `Mutect2` to have a bunch of `HaplotypeCaller` arguments that it didn't use. This was fixed in PR #5758. `FilterMutectCalls` also lost a few arguments as part of a huge change to the entire filtering model in PR #5688. I'm working on a blog post about this but for now the Mutect2 docs at https://github.com/broadinstitute/gatk/blob/master/docs/mutect/mutect.pdf are up-to-date and more user-friendly than they used to be.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5845#issuecomment-478008792:520,user-friendly,user-friendly,520,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5845#issuecomment-478008792,1,['user-friendly'],['user-friendly']
Usability,"@ilyasoifer do you have the means to quickly run minimap2? I would recommend simply realigning src/test/resources/large/CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam with minimap2 and making a quick ""are tests consistent with pervious versions"" test with a checked in vcf output. I don't know how to wrangle minimap2 to handle mates correctly however so i don't know if this is easy",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8337#issuecomment-1559878651:77,simpl,simply,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8337#issuecomment-1559878651,1,['simpl'],['simply']
Usability,"@jamesemery Great, thanks for checking. Could you do a review pass on this when you get a chance? It's not clear that the approach taken here of sending the owner config file around is what we want....it seems like instead we need a way to load the owner config from the launcher script itself.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4653#issuecomment-420055188:107,clear,clear,107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4653#issuecomment-420055188,1,['clear'],['clear']
Usability,"@jamesemery I will gladly review. If I understand the code change it seems like there was already basically the right logic to avoid this _but_ the code was neglecting to put the force calling alleles in a representation consistent with the output VCF. And the fix is simply to compute `forcedAlleles = AssemblyBasedCallerUtils.getAllelesConsistentWithGivenAlleles(givenAlleles, vc)` a bit upstream of where we were doing so previously. If I've got that right, this PR gets my :thumbsup:.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7740#issuecomment-1081342841:268,simpl,simply,268,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7740#issuecomment-1081342841,1,['simpl'],['simply']
Usability,"@jamesemery To be clear, comments are here, but code to review is in the other PR!!!!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8467#issuecomment-1714187064:18,clear,clear,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8467#issuecomment-1714187064,1,['clear'],['clear']
Usability,"@jamesemery What I'm actually trying to do is essentially `GENOTYPE_GIVEN_ALLELES` except that I don't know the ALTs. I realize that may sound silly. What I've ended up doing for now is generate a gVCF, genotype it, and then write a custom tool that consumes VCF and gVCF and inserts hom-ref genotypes based on a) where there is no call in the VCF and b) there is confidence in the hom-ref genotype in the gVCF. My point in logging this issue is mostly that `EMIT_ALL_SITES` is pretty misleading as it stands. I think it would be good, at a minimum, to update the documentation for that option to make it very clear that it does not in fact ""emit all sites"" but instead ""emits more sites, but still a subset of all sites in the region being called"".",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6059#issuecomment-530535087:610,clear,clear,610,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6059#issuecomment-530535087,1,['clear'],['clear']
Usability,"@jamesemery and now the overview of the more complex changes:. - `AssemblyResultSet`: the code for adding and removing haplotypes based on pileup alleles has become a `void` method of this class, where it belongs. Here and elsewhere I introduce snappy variable and function named referring to ""good"" and ""bad"" alleles, which I find visually much clearer. The code is basically the same as before but somewhat streamified. I extracted a `makeHaplotypeWithInsertedEvent` method to eliminate some code duplication between GGA and pileup force-calling.; - `HaplotypeCallerEngine` and `Mutect2Engine`: Force-calling alleles are split into biallelic `Events`. Duplicated code for finding all pileup events, then sifting them into good event to force-call and bad events to remove is extracted as `PileupBasedAlleles.goodAndBadPileupEvents`. Computing `allVariationEvents` is much simpler because 1) it now uses `Event` instead of `VariantContext` and 2) `Event` overrides `equals` and `hashCode`.; - `PileupBasedAlleles`: `getPileupVariantContexts` and sorting into good and bad pileup variants has been unified into `goodAndBadPileupEvents()`. It has additionally been somewhat rewritten for conciseness. Also, instead of the somewhat kludgy method of making `VariantContext` with four temporary attributes, then filtering based on those attributes, it calculates the filtering status immediately and uses `Events`. Also fixed the somewhat-misleading use of the word `alt` to mean `SNP`.; - `AssemblyBasedCallerUtils`: `applyPileupEventsAsForcedAlleles`, along with several helper methods that it calls, has been moved into `AssemblyResultResult`, where it is now a void member method.; - `GATKVariantContextUtils` mainly just using `Event` instead of `VariantContext`, which simplifies the code for splitting a `VariantContext` into biallelics. After going through this exercise I realize that it's not actually so much. The diff's bark is worse than its bite. The overwhelming majority of changes are eit",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574175702:346,clear,clearer,346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574175702,2,"['clear', 'simpl']","['clearer', 'simpler']"
Usability,@jamesemery could you take a look at this one please? This should be a simple fix.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5949#issuecomment-519518136:71,simpl,simple,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5949#issuecomment-519518136,1,['simpl'],['simple']
Usability,"@jamesemery sorry to bug on this topic, but I'm hoping to make a push early this year to fully migrate my lab off GATK3 . I looked more closely at the specific annotations we need to migrate. I decided that I will implement our walker, 'DiscvrVariantAnnotator', which is basically a light wrapper around VariantAnnotation. This will make it easier to spike in custom annotations. In that walker, I will override makeVariantAnnotations(). I will make a new marker interface for EngineAwareAnnotation, and test that on all the Annotation classes, and use this to inject FeatureManager. So no core GATK changes needed. I did find one thing I'd like to propose. You probably know PedigreeAnnotation is special-cased in GATK. Annotations that use it have automatic argument validation and have the SampleDB injected. Currently, PedigreeAnnotation is a subclass of InfoFieldAnnotation, so isnt available to GenotypeAnnotations. There doesnt appear to be a solid reason why. I tried to fix that and my best idea is the proposal here: #7041 . The core idea is to convert InfoFieldAnnotation and GenotypeAnnotation to interfaces. This is generally a trivial switch in existing code. With that, it becomes possible for classes that currently extend PedigreeAnnotation (which I switched to no longer extend InfoFieldAnnotation) to simply PedigreeAnnotation and implement InfoFieldAnnotation. This makes it possible for future classes to extend PedigreeAnnotation and implement GenotypeAnnotation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-760424063:1320,simpl,simply,1320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-760424063,1,['simpl'],['simply']
Usability,"@jean-philippe-martin Can you comment on this error with your thoughts? Despite now doing a channel reopen on `UnknownHostException` in our fork of the NIO library, all reopens are failing, which implies that this error can't be recovered from via a simple retry. Could there be something wrong in our authentication setup?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-412906931:250,simpl,simple,250,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-412906931,1,['simpl'],['simple']
Usability,@jean-philippe-martin I think we can set up a repro by creating a new github project with a simple travis build that just does an NIO access. I don't think we can reproduce it locally since I'm pretty sure it's a bad interaction with the environment.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-516890466:92,simpl,simple,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-516890466,1,['simpl'],['simple']
Usability,"@jean-philippe-martin I think we should do the comparison in https://github.com/broadinstitute/gatk/issues/995 before porting the ApplyBQSR optimizations, actually. If it turns out that we decide to go with the simpler broadcast approach we'd then need to figure out how the dataflow ApplyBQSR changes fit in. So it probably makes sense to spin out a separate ticket for the ApplyBQSR changes and close this one.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/970#issuecomment-148758446:211,simpl,simpler,211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/970#issuecomment-148758446,1,['simpl'],['simpler']
Usability,"@jean-philippe-martin It's looking like @Horneth won't have time to implement this in the short-term future -- since you mentioned that the change was fairly simple, would you be able to submit a PR yourself? We'd be happy to help review.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4828#issuecomment-394809501:158,simpl,simple,158,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4828#issuecomment-394809501,1,['simpl'],['simple']
Usability,"@jean-philippe-martin It's not clear to me how widespread this issue is, or what conditions trigger it -- @lbergelson care to comment?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427415516:31,clear,clear,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427415516,1,['clear'],['clear']
Usability,"@jean-philippe-martin Yeah, I was being a bit over-aggressive with the retries to maximize my chances of fixing the failures. We could make the retries conditional, and I did extract `CloudStorageRetryHandler.isRetryable()` and `CloudStorageRetryHandler.isReopenable()` methods, but are we 100% sure that in `CloudStorageFileSystemProvider` we wouldn't want to retry any of the errors that in `CloudStorageReadChannel` result in a reopen? That wasn't clear to me.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315471923:451,clear,clear,451,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315471923,1,['clear'],['clear']
Usability,"@jean-philippe-martin, when you have a chance could you please take a look at the stack trace above and give your thoughts? Our NIO library dependency was not upgraded between 4.0.11.0 and 4.0.12.0 (it was last upgraded in 4.0.9.0), so it's not clear what it is about 4.0.12.0 that is leading to this higher failure rate. . We've already tried a custom build of 4.0.12.0 that included the version of htsjdk from 4.0.11.0, but that didn't help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459838085:245,clear,clear,245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459838085,1,['clear'],['clear']
Usability,"@jfarrell Do you recognize ""scc"" as a local host name ? ""hdfs:///project/casa/gcad/adsp.cc/sv"" looks reasonable enough as a file URI, except that the hadoop file system provider requires an authority component (the part of the uri between the second and third slash: ""hdfs://authority-component/..."") be provided in such URIs. Since you didn't include one as part of the hdfs path on the command line, it looks like transform along the way resulted in one being added (the authority component looks like ""host:port""), resulting in the port number -1. So I'm not clear if its a configuration issue, or a bad code code path, or both. But I would suggest trying an hdfs path with a valid authority component (one that works with the hadoop shell). @SHuang-Broad I do see some code paths in `StructuralVariationDiscoveryPipelineSpark` that call `Paths.get directly`, rather than `IOUtils.getPath()`. I would also suggest replacing the direct calls to `makeSAMOrBAMWriter` in `SVFileUtils` with the GATK wrapper code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-493980166:562,clear,clear,562,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-493980166,1,['clear'],['clear']
Usability,"@jjfarrell Glad you found that article useful!. In general, `--consolidate` will be memory and time intensive. It's not intuitive, but as you already figured out if `--consolidate` is enabled, we do it on the very last batch. If you only have on the order of a few hundred batches total, not having specified consolidate shouldn't affect read performance much. The only other thing that would help scale here would be to break up your intervals so that larger contigs are split up into multiple regions. Less memory required and you can throw more cores at it (if you have them). What sort of performance did you see on `GenotypeGVCFs` or `SelectVariants`? That could be the other issue with these large intervals.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1252834003:120,intuit,intuitive,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1252834003,1,['intuit'],['intuitive']
Usability,@jkobject Discrete genotypes are not meaningful in somatic calling and Mutect2 has long simply emitted 0/1 for all variants as a placeholder. We're probably going to get rid of the GT entirely soon.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7650#issuecomment-1154420873:88,simpl,simply,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7650#issuecomment-1154420873,1,['simpl'],['simply']
Usability,"@jkobject Just to be clear, we hardly ever recommend making a custom panel of normals. If you do wish to make one, we recommend running the mutect2_pon.wdl script in the GATK github. In that script Mutect2 is run in regular VCF mode, not GVCF mode, which as far as Mutect2 is concerned most users should never need to deal with. Finally, GenomicsDBImport can't handle MNPs so you will need to set `--max-mnp-distance 0`. But if possible it's far easier to run our WDL.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7849#issuecomment-1613459204:21,clear,clear,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7849#issuecomment-1613459204,1,['clear'],['clear']
Usability,"@jnktsj see this PR to get an idea of how minimal the changes would be to switch the FC Featured versions of the ModelSegments WDLs to use NIO. For various reasons, I cannot easily make the switch to the WDLs in the repo here (as you can see, this causes tests to fail). So if you would like to go ahead and start testing, I would suggest that you simply clone the Featured WDLs and make the changes yourself, if that's something you're comfortable with.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5015#issuecomment-406044277:348,simpl,simply,348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5015#issuecomment-406044277,1,['simpl'],['simply']
Usability,"@jonn-smith Could you comment on this one? The tool output clearly states that we don't support this version of Gencode, and that errors may occur:. ```; GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 34) (given: 38): ##description: evidence-based annotation of the human genome (GRCh38), version 38 (Ensembl 104), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; ```. Do we claim to support 38 anywhere? (eg., in documentation, etc.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7385#issuecomment-891227342:59,clear,clearly,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7385#issuecomment-891227342,1,['clear'],['clearly']
Usability,@jonn-smith Could you take a look at this super simple PR when you get a chance?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3479#issuecomment-324144199:48,simpl,simple,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3479#issuecomment-324144199,1,['simpl'],['simple']
Usability,"@jonn-smith Is there a forum post (or other docs) on how to setup a datasource for remote, NIO access? Do we make it clear that this only supports what the GATK supports?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5425#issuecomment-439976455:117,clear,clear,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5425#issuecomment-439976455,1,['clear'],['clear']
Usability,@jonn-smith Thank you. I will be looking at the ucsc. I also found the following tool that implements the ucsc liftover file creation....the logic seems simple.; https://github.com/konstantint/pyliftover,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6837#issuecomment-800419348:153,simpl,simple,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6837#issuecomment-800419348,1,['simpl'],['simple']
Usability,"@jonn-smith, I did see XsvLocatableTableCodec and the .config file path, but this does not appear to work. To be clear this is something like:; ```; gatk IndexFeatureFile -I ./hg19/testTextSource.config; ```; In IndexFeatureFile (https://github.com/broadinstitute/gatk/blob/abe8148bda234edf6bd00fa51df44d456e8e2641/src/main/java/org/broadinstitute/hellbender/tools/IndexFeatureFile.java#L118), it does identify the correct codec; however, it then calls:. IndexFactory.createDynamicIndex(featurePath.toPath(), ...). where featurePath is the config file. This calls IndexFactory to open a lineReader on the config file (not the backing data source): https://github.com/samtools/htsjdk/blob/6d3fc7bc1f613ecfce1c22d368f3ae17cb86823d/src/main/java/htsjdk/tribble/index/IndexFactory.java#L598. . This then fails during XsvLocatableTableCodec.readActualHeader(), since this is trying to read the config file, not the TXT file.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1591678472:113,clear,clear,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1591678472,1,['clear'],['clear']
Usability,@jsotobroad You were perfectly clear. I must have made that change on a different branch by mistake!!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4306#issuecomment-362872226:31,clear,clear,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4306#issuecomment-362872226,1,['clear'],['clear']
Usability,"@kdatta Is this example code still current? If not, should we close this? We do eventually want some TileDB example code checked in, but ideally it would take the form of a simple, runnable GATK tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2181#issuecomment-267126100:173,simpl,simple,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2181#issuecomment-267126100,1,['simpl'],['simple']
Usability,"@kdatta Looks like the integration tests passed on travis after clearing the cache! Once you address comments, squash, and rebase onto the latest gatk master the unit tests should pass as well, since you just need the TestNG fix that got merged into master. This means we can merge this today in all likelihood!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-296301829:64,clear,clearing,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-296301829,1,['clear'],['clearing']
Usability,"@kdatta Thanks for the clarification! One more question: when a combine operation is not defined for a particular attribute, is that attribute simply dropped by GenomicsDB? Ie., a client who reads VariantContexts from GenomicsDB will not see the attribute at all in the returned VariantContexts, even though it was present in the original GVCF inputs?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-293989145:143,simpl,simply,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-293989145,1,['simpl'],['simply']
Usability,"@kdatta Thanks for the update -- we do need to get these tests passing with our `assertVariantContextsAreEqual()` comparison routine, rather than your diffing tool, but we can relax this routine to be agnostic to allele ordering. About the `MIN_DP` issue: can you explain what was causing it? Why was it working with a `VCFCodec` and not a `BCF2Codec`? I still don't understand. Does it work now with our comparison routine and using a `BCF2Codec` internally, or does it still require a `VCFCodec` to pass? . And what was the ""ExcessHet problem"" (don't see a description of it above)? Was it just the ""no combination operation"" warning? What did the output look like before and after the fix for this annotation?. @cmnbroad has volunteered to have a look at the tests in this branch this afternoon, so we should be able to give you some more feedback soon!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-293978277:842,feedback,feedback,842,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-293978277,1,['feedback'],['feedback']
Usability,"@kguraj Thanks for the response(s). The test in the PR was super useful as a temporary test, but as you mentioned it runs pretty slowly, and as it stands the test passes on current master anyway. It seems to require on the order of 9000-1000 intervals instead rather than 1000 to actually hit stack overflow. Since that would be a very slow running test, I'm inclined to back it out. Also, the user who originally reported the issue was using 11k intervals, and it seems that the stack overflow fix is unlikely to help in that case. Is there any guidance for users on what is a reasonable number of intervals per process ? It sounds like the intention was that it be used with pretty small intervals. Should we issue a warning message in GenomicsDBImport at some threshold number of intervals ?. Are you planning to produce a jar with the error messages suppressed for this PR?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407867902:546,guid,guidance,546,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407867902,1,['guid'],['guidance']
Usability,"@kgururaj As I start to think about upgrading exome joint calling to use GenomicsDBImport the 100 interval threshold seems like it might be problematic. I've been working with WGS data, so I don't have much intuition for benchmarking with missing data. Is there any performance downside to running over larger intervals that include missing data? For example, if we want to scatter the exome 50 ways, each subset of the exome interval list will have ~4000 intervals, but the GVCFs won't have data outside those intervals. Does it make sense to pass to GenomicsDBImport a single interval encompassing all of those?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5066#issuecomment-409956462:207,intuit,intuition,207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5066#issuecomment-409956462,1,['intuit'],['intuition']
Usability,"@kgururaj I just tried this out with my annotations and it worked right out of the box! The update was very simple on my end. Ideally it might be nice to define the combine operations as static Strings in the annotation classes, but we can do that on the GATK side.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4993#issuecomment-415137763:108,simpl,simple,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4993#issuecomment-415137763,1,['simpl'],['simple']
Usability,"@kgururaj and @kdatta Here's some GVCF data for a trio of samples, each called to haploid (ploidy 1) and tetraploid (4) genotypes. I included the reference (just chromosome 20) and the intervals list. This is data from one of our workshop tutorials so many of the intervals in the list I used don't have any data (so lots of no-calls) but there should be enough usable calls for testing purposes. Let me know if this isn't sufficient to get you started. . Thanks for looking into this, it's very important for a non-trivial subset of our users. . [genomicsdb.zip](https://github.com/broadinstitute/gatk/files/1171416/genomicsdb.zip)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3342#issuecomment-317577301:362,usab,usable,362,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3342#issuecomment-317577301,1,['usab'],['usable']
Usability,"@koncheto-broad this is one of the VQSR-lite PRs you will want to eventually rebase on. It's still awaiting review (I was waiting until the dust from updating to Java 17 in #8035 settles), but if anyone from your team wants to take a first crack, feel free! Not too many code changes, so hopefully it should be pretty manageable. Just so it's all in one place: your #8157 GVS branch is currently rebased on #7954, which contains the ""serial SNP-then-indel"" version of the Joint Genotyping WDL (written by Megan for Ultima) and the Java code for the tools. Some minor updates were made to the Java code in #8049 and the WDL was rewritten by me to do SNPs and indels in a single pass in #8074. (EDIT: I was originally confused here, the WDL that was replaced in this PR simply ran SNPs and indels separately, rather than serially—thanks to George for correcting me here.). The PR here makes relatively minor updates to both the Java code and the WDL and might require very minor updates to GVS code or JSON configurations. And finally, the larger PR at #8132 adds a Pure Java BGMM backend. As we discussed during my mobbing presentation, this is provided merely as a convenience for those users that might not be able to control their python environment (hopefully a small number, these days!), so getting it merged is probably less urgent and should not affect any GVS work.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8131#issuecomment-1414056344:768,simpl,simply,768,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8131#issuecomment-1414056344,1,['simpl'],['simply']
Usability,"@laserson the `SAMRecord` vs. Google `Read` is a loooooong story.; The super-short version:; We had a bunch of utilities written for `SAMRecord` that @droazen refactored over months to take the GATKRead interface. As it happens, the SAM spec and the GA4GH spec are not 100% compatible. So, it's not possible to losslessly convert from A -> B -> A (where A is `SAMRecord` or Google `Read`). The cases where it doesn't work are edge cases, but they exist. Second, @jean-philippe-martin found that converting to Google `Read` was fairly expensive. Between those two points, I think we're probably better off with SAM-backed reads. (Also, right now the Google `Read` is serialized via JSON, so it's not that small anyway.). @tomwhite and @jean-philippe-martin, I think adding the header back will be fine for us engineers working on the engine, but it will make for a poorer user experience for newcomers and Comp Bios to burden them with having to care about what happens with shuffles (when they just want to prototype something). . That said, I think this is probably the best approach we have at our disposal. If we do, we need to do an excellent job of throwing errors if users try to perform actions that would require the header. The error message should explain what really happened and ideally point to some documentation we write explaining the stripping of the header and how to fix it. If this error occurs, it needs to be simple for anyone to fix it. @droazen @lbergelson, what do you two think? (also @laserson, do you have any ideas or thoughts on the header since we're probably stuck with `SAMRecord`?)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141086025:871,user experience,user experience,871,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141086025,2,"['simpl', 'user experience']","['simple', 'user experience']"
Usability,"@lbergelson - In gradle, I first resolve with maven central and then with your artifactory:. ```gradle; repositories {; mavenCentral(); maven {; url ""https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/""; }; }; ```. In the case of maven, for several repositories this should be done following [this](https://maven.apache.org/guides/mini/guide-multiple-repositories.html). I think that the configuration for the repositories should look like this (if I remember correctly):. ```xml; <repositories>; <repository>; <id>central</id>; <name>Maven Repository Switchboard</name>; <layout>default</layout>; <url>http://repo1.maven.org/maven2</url>; <snapshots>; <enabled>false</enabled>; </snapshots>; </repository>; <repository>; <id>snapshots</id>; <snapshots>; <enabled>true</enabled>; </snapshots>; <name>libs-snapshot</name>; <url>https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot</url>; </repository>; </repositories>; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-340482852:334,guid,guides,334,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-340482852,2,['guid'],"['guide-multiple-repositories', 'guides']"
Usability,"@lbergelson ; I should mention the version of BWA I document is v0.7.15 (https://software.broadinstitute.org/gatk/documentation/article.php?id=8017). The Genomics Platform has also moved on to v0.7.15: ; ```; WMCF9-CB5:Documents shlee$ docker inspect broadinstitute/genomes-in-the-cloud:2.2.5-1486412288; [; {; ""Id"": ""sha256:69ece5bcfc730304ad77e9473c17094328924fc13b2ed3e63b7ac2d4c859a483"",; ""RepoTags"": [; ""broadinstitute/genomes-in-the-cloud:2.2.5-1486412288""; ...; ""Labels"": {; ""GOTC_BGZIP_VER"": ""1.3"",; ""GOTC_BWA_VER"": ""0.7.15.r1140"",; ""GOTC_GATK34_VER"": ""3.4-g3c929b0"",; ""GOTC_GATK35_VER"": ""3.5-0-g36282e4"",; ""GOTC_GATK36_VER"": ""3.6-44-ge7d1cd2"",; ""GOTC_GATK4_VER"": ""4.alpha-249-g7df4044"",; ""GOTC_PICARD_VER"": ""1.1150"",; ""GOTC_SAMTOOLS_VER"": ""1.3.1"",; ""GOTC_SVTOOLKIT_VER"": ""2.00-1650"",; ""GOTC_TABIX_VER"": ""0.2.5_r1005""; ```. If the spark version we offer currently in GATK4 is roughly equivalent to v0.7.13, and this is the latest release in the Apache branch of the BWA repo that is usable by us, then should we ask HL for another Apache release equivalent to v0.7.15?. Note to self: this tool currently is not usable as it requires hacks to the command and also silently drops reads. Needs fixing not documenting.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2711#issuecomment-301184380:991,usab,usable,991,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2711#issuecomment-301184380,2,['usab'],['usable']
Usability,@lbergelson @cwhelan @tedsharpe Going to break this PR down into smaller pieces. I will implement the feedback received thus far as well.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2646#issuecomment-299292827:102,feedback,feedback,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2646#issuecomment-299292827,1,['feedback'],['feedback']
Usability,"@lbergelson @droazen Ah, SV has two arguments for samples: ""sample_name"" takes sample names, and ""sample_files"" takes filea containing samples, but it will take *any* files, regardless of extension. The whole thing is also true of ""exclude_samples"". We could eliminate the file-based arguments, but the result would only work with "".list"" files. If we can break backward command line compatibility, we can simplify SV, remove two arguments, and remove the SampleUtils and SampleUtilsUnitTest file-reading code. We just need to decide.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2390#issuecomment-277346980:406,simpl,simplify,406,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2390#issuecomment-277346980,1,['simpl'],['simplify']
Usability,@lbergelson @droazen and here i was thinking this simple fix would for whatever reason be easy and painless to get in...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6195#issuecomment-538396166:50,simpl,simple,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6195#issuecomment-538396166,1,['simpl'],['simple']
Usability,"@lbergelson A couple of simple filters to add, but since this touches engine packages I thought I'd offer you the opportunity to have a look. Should take < 5 min, I hope.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6295#issuecomment-561328264:24,simpl,simple,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6295#issuecomment-561328264,1,['simpl'],['simple']
Usability,"@lbergelson As discussed earlier today, that would be more awkward than the simple boolean toggle in the case of `-L`, since you really don't want to specify an alternate extension in that case, you just want to turn the expansion off completely.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358055056:76,simpl,simple,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358055056,1,['simpl'],['simple']
Usability,@lbergelson Can you provide @kgururaj with your simple test case that replicates this issue?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3814#issuecomment-344285682:48,simpl,simple,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3814#issuecomment-344285682,1,['simpl'],['simple']
Usability,"@lbergelson Could we reopen this? We were able to track down the source of the modified BQs across active regions. At the end of the function `adjustQualsOfOverlappingPairedFragments(final GATKRead clippedFirstRead, final GATKRead clippedSecondRead)`, the base qualities are set in the clipped reads:; ```; clippedFirstRead.setBaseQualities(firstReadQuals);; clippedSecondRead.setBaseQualities(secondReadQuals);; ```. In some cases, the clipped read is actually the original read, modifying the original read's BQ. I've committed a simple fix to my branch that ensures that the clipped read is never the original read.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4926#issuecomment-402295512:532,simpl,simple,532,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4926#issuecomment-402295512,1,['simpl'],['simple']
Usability,"@lbergelson Do you have an opinion on the best way to pip install the gcnvkernel python package and dependencies for Travis testing? I've verified that the pip install works within a basic conda environment with python=3.6. We'll need to load this environment both for unit/integration tests as well as WDL tests. As long as this is the only python environment we need, I think we can simply use the base environment in the Docker. If more environments are required (e.g., for @lucidtronix), then maybe we'll need to be more clever for unit/integration tests, but we can still load them manually in the scripts that kick off the WDL tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-348073948:385,simpl,simply,385,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-348073948,1,['simpl'],['simply']
Usability,"@lbergelson I agree, gradle's default location for native code is non-intuitive and a little ugly. I left the code in the default location so we could discuss where you want to keep it. I'm OK with moving it to `src/main/cpp`. I'll look into removing the `build/classes/main` hardcoding. Also, I'll look into a way to convince gradle to use /usr/bin/gcc-4.8 without using sudo.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-186434234:70,intuit,intuitive,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1504#issuecomment-186434234,1,['intuit'],['intuitive']
Usability,"@lbergelson I disagree -- it's very clear to me that those tests will trigger Google authentication, just by tracing through the code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2706#issuecomment-300806909:36,clear,clear,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2706#issuecomment-300806909,1,['clear'],['clear']
Usability,@lbergelson I simplified the subsetting and removed the BitSet. Back to you.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1852#issuecomment-242806423:14,simpl,simplified,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1852#issuecomment-242806423,1,['simpl'],['simplified']
Usability,"@lbergelson I understand the change of userClassPathFirst can cause problems.; About the new parameter, I shouldn't have ""pull request"" it. It's absolutly unnecessary as `--conf 'spark.submit.deployMode=cluster'` works. Plus, as you said, it's hardcoded...; About #3933, I didn't retry the `-- --deploy-mode` solution after my userClassPathFirst modification. I added the parameter in my fork to test. I still think it's important to have it in gatk's parameters because it's simple for users, but it's not an emergency. For me, the userClassPathFirst change is important. Or a parameter to specify it. Without it, I can't get my jobs to work in cluster mode.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3946#issuecomment-351440051:476,simpl,simple,476,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3946#issuecomment-351440051,1,['simpl'],['simple']
Usability,"@lbergelson I've addressed your feedback now, so back to you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2256#issuecomment-267551963:32,feedback,feedback,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2256#issuecomment-267551963,1,['feedback'],['feedback']
Usability,"@lbergelson It's dawning on me that I completely misunderstood this ticket. Is the idea that a push build simply builds your (in general unrebased) commit, while a PR build intends to build the repo as would be upon merging? And is the PR build the Travis build that instantly reports passing when we issue PRs?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5213#issuecomment-584447441:106,simpl,simply,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5213#issuecomment-584447441,1,['simpl'],['simply']
Usability,"@lbergelson Responded to your comments, I think it should be slightly clearer to read/understand now",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5607#issuecomment-462497782:70,clear,clearer,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5607#issuecomment-462497782,1,['clear'],['clearer']
Usability,"@lbergelson Sorry to be unclear---this isn't a GATK issue. For Cromwell, you can configure various options for each backend. For example, if you are running on a local backend with Docker, you can set a `submit-docker` attribute to specify the string that runs the Docker container; so to solve the above problem, you'd set this to include `--shm-size` and set it accordingly. However, according to @jsotobroad, you're not allowed such an attribute when submitting to Google cloud. If that's the case, then this is more of an issue with the Cromwell/Google Pipelines interface than the data.table package (although, as the discussion in the GitHub issue above shows, it'd be a simple fix on the data.table end, so I'm not sure why it's not addressed yet...) Changing the R script to get around the issue in this particular case is not unacceptably ugly, but you could imagine we might run into a similar problem in the future if anything else exceeds the 64MB /dev/shm limit and also cannot specify tmpfs. So perhaps we should take a look at the underlying issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357375691:677,simpl,simple,677,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357375691,1,['simpl'],['simple']
Usability,"@lbergelson Thanks for your quick reply! Hopefully it is just something simple. But I think it's nothing to with spark, because SortReadFileSpark can process filepath with umlauts. For example a path like `/media/Ergebnisse/1399-17_Exom (Neuromuskulär)_NB501654_0052/1399-17.recal.bam`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4337#issuecomment-363331462:72,simpl,simple,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4337#issuecomment-363331462,1,['simpl'],['simple']
Usability,"@lbergelson You're right, it would be easier to read that way, but it leaves a dangling ""Optional Arguments"" string in the output even when there are no optional arguments. If you're still not sold I can rewrite it to iterate once to count the optional args, but this is a cheap, simple way to get the right output.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/566#issuecomment-112561579:280,simpl,simple,280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/566#issuecomment-112561579,1,['simpl'],['simple']
Usability,"@lbergelson and @jonn-smith thanks for your replies, they are really helpful. . I do have some additional questions related to information you shared in your replies: ; > There's some existing utility code that could probably help you. Any pointers to these parts are appreciated! . > you can render the annotations in MAF format . @jonn-smith is there also an option to take in an already annotated VCF and produce the corresponding MAF without having to annotate things again (so a simple conversion)? This is what I'm looking for at the moment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8154#issuecomment-1380290516:484,simpl,simple,484,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8154#issuecomment-1380290516,1,['simpl'],['simple']
Usability,"@lbergelson and I will review in person later today, and make easy/simple changes ourselves to save on back-and-forth -- if we have non-trivial questions or changes needed we'll send back to you for a second round.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-277253978:67,simpl,simple,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-277253978,1,['simpl'],['simple']
Usability,@lbergelson can you review - it's a simple enhancement to the CompareBaseQualities tool,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1773#issuecomment-214757716:36,simpl,simple,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1773#issuecomment-214757716,1,['simpl'],['simple']
Usability,@lbergelson clearly volunteered to review this pull req,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1126#issuecomment-157404178:12,clear,clearly,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1126#issuecomment-157404178,1,['clear'],['clearly']
Usability,"@lbergelson everything I know I learned from there:; http://stackoverflow.com/questions/28939166/error-submitting-a-cloud-dataflow-job. Mine was also in the 4MB range, I switched to loading that file at the worker instead of the client and it worked. So the size limit is probably somewhere between 3 and 4MB.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/595#issuecomment-114594863:32,learn,learned,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/595#issuecomment-114594863,1,['learn'],['learned']
Usability,"@lbergelson has been able to replicate the bug using a simple test case, so this is confirmed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3814#issuecomment-343230937:55,simpl,simple,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3814#issuecomment-343230937,1,['simpl'],['simple']
Usability,"@lbergelson or @droazen: this is related to your comments on #8752 about preserving the default behavior of just writing the first source. This PR overloads simpleMerge(), meaning code needs to opt-in to the feature of preserving all source names. . I cannot kick off tests - would one of you be able to to that?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8871#issuecomment-2164367475:157,simpl,simpleMerge,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8871#issuecomment-2164367475,1,['simpl'],['simpleMerge']
Usability,@lbergelson thank you for the comment and sorry for my bit late response. I excluded the dependency to the jsr203-s3a and tested that both local- and spark-gatk can access s3a files by dynamically loading it. I also added a new directory `scripts/s3a` for documentation and simple tests for s3a demonstration.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6698#issuecomment-665484597:274,simpl,simple,274,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6698#issuecomment-665484597,1,['simpl'],['simple']
Usability,"@lbergelson thanks - could you take another look?. I agree about the many modes -- I'm not sure there's a way to clear that up. We're game to help with documentation/blog stuff that can help clarify what sort of usecases would benefit from different modes/features if that would help. Do you have any pointers for sample data that I could use for testing the ""many contigs to several"" case?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6681#issuecomment-667421004:113,clear,clear,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6681#issuecomment-667421004,1,['clear'],['clear']
Usability,"@lbergelson that seems to be a separate bug, since this just reverts some commits. There's obviously a simple workaround here too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-267026554:103,simpl,simple,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-267026554,1,['simpl'],['simple']
Usability,@lbergelson the tests are not running on [gatk-jenkins.broadinstitute.org](url) so it's not usable yet. What remains to be done?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1400#issuecomment-199324556:92,usab,usable,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1400#issuecomment-199324556,1,['usab'],['usable']
Usability,"@lbergelson you beat me because I was stuck trying to actually run a Picard tool in the integration test. (For future reference, that needs a workaround because the test running adds the ERROR level logging to all command lines and Barclay can't parse that for Picard tools for some reason.). The big reason I was using this instead of IntervalListTools is because the Picard version creates a terrible output file structure that I was having trouble capturing with a simple glob in WDL. I agree that the functionality here is largely redundant, but it was helping me get my workflow working faster at the moment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5392#issuecomment-435894196:468,simpl,simple,468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5392#issuecomment-435894196,1,['simpl'],['simple']
Usability,"@lbergelson, @akiezun AFAIK picard tools need you to specify specifically FLAG=true/ FLAG=false if it's a boolean flag. it is true that, if you want, any argument can have a default value (true or false) but to change it you will still need to assign true or false (i.e even if there is a default you cannot simply have FLAG on the commandline). Yes, the logic of the pipeline specifies all the commandline arguments, regardless of defaults so that if the defaults change (which the GATK used to do all the time!) the pipeline will not change. Thus the use case has to include being able to set all arguments to their value boolean or otherwise.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/133#issuecomment-94434510:308,simpl,simply,308,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/133#issuecomment-94434510,1,['simpl'],['simply']
Usability,"@lbergelson. Our simple s3 nio library is not currently open source, but we would be willing to make it so after testing it properly. We found that to get the s3 nio library work with GATK, a few minor changes needed to be made in the GATK source. This is especially true for the spark tools because, on AWS EMR Spark clusters, s3 uris can be treated exactly as if they are HDFS uris. Therefore, it was not quite as simple for us to just add the s3 nio library to the classpath and have everything work as expected. For that reason we put the project on hold until GATK is closer to release. Thanks,; David. ________________________________; From: Louis Bergelson <notifications@github.com>; Sent: Monday, July 31, 2017 11:57 AM; To: broadinstitute/gatk; Cc: David Brown; Mention; Subject: Re: [broadinstitute/gatk] update com.google.guava version (#3102). @david-wb<https://github.com/david-wb> Is your s3 plugin available as an open source plugin that others could use? We had another question about s3 support in gatk and I thought you might have some insight about it. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319146368>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ABxO-d5XTtUyeAI0GzCFLP5eVGYiyQJEks5sThWegaJpZM4N31U->.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319185834:17,simpl,simple,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319185834,2,['simpl'],['simple']
Usability,"@lbergson's instructions above are good, but somehow they did not work for me. I was able to follow the [application default credentials](https://developers.google.com/identity/protocols/application-default-credentials) instructions, though. Here are the steps I took:. 1. create a new service account on the Google Cloud web page and download the JSON key file.; 2. gcloud auth activate-service-account --key-file ""$PATH_TO_THE_KEY_FILE""; 3. export GOOGLE_APPLICATION_CREDENTIALS=""$PATH_TO_THE_KEY_FILE"". I cleared my credentials first to make sure that the access worked because of the above steps, not because of other credentials. After those steps, gatk was able to run from my desktop and access files using the service account credentials. `gsutil ls` worked as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2425#issuecomment-282900470:508,clear,cleared,508,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2425#issuecomment-282900470,1,['clear'],['cleared']
Usability,"@ldgauthier & @droazen I've done as you've suggested. There is now a check in `GenomicsDBImport`, by wrapping the FeatureReader. It's a little ugly but it gets the job done. I've also added a simple test for GenotypeGVCFs to genotype a GVCF that has an MNP in it. I _think_ this is probably now ready for review. Let me know if you think further tests are needed!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5182#issuecomment-422989371:192,simpl,simple,192,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5182#issuecomment-422989371,1,['simpl'],['simple']
Usability,"@ldgauthier / @davidbenjamin Would either of you like to comment on this one? This is a long-standing issue with our assembly-based callers, and it's not clear to me that there's an obvious solution.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-399562467:154,clear,clear,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-399562467,1,['clear'],['clear']
Usability,"@ldgauthier @ahaessly and I could use your thoughts/intuition as to what might be going wrong here. The `NullPointerException` the user reported is in the `StrandBiasUtils.encode()` method below, and it implies that either the `perAlleleValues` for one of the alleles is itself null, or the `perAlleleValues` for one of the alleles contains a null `Integer`. In `computeSBAnnotation()` we have `perAlleleValues.values().removeIf(Objects::isNull)`, which seems to rule out the former option (perAlleleValues for a particular allele itself being null), and implies that instead one of the individual Integers in the `List<Integer>` perAlleleValues for a particular allele is null. Any ideas on how that could happen?. ```; public static String encode(List<Integer> alleleValues) {; return String.join("","", alleleValues.stream().map(i -> i.toString()).collect(Collectors.toList()));; }. protected static String makeRawAnnotationString(final List<Allele> vcAlleles, final Map<Allele, List<Integer>> perAlleleValues) {; final List<String> alleleStrings = vcAlleles.stream(); // does not replace a null value with zero list - only if the key is not in the map; .map(a -> perAlleleValues.getOrDefault(a, ZERO_LIST)); .map(StrandBiasUtils::encode); .collect(Collectors.toList());; return String.join(AnnotationUtils.ALLELE_SPECIFIC_RAW_DELIM, alleleStrings);. }. public static Map<String, Object> computeSBAnnotation(VariantContext vc, AlleleLikelihoods<GATKRead, Allele> likelihoods, String key) {; // calculate the annotation from the likelihoods; // likelihoods can come from HaplotypeCaller or Mutect2 call to VariantAnnotatorEngine; final Map<String, Object> annotations = new HashMap<>();; final ReducibleAnnotationData<List<Integer>> myData = new AlleleSpecificAnnotationData<>(vc.getAlleles(),null);; getStrandCountsFromLikelihoodMap(vc, likelihoods, myData, MIN_COUNT);; Map<Allele, List<Integer>> perAlleleValues = new LinkedHashMap<>(myData.getAttributeMap());; perAlleleValues.values().removeIf(Ob",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-697902360:52,intuit,intuition,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766#issuecomment-697902360,1,['intuit'],['intuition']
Usability,"@ldgauthier Emitting the spanning-deletion-only sites completely would definitely make things simpler, since I could then use EMIT_ALL_CONFIDENT_SITES and GenotypingEngine would just naturally do the right thing. Also, the result would comport with my own naive expectations. Using the current PR, outputs could contain LowQual sites that GATK3 wouldn't have included. So if you're good with that, I'll update the PR and tests to reflect that before any more reviewing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5219#issuecomment-424454872:94,simpl,simpler,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5219#issuecomment-424454872,1,['simpl'],['simpler']
Usability,@ldgauthier PR for you! Hopefully simple...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6438#issuecomment-581539634:34,simpl,simple,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6438#issuecomment-581539634,1,['simpl'],['simple']
Usability,"@ldgauthier Some parts of taking splitting MNPs at the end of HaplotypeCaller are easy: breaking eg one DNP at position n into a SNP at n and a SNP at n + 1, letting the SNPs inherit the PLs, AF, and AD (okay, this isn't quite right because a read might end in the middle of the MNP, but close enough) of the parent MNP. . . but the general problem of splitting annotations seems like it might be too tricky. I'm leaning toward instead just modifying `AssemblyBasedCallerGenotypingEngine.phaseCalls()`. It seems that this phasing relies very heavily on perfect phasing or anti-phasing and that even one questionable haplotype with incorrect phasing can spoil things. I would guess that we could improve the phasing by making some simple guess as to which haplotypes are real. Basically, the problem is that while HaplotypeCaller imposes ploidy on alleles, it does not do so on haplotypes, and so phasing information is diluted. With your permission I would like to merge this PR and open a new issue for improving `phaseCalls`. After all, the issue is fixed in M2, and HC now has a perfectly good MNP mode, with the caveat that it doesn't interact nicely with GVCF mode.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4650#issuecomment-384836262:730,simpl,simple,730,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4650#issuecomment-384836262,1,['simpl'],['simple']
Usability,@ldgauthier Thanks for the feedback -- I'll see if I can add some additional assertions about the actual alleles retained at each site that had more than the maximum.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4497#issuecomment-370811446:27,feedback,feedback,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4497#issuecomment-370811446,1,['feedback'],['feedback']
Usability,"@ldgauthier The issue that I've been dealing with in trying to implement https://github.com/broadinstitute/gatk/issues/5651 is that in sites with a star allele, you have two alternate alleles, so we need to provide an alternate mapping from GT to PGT there as well. For example this would be the representation of a phased deletion and a spanned SNP:. ```; chr1 10 . ACGT A 0|1 PGT=0|1; chr1 12 . G T,* 1|2 PGT=1|0; ```. Since the real ALT we're trying to phase at position 12 is the `T` with index 1, and the '*' is taking the place of the ref allele as a representation of ""no variation at this site"", this lead me to start thinking of PGT as the label for the haplotype on which the variant alt allele represented at this site appears. I thought this was consistent with the definition of PGT in the header line as. > Physical phasing haplotype information, describing how the alternate alleles are phased in relation to one another; will always be heterozygous and is not intended to describe called alleles. In the case of homozygous sites, though, this doesn't really make a lot of sense. Perhaps a clearer definition of PGT could be: ""Descriptor of which of the two phased haplotypes represented by the current phase set the alternate allele (excluding *) occurs on. Not intended to match genotype allele indices at the site."". Or to reduce confusion with genotype allele indices, we could change it to a different representation like . ""Aa""; ""aA""; ""AA"". And provide a more detailed explanation elsewhere.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6432#issuecomment-705643030:1105,clear,clearer,1105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6432#issuecomment-705643030,1,['clear'],['clearer']
Usability,"@ldgauthier The test is much clearer now, thanks for pointing me to the example. This will end up being tested in WARP with the next GATK release and I'm not sure how easy it is to test two commits of GATK in WARP against each other. If it's possible to do that without updating the official truth data, then I could run that before we merge this. Otherwise we'll end up catching any issues when we update WARP after the next GATK release (which I'm motivated to do when the time comes).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8862#issuecomment-2159220666:29,clear,clearer,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8862#issuecomment-2159220666,1,['clear'],['clearer']
Usability,"@ldgauthier This looks good, its a pretty simple change and there are unit tests and integration tests that enforce the new behavior. I would squash the two commits and give them an informative commit message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320707124:42,simpl,simple,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320707124,1,['simpl'],['simple']
Usability,"@ldgauthier This ticket seems to be asking for genotype priors i.e. population allele frequencies to be learned within joint calling. If I interpret the request correctly, that's what new qual does. Can we close this?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5244#issuecomment-481806389:104,learn,learned,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5244#issuecomment-481806389,1,['learn'],['learned']
Usability,@ldgauthier what do you think would be the implications of fixing this by either keeping the 2bp ALLELE_EXTENSION overlap or remove it. I guess that most of the time the variant is supported by a healthy number of reads and the AD/DP is perhaps a couple of reads lower that is supposed based on the PL if anything. It is more parsimonious to simply don't consider reads that don't overlap the variant but it seems to me that the 2bp was put there for a reason (increase sensitivity?),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5434#issuecomment-439966204:342,simpl,simply,342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5434#issuecomment-439966204,1,['simpl'],['simply']
Usability,"@lh3 We agree about the low-cov joint calling and have already tested it on 191 low-coverage (roughly 3-4x) samples from 1kg. The calls were identical except for one site with qual just above 30 that used to be just below, but this difference is basically arbitrary. If we simply add 15 to the qual threshold (as we should, because the new qual is systematically more permissive due to learning a minor allele fraction that may be greater than the average genome-wide heterozygosity), results are completely identical.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2255#issuecomment-258436797:273,simpl,simply,273,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2255#issuecomment-258436797,2,"['learn', 'simpl']","['learning', 'simply']"
Usability,"@lucidtronix @cmnbroad we set the *_NUM_THREADS flags in the WDL, but the changes to the Dockerfile will affect users who don't use the WDL (or don't follow it as a guideline for building their own scripts).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-475628454:165,guid,guideline,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-475628454,1,['guid'],['guideline']
Usability,"@lucidtronix @cmnbroad, I see for v4.0.12.0, CNNScoreVariants falls under the `EXPERIMENTAL Tool` label. When you say the tool will come out of beta, do you mean there will be a change in this label or something else? I'm writing a document that links to the CNN workflow and need to be clear on the status of the workflow. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5548#issuecomment-452818246:287,clear,clear,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5548#issuecomment-452818246,1,['clear'],['clear']
Usability,"@lucidtronix @mbabadi @samuelklee I think the best solution would be to establish a single, common Python environment, with a single set of dependencies, that all GATK Python tools depend on. We would establish a single docker image that has all of these dependencies pip installed, and could also include a conda env for the GATK environment for users who don't want to use the docker image. If we could do that, it would eliminate the need load per-tool conda environments. From what I've seen so far based on existing branches, the two environments we need (gCNV and CNN-VQSR) don't look that far apart in terms of dependencies. gCNV is using Theano, and CNN Tensorflow, but the rest looks [pretty close](https://docs.google.com/a/broadinstitute.org/spreadsheets/d/1RV7--uBQ0ctlXzMH09cmr0VimpZYIU68DdxJzE60y-c/edit?usp=sharing). So a strawman proposal for the main components for a common environment would be:. Python 3.6; Numpy >= 1.13.1; Scipy 1.0.0; Theano .0.9.0; Tensorflow 1.4.0; Pymc3 3.1; Keras 2.1.1. Can you all chime on on whether you think we can converge in a single environment ? If so, it would greatly simplify things, and we can start with getting a docker image built for running travis tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3692#issuecomment-348188451:1122,simpl,simplify,1122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3692#issuecomment-348188451,1,['simpl'],['simplify']
Usability,@magicDGS Can you please compile (with a simple `g++ avx-all.cpp`) and run the short program below on the affected Mac and report back the output? This is basically the code being executed by GKL to determine if AVX is supported. Code to compile and run (zipped): [code.zip](https://github.com/broadinstitute/gatk/files/1310975/code.zip),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-330240343:41,simpl,simple,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-330240343,1,['simpl'],['simple']
Usability,"@magicDGS I could certainly do that (split out an OptionalReadFilterArgumentCollection), though we'd then need to add a ""requiresReadFilters"" method to determine which to use. I guess it depends on how common that case would be. An simple alternative would be to just override makeReadFilter and reject any command line filter requests or do any custom filter handling.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1900#issuecomment-225997121:232,simpl,simple,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1900#issuecomment-225997121,1,['simpl'],['simple']
Usability,@magicDGS I'd much prefer to keep this as simple as possible. It should be fairly easy to introduce a shim layer between the GATK walker classes and your tool classes that overrides whatever methods you'd like to customize. We could certainly consider changing the way the CommandLineProgram methods are factored if that helps.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382900549:42,simpl,simple,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382900549,1,['simpl'],['simple']
Usability,"@magicDGS If you think an AbstractPluginDescriptor would be useful, I'd suggest initially creating a separate PR in GATK, since that would make it easy to see to how it simplifies the existing descriptors. Then once that converges, we can move the abstract part to Barclay.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-408101219:169,simpl,simplifies,169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-408101219,1,['simpl'],['simplifies']
Usability,"@magicDGS It looks like you have triggered a few new compiler errors in the last branch, namely in the following places:. ```; /gatk/src/test/java/org/broadinstitute/hellbender/tools/spark/sv/discovery/SVDiscoveryTestDataProvider.java:33: error: cannot find symbol; BaseTest.b38_reference_20_21, ReferenceWindowFunctions.IDENTITY_FUNCTION);; ^; symbol: variable BaseTest; location: class SVDiscoveryTestDataProvider; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/formats/SampleLocatableCollectionUnitTest.java:30: error: cannot find symbol; private static final String TEST_SUB_DIR = toolsTestDir + ""copynumber/formats"";; ^; symbol: variable toolsTestDir; location: class SampleLocatableCollectionUnitTest; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/utils/annotatedregion/SimpleAnnotatedGenomicRegionUnitTest.java:18: error: cannot find symbol; private static final String TEST_FILE = publicTestDir + ""org/broadinstitute/hellbender/tools/copynumber/utils/combine-segment-breakpoints-with-legacy-header-learning-combined-copy-number.tsv"";; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259:1047,learn,learning-combined-copy-number,1047,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259,1,['learn'],['learning-combined-copy-number']
Usability,"@magicDGS Review complete for now. Looks good but I have some nitpicks. I think they're almost all due to it being ancient gatk3 code that no one has updated in a long time. I'd recommend dropping the deprecated formats and only supporting mpilup single sample format which should allow for massive simplification of both the Codec and the Feature. . We need some unit tests for the codec itself since it has a bunch of different potential error cases, and we should have some integration tests for the tool that show it correctly failing on cases with errors.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1862#issuecomment-224417179:299,simpl,simplification,299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1862#issuecomment-224417179,1,['simpl'],['simplification']
Usability,"@magicDGS Sorry for the delayed reply, I had to see what direction the `HaplotypeCaller` branch would take before I could answer your post above. In order to get the `HaplotypeCaller` performance up to acceptable levels we've had to make some changes to the traversal that have caused it to diverge quite a bit from the idea of a `SlidingWindowWalker` in this branch. Also, the way `SlidingWindowWalker` handles the `intervalsForTraversal` (using them to select fixed-size windows) is not compatible with what the `HaplotypeCaller` currently requires. As a result, I recommend that we merge your `SlidingWindowWalker` in as a separate traversal rather than trying to reconcile it with the `HaplotypeCaller` branch and mutate it into something that might not be as useful to you. Fortunately, walkers in GATK4 are simple enough that it's perfectly fine to have several similar-but-subtly-different walker types, provided they all serve actual use cases. I'll",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1528#issuecomment-204134447:813,simpl,simple,813,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1528#issuecomment-204134447,1,['simpl'],['simple']
Usability,"@magicDGS The GATK versioning scheme is not related to the API -- it is targeted at end users rather than projects using GATK as a library. Here's a slide that explains it:. <img width=""824"" alt=""gatk_versioning"" src=""https://user-images.githubusercontent.com/798637/38042254-e5bb85a4-3281-11e8-8d83-017bb6b73fda.png"">. As the slide mentions, we have given some thought to supplementing the main version number with an ""API version number"", but we'd have to more clearly define what constitutes the official public API for the GATK before doing so. On a side note, now that we're in general release it may be easier for you to get PRs for things like new walker types merged into the GATK proper, particularly if they are fairly self-contained and don't involve refactoring lots of engine classes. I was planning to ask whether you wanted to resurrect your `SlidingWindowWalker` PR at some point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4603#issuecomment-376946968:463,clear,clearly,463,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4603#issuecomment-376946968,1,['clear'],['clearly']
Usability,"@magicDGS The HaplotypeCaller traversal has undergone some changes in the past few weeks to improve performance and bring the output of the tool closer to GATK3. There is now an `AssemblyRegionWalker` that divides the intervals into active and inactive regions, in a greatly simplified version of the GATK3 traversal. Initially, I did plan on having `AssemblyRegionWalker` extend the former `ReadWindowWalker`, or an adapted version of your `SlidingWindowWalker`, and I did implement it like this at first, but ultimately I collapsed it into a single class for several reasons:; - Inheriting from a more generic traversal type caused usability issues and confusion with respect to the command-line arguments. The `ReadWindow` was the unit of processing for the superclass, but for `AssemblyRegionWalker` it was the unit of I/O and `AssemblyRegion` was the unit of processing, and I couldn't update the docs for `ReadWindowWalker` to clear up the confusion without mentioning `AssemblyRegion`-specific concepts.; - The `ReadShard` / `ReadWindow` was/is **only** there to prove that we can shard the data without introducing calling artifacts, and to provide a unit of parallelism for the upcoming Spark implementation. It's not something we really want to expose to users as a prominent knob, and we may hide it completely in the future once the shard size is tuned for performance.; - Inheriting from a more abstract walker type caused a number of other problems as well: methods that should have been final in the supertype could no longer be made final, with the result that tool implementations could inappropriately override engine initialization/shutdown routines. Also, there were issues with the progress meter, since both the supertype traversal and subtype traversal needed their own progress meter for their different units of processing. Ultimately it was just too awkward and forced, and the read shard is something that we eventually want to make an internal/encapsulated implementation d",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210806513:275,simpl,simplified,275,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210806513,3,"['clear', 'simpl', 'usab']","['clear', 'simplified', 'usability']"
Usability,"@magicDGS This PR is necessary for my work on Mutect2, but I'm out on Monday and Tuesday anyway. If #2154 is merged before Wednesday then all is fine; otherwise I can simply re-instate `PerReadAlleleLikelihoodMap` in this PR and delete it in a later PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-255604622:167,simpl,simply,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-255604622,1,['simpl'],['simply']
Usability,"@magicDGS Yes, I think it would be much simpler if we had one PR with all of the fixes for the validation rules (and related help issues). The extensibility changes we've been discussing should be a separate PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2377#issuecomment-278330318:40,simpl,simpler,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2377#issuecomment-278330318,1,['simpl'],['simpler']
Usability,"@magicDGS Yes, it was the additional commits beyond 6d1cbf5 that I was referring to (and it wasn't clear to me whether **all** of the code review requests were in that commit, or if some were distributed amongst the other commits with the additional changes). In general I think once we start a review, the only changes should be based the code review requests. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-271587711:99,clear,clear,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-271587711,1,['clear'],['clear']
Usability,@magicDGS very simple comments 👍 when addressed,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2243#issuecomment-271648869:15,simpl,simple,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2243#issuecomment-271648869,1,['simpl'],['simple']
Usability,"@magicDGS, after much discussion with @droazen, we will make this test set even smaller. Also, the current test set will be temporary, to unimpede you, until updates to the main test set can be made (discussion to start next week). @cmnbroad says we need to keep an eye out for coverage in the tests, given the need to make this dataset extremely small. So I removed chr17 from the mini-reference, such that only four small snippets of reference from various chromosomes remained. However, it appears there are only two usable indel realignments going on with GATK3. Note thate these are targeted exome samples with comparatively low coverage. [for_magicDGS.zip](https://github.com/broadinstitute/gatk/files/1820785/for_magicDGS.zip). There are two samples, so as to enable testing nWayOut, and an artificial reference `hg38_Shl01`. The two sites to hone in on are chr11:177568 and chr11:207134. Note also that the BAMs are in an invalid state according to ValidateSamFile. However, GATK3 RealignerTargetCreator and IndelRealigner did not seem to mind. I think these tools should allow processing of BAMs in any validation state. Apologies for the meager state of the data. On the bright side, the data set including the ref is only 23MB and will meet with @droazen's approval in terms of size. . Good luck @magicDGS.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373845600:520,usab,usable,520,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373845600,1,['usab'],['usable']
Usability,"@magicDGS:. 1. Yes, you're right that you're already correctly testing that you get the right number of shards back. No need for an extra assertion. 2. I think that realistically-sized reads (of differing lengths!) does add to the unit test, since it's important to test with reads that overlap extensively with other reads. You'll also want to vary the read lengths to test with reads of different lengths at the same start position, shorter reads that start after longer reads, and any other arrangements that are significant to your `ShardingIterator`. . It shouldn't be too difficult to write a simple method that uses `ArtificialReadUtils` to create small pileups of reads within a given interval (might be worth extracting into `ArtificialReadUtils` itself so that future tests can use it).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4682#issuecomment-389998139:599,simpl,simple,599,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4682#issuecomment-389998139,1,['simpl'],['simple']
Usability,"@magicdgs You could include this filter in ReadTools and the plugin would discover it - after all, thats part of the purpose of plugins ;-). Anyway, at a minimum we should make sure the doc clearly explains when/how to use this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5367#issuecomment-434681393:190,clear,clearly,190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5367#issuecomment-434681393,1,['clear'],['clearly']
Usability,"@marchoeppner `MarkDuplicatesGATK` was removed because it had fallen out-of-date with respect to the version in Picard, and as an unmaintained tool was in our view not safe for use, and was causing confusion for our users. The loss of CRAM support is an unfortunate side effect of its removal. We've been doing a lot of work on our parallel version of `MarkDuplicates`, however, which is called `MarkDuplicatesSpark`. This version is fully up-to-date with respect to the Picard version, can run much faster than the Picard version when multiple cores or multiple machines are available, and will fully support CRAM in the future. CRAM support in that tool will come as a side effect of our migration to the new Disq library (https://github.com/disq-bio/disq), which is scheduled to happen within the next few months. In the meantime, I'd suggest continuing to request the Picard community to add CRAM support to their version. It's likely not a lot of work, and may simply require passing the reference through to the reader class, which could be a ~1 line change!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5218#issuecomment-424882567:966,simpl,simply,966,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5218#issuecomment-424882567,1,['simpl'],['simply']
Usability,"@matthdsm this was intentionally left out of the recent 4.6 release, but should go into the next minor release. Would of course appreciate any testing/feedback from the community before then!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2200883096:151,feedback,feedback,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2200883096,1,['feedback'],['feedback']
Usability,"@mbabadi Ah, well file-based I/O would be the simplest option of all, of course, and should definitely be considered as a candidate solution to this ticket, particularly if you've already tried it and found the performance penalty to be minimal for your use case (@cmnbroad take note). The division of labor you describe between Java and Python sounds great, by the way -- exactly the sort of approach I was hoping you'd implement.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3698#issuecomment-337319853:46,simpl,simplest,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3698#issuecomment-337319853,1,['simpl'],['simplest']
Usability,"@mbabadi I've updated my PR to use miniconda3. @mbabadi @lucidtronix @samuelklee I think we should aim for tools that at least run out-of-box, without depending on any out-of-band configuration other than the conda env. On top of that we can provide guidance/configs for users on how to enable further optimizations, like g++. Does that sound like an achievable goal ?. As for the docker, we're going to have strike the right balance between image bloat and performance(including test performance). I think we're around 4+ gig now, and counting. Before the Python integration we were at 1.9G, and trying to find ways to reduce it. So lets see where we wind up but keep that in mind. Finally, we need to find a way to install the (GATK) python package(s) without depending on access to the GATK repo. Right now I think the gCNV branch has a ""pip install from source"" added to the conda env .yml. That will work on the docker at the moment (and thus on travis), but that won't work for non-docker users how don't have source/repo access. Also, one of the proposals to reduce the size of the docker is to remove the repo clone that is currently there. My proposal is that we change the gradle build to create an archive/zip of the python source (this would include the VQSR-CNN package code as well as gCNV kernel). We can then copy that on to the docker image, and pip-install it from the copy. That would retain the ability to always run travis tests based on the code in the repo, and also keep the nightly docker image in sync. We'll also have deliver the archive as an artifact somehow (perhaps including PyPi) for non-docker users.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350303277:250,guid,guidance,250,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350303277,1,['guid'],['guidance']
Usability,"@mbabadi you're welcome! . About those two issues--I learned that with VPN on, Spark tools error locally (thanks to Steve). I turned off my VPN connection and am able to run PileupSpark locally. (There is an issue ticket on this at https://github.com/broadinstitute/gatk/issues/1534.). One other thing to note for PipeupSpark documentation--the tool will error if the output filename already exists. That is, unlike other GATK tools, it will not overwrite existing file names. Either this unusual behavior should be fixed or mentioned in the tooldoc. I'm testing this with dataproc now. When running locally, neither CollectBaseDistributionByCycleSpark nor CollectInsertSizeMetricsSpark output the PDF file. So this seems a bug and I'll put in an issue ticket if there isn't one already.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4068#issuecomment-356028074:53,learn,learned,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4068#issuecomment-356028074,1,['learn'],['learned']
Usability,@meganshand 1 very minor comment about the tests. 👍 After that. This is awesome to find such a simple solution.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2629#issuecomment-297761108:95,simpl,simple,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2629#issuecomment-297761108,1,['simpl'],['simple']
Usability,"@meganshand There is a warning in the docs for `ReadCoordinateComparator` that it should not be used for bam file output that needs to match the ordering of `SAMRecordCoordinateComparator` exactly, since it sorts all unmapped reads after all mapped reads. `ReadCoordinateComparator` is a comparator for `GATKRead`, and that interface does not allow unmapped reads to have a position. Ie., even if an unmapped `SAMRecord` is assigned the position of its mapped mate, calling `getContig()`/`getStart()` on the unmapped read via the `GATKRead` interface will return null/0. This was done mainly for consistency reasons and to simplify client code. Whenever we need bam file order for reads in GATK4, we operate on SAMRecords directly and use either the `SAMRecordCoordinateComparator` from htsjdk or the `HeaderlessSAMRecordCoordinateComparator` (for headerless Spark reads) that produces the same ordering. I recommend addressing this for this tool via `presorted = false` for now, since the GATK3 version has it set to false as well with the comment: ""**we don't want to assume that reads will be written in order by the manager because in deep, deep pileups it won't work**"". This suggests that even if you were to change the comparator used by this tool to behave like `SAMRecordCoordinateComparator`, you'd still have ordering issues in deep coverage areas. It's worthwhile, though, to open a separate ticket to explore whether `ReadCoordinateComparator` could be changed to exactly match bam file order. Eg., perhaps we could add `getAssignedContig()`, `getAssignedStart()`, etc. methods to `GATKRead` to expose the positions that unmapped reads with mapped mates get assigned for sorting purposes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1853#issuecomment-224668518:623,simpl,simplify,623,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1853#issuecomment-224668518,1,['simpl'],['simplify']
Usability,@mehrzads Thank you for posting about this issue. Have you been able to demonstrate different ref-confidence calls in active regions as a result of changing USE_CACHED_READ_INDEL_INFORMATIVENESS_VALUES? It would be simple enough to add a defensive check to ensure the reads have their transient fields purged between calls to the ReferenceConfidenceModel to be absolutely sure there is no issue.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5908#issuecomment-488317874:215,simpl,simple,215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5908#issuecomment-488317874,1,['simpl'],['simple']
Usability,"@mlathara Apologies, my comment was confusing. See replies below:. - I should have clarified when I said that my workspace where I simply removed the extra contigs ""executes just fine for SelectVariants"". The job start progressing (slowly) without extreme/overt errors. . - Regarding ReBlockGVCFs: the problem here is that I'm basically starting at step zero. It's not trivial to process >2000 gVCFs into genomicDb workspaces. Re-making all those gVCFs and then restarting the entire import is a huge hit. We already decided to only make workspaces with 250-500 samples (since it just wasnt working to go higher), and even that's a lot of computation time. I gotta be honest, I'm pretty close to abandoning GenomicsDB and looking at other solutions.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1211423602:131,simpl,simply,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1211423602,1,['simpl'],['simply']
Usability,"@mlathara I think we're talking a bit in circles. The main use case I foresee for a generic split/merge tool would be to allow parallelized processing. I cant say there wouldnt be other uses I'm not seeing now (in the VCF world, SelectVariants is an extremely useful tool), but i dont have a specific use-case for GenomicsDB subsetting today beyond this. . I would point out this rapidly gets into specifics and quirks of any one user's infrastructure. I dont actually mind copying the GenomicsDB workspace prior to appending to it, because processing occurs on shared lustre space, while our permanent data lives on other disk space. Therefore we would probably do a copy no matter what. I agree you dont want to develop our one person's infrastructure. . The only aspect that gives me pause on your plan regarding split jobs is that GATK doesnt provide the scheduler. Sure there used to be queue and I gather GATK pushes WIDL/Cromwell (unless this changed), but we never used these. If GATK is not trying to provide the scheduler (which is better), does this really just look like: . 1) kick off X independent jobs for GenomicsDB/append; 2) each job specifies the interval(s) on which to operate; 3) Each job has no knowledge of the other jobs; 4) each job writes it's output to the same workspace; 5) Presumably there is something in place so jobs can run concurrently. This must be the new feature?. I imagine this could work. It does obligate one to have/use some kind of shared disk space, which we can handle, but could be a negative for some.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-641469405:787,pause,pause,787,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-641469405,1,['pause'],['pause']
Usability,"@mlathara I updated my question with more details. Hope that is clear now. @ldgauthier Is this problem different from the one you talked about in #5449? Maybe I misunderstood that issue. I will try the normalization. By the way, what does this PID tag tells us 1660261_TC_T as it appears everywhere.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5944#issuecomment-493098861:64,clear,clear,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5944#issuecomment-493098861,1,['clear'],['clear']
Usability,"@mlathara Our primary use case involves calling variants on a constantly growing large dataset of WGS and WXS data. As you probably realize, the CombineGVCFs/GenomicsDBImport step is incredibly time consuming, and scatter/gather is pretty much essential to make these operations work in any halfway reasonable period of time. I have off-hand heard people from the broad mention large WXS datasets, and keep in mind we're working mostly w/ WGS. Regarding processing: our main downstream use right now is GenotypeGVCFs, and yes we expect to run that scatter/gather as well. I agree that in principle we could maintain these data as a folder of workspaces. In fact that was my original plan before I realized the GenomicsDB workspace already is essentially a folder of per-contig folders. The reason I like the solution of copying around the folders is b/c our end product is in an official file format that tools understand how to use. . A related point, before we decided to try GenomicsDB, my plan was to create a scheme (""file format"") that would allow our code to better operate on a folder of per-contig CombinedGVCF file. I would probably have written out a top-level JSON file that served the same purpose as the JSON files in a GenomicsDB workspace. As noted above, GenomicsDB is essentially already doing this for me. To the question about usage and support: perhaps that ways to think about this would be interval-based split and merge tools for GenomicsDB workspaces? This would obscure the internal structure of the workspace from the user (even if they basically just to folder copying). The split tool should be really simple and not have many caveats. The merge tool could have a lot of limits on what kind of workspaces can or cannot be merged. Perhaps it could do sanity checking on the JSON files to make sure they're compatible, and then copy the folders into this new merged workspace?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-635338868:1631,simpl,simple,1631,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-635338868,1,['simpl'],['simple']
Usability,"@mlathara The nodes have considerably more (256 or so). is there any rule or thumb or guidance on expected memory needs based on number of gVCFs and/or type of input (WES vs WGS)?. I do think you might be onto something though. Out default cluster submission code takes our slurm job memory request, subtracts only a few GB and passes the remainder to -Xmx/Xms. I will update to leave more buffer as you suggest. Our cluster happens to be undergoing maintenance this week, so this particular job was killed. I'll update the GATK version, add --genomicsdb-shared-posixfs-optimizations, and adjust the memory. One other thing: i noticed GenomicsDBImport is not nearly as verbose in logging as typical GATK tools. Is that expected, or a symptom of whatever problem we're having?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-656259475:86,guid,guidance,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-656259475,1,['guid'],['guidance']
Usability,"@mlathara To those points:. - Yes, the test case I tried to make using GATK's test data doesnt show this. When I was working quickly I thought I repro'd it, but as you point out the REF bases for chr20:10-20 are actually Ns, so in this instance GenotypeGVCFs is doing the right thing. - Since my original posts, we figured out new information (posted above). When we simply do a SelectVariants on the genomicsDB workspace over these intervals, it produces a gVCF with Ns listed as the reference. In the actual reference, those sites are not Ns. That's making us look in a different direction than I originally thought. Our current plan is to remake one of our workspaces (exome data from ~800 samples) and see if this repros.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7018#issuecomment-755549351:367,simpl,simply,367,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7018#issuecomment-755549351,1,['simpl'],['simply']
Usability,"@mlathara and @nalinigans A couple quick updates:. - ReblockGVCFs reduced gVCF size by 5-8x as advertised. I re-ran this on our ~2000 gVCFs, which is possibly one of the main reasons for improvement below.; - This meant we needed to scrap all existing workspaces. As a side comment, the poor tools around manipulation of GenomicsDB workspaces is a pretty major disadvantage. Your guidance seems to suggest they are designed as a quasi-permanent store of gVCF data. Maybe I'm missing something, but this doesnt seem very workable anymore. Any need to modify any sample that went into the workspace means the whole thing needs to be re-created. For example, we also plan to re-generate some older gVCFs with the newer HaplotypeCaller at some point in the future, and doing this would also mean we need to scrap any existing workspaces. ; - For this round, I started with the 2000 gVCFs, and ran scatter jobs where each has ~1/750th of the genome, split more or less evenly (i.e. no attempt yet to intelligently design borders). Unlike before, each job creates the workspace on-the-fly, and then immediately uses it for GenotypeGVCFs. The workspace is basically a throw-away intermediate file. As far as computational time, this is not that bad (at least for very small intervals/job). I also did not bother running consolidate on these, and imported with a batchSize of 50.; - With the limited interval GenomicsDB workspaces, GenotypeGVCFs runs reasonably well. . So some open questions:. - It's unclear why running GenotypeGVCFs with a GenomicsDB workspace that has intact chromosomes, even when using -L over a small interval, fails to run or runs painfully slowly with extremely high memory. I will try to find time for actual profiling, but this is a little cumbersome since I'm not sure I can run this on my windows dev machine. As noted above, given how awkward maintaining genomicsdb workspaces is, I'm currently thinking that we should view these as transient stores and not bother saving them a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1220618297:380,guid,guidance,380,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1220618297,1,['guid'],['guidance']
Usability,"@mohitmathew Yes, we are still working on this! The PR is not yet in a usable state, but we intend to finish it for the next release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1680822021:71,usab,usable,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1680822021,1,['usab'],['usable']
Usability,"@mwalker174 ; Hi Mark, I've finished writing the tests and would you please check again?; Here's the log running the whole pipeline (the number of simple variants extracted is approximately 1.5X the number of complex variants):. ```; .... below is output for complex variants only; 23:09:25.288 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 1334 variants.; 23:09:25.288 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 1334; 23:09:25.289 INFO StructuralVariationDiscoveryPipelineSpark - INV: 0; 23:09:25.289 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 0; 23:09:25.289 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 23:09:25.289 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 0; 23:09:25.289 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 0; 23:09:25.289 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 0; 23:09:25.289 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 0; 23:09:25.289 INFO StructuralVariationDiscoveryPipelineSpark - INS: 0; ..... below is output from this tool; 23:09:48.167 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 688 variants.; 23:09:48.168 INFO StructuralVariationDiscoveryPipelineSpark - INV: 1; 23:09:48.168 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 125; 23:09:48.168 INFO StructuralVariationDiscoveryPipelineSpark - INS: 562; 23:09:48.168 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 0; 23:09:48.168 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 23:09:48.168 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 0; 23:09:48.168 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 0; 23:09:48.168 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 23:09:48.168 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 0; 23:09:48.215 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 1555 variants.; 23:09:48.216 INFO StructuralVariationDiscoveryPipelineSpark - INV: 21; 23:09:48.216 INFO StructuralVariati",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4602#issuecomment-389343644:147,simpl,simple,147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4602#issuecomment-389343644,1,['simpl'],['simple']
Usability,"@mwalker174 ; Thanks!. To answer you question about the END==POS insertion variants, . First quote the spec; > For precise variants, END is POS + length of REF allele - 1,. Now for simple insertions, the REF allele is a single base allele, which by the above definition forces be equal to POS. Second, if you look at the 4th variant (insertion) on page 11 of the spec version 4.2, END == POS. So I'm following the VCF spec. It's a little ambiguous as the spec doesn't give any example for replacements, i.e. some ref bases are replaced by other bases, so; * when the ref sequence being replaced is <50bp, I emit ""fat insertion"", as documented here. ; * when the replaced region is >49 bp, a DEL call is emitted.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4602#issuecomment-391559827:181,simpl,simple,181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4602#issuecomment-391559827,1,['simpl'],['simple']
Usability,"@mwalker174 If the reads in your bam are failing `WellFormedReadFilter`, then the GATK (generally speaking) can't handle them. Reads must pass at least that filter in order to be usable by GATK. Are you able to modify the bam to add read groups, etc., to allow the bam to pass the filter? If not, it is theoretically possible to disable `WellFormedReadFilter` using the `--disableReadFilter` argument, but I don't recommend it...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2219#issuecomment-254623625:179,usab,usable,179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2219#issuecomment-254623625,1,['usab'],['usable']
Usability,"@nalinigans For AD, I don't think we care about the distinction between '.' and 0. If AD is the only problematic field, and we're not seeing any issues with PL or any other attribute, then I'd advocate for a simple '.' -> 0 translation (for AD only!) within GenomicsDB, if such a thing is possible. @ldgauthier do you agree?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6744#issuecomment-676514387:208,simpl,simple,208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6744#issuecomment-676514387,1,['simpl'],['simple']
Usability,"@nalinigans I will see how feasible that is on our cluster. Another question: I'm still baffled at the sort of issues we keep having if GenomicsDB is really used that widely. One question: I have been viewing the aggregated workspace as a semi-permanent store (more like a database). Rather than that, do most users just make the workspace on-the-fly, use it immediately, and then discard? I was thinking overnight about this, and I'm wondering if we should simply drop the idea of even trying to make workspaces with whole chromosomes. I *think* we could scatter 1000 jobs for the genome, give each a coordinate set, then import the 2000 gVCGs into a workspace of only 2m sites or so, do GenotypeGVCFs, and discard that workspace, and then merge all those VCFs. I thought in the past I read guidance that the GenomicsDB workspace needed to import intact contigs. However, if the only downstream application is to run GenotypeGVCFs on a the same targeted region, is there any reason that woudlnt work? I would hope that running GenomicsDbImport with -L would import any gVCF variant overlapping that interval, and therefore I dont think subsetting to a partial chromosome would matter. Any comments on this would be appreciated.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1212078765:458,simpl,simply,458,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1212078765,2,"['guid', 'simpl']","['guidance', 'simply']"
Usability,"@nalinigans Yes, it's been surprising me quite a bit too. When you say 'can you run SelectVariants', do you mean simply trying to select from the source GenomicsDB workspace as a test to see if java has enough resources? I can try this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1201585570:113,simpl,simply,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1201585570,1,['simpl'],['simply']
Usability,"@nalinigans on a related perf question: there are posts about workspaces with lots of small contigs being a problem. There are some recommendations out there about creating multiple workspaces where each has one contig or a subset of contigs. Can you say any more about where that overhead comes from?. Given we have an existing multi-contig workspace, and aggregating this many samples into a workspace is pretty big task, are there any ways to separate the existing workspace into a bunch of single-contig workspaces? The only metadata that I see referring to contigs is vidmap.json. For example, subsetting a workspace could be something simple like this:; ```; # DB refers to the original, and LOCAL_DB is a copy with just one of the contigs:; mkdir $LOCAL_DB; cp ${DB}/__tiledb_workspace.tdb ${LOCAL_DB}/; cp ${DB}/callset.json ${LOCAL_DB}/; cp ${DB}/vcfheader.vcf ${LOCAL_DB}/; cp ${DB}/vidmap.json ${LOCAL_DB}/; ln -s ${DB}/20\$1\$77137495 ${LOCAL_DB}/; ```; Using this subset workspace seems to execute just fine as an input for SelectVariants.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1211342015:641,simpl,simple,641,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1211342015,1,['simpl'],['simple']
Usability,@nalinigans thank you very much! do you have any guidance on what a reasonable batch size might be?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1081056829:49,guid,guidance,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1081056829,1,['guid'],['guidance']
Usability,@nh13 I wrote a test for your branch (its very simple it just reruns the gvcf mode tests with --disable-optimizations enabled) that should work for your branch. Its in the branch je_addTestForDisableOptimizations. Since you submitted this PR from your own clone of the GATK I cannot push this onto the branch as it stands. Would you be able to copy it into this branch?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7125#issuecomment-793077846:47,simpl,simple,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7125#issuecomment-793077846,1,['simpl'],['simple']
Usability,"@nh13 in particular should give feedback on whether these guidelines are useful, or if additional clarity is needed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/382#issuecomment-93779237:32,feedback,feedback,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/382#issuecomment-93779237,2,"['feedback', 'guid']","['feedback', 'guidelines']"
Usability,"@obigriffith Right, but the expression you cited did reference attribute(s) that don't exist in the variants you cited as not being filtered (I'm not saying its intuitive, just that this explains whats happening). . i.e. I think you cited this variant:. `chr6 54228213 . A G 412.77 PASS AC=2;AF=1.00;AN=2;DP=12;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=52.55;QD=28.71;SOR=3.442 GT:AD:DP:GQ:PL 1/1:0,11:11:33:441,33,0`. as not being filtered when used with this expression:. `""QD < 2.0 || FS > 60.0 || MQ < 40.0 || MQRankSum < -12.5 || ReadPosRankSum < -8.0 || SOR > 3.0""`. Even though this has an SOR value that meets the filter criteria, the expression is short-circuited when applied to that variant because it has no `MQRankSum` attribute. This results in a PASS. If you have a counter example, or I'm missing something, please do let me know.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5362#issuecomment-436040103:161,intuit,intuitive,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5362#issuecomment-436040103,1,['intuit'],['intuitive']
Usability,@pawel125 This looks like a filesystem error - `I/O error in the advisory file locking logic (disk I/O error)`. Are you using an NFS file system to store the datasources or some other kind of network-mounted drive?. To be clear - the first issue you had was **not** a typo. The v1.7 data sources are not backwards compatible and the code changes haven't been merged yet.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6708#issuecomment-661885327:222,clear,clear,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708#issuecomment-661885327,1,['clear'],['clear']
Usability,"@pgrosu, would you like to try your hand at writing a minimal repro for the bug? This would be useful, and this doesn't require signing anything. You could then submit it as a bug report (or to SO for feedback first).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107694945:201,feedback,feedback,201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107694945,1,['feedback'],['feedback']
Usability,"@pieterlukasse Yeah - I'm planning on updating some of the Funcotator core to be more permissive for input data types and to fix a few long-standing bugs, but have been unable to do so because of other high-priority tasks (as @lbergelson said). The output formats are pretty well-established, so I don't think there's any risk in writing an additional parser. However if you simply want to view the outputs, you can render the annotations in `MAF` format and that will produce a `MAF` (TSV) file that is much more easily viewed / parsed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8154#issuecomment-1379018376:375,simpl,simply,375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8154#issuecomment-1379018376,1,['simpl'],['simply']
Usability,@pogodina-nadezda This is expected behavior but it's unintuitive and not necessarily ideal. ; The AD is calculated based on the best match of each read to each possible haplotype during assembly. It's not based on the pileup at the site. So a read that has no quality at a site might still be counted towards that site if it matches the relavent assembled haplotype better than any alternative one during the read scoring phase. . @jamesemery This is the second time in 2 days that we've had questions about this though so it's clearly confusing and maybe not the best solution.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/9014#issuecomment-2432448921:528,clear,clearly,528,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/9014#issuecomment-2432448921,1,['clear'],['clearly']
Usability,"@ronlevine I know this a port from gatk3, but I think theres a bit of refactoring that can be done. It seems like it's more complicated than it needs to be. Could you take a look and see? In particular I'm not sure why things get converted to a bitset, it looks like you should just be able to derive the indecies directly and avoid creating a bitset. If I'm missing some detail and it can't be simplified let me know.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1852#issuecomment-242102049:395,simpl,simplified,395,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1852#issuecomment-242102049,1,['simpl'],['simplified']
Usability,"@samuelklee . The CNLoH are probably artifacts (faux-CNLoH) -- I think I misdiagnosed. However, there are other changes in this PR and we can always disable the faux-CNLoH pruning by default (there is a flag). Additionally, artifact or not, it is useful to remove the faux-CNLoH. Users are already using this branch and giving me positive feedback (definitely more positive than adjusting num_changepoints_penalty_factor). I suggest merging mostly for practical reasons. It buys us more time to put in a principled solution. And this workflow is clearly marked as an unsupported prototype anyway (as are the GATK CLIs). I want to emphasize that this whole workflow is not a long-term solution. In other words, I would like to get this in and then focus on a supported solution. Two comments: ; > If these events were indeed not CNLOH, as we discussed, then I don't think we should merge this. Perhaps we should take a step back and answer definitively whether simply blacklisting common germline regions is enough to replicate/obviate most of the postprocessing. Should be straightforward to run an evaluation with and without blacklisting---and hopefully our truth data accurately reflects whether blacklisting is desirable. There are definitely events that get missed without the germline tagging, so this is an improvement over blacklisting alone. And while I have seen erroneous germline tagging (i.e. false calling a segment germline), it was only ever due to really noisy data (e.g. a bad PoN) or a poorly tuned segment caller. I am pretty sure that most common germline regions are being blacklisted already. The hotspots addressed in this PR (faux-CNLoH) could be added, but I think we will find new areas and a few of these areas were rather big. I have users that are actively using this from the branch, for reasons other than the faux-CNLoH pruning. Results are improving without an appreciable hit to sensitivity, which we got when using parameters like num_changepoints_penalty_factor. A",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461258874:339,feedback,feedback,339,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461258874,3,"['clear', 'feedback', 'simpl']","['clearly', 'feedback', 'simply']"
Usability,"@samuelklee ; My understanding: the code that **can** (and I think should) be borrowed from VCF is `CHROM`, `POS`, `ID`, `INFO`, with `END` from `INFO` extracted to be its own column. ; Then; * `FILTER` can be optional.; * `QUAL` can be optional but it is a nice-to-have feature as a quick-glance confidence measure, if that applies.; * `FORMAT` is going to be hard, because I understand the complaint that they can be wasting space, but I have seen VCF files that have rows with different numbers of fields in `FORMAT`, and that is spec-compliant. If this flexibility is allowed, i.e. allowing sample specific information to be missing on several rows, then the `FORMAT` column can be shared. Recap: only `REF`, `ALT` are missing, which is not much code I believe. I think VCF just happens to have a name that starts with V. Stripping out the `REF`, `ALT`, it is quite flexible for describing any annotated interval (OK, 0-length is up for debate) on a piecewise linear coordinate. And I just made myself sound like a VCF-lover. I simply think much of it can be reused.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-481753416:1032,simpl,simply,1032,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-481753416,1,['simpl'],['simply']
Usability,"@samuelklee DRAGEN STRE model doesn't actually make any alterations to the smith waterman parameters or how they work, it just works by adjusting the indel gap penalties that are used for the PairHMM. At one point we were concerned about SW parameters being different with dragen but as it turns out the biggest visible effect of the SW parameters on the output (the alignment we perform after haplotypes discovery) is irrelevant since they don't realign their reads internally. We kept the default gatk alignment behavior and thus the SW parameters that are used (for dangling head recovery which I believe are the old arguments) still match. As far as unifying the parameters I suspect it could be done though one wonders if there aren't risks where the different contexts in which we use the parameters will not perform as well with a unified set. Speculation on my part though. I agree with David that we should be cautious about making changes that will affect the HaplotypeCaller before November. . I support including an argument in any case (possibly multiple) to include the SW parameters. I would actually advocate we read these files in as tables of parameters where you simply point to on the command line to configure new parameters.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705611993:1182,simpl,simply,1182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705611993,1,['simpl'],['simply']
Usability,@samuelklee Expanded on your feedback. Let me know if the changes are okay.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3157#issuecomment-311458151:29,feedback,feedback,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3157#issuecomment-311458151,1,['feedback'],['feedback']
Usability,"@samuelklee I agree with your comments, but if **arbitrary** type of annotations are allowed, especially when multiple values (lists) are allowed, then it is going to look very like VCF. I was simply pre-warning.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-481322968:193,simpl,simply,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-481322968,1,['simpl'],['simply']
Usability,"@samuelklee I support exposing these parameters via the command line, but I'd be opposed to any consolidation of parameters that changes the HaplotypeCaller output prior to the initial DRAGEN-GATK release in November, as the evaluations in that project are difficult enough as it is. If you want to do an evaluation to find the best set of SW parameters now, that's fine of course -- but we wouldn't be able to actually merge any breaking HaplotypeCaller changes until after the November DRAGEN-GATK release, and we'd also have to check whether the proposed changes affect the functional equivalence of GATK and DRAGEN (we're developing tests now that can check this). If you want to expose the SW parameters on the CLI now, I think 12 arguments is fine. Just give each argument a clear prefix indicating what it applies to (eg., `--read-to-haplotype-mismatch-penalty`). If a user has gotten to the point where they feel the need to mess with the SW parameters, their command line is probably already long and complex as it is, so adding a few additional arguments won't ruin their day.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705081291:781,clear,clear,781,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705081291,1,['clear'],['clear']
Usability,"@samuelklee I think it's right for what we're doing. We mount the test data as `/testdata` and then create a symlink from src/test/resources to /testdata to provide it to the test files. It seems to work.; ; I'm not clear what they get more of the other way around. More tests? Are they using our create docker script? Or our travis file? Or something else? I think we might just be able to just directly mount test data to src/test/resources and avoid the symlink, but I probably had a reason when I set it up that way... I think this is a non-issue unless they can provide more information.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3730#issuecomment-339439156:216,clear,clear,216,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3730#issuecomment-339439156,1,['clear'],['clear']
Usability,"@samuelklee I'd say lets leave 2.1 base image up there for now, and yes on the cache clearing. Once tests pass with the cache cleared it should be good to merge. Feel free to squash and rebase if you like.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5040#issuecomment-408453109:85,clear,clearing,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5040#issuecomment-408453109,2,['clear'],"['cleared', 'clearing']"
Usability,"@samuelklee I've incorporated your feedback and will make a new commit that reflects these shortly. Also, as mentioned in one of the comments above, the two notebooks are on the forum now at:; - [Notebook#11685](https://gatkforums.broadinstitute.org/gatk/discussion/11685/) ; - [Notebook#11686](https://gatkforums.broadinstitute.org/gatk/discussion/11686/) . Please let me know if these are okay with you. Again, most of the content should be familiar to you as I've just condensed and reorganized the explorations I had previously shared with you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5829#issuecomment-478403475:35,feedback,feedback,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5829#issuecomment-478403475,1,['feedback'],['feedback']
Usability,"@samuelklee It wasn't just a rebase, it was a complete rewrite because the old code had since become completely entangled with DRAGEN code. But I did it! Everything is passing, the code is dramatically simpler, and it's even a bit faster. I have done my best to make a coherent commit history. I would recommend reviewing one commit at a time in side-by-side diff mode. Note that some commits rip out old code and replace it with pseudocode, deferring the new code to a later commit. Other commits tell a story of what all the different caches meant in order to motivate the simpification of later commits. The baroqueness of the old code was motivated by three considerations:; * cache-friendliness -- traversing all arrays by incrementing the innermost index, reads. This is absolutely essential.; * flattening 3D arrays into 1D arrays. This was a premature optimization.; * Precomputing addition operations -- this was misguided. The DRAGEN code relied on these caches in a rather complex way, which fortunately turned out not to be necessary and which could be dramatically simplified. My notes on tracking all the variables from the parent genotype calculator down to the DRAGEN calculator are in this google doc: https://docs.google.com/document/d/1v6s57mUAwfj38nL3VdktjA059kYBkJfokq18IDy79E8/edit?usp=sharing. Good luck and don't hesitate to ask me to explain anything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1023647476:202,simpl,simpler,202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1023647476,2,['simpl'],"['simpler', 'simplified']"
Usability,"@samuelklee Now it's back to you. I agreed with and implemented all of your suggestions. `GenotypeIndexCalculator`, `GenotypeAlleleCounts`, `GenotypeLikelihoodsCalculator` and `GenotypeLikelihoodsCalculator` (renamed to `GenotypesCache`) now have clearly-defined roles. A lot of premature optimization is gone.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1068695779:247,clear,clearly-defined,247,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1068695779,1,['clear'],['clearly-defined']
Usability,@samuelklee See upcoming WDL convention guide for GATK repo.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4072#issuecomment-355870160:40,guid,guide,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4072#issuecomment-355870160,1,['guid'],['guide']
Usability,"@samuelklee Since currently there is no tools available, I am trying to combine the CNV at interval level first. But I don't understand very clearly what the GT (genotype) 0,1,2 and CN (0,1,2,4) indicated in gVCF result. Should I filter out all entries with GT not equals to 0 as CNV events?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5373#issuecomment-434476283:141,clear,clearly,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5373#issuecomment-434476283,1,['clear'],['clearly']
Usability,@samuelklee Sounds like a perfect application and a lot simpler than my fix. Hopefully your rapid prototype will be faster too.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2746#issuecomment-319178018:56,simpl,simpler,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2746#issuecomment-319178018,1,['simpl'],['simpler']
Usability,@samuelklee Thanks for yor help. I created the ython package and could set up the conda environment. I activated it and run the command for DetermineGermlineContigPloidy again. Now it`s running :-). Thanks again for you very quick respons and high quality help! I am realy looking forward to the BestPractice guide for GermlineCNV calling. Thanks to all. ; I will close this issue now.; Stefan,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357234489:309,guid,guide,309,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357234489,1,['guid'],['guide']
Usability,"@samuelklee The module can now save and load everything, including the state of the optimizer. This allows to making interesting inference pipelines. Here's a decent strategy for obtaining the global optimum (it works flawlessly on simulated data every time):. - In the first pass, one disables annealing and obtains the variational parameters in a thermal state. The temperature needs to be _high enough_ to allow most/all local minima to merge, though, not too high to allow copy numbers to travel too far away from baseline copy numbers. If this occurs, one must anneal very slowly in the next stage (see below). The results are checkpointed once converged. - In the second pass, one makes another call to the CLI tool, this time w/ annealing enabled (starting from the same temperature) and starting from the checkpointed thermal results (model params, posteriors, adam(ax) state). The annealing rate must be slow enough to prevent thermal fluctuations from getting quenched (i.e. the evolution must be quasi-isothermal). One must look for a steady and linear rise of ELBO, such that when the annealing protocol ends, SNR quickly drops to values below 1. In both runs, the learning rate must be very small (in the rate 0.01-0.05) such that we wouldn't have to worry about controlling stochastic noise. Adam(ax) quickly adjusts its moment estimates and compensates for the small learning rate, so this doesn't increase the training time significantly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-347369020:1177,learn,learning,1177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-347369020,2,['learn'],['learning']
Usability,"@schaluva Could I get access to a bam for that chromosome or some smaller interval that exhibits the bug and the original, non-simplified germline resource VCF? I think the error in filtering has been fixed, so I'm focusing on the first error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6098#issuecomment-530090255:127,simpl,simplified,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6098#issuecomment-530090255,1,['simpl'],['simplified']
Usability,"@schelhorn @ddrichel Thanks for evaluating the new PON, and sorry that it didn't resolve the precision issue! I agree that in an ideal world where grant-imposed deadlines didn't exist, and we had unlimited developer resources, fixing the issue in M2 would be the best path forward. Since we unfortunately don't live in that world, and are unlikely to have developer bandwidth to work on this issue in the near future, let me suggest an alternate path:. Since you are satisfied with the output of 4.1.8.1, and are only prevented from running that version by the log4j issue, I think your best option for now is to run a build of 4.1.8.1 with the log4j vulnerability patched out. This is very simple to create, and just involves changing the log4j version in our build file and rebuilding GATK. If you'd like to pursue this option, we'd be happy to create such a build for you, or provide instructions for creating it yourself if you prefer.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1535175016:691,simpl,simple,691,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1535175016,1,['simpl'],['simple']
Usability,"@shuaiwang2 Hi, we don't currently support indexes that long. We use a bai index for bams and tabix for vcf which only support up to 512 M. You need to use a CSI index for references that large but we don't support writing those. (Reading them is weird, I think we can read BAM csi indexes but not VCF ones). . It might be possible to work around this issue by setting `--create-output-variant-index false`, although downstream gatk tools would need an index if you're sharding them. Otherwise I recommend splitting your chromosomes into two separate parts and calling on the split chromosomes. Splitting along a long region of N's should be a safe way to avoid missing any useful calls. (The telemere might be a good spot unless you have a T2T reference.). . We should probably improve that error message to make it clear what the problem is.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8192#issuecomment-1422828609:817,clear,clear,817,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8192#issuecomment-1422828609,1,['clear'],['clear']
Usability,"@sooheelee Anyone on engine team is a good bet to ask for a review for simple documentation changes like this. For more tool specific complex documentation changes, the tool author/maintainer is probably best.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5658#issuecomment-462371578:71,simpl,simple,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5658#issuecomment-462371578,1,['simpl'],['simple']
Usability,"@sooheelee I think we should be able to hit Jan 9 for what I've been calling the ""ModelSegments"" pipeline, in terms of getting the new code merged into master. It will be ready to go for WGS. However, it's hard to say whether or not we'll have completed internal evaluations of this pipeline by then. These will be necessary to identify good default values for parameters that will affect sensitivity. @LeeTL1220 and @katevoss are helping out here. @MartonKN is also beginning work on an improved caller, which could potentially replace the current one before release. As for gCNV, @asmirnov239 and I will be helping @mbabadi get the python version wrapped in Java. We should be able to get at least cohort-calling mode in by release. Case calling can come shortly after if we don't manage to get it in as well. Here, we are relying a bit more on external groups to run evaluations and provide feedback, but we will do what internal evaluations we can before release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3769#issuecomment-341271339:894,feedback,feedback,894,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3769#issuecomment-341271339,1,['feedback'],['feedback']
Usability,@stefandiederich Thanks for reporting this. We'll have to take a look if it's something simple that can be changed in our code or something fundamental in the way spark process filenames.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4337#issuecomment-363122927:88,simpl,simple,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4337#issuecomment-363122927,1,['simpl'],['simple']
Usability,"@stefandiederich, I think this is a problem with how your BED file is being interpreted. In general, with GATK, it's best to use 1-based coordinates intervals, e.g. that of a [Picard-style interval_list](https://gatkforums.broadinstitute.org/gatk/discussion/1319/collected-faqs-about-interval-lists). BED is 0-based. See https://www.biostars.org/p/84686/ for a clear illustration of the differences. . If provided a BED file, i.e. an intervals list with `.bed` extension, GATK will convert it to the expected 1-based format. So, if `chr2 29430911 29430911` is 0-based BED, then conversion to 1-based would yield `chr2 29430912 29430911`, making the stop less than the start as the error message says. . It seems though that your intervals are actually already 1-based, not 0-based (which the BED format implies). Make sure your coordinates are expected and try changing the file extension.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4504#issuecomment-371144113:361,clear,clear,361,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4504#issuecomment-371144113,1,['clear'],['clear']
Usability,"@t-ogasawara @frank-y-liu @gspowley @paolonarvaez @droazen @lbergelson please comment on the following proposal. The proposal is that we would spin off native PairHMM as a separate project/repo on github and host AVX code there and have alternative implementations extend that project/repo (by creating repos that depend on the AVX one). . In other words, now we have 1 repo, broadinstitute/gatk. After the proposed change we'll have 3 repos (all BSD licensed):; 1) broadinstitute/gatk; 2) broadinstitute/nativePairHMM-AVX; 2) broadinstitute/nativePairHMM-PPC. We will duplicate the native code (AVX and PPC will be separate copies of C++ files etc) to simplify the testing burden. The parties interested in working on a specific architecture will contribute code directly to the respective architecture-specific repo and gatk will take occasional updates of those repos. The gatk repo will depend on the other two. The PPC repo will depend on the AVX repo (and any other native repos will depend on the AVX one). The avx and ppc repos will have their own build systems and unit tests against the new interface. The AVX repo will expose something like the following Java API (to be worked out in detail). ```; //Used to copy references to byteArrays to JNI from reads; public final class JNIReadDataHolderClass {; public byte[] readBases = null;; public byte[] readQuals = null;; public byte[] insertionGOP = null;; public byte[] deletionGOP = null;; public byte[] overallGCP = null;; }. //Used to copy references to byteArrays to JNI from haplotypes; public final class JNIHaplotypeDataHolderClass {; public byte[] haplotypeBases = null;; }. public interface NativePairHMMKernel extends AutoCloseable { . /**; * Function to initialize the fields of JNIReadDataHolderClass and JNIHaplotypeDataHolderClass from JVM.; * C++ code gets FieldIDs for these classes once and re-uses these IDs for the remainder of the program. Field IDs do not; * change per JVM session; *; * @param readDataHolderClass class",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-214914864:653,simpl,simplify,653,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-214914864,1,['simpl'],['simplify']
Usability,"@takutosato @davidbenjamin ; This is a fairly simple addition, either of you interested, or have any thoughts about how this should be done?. We have a task like this in the liquid biopsy pipeline already, it might be nice to refine it too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6692#issuecomment-653148645:46,simpl,simple,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6692#issuecomment-653148645,1,['simpl'],['simple']
Usability,"@takutosato To be clear, this issue is from a year ago, and I'm just confirming that we can close it. This is not new bug behavior. No action required on your part besides what you just said.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3944#issuecomment-443743151:18,clear,clear,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3944#issuecomment-443743151,1,['clear'],['clear']
Usability,"@takutosato had a good suggestion: to stratify to low-complexity regions in the high-confidence regions. Not sure how many variants are there, but will take a look. EDIT: looks like it's ~5k / ~54k on chr22 in CHM. More generally, I think that defining the appropriate loss function for optimization to set ""default"" parameter values obviously has no unique answer. The problem is also made a little more complicated by our current strategy of sensitive calling + non-trivial filtering. But it would be great to come up with some hard constraints (e.g., we never want runtime/cost to exceed X, we always want to maintain Y metrics in these regions on these samples) and general procedures, then apply them as equitably as possible across all method/parameter changes. Also generally, I'm a bit wary of focusing too hard on the high-confidence regions, as this might lead to overfitting or could understate the potential of method/parameter changes in more difficult regions. But probably we'll have to downweight the loss or do more manual checks in low-confidence regions until we improve truth resources there. One naive question, just want to double check: is it correct that the overall scaling of each set of SW parameters is inconsequential? E.g., if I multiply each by a constant, should I expect the same results? I would expect this to be the case (unless my hazy recollection of the details of SW scoring is off) and simple experiments bear this out, but I'm not sure if there are some edge cases or idiosyncrasies in our implementation or use of the scores that I might be missing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-714570055:1427,simpl,simple,1427,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-714570055,1,['simpl'],['simple']
Usability,"@tedsharpe , please feel free to review as well. This to me is more about learning than reviewing, though I'll try hard.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1939#issuecomment-228442132:74,learn,learning,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1939#issuecomment-228442132,1,['learn'],['learning']
Usability,@tedsharpe @SHuang-Broad I've tried to address your comments -- want to have a another look? . Due to issues in the class I backed out my usage and refactoring of SATagAlignmentBuilder and SATagAlignment and just went with my own simple little parser.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2684#issuecomment-301569060:230,simpl,simple,230,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2684#issuecomment-301569060,1,['simpl'],['simple']
Usability,"@tedsharpe I've addressed some of your comments here -- all the simpler stuff plus:. - I now only make distal targets for split reads with one supplementary alignment. We can make a ticket to handle more complex cases at some point.; - I renamed the concept of strand in the `EvidenceTargetLink` and related classes -- I'm now calling it `evidenceUpstreamOfBreakpoint`.; - I canonicalize `EvidenceTargetLinks` and only create them when the source is upstream of the target. This allowed me to get rid of the de-duplication code, so thanks for the suggestion. It seemed tricky to me to try to cluster these links during the initial pass over the reads while at the same time keeping track of coherent evidence. In my testing it doesn't seem like it is slow to run over the `EvidenceRDD` again to do this, but we could think about trying to change this sometime if we're looking for optimizations. . Want to take another look?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3469#issuecomment-328300806:64,simpl,simpler,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3469#issuecomment-328300806,1,['simpl'],['simpler']
Usability,"@tfenne I'm not sure we quite expect every site in the provided intervals to be covered by a variant or homeVar call. If the HaplotypeCaller deems a site to be active then it is assembled and genotyped, the `EMIT_ALL_SITES` switch is applied to the genotyper and prevents the genotyper from returning a null variant context at sites that are clearly not real variants. That does not however mean that sites that never make it to the genotyper will get returned. That means activityRegions that are not considered sufficiently active to be assembled will still not be covered in the output in `EMIT_ALL_SITES` mode. Perhaps the docs could be updated to better reflect this? If you want an estimate of the reference confidence for non-variant sites perhaps you should use a GVCF instead?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6059#issuecomment-530533223:342,clear,clearly,342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6059#issuecomment-530533223,1,['clear'],['clearly']
Usability,"@tomwhite @davidadamsphd could you take a look and see if it's in the right direction?. Some notes:; - This is only impl'd for pure Spark at the moment. Gonna work on adding support for dataflow as well.; - It was easier to remove the `final` modifier on the `GATKRead` impl rather than reimplement all the methods and simply pass them through. Let me know if that's ok.; - Should we target Parquet IO only in the context of writing to Hadoop? Or should I make sure it works anytime a local/single bam file is being written?; - Definitely need to add more tests. One thing that's annoying is that the cleanup for `readsSinkParquetTest` doesn't seem to happen.; - Registered `AlignmentRecord` with the `GATKRegistrator`, but there aren't any tests that exercise it. There's a touch of scala-to-java ugliness there, so let me know if we should just reimplement the `AvroSerializer` class.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/888#issuecomment-139423282:319,simpl,simply,319,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/888#issuecomment-139423282,1,['simpl'],['simply']
Usability,"@tomwhite I just took a look and I did overstate the case when I said CramContainerIterator materializes SAMRecords. It stops short of doing that, but it does crack each container open and iterate through and decompress each data block in each slice in each container as it goes along. Its not clear to me how much this affects the difference in split calc time vs. bam.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-374324770:294,clear,clear,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-374324770,1,['clear'],['clear']
Usability,"@tomwhite I'm looking into the performance issues now with the new code path -- it brings the output much closer to GATK3, but clearly needs some profiling work. Can you tell me what kind of difference you saw in the runtime on Spark? Eg., was it on the order of 20-30%, or was it worse than that?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3533#issuecomment-330905564:127,clear,clearly,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3533#issuecomment-330905564,1,['clear'],['clearly']
Usability,"@tomwhite That sounds like a pretty good improvement! For reasons that are not clear to me, htsjdk doesn't generate .crai index files, only .bai, so we'd definitely want something like the CramContainerHeaderIterator method for those. One other thought that occurs to me is that we should think about how to ensure that mates are kept together for CRAM. The spec doesn't require that mates be contained in the same slice, and since the default slices-per-container for both htslib and htsjdk is 1, they don't even have to be in the same container.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-379034481:79,clear,clear,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-379034481,1,['clear'],['clear']
Usability,"@tomwhite To clarify, I think that the caller of `ensureCapacity()`, namely `GenotypeLikelihoodCalculators.calculateGenotypeCountUsingTables()`, also needs to be synchronized in order to avoid some unlikely but still-possible races. Given this, I think that we should consider whether `ThreadLocal` might be a better option here. It's not 100% clear to me whether a `ThreadLocal` `get()` call is cheaper than a synchronized method call, but some casual googling suggests that it might be. If we're going to end up entering a synchronized method on every single call to `GenotypeLikelihoodCalculators.getInstance()`, we might want to do some research into whether `ThreadLocal` + no synchronization would be faster, since I believe that this is a performance-sensitive section of code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5071#issuecomment-422171244:344,clear,clear,344,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5071#issuecomment-422171244,1,['clear'],['clear']
Usability,"@tomwhite We host our internal WDLs for the best practices pipeline in the dsde-pipelines repository, and we're starting to put public versions in the public repo https://github.com/broadinstitute/wdl. @vdauwera recommends that we put any WDLs we write for GATK4 in https://github.com/broadinstitute/wdl as well, but within a directory that clearly marks them as experimental/unsupported.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1974#issuecomment-231770124:341,clear,clearly,341,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1974#issuecomment-231770124,1,['clear'],['clearly']
Usability,@tomwhite and/or @laserson should have a look at this and give JP high-level feedback on his approach to optimization.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/987#issuecomment-146905889:77,feedback,feedback,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/987#issuecomment-146905889,1,['feedback'],['feedback']
Usability,@tomwhite this looks fine to me as a start for us to experiment with but I wish the install was simpler and so we should either include building of jbwa as part of our build or (preferable) use a pre-built version from maven central. wdyt?. back to @tomwhite,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1750#issuecomment-215795846:96,simpl,simpler,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1750#issuecomment-215795846,1,['simpl'],['simpler']
Usability,"@tovanadler Review complete. Looks good, just a few comments. I have a few comments about the organization of duplicate marking. I think you've inherited some very old style code that could maybe use some refactoring. I think we do need to also include the histogram and the metrics headers. Those could be done in a separate ticket though. I'm a bit worried that the test is indeterministic. Unless I overlooked something which is likely, it seems like it might depend on the ordering of a PCollection which is undefined. This isn't problematic for the actual metric file, but might be for the tests. What do you think about reorganizing to output an annotation on only 1 of the ""best"" reads with the count of all optical duplicates in it's group. That would simplify the code, and since we only care about the global count it wouldn't change the information content.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/749#issuecomment-126762958:760,simpl,simplify,760,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/749#issuecomment-126762958,1,['simpl'],['simplify']
Usability,@tovanadler Thanks for the update. It's clearer this way. Do you know how the Combine.perKey is implemented? Will it scale? I'm afraid it's going to try and pulldown all metrics in a library to a single node and then iterate through them all.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/782#issuecomment-128095847:40,clear,clearer,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/782#issuecomment-128095847,1,['clear'],['clearer']
Usability,@ttbek I see your point and thank you for bringing this up. Based on your feedback we are going to create an article to better explain common GATK file types and input file formats. Sorry about the inconvenience and please continue to share your valuable feedback with us.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6639#issuecomment-640927891:74,feedback,feedback,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6639#issuecomment-640927891,2,['feedback'],['feedback']
Usability,"@vdauwera - I think that makes sense. We've been brainstorming ideas for how a user would actually input the filter strings and there seem to be a few options. - JEXL; - it's already in use elsewhere and we can use JEXL functions at the command-line to specify ""hasAtLeast(5,""D"")"" for simple filters, but it seems like it would get clunky with increasing filter complexity; - Regular Expressions; - they're fairly universal, but it would be hard to match numerical values and can be confusing/exhausting to write correctly; - Modified regular expressions, for example:; - ^D matches any number of deletions at the start; - DMD matches any number of deletions followed by any number of (mis-)matches, followed by any number of deletions; - ^<5SM>=4D$ matches less than 5 soft clipped bases at the start of the cigar, followed by any number of (mis-)matches, followed by at least 4 deletions at the end of the cigar; - Command-line options passed into the filter, for example:; - --hasAtLeast 5 D --startsWith S --endsWith M. We can also implement some combination of these. What do you think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/588#issuecomment-308850737:285,simpl,simple,285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/588#issuecomment-308850737,1,['simpl'],['simple']
Usability,"@vdauwera -- just to be clear, this is only in GATK 4 M2, which is pre-release (but we're working as fast as we can).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2291#issuecomment-272664743:24,clear,clear,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2291#issuecomment-272664743,1,['clear'],['clear']
Usability,"@vdauwera Thanks for the guidance. We'll get to work. @takutosato, you were also wondering about this. Here's our answer.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2596#issuecomment-328628951:25,guid,guidance,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2596#issuecomment-328628951,1,['guid'],['guidance']
Usability,@vdauwera The latest game plan for this ticket (which is being addressed in #2021) is to have SplitNCigarReads create a supplementary alignment from each split and soft clip the bases that align elsewhere. This allows the bam to be more usable by other tools (like BQSR) since the logic to handle supplementary reads already exists. This means that we need an additional argument to HaplotypeCaller so that allows using supplementary alignments (See #2043). . My question is how can we document that SplitNCigarReads is not recommended for use with the changes to make the reads supplementary until #2043 is resolved? Is it possible to make the tool hidden in GATK4 or give it some tag that makes it clear it isn't ready for use yet?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1394#issuecomment-235062440:237,usab,usable,237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1394#issuecomment-235062440,2,"['clear', 'usab']","['clear', 'usable']"
Usability,@vdauwera any feedback from GATK 3.7 users? @droazen how's the Palantir tie-out doing?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2255#issuecomment-272495952:14,feedback,feedback,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2255#issuecomment-272495952,1,['feedback'],['feedback']
Usability,@vdauwera wouldn't it be simpler to have those docs on the github page?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1049#issuecomment-151706338:25,simpl,simpler,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1049#issuecomment-151706338,1,['simpl'],['simpler']
Usability,"@vidprijatelj Thanks for the report! Can you check the UMASK value in your shell? You can do this by simply typing the command `umask`. If it's set to something like 0077, that could explain what you're seeing. . GATK does not, in general, require permissions for users other than the owner of the file/directory, so it's a bit surprising that this is causing issues for you. Could you paste the full stacktrace for the exception you're getting? You may need to set `GATK_STACKTRACE_ON_USER_EXCEPTION=true` in your environment in order to get GATK to print the stack trace.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8233#issuecomment-1466807447:101,simpl,simply,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8233#issuecomment-1466807447,1,['simpl'],['simply']
Usability,"@vilay-nference Thank you for doing this work. It's nitpicky annoying stuff to figure out.; ; I have one additional request. Instead of addding additional direct implementation dependencies, could we specify the transtive version requirements in a [gradle constraints block](https://docs.gradle.org/current/userguide/dependency_constraints.html)? . That will: ; 1. make it clear that we don't rely on these directly; 2. prevent us from keeping them around if we do something like remove hadoop in the future; 3. lets us rewrite those force blocks to instead define minimum versions so if the libraries move forward in the future we're not accidentally holding on a to an old version",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8950#issuecomment-2297074810:373,clear,clear,373,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8950#issuecomment-2297074810,1,['clear'],['clear']
Usability,"@vruano This is so much clearer now. Much better to write your own search function that does what you want than to use the existing one with an invalid comparator and rely on the implementation to stay the same. . The only issues left I think are to create a comparator in SimpleInterval and just use that, instead of having a lot of them scattered all over the place. I think they're all compatible with doing the same thing sorting first by contig, then start, then end. That and using the new SimpleInterval(Locatable) constructor when appropriate.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/432#issuecomment-97531671:24,clear,clearer,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/432#issuecomment-97531671,1,['clear'],['clearer']
Usability,@wujh2017 Great! Let us know if you have any more feedback. Please be aware that both DetermineGermlineContigPloidy and GermlineCNVCaller are still in beta. There are some parameters that may need to be tuned appropriately for your data. We are currently running evaluations and will release some recommendations that we find suitable for data generated at the Broad.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4457#issuecomment-369254401:50,feedback,feedback,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4457#issuecomment-369254401,1,['feedback'],['feedback']
Usability,"@yfarjoun @vdauwera I've refined the tool categorization based on feedback on the tentative categorization. Thank you @yfarjoun for the review and feedback. The refinement is reflected in the new tabbed sheet in the shared Google Spreadsheet:`1217Changes_categorization-and-assignments`. I've separated out GATK vs Picard tools for each of the categories. . Here is a summary of the changes. 1. New 11 to `Diagnostics and QC`:; AnalyzeCovariates (from Alignment, Duplicate flagging and BQSR); GatherBQSRReports (from Alignment, Duplicate flagging and BQSR); FlagStat (from Read Data Manipulation); FlagStatSpark (from Read Data Manipulation); GetSampleName (from Read Data Manipulation); Picard BamIndexStats (from Read Data Manipulation); Picard CalculateReadGroupChecksum (from Read Data Manipulation); Picard CheckTerminatorBlock (from Read Data Manipulation); Picard CompareSAMs (from Read Data Manipulation); Picard ValidateSamFile (from Read Data Manipulation); Picard ViewSam (from Read Data Manipulation). 2. Merge 14 tools remaining in `Alignment, Duplicate flagging and BQSR` with 37 tools in `Read Data Manipulation`. Keep latter name. 	51 tools. 3. Move these out of `Read Data Manipulation`:; CompareDuplicatesSpark (to DxQC); ConvertHeaderlessHadoopBamShardToBam (to Other); CreateHadoopBamSplittingIndex (to Other). 4. Move ValidateVariants into `Variant Evaluation`. Also:; `Variant Evaluation and Refinement` --> `Variant Evaluation`; `VCF Manipulation` --> `Variant Manipulation` . Let us know your thoughts. Thank you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-352313248:66,feedback,feedback,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-352313248,2,['feedback'],['feedback']
Usability,@yfarjoun Geraldine has promised to followup on the categorization discussion.; @samuelklee Remember that the Best Practice Workflows and related documentation will guide folks to which tools to use for each workflow. The tool docs section is meant to categorize based on function and is purposefully workflow-agnostic.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-347671295:165,guid,guide,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-347671295,1,['guid'],['guide']
Usability,"@yfarjoun Just to be clear, are you saying that `getMateAlignmentEnd() + 1` is ideal for forward strand reads but `read.getStart() + abs(read.getFragmentLength())` will have to do if the `MC` tag is missing, and that we can leave it as `getMateStart() + 1` for reverse strand reads?. @droazen A priori I would expect the additional cost of parsing each read's mate CIGAR to be negligible compared to other stuff we do but I also understand the virtue of being careful. Given, however, that this is invoked for every assembled read in HaplotypeCaller it should suffice just to measure the wall clock time of HaplotypeCaller. Would seeing no change there be enough?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358768726:21,clear,clear,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358768726,1,['clear'],['clear']
Usability,"@yfarjoun We should sit down at some point to discuss the best way to activate the prefetching in Picard. It may be a little less trivial than I had thought based on the above, but should still be fairly simple.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678256:204,simpl,simple,204,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678256,1,['simpl'],['simple']
Usability,"@yurivict The large files under `src/main/resources/large/` are required to build GATK, since they are packaged inside the GATK jar and used by tools at runtime. These are things like ML models and native C/C++ libraries used for acceleration of certain tools. The large files under `src/test/resources/large/`, on the other hand, are only required by the test suite when running tests. Hope this clears things up!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8912#issuecomment-2223906223:397,clear,clears,397,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8912#issuecomment-2223906223,1,['clear'],['clears']
Usability,"@yurivict There is a note in the README about this in the ""Building GATK4"" section:. ```; Note that you must have a full git clone in order to build GATK, including the git-lfs files in src/main/resources. The zipped source code alone is not buildable.; ```. However, I will edit it to make it clearer.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8912#issuecomment-2225898092:294,clear,clearer,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8912#issuecomment-2225898092,1,['clear'],['clearer']
Usability,A couple unrelated tests failing; hopefully a rebase will clear those up.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2098#issuecomment-240491388:58,clear,clear,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2098#issuecomment-240491388,1,['clear'],['clear']
Usability,"A few points:; 1. When we wrote the Java interface, the 'agreement' was that the sample names would be unique and consistent within the VCF headers. Hence, the assert statement in the Java code.; 1. Having said that, the sample name in the VCF header is ignored completely if checks are disabled (which are disabled by default). This includes the assert statement and a couple of other checks in the importer code. The sample name is taken from the name to reader map provided in the constructor call. This map is created from the tab delimited file.; 1. Would it be possible to provide a simple test case to replicate the bug? I couldn't replicate it. Here is what I did.; 1. Three VCF files - t0.vcf.gz, t1.vcf.gz, t0_dup.vcf.gz. t0 and t0_dup are identical except for the GT field in one location. So, these 2 files have the same header (same sample name in the header).; 1. Tab file (unique sample names). HG00141 test_inputs/vcf_test_inputs/t0.vcf.gz; HG0155 test_inputs/vcf_test_inputs/t0_dup.vcf.gz; HG00192 test_inputs/vcf_test_inputs/t1.vcf.gz. 1. Import. ./gatk-launch GenomicsDBImport --genomicsDBWorkspace /tmp/ws -L 1:1-1000000 --sampleNameMap test_inputs/gatk4_dup_test_list --batchSize 2; 1. Query prints the output correctly. ./bin/gt_mpi_gather -j test_inputs/query/gatk4-generated.json --produce-Broad-GVCF. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT HG00141 HG00192 HG0155; 1 12144 . G <NON_REF> . . . GT 0/0 . 0/0; 1 12191 . T <NON_REF> . . . GT 0/0 0/0 0/0; 1 17385 . G A,T,<NON_REF> . . . GT 0/1 2/2 1/1. ./gatk-launch SelectVariants -V gendb:///tmp/ws --output t.vcf.gz -R Homo_sapiens_assembly19.fasta; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT HG00141 HG0155 HG0192; 1 12141 . C <NON_REF> . . END=12144 GT:DP:GQ:MIN_DP:PL ./.:2:0:0:0,0,0 ./.:2:0:0:0,0,0 .; 1 12145 . C <NON_REF> . . END=12277 GT:DP:GQ:MIN_DP:PL ./.:2:0:0:0,0,0 ./.:2:0:0:0,0,0 ./.:3:0:0:0,0,0; 1 12278 . C <NON_REF> . . END=12295 GT:DP:GQ:MIN_DP:PL ./.:2:0:0:0,0,0 ./.:2:0:0:0,0,0 .; 1 17385 rs987;d345",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3814#issuecomment-343344853:589,simpl,simple,589,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3814#issuecomment-343344853,1,['simpl'],['simple']
Usability,A lot of tutorials and information are available on our support [website](https://gatk.broadinstitute.org/hc/en-us). It includes best practice guides and a forum to ask questions.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6592#issuecomment-626235550:143,guid,guides,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6592#issuecomment-626235550,1,['guid'],['guides']
Usability,"A new annotation with features like `failureMessage` and `force=true` is a lot more complex and more work than just prioritizing type `X` for a `FeatureInput<X>`, if that will work just as well. See the chat room slogan ""hellbender instinct shall be to simplify and rip stuff out"" :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1184#issuecomment-163305134:253,simpl,simplify,253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1184#issuecomment-163305134,1,['simpl'],['simplify']
Usability,"ADAM has no header. I realize I'm only coming into the game rather late, but would it be possible to ditch `SAMRecord`? Since you're already using Google `Read`-backed data as well, instead of writing against an interface (`GATKRead`), you could simply come up with your own, more-awesome concrete data structure. (Perhaps even an Avro `SpecificRecord` a la `AlignmentRecord`). In cases where ADAM wants a header back, at the moment it actually runs an aggregation across all the reads to rebuild it. (I'm trying to add a patch that allows you to specify a header, though, because it's breaking a hellbender test for reading/writing parquet.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-140990644:246,simpl,simply,246,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-140990644,1,['simpl'],['simply']
Usability,AFAIK the GATK3 one used multithreading etc. Can we do a simple one just for readwalkers that does not use multithreading?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/974#issuecomment-149692146:57,simpl,simple,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/974#issuecomment-149692146,1,['simpl'],['simple']
Usability,"Actually what you said is correct: it is very painful to extend the `Main` class and use the current implementation. The simplest `Main` class that I'm using it's not extending the GATK one just because of the static methods (see the code [here](https://github.com/magicDGS/thaplv/blob/master/src/main/java/org/magicdgs/thaplv/Main.java)), that's why I would like to include this change. In few minutes I will commit the changes that you propose, including the method and the change from static. Thanks for the feedback, @lbergelson!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2204#issuecomment-255841430:121,simpl,simplest,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2204#issuecomment-255841430,2,"['feedback', 'simpl']","['feedback', 'simplest']"
Usability,"Actually, a second thing just popped into my head. The name `LocusDepth` makes perfect sense but the abbreviation `LD` is overloaded with Linkage Disequilibrium. Not a huge problem in context, but it's likely the abbreviation will make its way into VCF annotations in the future, which could create confusion. Is there another name we could use? I think `SiteDepth` or `BaseDepth` are also clear and unambiguous. @cwhelan any thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7861#issuecomment-1146164659:390,clear,clear,390,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7861#issuecomment-1146164659,1,['clear'],['clear']
Usability,Added a very simple test for sorting iterator. Back to you @droazen.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2249#issuecomment-267139593:13,simpl,simple,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2249#issuecomment-267139593,1,['simpl'],['simple']
Usability,Added some changes per Laura's review. Mainly:; - added a `--genomicsdb-update-workspace-path` that specifies the path to an existing workspace for incremental import and interval_list generation cases; - removed `--incremental` since the above made it superfluous; - added an `--output-interval-list-to-file` argument that will just generate a picard style interval_list at the location specified by the argument for an existing workspace. No import done when this is used; - changed the existing tests to use multiple intervals instead of a single interval. @ldgauthier I'm not entirely sure about the picard interval_list generation. Any chance you could help with providing some expected input/output for that so that I can add a test for it? I ran through a simple test with it but not really sure what the output should look like.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5970#issuecomment-518447724:763,simpl,simple,763,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5970#issuecomment-518447724,1,['simpl'],['simple']
Usability,"Additional feedback from the user for the mutect2 workflow. > ""Of note, it is really difficult and not really 'user-friendly' to have to predict disc space and runtime for Funcotator, which seem to depend (based on calculations you copied above from other Functotator workflows) on outputs of Mutect2 (eg vcf sizes), when here Mutect and Funcotator and bundled together. So I cannot see output of Mutect to predict values for Funcotator - especially not when I get to run this over hundreds of samples. It is also pricey to have jobs failing because of this. It would be much better to have these variables encoded, so that the algorithm uses Mutect outputs to predict memory etc. that it will need to run Funcotator downstream. If this is really how things work (and this is my current understanding), I really do not know how to estimate this for many samples without 'trial and error' that is both costly and it will take extremely long time....""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6680#issuecomment-651354230:11,feedback,feedback,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6680#issuecomment-651354230,2,"['feedback', 'user-friendly']","['feedback', 'user-friendly']"
Usability,Address PR comments to some extent. @SHuang-Broad take a look and let me know if things are more clear/better structured to you now. I think that renaming the `AssembledBreakpoint` class makes things at least a little bit less confusing.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2079#issuecomment-240524115:97,clear,clear,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2079#issuecomment-240524115,1,['clear'],['clear']
Usability,"Addressed feedback, updated so it can write reports and added test that checks the exact same reports as the BaseRecalibrator integration test (they pass).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/511#issuecomment-101783201:10,feedback,feedback,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/511#issuecomment-101783201,1,['feedback'],['feedback']
Usability,"After discussing with @ldgauthier, I'm going to approve this PR as-is, and Laura will address the remaining TODOs in a separate PR. For the record, the three remaining issues that need addressing are:. * Get rid of the `instanceof VariantWalker` check in `FeatureManager` by making `GATKTool.getGenomicsDBOptions()` return null (or `new GenomicsDBOptions(referenceArguments.getReferencePath())`) instead of throwing an exception, and then having `GATKTool.initializeFeatures()` (and its overrides) pass the GenomicsDB options in to the `FeatureManager` constructor, which can then propagate them down here. * Add a simple direct integration test for the new `--floor-blocks` HaplotypeCaller arg. * Address my maintenance concerns about `AnnotationUtils.isAlleleSpecific()` by adding an empty marker interface for AS annotations (open to other ideas here if you don't like that one)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4947#issuecomment-517350314:615,simpl,simple,615,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4947#issuecomment-517350314,1,['simpl'],['simple']
Usability,"After getting feedback from @vruano on pull request [45](https://github.com/broadinstitute/hellbender-protected/pull/45) in hellbender-protected and speaking with @droazen and @lbergelson, it seems that LocusWalker should be implemented instead. For the time being we will move forward with SamLocusIterator, but I'll file a separate issue in hellbender-protected to remind us to switch over to LocusWalker once it is implemented.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/335#issuecomment-116846893:14,feedback,feedback,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/335#issuecomment-116846893,1,['feedback'],['feedback']
Usability,"After more digging around it seems that in the case of partial alignment (i.e. hard clipped bases) the BD and BI tags that sentieon just copies from the consensus fastq aren't trimmed to the actual length of the aligned sequence, and thus are to long and it's this that causes problems. . As these are non-standard tags the SAM/BAM format specification doesn't say anything on whether their length must equal the aligned segment of bases, but it clearly doesn't make any sense to have quality data on bases that are not part of the alignment (= hard clipped), so IMHO the solution here would be for Sentieon to fix their tool. I've written a small utility that trims the BD and BI tags (based on the CIGAR-string) to have the same length as the actual aligned segment of the read, https://github.com/avalind/doppelganger.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-669525805:446,clear,clearly,446,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-669525805,1,['clear'],['clearly']
Usability,"Ah! I see. This is indeed an unintuitive behavior. Especially in the case where a user is providing a compound expression with a series of filters separated by the OR operator. The user is expecting that any variant that meets any of the filter criteria will be marked for filtering. If I understand correctly, a variant could fail 4/5 filters, be NULL for 1/5 filter expressions and end up with a PASS status! This is rarely the desired behavior. In this use case, I might want an --ignore-missing-values option. I don't necessarily want to fail all variants just because they have a missing value for a feature. But, I also don't want them to be evaluated as PASS if they fail filters for which they do have values. I guess maybe a partial solution is to strongly encourage separate filter expressions, for this the most common use case of wanting to apply several filters in the OR situation. I guess if you have AND operators in the mix, it gets more complicated. If I want to filter a variant only if it fails filter_A AND filter_B it is less clear what the right behavior is when feature A or B is NULL. I guess it should pass?. I don't have enough understanding of why these values are missing. I'm using a pretty standard workflow (GATK HaplotypeCaller) to get these variants and I guess I naively assumed they would be complete for these features.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5362#issuecomment-436049581:1048,clear,clear,1048,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5362#issuecomment-436049581,1,['clear'],['clear']
Usability,"Ah, I see. the temporary nature of your suggestion was not clear (to me). I accept your suggestion. On Thu, Nov 9, 2017 at 9:23 PM, droazen <notifications@github.com> wrote:. > @yfarjoun <https://github.com/yfarjoun> I'm suggesting that while we're; > in the process of tieing out the GATK4 HaplotypeCaller against GATK3, we; > should not be making changes like this. After the tie-out is complete, then; > we can of course revisit this branch.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/3680#issuecomment-343295944>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0mhcLngpG-X_ZcKseu-Ctszn3_Wxks5s021WgaJpZM4Pzjie>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3680#issuecomment-343497974:59,clear,clear,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3680#issuecomment-343497974,1,['clear'],['clear']
Usability,"Ah, I was not aware until now that we had a tool called SplitByRG -- which is probably because I'm mostly familiar with public tools, and SplitByRG appears to be in private. . After further thought, my guess is that the difference is: SplitByRG writes out a separate bam for each readgroup, and they are all output (core function modality is scattering), whereas the PrintReads + filters solution only writes out a specified subset, to a single output bam (core function modality is subsetting). If so then perhaps it does make sense to keep them separate, except that instead of making it a PrintReadsBy[blah](a name that does not clearly distinguish the core functionality), I would recommend making it a generic tool called SplitReads (analogous to PrintReads, but with a distinct scattering modality), and offer several options for how to split (e.g. you could choose a specific RG tag or other non-RG property of the read data -- including randomness, which would cover the functionality of SplitSamFile).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/74#issuecomment-67869375:632,clear,clearly,632,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/74#issuecomment-67869375,1,['clear'],['clearly']
Usability,"Ah, got it. By the way, @kvinter1 thanks for being the first person to take on a ""learn GATK"" issue!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4932#issuecomment-412926174:82,learn,learn,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4932#issuecomment-412926174,1,['learn'],['learn']
Usability,"Ah, ok. I've filed a new issue for the documentation of -DSTACK_TRACE_ON_USEREXCEPTION (#2445). . StorageException is different from UserException in that it doesn't have the user-relevant context. Like IOExceptions, we normally catch StorageException and transform them into user-friendly UserExceptions (as this PR does). Because of this lack of context, I don't think there's much ""special"" we can do about them (printing them out fully, as we do now, is the best I can think of). If you have an idea though I'm open to suggestions.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2417#issuecomment-285175500:276,user-friendly,user-friendly,276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2417#issuecomment-285175500,1,['user-friendly'],['user-friendly']
Usability,Ah. I see. It's not clear to me what that problem is though. You can have many version of gradle coexisting. Gatk doesn't have to build with system gradle because it comes with the `./gradlew` wrapper which chooses the correct version to build it with.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444200479:20,clear,clear,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444200479,1,['clear'],['clear']
Usability,"Aha, after clearing the travis cache for the PR build it passed! Merging",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422499733:11,clear,clearing,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422499733,1,['clear'],['clearing']
Usability,Ahh... I see https://github.com/disq-bio/disq/pull/124 was such a simple fix.... How did we find this bug in the first place? Was the split guessing failing in some case? I think on this end its probably acceptable to just accept this branch and point to the PR in disq. Can we not write a unit test for the SBI index there where we provide an invalid SBI index in a place where the split guessing would have worked and assert that it is indeed trying to use the index?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6323#issuecomment-567092790:66,simpl,simple,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6323#issuecomment-567092790,1,['simpl'],['simple']
Usability,"Also renamed this ticket to be less scary and more precise, since we know it's a 2-minute pause in the NIO library. It clearly doesn't always happen, though, as I don't think I've ever seen it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427371743:90,pause,pause,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427371743,2,"['clear', 'pause']","['clearly', 'pause']"
Usability,"Also, I suspect that for Terra another workaround might be to request a different machine type that does not support AVX:. https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/. ```; runtime {; cpu: 2; cpuPlatform: ""Intel Skylake""; }; ```. https://cloud.google.com/compute/docs/regions-zones/#available. Would appreciate any guidance on this in the meantime. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781806444:332,guid,guidance,332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781806444,1,['guid'],['guidance']
Usability,"Also, MQ filtering results in stochastic coverage dropout. It is likely that low MQ regions significantly overlap across samples, in which case, downstream CNV can learn such biases and correct the coverage. Will test this in validations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375722179:164,learn,learn,164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375722179,1,['learn'],['learn']
Usability,"Also, just to provide some context to all tagged: certain users of the old CNV pipeline expressed somewhat vague concerns with the non-fragment-based coverage collection strategies—which also differed across WES and WGS, to boot—-but didn’t offer any compelling demonstrations that fragment-based strategies were better. For the new version of the pipelines, the main priority was to pick a single strategy to unify WES/WGS coverage collection. We decided to give a simple fragment-based strategy a shot—-with the intention of using automated evaluations to test it in a rigorous manner. Although those aren’t in place yet, I’m comfortable with making the call against it at this point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375126971:466,simpl,simple,466,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375126971,1,['simpl'],['simple']
Usability,"Am 90% certain at this point that the jar they were using for testing was built incorrectly. The `CloudStorageReadChannel.class` file in the latest `google-cloud-nio-0.19.0-alpha-shaded.jar` should be 6169 bytes, but their jar has 5401 bytes for that class. And that's the primary class JP patched in the latest release. So I am pretty hopeful that this was just a simple build error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2749#issuecomment-306947226:365,simpl,simple,365,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2749#issuecomment-306947226,1,['simpl'],['simple']
Usability,"Am un-assigning this, as it's not clear that we want to merge this at this time. Feel free to re-assign if you'd like to see this merged.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/345#issuecomment-101324830:34,clear,clear,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/345#issuecomment-101324830,2,['clear'],['clear']
Usability,"And another one, `https://www.broadinstitute.org/gatk/guide/tooldocs/org_broadinstitute_gatk_tools_walkers_annotator_RMSMappingQuality.php`, in `MappingQualityRankSumTest`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6382#issuecomment-652024594:54,guid,guide,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6382#issuecomment-652024594,1,['guid'],['guide']
Usability,"Anecdotally, some people have seen logging issues around the Conda; progress bars filling logs. I know Conda had a change request to add a; silent or quiet mode. Suggestions on the back of a postcard... On Mon 15 Oct 2018, 21:27 Chris Norman, <notifications@github.com> wrote:. > Changing the exception throwing code won't help with either of those -; > that code would only execute when the tool is actually run. Currently, the; > PR is failing to even build on Travis during the part of the build where it; > creates the Docker image on which the tests will run. Travis is killing it; > because its producing so much progress output during the conda environment; > creation - right when its resolving tensorflow packages.; >; > My suggestion above was to see if we can (at least temporarily) get past; > that so we can see how big the Docker is, and whether the CNNScoreVariants; > tests pass with the new environment. Then we can figure out if we have any; > additional issues to resolve.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5291#issuecomment-430000969>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AG6lrwV2gaTYs6ur_AXznl6iV0AMxQ8Cks5ulO_DgaJpZM4XNHdi>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-430007451:68,progress bar,progress bars,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-430007451,1,['progress bar'],['progress bars']
Usability,Another argument against this: the map function of a tool should clearly articulate its inputs in its signature. A map() that takes no parameters and relies on reflection/injection into members for its inputs would be supremely bad design.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/242#issuecomment-76739266:65,clear,clearly,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/242#issuecomment-76739266,1,['clear'],['clearly']
Usability,"Another thing that just come to my mind is to rely on [SLF4J](https://www.slf4j.org/) for logging - downstream projects can configure which logger they want to use, and they can have their own ways of setting logging verbosity. If the logging system from HTSJDK wants to be maintain, it can also add a simple implementation of SLF4J with the verbosity levels that are in the current implementation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-371401288:302,simpl,simple,302,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-371401288,1,['simpl'],['simple']
Usability,"Apart of the amount of work in both Barclay and GATK, I think that this shouldn't be implemented for 2 reasons:. * After #3486, some tools are hidden from the command line (and they will be most likely undocumented too). If the bash-completion works with undocumented tools that are hidden from the command line, there will appear anyway after pressing tab-tab. If that tools are treated in a different way, then it requires even more work - Barclay does not use the omitFromCommandLine at all, and that means that GATK should extend the bash-completion to take it into account.; * If a tool can bash-complete but it does not show in the online help pages (the main source for help, taking into account that in the CLI is a bit messy when the parameter space grows), then it will be really difficult to really understand how the tool work. Even if it shows the parameters with tab-tab, the only way of checking what the meaning of each of them is look at the CLI help. Because the bash-completion is a sub-type of help-doclet, it should require the `@DocumentedFeature` annotation: that is the marker interface in Barclay for mark classes as parsed/added to the ""help"" generated by doclets....",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3596#issuecomment-331112758:202,undo,undocumented,202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3596#issuecomment-331112758,2,['undo'],['undocumented']
Usability,"Apologies @bbimber -- your efforts to port this tool to GATK4 are much appreciated. Our team has been extremely busy with the lead up to the 4.0 release, which is why we haven't been as responsive lately. I'll have someone take a look at the test data in question to see if it can be publicly shared.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/616#issuecomment-358029799:186,responsiv,responsive,186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616#issuecomment-358029799,1,['responsiv'],['responsive']
Usability,"Apologies on the poor report. There are no other users in these compute nodes (I am the tester) and for all intents and purposes the ulimit is pretty high (hard limit of 8192 max files). I am using GATK version 4.1.4.1, although it might be the one that has been optimised for IBM power9 systems by @ruzhuchen. Currently I am waiting for the sys admin to increase the max files further, but I believe that this is far from ideal. Here is the (simplified) command:; ```bash; gatk --java-options ""-Xmx40g -Djava.library.path=/bio/apps/gatk_4.1.4/gatk-4.1.4.1/libs -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" Mutect2 -R Homo_sapiens_assembly38.fa -I illuminaN_hg38.br.recal.bam --max-mnp-distance 0 -O illuminaN.vcf.gz; ```; May be I am running it wrong?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-598233814:443,simpl,simplified,443,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-598233814,1,['simpl'],['simplified']
Usability,"Applied feedback, let me know if it's OK now!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/869#issuecomment-135849587:8,feedback,feedback,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/869#issuecomment-135849587,1,['feedback'],['feedback']
Usability,"Applied feedback, rebased, squashed. Merge pending passing tests. Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107694686:8,feedback,feedback,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107694686,1,['feedback'],['feedback']
Usability,"Applied feedback, reproduced bug and updated our description (#650), submitted bug report (https://github.com/google/google-http-java-client/issues/297), squashed. Merging once tests pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/835#issuecomment-132698966:8,feedback,feedback,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/835#issuecomment-132698966,1,['feedback'],['feedback']
Usability,"Are the errors below part of this, when starting BwaSpark with spark-submit?; I activated ""--disable-sequence-dictionary-validation true"", but that doesn't help. It is very unclear, why a BAM is not recognized as a BAM file. I have tried all kinds of ways to make sure that it is a BAM and not a SAM file.; The documentation for BwaSpark also says ""BAM/SAM/CRAM file containing reads"", so if SAM files are really not possible, that should probably be changed.; ...; Even on verbosity DEBUG, the comments are not at all helpful to get at the problem.; E.g. ""Cannot retrieve file pointers within SAM text files.""; Is that a general statement about SAM files? Or does it only say, that in this specific SAM file (which is actually a BAM file), file pointers cannot be found?; What pointers are meant exactly?; How could this be fixed?. ```; ""SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.""; Which URL?; Which stream?; Why would this happen? What could be the error?; The SAM/BAM distinction seems very unclear. It would be more helpful, if some specific missing aspect (e.g. not queryname sorted) would be clearly declared as the culprit.; ...; 00:29 DEBUG: [kryo] Write: SAMFileHeader{VN=1.5, SO=queryname}; ...; WARNING	2018-01-16 02:11:25	SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.; ...; java.lang.UnsupportedOperationException: Cannot retrieve file pointers within SAM text files.; 	at htsjdk.samtools.SAMTextReader.getFilePointerSpanningReads(SAMTextReader.java:185); ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4131#issuecomment-357838062:1149,clear,clearly,1149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4131#issuecomment-357838062,1,['clear'],['clearly']
Usability,Are we interested in writing some definitive guide on how to tune the `af-of-alleles-not-in-resource` parameter for different contexts?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4745#issuecomment-387218068:45,guid,guide,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4745#issuecomment-387218068,1,['guid'],['guide']
Usability,"As I understand, there are two ways:; 1) Update all guides that include tools not ported to GATK4 so users could use GATK4 to get the results as they did earlier.; 2) Add all tools from GATK3.6 to GATK4. Otherwise non official forks will appear.. For now could you please add all tools to GATK4?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-319602267:52,guid,guides,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-319602267,1,['guid'],['guides']
Usability,"As determined by @davidadamsphd , the `Copyable` interface idea won't work:. The recommendation from the Dataflow team was to make a narrow API and do the copying part of the API. I started down this route, and I think it might be doable for things like the walker interface. The idea is to make a Copyable interface and have our interfaces extend that. . However, we have unsafe code already in the engine. I tried to make this SafeDoFn approach, however it became clear quickly that we'd have a combinatorial explosion of classes because we don't just have `DoFn<GATKRead,POut>`, but also `<Iterable<GATKRead>,POut>`, and many others. So, this approach will not work for the engine. I then tried to make a general purpose solution (using coders to write to bytes and then recreate a new class). This doesn't work for a few reasons, most critical is that the coder registry isn't Serializable, so that can't be passed down deep enough to get this to work. While working on this, I chatted with someone on the Dataflow team who is working on the verification on the direct runner. He has a PR out and likely going to get it approved soon. So, for the engine, we could always test using the direct runner and know for sure there are not issues (once we can use his code). However, there are two downsides:. 1) We will need to wait for a cut of the SDK (which looking at their previous clip is likely ~ two weeks away). . 2) I don't know if we want the direct runner test as our general purpose solution. Can we expect Comp Bios to always test with the direct runner first? Will they write anything more complex than functions that use the Walker interface?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/702#issuecomment-127403661:466,clear,clear,466,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/702#issuecomment-127403661,1,['clear'],['clear']
Usability,"As discussed in person, extract a simple `Shard<T>` interface here to be more compatible with the work done in the `SlidingWindowWalker` branch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2016#issuecomment-234018888:34,simpl,simple,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2016#issuecomment-234018888,1,['simpl'],['simple']
Usability,"As we discussed on Slack, this will fix the NaNs, but I'm not convinced that we should allow the single-contig use case without at least a warning. The ploidy step will essentially perform no inference, since I think the per-contig bias and ploidy factors will cancel out with the way the likelihood is written---it will simply return the prior, and all samples will be guaranteed to have ploidy = 2. @asmirnov239 is going to do some more testing to make sure we understand this right and perhaps add a warning/documentation. The current likelihood is a bit confusing (I tried to address some of these issues in the unmerged ploidy-model update), but in any case, the problem is degenerate and it's hard to define appropriate behavior without additional priors and model structure.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6613#issuecomment-631693589:321,simpl,simply,321,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6613#issuecomment-631693589,1,['simpl'],['simply']
Usability,"As we discussed, it's possible that these are simply common germline CNVs that are being median-normalized out in CR by the PoN. Let's investigate the sample-median-normalized counts in some of the questionable regions, along with the per-bin medians in the PoN. I do not think a gCNV run is necessary (it will probably be a bit expensive, anyway). More generally, I think a better approach to germline tagging would be to avoid the caller entirely. Let's take the ModelSegments output for a normal, and then tag ModelSegments segments in the tumor that sufficiently overlap any normal segment in CR-AF-genomic space (where we have some freedom to define the overlap criteria). Essentially, let's just try to highlight differences between the tumor and normal in CR-AF space. This would rescue events in the normal that may be further amplified or deleted in the tumor. Subsequently, simple filtering of these events would be less misleading than imputation. I do not think such tagging should be implemented in Java, if we can avoid it. Rather, a relatively simple python script that runs through each tumor segment and checks for overlaps would suffice. This script could output a tagged/filtered ModelSegments result, as well as do the conversion step for downstream tools. This also obviates the need for the Java code for combining segment breakpoints and additional CNV collection classes in the current post-processing tools. What do you think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-442911810:46,simpl,simply,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-442911810,3,['simpl'],"['simple', 'simply']"
Usability,Back to @jamesemery for a simple change,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2042#issuecomment-237349722:26,simpl,simple,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2042#issuecomment-237349722,1,['simpl'],['simple']
Usability,"Back to @meganshand. I put in a simple mitochondrial integration test. Given that our MC3 validation already covers this particular bug I actually don't think it needs a new test for mitochondria. Also, for later, are any of your spike-in bams public (or rather, public + public)? I noticed that the NA12878 truth doesn't have very low AFs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5057#issuecomment-408649991:32,simpl,simple,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5057#issuecomment-408649991,1,['simpl'],['simple']
Usability,BaseRecalibrator with 3GB heap (file size 100GB). This is a snapshot after ~1 hour of runtime. Check out the differences in the y axis here. GATK3 is clearly struggling while Hellbender is doing fine:. GATK3 heap profile after GC (each red triangle is a full GC); ![image](https://cloud.githubusercontent.com/assets/1993519/13857812/dce2bcb8-ec51-11e5-9fb2-9745e86c8e24.png). GATK4 heap profile after GC:; ![image](https://cloud.githubusercontent.com/assets/1993519/13857765/b4525934-ec51-11e5-95aa-4135c05ef850.png),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1460#issuecomment-198037375:150,clear,clearly,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1460#issuecomment-198037375,1,['clear'],['clearly']
Usability,Beautiful results @samuelklee -- and some of that data was really squirrely too!. I think continuing with the current round of evaluations makes sense. Those unusual sex genotype samples are pretty rare so spot checking should be fine. I'm excited about having a robust set of learning parameters so we can get this tool to users. We can work on catching the tricky and interesting but rare cases as a second phase.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376516485:277,learn,learning,277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376516485,1,['learn'],['learning']
Usability,"Because it is related with the `LocusWalker` pull request, could you review, @droazen? It is a very simple PR, but I will need it in my software. Thank you in advance.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1833#issuecomment-220021626:100,simpl,simple,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1833#issuecomment-220021626,1,['simpl'],['simple']
Usability,Because there is currently no way in travis to prevent the build stages from being triggered in every pull request it was decided to simply upload the nightly build without tests instead. An example of how to use build stages can be seen in this branch for future reference: https://github.com/broadinstitute/gatk/tree/je_travisBuildStages,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3396#issuecomment-319721849:133,simpl,simply,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3396#issuecomment-319721849,1,['simpl'],['simply']
Usability,"BucketUtils was a solution before we had Filesystem providers. It's stuck around as a parallel set of code because we couldn't trust the providers at first. In the long run it should be removed and replaced entirely by `Files` operations. We need to test that all the functionality exists / works as expected though, and it hasn't been a high priority to do so. Particularly, I'm not sure we have a lot of faith in the HDFS NIO plugin, so we may need to keep around special cases for that. It could definitely at least be simplified a lot though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3569#issuecomment-328993020:522,simpl,simplified,522,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3569#issuecomment-328993020,1,['simpl'],['simplified']
Usability,"Built a PoN with those normals. Some tuning of parameters was required to get reasonable results. After discussion with @mbabadi, we decided that the current model has a little too much freedom and can probably be made simpler (negative binomial -> Poisson). This should result in more robust results and decrease the amount of tuning needed. Also note that normal sample 8007540251 has something going on in chr12.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-365640616:219,simpl,simpler,219,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-365640616,1,['simpl'],['simpler']
Usability,"But if your implementation is a `VariantWalker` and #2223 is implemented, this will clash. By the way, I don't know if there is any plan to include all the tools from Picard, but it seems that the behaviour will be replicated if so, no?. Thanks anyway for the feedback, close the PR in case you think that it is not necessary.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2232#issuecomment-256020212:260,feedback,feedback,260,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2232#issuecomment-256020212,1,['feedback'],['feedback']
Usability,"By doing the following, I was able to get a JointGenotyping result for my 343 samples:; - increased the amount of memory allocated to the Java heap in ImportGvcfs to 50000m; - modified the runtime attributes for all the joint genotyping tasks to match the format that Cromwell accepts for HPC environments (https://cromwell.readthedocs.io/en/stable/tutorials/HPCIntro/#specifying-the-runtime-attributes-for-your-hpc-tasks); - increasing the runtime memory attribute for ImportGvcfs and GenotypeGvcfs from 26000 MiB to 60 G; - executing the workflow with the following sbatch parameters:; nodes=4; ntasks=32; mem=248g; tmp=429G; - manually tar'ing up all the genomicsdb directories from the execution directories of all 10 shards of ImportGvcfs after they successfully completed GenomicsDBImport and failed with the error message: ; pure virtual method called ; terminate called without active exception; - running an abbreviated version of JointGenotyping which started at GenotypeGvcfs and executed the remainder of the JointGenotyping workflow unchanged.; ; I think this pretty clearly demonstrates that, whatever is going on, it occurs between GenomicsDBImport's successful creation of genomicsdb and the tar -cf of same. The failure is 100% reproducible with a number of different runtime configurations. The error messages are from C++ and seem to be occurring at the point where native C++ code is handing execution back to Java.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1314069533:1080,clear,clearly,1080,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1314069533,1,['clear'],['clearly']
Usability,"By modifying the test I was able to isolate the error in the `org.broadinstitute.hellbender.tools.walkers.variantutils` package, which is strange because the PR did not modify the javadoc for any class in that package. The integration test runs `com.sun.tools.javadoc.Main.execute` and asserts that the output code is zero, which does not yield a useful error message. In order to produce something more meaningful I hacked the test to output the entire `stdout` and `stderr` as follows:. ```; final StringWriter out = new StringWriter();; final PrintWriter err = new PrintWriter(out);. final int result = com.sun.tools.javadoc.Main.execute(""program"", err, err, err, ""doclet"",docArgList.toArray(new String[] {}));; err.flush(); // probably not needed; String message = out.toString(); // message contains the entire stdout and stderr of the call to execute; Assert.assertEquals(result, 0, message);; ```. The output is about 2000 lines, but a lot of it is clearly innocuous. Removing lines such as; * `2022-08-16T00:09:07.2336106Z [parsing completed 1ms]`; * `2022-08-16T00:09:07.4456202Z [loading ZipFileIndexFileObject[/jars/gatk-package-4.2.6.1-56-gad9a538-SNAPSHOT-test.jar(org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCFIntegrationTest.class)]]`; * `2022-08-16T00:09:07.4459732Z [loading RegularFileObject[src/main/java/org/broadinstitute/hellbender/cmdline/argumentcollections/OptionalIntervalArgumentCollection.java]]`; * `2022-08-16T00:09:07.4462012Z [parsing started RegularFileObject[src/main/java/org/broadinstitute/hellbender/cmdline/argumentcollections/OptionalReferenceInputArgumentCollection.java]]`; * 2022-08-16T00:09:07.2322755Z [loading ZipFileObject[/gatk/gatk-package-unspecified-SNAPSHOT-local.jar(htsjdk/samtools/SAMSequenceDictionary.class)]]. brings it down to 353 lines, the majority of which look like . ```2022-08-16T00:09:07.4435974Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:479: error: cannot find symbol; 2022-08-1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217231488:956,clear,clearly,956,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217231488,1,['clear'],['clearly']
Usability,"By the way, I thought @vdauwera was opposed to using optional inputs in this way at some point (see #3657). Was that question ever decided? (I'm still of the opinion that they *should* be used in this way, but this is one of the reasons I didn't for this iteration of the WDL.). To be clear, the pair WDL right now does not allow all of the workflow paths (tumor-only, no PoN, etc.) that the new tools make possible. It only allows the one that we will most likely run in production (matched-normal + PoN). We should probably make the WDL a little more flexible to cover the most common use cases, but I'm fine if it doesn't completely expose all of the possible workflow paths---this would probably just make the WDL harder to maintain. Users can write their own WDLs in this case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3983#issuecomment-362696132:285,clear,clear,285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3983#issuecomment-362696132,1,['clear'],['clear']
Usability,"CalculateGenotypePosteriors is only intended for trios. This is noted (admittedly not too clearly) in the output section of the docs (`Per-site, per-trio joint likelihoods (JL) and joint posteriors (JL)` -- which needs a fix to be JP for posteriors) In GATK3, CalculateGenotypePosteriors shares some code with PhaseByTransmission (namely the FamilyLikelihoods.java), which does support parent-child pairs, which is why you encountered comments relevant to pairs. We can certainly update the docs for clarity.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5409#issuecomment-438740998:90,clear,clearly,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5409#issuecomment-438740998,1,['clear'],['clearly']
Usability,"Can you describe more precisely what you mean by ""processing"" here?. On Wednesday, April 6, 2016, Geraldine Van der Auwera <; notifications@github.com> wrote:. > GATK3 is very slow when processing references with large numbers of; > contigs, such as draft genomes. In the past this mostly affected microbial; > genomes so we didn't do anything about it, but now the Hg38 has a lot more; > contigs so we have to make sure that's not going to be a problem with; > GATK4.; > ; > To be clear, efficient processing of reference genomes with thousands of; > contigs is a must-have.; > ; > Efficient processing of e.g. microbial draft genomes with tens of; > thousands of contigs is a nice-to-have. More than that is just crazy talk.; > ; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/gatk/issues/1688. ## . Sent from Gmail Mobile",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1688#issuecomment-206324138:482,clear,clear,482,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1688#issuecomment-206324138,1,['clear'],['clear']
Usability,"Can you give a bit more information here? If I'm understanding correctly, it's not clear that the same issue is at play here. The original issue was that duplicate/incomplete fragments were causing queries to the workspace to fail. . In this latest instance, it seems you are appending additional samples to the existing workspace. Is that right? If so,; - are you seeing the same/similar error? That is, it's a core dump? Can you share the error messages, any logs, core dump files etc?; - did you clean up the workspace before importing? That is, remove the incomplete fragment @nalinigans identified and the duplicated ones?. My first instinct is that even if the incomplete/duplicated fragments weren't cleaned up, the incremental import shouldn't have an issue -- at least not till it gets to the consolidate phase, which only happens after all batches are imported. Sounds like you were seeing an issue at batch 3 of 4, so might have something to do with the samples in that batch...or some other import issue. You mentioned that previous imports to this particular contig failed -- were those just transient failures that worked when rerun, or was there some configuration that you changed to get that to work?. For completeness, the way I identified duplicate fragments was to do an md5sum check on some of the internal files. If any pair of fragments have the same md5sum they are likely duplicates. So, from the workspace directory, something like:. ```; find . -name ""ALT.tdb"" -exec md5sum {} \;|sort; ```; That will highlight the fragments that are potentially duplicate. To confirm that the fragments are indeed duplicates, you'll then want to take that list of potentially duplicate fragments and check that all corresponding files within each pair of potentially duplicate fragments actually have the same md5sum. I have a crude bash script that I can share if you want.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-722541707:83,clear,clear,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-722541707,1,['clear'],['clear']
Usability,"Can you have a look to this one, @cmnbroad? It is just a simple change for let me upgrade my dependencies and do not include the NPE in not bounded arguments...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2455#issuecomment-285858467:57,simpl,simple,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2455#issuecomment-285858467,1,['simpl'],['simple']
Usability,"Can you have a look to this, @cmnbroad? This is a very simple PR and it is already reviewed in Picard...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2243#issuecomment-268280066:55,simpl,simple,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2243#issuecomment-268280066,1,['simpl'],['simple']
Usability,"Can you please test this change with the `HaplotypeCaller` in protected and make sure nothing changes? In particular, can you run `HaplotypeCallerIntegrationTest` and `HaplotypeCallerEngineUnitTest` and make sure they pass with this change? This PR makes me a little nervous given the centrality of the classes touched, even though the optimization itself is simple enough...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1795#issuecomment-216595202:359,simpl,simple,359,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1795#issuecomment-216595202,1,['simpl'],['simple']
Usability,"Certainly the author can't just ""certify"" that the tool works without writing tests to prove it on an ongoing basis as the tool is modified -- I don't think that was what @nh13 meant (but please correct me if I misunderstood). I read that as ""if tests pass, the author certifies that the tool is in a usable state for its intended use(s)""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/382#issuecomment-93806764:301,usab,usable,301,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/382#issuecomment-93806764,1,['usab'],['usable']
Usability,Checking in from the future: we have clearly been failing this as I'm finding `time gatkPrintReads --help` takes ~2.5-3 seconds.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2127#issuecomment-494961720:37,clear,clearly,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2127#issuecomment-494961720,1,['clear'],['clearly']
Usability,"Cleaning the bam (and the sam) test files is almost done - it's taken some time because some have been like mini debugging exercises in themselves, followed by the capturing and substitution of the new expected output files for the tests. There are a few issues that still remain, however, and unfortunately I am out of time - I'm headed to an overseas meeting on Monday and will be out for two weeks. I had hoped to finish before the trip, but my BMC Bioinformatics paper came through so I had to spend time on proofs etc.. I will resume ASAP after I get back.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/569#issuecomment-122571160:532,resume,resume,532,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/569#issuecomment-122571160,1,['resume'],['resume']
Usability,Closing PR. It is quite old and it isn't clear that this is necssary for the current codebase.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3680#issuecomment-481769701:41,clear,clear,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3680#issuecomment-481769701,1,['clear'],['clear']
Usability,"Closing as a part of my issue clearing rampage, but let it be known Pyro is on the roadmap for future CNV models, and we are currently looking into updating PyMC3 to resolve some dependency issues with gCNV.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766#issuecomment-926143041:30,clear,clearing,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766#issuecomment-926143041,1,['clear'],['clearing']
Usability,Closing because I haven't heard back from the user. If the forum discussion resumes and it turns out that there is a bug I will re-open a more specific ticket.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5536#issuecomment-451711941:76,resume,resumes,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5536#issuecomment-451711941,1,['resume'],['resumes']
Usability,"Completing https://github.com/broadinstitute/hellbender/issues/673 will take care of the case of ""missing reference for CRAM"", but we also need to make sure we're handling the case of ""wrong reference"" elegantly (where elegantly means ""throw a `UserException` with a descriptive error message). We want a test case with a reference that is the wrong reference for a CRAM, but has a compatible sequence dictionary (so that it won't be caught by the sequence dictionary validation). Both the wrong and missing reference cases should have a simple integration test that runs, eg., `PrintReads` with `expectedExceptions = UserException.class`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/677#issuecomment-126031374:538,simpl,simple,538,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/677#issuecomment-126031374,1,['simpl'],['simple']
Usability,"Congratulations on your graduation! And good luck with your application, I know from personal experience it is a hassle, but it’s worth it!. Yes, that is what we are proposing. @davidbenjamin can give you some more guidance to get you started. . Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4632#issuecomment-404109319:215,guid,guidance,215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4632#issuecomment-404109319,1,['guid'],['guidance']
Usability,Could I have some feedback about the efficiency of the Fisher's Exact Test implemented here? I'm planning to use it in other context where the performance could be reduced and I think that this is a good opportunity to have some information about it. Thanks in advance!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-267036486:18,feedback,feedback,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-267036486,1,['feedback'],['feedback']
Usability,"Dear Gökalp: . Thank you very much!. You suggested to run **conda env create -f gatkcondaenv.yml**. Where is the **gatkcondaenv.yml** file?. If I simply used **git clone https://github.com/broadinstitute/gatk.git**. The cloned package has a **gatk executable**. I found that I could run it directly. If I simply go to **https://gatk.broadinstitute.org**/hc/en-us homepage, and download the latest version file https://github.com/broadinstitute/gatk/releases/download/4.6.0.0/gatk-4.6.0.0.zip. After unzipping it, there is also a **gatk executable**, and I could also run it directly (./gatk) on the shell. So, now I am a bit puzzled: which is the recommended way to install and run GATK?. Finally, it seems that you guys now recommend **WARP** https://broadinstitute.github.io/warp/, which seems to be a completely new set of tools and pipeline scripts. Is WDL now the recommended approach to run GATK?. Thank you very much & best regards,; Jie",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8664#issuecomment-2215391015:146,simpl,simply,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8664#issuecomment-2215391015,2,['simpl'],['simply']
Usability,"Dear all,. I am a bit confused why GATK uses `[0,1,2]` for the `GT` files, even though VCF specifications clearly state that the `GT` field is `encoded as allele values separated by either of / or |`. They even say that for `diploid calls examples could be 0/1, 1 | 0, or 1/2, etc`. As it is right now, if I read a VCF from GATK CNV germline pipeline through `bcftools`, the `GT` field is changed to `-65`:; ```; 1 17345376 CNV_1_17345376_161326630 N <DUP> 101.19 . END=161326630 GT:CN:NP:QA:QS:QSE:QSS -65:3:13:11:101:3:18. 1 161332119 CNV_1_161332119_161332223 N <DEL> 3.19 . END=161332223 GT:CN:NP:QA:QS:QSE:QSS -65:1:1:3:3:3:3. 1 193091331 CNV_1_193091331_241683022 N <DUP> 268.21 . END=241683022 GT:CN:NP:QA:QS:QSE:QSS -65:3:27:34:268:36:3. 2 96919546 CNV_2_96919546_96931119 N . 62.93 . END=96931119 GT:CN:NP:QA:QS:QSE:QSS -65:2:3:38:63:38:63. 3 10183532 CNV_3_10183532_69928534 N . 469.93 . END=69928534 GT:CN:NP:QA:QS:QSE:QSS -65:2:22:31:470:19:75. 3 69986973 CNV_3_69986973_70014399 N <DUP> 10.12 . END=70014399 GT:CN:NP:QA:QS:QSE:QSS -65:3:8:4:10:4:10; ```. Any reason to not use the standaed `GT` format?. I have also noticed that GATK outputs some non-variable SVs to the VCF without any ALT allele. Why not remove them if they are actually not SVs, if `GT=0` and `CN=2`?. thanks,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6167#issuecomment-621738904:106,clear,clearly,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6167#issuecomment-621738904,1,['clear'],['clearly']
Usability,"Despite possible not-best practices, it is alarming that this base-quality clipping action is occurring for reads that HaplotypeCaller sees (reads pass engine filtering), that it is undocumented, and that it seems to inconsistently alternate between assigning ! and 5 scores. Should note that the users who reported this inconsistency also have proposed code changes to fix the inconsistency such that clipping does not occur at all. . It's not clear to me: ; [1] Do we intend for this clipping action to occur or not, and; [2] If yes, then is it clipping in a manner that we intend?. Please let me know if this is something to clarify on the documentation end. Also, if you need, I can bundle up the data I generated in broadinstitute/dsde-docs#2661 towards examining this case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3834#issuecomment-344370788:182,undo,undocumented,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3834#issuecomment-344370788,2,"['clear', 'undo']","['clear', 'undocumented']"
Usability,"Did a quick test with sklearn's BayesianGaussianMixture, fitting 8 components to 2.5M 10D points generated from 4 isotropic blobs. On a Google Colab instance (which I believe are n1-highmem-2s), 150 iterations (which I think is the current maximum) completed in 14 minutes, with `%memit` reporting a memory peak of ~1.5GB. Note that convergence within the default tolerance isn't actually reached in 150 iterations for this toy data (as usual, it takes a while for the weights of unused components to shrink to zero). In any case, we'd have to compare against the number of iterations currently required to converge with the real data (and perhaps also check that the convergence criteria match up) to get a better idea of real runtime. Various tweaks to priors or other runtime options (such as k-means vs. random initialization) could also affect convergence speed. Minibatching isn't built in, but I think it should be pretty trivial to hack together something with the `warm_start` option; we could probably just do a warm start with a subset of the data. See also https://github.com/scikit-learn/scikit-learn/pull/9334.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6425#issuecomment-594205039:1095,learn,learn,1095,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6425#issuecomment-594205039,2,['learn'],['learn']
Usability,"Did some more thinking about this issue. Ideally, we'd drop all -L bins that overlap at all with any -XL regions, then check that the remaining bins are a subset of the annotated intervals and/or count files, if available. This seems most natural, in that -L/-XL would specify the desired set of intervals for filtering, and we'd fail if all of these are not available in the other inputs. However, due to the way intervals are resolved by the engine, I don't think it's easy to identify which bins overlap with -XL regions---the engine will instead split bins and retain the parts that don't overlap. So alternatively, if we assume that in typical use the annotated intervals and count files will contain the desired intervals as a subset, we can simply take the intersection of all intervals to drop these partial bins. However, if a user screws up and provides annotated intervals or count files with bins that don't match those specified via -L, then we don't really have a good strategy for failing---probably the only fair check we can do is fail if no bins remain after intersection. If we assume that users will typically be using or following the WDL, I think I'm OK with the second strategy. Any objections or thoughts, @sooheelee?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5388#issuecomment-437393687:748,simpl,simply,748,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5388#issuecomment-437393687,1,['simpl'],['simply']
Usability,"Did you ever hook up the new qual to the genotyping? I read this ticket as; asking for genotype posteriors to be output by HC/GGVCFs. On Wed, Apr 10, 2019, 2:22 PM David Benjamin <notifications@github.com>; wrote:. > @ldgauthier <https://github.com/ldgauthier> This ticket seems to be; > asking for genotype priors i.e. population allele frequencies to be learned; > within joint calling. If I interpret the request correctly, that's what new; > qual does. Can we close this?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5244#issuecomment-481806389>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdFqZ7Nrl4o9sSY5GwbEAvb0e6XuUks5vfiv7gaJpZM4XCuSv>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5244#issuecomment-483664820:356,learn,learned,356,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5244#issuecomment-483664820,1,['learn'],['learned']
Usability,"Dijkstra origina algorithm is about finding the single shortest route (or one of the in case of a tie), here we need the one that finds the K-shortest routes which is described [here](https://en.wikipedia.org/wiki/K_shortest_path_routing). Is this one implanted in Jgraph? In that case, yes we could.... . Otherwise if we have to implement the it from scratch... then there is no guaranteed the code is going to be simpler.... it could simpler just because I didn't bother to make the current one as simple as it could be.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3561#issuecomment-328169271:415,simpl,simpler,415,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3561#issuecomment-328169271,3,['simpl'],"['simple', 'simpler']"
Usability,"Disagree. For sophisticated Java developers like us, it's clear enough. But will the average GATK user know that `source release 1.8` refers to **Java 8**, and that they may need to set their Java default version **manually** even after installing Java 8? Would like to hear from @vdauwera on this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/489#issuecomment-119227449:58,clear,clear,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/489#issuecomment-119227449,1,['clear'],['clear']
Usability,Does functotator support structural variants now? It is not clear from the documentation or this Github issue. Cheers!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4083#issuecomment-788084917:60,clear,clear,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4083#issuecomment-788084917,1,['clear'],['clear']
Usability,"Done with my review. Thanks for doing this much-needed refactor! The BaseRecal stuff looks sound, but I have some other feedback that we should discuss/address.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/911#issuecomment-142750080:120,feedback,feedback,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/911#issuecomment-142750080,1,['feedback'],['feedback']
Usability,"EFkamFjZW5jeVJlZmVyZW5jZUxvY2F0aW9ucy5qYXZh) | `90.377% <85.714%> (ø)` | `55 <0> (ø)` | :x: |; | [...lbender/tools/spark/sv/SVVariantConsensusCall.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...3ac3c99977729d83c38f42bd372cece0a16df996?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TVlZhcmlhbnRDb25zZW5zdXNDYWxsLmphdmE=) | `85.556% <89.474%> (-1.33%)` | `21 <0> (-14)` | |; | [...bender/tools/spark/sv/AssemblyAlignmentParser.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...3ac3c99977729d83c38f42bd372cece0a16df996?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9Bc3NlbWJseUFsaWdubWVudFBhcnNlci5qYXZh) | `64.706% <90.741%> (+12.941%)` | `32 <31> (+19)` | :white_check_mark: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...3ac3c99977729d83c38f42bd372cece0a16df996?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `73.611% <0%> (-2.083%)` | `36% <0%> (ø)` | |; | ... and [1 more](https://codecov.io/gh/broadinstitute/gatk/pull/2376?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2376?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2376?src=pr&el=footer). Last update [92cb860...3ac3c99](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...3ac3c99977729d83c38f42bd372cece0a16df996?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2376#issuecomment-276436132:4574,learn,learn,4574,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2376#issuecomment-276436132,1,['learn'],['learn']
Usability,"Evaluation is so complicated (as necessary, and correctly so) now as we learned along the way, this ticket is no longer relevant.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4684#issuecomment-566723997:72,learn,learned,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4684#issuecomment-566723997,1,['learn'],['learned']
Usability,"Even if we had default methods, `Locatable` should be simple (like `Comparable`) and shouldn't be polluted with every possible operation you might want to perform on an interval.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/305#issuecomment-79198026:54,simpl,simple,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/305#issuecomment-79198026,1,['simpl'],['simple']
Usability,"FBhcnNlci5qYXZh) | `67.476% <0%> (+0.558%)` | `66% <0%> (+28%)` | :arrow_up: |; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...8e22a8a5969d2efc6f49ac272e53e893eb5eb048?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `86.911% <0%> (+1.427%)` | `74% <0%> (+25%)` | :arrow_up: |; | [...stitute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...8e22a8a5969d2efc6f49ac272e53e893eb5eb048?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `95.714% <0%> (+2.456%)` | `48% <0%> (+19%)` | :arrow_up: |; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...8e22a8a5969d2efc6f49ac272e53e893eb5eb048?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `87.156% <0%> (+2.945%)` | `59% <0%> (+6%)` | :arrow_up: |; | ... and [3 more](https://codecov.io/gh/broadinstitute/gatk/pull/2488?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2488?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2488?src=pr&el=footer). Last update [e1e71d7...8e22a8a](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...8e22a8a5969d2efc6f49ac272e53e893eb5eb048?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2488#issuecomment-287907716:4600,learn,learn,4600,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2488#issuecomment-287907716,1,['learn'],['learn']
Usability,"FWIW I poked around a bit with the deflater and the main issue is that if we pass the deflater as a parameter then the default is specified simply by a constructor call and not by a run-time constant (also, the deflater can only be created once the compression level is known which is very late) and so there's no longer a central place where everyone gets their customizable deflaters from. I have a solution that I can submit for review in the next few days (make `DeflaterFactory` a proper factory with an overridable `makeDeflater` method, make it settable on writerFactory and also and provide a default one that can be set/queried in `BlockCompressedOutputStream.getDeflaterFactory` - that way one can set the default once and for all for everyone and also selectively use different deflaters for different writers is one so desires).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1867#issuecomment-223078285:140,simpl,simply,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1867#issuecomment-223078285,1,['simpl'],['simply']
Usability,"FYI I'm planning a ""GATK 4 Alpha"" category for the forum + documentation guide to host the user-facing documentation, so feel free to keep the developer docs in the readme -- or we'll add a note in the readme pointing to the forum/guide pages.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1049#issuecomment-151661949:73,guid,guide,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1049#issuecomment-151661949,2,['guid'],['guide']
Usability,"Fair enough. So could you then give guidance on how much it would require as a function of number of read groups? Since we're scrapping indels, the context covariate is just previous base.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1460#issuecomment-178321797:36,guid,guidance,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1460#issuecomment-178321797,1,['guid'],['guidance']
Usability,"Fine but this is clearly premature optimization. How about a class called Intervals or intervalutils for this sort of random; utility ?. On Thursday, February 18, 2016, droazen notifications@github.com wrote:. > @akiezun https://github.com/akiezun What will actually happen is that; > someone will need that functionality months from now, forget that it; > already exists (embedded in some random tool), and re-implement it. It; > should be moved back now before this is allowed to happen.; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/gatk/pull/1497#issuecomment-185886728. ## . Sent from Gmail Mobile",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1497#issuecomment-185888065:17,clear,clearly,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1497#issuecomment-185888065,1,['clear'],['clearly']
Usability,"Fine either way, as long as it's clear what remains to be done",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1771#issuecomment-224300621:33,clear,clear,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1771#issuecomment-224300621,1,['clear'],['clear']
Usability,"First-pass review complete -- back to @tomwhite. Many of my suggestions center around pushing arguments and functionality up into `GATKSparkTool` as much as possible, even if they're not applicable to every tool, as we ideally want to spare tool authors from having to manually manage these low-level Spark parameters when they don't want/need to, and we also want to enforce consistency across tools and avoid duplicated boilerplate code. At the same time, there should be clear mechanisms for tools to override the defaults when they have to (eg., overridable methods in `GATKSparkTool`), as I'm not sure whether tools like BQSR are going to be happy with the new 128 MB default input split size.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1432#issuecomment-172100907:474,clear,clear,474,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1432#issuecomment-172100907,1,['clear'],['clear']
Usability,"First-pass review complete, back to @akiezun. This is a bit messy/spotty, with large blocks of missing GATK3 functionality, some annotations not in a usable state (eg., `AS_QualByDepth`), lots of TODOs in the code, and the branch is not currently compiling. We can probably get it merged in as a work-in-progress, but we should make sure we have tickets to capture the remaining work to be done.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1840#issuecomment-223696878:150,usab,usable,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1840#issuecomment-223696878,1,['usab'],['usable']
Usability,"Fixing the tests failures. Some simple ones (test groups now ""_todo"", rename test inputs on git too). One of them is weird, and only reproduces with the command line... after many minutes of running...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/812#issuecomment-132282122:32,simpl,simple,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/812#issuecomment-132282122,1,['simpl'],['simple']
Usability,For @cmnbroad. It shouldn't be too hard to implement some simple mechanism here. . Needed for @lucidtronix 's work on the next-generation VQSR.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3698#issuecomment-336995777:58,simpl,simple,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3698#issuecomment-336995777,1,['simpl'],['simple']
Usability,For @jamesemery -- this would be a good one for learning about Spark serialization,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1926#issuecomment-227537537:48,learn,learning,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1926#issuecomment-227537537,1,['learn'],['learning']
Usability,"For a quick analysis, I made a serialized versions of DBSNP (13572728 variants from `dbsnp_135.b37.excluding_sites_after_129.vcf`), size of VCF on disk 2175071049 bytes (2.0G). (all false postive probs are predicted, it'd be easy to measure it too). Map keys are contig names. ```; Map of String->BloomFilter with 0.001 false positive prob = 27320529 bytes (26M); Map of String->BloomFilter with 0.0004 false positive prob = 30943001 bytes (30M); Map of String->BloomFilter with 0.0001 false positive prob = 36423625 bytes (35M); Map of String->BloomFilter with 0.00004 false positive prob = 40046089 bytes (38M); Map of String->BloomFilter with 0.00001 false positive prob = 45526681 bytes (43M); Map of String->BloomFilter with 0.000001 false positive prob = 54629745 bytes (52M); Map of String->int[] of positions = 60790452 bytes (58M); List<GATKVariant> made just like the one in spark BQSR = 366463957 bytes (349M); ```. Variants from dbSNP cover 0.004 of the genome (15195436 bases of 3101804739) so if we want reasonable precision (number of false positives over all reported hits), say 0.9 precision (of 10 hits only 1 can be false) we need (1-0.9) x 0.004 false positive prob = 0.0004. For 0.99 precision (of 100 hits only 1 can be false) we need (1-0.99) x 0.004 false postive prob = 0.00004. These are approximations of course. Given these numbers, I conclude that, for now, exploring BloomFilters does not seem to make sense (too little saving and too many complications with using a probabilistic data structure - eg we'd need to use it too for the walker BQSR). It does make sense however to explore alternatives to the list of GATKVariants because it's very big when serialized (maybe Kryo does a better job but it's still a big object). A simple alternative like sorted int[] may be sufficient and has attractive properties (trivial to implement and understand, O(log) lookups, 0% false positives, small size when serialized).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1407#issuecomment-203727133:1756,simpl,simple,1756,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1407#issuecomment-203727133,1,['simpl'],['simple']
Usability,"For a single sample with uncovered intervals and the interval-median filter disabled, it looks like the PoN builds successfully, but we get a `java.lang.IllegalArgumentException: Non-finite log2 copy ratio is not allowed` later on in DenoiseReadCounts. Probably should fail earlier in CreateReadCountPanelOfNormals, but it looks like bad behavior is ultimately prevented. For multiple samples with completely uncovered intervals and the relevant filters disabled, an exception is thrown when the SVD fails (unless the SVD is skipped by requesting `--number-of-eigensamples 0`, in which case behavior reverts to the above). Probably could fail a bit earlier here as well. Note that running with the interval-median filter disabled is atypical, but it is done in CreateReadCountPanelOfNormalsIntegrationTest simply to make checking filtering of simulated data a little more sane.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6878#issuecomment-705946973:806,simpl,simply,806,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6878#issuecomment-705946973,1,['simpl'],['simply']
Usability,"For now we'll use tribble to index the locatable *SV sources. For gene name / transcript ID indexed files, we will use simple maps (key -> annotation list) for now. Down the road we may explore methods to speed this up, maybe with a database.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3758#issuecomment-347610537:119,simpl,simple,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3758#issuecomment-347610537,1,['simpl'],['simple']
Usability,"For record keeping, as the comments and replies may be buried in the many commits. ------------; ### On the problem of too many splits of RDD and performance concerns. Initial comment by @cwhelan :; > I'm starting to really not like this approach of splitting up the RDD into lots of smaller RDDs for later processing. It seems inefficient to me: it launches tons of different Spark stages each of which has a bunch of overhead. Perhaps not in this PR, but I think it would be better to classify the contigs on the fly and dispatch them to the right processing methods in a single pass over the RDD. Reply by @SHuang-Broad. > I tried to fix it in this PR, but that seems to be a big task,; and probably is impossible to achieve in a single pass,; because currently each class of contig ends up producing a different type of object; (3 general classes: simple -> SimpleNovelAdjacency, complex -> ComplexVariantCanonicalRepresentation, and unknown -> SAM records of the contigs); and a groupBy() operation is necessary in the middle using these objects as keys; due to the fact that different contigs may produce the same variant; So what I'm thinking about, is two pass:; one pass for splitting them up into the 3 classes,; then another pass on each of those 3 RDD's to turn them into VariantContext's.; Any better idea?. Reply by @cwhelan ; > That would be better, and yeah you don't have to do it in this PR.; In theory you could make the keys for the groupByKey() (ie NovelAdjacencyAndAltHaplotype, CpxVariantCanonicalRepresentation, right?) all inherit from the same superclass and do a single group by, couldn't you? Then you could do everything in a single pass. Reply by @SHuang-Broad; > Yes, that is what I'm planning but I'm not sure yet about how to approach that (I actually tried it, before putting in the above comment, and quickly ran into the problem of mixing Java serialization and Kryo serialization, so a larger re-structuring might be needed, and not just a inheritance structure). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030:852,simpl,simple,852,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030,1,['simpl'],['simple']
Usability,"For reference, doc from the GATK3 best practices (https://www.broadinstitute.org/gatk/guide/tooldocs/org_broadinstitute_gatk_tools_walkers_bqsr_AnalyzeCovariates.php). ```; # Generate the first pass recalibration table file.; java -jar GenomeAnalysisTK.jar \; -T BaseRecalibrator \; -R myreference.fasta \; -I myinput.bam \; -knownSites bundle/my-trusted-snps.vcf \ # optional but recommendable; -knownSites bundle/my-trusted-indels.vcf \ # optional but recommendable; ... other options; -o firstpass.table. # Generate the second pass recalibration table file.; java -jar GenomeAnalysisTK.jar \; -T BaseRecalibrator \; -BQSR firstpass.table \; -R myreference.fasta \; -I myinput.bam \; -knownSites bundle/my-trusted-snps.vcf \; -knownSites bundle/my-trusted-indels.vcf \; ... other options \; -o secondpass.table. # Finally generate the plots and also keep a copy of the csv (optional).; java -jar GenomeAnalysisTK.jar \; -T AnalyzeCovariates \; -R myrefernce.fasta \; -before firstpass.table \; -after secondpass.table \; -csv BQSR.csv \ # optional; -plots BQSR.pdf; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/322#issuecomment-94592372:86,guid,guide,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/322#issuecomment-94592372,1,['guid'],['guide']
Usability,"For repeated operators (whether xIyI or xMyM), I think GATK3 has/had a function to simplify cigars to ""sanitize"" that situation. In terms of desired behavior, we don't want to filter out the reads, we want to transform them to be processable without difficulty. I think xIyD should be considered valid.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/428#issuecomment-95056320:83,simpl,simplify,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/428#issuecomment-95056320,1,['simpl'],['simplify']
Usability,"For reporting the number of reads that fails each of the filters, the composed filter could be changed by a `CountingReadFilter`; using the `getSummaryLine()` method will provide the number of reads failing each of the components. Developers could have in their tools a field with the `WellFormedReadFilter` and call a new method for reporting the summary, to log a warning/debug line. For exploding depending on the tool, maybe an advance/hidden argument can be added to the filter (something like `--failOnMalformed`) to throw an exception if true; developers might add a default filter with this value equals to true if they want to enforce by default this behaviour. I think that this a simpler idea for allow the developer to choose, and give some flexibility to the user to change the behaviour as its own risk (they can disable all filters anyway, which is also risky).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3454#issuecomment-323698699:691,simpl,simpler,691,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3454#issuecomment-323698699,1,['simpl'],['simpler']
Usability,"For the most part I expect people use the precompiled jar for production; work, so I'm not too worried about that. Just make sure to have a TL;DR; line at the top of the readme that makes it clear what this is. On Mon, Oct 5, 2015 at 1:16 PM, Adam Kiezun notifications@github.com; wrote:. > sad but necessary; > @vdauwera https://github.com/vdauwera will buy us a plush hellbender; > ; > BTW, @vdauwera https://github.com/vdauwera will people be confused when; > they find the broadinstitute/gatk repository and think this is the 3.x; > branch that they can use for production? I bet they will - what should we; > do about this then?; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/hellbender/issues/945#issuecomment-145602883; > . ## . Geraldine A. Van der Auwera, Ph.D.; Group leader, Comms & Support; Data Science & Data Engineering; Broad Institute",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/945#issuecomment-145615665:191,clear,clear,191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/945#issuecomment-145615665,1,['clear'],['clear']
Usability,"For what its worth, I know I always find it difficult to find things on the GATK forums. A wiki is a much clearer way for me to navigate static information. It's also easy for everyone to edit and has a clear history.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1049#issuecomment-151874932:106,clear,clearer,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1049#issuecomment-151874932,2,['clear'],"['clear', 'clearer']"
Usability,"From Lee:. he COSMIC datasource in oncotator simply finds all overlapping records and counts the protein change (""Mutation AA"") values. Like a histogram of all overlapping records. (edited). `mutation_AAs = collections.Counter([entry['Mutation AA'] for entry in overlapping_cosmic_entries])`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4400#issuecomment-420360969:45,simpl,simply,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4400#issuecomment-420360969,1,['simpl'],['simply']
Usability,"Gave a bit of initial feedback -- will do a full review next week, and answer all of the questions you posted.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/792#issuecomment-128807445:22,feedback,feedback,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/792#issuecomment-128807445,1,['feedback'],['feedback']
Usability,"GenomicsDB workspaces can be moved freely - i.e., there is nothing about the workspace name or path that cannot be changed after initial creation. This wasn't true in the past (way way back in the past) but is certainly true now. Just want to clarify that in case that wasn't clear. I guess I see this as six of one, half a dozen of the other. Currently, the user can copy the initial workspace to a new location and incrementally import samples to the new location. The option proposed by @bbimber (specify existing workspace, new gVCFs and new output location) would require the tool to copy the existing workspace to the new location and then import new samples to it. Only real difference is who is doing the copying.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6558#issuecomment-617366264:276,clear,clear,276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6558#issuecomment-617366264,1,['clear'],['clear']
Usability,"Good catches, thank you! I've switched to using paging as you recommend since the code's a big shorter and simpler that way. I'll squash&merge once tests pass, unless you object.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/869#issuecomment-135875333:107,simpl,simpler,107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/869#issuecomment-135875333,1,['simpl'],['simpler']
Usability,"Good point. In the cases when you're running a tool on a data set with a knowable number of records, it would be useful to have this feedback.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5179#issuecomment-420762396:133,feedback,feedback,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5179#issuecomment-420762396,1,['feedback'],['feedback']
Usability,"Great! I can't remember if I wrote up the design requirements somewhere, but they're simple. The only non-obvious thing is to take a ""high-confidence"" interval list where we assume anything not in the truth is a false positive (as in NIST GiaB). Might also be useful for DREAM, but I don't remember the details of how that truth data is represented.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2267#issuecomment-266453955:85,simpl,simple,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2267#issuecomment-266453955,1,['simpl'],['simple']
Usability,Great! Thanks for the feedback @magicDGS.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2315#issuecomment-286425107:22,feedback,feedback,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2315#issuecomment-286425107,1,['feedback'],['feedback']
Usability,HaplotypeCaller does not resume from where it stopped. If you need to perform the same task again restart the whole task using the very same commandline.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7454#issuecomment-918232900:25,resume,resume,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7454#issuecomment-918232900,1,['resume'],['resume']
Usability,Have since learned external tools can separate out mixed-type records into biallelic records.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1537#issuecomment-447900242:11,learn,learned,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1537#issuecomment-447900242,1,['learn'],['learned']
Usability,"Have to disagree with you on that point, @magicDGS. Comma-separated values for lists seems like the most straightforward/simple/human-editable approach, whereas the other options seem more complex (and therefore more messy/error-prone). (Unless it turns out that we need nested lists, which I'm hoping is not the case!)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307794543:121,simpl,simple,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307794543,1,['simpl'],['simple']
Usability,"Having the same issue here, and I follow essentially the same steps with .csi and .idx indexing for bam and .g.vcf files, respectively. ; @tfenne or anyone else, have you figured a workaround to worked with compressed VCF files properly indexed for large chromosomes (> 512 * 2^20)? . I would have to carry ~1000 uncompressed *.g.vcf to GenomicsDBImport and I simply don't have the disk-space for that manoeuvre.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6110#issuecomment-624152200:360,simpl,simply,360,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6110#issuecomment-624152200,1,['simpl'],['simply']
Usability,Hello @bbimber thank you for the response. I would recommend using the read filters (in your case `-rf MappingQualityReadFilter --minimum-mapping-quality ##` to achieve the same functionality as the `-mmq` argument from GATK3. When porting over the tool we tried to push as much functionality from obscure arguments into the existing filtering framework as possible and `-mmq` was one of the ones that was redundant as it was a simple filter placed on the reads before counting them which the existing filtering code was able to handle. I will add some lines to the documentation clarifying this for users in the future.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6617#issuecomment-634752928:428,simpl,simple,428,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6617#issuecomment-634752928,1,['simpl'],['simple']
Usability,"Hello @cmnbroad. My current solution satisfy all the constraints and it's not too complicated, although is not as simple as a common generic class that just need to be extended. Have a look and if you like it I can implement some tests for `CountingVariantFilter`; if not, I could come back to a separate `CountingVariantFilter` with its own and/or/negate inner classes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2195#issuecomment-272482490:114,simpl,simple,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2195#issuecomment-272482490,1,['simpl'],['simple']
Usability,"Hello Geraldine:. > On 1/Mar/2017, at 7:56 PM, Geraldine Van der Auwera <notifications@github.com> wrote:; > ; > @chlangley One thing we could potentially do to attract attention to this issue and solicit feedback from the community would be to feature it on the GATK blog. If you were to write a concise case study detailing the impact of the problem on your results, others may be motivated to look at their own results, and if it causes problems there, add their voices to yours. We're willing to bring this to public attention, we just don't have the bandwidth to do the legwork. I started to work on this a bit and found myself blocked. . At this point I have a simple question: The GATK blog is separate from the forum (?). When I am on the blog page I can’t seem to find a button to submit a new post. I must be missing something or the route to blog posting is only via the forum?. Sorry to bother you with such mundane question. Cheers,; Chuck",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/269#issuecomment-287541436:205,feedback,feedback,205,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/269#issuecomment-287541436,2,"['feedback', 'simpl']","['feedback', 'simple']"
Usability,"Hello Laura, one question. You stated that the above alt allele should be treated as a deletion. Just wanted to check with you a boolean condition to determine if an alt allele is a deletion (not including symbolic allele handling for simplicity):; ```cpp; is_deletion = ( ref_allele.length() > alt_allele.length() ); || ( ref_allele.length() == alt_allele.length() ; && ref_allele[0] == alt_allele[0] ); ```; The second predicate in the OR expression is for the case described above. Do you think this condition is correct?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6500#issuecomment-601676489:235,simpl,simplicity,235,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6500#issuecomment-601676489,1,['simpl'],['simplicity']
Usability,"Hello everyone: I am realizing that the GATK framework is going to have a lot of dependencies from java and python even if the simpler framework is the one need it. Maybe it is a good idea to start thinking about sub-modules within the same repository for the engine (maybe even separate the Spark framework), CNV...and create an independent artifact for every of them, and one combined one. Does it sound reasonable?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-346051614:127,simpl,simpler,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-346051614,1,['simpl'],['simpler']
Usability,"Hello, ; I forgot to report back here. I figured out what my problem was:; I ran ApplyVQSR twice on my dataset. The first time with a sensitivity threshold of 99% and the second time with 97% (on the data which resulted from the 99% threshold run). When I use 97% right away everything worked. . However, I am still a little confused, why ""updating"" the sensitivity threshold results in my observed output, where these sites PASS the filtering and if I use 97% right away they do not pass. However, the ""fix"" (i.e. using the intended filtering threshold on the original data) is very simple and doesn't take long, so I will close this issue. Feel free to reopen if you need any more information. ; Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7259#issuecomment-847682476:584,simpl,simple,584,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7259#issuecomment-847682476,1,['simpl'],['simple']
Usability,"Hello,. @jonn-smith and @lbergelson: I'd like to make a custom data source using tabular data as the input. These data should be matched on position, not considering allele, using LocatableXSV as the type. There is an example of a TSV using Oreganno in the docs (https://gatk.broadinstitute.org/hc/en-us/articles/360035889931-Funcotator-Information-and-Tutorial).; however, I ran into two issues:. - A TSV needs to be indexed to be read. It's not clear how to generate an idx file from a non-bgzipped tsv. GATK's IndexFieldFile does not recognize basic TSVs as input files. Perhaps I'm missing something. - It would be possible to gzip the TSV and make a tabix index. The problem is that while most GATK code seamlessly handles unzipped or gzipped inputs, LocatableXsvFuncotationFactory expected unzipped. This is a minor change to the file reading code that allows gzipped TSV inputs. Below is an example input. You can bgzip this and index using:; ```; tabix textSource.txt.gz -s 1 -b 2 -e 3 -S 1 -f; ```; With this PR, I think funcotator will now support gzipped LocatableXSV sources. Would it be possible to add this?. [textSource.txt](https://github.com/broadinstitute/gatk/files/11747583/textSource.txt)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1591439727:447,clear,clear,447,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1591439727,1,['clear'],['clear']
Usability,"Hello,; yes simply because i was working under the base environment of conda, so; conda deactivate command solved the problem. Le dim. 9 avr. 2023 à 15:09, wangwenzheng-agis ***@***.***> a; écrit :. > Hi,i have the same problem, have you solve it ?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/8280#issuecomment-1501137724>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AWCQKJGPGKTPFL54TTIL5LLXAK7INANCNFSM6AAAAAAWV6IL2A>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8280#issuecomment-1501146041:12,simpl,simply,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8280#issuecomment-1501146041,1,['simpl'],['simply']
Usability,Here is a blog regarding the Deep CNN model used for variant filtering.... https://gatkforums.broadinstitute.org/gatk/discussion/10996/deep-learning-in-gatk4,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4511#issuecomment-371816136:140,learn,learning-in-,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4511#issuecomment-371816136,1,['learn'],['learning-in-']
Usability,Here's a profile. It's clear that all time goes into reading and writing and almost no overhead comes from the engine. Closing this - we win and no obvious problems in the profile.; ![image](https://cloud.githubusercontent.com/assets/1993519/10668338/da596c10-78a9-11e5-8aa0-b6c0ceddad08.png),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1035#issuecomment-150248706:23,clear,clear,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1035#issuecomment-150248706,1,['clear'],['clear']
Usability,"Here's a prototype showing one way of doing this: https://github.com/broadinstitute/gatk/commit/3cf7f9078b6aedcb87a4ca77c2aa8e84e7e5fe99. The idea is that `GATKTool` has a `-spark` flag, so you can run a tool in Spark mode. The parallel `GATKSparkTool` hierarchy would disappear, and tool writers would optionally be able to support Spark as an alternative to the regular walker, by providing the relevant code in the same tool class. As an example, the `FlagStat` implementation looks like this:. ``` java; @Override; public void traverse() {; if (sparkArgs.useSpark) {; sum = getReadsRdd().aggregate(new FlagStatus(), FlagStatus::add, FlagStatus::merge);; } else {; sum = getReadsStream().collect(FlagStatus::new, FlagStatus::add, FlagStatus::merge);; }; }; ```. Note that the walker version uses the Java 8 Streams API, while the Spark version uses the RDD API. While these are different APIs, many of the concepts are similar, so it should be possible to share the underlying logic by encapsulating it in classes, in much the same way as is done by the `FlagStatus` class for `FlagStat`. It would also be possible to keep the existing `apply` method for walker versions of tools that simply iterate over each record. Removing the parallel `GATKSparkTool` hierarchy has a number of benefits, such as reducing duplication, making it easier for tool writers to add Spark support, and making it easier to share tests. Thoughts? /cc @DR, @lbergelson, @cmnbroad",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2217#issuecomment-254180398:1188,simpl,simply,1188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2217#issuecomment-254180398,1,['simpl'],['simply']
Usability,"Here's how these scripts are organized and why they take the form it is now:. How to run; * `manage/project.sh` is the ""executable""; * paths for VCF files (zipped or not) from PacBio callsets on CHM haploids, and Manta's VCF on the mixture should be provided to `manage/project.sh`, and; * paths for two versions of GATK-SV callsets; one is fine, but scripts in the sub-directory `manage` must be modified. Two GATK-SV vcf files are requested because this would allow one to compare if a supposedly improvement would make our raw sensitivity/specificity better or worse, that was the use case [here](https://github.com/SHuang-Broad/GATK-SV-callset-regressionTest), and; * paths to where results are to be stored, one for each GATK-SV callset must be given and ; * path to where to store the results of comparing the two callsets; * several GNU bash utilities are expected, `guniq` and `gsort`, when run on a Mac, as well as `bedtools`. and what to expect; * the scripts checks the VCF files, prints to screen a slew of information that one can pipe, or simplely browse through.; * the scripts also outputs the ID's of variants from each of the two GATK callsets that are ""validated"" by PacBio haploid calls. Misc points:; * watch out for ""duplicated"" records, as sometimes different assembly contigs mapped to the same locations have slightly different alleles (SNP, for example) hence both would be output, but there aren't many such records based on experience; * there are also some variants that we output to the VCFs having size <50 or >50K, both of which are filtered upfront and saved separately.; * The scripts started when we first call insertions, deletions, inversions and small duplications, and back then PacBio call sets on the CHM haploids were not available, so Manta's calls were used as ""reference"", that explains why they are referred to throughout the project",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4406#issuecomment-365730030:1053,simpl,simplely,1053,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4406#issuecomment-365730030,1,['simpl'],['simplely']
Usability,"Here's some old code that uses SamLocusIterator (from tfennel) that AllelicCapseg can adapt for now. From Tim:; ""They key to making this nice and simple is the SamLocusIterator class, which given a BAM file and a list of intervals, will give you pileups at each position in the intervals, filtered how you want them, and even provide convenience methods to access the exact base per read that is piled up at the site etc. The really nice things about doing it this way is that the constructor to SamLocusIterator takes a simple parameter to tell it whether to use an index/query mechanism (similar to what you're doing now) or to just read the BAM serially up until the last interval is reached and output the loci of interest. Running the below with ~100k sites on a standard exome (15GB or so) without using the index took only about 15 minutes."". ```; public void pileup(final File bam, final IntervalList intervals, final int minQ, final File outputFile) {; final int MAX_INTERVALS_FOR_INDEX = 25000; // just a guess, not sure what the right number is. final SamLocusIterator iterator = new SamLocusIterator(new SAMFileReader(bam), intervals, intervals.size() < MAX_INTERVALS_FOR_INDEX);; iterator.setEmitUncoveredLoci(false);; iterator.setQualityScoreCutoff(minQ);. final BufferedWriter out = IoUtil.openFileForBufferedWriting(outputFile); // will automatically gzip if filename ends with .gz; try {; while (iterator.hasNext()) {; final SamLocusIterator.LocusInfo locus = iterator.next();; int a=0, c=0, g=0, t=0;. for (final SamLocusIterator.RecordAndOffset rec : locus.getRecordAndPositions()) {; switch (rec.getReadBase()) {; case 'A' : ++a; break;; case 'C' : ++c; break;; case 'G' : ++g; break;; case 'T' : ++t; break;; }; }. out.append(locus.getSequenceName() + ""\t"" + locus.getPosition() + ""\t"" + a + ""\t"" + c + ""\t"" + g + ""\t"" + t + ""\t"");; }. out.close(); ; }; catch (IOException ioe) { throw new RuntimeIOException(ioe); }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/335#issuecomment-88102420:146,simpl,simple,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/335#issuecomment-88102420,2,['simpl'],['simple']
Usability,"Hey @bbimber I will have to think on this. The most simple solution might be to add a feature context side input for the annotation in question but looking at how that code is threaded in the variant callers it would take a little bit of work to add it to those tools and probably introduce some complicated questions, (like for example: what is the correct featurecontext to send to annotate a variant that only covers one base of the site in question where the feature context object exists?). Its possible to do something like that for variant annotator a little bit more easily but i guess the question comes down to this: How generalized do you think this annotation will be? Does it need to be annotatable with variant annotator or could you write a separate tool that does the variant -> variant association and calculates the annotation without using the plugin framework? If it needs to be generalizable I would agree with @droazen that the easiest approach would be to add the side input as an argument and make the annotation object responsible for querying the feature context. This is inelegant but might be preferable to putting the entire walker context into the `annotate()` function.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-754249851:52,simpl,simple,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-754249851,1,['simpl'],['simple']
Usability,"Hey @brianjohnhaas. I'm not quite sure i fully understand what we can change to help you here. However there is a feature you might not be aware of in the bamout that can help you figure out which reads go with what haplotype. In our bamout we assign a tag (that for whatever reason it looks like IGV hides by default) called the XA tag. If you look at an IGV bamout and color by that tag you can see what reads were grouped by what haplotypes. If a read has no XA tag that means it was non-informative about any one haplotype over a second possible contender and thus it was not strong evidence one way or another. Given that in reality when genotyping we are taking the net likelihoods of all reads vs all haplotypes its somewhat of a simplification to say ""this read comes from that haplotype"" as often reads can be evidence for a number of haplotypes that might get called in aggregate but this simplification works in simple cases. Below is a screenshot of what it looks like to do this in a very simple case. Hopefully this answers your question? I would be happy to go deeper into this if you would like. . ![Screenshot 2024-03-08 at 2 35 42 PM](https://github.com/broadinstitute/gatk/assets/16102845/7d11ff5f-418e-4826-89fc-07535648a71f)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1986302994:737,simpl,simplification,737,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1986302994,4,['simpl'],"['simple', 'simplification']"
Usability,Hey @gokalpcelik thanks for writing in. So there are a few important differences that could be confounding the results you see for SplitNCigarReads between GATK3 and GATK4. The big one is that in GATK 4 the reads get soft clipped instead of hard clipped and the subsequent splits for the reads are marked as Supplementary reads (which does not seem to have been the case in GATK3). Can you check that you aren't filtering non-primary alignments from your output/IGV sessions? Many downstream tools that might operate on split reads must be careful to handle these differences correctly which can easily cause confusion when comparing gatk3.8 results to gatk4+ results. A simple way to confirm is to slect one of those softclipped reads in IGV and to search the output BAM for GATK4 for reads sharing the same name. You should see the matched mates. If it really does appear that the right overhangs are getting dropped as appears from your screenshots then it would be helpful if you could clarify what arguments you ran for both versions of the tool as well as sharing with us an example file where this is happening.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7323#issuecomment-865275697:671,simpl,simple,671,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7323#issuecomment-865275697,1,['simpl'],['simple']
Usability,"Hey @jemunro,. Thanks for sharing your fix. I tried it on my data but now I have this ERROR message:; ```; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A GATK RUNTIME ERROR has occurred (version 3.8-0-ge9d806836):; ##### ERROR; ##### ERROR This might be a bug. Please check the documentation guide to see if this is a known problem.; ##### ERROR If not, please post the error message, with stack trace, to the GATK forum.; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR MESSAGE: For input string: ""NaN\1SOR=0.693""; ##### ERROR ------------------------------------------------------------------------------------------; INFO 13:46:00,793 HelpFormatter - ---------------------------------------------------------------------------------- ; ```; Would not be enough to use this code instead?:; ```; bcftools view in.vcf.gz |; sed 's/=nan/=NaN/g' |; bgzip > fixed.vcf.gz; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734:363,guid,guide,363,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734,1,['guid'],['guide']
Usability,"Hey @lbergelson, @droazen or @jamesemery: sorry to keep bugging you all here, but I'm not sure what else to do here. I'm hoping we can finalize and close out this feature, or identify what is needed to do so. I recapped the state of this PR in my post above. . I could make a clean feature branch with everything in one place if you want; however, if someone with write permissions could simply approve (https://github.com/broadinstitute/gatk/pull/8871) , merge into this branch, and kick off tests that is all I need right now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8752#issuecomment-2243039952:388,simpl,simply,388,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8752#issuecomment-2243039952,1,['simpl'],['simply']
Usability,"Hey @lucidtronix, sorry for the delay. . I like the CNNVariant* basename in principle, as it makes it easy to understand which tools are related. CNNVariantWriteTensors and CNNVariantTrain are both quite straightforward so no objections there. However I have some reservations about CNNVariantScore because it's ambiguous as to whether it refers to a score called that, or whether it's the verb to score. As I see it we could resolve that by simplifying the basename to just CNN, and making the three tools CNNWriteTensors, CNNTrainModel and CNNScoreVariants. What do you think? Do we have any reason to believe we would need to be able to call something else CNN* where *!=Variant? If not, the overall process can still be called CNNVariant without needing to include Variant explicitly in the tool names. . For VariantTranchesFromInfoKey, I'd like to find a simpler way to express what it does -- would FilterVariantTranches sound appropriate to you? I'm still a bit fuzzy on exactly what are the inputs/outputs of this tool. Is it a direct analog to the VQSR ApplyRecalibration tool, ie does it take a sensitivity threshold? And can one use any arbitrary Info key? That's what the current name implies to me.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-372466321:442,simpl,simplifying,442,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-372466321,2,['simpl'],"['simpler', 'simplifying']"
Usability,"Hey @mwalker174,. Setting `--host-min-identity 20` lowered the `READS_AFTER_PREALIGNED_HOST_FILTER` to 131467, which is closer to what I expected (albeit still 12% of the reads) so thanks for the suggestion. I'm still unsure why the preferred approach is to use this fairly arbitrary metric that doesn't incorporate both mates instead of leveraging the known alignments from STAR, which does. Given what I've learned today, I think the better approach (for my use case) would be to filter the unique mappers, the multi-mappers and the chimeric reads (which in my data set represent 97.5% of the reads) and then apply the QUALITY_AND_COMPLEXITY_FILTER and the DUPLICATE_READS_FILTER. Would you agree?. To put myself in your shoes, I would guess that PathSeq is designed for general purpose use cases (which is probably `--is-host-aligned false`) and that performing such a filtering would require specific handling for each supported aligner, which would be a lot of work. Moreover, my use case with short paired-end reads is also probably not common. So I understand why you use the existing approach but are there any reasons that I'm missing as to why you'd suggest to stick with the basic approach for my use case instead of the one that I proposed above?. Best, Welles",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6687#issuecomment-652524772:409,learn,learned,409,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6687#issuecomment-652524772,1,['learn'],['learned']
Usability,"Hey @samuelklee. That is true, the default location for a gradle test output is tests/#taskname#. I'm not sure what the problem is however. If you look at the gradle test logs there is a line pointing to where the reports live: "" Test report will be written to https://storage.googleapis.com/hellbender-test-logs/build_reports/master_20802.3/tests/test/index.html."" Those links seem to work on the latest master. We fix this by simply renaming the files before we upload them however. Is this explanation adequate or would you like the build system changed?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5029#issuecomment-406332294:428,simpl,simply,428,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5029#issuecomment-406332294,1,['simpl'],['simply']
Usability,"Hey all, I'm still interested in supporting this. We don't really have a ""plugin API"", I am in fact the API, but if you give me something usable I'll plug it in. As this is marked ""QuixoticDream"" I don't think that's likely. I'm closing the corresponding IGV issue, too many open issues, but it doesn't mean I've lost interest.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3286#issuecomment-433201230:138,usab,usable,138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3286#issuecomment-433201230,1,['usab'],['usable']
Usability,"Hi @LiviaMoura . We don't have any haploid calling in the Broad production pipeline, so we never included that feature in Gnarly. (For chrY people typically filter out hets and then treat 0/0 as 0 and 1/1 as 1. chrX on males admittedly requires a little more finesse.) I can probably take a look next week. I'm not sure how much effort a fix would entail, but hopefully the haploid case is just a simpler version of the diploid case right? :-)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7690#issuecomment-1049206545:397,simpl,simpler,397,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7690#issuecomment-1049206545,1,['simpl'],['simpler']
Usability,"Hi @Neato-Nick @davidbenjamin . Apologies for posting this message here. I have posted this message few days before at the regular GATK forum and also using the direct inbox option but have got no response so maybe something wrong with my account. The issue is - I have done variant calling on 384 potato samples following, mostly, GATK best ##practices and have applied hard filters to select SNPs for further usage. However, I am noticing that '--max-nocall-fraction', '--max-nocall-number' and '--max-fraction-filtered-genotypes' arguments for 'SelectVariants' are not working properly. I have tried with various cutoff settings and every time I am observing SNPs with a much larger number of genotypes (~246 out of 384 with 0.10 setting) with 'no call' than the set thresholds. I have searched the forum first but couldn't find any relevant threads. I am using the latest GATK version (4.0.7.0). I am attaching three example sets of (1) log files (2) subset vcf files and (3) vcf index file for the three main vcfs. I would appreciate if you could provide any feedback on this issue and/or if this behaviour has been observed by some other users also. The link to the original post is here:; https://gatkforums.broadinstitute.org/gatk/discussion/12688/possible-bug-in-selectvariants-tool#latest; [SelectVariantBugReport.zip](https://github.com/broadinstitute/gatk/files/2291206/SelectVariantBugReport.zip). Regards,; Sanjeev",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-413285177:1064,feedback,feedback,1064,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-413285177,1,['feedback'],['feedback']
Usability,Hi @RWilton i'm sorry to hear that. I suspect its unrelated given how simple this PR is but its quite possible that filter has been broken since evidently nobody was able to use and adjust it for a long time. This is the logic here that the filter uses:; `return read.isPaired() && !read.isUnmapped() && !read.mateIsUnmapped() &&; (Math.abs(read.getStart() - read.getMateStart()) >= mateTooDistantLength || !read.getContig().equals(read.getMateContig()));`. That logic is correct for what the filter is doing. It should be noted that the filter does the opposite of what you expect it to (since its intended for our SV pipeline) in that it filters out all reads that are NOT having distant mates. This means if you try to run HaplotypeCaller with this setting you will be throwing away every read pair EXCEPT the distant ones which results in mostly no reads. We should perhaps rename this filter to be a little less confusing.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7701#issuecomment-1103010098:70,simpl,simple,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7701#issuecomment-1103010098,1,['simpl'],['simple']
Usability,"Hi @ScienceConnor - thanks for the feedback, this is Ilya from Ultima Genomics. ; From what I see, this seems to me to be more of the output format issue rather than the issue with HaplotypeCaller per se.; Would you mind pinging me over ilya dot soifer at ultimagen dot com and I am happy to help you out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8112#issuecomment-1332400762:35,feedback,feedback,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8112#issuecomment-1332400762,1,['feedback'],['feedback']
Usability,"Hi @Tintest,. If you need some guidance in interpreting the WDL pipeline script that @samuelklee linked, please let me know.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5053#issuecomment-407771160:31,guid,guidance,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5053#issuecomment-407771160,1,['guid'],['guidance']
Usability,"Hi @bklein345, thanks for this contribution! I'd be happy to review, but the current CNV tech lead @mwalker174 should probably make the final decisions about how this tool should ultimately go in. A few quick thoughts:. 1) If you'd like to make the PR from your Broad account, feel free to reopen---either way is fine with us. However, if you do, perhaps pushing a fresh branch to this repo might make it a little easier for us to check it out for review---again, not a big deal, so I'll leave it up to you. 2) We try to adhere to the Google style guide https://google.github.io/styleguide/javaguide.html, so the review may yield a lot of seemingly minor and nitpicky change requests. Don't take these personally---the goal is just to make the code base as uniform and easy to maintain as possible! If you prefer, I'm sure we can find a GATK developer to take a quick once over of your branch and make these minor changes. 3) Since the new tool borrows so heavily from CollectAllelicCounts, I think it might be worth consolidating shared code and reducing code duplication---again, with the goal of making future maintenance more straightforward. I'll try to identify some places this can be done during my review. Again, we can make these changes on our end during the once over, or you can address them after the review (or we could also do this on our end in a separate PR after this one goes in). 4) In the near future, I think we should finally make the effort to replace both GetPileupSummaries and CollectAllelicCounts with this new tool. As mentioned in our email thread, @davidbenjamin and I discussed this long ago, e.g. https://github.com/broadinstitute/gatk/issues/4717#issuecomment-386734926. From a methods perspective, we'd simply need expand the current functionality of your tool to also report the reference allele and do some quick sanity checks to make sure that the differences in count definition and read filtering don't have any undesired downstream effects. However, as we als",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6543#issuecomment-610462293:548,guid,guide,548,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6543#issuecomment-610462293,1,['guid'],['guide']
Usability,"Hi @cwhelan , I've expanded this PR to do more than what it originally was trying to fix, and separated the patches by commits as usual:. * the originally proposed fix, which brings back the annotation that are available to simple variants but go missing due to a careless bug, is now done in commit 50f1b640a31ddb528dc763b83b26a9d98dce8556; this commit also accordingly refactors the giant class `CpxVariantDetector` into three new classes; * in the 2nd commit 734516383fb665a79796de76535560fc03cb754b, I did more refactoring on how we group the descriptions for the annotation keys, and updated the test VCF files accordingly.; * because of the refactoring, the review comments were gone, so I added them back in the 3rd commit b7619c45a949dfba21d65a5ed876bc72e832aa77, which contains the comments and my replies. They come in as TODO's but are going to be removed ultimately; * in the following commits, I added tests for the CPX code path, selecting three representative cases (there's no limit how complex the scenario can go). One particular commit 224c97c7b736e94ed6b4d8b067ec830a9f8f2403 is large but most of it is for adding a flat file that contains the chromosome names in hg38 and their lengths for building a bare bone sequence dictionary used in building test data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525:224,simpl,simple,224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525,1,['simpl'],['simple']
Usability,"Hi @david-wb . I reformatted your comment slightly to make the stack trace more legible, I hope you don't mind. I suspect your intuition about the System.exit(0) is entirely correct. I suspect we haven't noticed it because we typically run in yarn client mode and you're running in cluster mode. . Two questions:; 1. How often does it happen? Can you regularly reproduce it?; 2. Have you examined the output files to make sure they are correct and not truncated? . It looks like we'll probably have to add a check and wait for the spark context to properly shut down.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2666#issuecomment-299493397:127,intuit,intuition,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2666#issuecomment-299493397,1,['intuit'],['intuition']
Usability,"Hi @jean-philippe-martin ,. A `Feature` in our codebase has a specific meaning that is different from ""interval"": it is a record that 1. has a location on the genome plus (typically) some metadata information about that location and 2. is in one of the formats supported by our file-parsing framework tribble and is the product of a tribble codec. A VCF record is an example of a `Feature`. . The common interface between `Feature` and `SimpleInterval` is called `Locatable`. I recommend (for now) that you simply alter your uprooted version of BQSR to take a `List<? extends Locatable>` instead of a `List<? extends Feature>` in `apply()`. This should require no code changes beyond changing method parameter types, and it will allow you to feed BQSR `SimpleIntervals` for the known sites for now, and `Features` like VCF records later on when we're ready for that. Please do return `ArtificialTestFeature` to the `FeatureDataSourceUnitTest` from which it came -- this is a very incomplete class meant only for testing purposes and not for external use.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/511#issuecomment-100393247:507,simpl,simply,507,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/511#issuecomment-100393247,1,['simpl'],['simply']
Usability,"Hi @lbergelson and thanks for considering my issue,. I'm sorry but I'm not familiar to artifactory dependency, if necessary I'll deepen about it; so I just inserted this dependency in the project's pom.xml; ```; <dependency>; <groupId>org.broadinstitute</groupId>; <artifactId>gatk</artifactId>; <version>4.beta.6-18-g2ee7724-20171025.162137-1</version>; </dependency>; ```; as reported in the [artifact repository](https://broadinstitute.jfrog.io/broadinstitute/webapp/#/artifacts/browse/tree/General/libs-snapshot-local/org/broadinstitute/gatk/4.beta.6-18-g2ee7724-SNAPSHOT/gatk-4.beta.6-18-g2ee7724-20171025.162137-1.jar), but when I execute `mvn clear install` in my folder project, I receive this error: ; ```; [ERROR] Failed to execute goal on project GATKpipe: ; Could not resolve dependencies for project uk.ac.ncl:GATKpipe:jar:0.0.1-SNAPSHOT: ; Could not find artifact org.broadinstitute:gatk:jar:4.beta.6-18-g2ee7724-20171025.162137-1 -> [Help 1]; ```. Am I making any mistake?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339624024:650,clear,clear,650,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339624024,1,['clear'],['clear']
Usability,"Hi @magicDGS. After looking a bit more at this PR , and talking with others, I think we should put this branch on hold for a bit. We plan to introduce a new class soon that will serve as a common currency for input specifiers, and we'll probably want to revisit these constructors then. Hopefully that will be a simplifying change. In the meantime, I'd prefer not to introduce more overloads. We'd like to put this on hold until we make progress on that, and then perhaps resurrect parts of this branch as needed. My apologies for the churn.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-274960068:312,simpl,simplifying,312,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-274960068,1,['simpl'],['simplifying']
Usability,"Hi @magicDGS. I went down this same path (composition of CountingFilter) when I originally implemented CountingReadFilter, but I abandoned it for the model we currently have. I think the current model is much simpler in a number of ways. This is an interesting problem, but I would say lets just implement a straight CountingVariantFilter/tests and not try to do the common implementation. . BTW, when looking at this PR I noticed two bugs in the existing code that we should make sure not to propagate to the Variant one (feel free to fix/test these as part of this PR):. - CountingReadFilter.resetFilterCount only resets the root filter count; it needs an override in BinOp to propagate the reset call to the lhs/rhs operands.; - there is a bug in the getSummary tests/code; you can see the fix [here](https://github.com/broadinstitute/gatk/commit/9ef1458271834aed9b64a5d66f94df33f025eafb). Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2195#issuecomment-272954313:209,simpl,simpler,209,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2195#issuecomment-272954313,1,['simpl'],['simpler']
Usability,Hi @potter-s ; Our docker image is already built with root account only however PATH is set to be usable by all users so if you wish to keep user priviledges after execution you may add ` -u $UID:$GID` parameter to docker command line therefore the container will run using your user permissions. . This has a catch of course. Temporary folders must be set where your user has RWX permissions therefore we want users to pay attention to that. There is a writing that we posted a while ago which you may refer to for setting up your temporary files for GATK workflows. . [How to setup temporary folder for GATK local executtion](https://gatk.broadinstitute.org/hc/en-us/articles/18965297287067-How-to-setup-and-use-temporary-folder-for-GATK-local-execution). For some of the tools such as gCNV or CNN you may need to setup additional environment variables to locate python compilation directory to a place where you have read and write permissions. . I hope this helps.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8856#issuecomment-2145780965:98,usab,usable,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8856#issuecomment-2145780965,1,['usab'],['usable']
Usability,"Hi @qindan2008 - is this the full log file that is produced, or is there more to it? If there is more to the log file can you post it? Would you mind posting one or two of your variants as well? They can be simplified - I only the need position and alleles. Also, did you happen to make any modifications to the data sources? If you enabled gnomAD, Funcotator will try to read the gnomAD data sources via the Google Cloud API, which may be slow or fail depending on your internet connection and settings. You could experience similar issues if you added another web-facing data source.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7135#issuecomment-799646869:207,simpl,simplified,207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7135#issuecomment-799646869,1,['simpl'],['simplified']
Usability,"Hi @samuelklee ; yes you are right, I did not recreate the conda environment when updating to 4.0.3.0. I'll try that and give you a feedback. Do you know the state of developement of the germline CNV best practise or a short manual?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4679#issuecomment-382717819:132,feedback,feedback,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4679#issuecomment-382717819,1,['feedback'],['feedback']
Usability,Hi @samuelklee @mwalker174 . New defaults are clearly not suitable for anyone to use them directly. I forgot to pay attention to this detail and realized that all my female samples turned turner (X:1 Y:0) due to these new parameters (I reverted these parameters and looks like the problem is solved). Could that be possible that UKBB is using a very heterogenous exome dataset generated from different centers with different kits etc..?. My sample set is usually smaller like 50 to 100 samples at a time but sequenced using a single instrument and single kit so I expect them to be more homogenous compared to UKBB. I also tend to remove samples with extreme AT/GC Dropout values (samples with values greater or equal to ~%9 are removed from my set. Of course I usually check for mean and median values as well for that I may keep some but still remove anything more than %10) which kills the whole purpose of CNV calling due to extreme fluctuation.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8628#issuecomment-1858805583:46,clear,clearly,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8628#issuecomment-1858805583,1,['clear'],['clearly']
Usability,"Hi @tedsharpe ! . I also commented about it on the helpdesk but should probably reply directly here. The .bam file was aligned to a reference , the same reference I used to run the tool. I was wondering If the bam still contained unmapped reads and so used ; `samtools view -b -F 4` on the file to retain only mapped reads and re-run the GATK tool. However this did not improve the situation. Best,; Domniki. error log:. 22/03/11 06:13:57 INFO SparkUI: Stopped Spark web UI at http://10.222.0.104:4040; 22/03/11 06:13:57 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 22/03/11 06:13:58 INFO MemoryStore: MemoryStore cleared; 22/03/11 06:13:58 INFO BlockManager: BlockManager stopped; 22/03/11 06:13:58 INFO BlockManagerMaster: BlockManagerMaster stopped; 22/03/11 06:13:58 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 22/03/11 06:13:58 INFO SparkContext: Successfully stopped SparkContext; 06:13:58.369 INFO FindBreakpointEvidenceSpark - Shutting down engine; [March 11, 2022 6:13:58 AM GMT] org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark done. Elapsed time: 3.28 minutes.; Runtime.totalMemory()=29312942080; java.lang.ArithmeticException: / by zero; at org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark.removeUbiquitousKmers(FindBreakpointEvidenceSpark.java:640); at org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark.addAssemblyQNames(FindBreakpointEvidenceSpark.java:507); at org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark.gatherEvidenceAndWriteContigSamFile(FindBreakpointEvidenceSpark.; at org.broadinstitute.hellbender.tools.spark.sv.evidence.FindBreakpointEvidenceSpark.runTool(FindBreakpointEvidenceSpark.java:136); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:546); at org.broadinstitute.hellbender.engine.spark.SparkCommandLinePro",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7710#issuecomment-1064823936:647,clear,cleared,647,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7710#issuecomment-1064823936,1,['clear'],['cleared']
Usability,"Hi @wujh2017,. You should filter your variants using the various quality scores described in the VCF header. We find that simply filtering on QS is typically a good strategy. Also, you might find it more helpful to post this sort of question in the GATK forums---other users might benefit from seeing the answer there.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4790#issuecomment-394487888:122,simpl,simply,122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4790#issuecomment-394487888,1,['simpl'],['simply']
Usability,"Hi Adam,. Maybe I'm thinking naively here - and I don't have access to a complete and proper Spark cluster for rigorous testing - but just as a simple test of loading a VCF via Spark, I took [PrintReadsSpark.java](https://github.com/broadinstitute/gatk/blob/030858bc08328200b9df287db2571b907189ec66/src/main/java/org/broadinstitute/hellbender/tools/spark/pipelines/PrintReadsSpark.java) and performed following updates:; - Copied `./src/test/resources/org/broadinstitute/hellbender/utils/SequenceDictionaryUtils/test.vcf` into the local directory.; - Renamed the copy of `PrintReadsSpark.java` as `PrintVCFSpark.java`; - Added `import org.broadinstitute.hellbender.utils.variant.Variant;`; - Added `import org.broadinstitute.hellbender.engine.spark.datasources.VariantsSparkSource;`; - As a test, I changed to the `runTool` method with the following to print the information in the first element in the RDD:. ``` Java; JavaRDD<Variant> rddParallelVariants =; variantsSparkSource.getParallelVariants(output);. System.out.println( rddParallelVariants.first().toString() );; ```. And after re-compiling GATK and running `PrintVCFSpark`, I got the following to print the first element of the RDD:. ``` Bash; $ ./gatk-launch PrintVCFSpark --input test.vcf --output test.vcf. Running:; /home/pgrosu/me/hellbender_broad_institute/gatk/build/install/gatk/bin/gatk PrintVCFSpark --input test.vcf --output test.vcf; [February 14, 2016 7:04:16 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVCFSpark --output test.vcf --input test.vcf --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --bamPartitionSize 0 --disableSequenceDictionaryValidation false --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false; [February 14, 2016 7:04:16 PM EST] Executing as pgrosu on Linux 2.6.32-358.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_05-b13; Version: Version:4.alpha-86-g154d0a8-SNAPSHOT JdkD",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1486#issuecomment-184011857:144,simpl,simple,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1486#issuecomment-184011857,1,['simpl'],['simple']
Usability,"Hi Chuck, the GATK blog is set up to only accept posts from admins or moderators on the forum (or my team). If you're willing to write something up, we would do it as a guest post, where I would post the text on your behalf (with clear attribution to you). If you'd like to share a draft with us the easiest way to do it is through a google doc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/269#issuecomment-287546670:230,clear,clear,230,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/269#issuecomment-287546670,1,['clear'],['clear']
Usability,"Hi DarioS. FastaAlternateReferenceMaker is a really simple tool. It actually just looks at the alternate alleles at each site and uses the first non-symbolic one to make the fasta. It doesn't even look at the genotypes. So it should work fine with a multisample vcf but it will give you a mush of samples together as a single fasta. I could be extended to be smarter but it's not a high priority for us right now. . We should improve the documentation, I had to go look in the code to see what it was doing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7557#issuecomment-969237729:52,simpl,simple,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7557#issuecomment-969237729,1,['simpl'],['simple']
Usability,"Hi David,. Thanks for your response and effort developing the best practices pipeline and GATK. I'm not certain, but I would suspect that a significant percentage of your users may also not use the best practices pipeline for one reason or another. In my particular case, I intersect calls from multiple variant callers and prefer to run this pipeline without the added abstraction of Terra (or WDL) for the sake of simplicity. This was easy to fix on my end, thanks again. Andrew. @davidbenjamin. > On Sep 3, 2019, at 4:16 PM, David Benjamin <notifications@github.com> wrote:; > ; > @lbergelson The stats file is not optional, but the argument is optional because by default FilterMutectCalls looks for the stats file produced automatically by Mutect2 in the same directory as the output vcf.; > ; > @andrewrech The official best practices pipeline -- that is, mutect2.wdl in this repo and hosted on Terra (formerly Firecloud) -- handles this automatically. We generally discourage users from writing their own pipelines because it takes very long and can easily yield inferior results. Is the official pipeline missing a feature that you need?; > ; > As for backwards compatibility, while we can guarantee that Mutect2 and FilterMutectCalls from the same GATK release will always work together we do not make any promises about the interoperability of different releases.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6124#issuecomment-527643415:416,simpl,simplicity,416,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6124#issuecomment-527643415,1,['simpl'],['simplicity']
Usability,"Hi Jose,; Your system ulimit setting is too low. Please do this with root at; /etc/security/limits.conf; * soft memlock unlimited; * hard memlock unlimited; * hard nofile 20480; * soft nofile 20480; * hard nproc 40960; * soft nproc 40960; * soft stack unlimited; * hard stack unlimited. Ruzhu; -------------------------------------------; Ruzhu Chen, PhD (845) 433-8426(T/L 293-8426); Email: ruzhuchen@us.ibm.com, Mobile: (845) 337-7238; Sr. Technical Solution Architect, HPC / Genomics & Life Sciences; IBM Systems, 2455 South Road, Poughkeepsie, NY 12601. From:	Jose Sergio Hleap <notifications@github.com>; To:	broadinstitute/gatk <gatk@noreply.github.com>; Cc:	ruzhuchen <ruzhuchen@us.ibm.com>, Mention; <mention@noreply.github.com>; Date:	03/12/2020 11:37 AM; Subject:	[EXTERNAL] Re: [broadinstitute/gatk] Got ""Too many open files""; when use BaseRecalibratorSpark (#5316). Apologies on the poor report. There are no other users in these compute; nodes (I am the tester) and for all intents and purposes the ulimit is; pretty high (hard limit of 8192 max files). I am using GATK version; 4.1.4.1, although it might be the one that has been optimised for IBM; power9 systems by @ruzhuchen. Currently I am waiting for the sys admin to; increase the max files further, but I believe that this is far from ideal.; Here is the (simplified) command:. gatk --java-options ""-Xmx40g; -Djava.library.path=/bio/apps/gatk_4.1.4/gatk-4.1.4.1/libs; -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" Mutect2 -R; Homo_sapiens_assembly38.fa -I illuminaN_hg38.br.recal.bam; --max-mnp-distance 0 -O illuminaN.vcf.gz. May be I am running it wrong?. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub, or unsubscribe.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-598269062:1327,simpl,simplified,1327,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-598269062,1,['simpl'],['simplified']
Usability,"Hi Karthik @kvn95ss ,. This isn't going to do what you want it to do if we implement it as you suggest. The latest GVCF formats try to preserve more annotation data so we can get better statistical power by using all mapping quality values (for example) rather than taking the median across all samples. As such, genomicsDB is going to return a value that isn't usable by VariantRecalibrator without going through GenotypeGVCFs to take the final mean and square root of the stored sum of the squared MQ values. GenomicsDB also won't calculate the FS or SOR values; it will only return the strand bias table. Finally, GenotypeGVCFs will apply a QUAL threshold to remove the lowest evidence variants so your final callset isn't riddled with false positives. GATK4 joint calling pipelines should always include GenotypeGVCFs, whether using CombineGVCFs or GenomicsDBImport to combine single-sample GVCF data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7169#issuecomment-811123495:362,usab,usable,362,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7169#issuecomment-811123495,1,['usab'],['usable']
Usability,"Hi Laura, hope you are enjoying your maternity leave!; Unfortunately i will not have time to look into this, since I’m writing up a paper.; cheers,. > On Feb 12, 2017, at 4:17 PM, Laura Gauthier <gauthier@broadinstitute.org> wrote:; > ; > This is probably affecting some of the GWAS studies but in subtle ways that haven't popped up yet. I'm cc'ing Andrea in the hopes that he has some time to think about the issue. I'd need some uninterrupted time to work out the details and that's hard to come by at the moment.; > ; > On Feb 11, 2017 12:21 AM, ""chlangley"" <notifications@github.com <mailto:notifications@github.com>> wrote:; > Thanks for getting this cleared up.; > OK, what next? I'll check with colleagues who may be aware this 'feature'. Perhaps the case can be made more clearly by a group of users, including visible labs working on human evolutionary genomics.; > ; > I don't know the CA genomics community well, but my shallow poling suggests most are happily unaware that SNPs near indels will often be assigned lower quality than they might.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/broadinstitute/gatk/issues/269#issuecomment-279122551>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AGRhdNaqeg_h2KxcxGULyoiSO3D8EY9eks5rbUVogaJpZM4DrC8o>.; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/269#issuecomment-279274088:656,clear,cleared,656,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/269#issuecomment-279274088,2,['clear'],"['cleared', 'clearly']"
Usability,"Hi Marissa - I think we're all in agreement that we'd like to find a way to make Intel-TF the default, but whether or not we can have CNNScoreVariants require AVX to run is less clear. Naturally, we'd prefer to not have to provide a custom TF distribution for a fallback, but there are 3 cases where we may not have a choice: user with old hardware, Travis/CI testing, and GCE. We may need to provide a fallback environment for those (I'll try to get resolution on that). If it turns out we do, I'm actually not suggesting the fallback be automatic (3 in your list), just that we have a graceful failure mode and an instructive error message. . In the meantime, there is still the issue that this PR fails to even build on Travis. It looks like it produces so much output building the Docker image that it exceeds the allowable Travis build log size. That will need to be resolved, and we'll also need to understand the impact of this change on the size of our Docker image, which is already large, and continues to be a challenge for us.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-429451059:178,clear,clear,178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-429451059,1,['clear'],['clear']
Usability,"Hi Nick, looks good. A few comments: many if not all of the warnings could be fixed rather than simply suppressed. Fixing warnings is always preferred to suppressing them. Can you try fixing them?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/435#issuecomment-95712825:96,simpl,simply,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/435#issuecomment-95712825,1,['simpl'],['simply']
Usability,"Hi all, thanks again for working to integrate this code!. Saw some confusion in the comments above and just wanted to clarify: if you take a look at the VQSR-lite PR https://github.com/broadinstitute/gatk/pull/7954/commits that the current branch is rebased upon, you'll see that it contains a version of the Joint Genotyping WDL (which was put together by Megan for Ultima) along with Java code for the tools (which was written by me). Both the WDL and the code have been updated in subsequent PRs. The WDL was rewritten by me in #8074; the main difference is that we no longer run SNPs and indels filtering in ""series"", but instead run them in a single step. However, this requires that you use the same annotations for both SNPs and indels; GVS might not be ready for that just yet, since the default WARP implementation uses different annotations. (But see also the comment here: https://github.com/broadinstitute/gatk/pull/8074#issue-1423991277. The gist is we can easily reimplement Megan's/WARP's ""serial"" SNP-then-indel workflow using the simpler single-step workflow.) (EDIT: I was originally confused here, Megan’s WDL simply runs SNPs and indels separately—thanks to George for correcting me here!). Note also that test infrastructure was moved from Travis to Github Actions between these PRs, so the Travis references above have already been cleaned up. There have also been a few additional minor PRs merged in the interim, with a couple more incoming. These PRs do not fundamentally change the interfaces of the tools/WDL, however, so I think you can update to them when you're ready. Punchline: this branch should suffice for a first cut of a VQSR/VQSR-lite bakeoff, and although it is already slightly out of date, it shouldn't be too much work to get things updated after the first cut is done.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8157#issuecomment-1412640649:1047,simpl,simpler,1047,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8157#issuecomment-1412640649,2,['simpl'],"['simpler', 'simply']"
Usability,Hi all.; We do have a PR in the master branch to fix this issue. However keep in mind that the variant you are trying to call is probably way above the size that one can call a simple INDEL. ; [https://github.com/broadinstitute/gatk/pull/6388](https://github.com/broadinstitute/gatk/pull/6388),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8699#issuecomment-2374721379:177,simpl,simple,177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8699#issuecomment-2374721379,1,['simpl'],['simple']
Usability,"Hi! This issue is a duplicate of #7054 - under the hood a few changes need to be made to support arbitrary `FeatureTag`s. ; As gencode is updated they seem to be adding more `FeatureTag`s, which Funcotator doesn't expect. The fix is relatively straight-forward, but requires several other changes as well. Unfortunately there isn't a good workaround right now. As a side-note, the `getGencode.sh` script you referenced (and all scripts in that same folder: `scripts/funcotator/data_sources`) are not supported and are designed to be for internal use (I have a file in that folder to indicate this, but I'll admit it's not 100% clear). That said, `getGencode.sh` should work properly - the issue is in the GATK itself (specifically in `org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfTranscriptFeature` and associated classes). This is on the short list of things to update next, so I'll try to get to it soon (though I'm not exactly sure when that will be). Given two people have experienced this issue, I'll prioritize it somewhat higher.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7134#issuecomment-799569339:627,clear,clear,627,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7134#issuecomment-799569339,1,['clear'],['clear']
Usability,"Hi, I am encountering a similar error attempting to run `GenotypeGVCFs` in `gatk v4.1.2.0`. It runs very briefly and writes a handful of variants from a single scaffold to the output file but then exits with `java.lang.ArrayIndexOutOfBoundsException` (see below). I have also tried adding the `-L` flag and an interval list, which performs similarly but outputs variants from a different scaffold. Any idea why this is happening or what I can do to overcome this problem? I have run `GenomicsDBImport` and `GenotypeGVCFs` successfully in the past (same version, same computer) on a different dataset, so I'm not sure what about this data is causing the problem. Any guidance is much appreciated!. Thanks,; Jessie. ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jsalt/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar GenotypeGVCFs -R /nfs/data1/jsalt/3RAD/colinus_virginianus_13May2017_V3Fw6_newchrom.fasta -V gendb://odont_cyr_8_snp_db -O odont_cyr_8_snp_db.vcf; 14:59:47.866 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jsalt/gatk-4.1.2.0/gatk-package-4.1.2.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Feb 03, 2020 2:59:59 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 14:59:59.674 INFO GenotypeGVCFs - ------------------------------------------------------------; 14:59:59.675 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.2.0; 14:59:59.675 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 15:00:09.686 INFO GenotypeGVCFs - Executing as jsalt@mustard on Linux v3.10.0-957.1.3.el7.x86_64 amd64; 15:00:09.686 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 15:00:09.687 INFO GenotypeGVCFs - Start Date/Time: F",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6357#issuecomment-581619640:666,guid,guidance,666,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6357#issuecomment-581619640,1,['guid'],['guidance']
Usability,"Hi,. Thanks for the response. Running with -u isn’t ideal as we can’t control; how the user runs this (unless they do this on their own hardware or say a; cloud instance). However, I managed to convert the docker image into a singularity one and; that runs ‘out of the box’ in user space. Simon. On 3 Jun 2024, at 18:43, Gökalp Çelik ***@***.***> wrote:. Hi @potter-s <https://github.com/potter-s>; Our docker image is already built with root account only however PATH is; set to be usable by all users so if you wish to keep user priviledges after; execution you may add -u $UID:$GID parameter to docker command line; therefore the container will run using your user permissions. This has a catch of course. Temporary folders must be set where your user; has RWX permissions therefore we want users to pay attention to that. There; is a writing that we posted a while ago which you may refer to for setting; up your temporary files for GATK workflows. How to setup temporary folder for GATK local executtion; <https://gatk.broadinstitute.org/hc/en-us/articles/18965297287067-How-to-setup-and-use-temporary-folder-for-GATK-local-execution>. For some of the tools such as gCNV or CNN you may need to setup additional; environment variables to locate python compilation directory to a place; where you have read and write permissions. I hope this helps. —; Reply to this email directly, view it on GitHub; <https://github.com/broadinstitute/gatk/issues/8856#issuecomment-2145780965>,; or unsubscribe; <https://github.com/notifications/unsubscribe-auth/ABU3SAWISO2HSCUNHK3SGIDZFSTK5AVCNFSM6AAAAABIWRNXGKVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDCNBVG44DAOJWGU>; .; You are receiving this because you were mentioned.Message ID:; ***@***.***>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8856#issuecomment-2155884154:483,usab,usable,483,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8856#issuecomment-2155884154,1,['usab'],['usable']
Usability,"Hitting a snag: the md5 output option doesn't seem to work with streams, and so the simple approach of ""just use Path everywhere"" fails because makeSAMWriter in htsjdk doesn't behave identically between a file or an outputStream. Now the question is: is there a fundamental reason for that, or can just add in the md5 feature? At first blush, it seems possible. @droazen, what's your expert opinion?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-290866339:84,simpl,simple,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-290866339,1,['simpl'],['simple']
Usability,"Hmm, I started taking a stab at the LL score implementation, but I think it's going to complicate the code quite a bit and add some branching options to the tool interfaces. Compounding this with a change in the use of ""truth"" and ""validation"" terminology, I fear that the resulting differences from the legacy strategy might be a bit much for users to digest!. So I'd want to better understand the cost/benefit before we proceed. How critical is automatic tuning of the hard threshold? And what's the relative importance to method changes that increase AUC (i.e., as opposed to figuring out where on the curve to hard threshold)? Is there a clear path forward for evaluating such a tuning process? @meganshand would be glad to chat more!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1065524909:642,clear,clear,642,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1065524909,1,['clear'],['clear']
Usability,"How much does count collection cost at the desired bin size? How does this compare to bincov? Perhaps we could eliminate one of these steps if redundant. Note that the read counts are read once and stored in memory, so unless this takes a significant amount of time, then indexing is probably not the highest priority here (although I agree it would be nice to have in general). One related issue, as you mention, is file localization---since each shard only operates on a portion of the counts in each sample, it is a bit wasteful to localize the whole file. But how much does file localization cost? I can't imagine that it is the lowest hanging fruit. One of the more important issues, which you also mention, is optimizing parameters for inference. This includes not only the minimum number of epochs for training, but also things like the learning rate, annealing schedule, iterations per epoch, conditions for epoch convergence, etc. I'll be talking about how to tune these inference parameters---as well as other things in the pipeline---at the next BSV meeting. Let's brainstorm more things to try and prioritize them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5288#issuecomment-427562932:844,learn,learning,844,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5288#issuecomment-427562932,1,['learn'],['learning']
Usability,"However, the current algorithm and the k-dijkstra still would show the same problems in terms of doing a suboptimal selection of haplotypes in terms of their coverage of plausible variation. . I had implemented an alternative that fixed that issue... but I couldn't find the code ... perhaps just in my local machine (backups) need to find it. ; . In any case the idea is quite simple.... we simply simulate haplotypes based on those same furcation likelihoods and we stop when we have not discovered anything new for a while... the problem of such an approach is to make it deterministic. I guess we could fix a seed based on information on the current active region.... anyway,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3561#issuecomment-328171212:378,simpl,simple,378,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3561#issuecomment-328171212,2,['simpl'],"['simple', 'simply']"
Usability,"I _believe_ your issue is that you are assigning 600GB to execution of cromwell, but the error is with the call to **VariantRecalibrator** in one of the tasks not having enough memory. A few tasks call **VariantRecalibrator**, do you know which task failed? Can you post the java call from the STDERR file? For me, it was task **SNPsVariantRecalibrator** which was assigned only 3.5GB of memory by default. In [joint-discovery-gatk4.wdl](https://github.com/gatk-workflows/gatk4-germline-snps-indels/blob/master/joint-discovery-gatk4.wdl), the memory assigned for each task can be set via ""machine_mem_gb"", but it looks like the current [input.json](https://github.com/gatk-workflows/gatk4-germline-snps-indels/blob/master/joint-discovery-gatk4.hg38.wgs.inputs.json) does not have that variable, but instead ""mem_size"" for each task. . A simple solution would be to replace ${java_mem} with a static value in calls to **VariantRecalibrator** (lines 564 & 684). For example, replace:. `${gatk_path} --java-options ""-Xmx${java_mem}g -Xms${java_mem}g""`. with. `${gatk_path} --java-options ""-Xmx100g -Xms100g""`. I'm not certain this will help, but I think it's a step in the right direction.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6165#issuecomment-571396381:837,simpl,simple,837,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6165#issuecomment-571396381,1,['simpl'],['simple']
Usability,"I added a simple patch to fix this undocumented behaviour (#1757). Nevertheless, I'm working in an abstraction to include multi-sample support instead of include all the reads without differentiation in the pileup.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1752#issuecomment-213277514:10,simpl,simple,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1752#issuecomment-213277514,2,"['simpl', 'undo']","['simple', 'undocumented']"
Usability,"I added integration tests for simple output and including features or verbose. While doing it, I realized that GATK 3.5 included some filters that wasn't included here, and that indels weren't tracked, so I changed also the code to fit the previous implementation. Back to you @akiezun.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1836#issuecomment-221651158:30,simpl,simple,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1836#issuecomment-221651158,1,['simpl'],['simple']
Usability,"I added the split size option back, and wrote a test for `dirSize`. All feedback should have been addressed now. Back to @droazen.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1432#issuecomment-173633156:72,feedback,feedback,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1432#issuecomment-173633156,1,['feedback'],['feedback']
Usability,"I addressed partially your comments (and fixed a compilation error due to the tests using the previous arguments). One of the major points of discussion are the following:. * `Collection` instead of `List`: I think that the first is more flexible, because a client maybe wants to have a `LinkedHashSet` as the argument to avoid repetition of the same filter. I agree that the abstract class should discourage not honoring the user order.; * Access to methods/fields: I think that the plugin could be used outside GATK in a different way by extending it. I explained some of my usage cases in one of the comments in the code, but just by overriding a simple method the whole plugin could be used very nicely in some of them. I would prefer to do that than copy your code and re-implement the bits that I would like to change. Back to you for your ideas on this, @cmnbroad!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-275359208:650,simpl,simple,650,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-275359208,1,['simpl'],['simple']
Usability,"I agree that it is better to keep it simpler. I was proposing this before looking the latest commits in the HC branch. I will work on this walker without thinking about other cases, but I would like to keep the idea of padding and slide over intervals instead of the genome from the begining. It will be useful for the things that I have in mind. Should I close this PR until I implement everything, @droazen?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210833987:37,simpl,simpler,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210833987,1,['simpl'],['simpler']
Usability,"I agree with Joshua: there are several places where the billing project currently needs to be specified in the command line and such manual modifications are not very user-friendly. Another way to perhaps address this is to make sure that an input argument, which specifies the billing project, also addresses the issue throughout the script, so that the user does not need to make any additional changes",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6669#issuecomment-647584422:167,user-friendly,user-friendly,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6669#issuecomment-647584422,1,['user-friendly'],['user-friendly']
Usability,"I already addressed the reviewer's feedback, so this should be assigned to @droazen or @lbergelson.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2417#issuecomment-285121959:35,feedback,feedback,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2417#issuecomment-285121959,1,['feedback'],['feedback']
Usability,"I also prefer the use of flags over special values, because of the case where the special value is accidentally triggered: maybe that value is obviously out of a reasonable range to us but not an unsophisticated user. I worry about complaints like ""I clearly set the value, but it didn't take effect."" At the least, there needs to be something like: `WARN: disabling trim feature due to parameter value -1`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/143#issuecomment-71232186:251,clear,clearly,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/143#issuecomment-71232186,1,['clear'],['clearly']
Usability,"I am very interested in this feature. In my current workflow I am using `freebayes` (and in an older version simply `pileup`) to query mutation sites (after doing the actual mutation calling using gATK4 M2) on a cohort level and would be very interested in a GATK naive approach. P.s. personally more interested in a multi-step mutation calling method than multi-sample calling, where one first calls mutation in multiple samples that are then joined together in a consensus callset, after which the consensus callset is queried individually across the entire cohort of patient resulting in genotype and allele frequencies for each variant across the entire cohort",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4887#issuecomment-430817379:109,simpl,simply,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4887#issuecomment-430817379,1,['simpl'],['simply']
Usability,"I am working on a test for #1572. I am not sure what a test for #3069 would look like, or if it is really necessary. We simply changed the way GKL outputs warnings and information. Any ideas?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312295566:120,simpl,simply,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312295566,1,['simpl'],['simply']
Usability,I can confirm that the fix works for me: I now see a user-friendly error message. Thank you!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/357#issuecomment-91289762:53,user-friendly,user-friendly,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/357#issuecomment-91289762,1,['user-friendly'],['user-friendly']
Usability,"I can do this but first, since it seems like a nice way to learn about the GATK engine, I'll open it up to @TedBrookings @MartonKN @takutosato @meganshand @sjfleming @madduran @dalessioluca.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5079#issuecomment-409967138:59,learn,learn,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5079#issuecomment-409967138,1,['learn'],['learn']
Usability,"I can see why you'd change this; however, it breaks this particular legacy tool. VariantEval uses those labels to populate columns in the reports is creates. In GATK3, if there is no user-supplied label on in the argument, it will simply use the argument name, which ends up being either eval, comp or dbsnp. Those strings end up in most reports that are created. Switching these to the filepath doesnt strictly break function, but it's a lot less friendly to look at and doesnt add much value in most cases. Generally speaking, I agree there isnt much of a reason for a tool to reply on those user-supplied names as much of anything beyond a label. However, if this is essentially just a label, is there a situation where non-unique names is actually a problem? A tool probably shouldnt rely on this user-supplied value as a way to uniquely find an input. If this value if generally being used for things like populating user-facing values in a reports, having this extremely long filepath as the name isnt exactly user friendly. If a given tool accepts a list of FeatureInputs, it would seem like it's the responsibility of that developer to make sure that tools deals with the potential of overlapping labels appropriately. Perhaps a solution is to delegate some of this behavior back to the argument definition? A few thoughts/comments:. 1) Is there any reason name can't just be NULL (instead of file URI) if nothing was supplied, instead of filepath? . 2) Similar to 1, if FeatureInputs somehow tracked whether there was actually a user-supplied name or if name was NULL (defaulting to filename), then upstream code could potentially use this information to change behavior. 3) While this if more involved, perhaps ParsedArgument.of() could take another nullable ""defaultName"" argument, and if there is no user-supplied name in the argument value and if defaultName is non-null then it is used as the FeatureInput name instead of filepath? Then perhaps through either a flag in the tool, or bett",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4426#issuecomment-367486387:231,simpl,simply,231,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4426#issuecomment-367486387,1,['simpl'],['simply']
Usability,"I can't reproduce this yet. I tried downloading the jar, unzipping it, and running the example command you gave, but I can't reproduce what you're seeing. I modified it for my local files:; ```; java -jar gatk-package-4.2.5.0-local.jar \; GenotypeGVCFs \; -R /Users/louisb/Workspace/gatk/src/test/resources/large/Homo_sapiens_assembly19.fasta.gz \; --variant gendb:///Users/louisb/Workspace/gatk/output \; -O out.vcf \; --annotate-with-num-discovered-alleles \; -stand-call-conf 30 \; --max-alternate-alleles 6 \; --force-output-intervals 20 \; -L 20 \; --only-output-calls-starting-in-intervals \; --genomicsdb-shared-posixfs-optimizations; ```; It runs to completion on my machine. ; My md5sum matches yours so that's not the problem. It's not clear to me what's going on here. Are the previous releases working on your cluster still?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7675#issuecomment-1042010522:746,clear,clear,746,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7675#issuecomment-1042010522,1,['clear'],['clear']
Usability,"I could be onboard with `site`. It's not entirely intuitive, but it will get a header line, right?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-590338945:50,intuit,intuitive,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6399#issuecomment-590338945,1,['intuit'],['intuitive']
Usability,"I created a panel of normals from 90 WGS TCGA samples with 250bp (~11.5M) bins, which took **~57 minutes** total and produced an **11GB PoN** (this file includes all of the input read counts---which take up 20GB as a combined TSV file and a whopping 63GB as individual TSV files---as well as the eigenvectors, filtering results, etc.). The run can be found in /dsde/working/slee/wgs-pon-test/tieout/no-gc. It completed successfully with **-Xmx32G** (in comparison, CreatePanelOfNormals crashed after 40 minutes with -Xmx128G). The runtime breakdown was as follows:. - ~45 minutes simply from reading of the 90 TSV read-count files in serial. Hopefully #3349 should greatly speed this up. (In comparison, CombineReadCounts reading 10 files in parallel at a time took ~100 minutes to create the aforementioned 20GB combined TSV file, creating 25+GB of temp files along the way.). - ~5 minutes from the preprocessing and filtering steps. We could probably further optimize some of this code in terms of speed and heap usage. (I had to throw in a call to System.gc() to avoid an OOM with -Xmx32G, which I encountered in my first attempt at the run...). - ~5 minutes from performing the SVD of the post-filtering 8643028 x 86 matrix, maintaining 30 eigensamples. I could write a quick implementation of randomized SVD, which I think could bring this down a bit (the scikit-learn implementation takes <2 minutes on a 10M x 100 matrix), but this can probably wait. Clearly making I/O faster and more space efficient is the highest priority. Luckily it's also low hanging fruit. The 8643028 x 30 matrix of eigenvectors takes <2 minutes to read from HDF5 when the WGS PoN is used in DenoiseReadCounts, which gives us a rough idea of how long it should take to read in the original ~11.5M x 90 counts from HDF5. So once #3349 is in, then I think that a **~15 minute single-core WGS PoN could easily be viable**. I believe that a PoN on the order of this size will be all that is required for WGS denoising, if i",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-317614503:580,simpl,simply,580,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-317614503,1,['simpl'],['simply']
Usability,"I did a quick scalability ministudy - this seems to scale well up to 12 cores and then diminishes due to Amdahl's law I think that's fine. There is no diminished runtime due to OMP overhead when on 1 core. Note that our cluster on which I wan these was not empty (a few of the 48 cores were in use) and do this is just a ballpark estimate of scalability, in particular 24 was worse than 12 probably due to interference. Based on this I think OMP is a good idea and it's going to work on 1 CPU too. limited to 1 OMP thread, using 10GB of RAM. ```; real 2m15.621s; user 3m17.269s; Total compute time in PairHMM computeLogLikelihoods() : 50.964700625000006; ```. ---. limited to 1 OMP thread, using 32GB of RAM . ```; real 1m46.597s; user 3m17.363s; Total compute time in PairHMM computeLogLikelihoods() : 45.797104454; ```. limited to 2 OMP threads, using 32GB of RAM. ```; real 1m26.310s; user 3m24.636s; Total compute time in PairHMM computeLogLikelihoods() : 23.790980359000002; ```. limited to 4 OMP threads, using 32GB of RAM. ```; real 1m15.298s; user 3m29.834s; Total compute time in PairHMM computeLogLikelihoods() : 11.332445694; ```. limited to 6 OMP threads, using 32GB of RAM. ```; real 1m14.015s; user 3m20.876s; Total compute time in PairHMM computeLogLikelihoods() : 7.862075811; ```. limited to 12 OMP threads, using 32GB of RAM. ```; real 1m6.370s ; user 3m42.340s; Total compute time in PairHMM computeLogLikelihoods() : 4.585800097; ```. limited to 24 OMP threads, using 32GB of RAM (clearly, OMP hits the limit here). ```; real 1m8.779s; user 4m15.489s; Total compute time in PairHMM computeLogLikelihoods() : 3.047581173; ```. limited to 48 OMP threads, using 32GB of RAM (worse than 12 threads). ```; real 1m11.535s; user 6m26.100s; Total compute time in PairHMM computeLogLikelihoods() : 4.112299148; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1800#issuecomment-218810496:1501,clear,clearly,1501,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1800#issuecomment-218810496,1,['clear'],['clearly']
Usability,"I did a simple experiment and changed the version of Java used in the non-Docker (""17"", although again I'm not sure what this actually resolves to) to that used in the Docker (17.0.1+12). This causes both non-Docker and Docker tests to now fail, rather than just the Docker tests; see https://github.com/broadinstitute/gatk/pull/8174#issuecomment-1402974502. Moreover, the test failures produce exactly the same discrepant numerical results. I think we can probably conclude that the expected test results were generated with ""17"" and that changing to 17.0.1+12 generates different results. This is not too unreasonable; see the Slack thread linked in https://github.com/broadinstitute/gatk/pull/8111#issuecomment-1331407680, for example, which shows that we might be getting into pretty hairy territory and that even changes to things like how HotSpot Intrinsics are implemented in each JVM can cause the numerical differences we see here. So perhaps we can either 1) change the Docker version to the version corresponding to ""17"" or 2) change the non-Docker version to 17.0.1+12 and update the expected results?. Not sure about the failing WDL test yet, but hopefully this is enough to get us started!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1403016955:8,simpl,simple,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1403016955,1,['simpl'],['simple']
Usability,"I did some more work on the broadcast approach to see how feasible it would be, and found that Spark Dataflow made two unnecessary copies of the data (now fixed: https://github.com/cloudera/spark-dataflow/pull/60), which caused OOM errors when trying to broadcast the 3GB reference data. With this fixed, I ran a [pipeline called JoinReferencesDataflow](https://github.com/tomwhite/hellbender/blob/hadoop-references/src/main/java/org/broadinstitute/hellbender/tools/dataflow/pipelines/JoinReferencesDataflow.java) on a small cluster that broadcasts the reference as a dataflow view. The code is a modified version of CountReadsDataflow that simply sends the view, and then doesn't use it, so we can see the cost of doing a broadcast (See the rest of the code in this branch: https://github.com/tomwhite/hellbender/tree/hadoop-references). JoinReferencesDataflow took 2 min 25s to run, of which 18s were for reading the reference from the local filesystem in the driver. For comparison, CountReadsDataflow took 17s on the same cluster. So broadcasting the reference takes less than 2 minutes. Note that this was just for one task, but Spark has [an efficient protocol for sending broadcast variables](http://www.cs.berkeley.edu/~agearh/cs267.sp10/files/mosharaf-spark-bc-report-spring10.pdf), which scales well with the number of nodes, so the approach looks feasible. Having said all that, we might still want to use the sharding approach, in order to share more code between the Google and Spark dataflow implementations. One way this could work would be to generalize `RefAPISource` and `RefAPIMetadata` to support reading reference data from a [ReferenceHadoopSource](https://github.com/tomwhite/hellbender/blob/hadoop-references/src/main/java/org/broadinstitute/hellbender/engine/dataflow/datasources/ReferenceHadoopSource.java), which is in line with @droazen's last comment. Am I right in thinking that the read pipeline work is being completed in https://github.com/broadinstitute/hellbender/tr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/567#issuecomment-120001353:641,simpl,simply,641,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/567#issuecomment-120001353,1,['simpl'],['simply']
Usability,"I did this and learned some things. However, it will be easier to evaluate the impact of GC correction with a standard evaluation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3151#issuecomment-356736140:15,learn,learned,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3151#issuecomment-356736140,1,['learn'],['learned']
Usability,"I didn't read the description of this tool well enough, apparently you can simply add a `--PROGRAM null` to remove the default list. Closing the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4370#issuecomment-363922690:75,simpl,simply,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4370#issuecomment-363922690,1,['simpl'],['simply']
Usability,I don't believe @mwalker174 has incorporated feedback as of yet.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4026#issuecomment-355865508:45,feedback,feedback,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4026#issuecomment-355865508,1,['feedback'],['feedback']
Usability,"I don't know how to accomplish that with gradle. Is just keeping the test jvm going all we need? Or does the ui shutdown after each test? We could add an infinitely running ""test"" in a special test group to If we want to be keep the test jvm open. Alternatively if we really need to be able to run tests and then view the UI afterwards we could put together something using https://github.com/hammerlab/spree. It's a minor pain to set up, I had weird ruby packaging problems getting meteor installed, but it solves the problem of ""how do we collect spark logs in a usable way"".",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1193#issuecomment-159679676:565,usab,usable,565,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1193#issuecomment-159679676,1,['usab'],['usable']
Usability,"I don't think rushing a merge is needed. This is a dead simple utility tool that really only needs to be run once or twice (if I understand the needs for the SV pipeline---possible I'm missing something). Why not just create the desired bins, either by using this dev branch or an external script, and provide that as a resource to the SV pipeline for the time being?. As for using streams for coverage collection, do you mean NIO?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-466100631:56,simpl,simple,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-466100631,1,['simpl'],['simple']
Usability,"I don't think that will work as the key needs to be `GATKRead` to take advantage of the `SAMRecordToGATKReadAdapterSerializer`. How about writing a new `Comparator<GATKRead>` that wraps a `SAMRecordCoordinateComparator`? That should be pretty simple and won't require a new serializer. BTW minor correction: `ReadSparkSink` operates on `JavaPairRDD<GATKRead, Void>` (not `JavaPairRDD<GATKRead, SAMRecordWritable>`) at the moment - the values are null so as to not duplicate the amount of data going through the shuffle.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1249#issuecomment-162024954:243,simpl,simple,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1249#issuecomment-162024954,1,['simpl'],['simple']
Usability,"I don't think this branch satisfies https://github.com/broadinstitute/hellbender/issues/372 at all. There are still methods with 4+ undocumented parameters, and you eliminated what seemed a useful abstraction (`TruthSensitivityMetric`) in favor of passing around a raw array of doubles.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/416#issuecomment-99142930:132,undo,undocumented,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/416#issuecomment-99142930,1,['undo'],['undocumented']
Usability,"I don't want to make any changes to phasing until the new assembly modifications are done, because I expect that will clear up a lot of lost sensitivity.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5651#issuecomment-475723987:118,clear,clear,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5651#issuecomment-475723987,1,['clear'],['clear']
Usability,"I downloaded the GTF file for comprehensive gene annotation in CHR regions from Gencode. However, based on the errors I encountered earlier, I made some simple modifications to the GTF file in an attempt to identify the cause of the errors.; Here're the errors I encountered earlier and my codes to modify the GTF file.; ```; #error:; java.lang.IllegalArgumentException: Unexpected value: overlaps_pseudogene; #code:; grep -v '""overlaps_pseudogene""' gencode.v43.annotation.gtf >gencode.v43.annotation_nooverlaps_pseudogene.gtf; ```; ```; #error:; java.lang.IllegalArgumentException: Unexpected value: Ensembl_canonical; #code:; grep -v 'Ensembl_canonical' $newgtf_path>gencode.v43.annotation_nooverlaps_pseudogene_Ensembl_canonical.gtf; ```; ```; #error:; java.lang.NullPointerException: Cannot invoke ""org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfTranscriptFeature.getContig()"" because ""transcript"" is null; #code:; grep 'transcript' $newgtf_path>gencode.v43.annotation_transcript.gtf; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8394#issuecomment-1613939137:153,simpl,simple,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8394#issuecomment-1613939137,1,['simpl'],['simple']
Usability,"I finished the implementation for the draft `SlidingWindowWalker` (I should implement an example and an integration test, but I would like to wait till some issues are solved). made a ""TODO"" about the way in which the intervals are constructed, because I will need a that `ReadShard` have a way to construct a shard without `ReadSource` (either null or empty source), just in case that the implemented `SlidingWindowWalker` does not require reads. @droazen, could you review and give me some feedback about this, because this class is important for other parts of GATK?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-215710163:492,feedback,feedback,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-215710163,1,['feedback'],['feedback']
Usability,I fixed the artifact uploading as well now. Everything should be good provided tests are passing. It turned out to be something really simple and dumb.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6007#issuecomment-506503209:135,simpl,simple,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6007#issuecomment-506503209,1,['simpl'],['simple']
Usability,"I fully understand, and realize this isnt a priority for the group. Nonetheless, just getting the test data seems like it should be a simple thing if at all possible. i dont know the full reasoning behind why the GATK3 test data are not public, but I have no need to share it beyond myself if that makes this easier.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/616#issuecomment-358031120:134,simpl,simple,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616#issuecomment-358031120,1,['simpl'],['simple']
Usability,"I had a look at the source code of [HypergeometricDistribution](HypergeometricDistribution). If I am right, we are doing the following. We are invoking `logProbability()` for all possible `x[0][0]`. For a table with large numbers, we have to compute logBinomial for many iterations (see line 202–222 in the HypergeometricDistribution source code). Typically logBinomial calls three logGamma and each logGamma calls `log()` twice. This involves lots of computation and is not the fastest way to implement Fisher's exact test. A faster way to implement the test takes the advantage of two observations. 1) When carrying the test, we are calling hypergeo(i,m+n,m,k), hypergeo(i+1,m+n,m,k), ... in order, and we can derive hypergeo(i+1,m+n,m,k) from hypergeo(i,m+n,m,k) by simply multiplying a number. This will be much faster than doing the full hypergeo->logBionomial->logGamma->log computation for each `i`. 2) For a large table, often when `i` is sufficiently smaller or larger than `x[0][0]`, the hypergeo probability is small enough to be ignored from the sum. It is not necessary to calculate hypergeo for the full range of `lo<=i<hi`. This trick can also dramatically reduce the number of iterations for large tables. htslib has a [exact test implementation](https://github.com/samtools/htslib/blob/bf753361dab9b1640cf64f7886dbfe35357a43c5/kfunc.c#L201) that considers the two observations. I understand that the time spent on the `FisherExactTest` class probably won't show up at all in a profiler. I am not requesting to improve the implementation now. Just let you know the tricks. In addition, when we use this class for other purposes, a fast exact test may become a good thing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-266289212:769,simpl,simply,769,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-266289212,1,['simpl'],['simply']
Usability,"I had a look to the other branch, @droazen, and I think that it is more functional than this one:; - Check if the input already have a sequence dictionary, and only updates if `--replace` is provided. The version in this PR just overrides the dictionary.; - Check if all the variants agree with the new sequence dictionary, throwing an error if the contig is not present or the variant falls outside the chromosome range. This version does not account at all for that.; - It is a `VariantWalker`, and thus the code is simplest. But the pitfall of this is that if #2223 is implemented, that class will require a dictionary for the input as a `GATKTool`. I'm not sure how that is going to be done, but I guess that it will introduce problems in the class implemented by @cmnbroad. I think that the other version is more complete and I like it more because it is more concern about putative problems.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2232#issuecomment-257143389:518,simpl,simplest,518,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2232#issuecomment-257143389,1,['simpl'],['simplest']
Usability,"I have a few lines of code that dynamically sets the log4j level for command line tools to match the existing VERBOSITY arg, It seems to work in simple testing so I don't think we need to downgrade to do it. Let me know if you want the code, or if you haven't started you can reassign this to me.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/243#issuecomment-115810391:145,simpl,simple,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/243#issuecomment-115810391,1,['simpl'],['simple']
Usability,"I have a good feeling about numerical instability from this point forward because:. * My terminology was lazy. It's not really ""numerical instability,"" which is a deep and frightening topic, but rather just plain old finite precision, which is not nearly so hydra-headed a problem.; * I learned the general rule for avoiding finite precision problems with a qual score, which is: always calculate probabilities of alleles being absent. Previously I was calculating the probability that samples had an allele and subtracting (in log space) that from 1. The problem with that is that for very good GQs this probability is so closed to 1 that quals can become infinite. In this PR we add up the probabilities of genotypes that don't have the allele, which is small but non-zero and everything works fine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-434769078:287,learn,learned,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-434769078,1,['learn'],['learned']
Usability,"I have no objection to this PR. However, it might be simpler to modify the SV pipeline to optionally produce this data on the fly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2607#issuecomment-297147327:53,simpl,simpler,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2607#issuecomment-297147327,1,['simpl'],['simpler']
Usability,"I have to say, too bad we don't have a mechanism in place that allows for the full reference, e.g. NIO only the contigs or portions thereof that are needed for a particular analysis @droazen @cmnbroad. That would make making test data so much easier. I would imagine this is simple to implement, given the reference is indexed. Such a feature would be useful for cloud analyses. I have to jump through ridiculous hoops to make small test data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373131560:275,simpl,simple,275,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373131560,1,['simpl'],['simple']
Usability,"I haven't understood how multi-allele model exactly works in the old GATK, so can't comment on why it does not perform well. In general, I am supportive of making the new model the default going forward. However:. > when we remove the other models. I would suggest retaining the old model if possible. As I said on the method meeting, the old model takes the full power of population information (by full, I mean under the Wright-Fisher and HWE assumptions, you can't derive a more powerful model in theory). My understanding is that David's current model isn't. This is fine as long as the information from sequence data overwhelms the population information, which is usually true for highCov data. However, when data is thin, the population information will play a more important role. Without thorough evaluations in multiple scenarios, it is not clear when the loss of population information in the new model starts to matter. It would be good to keep the old model as a reference point, at least for biallelic SNPs, until we have more comparison.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2098#issuecomment-242810127:851,clear,clear,851,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2098#issuecomment-242810127,1,['clear'],['clear']
Usability,"I havent published to github yet, pending getting these core changes in; however, the purpose is pretty simple: allow VariantEval to inherit from MultiVariantWalker, but not require it to include the required argument -V. this seemed comparable to VariantWalkerBase (no arguments), and VariantWalker (specifies -V). GATK3's VariantEval uses the --eval argument and I generally tried to keep everything in this port in sync with GATK3, within reason. If there is another way to subclasses to negate some @argument defined by a superclass this would work too. If you want to see more I'll push to github.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-379803776:104,simpl,simple,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-379803776,1,['simpl'],['simple']
Usability,"I implemented a very simple test for tracking Ns. Is it enough, @akiezun?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1833#issuecomment-220032813:21,simpl,simple,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1833#issuecomment-220032813,1,['simpl'],['simple']
Usability,"I just learned that KEBAB case is different from SNAKE case @cmnbroad. Sorry if KEBAB is offensive @cmnbroad but it is meant to clarify syntax (e.g. https://lodash.com/docs#kebabCase). To be clear, Geraldine wants KEBAB case that uses hyphens, and not SNAKE case, which uses underscores. . - So `--emitRefConfidence` would become `--emit-ref-confidence`. ; - So `--contamination_fraction_to_filter` would become `--contamination-fraction-to-filter`. @vruano will describe how he uses constants to manage parameters.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346172549:7,learn,learned,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346172549,2,"['clear', 'learn']","['clear', 'learned']"
Usability,I learned that gatk HaplotypeCaller does not phase multiallic sites anyways and thus will not continue with the development of this PR but it looks like it works so I will leave it here in case anyone needs it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8570#issuecomment-1787023462:2,learn,learned,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8570#issuecomment-1787023462,1,['learn'],['learned']
Usability,"I like the first idea the most, not adding it for a concrete sample. The point of the methods that I described is added the likelihood for a single sample, and default likelihood to the others. Probably will be better defined as following: `add(String sample, GATKRead read, Allele allele, double likelihood, double defaultLikelihood)`. Do you think that you can implement the `Visitor` before removing the `PerReadAlleleLikelihoodMap`? Thanks a lot for all the feedback.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-250233112:462,feedback,feedback,462,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-250233112,1,['feedback'],['feedback']
Usability,"I like the idea of the modified regexes, that seems like the best balance of usability and flexibility/power. I'd rather avoid having a slew of new special-cased arguments.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/588#issuecomment-309815640:77,usab,usability,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/588#issuecomment-309815640,1,['usab'],['usability']
Usability,I made you a page to start collecting such reminders at https://github.com/broadinstitute/gatk/wiki/Checks-and-tests-guidelines.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4825#issuecomment-468819341:117,guid,guidelines,117,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4825#issuecomment-468819341,1,['guid'],['guidelines']
Usability,"I need this for my own work, and it is a very simple change that does not affect the default behaviour. @droazen can you review?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1833#issuecomment-222350655:46,simpl,simple,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1833#issuecomment-222350655,1,['simpl'],['simple']
Usability,I patched this in joptSimple in https://github.com/pholser/jopt-simple/pull/89. This can be enabled by upgrading to the 5.0.1-beta build or waiting for a stable release. Unclear on the time lines for stable release. I suspect if we really need it we can ask for a 4.10 release and the maintainer would likely be willing to create one.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1347#issuecomment-178650249:64,simpl,simple,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1347#issuecomment-178650249,1,['simpl'],['simple']
Usability,"I prefer the classic GATK paradigm, in which by default every boolean is false, until you pass the flag to set it to true. This allows you to be able to just add the flag to the CL without specifying a value. From user POV this provides valuable consistency. It seems a lot more intuitive as well. It's like you're asking ""do you see a flag?"" and in the answer, no means no, and yes means yes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/133#issuecomment-70925401:279,intuit,intuitive,279,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/133#issuecomment-70925401,1,['intuit'],['intuitive']
Usability,"I prefer to host the docs in the forum for the following reasons:; - We want people to use the GATK website and forum as a one-stop shop for all GATK needs, not have to go to Github for some things, both for convenience and as a matter of branding;; - Many end-users don't know/understand Github;; - In the forum we can easily host multiple documents in a way that's intuitive to navigate;; - We can easily render the docs as webpages within the GATK website, which many end-users prefer;; - Forum docs are easy for my team to update or tweak at a moment's notice;; - Users can comment directly on the documents, or create new discussion threads, and it's easier for us to answer them if all is in the same place. ; - If we need to open a github issue ticket (for bug report, feature request etc) we can do it directly from the forum discussion.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1049#issuecomment-151707594:367,intuit,intuitive,367,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1049#issuecomment-151707594,1,['intuit'],['intuitive']
Usability,"I prefer to keep this one open, it will be simpler to rebase and include the changes. Should the `common = true` changes being included in the other or here?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-278340959:43,simpl,simpler,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-278340959,1,['simpl'],['simpler']
Usability,"I propose to still hide from the command line and docs the example walkers. They are meant only for developers, to show how to use some kind of walkers and have a running tool for integration tests. Having then in the command line will generate software users to run them instead of use them for developmental purposes... In addition, I think that this is a good moment to also generate a sub-module structure (as I suggested in #3838) to separate artifact for different pipelines/framework bits (e.g., engine, Spark-engine, experimental, example-code, CNV pipeline, general-tools, etc.). For the aim of this issue, this will be useful for setting documentation guidelines in each of the sub-modules: e.g., example-code should be documented for developers, but not for the final user; experimental module should have the `@Experimental` barclay annotation in every `@DocumentedFeature`; etc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346291829:662,guid,guidelines,662,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346291829,1,['guid'],['guidelines']
Usability,"I rebased on master and addressed the feedback. I've added comments (prefixed with ""Hellbender"") in the htsjdk code to make it very clear where the changes are. I'll look at the changes needed in htsjdk next to address #831.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/827#issuecomment-132560424:38,feedback,feedback,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/827#issuecomment-132560424,2,"['clear', 'feedback']","['clear', 'feedback']"
Usability,I released a snapshot. A signed artifact will follow (1.0.0). Feel free to send me feedbacks BEFORE.; https://oss.sonatype.org/content/repositories/snapshots/com/github/jsr203hadoop/jsr203hadoop/0.0.1-SNAPSHOT/. Final artifact will follow these names:. ``` xml; <groupId>com.github.jsr203hadoop</groupId>; <artifactId>jsr203hadoop</artifactId>; <version>0.0.1-SNAPSHOT</version>; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1326#issuecomment-166677912:83,feedback,feedbacks,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1326#issuecomment-166677912,1,['feedback'],['feedbacks']
Usability,"I see `Timeout (30 minutes) reached. Terminating ""./gradlew jacocoTestReport""`. It's not clear to me how my changes could have introduced a deadlock or similar problem. . I ran the full test suite (`./gradlew test`) locally to take a look and it passes. Took 20min. Running `SeekableByteChannelPrefetcherTest` by itself also passes, unsurprisingly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2391#issuecomment-277399501:89,clear,clear,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2391#issuecomment-277399501,1,['clear'],['clear']
Usability,"I see. . Yes. That's what I'm planning on (except that `AssemblyContigAlignmentsConfigPicker` is upstream of this unit), and here's the thought for why:; * I'd try to place the alignment picking step in a single place as much as possible, this makes improvements to the alignment picking/filtering step easier; * the size-based filter can be tuned, even by an CLI argument, this would affect the number of segments in the CPX logic, and the alt_arrangment annotations, and the simple variants re-interpreted by `CpxVariantReInterpreterSpark`, but it won't affect the alt haplotype sequence, which IMO is what really is important. ; * I'm developing a downstream variant filter, which hopefully can cut down the false-positives. And for the question of ""why 2 instead of 1"", I think what you are suggesting is to change; ```java; public static final int MIN_READ_SPAN_AFTER_DEOVERLAP = 2;; if (one.getSizeOnRead() >= MIN_READ_SPAN_AFTER_DEOVERLAP) result.add(one);; ```; to; ```java; public static final int MIN_READ_SPAN_AFTER_DEOVERLAP = 1;; if (one.getSizeOnRead() > MIN_READ_SPAN_AFTER_DEOVERLAP) result.add(one);; ```; Am i right?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4962#issuecomment-405619353:477,simpl,simple,477,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4962#issuecomment-405619353,1,['simpl'],['simple']
Usability,"I simply mean migrate to hellbender. On Thu, Dec 11, 2014 at 9:40 AM, rpoplin notifications@github.com wrote:. > What does as a command line program mean?; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/hellbender/issues/18#issuecomment-66627537; > .",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/18#issuecomment-66629944:2,simpl,simply,2,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/18#issuecomment-66629944,1,['simpl'],['simply']
Usability,"I started investigating how to do this, here are a few notes:; * The change in Picard's MD added a histogram for counts of (all) duplicates, optical duplicates, and non-optical duplicates.; * The histogram is serialized to text in the metrics file. (I believe there was no histogram before this change.); * The duplicates are found by sorting the file and breaking reads into chunks, where each chunk contains reads that are duplicates. (See `MarkDuplicates#generateDuplicateIndexes`). It's not clear to me where the equivalent code would live in the GATK Spark implementation. It looks like `MarkDuplicatesSparkUtils#markDuplicateRecords` is where the duplicate counts can be obtained, but I'm not sure if the code that uses this method (`MarkDuplicatesSpark#mark`) can piece together the counts for the histogram. Even if it could, the return type of `MarkDuplicatesSpark#mark` is `JavaRDD<GATKRead>`, which would need altering to incorporate the extra three int fields for the counts. Thoughts @jamesemery?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6155#issuecomment-539036697:495,clear,clear,495,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6155#issuecomment-539036697,1,['clear'],['clear']
Usability,"I suggest we start with just the toggle, since we have an immediate need for that. Finer-grained control can be addressed as part of the more general customization/delegation mechanism we've started in other PRs, and so clearly need.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358475214:220,clear,clearly,220,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358475214,1,['clear'],['clearly']
Usability,"I talked to comms and we agreed that a ""mitochondria-mode"" argument to Mutect2 was the right balance of clarity (you're really running Mutect2 not a wrapper) and simplicity (you don't need a laundry list of arguments to change which mode you're in if you just want to run with optimized defaults). . @ldgauthier @davidbenjamin @takutosato @rcmajovski Could you please take another look? Removing the wrapper tools has cleaned up the code so there are fewer changes now. I also changed TLOD to LOD in this version, but I'm happy to take that out and have that be future work if anyone is worried about it being a breaking change.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-428195077:162,simpl,simplicity,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-428195077,1,['simpl'],['simplicity']
Usability,"I think I see what's going on. Since the force calling allele is so huge (a deletion from 36957826 to 36958130) the GATK engine does not create an AssemblyRegion that spans it. Rather, it creates a big region from 36957826 to 36958125 and a tiny one from 36958125 to 36958130. This is silly and worth fixing but the bug hasn't occurred yet. The GATK goes through both assembly regions, the big one and the small one, and _the force calling allele is genotyped in both_. This happens because in `HaplotyeCallerEngine`, line 607, the call to `features.getValues(hcArgs.alleles)` grabs all overlapping variants in the force calling VCF, thus leading to its appearance in both assembly regions. I think the fix might be as simple as counting only force calling alleles that _begin_ in an assembly region. A different solution might be to guarantee upstream that force calling alleles fit completely in a single assembly region, perhaps skipping them with a warning if they are too big for the GATK to handle. @droazen I can get my hands dirty and probably fix this reasonably quickly at this point, but could you weigh in on the two possible solutions?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8106#issuecomment-1405466500:719,simpl,simple,719,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8106#issuecomment-1405466500,1,['simpl'],['simple']
Usability,I think I'm inclined towards just the simple toggle.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358058383:38,simpl,simple,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358058383,1,['simpl'],['simple']
Usability,"I think it triggers in certain situations where a firewall is blocking the connection. If the internet is simply unreachable it doesn't happen, so I don't know what the exact error case is. It happened consistently for people inside Intel's firewall or vpn. . An option to disable gcs support isn't a bad idea, it's kind of a hack though, it would be better if we could understand and avoid triggering the problem. If we could only initialize GCS support when we are sure that we actually are accessing files from google that could be a useful, but it doesn't seem like there's any single point we can plug into to detect that, it would have to be spread over everything that uses paths.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427432141:106,simpl,simply,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427432141,1,['simpl'],['simply']
Usability,I think it's simply that HDF5Library uses `org.apache.log4j.LogManager` rather than `org.apache.logging.log4j.LogManager`.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3763#issuecomment-340867902:13,simpl,simply,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3763#issuecomment-340867902,1,['simpl'],['simply']
Usability,"I think that a proper example would be the one in the tutorial from @sooheelee (https://software.broadinstitute.org/gatk/blog?id=7847, see also https://github.com/broadinstitute/gatk/issues/3104#issuecomment-314886000). I divided the PRs for the `IndelRealignment` into 4 different sections for better review (2 components of indel-realignment, `RealignerTargetCreator`and `IndelRealignment`). This strategy is because I dissected the pipeline into the easy `RealignerTargetCreator` to found regions worth to look at (this could be marked as experimental/beta before the indel-realignment is in) and the more complicated and component-based `IndelRealigner` (the same as with other tools, this can be marked as experimental/beta until a really good coverage is achieved - in the meantime, I have some test with the current data in the repository and the GATK3 counterpart). There are two parts that are usable outside `IndelRealigner` that are worthy to separate into two commits, and might be useful for other tools/downstream projects: `ConstrainedMateFixingManager` and `NWaySAMFileWriter`. That's the reason of making the port in split PRs. One option can be to have the PRs open, and reviewed independently without acceptance until every component is ready. Otherwise, I think that an experimental tag would be good until we find a good set of tests for edge cases. Does this approach make sense for you, @cmnbroad?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366187605:903,usab,usable,903,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366187605,1,['usab'],['usable']
Usability,"I think that it is necessary to have a way for downstream projects to override some of the top-level arguments in the base CLP class. For example, the config file is for documentation purposes, but I don't want to expose users to that argument because I will set the defaults programmatically. Another example is the GCS retries, which might not be useful for a software that is not planning to support GCS even if it is already implemented (or does not want to expose). As a downstream developer, for me it is important to being able to configure arguments and expose/hide them to my final users; with the current implementation, my main issue is to have an argument that are irrelevant for the toolkit user and that I get questions about why and how to use them (the most clear example, the config file). If the main problem is to change an interface, a default value for new methods can be added to keep the same behavior.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-361876183:774,clear,clear,774,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-361876183,1,['clear'],['clear']
Usability,"I think that the full version of the binned read-count collection that @asmirnov239 is working on could be easily modified to give you what you want. Let's keep this tool as simple as possible for now. However, something that would be much easier to change in this code (and might have a bigger effect) would be adding counts to all bins that overlap each fragment. It would be interesting to see how this changes the statistics of the counts. If we have some bandwidth, we can try experimenting with this before release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3775#issuecomment-341838868:174,simpl,simple,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3775#issuecomment-341838868,1,['simpl'],['simple']
Usability,I think that the name `Transformer` makes it pretty clear that it mutates its input. Returning a brand new read upon each transformation would introduce non-trivial overhead for no good reason (unless we're going to make reads immutable across the board).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/312#issuecomment-82511749:52,clear,clear,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/312#issuecomment-82511749,1,['clear'],['clear']
Usability,"I think that this does not require a line reader. It could be done by simply use `Files.lines(path).iterator()` for the `Path`. Maybe it could be included directly in the utils class (e.g., `Utils.lineIterator(Path)`).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3756#issuecomment-340714843:70,simpl,simply,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3756#issuecomment-340714843,1,['simpl'],['simply']
Usability,"I think the general format `gatk-launch Tool toolArgs -- sparkArgs` is pretty clear. Would this be solved by just making the terminology consistent (eg., change `Tool` to `GATKTool` etc.)?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1286#issuecomment-163307090:78,clear,clear,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1286#issuecomment-163307090,1,['clear'],['clear']
Usability,"I think the upgrade to samtools was a consequence of changing the base image from Ubuntu 16.04 -> 18.04 in #5026, since samtools is simply installed using apt-get. If we want to be more specific about which versions of samtools, bedtools, tabix, etc. are included in the Docker images, we may want to build these accordingly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6148#issuecomment-650290760:132,simpl,simply,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6148#issuecomment-650290760,1,['simpl'],['simply']
Usability,"I think this makes gatk less user-friendly and is in contrast with; Cromwell's behavior, which does use the current billing project by default. On Mon, Jun 22, 2020 at 10:58 AM droazen <notifications@github.com> wrote:. > Closed #6669 <https://github.com/broadinstitute/gatk/issues/6669>.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/6669#event-3468784130>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABH6TH6RUMGKVXEMGQUBVGLRX5WPVANCNFSM4OETXLIQ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6669#issuecomment-647573660:29,user-friendly,user-friendly,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6669#issuecomment-647573660,1,['user-friendly'],['user-friendly']
Usability,I think this should be contained in the WDL style guide.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2923#issuecomment-459396390:50,guid,guide,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2923#issuecomment-459396390,1,['guid'],['guide']
Usability,I think this will be difficult and we don't have a python unit testing framework. Let's try for some simple tests in #4375.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4464#issuecomment-459532819:101,simpl,simple,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4464#issuecomment-459532819,1,['simpl'],['simple']
Usability,"I think we can generally enable this by pushing the option up to VariantWalker / GATKTool and integrating it with the createVCFWriter method. . It can optionally return a writer wrapped in a decorator that only outputs sites within the given intervals. We might want to rename the option in that case to something like ""only-output-variants-starting-in-intervals"" so it's clear that it only effects variant outputs. Or make it work with generated bamWriters too...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6339#issuecomment-568100260:372,clear,clear,372,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6339#issuecomment-568100260,1,['clear'],['clear']
Usability,"I think we have a good idea of what side inputs are for and when we would need them now. . My understanding is that side inputs are appropriate to use when you have a fixed object or set of objects which must be provided as a whole to a task or tasks in a pipeline. If these things can be known at pipeline creation and are inexpensive to generate, it's possible to simply pass the objects as parameters in the pipeline creation. However, if the object is generated as part of the pipeline, then it must be passed as a side input instead. . @wbrockman Is my understanding correct?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/282#issuecomment-94354043:366,simpl,simply,366,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/282#issuecomment-94354043,1,['simpl'],['simply']
Usability,I think we've satisfied this one for alpha purposes with our recent README changes. We can write a more in-depth guide for beta.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/964#issuecomment-164045940:113,guid,guide,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/964#issuecomment-164045940,1,['guid'],['guide']
Usability,"I think without a matched normal, there is not much you can do for high purity samples in LOH regions. Flipping the binomial test to filter against the null hypothesis of hom (rather than a null of f = 0.5, as in GetHetCoverage) seems to work well otherwise. Expanding the allele-fraction model to include hom sites is an option, but then you would be guided by the prior. Closing for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2856#issuecomment-335586260:352,guid,guided,352,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2856#issuecomment-335586260,1,['guid'],['guided']
Usability,"I tried a quick upgrade of our guava dependency from 18 -> 22, but it ends in test failures. It looks like at least one of our hadoop dependencies requires guava <= 18. I'm not totally clear if it's an issue for hadoop-core or only in hadoop-minicluster which is a library we use for running tests. If you're not using hdfs I think you won't have any problems including 22, but I'm afraid we can't upgrade our default version without some work. . Hopefully hadoop 3.x will solve the problem in general by shading their internal version of guava. ; https://issues.apache.org/jira/browse/HADOOP-14284, https://issues.apache.org/jira/browse/HADOOP-10101. It sounds like you have a reasonable workaround, let us know if you have further issues with it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308181516:185,clear,clear,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308181516,1,['clear'],['clear']
Usability,"I tried clearing my caches and rebuilding, but I resolve everything. I noticed that our artifactory website looks much different today than it did yesterday. I wonder if it was down temporarily for an update. Maybe try again now? Unless they put it behind the firewall which would be a disaster... can you access https://artifactory.broadinstitute.org/?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2579#issuecomment-292587641:8,clear,clearing,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2579#issuecomment-292587641,1,['clear'],['clearing']
Usability,"I tried to do it, and I'm afraid that it won't be trivial as I expected: because it is a facade, there is not accesibility to `Logger.setLogLevel()` and this is required to set the verbosity level in the command line. After explore a bit the code, it seems that [`LoggingUtils`](https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java) is the only place where a concrete implementation should be used. My suggestion is to move this class to a package that could be excluded by the backend user (because it contains methods to change the logging of log4j, I suggest `org.apache.logging.log4j`), which implements a simple interface/abstract class `org.broadinstitute.hellbender.utils.LoggingUtils` to set the log level (LoggingUtils.setLoggingLevel(final Log.LogLevel verbosity)`. The default implementation (that could be used by final users callid`super.setLoggingLevel(final Log.LogLevel verbosity)`) could setup the htsjdk and the java.util.logger.Logger. This implementation requires to change the `CommandLineProgram` to have a setter for the `LoggingUtils` to use, that could be set in `Main` (as in my PR for improve the extensibility of this class). The only pronblem is that it requires to be initialize with a simple implementation class of `LoggingUtils`, which should use the default. I think that this design does not break the behaviour of GATK, but introduce more complexity in the code. If you think that this is worthy, I could implement it today. @lbergelson, I'm not able to run Spark tools in a cluster yet, neither in gcloud dataproc, sorry. I'll wait for your answers on this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-259073062:676,simpl,simple,676,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-259073062,2,['simpl'],['simple']
Usability,"I tried to run it locally with inputs in GCS and the program crashed with a; null pointer exception. The same command worked fine when running on the; cluster. I'm happy to learn that copying the inputs locally is a workaround. I'll start on the rebasing journey. I'll post a note once I'm done so; someone can do the code review. On Tue, Oct 13, 2015 at 6:19 AM, Tom White notifications@github.com wrote:. > @jean-philippe-martin https://github.com/jean-philippe-martin, that's; > accurate.; > ; > BTW ReadsSparkSink should work fine locally (it can write local files, see; > ReadsSparkSinkUnitTest). What was the problem that you hit?; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/gatk/pull/987#issuecomment-147711651.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/987#issuecomment-147777938:173,learn,learn,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/987#issuecomment-147777938,1,['learn'],['learn']
Usability,"I utilized Mutect2 during clinical tumor testing, and the example I provided earlier clearly represents a false positive site. Regrettably, Mutect2 failed to accurately identify it, thereby leading to the inclusion of such false positive sites in clinical medical reports. This outcome is entirely unacceptable. If it is inappropriate to categorize these false positives as STRs, are there alternative methods available for determining these erroneous sites?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8340#issuecomment-1613985690:85,clear,clearly,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8340#issuecomment-1613985690,1,['clear'],['clearly']
Usability,"I was hoping that by hardcoding the standard set of covariates, we'd end up with something a bit cleaner -- but it looks like there is still a fair bit of ugliness here (eg., the persistence of things like `getOptionalCovariatesStartIndex()`). Do you feel that we've gained enough in code reduction / simplicity to justify the loss of flexibility?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/258#issuecomment-78085268:301,simpl,simplicity,301,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/258#issuecomment-78085268,1,['simpl'],['simplicity']
Usability,"I was mistaken about this not being faster - I was using a counting function that Spark can optimise by pulling onto the map side so that the records don't go through the shuffle. I changed this to simply dump the processed reads so they have to go through the shuffle, and I got the following timings when processing a 121GB BAM file.; - With shuffle: 27 min; - No shuffle (two scans over input): 24.7 min (8% saving); - No shuffle (one scan over input): 17 min (37% saving). The version that does two scans is faster, but not hugely so. Removing a scan is possible, but requires the use of a sequence dictionary to find the end points of contigs. I've done this in the latest version of my branch (https://github.com/broadinstitute/gatk/compare/tw_overlap_partitioner), but there are more edge cases to test. Before I do this, however, it would be worth trying this approach with the Haplotype Caller to see if it works, and if it is appreciably faster. If the number of reads is filtered significantly so only a fraction go through the shuffle, then the performance gains will be smaller, and may not in fact be worth the increase in code complexity. @droazen, what do you think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1988#issuecomment-249590040:198,simpl,simply,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1988#issuecomment-249590040,1,['simpl'],['simply']
Usability,"I was thinking that if we relied on PyPI for distribution, it would only be for released builds, not a release for every repo merge commit. But, I'm increasingly inclined to think that in the short term we should just include the python archive/zip file right in the gatk distribution zip, and modify the env .yml to install from that. Then every configuration (docker image, git clone user, and end user) could use exactly the same method to establish the environment. That seems like the simplest solution for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3964#issuecomment-352279343:490,simpl,simplest,490,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3964#issuecomment-352279343,1,['simpl'],['simplest']
Usability,I wasn't able to reproduce this exact issue. However at least I can make the error message a bit more user-friendly (submitting #2417 for review). Crucially this will now give the name of the file we're having issues with (thus removing the uncertainty about whether it's the data or the index file we cannot access).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2415#issuecomment-281515286:102,user-friendly,user-friendly,102,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2415#issuecomment-281515286,1,['user-friendly'],['user-friendly']
Usability,I will incorporate my feedback to the branch @mwalker174.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3918#issuecomment-356035082:22,feedback,feedback,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3918#issuecomment-356035082,1,['feedback'],['feedback']
Usability,"I would like to know how to add more allele-specific annotations. Example; code would be great. On Thu, Aug 23, 2018 at 8:12 PM, Karthik Gururaj <notifications@github.com>; wrote:. >; > - If you are planning to add more allele specific annotations (other; > than the ones listed [here](For the allele specific annotation fields; > that we know; > <https://github.com/Intel-HLS/GenomicsDB/blob/master/src/main/java/com/intel/genomicsdb/importer/Constants.java>)),; > then I can provide more example code in GATK showing how to set the type; > and length descriptors.; > - If you simply wish to change the combine operation for existing; > annotations, the example code in this PR should suffice; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/4993#issuecomment-415611462>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdOgKRPyTCP0gxEq0Ye1b4Q5CZ8HFks5uT0TWgaJpZM4VJ9WN>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4993#issuecomment-415804596:578,simpl,simply,578,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4993#issuecomment-415804596,1,['simpl'],['simply']
Usability,"I would like to specify what passing a `ReadFilter` to some of my tools means, so maybe passing an `ArgumentCollection` will be simpler than this one, I agree. Although #2085 may solve the issue regarding the `ReadTransformer`/`ReadFilter` ordering, I would like to have in the plugin a way to specify different parameters (maybe some of then hidden before expose to users or advanced in the case of disabling). I will open a new PR for that change, but I will really appreciate if I can get something like that in this and other plugins (if implemented).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2353#issuecomment-275082983:128,simpl,simpler,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2353#issuecomment-275082983,1,['simpl'],['simpler']
Usability,"I would prefer to not require an extra `--sparkMaster` argument to run a Spark tool locally -- ie, `/gatk-launch CountReadsSpark -I flag_stat.bam` should run locally by default. I think we should keep the name `sparkRunner` for symmetry with `sparkMaster`, and to make it clear it's a Spark argument and not a tool argument, but we should rename `SUBMIT` to `SPARK`, and `DIRECT` to `LOCAL`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1329#issuecomment-163672338:272,clear,clear,272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1329#issuecomment-163672338,1,['clear'],['clear']
Usability,I wrote a very minimal guide that says the same thing here: https://github.com/broadinstitute/gatk/wiki/How-to-update-the-gatk-base-docker,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5496#issuecomment-446270446:23,guid,guide,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5496#issuecomment-446270446,1,['guid'],['guide']
Usability,"I'd also be hesitant to break the previous expectation that IntervalArgumentCollection contains a non-empty list of intervals. If I understand correctly (and apologies if not, I'm glancing at the repo between paternity-leave duties and am quite sleep deprived!), all calling code would have to add an explicit check that the new option isn't enabled or risk failing ungracefully downstream. For CNV code, this might be as simple as changing the validation method `CopyNumberArgumentValidationUtils.validateIntervalArgumentCollection`, but I wouldn't generally expect it to be so straightforward to add such checks throughout the codebase. I also agree with @lbergelson that the expected behavior might not be immediately clear and that perhaps this could be addressed in the scattering step---seems like shards could just be limited to regions that cover the resource at the outset. Consider also an older comment at https://github.com/broadinstitute/gatk/pull/5392#issuecomment-435588845 about whether or not we should just use the equivalent Picard tool (horrible glob aside).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6209#issuecomment-540740687:422,simpl,simple,422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6209#issuecomment-540740687,2,"['clear', 'simpl']","['clear', 'simple']"
Usability,"I'd rather keep the message more generic, and think of the check as simply defining what a valid `CopyRatio` object can be: an interval associated with a finite double value. One might imagine that someone would try to create such an object that does not originate from a BAM (perhaps for test data, or for imputing missing values in pre-existing data, etc.). This check says that they must create it with some finite value. A more appropriate place for the sort of message you suggest is in the relevant denoising method. In the edge case you encountered, you used a BAM that was almost completely uncovered in all bins at the specified resolution, resulting in a sample median of zero. Since one of the steps in standardization is dividing by the sample median, this results in a divide by zero. I've added the corresponding check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-365726746:68,simpl,simply,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-365726746,1,['simpl'],['simply']
Usability,"I'll wait for @laserson and @tomwhite to get a chance to chime in, but it looks like we have plan. Supposing that it takes @cmnbroad two weeks (which seems like a reasonable estimate to me). We should we do in the mean time? Is there something simple we can do (that's hacky but correct) to hold us over until the real fix is in?; @tomwhite's suggestion of stripping the header before shuffles, then adding it back after sounds OK to me (and should be easy to clean up).; Other thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141293657:244,simpl,simple,244,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141293657,1,['simpl'],['simple']
Usability,"I'm adding some issues and PRs for make the plugin usable in other cases too, @cmnbroad. Maybe you prefer that solution instead of make it extensible. Just let me know.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-275376544:51,usab,usable,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-275376544,1,['usab'],['usable']
Usability,"I'm going to assign it to @kshakir for now - to implement the simplest -L (one set of intervals, provided by a file). He may choose to split this issue into smaller ones for more granular features. The approach we're going to take is to implement only the features of -L that we need. The first milestone reflects the first feature to implement.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4#issuecomment-67049771:62,simpl,simplest,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4#issuecomment-67049771,1,['simpl'],['simplest']
Usability,"I'm going to close this issue because it's not a bug. Several things in the code of Mutect2 and FilterMutectCalls adapt as they traverse the genome and it's possible that some learned parameter shifts minutely. For example, the assembly graph pruning algorithm uses knowledge of previously assembled regions to better distinguish between errors and somatic variation. It's also possible that somewhere we forgot to give something a fixed random seed. In full honesty, I _wish_ that I knew exactly what causes the 3142 to become 3143, and I regret that I don't have time for it. Nonetheless, in principle it is not cause for alarm.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8152#issuecomment-1983783338:176,learn,learned,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8152#issuecomment-1983783338,1,['learn'],['learned']
Usability,I'm going to keep the initialization as is because it mirrors HaplotypeCaller and because I feel like defining blocks by their size is more intuitive than defining the number of blocks between two bounds.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5615#issuecomment-458580294:140,intuit,intuitive,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5615#issuecomment-458580294,1,['intuit'],['intuitive']
Usability,"I'm not clear why the inputs table in gvs-overview.md is rendering as not having rows between some of the items, the only changes to that table were intelliJ auto-white space added to make the columns line up, and one more row on the bottom about the new boolean for using classic vqsr.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8466#issuecomment-1674974109:8,clear,clear,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8466#issuecomment-1674974109,1,['clear'],['clear']
Usability,"I'm not completely opposed to that way of dealing with this, but I'm not yet convinced either. . I'm not sure I see how having an extra argument is somehow shorter than having one special value that is included in the description of the original argument. As in:. --trimWhatever | -trimWvr -- bla bla bla; default w; min x max y; to disable trimming, use z. . As for the documentation auto-generator showing the two args together, that is dependent on setting up the arguments so that the code specifies they are related, and adding some logic to the auto-generation to pull related arguments together. (As a contributing developer to a documentation auto-generator --the GATKDocs-- I can tell you that is not necessarily trivial and adds even more moving parts.) This also generates additional complexity for third-party developers of wrappers (such as Galaxy). Finally, it can be a source of confusion for users who are trying to look up an argument called ""-dont-Trim-whatever"" since presumably it's only going to be listed under T (-Trim-whatever) and not under D in the alphabetical list. Or should it be listed twice? . A reference manual can be very ""nice"" and helpful, and it must be organized in the most intuitive way possible, especially since there is no way we can provide examples that cover every single use case under the sun (trust me, there's not).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/143#issuecomment-71122930:1214,intuit,intuitive,1214,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/143#issuecomment-71122930,1,['intuit'],['intuitive']
Usability,I'm not totally clear from your response but I think you've resolved the problem? . If you're encountering a bug merging bai files could you open an issue describing that with your stack trace and any relevant information about the configuration you're running?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6233#issuecomment-547956623:16,clear,clear,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6233#issuecomment-547956623,1,['clear'],['clear']
Usability,"I'm sorry, I don't know another tool that does the same thing. If you could provide some samples that cause the problem that would actually be really helpful. It *should* be a simple fix so I could try to get a path out soon, but it's always faster with a test case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8427#issuecomment-1646250031:176,simpl,simple,176,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8427#issuecomment-1646250031,1,['simpl'],['simple']
Usability,"I'm with @davidbenjamin that a camel-case looks clearer, because there are very long names in the GATK-framework that may involve a lot of dashes. Even if the bash-completion will help on this, for downstream projects it can be a nightmare to change this. For instance, I'm not planning to add the bash-completion generation to my toolkit, and I personally find difficult to read long arguments with tons of dashes...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2596#issuecomment-323703013:48,clear,clearer,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2596#issuecomment-323703013,1,['clear'],['clearer']
Usability,"I've added a new end-to-end test for SelectVariants that writes to GCS. Sadly, the IntegrationTestSpec class uses Files throughout, so it wasn't possible to do this simply without first completely refactoring IntegrationTestSpec (which should probably be its own pull request). . Doing this refactoring would have the advantage that changing existing end-to-end tests from local to GCS would be trivial. For now instead I went with an ad-hoc approach. It works, and the test passes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-455686612:165,simpl,simply,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-455686612,1,['simpl'],['simply']
Usability,"I've added some non-trivial (code-wise, logical wise very simple) code to single out slow assemblies more obviously. That is, generating another txt file collecting the runtime for those slow ones.; Example here ; /user/shuang/experiments/NA12878_PCR-_30X; /user/shuang/experiments/NA12878_PCR-_30X/assembly_betterLogging_longOnes",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1997#issuecomment-245295941:58,simpl,simple,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1997#issuecomment-245295941,1,['simpl'],['simple']
Usability,"I've added the additional test you requested, and confirmed that it passes. The `SkipExceptions` are there to skip JBWA tests on platforms for which we don't have a build of the library -- I've extracted a `skipJBWATestOnUnsupportedPlatforms()` method to make this clearer.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1847#issuecomment-220757508:265,clear,clearer,265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1847#issuecomment-220757508,1,['clear'],['clearer']
Usability,"I've addressed @davidadamsphd's feedback. The tests were passing on Friday, but now the build is failing due to https://github.com/broadinstitute/gatk/pull/1185, so that should be merged before this one.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1174#issuecomment-158912039:32,feedback,feedback,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1174#issuecomment-158912039,1,['feedback'],['feedback']
Usability,I've addressed all the feedback and all tests are passing so I'm going to squash and merge this now.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3452#issuecomment-325607019:23,feedback,feedback,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3452#issuecomment-325607019,1,['feedback'],['feedback']
Usability,"I've addressed the feedback so far - except for @davidadamsphd's last comment about checking in a sharded BAM. @lbergelson let me know if you'd like me to do that; also, what do you think about the overwriting behaviour?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/980#issuecomment-147751416:19,feedback,feedback,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/980#issuecomment-147751416,1,['feedback'],['feedback']
Usability,I've also incorporated @davidbenjamin 's in line feedback. Please let me know if there are additional fixes for the documentation section.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2816#issuecomment-306281558:49,feedback,feedback,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2816#issuecomment-306281558,1,['feedback'],['feedback']
Usability,"I've been thinking about this literal edge case. We now have metagenomic pipelines that are meant to align data to presumably extremely small references (bacteria, infectious agents, e.g. viri). These organisms have a different expectation for mutation/variant rates that my synthetic data could represent. I am unfamiliar with the details of the metagenomics pipelines except that it aligns reads to a giant conglomerate of different organisms. I forget whether the pipeline actually produces an alignment BAM or just a list of organisms--perhaps @mwalker174 could inform us. On the forum, we've had a few cases where we encourage folks to use our tools even when they work in other nonmammalian organisms such as bacteria. However, knowing how our assembler handles data at the edges of contigs, and how variants that are close together trigger alternate assumptions, e.g. the presence of an indel as I learned from @droazen, then I'd like to know how I should actually be informing our nonmammalian researchers. Whether they should or should not consider assembly-based calling, whether there are certain parameters they could employ to ensure calling some variant (even if wrong) rather than no variant within the confines of a small genome, or whether I should point them to a pileup caller, etc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4073#issuecomment-360515238:905,learn,learned,905,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4073#issuecomment-360515238,1,['learn'],['learned']
Usability,I've incorporated your feedback @davidbenjamin. Many thanks for the review. Waiting for checks to pass.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3124#issuecomment-309833042:23,feedback,feedback,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3124#issuecomment-309833042,1,['feedback'],['feedback']
Usability,I've incorporated your feedback @ldgauthier.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5601#issuecomment-458725009:23,feedback,feedback,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5601#issuecomment-458725009,1,['feedback'],['feedback']
Usability,I've incorporated your feedback @samuelklee. Thanks for the review.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3146#issuecomment-310676868:23,feedback,feedback,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3146#issuecomment-310676868,1,['feedback'],['feedback']
Usability,"I've incorporated your feedback to #5601 @ldgauthier and the commit is undergoing tests. Please feel free to merge the PR if you accept the changes and have no further comments. . As for [Article#11074](https://software.broadinstitute.org/gatk/documentation/article?id=11074), given we have addressed the original issues (e.g. Latex), I am going to consider the additional recommendations as something for the not-so-near future. Would that be okay with you @ldgauthier?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5409#issuecomment-458728389:23,feedback,feedback,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5409#issuecomment-458728389,1,['feedback'],['feedback']
Usability,"I've just run into this issue, is it okay to ignore these warnings? I'm new to GATK so it's not clear to me what a combination operation is, and if it has effect on the output.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2689#issuecomment-369990259:96,clear,clear,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2689#issuecomment-369990259,1,['clear'],['clear']
Usability,"I've made some improvements to this PR, including:; - Made it easier to use the `joinOverlapping` method by making the function you supply only have to worry about one interval (shard) at a time. This simplifies the callers code, so PileupSpark (for example) is now shorter.; - Added some documentation. I've also used the same technique to improve `AddContextDataToReadSpark` so that references are filled in on a per shard basis, rather than per read. In tests on a 6.6GB file I managed to get BaseRecalibratorSpark's runtime down from 10.61 minutes to 3.73 minutes, which is over 60% faster.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2190#issuecomment-250750843:201,simpl,simplifies,201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2190#issuecomment-250750843,1,['simpl'],['simplifies']
Usability,"I've now improved the naming of the parameter tot specify the Spark submit command (now it's `--sparkSubmitCommand`), to address @lbergelson's feedback. I updated to the latest shaded google-cloud-nio artifact, and it works with Spark 2 on a cluster. However, the `GcsNioIntegrationTest` fails due to the `javax` package (and subpackages) being shaded (these packages should not be shaded since Java provides these classes). So I'm afraid we'll need another release to fix this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2220#issuecomment-257582314:143,feedback,feedback,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2220#issuecomment-257582314,1,['feedback'],['feedback']
Usability,I've ran this one in my test and it's clear the current code doesn't have the problem of prefetching a prefetcher.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2643#issuecomment-298468693:38,clear,clear,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2643#issuecomment-298468693,1,['clear'],['clear']
Usability,"If Louis says this is allowed in our style guide then you can leave them; in. I didn't realize that. Feel free to drop the hammer on us for any style; violations. On Mon, May 1, 2017 at 1:04 PM, tedsharpe <notifications@github.com> wrote:. > *@tedsharpe* commented on this pull request.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/spark/sv/; > BreakpointClusterer.java; > <https://github.com/broadinstitute/gatk/pull/2627#discussion_r114155944>:; >; > > }; >; > - @Override; > - public Iterator<BreakpointEvidence> apply( final BreakpointEvidence evidence ) {; > - if ( evidence.getContigIndex() != currentContig ) {; > - currentContig = evidence.getContigIndex();; > - locMap.clear();; > + public Iterator<BreakpointEvidence> apply( final Iterator<BreakpointEvidence> evidenceItr ) {; > + while ( evidenceItr.hasNext() ) {; > + final BreakpointEvidence evidence = evidenceItr.next();; > + final SVInterval location = evidence.getLocation();; > + final SVIntervalTree.Entry<List<BreakpointEvidence>> entry = evidenceTree.find(location);; > + if ( entry != null ) entry.getValue().add(evidence);; >; > Pretty sure that Louis said that this was one of our departures from; > Google style: single statements following an ""if"", ""else"", or ""else if""; > that fit comfortably on the same line are allowed (but not required) to be; > unbraced.; > Since you prefer braces, I'll change these.; > However, since you've thrown down the gauntlet, I'm going to start nailing; > you guys on very long lines (max line length is supposed to be 100; > characters). So there.; >; > —; > You are receiving this because your review was requested.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/2627#discussion_r114155944>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AArTZZPkQPglpEhCzZqbA17GshZt6t-Dks5r1hCsgaJpZM4NKPYH>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2627#issuecomment-298379400:43,guid,guide,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2627#issuecomment-298379400,2,"['clear', 'guid']","['clear', 'guide']"
Usability,"If anyone wants to learn more about the horrors of HLA (and MHC more generally) naming, ping me elsewhere, probably best at https://github.com/nmdp-bioinformatics/genotype-list.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3360#issuecomment-324732655:19,learn,learn,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3360#issuecomment-324732655,1,['learn'],['learn']
Usability,"If it's a difficult/non-trivial change, though, then it may not be worth fixing. I thought it would be a simple change.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3596#issuecomment-330941066:105,simpl,simple,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3596#issuecomment-330941066,1,['simpl'],['simple']
Usability,"If there is sufficient demand, we could implement a `LocusWalker` class for GATK4, particularly as the key classes from GATK3 were recently ported as part of https://github.com/broadinstitute/gatk/pull/1442. Adding new walker types in GATK4 is much simpler than it was in GATK3, so this would actually be a fairly easy thing to add.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1463#issuecomment-178662601:249,simpl,simpler,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1463#issuecomment-178662601,1,['simpl'],['simpler']
Usability,"If these events were indeed not CNLOH, as we discussed, then I don't think we should merge this. Perhaps we should take a step back and answer definitively whether simply blacklisting common germline regions is enough to replicate/obviate most of the postprocessing. Should be straightforward to run an evaluation with and without blacklisting---and hopefully our truth data accurately reflects whether blacklisting is desirable. If tagging/filtering rare germline is still a concern, then I'd say the next step is to see whether simply changing segmentation parameters to artificially decrease resolution and/or simple length-based filtering suffices. Finally, simple filtering based on CR-AF as described above could be implemented. If the normal is available, we can make IS_NORMAL calls simply based on the overlap of the ModelSegments posteriors (with corresponding qualities). If not, then some heuristic determination of the normal state from the tumor alone as in Marton's caller could be performed. This would combine the IS_NORMAL calling and filtering steps into one simple tool. The output could be a tagged/filtered ModelSegments .seg file and the corresponding VCF.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-458551250:164,simpl,simply,164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-458551250,6,['simpl'],"['simple', 'simply']"
Usability,"If we do keep both methods, we should make it VERY clear in the docs that `onTraversalDone()` should be for closing resources, and `onTraversalSucess()` should be for producing final outputs, etc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1743#issuecomment-212597490:51,clear,clear,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1743#issuecomment-212597490,1,['clear'],['clear']
Usability,"If you get any more of these errors, it's either an argument that never had any effect or something that you 4.1.1 got rid of. In the latter case, you don't need to replace it with anything. In 4.1.1 `FilterMutectCalls` automatically learns a lot of parameters.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5845#issuecomment-478011007:234,learn,learns,234,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5845#issuecomment-478011007,1,['learn'],['learns']
Usability,"If you're interested in BWASpark tool I might wait a bit. There are a lot of issues with it as it currently stands, it's one of the least tested tools we have. We have someone working on a different more efficient implementation of the bwa bindings that may eventually be integrated into mainline gatk, so we've sort of stopped most development on BWASparkEngine until we're clear on the direction that the new work is going to take.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-267119998:375,clear,clear,375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-267119998,1,['clear'],['clear']
Usability,"In GATK4, the way to make a tool multithreaded is to implement it as a Spark tool. All Spark tools can be trivially parallelized across multiple threads using the local runner, and across a cluster using spark-submit or gcloud. . We wanted to avoid the complexities of implementing our own map/reduce framework, as was done in previous versions of the GATK, and instead rely on a standard, third-party framework to keep the GATK4 engine as simple as possible.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2345#issuecomment-273206164:440,simpl,simple,440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2345#issuecomment-273206164,1,['simpl'],['simple']
Usability,"In addition just to clarify that the ""contig"" word reference to the sequences in the given reference not the number of contigs that you might align to it, so single-contig-reference-aligner means an aligner that will align several sequences (read, contigs, random-stuff) vs a single sequence/contig reference. . I guess I shall change contig for chromosome or sequence to make it more clear.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4780#issuecomment-389990976:385,clear,clear,385,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4780#issuecomment-389990976,1,['clear'],['clear']
Usability,"In good news, the spark mailing list announced that spark master builds and runs all tests on 11 now. So it looks like support for java 11 coming in spark 3.0. When that is is going to be release isn't clear though. We should start moving to support java 11 in advance of that so we're ready when it releases.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6053#issuecomment-525337068:202,clear,clear,202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6053#issuecomment-525337068,1,['clear'],['clear']
Usability,In light of #6463 I'm clearly wrong about some part of this. I'll take another look after digging into that issue.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6432#issuecomment-590344630:22,clear,clearly,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6432#issuecomment-590344630,1,['clear'],['clearly']
Usability,"In looking at his further, the container header contains a stream offset, and each slice header also contains a global record counter. Both of these need to be updated. Its not clear if its possible to repair these without re-encoding the entire container stream, but if so that should probably be done in a method exposed by htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2201#issuecomment-324756574:177,clear,clear,177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2201#issuecomment-324756574,1,['clear'],['clear']
Usability,"In order to get it running though you will need to install the following things on each machine using apt-get: gawk, sysstat, and perf-tools-unstable. Additionally as root, you will have to set the /proc/sys/kernel/perf_event_paranoid variable from 1 to 0. For these tasks it might be possible to automate these steps by updating the system image that is used to setup dataproc clusters. In order to actually run and install PAT, you will need to download it from [here](https://github.com/intel-hadoop/PAT/tree/master/PAT) and add all the machines and ssh ports (including the master) in your cluster to the ""ALL_NODES"" setting in the config.template -> config file. You will also have to setup an SSH key to root on the cluster, which can be done with the command `gcloud compute ssh` and set the ""SSH_KEY"" variable in the config file to point to the google_compute_engine file in roots .ssh directory (public keys should have automatically been distributed to the other nodes). . At this point you need simply input the command line command you wish to run into the ""CMD_PATH"" variable and run ./pat run. I recommend running a spark-submit job using yarn-client as master. NOTE: the output will be a directory containing an excel spreadsheet and a bunch of data for each cluster. You will need to open the spreadsheet on a windows copy of excel and use ""control+q"" to run the macros that load the data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1986#issuecomment-234947495:1006,simpl,simply,1006,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1986#issuecomment-234947495,1,['simpl'],['simply']
Usability,"In the course of investigating https://github.com/broadinstitute/gsa-unstable/issues/1409 a few things came up that I want to document for when it's time to test the new model:; - Throw away the spanning deletions alleles! They shouldn't affect the QUAL anymore since we won't be using the independent alleles approximation, but I don't want them mucking with the site type and choice of prior (SNP vs INDEL); - For the purposes of QD for VQSR, we should be using AS_QD very shortly, in which case the choice of prior for mixed sites will be clear because we're evaluating per-allele; - For the purposes of QUAL for emission, at mixed sites I'm in favor of continuing to apply the SNP prior in accordance with the doctrine of maximal sensitivity until VQSR",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1697#issuecomment-230464015:542,clear,clear,542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1697#issuecomment-230464015,1,['clear'],['clear']
Usability,"In the interest of getting this merged, I've addressed the remaining blocking issue via documentation and naming: tool is now named `ConvertHeaderlessHadoopBamShardToBam`, and the docs make it clear what kinds of Hadoop bam shards it should be used with, and which it shouldn't. Will merge once tests pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1278#issuecomment-221101168:193,clear,clear,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1278#issuecomment-221101168,1,['clear'],['clear']
Usability,"InbreedingCoeff.java](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9JbmJyZWVkaW5nQ29lZmYuamF2YQ==) | `82.759% <100%> (ø)` | `11 <1> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/utils/GenotypeCounts.java](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vdHlwZUNvdW50cy5qYXZh) | `100% <100%> (ø)` | `4 <1> (ø)` | :arrow_down: |; | [.../hellbender/tools/walkers/annotator/ExcessHet.java](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9FeGNlc3NIZXQuamF2YQ==) | `98.592% <100%> (ø)` | `22 <2> (ø)` | :arrow_down: |; | [...broadinstitute/hellbender/utils/GenotypeUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vdHlwZVV0aWxzLmphdmE=) | `94.872% <100%> (+2.767%)` | `12 <0> (+3)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=footer). Last update [c8ede6e...c63c08b](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2546#issuecomment-290509295:2535,learn,learn,2535,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2546#issuecomment-290509295,1,['learn'],['learn']
Usability,"Initial commit by Mark DP in 2009: . > simpleComplement function() in BaseUtils. Generic framework for clipp…; > …ing reads along with tests. Support for Q score based clipping, sequence-specific clipping (not1), and clipping of ranges of bases (cycles 1-5, 10-15 for example). Can write out clipped bases as Ns, quality scores as 0s, or in the future will support softclipping the bases themselves. https://github.com/broadinstitute/gsa-unstable/commit/d6385e0d884cbd80c34e16e848297c3694f85a5a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/263#issuecomment-95101660:39,simpl,simpleComplement,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/263#issuecomment-95101660,1,['simpl'],['simpleComplement']
Usability,"Interesting! Thanks for generating these. I am already convinced by #4519 we should at least switch over to a ‘CollectReadCounts’ strategy for initial evaluations. A few comments:. -I’m guessing that the equal insert size and uniform sampling is enhancing many of these artifacts to a level that we probably don’t see in the real world. Can we take a look at some real-world examples?. -Same goes for the fact that homs will be unlikely. -Not sure about the dropouts. Might be worth running without SNPs as a confounding factor. -How flexible is SVGen? Might be worth putting together a more realistic simulated data set. Any chance @MartonKN might be able to use it to cook up some realistic tumor data?. -I don’t recall having a `CollectBaseCallCoverage` type tool in beta—which tool are you thinking of? On a related note, it seems there is some demand to port `DepthOfCoverage` from GATK3. However, I’d prefer that we roll a CNV-specific version of the tool even if it does get ported. In any case, I think along with findings from the other issue, we should issue a quick PR for `CollectReadCounts` and go ahead to change the `CollectCounts` WDL task to call it—it’s for this very reason that the task is named generically! @sooheelee note that we may have to update the tutorials, etc. at some point, but perhaps the right time will be until all evaluations are more complete. Speaking of which, this PR should not delay getting the first round of automated evaluations up and running. Again, the whole point of those is to have a reproducible baseline metric against which we can easily experiment with and adopt these sorts of changes. Although these sorts of theoretical/simulated/thought experiments are clearly useful to us, unfortunately, they may not be as compelling to some of our users as demonstrable improvement seems on real data!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375122976:1714,clear,clearly,1714,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375122976,1,['clear'],['clearly']
Usability,"Interesting, thanks for doing this experiment. It's already clear to me that Funcotator will need a different caching strategy for https://github.com/broadinstitute/gatk/issues/4771 -- I was going to implement one after merging your reads caching PR. Re-assigning this ticket to myself.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5143#issuecomment-416985644:60,clear,clear,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5143#issuecomment-416985644,1,['clear'],['clear']
Usability,"Interesting. Sorry this is causing so much trouble. From one of your above comments I wasn't clear if the solution using `--conf 'spark.submit.deployMode=cluster'` work correctly or not. . Is it possible that it's correct behavior for it to fail with the linkage error? According to the [mapr doc](https://maprdocs.mapr.com/52/DevelopmentGuide/c-loading-mapr-native-library.html) that command causes it to expect the application to load the library itself, but GATK by default doesn't have a copy of MAPR and won't load it on it's own. Have you included the mapr library somehow into the gatk jar? Or is it provided to spark some other way? I don't really know how maprfs works and how it interacts with hadoop paths.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350315653:93,clear,clear,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350315653,1,['clear'],['clear']
Usability,"Intriguing. Thanks for the good example. To get around this it looks like we need to update NIO to allow it to be in a special ""broken"" state where the CloudStorageFileSystemProvider allows itself to be constructed even without credentials, failing later when we ask it to do anything. I think this is possible, but the change would have to be in gcloud-java-nio itself. The additional state is a bit counter-intuitive (usually allocation-is-initialization) but it seems worthwhile in this case. I'll get the ball rolling over at gcloud-java-nio.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2110#issuecomment-241813191:409,intuit,intuitive,409,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2110#issuecomment-241813191,1,['intuit'],['intuitive']
Usability,Is there a way we can use constants for common arg names? Would be the simplest way to keep them all in sync IMO.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/133#issuecomment-94413465:71,simpl,simplest,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/133#issuecomment-94413465,1,['simpl'],['simplest']
Usability,It appears the merge process has undone a bunch of the work. Working on fixing that now :-(,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/894#issuecomment-142445038:33,undo,undone,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/894#issuecomment-142445038,1,['undo'],['undone']
Usability,It does in this very simple test I ran on dataproc.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2312#issuecomment-266636027:21,simpl,simple,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2312#issuecomment-266636027,1,['simpl'],['simple']
Usability,"It gives us the ability to easily aggregate records across multiple FeatureInputs, and (potentially, if we wanted) to retrieve records by type rather than by source. . FeatureInput should be simple, since (due to the way the argument-parsing system works) it must be initialized by a constructor that takes a single String (the argument value).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/242#issuecomment-76735788:191,simpl,simple,191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/242#issuecomment-76735788,1,['simpl'],['simple']
Usability,It is not clear for me what 2 separate repos can improve. Could you elaborate on that?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1788#issuecomment-217072086:10,clear,clear,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1788#issuecomment-217072086,1,['clear'],['clear']
Usability,It looks like it made the tests substantially slower.... I'm not totally clear on why. Maybe because it has to re-optimize code every time it restarts the jvm.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6093#issuecomment-521372663:73,clear,clear,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6093#issuecomment-521372663,1,['clear'],['clear']
Usability,It looks like it shouldn't be to difficult but it would necessitate either moving the bucket they are located in or asking people to clear out the hellbender bucket of other things because it appears the lifecycle features can only be applied on a per-bucket basis.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3578#issuecomment-329269545:133,clear,clear,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3578#issuecomment-329269545,1,['clear'],['clear']
Usability,"It seems to me that producing some parallel coordinate plots is the way to go to gain some intuition about how the SW and filters parameters affect the Area under the curve of the precision/recall curve. I assume that, overall we have about 10 parameters and 2-3 metrics (AUC for SNP, AUC for short Indel, AUC for long Indel). This is small enough that we should be able to gain intuition by looking at parallel coordinate plots. . This is a nice visualization package to produce parallel coordinate plots: https://facebookresearch.github.io/hiplot/index.html",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712860451:91,intuit,intuition,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712860451,2,['intuit'],['intuition']
Usability,"It seems to me the `Header definition line` encompasses the information given by the `VCF Field` so this latter is redundant. . It would definitely be useful to categorize INFO (cohort) versus FORMAT (SAMPLE) level annotations. I'm not clear on the significance of the `Type` nor `Category` fields. `Type` might be the groupings, e.g. HaplotypeCaller standard annotations versus Mutect2 standard annotations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-344423143:236,clear,clear,236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-344423143,1,['clear'],['clear']
Usability,"It would be nice to keep the separate tool around so that it can be used; for stuff like calling variants from de novo assemblies, like I showed at; Tuesday's meeting. But if both of you think it's not necessary to simplify the conversions; I'll defer to you. On Fri, Apr 14, 2017 at 11:59 AM, tedsharpe <notifications@github.com>; wrote:. > The decision about whether to hard clip or soft clip supplementary; > alignments is a flag to bwa mem. All it does is to replace initial and; > final 'S' in the cigar with 'H' instead. The code in applyAlignment; > respects that decision. So if we don't want any hard clipping, that's easy; > enough to do -- we just turn off that flag.; > That's probably the right thing to do since the code on line 89 of the; > AlignmentAssemblyParser always grabs the entire sequence, whether or not; > there's been hard clipping. I'd guess it's likely that there a bugs lurking; > here.; > I don't see any particular need to convert to SAM and then back into an; > AlignmentRegion. We can eliminate the SAM writing entirely once we have a; > single tool, and then there will only be a single path.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/2595#issuecomment-294179814>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AArTZffa-htFUWK3AckY3g2y2kR14wW-ks5rv5fKgaJpZM4M8xRs>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2595#issuecomment-294180667:215,simpl,simplify,215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2595#issuecomment-294180667,1,['simpl'],['simplify']
Usability,"It's a problem because we have to work with formats that support zero-length intervals (eg., BED). We need to talk this issue through and come to a clear decision.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/317#issuecomment-185798929:148,clear,clear,148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/317#issuecomment-185798929,1,['clear'],['clear']
Usability,"It's a simple change that I've implemented locally, I need to fix the picard programs that rely on the old behavior though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/175#issuecomment-94355649:7,simpl,simple,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/175#issuecomment-94355649,1,['simpl'],['simple']
Usability,"It's also worth noting here that GATK has a `--tmp-dir` argument, while Picard has `--TMP_DIR`, and it's not clear how they interact when running Picard tools from within GATK.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6811#issuecomment-691243311:109,clear,clear,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6811#issuecomment-691243311,1,['clear'],['clear']
Usability,"It's not a technical problem but it's more than a question of style. It's a user experience problem. Happy to go into detail at some point (just not now). I hear you on the internal wiring rationale; but I think we should explore whether it's possible to fix that, potentially through changes to WDL itself. Clearly the language isn't allowing you to do what you need as an author and what I need as a user -- which I would characterize as ""conditional optionality"", ie things are made optional or not depending on a condition. Would be good to get redteam involved to see what they can suggest.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3657#issuecomment-334049665:76,user experience,user experience,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3657#issuecomment-334049665,1,['user experience'],['user experience']
Usability,It's not clear to me how this is happening. It seems like a bug in the scattering code. Why do we want to support this? . Do we expect tools to produce empty bams/ vcfs if they're given empty intervals? What about tools that require intervals? It's not clear to me what the behavior of a tool with empty intervals specified should be.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6209#issuecomment-540723529:9,clear,clear,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6209#issuecomment-540723529,2,['clear'],['clear']
Usability,"It's not clear to me that we want these tools in Gatk4. We deliberately didn't port them because we felt they were unnecessary going forward. . I understand that there are some legitimate use cases that require them: ex low coverage naive variant calling from high ploidy pools which haplotype caller would do poorly on. (Also, do we know that haplotype caller doesn't do well on those sorts of things? Maybe we should consider modifications there if it doesn't?) I'm not sure that supporting that use case is worth the added complexity of maintaining and supporting these tools. Especially since we don't provide a pileup based variant caller as part of gatk4... . @vdauwera Can you comment? . @sooheelee I'm not sure I agree with you that supporting this for mutect 1 is useful. ; A) We don't want to support the use of mutect 1 anymore and would like to encourage people to switch to mutect 2 which I think we now believe is a better variant caller for both snps and indels. ; B) Mutect 1 users are already using gatk3, so they have access to these tools already. Mutect 1 also requires co-cleaning which I believe is a different but related tool to indel realignment. . For the variant review issue, we have thoughts on implementing a much better solution for variant review by creating an assembly plugin for igv.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308451988:9,clear,clear,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308451988,1,['clear'],['clear']
Usability,"It's not clear to me what code path you're going through when using a `gs://` URI for the input bam in your second test. `CountReadsSpark` calls `GATKSparkTool.getReads()` which calls `JavaSparkContext.newAPIHadoopFile()`, but the question is how Hadoop-BAM handles your `gs://` URI. In other parts of the GATK (eg., `ReferenceTwoBitSource`) we call into `BucketUtils.openFile()`, which handles GCS URIs directly by calling into `GcsUtil.open()`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1755#issuecomment-213153356:9,clear,clear,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1755#issuecomment-213153356,1,['clear'],['clear']
Usability,"It's not clear what to do in this case - the MAF format spec has limited values in the `VariantClassification` field, so `GencodeGtfFeature.GeneTranscriptType` doesn't map 1:1 to `VariantClassification`. Will need to put off until later.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4405#issuecomment-389283259:9,clear,clear,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4405#issuecomment-389283259,1,['clear'],['clear']
Usability,It's not exactly clear what you're trying to do here. Are you trying to write a new tool that just gets the per base read depth? If that's what you want to do you would start by implementing a new `LocusWalker`. In the `apply` method you implement you can check `alignmentContext.size()` to get the pileup depth at each locus.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3881#issuecomment-347585515:17,clear,clear,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3881#issuecomment-347585515,1,['clear'],['clear']
Usability,"It's not immediately obvious why the Spark tests are failing. It could be something to do with the Spark context which is shared between tests, and which may be picking up some state that is not cleared from one test to the next. The tests are passing on Travis, which also runs all of them. Do they fail if you run them individually?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448275058:195,clear,cleared,195,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448275058,1,['clear'],['cleared']
Usability,"It's pretty clear at this point that there is a bug in tribble with iteration over block-compressed inputs that lack an index. This is a completely different codepath (and even a different `FeatureReader`) than you get if an index is present. To buy us some time to nail this down, we are going to patch GATK to always require an index for block-compressed tribble files, even if `-L` is not specified. This change will go out in the bug fix release this Friday.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359855307:12,clear,clear,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359855307,1,['clear'],['clear']
Usability,Its not entirely clear to my why Codecov hasn't commented here. But here is the commit on their page: https://codecov.io/gh/broadinstitute/gatk/commit/af23590723748fa27a2d065e48c26a20d0e91488,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5018#issuecomment-405633317:17,clear,clear,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5018#issuecomment-405633317,1,['clear'],['clear']
Usability,Jar on Maven central updated - please clear any cached jars,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-295584988:38,clear,clear,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-295584988,1,['clear'],['clear']
Usability,"Java implementation of segmentation is now in the sl_wgs_segmentation dev branch, with a few simple unit tests. I'll expand on these and add tests for denoising in the future, but for now we have a working revised pipeline up through segmentation. The CLI is simply named ModelSegments (since my thinking is that it could eventually replace ACNV). I ran it on some old denoised exomes. Runtime is <10s, comparable to CBS. Here's a particularly noisy exome:. CBS found 1398 segments:; ![cbs](https://user-images.githubusercontent.com/11076296/30165095-cdf6251a-93ac-11e7-91fb-dcc8f48fe07f.png). Kernel segmentation with a penalty given by a = 1, b = 0 found 1018 segments:; ![kern](https://user-images.githubusercontent.com/11076296/30165106-dbbe0b40-93ac-11e7-99ec-5d58d8417d8b.png). Kernel segmentation with a penalty given by a = b = 1 (which is probably a reasonable default penalty, at least based on asymptotic theoretical arguments) reduced this to 270 segments :; ![kern-smooth](https://user-images.githubusercontent.com/11076296/30165113-e2b545a8-93ac-11e7-97a9-a692e43ebbdf.png). The number of segments can similarly be controlled in WGS. WGS runtime is ~7min for 250bp bins, ~30s of which is TSV reading, and there is one more spot in my implementation that could stand a bit of optimization, which might bring the runtime down. In contrast, I kicked off CBS 45 minutes ago, and it's still running... @LeeTL1220 this is probably ready to hand off to you for some WDL writing and preliminary evaluation. ; Although I can't guarantee that there aren't bugs, I ran about ~80 exomes with no problem. We can talk later today.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-327797936:93,simpl,simple,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-327797936,2,['simpl'],"['simple', 'simply']"
Usability,Just adding a note here that `FeatureCache` should eventually be refactored to use the simplified Interval class (when it exists) to track cache boundaries and compute overlap.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/100#issuecomment-76229630:87,simpl,simplified,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/100#issuecomment-76229630,1,['simpl'],['simplified']
Usability,Just as feedback we use gcs nio too in Cromwell and have had to add retries around this error as it has popped up every now and then.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300269489:8,feedback,feedback,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300269489,1,['feedback'],['feedback']
Usability,"Just follow the recommendations from our readme file ; ```. First, make sure [Miniconda or Conda](https://conda.io/docs/index.html) is installed (Miniconda is sufficient). To ""create"" the conda environment:; If running from a zip or tar distribution, run the command conda env create -f gatkcondaenv.yml to create the gatk environment. Execute the shell command source activate gatk to activate the gatk environment.; See the [Conda](https://conda.io/docs/user-guide/tasks/manage-environments.html) documentation for additional information about using and managing Conda environments.; ```; And yes you don't have to call SNPs and INDELs separately.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8664#issuecomment-2213817998:461,guid,guide,461,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8664#issuecomment-2213817998,1,['guid'],['guide']
Usability,"Just learned `awk '$5=""*""'` replaces `T,*` with `*` and the correct usage is `awk '5~""*""'`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5129#issuecomment-417441866:5,learn,learned,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5129#issuecomment-417441866,1,['learn'],['learned']
Usability,"Just pushed two commits to address your feedback, @droazen!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356142226:40,feedback,feedback,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356142226,1,['feedback'],['feedback']
Usability,"Just some notes before I forget:. Using these test samples, I made some tweaks to the ploidy model that made it more robust to incorrect ploidy calls and added a simple modeling of mosaicism:. ```` ; # per-contig bias; bias_j = Gamma('bias_j',; alpha=100.0,; beta=100.0,; shape=(ploidy_workspace.num_contigs,)); norm_bias_j = bias_j / tt.mean(bias_j). # per-sample depth; depth_s = Uniform('depth_s',; lower=0.0,; upper=10000.0,; shape=(ploidy_workspace.num_samples,)); ; # per-sample probability of mosaicism; pi_mosaicism_s = Beta(name='pi_mosaicism_s',; alpha=1.0,; beta=50.0,; shape=(ploidy_workspace.num_samples,)). # per-sample-and-contig mosaicism factor; f_mosaicism_sj = Beta(name='f_mosaicism_sj',; alpha=10.0,; beta=1.0,; shape=(ploidy_workspace.num_samples, ploidy_workspace.num_contigs,)); norm_f_mosaicism_sj = f_mosaicism_sj / tt.max(f_mosaicism_sj, axis=1).dimshuffle(0, 'x'). # per-contig mapping error; eps_j = HalfNormal('eps_j', sd=0.01, shape=(ploidy_workspace.num_contigs,)). # negative-binomial means; mu_sjk = depth_s.dimshuffle(0, 'x', 'x') * t_j.dimshuffle('x', 0, 'x') * norm_bias_j.dimshuffle('x', 0, 'x') * \; (ploidy_workspace.int_ploidy_values_k.dimshuffle('x', 'x', 0) + eps_j.dimshuffle('x', 0, 'x')); mu_mosaic_sjk = norm_f_mosaicism_sj.dimshuffle(0, 1, 'x') * mu_sjk. # ""unexplained variance""; psi = Uniform(name='psi', upper=10.0). # convert ""unexplained variance"" to negative binomial over-dispersion; alpha = tt.inv((tt.exp(psi) - 1.0)). def _get_logp_sjk(_n_sj):; _logp_sjk = logsumexp([tt.log(1 - pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x')),; tt.log(pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_mosaic_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x'))],; axis=0)[0]; return _logp_sjk. DensityDist(name='n_sj_obs',; logp=lambda _n_sj: tt.sum(q_ploidy_sjk * _get_logp_sjk(_n_sj), axis=2),; observed=n_sj); ````. Brie",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890:162,simpl,simple,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890,1,['simpl'],['simple']
Usability,"Just to be clear folks, we are using `gatk` directly, not `./gatk` in the example commands. And if you can, for those of you yet to make your updates, please use compressed file examples. Those of you who've already put in changes, thank you and Comms can tidy those bits later.; ```; <h3>Usage examples</h3>; <pre>; gatk --javaOptions ""-Xmx4g"" GenotypeGVCFs \; 	-R Homo_sapiens_assembly38.fasta; 	-V combined.g.vcf.gz; 	-O cohort.vcf.gz; </pre>. <pre>; gatk GenotypeGVCFs \; 	-R reference.fa; 	-V combined.g.vcf.gz; 	-O cohort.vcf.gz; </pre>; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-350095894:11,clear,clear,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-350095894,1,['clear'],['clear']
Usability,"Just to be clear, the gCNV code expects that the intervals obtained after resolving the inputs of `-L` and `-XL` via the engine should specify the *bins* that the user wishes to retain from the coverage files.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5388#issuecomment-435497601:11,clear,clear,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5388#issuecomment-435497601,1,['clear'],['clear']
Usability,"Just to make sure I understand the issue---will this cause technical problems in the Firecloud environment, or is it more of a style issue?. If the latter, one reason I prefer the use of optional file inputs to trigger tool-level ""modes"" when possible is that it propagates more naturally from the tool level. For example, let's consider a tool that can operate in either tumor-only or matched-pair mode. It is natural at the tool level to make the tumor a required input and the normal optional. The other options are quite awkward: 1) make both inputs required and switch between using the normal or not with a flag (in which case it is very easy for the user to shoot themselves in the foot if they forget to set the flag right, and we'd have to pass a dummy normal every time we want to run tumor only if we don't actually have a pair), 2) leave the normal as optional but add a flag anyway, which would be redundant and require an additional validation (i.e., if the flag is set to matched mode but we don't have a normal, we should fail early), or 3) write separate tools for each mode with the corresponding required inputs. If we accept that optional file input is the way to handle such a scenario at the tool level but not at the workflow level, then we will simply run into the same problems at the workflow level. I'm sure there are more complex scenarios when triggering on file presence/absence doesn't uniquely specify a workflow, in which case flags are a must. But for simple scenarios, I'm not sure why we shouldn't take advantage of the ability to specify optional file inputs in WDL (actually, I'm not sure how else we are supposed to use them?). However, if this is a problem for Firecloud, then I'd like to understand why---and what possible solutions there might be.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3657#issuecomment-334046444:1269,simpl,simply,1269,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3657#issuecomment-334046444,2,['simpl'],"['simple', 'simply']"
Usability,"Let's discuss. In the new pipeline, I currently have median absolute deviation after standardization and denoising output as text files during the plotting step, as before. But I think it actually makes more sense to output them after DenoiseReadCounts. We also can't output the number of segments until after the ModelSegments step. However, I would rather not bake this sort of thing into the jar if a simple `wc -l` would suffice.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3583#issuecomment-335602331:404,simpl,simple,404,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3583#issuecomment-335602331,1,['simpl'],['simple']
Usability,"Let's hear what others say, but I think I would strongly prefer to simply take over VariantEval in another repo if this was something you'd consider. I'd likely do much of what you propose anyway (certainly WRT testing); however, perhaps not the microscope we went through with the core GATK changes earlier. On plugins: I like what seems to be shaping up w/ Barclay. I carried over the Stratifier and Evaluator as plugins because it seems like it would make sense to allow tools to provide extensions (VariantEval, our tool, does). If I took this PR a step further, I would have migrated many arguments currently top-level on VariantEval into the plugins themselves (a good feature in Barclay). As an aside: I dont think VariantAnnotator is migrated yet, but we have many GATK3 plugins related to annotation, and hope that tool retains Annotator plugins when it get migrated. My impressions of barclay are probably a little out of date. I agree the main argument parsing framework is pretty robust. Specifically on plugins, it seems a little less so, or at least there are not many tools I visibly see exercising that part of the code. For example, there really should be a default implmentation or base class between Barclay's plugins and ReadFilter plugins. I'm guessing if more tools in GATK4 were using plugins this would have happened. I created something like this for VariantEval, and without a ton of work that could probably get generalized; however, doing so would throw a lot higher bar on me and as noted above I'm trying to take on less, not more at the moment. If we do take over VariantEval, I'm certainly happy to try to contribute code and experiences to improve the core, through more targeted PRs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407202501:67,simpl,simply,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407202501,1,['simpl'],['simply']
Usability,Looking at the code changes the way this argument work has changed from simply clearing previous filters while apply new ones to being used standalone just to revert filtering (i.e. adding the . again) with the expectation that it would not be used in conjuction with new filters. I think we should create to different arguments for each of those operations. say --overwrite-existing-filters that that the former and --revert-filters that that the latter and will fail if you try to filter again in the same run. ... or perhaps the latter should have its own tool RevertFilration.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7608#issuecomment-995592204:72,simpl,simply,72,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7608#issuecomment-995592204,2,"['clear', 'simpl']","['clearing', 'simply']"
Usability,"Looking at the existing code in Hadoop_BAM it makes the assumption that coordinates are always of the form ```chr:start-stop``` never things like ```chr```, ```chr:pos```, ```char:star+```... I've just generalized a bit more so that it can handle ':' and '-' inside the ```chr``` in a PR. I guess is not ideal but In any case this addresses the current fire and dependants have a clear work around which is to provide their intervals in the expected ```chr:start-stop``` format.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3360#issuecomment-331202249:380,clear,clear,380,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3360#issuecomment-331202249,1,['clear'],['clear']
Usability,Looking into finding a way to enable experimental docker features for `gcr.io/cloud-builders/docker` so that we can run with the `--squash` argument -- it's not yet clear that this is possible.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8247#issuecomment-1480107181:165,clear,clear,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8247#issuecomment-1480107181,1,['clear'],['clear']
Usability,"Looks great!. One quick note: I don't get the idea behind `Poisson` -- shouldn't we simply use negative binomials w/ modeled `mu_sj` and `alpha_sj`, evaluated at observed counts (`tt.arange(min_count, max_count + 1)`), and weighted with the number bins for each count (`_hist_sjm`)? i.e. if one observes an empirical distribution `P_obs(x)` rather than `x` draws, then the appropriate max likelihood objective function is `\sum_x P_obs(x) log P_model(x | \theta)`. Perhaps this is exactly what you've done and I don't get it. Another quick note: what I had in mind was _either_ modeling `mu_sj` at quantized ploidy states, _or_ let the ploidy state be unrestricted w/ a penalty via. a Bernoulli process (possibly w/ different per-contig penalties to account for e.g. higher rate of X/Y loss). We have enough samples in the cohort to select the quantized model (and those samples pin down the per-contig biases `b_j`). The samples that do not conform to quantized ploidy states can then choose whatever (variable) ploidy state they wish by paying a (hefty) price. We would also need to mask contigs that have variable ploidy calls from gCNV.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376286536:84,simpl,simply,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376286536,1,['simpl'],['simply']
Usability,"Looks like all packages *except* ggplot2 were successfully installed. The following lines in the R script are responsible for installing 3 of the packages:. ```; dependencies = c(""ggplot2"",""gplots"",""gsalib""); repos <- c(""http://cran.cnr.Berkeley.edu"",; ""https://cran.mtu.edu"",; ""http://lib.stat.cmu.edu/R/CRAN/""); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- 1; while(length(missing)!=0 & try <= length(repos)) {; install.packages(dependencies[missing], repos = repos[try], clean = TRUE); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- try + 1; }; ```. I guess this is supposed to ensure that the installs don't fail due to intermittent connection errors, etc., but each repo is only hit once and it's possible for the loop to exit with dependencies still missing. Could this have happened when the current base image was built and pushed? @jamesemery did you push this image?. Also, I learned that *reshape2* (as opposed to reshape) is actually a dependency of ggplot2 that is automatically installed along with ggplot2. So the original removal of reshape from the `install.packages` list was fine. However, the import statement that is removed in this PR fails whether or not ggplot2 successfully installs, and is extraneous in any case. This is all consistent with the fact that the users from the forum post only get an error message about reshape and not ggplot2. Note that they are using broadinstitute/gatk:4.0.4.0, in which ggplot2 is successfully installed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406028261:950,learn,learned,950,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406028261,1,['learn'],['learned']
Usability,"Looks like this failed on travis. I think given that given the lateness of the hour (release wise), we might want to take the original change that removes the libgcc-ng dependency, since that passed on travis, and rely on the simple workarounds for osx, which we'll have to convey out-of-band. Anything that requires changing the docker image seems risky at this point, not to mention that the image is already at 5.2 gig, which is way over our desired target. @samuelklee Any thoughts on this ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356131086:226,simpl,simple,226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356131086,1,['simpl'],['simple']
Usability,"Lots of refactoring was done for the Segmenter classes in #6499. At least for segmentation, all use cases (CR-only, AF-only, CR+AF, single-sample, multi-sample) now go through `MultisampleMultidimensionalKernelSegmenter`. `AlleleFractionKernelSegmenter` and `CopyRatioKernelSegmenter` classes still exist, but both simply call the `MultisampleMultidimensionalKernelSegmenter` class; this was done so preexisting tests for those two classes could be reused. I'm fine with calling this done. We can always open a new issue in the unlikely event we refactor the modelling code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5625#issuecomment-900609908:315,simpl,simply,315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5625#issuecomment-900609908,1,['simpl'],['simply']
Usability,Maybe @lbergelson would be willing to review or provide guidance for a new engine team member?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320262613:56,guid,guidance,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320262613,1,['guid'],['guidance']
Usability,"Maybe I misunderstand the underlying model, but if some Pedigree annotations only need to know which samples are founders (ExcessHet ?) , and some need to know the full relationships (PossibleDeNovo), then I'm suggesting we change the class hierarchy to reflect that:. PedigreeAnnotation; |--TrioAnnotation; |----PossibleDeNovo; |--ExcessHet (assuming ExcessHet only needs founders...); ... Then the plugin could deterministically validate whether the user has provided sufficient args for the set of requested annotations; and if so, propagate them accordingly. A TrioAnnotation could only be populated (from the command line at least) from a file, whereas the others could be populated from either a file or just a set of IDs. I think it would simplify the annotations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-463372550:746,simpl,simplify,746,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-463372550,1,['simpl'],['simplify']
Usability,"Maybe I'm simplifying things too much, but can't the equation in the paper be just rewritten as follows and thus the 2 will get eliminated:. ![paternal-maternal-phasing](https://cloud.githubusercontent.com/assets/6555937/17099330/b068c106-5235-11e6-83a1-718903d0012a.png). The above shows both orders that the phasing can happen assuming each phase representation is independent of the other, where each can appear with equal probability averaging to the unphased likelihood.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2019#issuecomment-234686510:10,simpl,simplifying,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2019#issuecomment-234686510,1,['simpl'],['simplifying']
Usability,"Maybe it would be clearer to rename `onTraversalDone()` -> `cleanup()` It seems useful to offer both options, but it is a bit confusing still.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1743#issuecomment-212609203:18,clear,clearer,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1743#issuecomment-212609203,1,['clear'],['clearer']
Usability,"Merging this now to have usable VCF NIO support in master -- continuous tests to prove that the wrapper is applied will be added in a separate PR, but my ad-hoc tests on the latest version of this branch suggest it's working fine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2393#issuecomment-277697090:25,usab,usable,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2393#issuecomment-277697090,1,['usab'],['usable']
Usability,Might actually be a simple fix in HTSJDK...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3669#issuecomment-390027480:20,simpl,simple,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3669#issuecomment-390027480,1,['simpl'],['simple']
Usability,"Modeling PCR stutter is better done with Valentin's approach, or in BQSR, or with deep learning. Making pairHMM fancier is not the answer.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1869#issuecomment-381080555:87,learn,learning,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1869#issuecomment-381080555,1,['learn'],['learning']
Usability,"Multiple badges should be fine, provided we include a clear label for each one.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1705#issuecomment-213567101:54,clear,clear,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1705#issuecomment-213567101,1,['clear'],['clear']
Usability,"My GenotypeGVCFs run for a single chromosome returned the following completion statement:; 18:54:40.516 INFO ProgressMeter - Traversal complete. Processed 606308 total variants in 75.2 minutes. However, there are only 46814 variant rows (excluding 52 header rows) in the corresponding vcf file. Does the above figure of 606308 correspond to a multiple of 'variants x number of samples'?. Also, there are only 16863 lines in my log file, does this mean that the 'Current Locus' column in the log file doesn't correspond to a single genomic location (bp) in the fasta file?. I am curious to know what is the relation between all these figures to fully understand what is happening while processing the gCVF files. Also, on the inbreeding coefficient warning issue, I understand from your @Neato-Nick feedback that the variants with these warnings may still be fine and can be retained. However, this still leaves me worrying that out of 384 samples the locus doesn't even have 10 samples for generating the required metrics. Such variants won't be of any use for downstream analyses anyway where any variants with more than 80% missing samples will be removed. Therefore, I wish to seek some more information about this 10 sample thing - does it have some other context or does it literally mean that there are only less than 10 samples carrying that variant?. Regards,; Sanjeev",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409255344:798,feedback,feedback,798,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409255344,1,['feedback'],['feedback']
Usability,"N_REF> . . DP=2528691;MQRankSum=0.387;MQ_DP=158;QUALapprox=1557;; chr20 1270175 . A *,<NON_REF> . . DP=1680371 | chr20 1270175 . A *,<NON_REF> . . DP=2528811; chr20 1270176 . A <NON_REF> . . . chr20 1270176 . A <NON_REF> . . .; chr20 1270177 . A <NON_REF> . . . chr20 1270177 . A <NON_REF> . . .; chr20 1270178 . C <NON_REF> . . . chr20 1270178 . C <NON_REF> . . .; chr20 1270179 . A G,<NON_REF> . . DP=1681456;MQ=60.00;MQRankSum=-1.330e-01;MQ_DP=3998;Q | chr20 1270179 . A G,<NON_REF> . . DP=2529148;MQ=60.00;MQRankSum=-1.330e-01;MQ_DP=3998;Q; chr20 1270180 . T <NON_REF> . . . chr20 1270180 . T <NON_REF> . . .; chr20 1270181 . T G,<NON_REF> . . DP=1680135;MQRankSum=-5.980e-01;MQ_DP=122;QUALapprox= | chr20 1270181 . T G,<NON_REF> . . DP=2528796;MQRankSum=-5.980e-01;MQ_DP=122;QUALapprox=; chr20 1270182 . G <NON_REF> . . . chr20 1270182 . G <NON_REF> . . .; chr20 1270183 . A <NON_REF> . . . chr20 1270183 . A <NON_REF> . . .; chr20 1270184 . C <NON_REF> . . . chr20 1270184 . C <NON_REF> . . .; chr20 1270185 . C A,<NON_REF> . . DP=1679938;MQRankSum=0.401;MQ_DP=276;QUALapprox=3525; | chr20 1270185 . C A,<NON_REF> . . DP=2528310;MQRankSum=0.401;MQ_DP=276;QUALapprox=3525;; chr20 1270186 . A <NON_REF> . . . chr20 1270186 . A <NON_REF> . . .; chr20 1270187 . G T,<NON_REF> . . DP=1680013;MQRankSum=1.52;MQ_DP=16;QUALapprox=210;RAW | chr20 1270187 . G T,<NON_REF> . . DP=2528560;MQRankSum=1.52;MQ_DP=16;QUALapprox=210;RAW; chr20 1270188 . C G,<NON_REF> . . DP=1680051;MQRankSum=-1.480e+00;MQ_DP=13;QUALapprox=1 | chr20 1270188 . C G,<NON_REF> . . DP=2528536;MQRankSum=-1.480e+00;MQ_DP=13;QUALapprox=1; ```; GenotypeGVCFs from the original jar agrees with the version on the left from the same jar, which isn't a big surprise. My intuition leads me to believe that this could be something like excluding no-call sites from the DP sum, but in the new version those sites don't become no-call without genotyping. Can you see if you can reproduce the problem with a more manageable number of samples?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3688#issuecomment-376896240:2039,intuit,intuition,2039,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3688#issuecomment-376896240,1,['intuit'],['intuition']
Usability,"Need some guidance here. The CompareSAMs tool was not propagating the validation stringency. I have a fix for that, but that alone doesn't fix the compareBAMFiles test in BaseRecalibrationIntegrationTest.java, since that uses SamAssertionUtils.assertSamsEqual, which also doesn't propagate (or accept) a validation stringency. Changing SamAssertionUtils to use either SILENT or LENIENT does fix the integration test, and all the other tests pass, but it seems like a relaxing of the stringency, and I'm not sure it should be necessary to the BQSR test. If relaxing the stringency for BQSR test _IS_ the right path, one possibility is to add a new method to SamAssertionUtils that accepts a validation stringency argument.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/419#issuecomment-109796266:10,guid,guidance,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/419#issuecomment-109796266,1,['guid'],['guidance']
Usability,"Next I set out to determine whether hellbender is slowing down on the larger interval simply because there is more data / a longer traversal, or because it's slower at processing the `1:1-10000000` interval than the `1:10000000-20000000` interval. And surprisingly, it appears that the latter is the case:. Time to process the `1:1-10000000` interval across two runs:. ```; GATK3: 5m25.983s 5m31.913s; HB: 6m2.156s 5m59.804s; ```. (Recall that HB was ~5% faster than GATK3 at processing the `1:10000000-20000000` interval). Moreover, our newly-installed progress meter shows that the rate at which we process records is unusually low at the start of the `1:1-10000000` interval, but is consistent throughout the processing of the `1:10000000-20000000` interval:. HB processing rate over 1:1-10000000:. ```; 14:22:19.520 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 14:22:29.522 INFO ProgressMeter - 1:769026 0.2 133000 797920.2; 14:22:39.531 INFO ProgressMeter - 1:1066133 0.3 298000 893553.2; 14:22:49.544 INFO ProgressMeter - 1:1389358 0.5 471000 941247.0; 14:22:59.572 INFO ProgressMeter - 1:1695902 0.7 636000 952785.2; 14:23:09.601 INFO ProgressMeter - 1:1961884 0.8 808000 968031.8; 14:23:19.636 INFO ProgressMeter - 1:2264803 1.0 985000 983099.3; 14:23:29.637 INFO ProgressMeter - 1:2583326 1.2 1162000 994352.2; 14:23:39.694 INFO ProgressMeter - 1:2817177 1.3 1297000 970638.9; 14:23:49.705 INFO ProgressMeter - 1:3095124 1.5 1467000 975993.8; 14:23:59.726 INFO ProgressMeter - 1:3372416 1.7 1637000 980190.6; 14:24:09.734 INFO ProgressMeter - 1:3678706 1.8 1810000 985355.8; 14:24:19.777 INFO ProgressMeter - 1:4087198 2.0 1984000 989880.0; 14:24:29.813 INFO ProgressMeter - 1:4341518 2.2 2165000 996983.7; 14:24:39.822 INFO ProgressMeter - 1:4598153 2.3 2350000 1004975.0; 14:24:49.834 INFO ProgressMeter - 1:4859664 2.5 2530000 1009892.7; 14:24:59.838 INFO ProgressMeter - 1:5103960 2.7 2712000 1014982.7; 14:25:09.887 INFO ProgressMeter - 1:5341742 ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1032#issuecomment-150660236:86,simpl,simply,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1032#issuecomment-150660236,1,['simpl'],['simply']
Usability,"Next commit includes:. * Change the name to PrimaryLineReadFilter; * Remove impl notes completely, because if they aren't tags, they will be populated to the user documentation. With the name change, I believe that it isn't necessary anymore: with the current text is clear that the concept of primary alignment is more stringent for this filter, the name change clarify that it is a different filter than the previous GATK versions, and the name of HTSJDK flag is also different. Back to you @cmnbroad",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3195#issuecomment-327440250:268,clear,clear,268,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3195#issuecomment-327440250,1,['clear'],['clear']
Usability,"Nice that HTSJDK is moving forward to version 3. The points that I would like to address are similar to yours, with some inclussions. * Regarding NIO support, I would go to remove completely `File` support. If API users need to use the `File` abstraction, they should convert to a `java.nio.Path` using the `toPath` method.; * In addition, I would like that HTTP/S and FTP is handled also with NIO. For HTTP/S, I am working in a simple `FileSystemProvider` that should be good enough for using in combination with HTSJDK ([jsr203-http](https://github.com/magicDGS/jsr203-http)), and I can speed up the development there for needs in HTSJDK; for FTP, maybe [ftp-fs](https://github.com/robtimus/ftp-fs) can be used or a simple implementation can be derived from the HTTP/S implementation (without credentials). This will remove the special handling of HTTP/S and FTP paths in HTSJDK in favor of a consistent and pluggable manner.; * Interfaces for the data types are great, and maybe it will be good to have codec interfaces for both encoding and decoding. For example, I am missing encoders in tribble (an attempt in https://github.com/samtools/htsjdk/pull/822 for writing support).; * For VCF, I would like to have a less diploid-centric interface and design, or at least a way of configure the catching of genotype-related attributes. Currently there are methods for homozygotes/heterozygotes that aren't really useful for triploids or even VCFs without variation (for example, in Pool-Seq data).; * Modular design for artifacts: thus, a project with only SAM/BAM requirements will require only `htsjdk-sam`, and if they also want CRAM support, `htsjdk-cram`. See https://github.com/samtools/htsjdk/issues/896 for more info about it.; * Common license for all HTSJDK, or at least for each module. This will be good for taking into account legal concerns when including the library, because now there is a mixture depending on the files that are used. This is what is coming to my mind now. Maybe I ad",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940:429,simpl,simple,429,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940,2,['simpl'],['simple']
Usability,"Nifty, I learned about docker system prune...; Total reclaimed space: 9.254GB",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-679242347:9,learn,learned,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6764#issuecomment-679242347,1,['learn'],['learned']
Usability,"No AVX = it'll crash... sounds bad, I admit. But remember we are talking about running a deep neural network over a large dataset: is someone really going to want to do that on hardware that is 8 years old (pre-AVX)? This version of TensorFlow is now the _default_ for all Anaconda users, which in practice probably means a sizeable fraction of the machine learning community, and so having minimum hardware requirements in line with theirs is perhaps not so unreasonable?. Another option would be to change the default: have the gatk enviroment use the accelerated TensorFlow (since almost everyone has AVX, and they can get a 10X or so speedup), but make a second environment available for people that want to try to run a deep neural network on very old hardware - gatk-old?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-417041021:357,learn,learning,357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-417041021,1,['learn'],['learning']
Usability,"No problem – I can see how this would be challenging to review – maybe it’s not even practical – if you decide it’s best just not to use it that’s OK - working on these issues has been a valuable learning experience for me. . I sent an archive with the new validations and the diffs between the old and new bams to akiezun. Although in many cases the files shared types of errors, I had to look at each file individually to take into account the particular errors in each file and how to fix them without (to the best of my knowledge) interfering with the purpose of the test. I did write a python script to use where necessary for converting multiple unpaired reads in a file to single reads, and I used bash scripts to call the picard tools to convert multiple files at a time from bam to sam for editing and then back again after they were modified. In some cases I had to modify the values in test output files to match the values produced by the test using the modified bams/sams, or just capture the new output files and use them to replace the old with the new. In two cases where file format errors appeared to be necessary but the filename did not indicate this, I renamed the files to make this clear. From: Louis Bergelson ; Sent: Thursday, August 20, 2015 2:13 PM; To: broadinstitute/hellbender ; Cc: nenewell ; Subject: Re: [hellbender] Issue 569 - bam and sam file cleanup. (#809). @nenewell Sorry this has been sitting. We've been trying to figure out how to review this one. Could you describe how you made the changes? Did you script it or go through by hand and modify them all?. —; Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/809#issuecomment-133123051:196,learn,learning,196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/809#issuecomment-133123051,2,"['clear', 'learn']","['clear', 'learning']"
Usability,"No problem. I'd rather take styling issues ironed out from the beginning, and in fact I learn quite a lot about GATK/Picard and Java in the process.; Thank you very much for your patience!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1529#issuecomment-191304706:88,learn,learn,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1529#issuecomment-191304706,1,['learn'],['learn']
Usability,No worries Laura. Thanks again for the feedback.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5601#issuecomment-459140569:39,feedback,feedback,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5601#issuecomment-459140569,1,['feedback'],['feedback']
Usability,"No worries on the timeline. I definitely appreciate your willingness to look into it and considering a fix. I know how unexpectedly time consuming it can become even if it seems simple, especially with other tasks and responsibilities. I hope you enjoy your holidays!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8134#issuecomment-1360383177:178,simpl,simple,178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8134#issuecomment-1360383177,1,['simpl'],['simple']
Usability,"Non-Spark walker implementations don't need an explicit --runner argument at all (and shouldn't, as we want them to be as easy to run as their GATK3 counterparts). I vote no on the `--sparkRunner` -> `--runner` rename, as I think our users are mostly unfamiliar with Spark, and it's good to be clear about what is a Spark argument and what is a tool argument.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1357#issuecomment-164069571:294,clear,clear,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1357#issuecomment-164069571,1,['clear'],['clear']
Usability,"Nope, simply an ignorance of that part of the VCF spec, and the fact that `INSERTED_SEQUENCE_MAPPINGS` is using `,` for separating fields of a single mapping.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2502#issuecomment-288285382:6,simpl,simply,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2502#issuecomment-288285382,1,['simpl'],['simply']
Usability,"Normally for most tools in order to traverse the entire reference you simply would not specify anything for --intervals (or -L which is equivalent) but currently DepthOfCoverage requires intervals be specified. The reason for this is that for several of the outputs of DepthOfCoverage we output rows where each row is one of the user supplied intervals which don't exist in the case where no intervals are supplied. This behavior could probably be changed to simply treat each chromosome separately as an ""interval"" though given the complexities of regions that are dropped/in gaps it might warrant a warning. . @humblescientist If you would like to traverse over your entire reference in DepthOfCoverage the best way would be to provide an interval list file with -L/--intervals that covers the entire genome. If you would like more information on interval list files that GATK accepts you can find more information here https://gatk.broadinstitute.org/hc/en-us/articles/360035531852-Intervals-and-interval-lists. I would recommend directing further questions about this to the forums since this tracker is intended for bug reports and feature requests in GATK.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7155#issuecomment-804299340:70,simpl,simply,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7155#issuecomment-804299340,2,['simpl'],['simply']
Usability,"Not sure how to get Travis to take up your branch again, so I made a pull request (#1691); https://github.com/broadinstitute/gatk/pull/1691. even though I don't actually intend to merge this yet (it should stay in a separate branch because it changes the repository). To be clear I don't intend to merge it into _main_ yet, but it makes perfect sense to merge it into the _gcs-nio_ branch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1662#issuecomment-207071663:274,clear,clear,274,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1662#issuecomment-207071663,1,['clear'],['clear']
Usability,"Not sure if this is outside the scope of a simple port, but I think it would be great if the fitting of a `GaussianMixtureModel` was made a little bit more generic and extracted. Right now the method `maximizeGaussian` takes in `List<VariantDatum>`, but it should be trivial to refactor it to take in a `double[]` or `List<Double>`. Fitting a GMM could be more generally useful for other methods, after all. It might even be useful to extract the k-means clustering code used to initialize the model, if this is retained in the port. Perhaps also outside the scope, but it'd also be nice if variable names were changed to match the notation in Bishop Ch. 10 (on which the variational-Bayes algorithm is based). I think this would make the code much easier to parse from a mathematical standpoint.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2062#issuecomment-236003146:43,simpl,simple,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2062#issuecomment-236003146,1,['simpl'],['simple']
Usability,"Not sure this is ready for a complete review yet, but wanted to get feedback early (not a lot of testing here).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6274#issuecomment-556364217:68,feedback,feedback,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6274#issuecomment-556364217,1,['feedback'],['feedback']
Usability,"Not sure what your `GenotypeGVCFs` command was, but did you use the `--genomicsdb-shared-posixfs-optimizations` option? This option is available for the import too and may improve your performance.; ```; --genomicsdb-shared-posixfs-optimizations <Boolean>; Allow for optimizations to improve the usability and performance for shared Posix; Filesystems(e.g. NFS, Lustre). If set, file level locking is disabled and file system; writes are minimized. Default value: false. Possible values: {true, false} ; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8637#issuecomment-1879779166:296,usab,usability,296,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8637#issuecomment-1879779166,1,['usab'],['usability']
Usability,"Note: this has the ""learn GATK"" label because it is self-contained, but it is not easy.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4919#issuecomment-400757635:20,learn,learn,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4919#issuecomment-400757635,1,['learn'],['learn']
Usability,"Now that I've spent a day surveying the landscape of p-values, I'm thinking what must've happened is that an undocumented mid-p-value correction was added to the one-tailed p-value we claim to calculate. This is probably a fine thing to calculate, but such a correction is not discussed in the annotation docs nor in the Wigginton paper cited there. Nor is this what is calculated by any of the other implementations out there, as far as I can tell. So we could keep the original calculation, while further clarifying what exactly we are calculating in the docs (and add references, if appropriate). In this case, we can just keep the cleanup and improved tests as a bonus. (As a further bonus, we won't lose our old friend 3.0103!). Or we could move to this calculation. In this case, I believe we would match the bcftools ExcHet p-value (although I still need to check this claim for correctness). I'm not sure if the original intent was to be more/less conservative in retaining sites during hard filtering prior to VQSR. But since the filtering threshold used in Best Practices seems very conservative, I would guess that we wanted to err on the side of not throwing out possible variants, even if they are pretty out of HWE. Which makes the choice of a mid p-value puzzling, since it's strictly smaller and will thus lead to more rejections (I think, if I've got everything the right way around!). Happy to go either direction. In the end, I have just reaffirmed my dislike for p-values, which I had hitherto thought to be saturated.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-893597356:109,undo,undocumented,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-893597356,1,['undo'],['undocumented']
Usability,"Now, it seems like calling `contaminationDownsampling` right after `retainEvidence` could cause problems if both methods remove reads. However, one might correctly point out that although the cache invalidation I mentioned is not handled systematically, the method `removeEvidenceByIndex` _does_ have some code to update the evidence by sample and the evidence index map. It's possible that this code is totally fine and that this lead is a dead end. However, the code looks like it could be simpler and it's tough to parse. For example, try to track the `to` variable, which determines the determination of the outer `for` loop:. ```; for (int etrIndex = 1, to = nextIndexToRemove, from = to + 1; to < newEvidenceCount; etrIndex++, from++) {; if (etrIndex < evidencesToRemove.length) {; nextIndexToRemove = evidencesToRemove[etrIndex];; evidenceIndex.remove(evidences.get(nextIndexToRemove));; } else {; nextIndexToRemove = oldEvidenceCount;; }; for (; from < nextIndexToRemove; from++) {; final EVIDENCE evidence = evidences.get(from);; evidences.set(to, evidence);; evidenceIndex.put(evidence, to++);; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6586#issuecomment-625030697:492,simpl,simpler,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6586#issuecomment-625030697,1,['simpl'],['simpler']
Usability,"OK - PedigreeValidationType is now set in the constructor and is final. This does not separate the two intertwined codepaths around PedigreeFile vs. FounderIds, but that was a pre-existing problem. It doesnt doesnt change the pre-existing weirdness around the timing of setting pedigreeFile and/or founderIds within GATKAnnotationPluginDescriptor, where PedigreeAnnotation gets special treatment. I dont think this makes that situation any worse. if you still have concerns on this proposal, I actually think I could make our code work if you simply exposed a protected getPedigreeFile() method on PedigreeAnnotation. I can make the SampleDB instance in my code without needed to share code here. It seemed useful to expose some of that code to avoid duplication, but if it's going to over-complicate we can remove it. Also: that one test failure seems potentially unrelated (https://travis-ci.com/github/broadinstitute/gatk/jobs/510624560)? A compile issue with javadoc?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7277#issuecomment-853986169:543,simpl,simply,543,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7277#issuecomment-853986169,1,['simpl'],['simply']
Usability,"OK, great---I'll issue some PRs to delete some of the prototype tools soon and update the spreadsheet accordingly. A non-CNV-specific ""Deprecated"" program group seems reasonable to me if there is enough demand. If this is the only way to delineate the legacy CNV + ACNV pipeline from the new pipeline, I'm OK with it---but we should probably make the situation clear at any workshops, presentations, etc. between now and release that might focus on the legacy pipeline. On a different note, are there any conventions for short names that we should follow?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346191550:361,clear,clear,361,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346191550,1,['clear'],['clear']
Usability,"OK, interesting. This was not entirely clear from the docs. Our cluster in theory is functioning again on monday and we will start these.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-656385491:39,clear,clear,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-656385491,1,['clear'],['clear']
Usability,"OK, so to be clear - should I press the ""merge"" button?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2101#issuecomment-248730919:13,clear,clear,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2101#issuecomment-248730919,1,['clear'],['clear']
Usability,"OK, thanks @droazen. I'll go ahead and expose all of them in a branch for now. For my own education, perhaps @jamesemery or @vruano can comment---does turning on DRAGEN sidestep all or some subset of the code paths where the above 3 sets of parameters come into play?. For what it's worth, now that I'm looking at short variants in malaria as a ""novice"" HC/M2 user, the command line options are quite daunting! Many of them are not well documented and it's not always clear which options might interact with each other. Perhaps once the evaluations are in place, it might be worth doing some model ablation to see if we can come up with a more minimal set of options (including the consolidation of the parameters under discussion, if possible).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705096593:468,clear,clear,468,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705096593,1,['clear'],['clear']
Usability,"OK, thanks for rerunning! I wonder if there are generalizations akin to F-score that would weight sensitivity higher, but the LL score is probably already unfamiliar enough. I think considering that this quantity is the square of the recall of labeled instances over the fraction M_1 / M of overall positive calls may make it more intuitive; we divide by M at some point, but this is balanced by the presence of the proportional M_1. In some sense, we are thus concerned with the relative distribution of labeled instances in the overall score-ordered callset, and less so the overall class balance.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1170094169:331,intuit,intuitive,331,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1170094169,1,['intuit'],['intuitive']
Usability,"OK, that's reasonable. I'll dig into the other test changes. I can answer a few:. - Regarding passing the VariantWalker: I agree that's not an improvement by itself, but I would argue it's not that much different than it was. My plan is to pass a VariantEvalContext object, which would obscure any need to have knowledge of the walker. In an attempt to keep this PR simpler, I didnt complete that work. I do expect to make a second PR in relatively short order, once we get this resolved. - With respect to testEvalTrackWithoutGenotypesWithSampleFields and the different reference: I think the issue is that the old version (master GATK branch) didnt validate as strictly. When switching to MultiVariantWalkerGroupedOnStart, the reference is required, and the tool will error if the contigs dont match. VariantEval on the master branch didnt really need the reference for anything, and was apparently more permissive if it didnt line up. It probably preferentially grabbed the dictionary from the VCF header. I will look into those other questions",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-744698072:366,simpl,simpler,366,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-744698072,1,['simpl'],['simpler']
Usability,"OK, the first test run I tried was with 1kb bins and *no additional normals*. Coverage takes about an hour to collect per BAM and ploidy inference takes about 10 minutes. A few things:. 1) Looks like we are concordant with the truth CN on X for all but 3/40 of the samples. The GQs for these discordant calls are low (~3, 23, and 25 compared with ~400 for most of the others). 2) However, we are striking out on over half of the samples on Y. We mostly call 1 copy when the truth calls 0. Mehrtash thinks this is because a) I didn't mask out any PARs or otherwise troublesome regions on Y and b) I didn't include any other normals. I'll try rerunning with a mask first, then with other normals, and then with both. Hopefully this should clear up with just the mask. 3) There are a few samples where we strike out because the truth calls 2 copies on Y and we call 1. Mehrtash pointed out that this is most likely because the prior table we put together assumes Y can have at most 1 copy. So hopefully these are trivially recovered once we relax this. 4) The GQs are weirdly high on 1, X, and Y compared to the rest of the autosomes. @ldgauthier any idea why this might be? If there's no reason, then something funny is going on within the tool. I haven't gotten a chance to plot any of the counts data yet, either, which may make things more obvious. I'll do this today.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-364234449:737,clear,clear,737,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-364234449,1,['clear'],['clear']
Usability,"OK. However, don't forget that the denoising model is fit independently in each block. So introducing too many blocks could cause overfitting, in a sense. Also, you want to make sure that you have enough bins in each block to learn the model. 10k seems safe, but I'd spot check results first if you want to go down to 1k.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4397#issuecomment-391071615:226,learn,learn,226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4397#issuecomment-391071615,1,['learn'],['learn']
Usability,Oh!!; I thought GATK on conda was maintained by GATK. My bad. Just learned from this [blog](https://gatkforums.broadinstitute.org/gatk/discussion/11361/installing-gatk4-via-conda). I will install it separately.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-595886955:67,learn,learned,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-595886955,1,['learn'],['learned']
Usability,"Ok -- caveat for all -- objects in bucket that are accessed via simple API Key need to have: User:allUsers:reader ACL permissions. if you need more complex access control, we'll have to support the ""secretFile"" attribute in `gcloud dataproc` -- not just the apiKey.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1609#issuecomment-228425738:64,simpl,simple,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1609#issuecomment-228425738,1,['simpl'],['simple']
Usability,"Ok, thanks for the feedback @lbergelson!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-411500763:19,feedback,feedback,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5094#issuecomment-411500763,1,['feedback'],['feedback']
Usability,"Okay tranche filtering and training script are in. They're pure python right now but it would be simple to wrap them in java CLP via PythonScriptExecutor. These scripts add several dependencies which will probably make the already big docker quite a bit bigger. Long term I think we can get rid of most of them as we already have for inference, but we want to have some training functionality available by AGBT which is the week after next. Ready for a first round review @cmnbroad.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-362679008:97,simpl,simple,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-362679008,1,['simpl'],['simple']
Usability,"On a whim I took the latest code from master and commented out the two lines in HaplotypeCallerEngine:257-258 that disable phsyical phasing if `emitReferenceConfidence()` is false, and tried running HC to generate a genotyped VCF with phase. At least on a simple test of a ~200bp locus with a pair of phased variants it appears to do the right thing and not cause any errors. I know testing calling in one small locus isn't exactly comprehensive, and I'm trying now to call a larger set of regions and compare the calls generated to expected phase. Does anyone recall why this restriction was in place? I'm hoping that perhaps it was needed at the time, but isn't now and was just left in place because nobody needed it removed? I see the lines in question were last touched by @droazen in April 2016, but even that commit seems to be a large scale moving around of code rather than a commit that addressed this specific issue. I'm going to open a PR to remove those lines - mostly so I can have the tests run up in CI, and see if anything breaks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470618640:256,simpl,simple,256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470618640,1,['simpl'],['simple']
Usability,"On second thought -- to simplify the merge to master we may take a different approach (copying files, squashing, etc) so I'm updating the approach above for this PR",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7260#issuecomment-844179537:24,simpl,simplify,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7260#issuecomment-844179537,1,['simpl'],['simplify']
Usability,On second thought there is an incredibly simple solution that R uses by including everything past 10e-7 as equal or more extreme.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2586#issuecomment-297757830:41,simpl,simple,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2586#issuecomment-297757830,1,['simpl'],['simple']
Usability,"On the first question, we definitely appreciate how much work this will take. Often, porting the code is the easy part; developing new tests and test data can be a huge effort. I can try to find out if it would be possible for you to take the tool over - I know this kind of thing has come up before for other tools, but I'd have to ask around to find that out. @vdauwera do you have input on this ?. As for the plugins, currently in your branch `VariantStratification` and `VariantEvaluator` are modeled as Barclay command line plugin descriptors, and I was questioning whether thats necessary. Being a plugin is not necessarily required - `ReadFilter` and `Annotation` are both plugins, but they didn't have to be, and it takes quite a bit of work (again, mostly test development) to get a plugin right. Also, I'd consider the Barclay plugin framework to be pretty developed at this point, so I'd be curious to learn more about what issues you see. And yes, definitely don't check any of the large GATK3 test files into the repo, even temporarily. Take a look at [General guidelines for GATK4 developers](https://github.com/broadinstitute/gatk#dev_guidelines) if you haven't already. As you pointed out, new GATK4 tests that use smaller files would have to be developed. We'd want those to be included, and passing tests on the CI server, before we started reviewing the branch, so we know we're reviewing code that works and is covered by tests as much as possible. The second commit in my list above would have only your GATK3 java test files, etc (but not the big files, which you appear to have locally). The third commit would have your ported tool code, as well as the new test code, with the new tests enabled, as well as the smaller input files and expected results files. At the end we'd remove commit #2.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407185633:913,learn,learn,913,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407185633,2,"['guid', 'learn']","['guidelines', 'learn']"
Usability,"On the general comment of this class being too big: I totally agree.; I haven't figured out how to make Java in this semi-functional style pretty. I could certainly pull a mess of nested classes out into top-level classes just to make the file smaller. But most of them are so specific to their use in this program that they wouldn't really be useful outside this context. I'll probably do just that, but it's not clear to me that it makes the program more comprehensible.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2444#issuecomment-285411154:414,clear,clear,414,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2444#issuecomment-285411154,1,['clear'],['clear']
Usability,"One note that might be useful (or known already to the team): simply calling `cache()` doesn't cause any action. It seems that one might need to force the computation to be done on the RDD (e.g. `count()`), for caching to work, if the predicate depends on the results of computation. (ref last comment in #1877)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1811#issuecomment-225204823:62,simpl,simply,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1811#issuecomment-225204823,1,['simpl'],['simply']
Usability,"One of our goals for alpha (https://github.com/broadinstitute/gatk/issues/961) is actually to wrap `spark-submit` and its many options to make it easier to run hellbender tools on spark. We want users to be able to type a simple command like `./hellbender ToolName [toolArgs] --sparkMaster X`, and have hellbender figure out whether to invoke `spark-submit` or `gcloud dataproc` on their behalf, and provide sensible defaults for all relevant spark options. . Perhaps there is a way in `SparkCommandLineProgram` to detect whether an option has already been set externally, and allow the default to be overridden if it has been?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1070#issuecomment-152538633:222,simpl,simple,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1070#issuecomment-152538633,1,['simpl'],['simple']
Usability,"One very simple way to do this would be for `GenotypeGVCFs` to simply invoke `CombineGVCFs` directly upon initialization when multiple inputs are specified. We should consider doing this as a quick way of restoring this functionality, as several users have requested this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2584#issuecomment-381198194:9,simpl,simple,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2584#issuecomment-381198194,2,['simpl'],"['simple', 'simply']"
Usability,"Oops, did not realize that CRAM support required special treatment of the reference. This only needs to be added as an input to the CollectFragmentCounts task, then, correct? Why are the changes to the CreateReadCountPanelOfNormals task needed?. More generally, if we are aiming to support CRAMs passed via -I in all relevant GATKTools/walkers, then this is probably something that should be added to the WDL style guide. I guess it’d be overkill to make the reference required for these on the Java side.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4253#issuecomment-360359965:415,guid,guide,415,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4253#issuecomment-360359965,1,['guid'],['guide']
Usability,Opened https://github.com/broadinstitute/GATKZendesk/pull/2 to resurrect this old article (source: https://web.archive.org/web/20160415213604/https://www.broadinstitute.org/gatk/guide/article?id=1328). I updated the article text and command lines for the modern era.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8272#issuecomment-1502305330:178,guid,guide,178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8272#issuecomment-1502305330,1,['guid'],['guide']
Usability,"Or maybe I'm confused and the user can get either/or, based on the wdl? It wasn't very clear either way.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5889#issuecomment-484348592:87,clear,clear,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5889#issuecomment-484348592,1,['clear'],['clear']
Usability,"Overall this looks good to me. I've added a few comments inline. Note that I haven't reviewed for style particularly, or consistency with the existing codebase. > 5) There are unit tests for all code except for the skeleton itself. This could be as simple as a Spark variant of `ReadsPreprocessingPipelineIntegrationTest`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/850#issuecomment-134164842:249,simpl,simple,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/850#issuecomment-134164842,1,['simpl'],['simple']
Usability,"Overall, this looks fine, just a few minor comments. Two broader questions/issues:; - Does the test data exercise all of the code paths and edge cases?; - In general, putting the majority of testing in integration tests instead of unit tests is bad pattern. It have several bad consequences (1) it becomes less clear which cases are being tested (2) it's slower than just running unit tests and (3) it makes it unhelpful to (perhaps someday) move to a testing framework that only runs tests relevant to the code directly affected (because all integration tests must be run).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1013#issuecomment-149599490:311,clear,clear,311,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1013#issuecomment-149599490,1,['clear'],['clear']
Usability,"PR Punts:. - [ ] Profile and check whether interning of resource labels in the LabeledVariantAnnotationsWalker affects memory or runtime. Unfortunately, I can't remember why I added this, but maybe I had a good reason. See https://github.com/broadinstitute/gatk/pull/7954#discussion_r933375971.; - [ ] Consider writing allele-specific scores and/or different strategies for consolidating to a site-level score. The current strategy of simply taking allele with the max score (across SNPs/INDELs for mixed sites, to boot) is borrowed from ApplyVQSR. See https://github.com/broadinstitute/gatk/pull/7954#discussion_r933570228.; - [ ] Add behavior for dealing with mixed SNP/INDEL sites in separate passes (and note that the current WDL currently does this, to allow for the use of different annotations across SNPs and INDELs). This might include rescuing previously filtered sites, etc. (e.g., by using the option to ignore the first-pass filter in the second pass). Alternatively, one could use a different FILTER name in each pass, which downstream hard-filtering steps could utilize intelligently. Or one might just split multiallelics upstream. In any case, I would hope that we could move towards running both SNPs and INDELs in a single pass with the same annotations as the default mode of operation.; - [ ] Clean up borrowed code in the `VariantType` class for classifying sites as SNP or INDEL. We mostly retained the VQSR code and logic to make head-to-head comparisons easier. Note also that we converted some switch statements to conditionals, etc. (which I think was done properly, but maybe I missed an edge case). See https://github.com/broadinstitute/gatk/pull/7954#discussion_r934776584.; - [ ] Think more about how to treat empty HDF5 arrays. It's possible we should handle this at the WDL level with optional inputs/outputs. Likely only relevant for atypical edge cases. See https://github.com/broadinstitute/gatk/pull/7954#discussion_r934845337. Next steps:. - [ ] I'll update the B",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1209555008:435,simpl,simply,435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1209555008,1,['simpl'],['simply']
Usability,"Perhaps related to #7185. It is not clear to me why min or median would be options, rather than GenotypeGVCFs simply getting the actual correct DP from each sample's GVCF.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/9007#issuecomment-2420589421:36,clear,clear,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/9007#issuecomment-2420589421,2,"['clear', 'simpl']","['clear', 'simply']"
Usability,Pinging @tedsharpe who gave feedback on the above thread,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8557#issuecomment-1775300469:28,feedback,feedback,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8557#issuecomment-1775300469,1,['feedback'],['feedback']
Usability,Please make this option hidden if it's only being kept for testing purposes (and document clearly that that is the case). Users should not have access to options that are not expected to have value.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2231#issuecomment-316842338:90,clear,clearly,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2231#issuecomment-316842338,1,['clear'],['clearly']
Usability,"Posting at the suggetion of shlee. There's discussion about what parts of VariantEval will be ported to GATK4 or whether Picard's partially overlapping tool CollectVariantCallingMetrics will take this over. I want to at least make you aware that we've developed a tool we're calling VariantQC, which is built in GATK3 and runs VariantEval internally to generate data stratified in various ways to make HTML QC reports, sorta like FASTQC or MultiQC (https://github.com/bbimber/gatk-protected/releases). An example report is here: https://prime-seq.ohsu.edu/_webdav/Internal/Bimber/Public/%40files/VariantQC_Example.html. Our goal was always to port this to GATK4, polish it up, and then make it more generally available. Much of what this tool does is take the pre-built tables/reports from VariantEval and put them into HTML, but we also wrote some custom stratifications to bin data by filter, etc. Like this thread notes, VariantEval has a lot of features not in picard, and honestly we dont use many of them. However, the extensibility of Stratifier/VariantEvaluator are pretty important for us. . We realize this is prioritized against all the GATK4 features; however, 1) how set are plans about migration of VariantEval/merge w/ picard and 2) if most of VariantEval isnt going to be ported, can we pick it up in our repo? We could also potentially offer some assistance in porting the tool because we have a vested interest; however, unless the task is defined as porting VariantEval as close as possible to as-is (not that this is critical, but it's the simplest thing for the outsider to do), it would need some discussion around exactly what's planned.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/616#issuecomment-320737252:1560,simpl,simplest,1560,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/616#issuecomment-320737252,1,['simpl'],['simplest']
Usability,"Rationale for engine changes:; This tool opens a large number of feature files (TSVs, not VariantContexts) and iterates over them simultaneously. No querying, just a single pass through each.; Issue 1: When a feature file lives in the cloud, it takes unacceptably long (several seconds, typically) to initialize it. A few seconds doesn't seem like a long time, but when there are large numbers of feature files to open, it adds up. This is caused by a large number of codecs (mostly the vcf-processing codecs) opening and reading the first few bytes of the file in the canDecode method. To avoid this I've reversed the order in which we test each codec, checking first if it produces the correct subtype of Feature, and only then calling canDecode. If you don't know what specific subtype you need, you can just ask for any Feature by passing Feature.class. It's much faster that way.; Issue 2: Each open feature source soaks up a huge amount of memory. That's because text-based feature reading is optimized for VCFs, which can have enormously long lines. So huge buffers are allocated. The problem is compounded for cloud-based feature files for which we allocate a large cloud prefetch buffer. (Though that feature can be turned off, which helps a little.) But the biggest memory hog is the TabixReader, which always reads in the index, regardless of whether it's used or not. Tabix indices are very large. To avoid this, I've created a smaller, simpler FeatureReader subclass called a TextFeatureReader that loads the index only when necessary. The revisions allow the new tool to run using an order of magnitude less memory. Faster, too.; Issue 3: The code in FeatureDataSource that creates a FeatureReader is brittle, and tests for various subclasses. To allow use of the new TextFeatureReader, I added a FeatureReaderFactory interface that allows one to ask the codec for an appropriate FeatureReader.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8031#issuecomment-1284340770:1449,simpl,simpler,1449,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8031#issuecomment-1284340770,1,['simpl'],['simpler']
Usability,"Re-assigning to @tomwhite as a possible future project, since he has a clear idea of how this could be implemented.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1644#issuecomment-288515251:71,clear,clear,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1644#issuecomment-288515251,1,['clear'],['clear']
Usability,Re-runs with PR feedback incorporated:. - [Integration](https://app.terra.bio/#workspaces/gvs-dev/mlc%20GVS%20Quickstart%203%20samples/job_history/e8b6077d-a90a-4cc2-be0d-0a08cb98280a); - [Beta](https://app.terra.bio/#workspaces/gvs-dev/mlc%20GVS%20Quickstart%203%20samples/job_history/52a3c02e-485b-4320-bb21-07931ecbe7dd),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1632980023:16,feedback,feedback,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1632980023,1,['feedback'],['feedback']
Usability,Re-worded the title and description to make it clear that the call in question is happening in the constructor for `GenomicsDBImporter` (`GenomicsDBImporter` line 464),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2714#issuecomment-301542931:47,clear,clear,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2714#issuecomment-301542931,1,['clear'],['clear']
Usability,"Ready for second pass review, @lbergelson. Now the implementation is much more simple than the previous one, and I added unit tests for the codec.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1862#issuecomment-224670233:79,simpl,simple,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1862#issuecomment-224670233,1,['simpl'],['simple']
Usability,"Regarding the non-Docker integration tests failing earlier today, I think this was because the R packages were added to the Travis cache in #3101. @cmnbroad cleared the cache to see if we could reproduce a compiler error introduced in #3934 on Travis (for the record, we could reproduce it on my local Ubuntu machine and gsa5, but not on Travis). This removed the cached getopt dependency, which then caused tests to fail. See #4246.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441:157,clear,cleared,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441,1,['clear'],['cleared']
Usability,"Removed the `splitContextByReadGroup()`, simplified methods and testing exception thrown by `splitBySample()`. Back to you for review again, @akiezun.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1774#issuecomment-219648141:41,simpl,simplified,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1774#issuecomment-219648141,1,['simpl'],['simplified']
Usability,"Reopening. It was hard to see due to the in-house cluster being used by multiple people. On a private cluster on GSC, the difference is clear - MarkDuplicatesSpark goes from 7.4 minutes to 6.6-6.7 minutes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1702#issuecomment-212155764:136,clear,clear,136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1702#issuecomment-212155764,1,['clear'],['clear']
Usability,Requested guidance (in a different ticket) on how this works when running locally.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3334#issuecomment-353612077:10,guid,guidance,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3334#issuecomment-353612077,1,['guid'],['guidance']
Usability,"Results are in:. Using the branch for PR #4971 with the value `ALIGNMENT_LOW_READ_UNIQUENESS_THRESHOLD` set to 10 and 19, while keeping the gap split children together (that is, method ; `private static GoodAndBadMappings splitGaps(final GoodAndBadMappings configuration, final boolean keepSplitChildrenTogether)` is called with `false` for its second parameter). Here are the comparisons:; ```; simple variants unique TP unique FP; size-10 filter: 10756 24 101; size-19 filter: 10755 1 0; ```. So I think your suggestion is a better trade off!. What I'll do is make that parameter an (advanced) CLI argument in PR #4971 , and experiment more to settle on a good default value.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4962#issuecomment-403890890:396,simpl,simple,396,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4962#issuecomment-403890890,1,['simpl'],['simple']
Usability,"Returning false instead of throwing when data is missing in the `GoogleGenomicsReadToGATKReadAdapter` is misleading -- we don't know the answer to the question the client is asking in such cases, so returning false is not correct behavior. If these fields are actually missing in the underlying reads we really do want to blow up with an exception on access, as it means the read object is not usable by us (and the query that produced these incomplete objects likely needs to be modified). Could you restore the previous versions of these methods (`isSecondaryAlignment()`, `isDuplicate()`, etc.) before I review?. As for the Google read converters, could you open a separate ticket with your description of the inconsistencies so we can decide whether to submit a patch?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/871#issuecomment-136771148:394,usab,usable,394,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/871#issuecomment-136771148,1,['usab'],['usable']
Usability,"Right @sooheelee, the template is certainly useful for that, but can just as easily be generated using `wdltool inputs`. Whatever you and @davidbenjamin decide, let me know if I should add the CNV templates back to be consistent. (But again, my vote is for removing the M2 template!). @LeeTL1220 can add whatever we decide about optional string type args to the style guide, but I'd prefer for this sort of thing to be automatically generated (#2480).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358438099:368,guid,guide,368,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358438099,1,['guid'],['guide']
Usability,"Rlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...6737d16d1f0749554cafe9f8cf869fac1fcede0c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...6737d16d1f0749554cafe9f8cf869fac1fcede0c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `77.6% <0%> (-9.6%)` | `28% <0%> (-8%)` | |; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...6737d16d1f0749554cafe9f8cf869fac1fcede0c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `70.946% <0%> (-6.757%)` | `18% <0%> (-4%)` | |; | ... and [4 more](https://codecov.io/gh/broadinstitute/gatk/pull/2433?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2433?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2433?src=pr&el=footer). Last update [92cb860...6737d16](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...6737d16d1f0749554cafe9f8cf869fac1fcede0c?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2433#issuecomment-283613034:4906,learn,learn,4906,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2433#issuecomment-283613034,1,['learn'],['learn']
Usability,"Rlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...f539662b2a136507a34ea2da64e0445d6df3469d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...f539662b2a136507a34ea2da64e0445d6df3469d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `77.6% <0%> (-9.6%)` | `28% <0%> (-8%)` | |; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...f539662b2a136507a34ea2da64e0445d6df3469d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `70.946% <0%> (-6.757%)` | `18% <0%> (-4%)` | |; | ... and [4 more](https://codecov.io/gh/broadinstitute/gatk/pull/2455?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2455?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2455?src=pr&el=footer). Last update [dfa9cf1...f539662](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...f539662b2a136507a34ea2da64e0445d6df3469d?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2455#issuecomment-285859315:4871,learn,learn,4871,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2455#issuecomment-285859315,1,['learn'],['learn']
Usability,"RpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvRXhhY3RBRkNhbGN1bGF0b3IuamF2YQ==) | `89.474% <0%> (-0.526%)` | `8% <0%> (+5%)` | |; | [...stitute/hellbender/utils/collections/CountSet.java](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb2xsZWN0aW9ucy9Db3VudFNldC5qYXZh) | `31.21% <0%> (-0.403%)` | `22% <0%> (ø)` | |; | [.../hellbender/tools/walkers/annotator/ExcessHet.java](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9FeGNlc3NIZXQuamF2YQ==) | `98.198% <0%> (-0.393%)` | `25% <0%> (+3%)` | |; | [...gine/spark/AddContextDataToReadSparkOptimized.java](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvQWRkQ29udGV4dERhdGFUb1JlYWRTcGFya09wdGltaXplZC5qYXZh) | `0% <0%> (ø)` | `0% <0%> (ø)` | :arrow_down: |; | [...ellbender/tools/spark/sv/GATKSVVCFHeaderLines.java](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9HQVRLU1ZWQ0ZIZWFkZXJMaW5lcy5qYXZh) | `0% <0%> (ø)` | `0% <0%> (ø)` | :arrow_down: |; | ... and [92 more](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=footer). Last update [e7c90f1...08af964](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2447#issuecomment-285197333:4140,learn,learn,4140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2447#issuecomment-285197333,1,['learn'],['learn']
Usability,"RpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmtFbmdpbmUuamF2YQ==) | `82.857% <59.091%> (-6.234%)` | `6 <3> (+1)` | |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmsuamF2YQ==) | `66.667% <60%> (ø)` | `5 <1> (+1)` | :arrow_up: |; | [...e/hellbender/engine/filters/ReadFilterLibrary.java](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9SZWFkRmlsdGVyTGlicmFyeS5qYXZh) | `94.048% <66.667%> (ø)` | `1 <0> (ø)` | :arrow_down: |; | [...der/tools/walkers/annotator/RMSMappingQuality.java](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9STVNNYXBwaW5nUXVhbGl0eS5qYXZh) | `98.413% <0%> (-1.587%)` | `34% <0%> (+20%)` | |; | [...ls/walkers/genotyper/afcalc/ExactAFCalculator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvRXhhY3RBRkNhbGN1bGF0b3IuamF2YQ==) | `89.474% <0%> (-0.526%)` | `9% <0%> (+6%)` | |; | ... and [18 more](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=footer). Last update [88c181d...6a33314](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2494#issuecomment-287889612:4128,learn,learn,4128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2494#issuecomment-287889612,1,['learn'],['learn']
Usability,"Running a particular bam sort takes ~20minutes with hdd and 16 minutes with ssd. So it's definitely being used somehow. It looks like spark.local.dir is over ridden by the environment variable LOCAL_DIRS, and I don't see that set, but it's possible it's being set but not recorded correctly in the UI or something like that. Someone will need to poke at a bit more to be more clear about what's happening.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2426#issuecomment-283481370:376,clear,clear,376,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2426#issuecomment-283481370,1,['clear'],['clear']
Usability,"S9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvRXhhY3RBRkNhbGN1bGF0b3IuamF2YQ==) | `89.474% <0%> (-0.526%)` | `8% <0%> (+5%)` | |; | [...stitute/hellbender/utils/collections/CountSet.java](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb2xsZWN0aW9ucy9Db3VudFNldC5qYXZh) | `31.21% <0%> (-0.403%)` | `22% <0%> (ø)` | |; | [.../hellbender/tools/walkers/annotator/ExcessHet.java](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9FeGNlc3NIZXQuamF2YQ==) | `98.198% <0%> (-0.393%)` | `25% <0%> (+3%)` | |; | [...roadinstitute/hellbender/utils/GenotypeCounts.java](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vdHlwZUNvdW50cy5qYXZh) | `100% <0%> (ø)` | `7% <0%> (+3%)` | :arrow_up: |; | [...ols/walkers/genotyper/MinimalGenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9NaW5pbWFsR2Vub3R5cGluZ0VuZ2luZS5qYXZh) | `27.273% <0%> (ø)` | `4% <0%> (+1%)` | :arrow_up: |; | ... and [58 more](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=footer). Last update [724fbd0...a163be6](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2506#issuecomment-288240771:4125,learn,learn,4125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2506#issuecomment-288240771,1,['learn'],['learn']
Usability,"S9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQmFzZVF1YWxpdHlDbGlwUmVhZFRyYW5zZm9ybWVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-14%)` | |; | [...llbender/tools/walkers/annotator/TandemRepeat.java](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...6b3c7a9b6d6dfb45fc64613bccf1a74e85a374fe?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9UYW5kZW1SZXBlYXQuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-5%)` | |; | [...oadinstitute/hellbender/tools/spark/sv/SvType.java](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...6b3c7a9b6d6dfb45fc64613bccf1a74e85a374fe?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdlR5cGUuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-5%)` | |; | [...tute/hellbender/metrics/SAMRecordAndReference.java](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...6b3c7a9b6d6dfb45fc64613bccf1a74e85a374fe?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9tZXRyaWNzL1NBTVJlY29yZEFuZFJlZmVyZW5jZS5qYXZh) | `0% <0%> (-100%)` | `0% <0%> (-3%)` | |; | ... and [430 more](https://codecov.io/gh/broadinstitute/gatk/pull/2510?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2510?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2510?src=pr&el=footer). Last update [724fbd0...6b3c7a9](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...6b3c7a9b6d6dfb45fc64613bccf1a74e85a374fe?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2510#issuecomment-288256519:4925,learn,learn,4925,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2510#issuecomment-288256519,1,['learn'],['learn']
Usability,"S9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyLmphdmE=) | `17% <0%> (-52.5%)` | `9% <0%> (-30%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5291/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5291/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `58.53% <0%> (-23.18%)` | `33% <0%> (-9%)` | |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/5291/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `77.08% <0%> (-3.13%)` | `31% <0%> (ø)` | |; | [...adinstitute/hellbender/engine/ReadsDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/5291/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZHNEYXRhU291cmNlLmphdmE=) | `89.39% <0%> (-3.04%)` | `61% <0%> (-2%)` | |; | ... and [25 more](https://codecov.io/gh/broadinstitute/gatk/pull/5291/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5291?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5291?src=pr&el=footer). Last update [626c887...a1e13fc](https://codecov.io/gh/broadinstitute/gatk/pull/5291?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-437412464:4416,learn,learn,4416,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-437412464,1,['learn'],['learn']
Usability,"ScoreVariantAnnotations:. Scores variant calls in a VCF file based on site-level annotations using a previously trained model. TODOs:. - [x] Integration tests. Exact-match tests for (non-exhaustive) configurations given by the Cartesian product of the following options:; * Java Bayesian Gaussian Mixture Model (BGMM) backend vs. python sklearn IsolationForest backend; (BGMM tests to be added once PR for the backend goes in.); * non-allele-specific vs. allele-specific; * SNP-only vs. SNP+INDEL (for both of these options, we use trained models that contain both SNP and INDEL scorers as input) ; - [x] Tool-level docs. Minor TODOs:. - [x] Parameter-level docs.; - [x] Parameter/mode validation.; - [x] Double check or add behavior for handling previously filtered input, clearing present filters, etc. Future work:. - [ ] The `score_samples` method of the sklearn IsolationForest is single-threaded. See (possibly stalled) PR at https://github.com/scikit-learn/scikit-learn/pull/14001 and some workarounds using e.g. `multiprocessing` ibid.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948563:774,clear,clearing,774,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948563,3,"['clear', 'learn']","['clearing', 'learn']"
Usability,See my minor correction/suggestion. Should follow up with a task to explain the two-repo structure clearly.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1207#issuecomment-160844574:99,clear,clearly,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1207#issuecomment-160844574,1,['clear'],['clearly']
Usability,"See some of my findings about numerical differences across 8/11/17 and possible causes in this old Slack thread: https://broadinstitute.slack.com/archives/C1HH1V5EC/p1657634295565369 We’re starting to get into some relatively hairy issues there, IMO!. But just in case it wasn’t clear: 1) None of these numerical differences should be scientifically concerning in the end, and 2) I think we still have numerical reproducibility within each fixed Java version (although if we happen to see any evidence to the contrary, please point to them here). So I don’t think we have too much to worry about once the test infrastructure settles.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8111#issuecomment-1331407680:279,clear,clear,279,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8111#issuecomment-1331407680,1,['clear'],['clear']
Usability,Seems like something like https://github.com/broadinstitute/gatk/issues/4794 could be avoided if we rewrote this. It seems like a pretty simple rewrite too...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4535#issuecomment-391044481:137,simpl,simple,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4535#issuecomment-391044481,1,['simpl'],['simple']
Usability,"ServletContextHandler@50f4b83d{/jobs/job/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@5d66ae3a{/jobs/job,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@30159886{/jobs/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@33de7f3d{/jobs,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO ui.SparkUI: Stopped Spark web UI at http://10.48.225.55:4041; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 18/03/07 20:32:55 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 18/03/07 20:32:55 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Stopped; 18/03/07 20:32:55 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/03/07 20:32:55 INFO memory.MemoryStore: MemoryStore cleared; 18/03/07 20:32:55 INFO storage.BlockManager: BlockManager stopped; 18/03/07 20:32:55 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/03/07 20:32:55 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/03/07 20:32:55 INFO spark.SparkContext: Successfully stopped SparkContext; 20:32:55.769 INFO FlagStatSpark - Shutting down engine; [March 7, 2018 8:32:55 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.FlagStatSpark done. Elapsed time: 1.60 minutes.; Runtime.totalMemory()=2091384832; 18/03/07 20:32:55 INFO util.ShutdownHookManager: Shutdown hook called; 18/03/07 20:32:55 INFO util.ShutdownHookManager: Deleting directory /tmp/farrell/spark-9e0f0525-00f3-4b37-b1d2-4cf55b4c8cb0. real 1m41.113s; user 0m49.698s; sys 0m4.432s. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:13258,clear,cleared,13258,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,1,['clear'],['cleared']
Usability,"Should I follow the existing convention of using UserException for user errors and GATKException for everything else that doesn't clearly fall under a standard exception type?. The alternative would be to port PicardException, which we decided not to do IIRC.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/73#issuecomment-69978719:130,clear,clearly,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/73#issuecomment-69978719,1,['clear'],['clearly']
Usability,Should have clear instructions in README on how to use the docs system from another project (likely via one's build file).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2209#issuecomment-253618941:12,clear,clear,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2209#issuecomment-253618941,1,['clear'],['clear']
Usability,Since the intent and implementation of this filter are not essential to my work -- I can simply filter pairs on TLEN prior to variant calling -- perhaps it's best to just let this one be. Thanks for the discussion and for helping me think things through.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7701#issuecomment-1105639777:89,simpl,simply,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7701#issuecomment-1105639777,1,['simpl'],['simply']
Usability,"Since the simple fix is merged for now, can we close this ticket and open a new one if the speed ends up being a problem?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1865#issuecomment-226005625:10,simpl,simple,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1865#issuecomment-226005625,1,['simpl'],['simple']
Usability,"Since we never actually look to see if something IS an optical duplicate and only care about the total number, we could just output a single annotation on one read in the best read pair with the number of optical duplicates found for that set of reads. It would make the code simpler but maybe not make as much sense logically?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/749#issuecomment-126755071:276,simpl,simpler,276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/749#issuecomment-126755071,1,['simpl'],['simpler']
Usability,"Since you asked, I have a couple of thoughts:. First, I don't know if allowing the SAMRecord header to be set to null ; something that was intended to be widely used, or whether it was an ; oversight in the API or done to solve some particular corner case. If ; many SAMRecord methods appear to be broken if the header is null, then ; perhaps this isn't something that was intended for wide use. Second, it sounds like the suggestion is that headerless SAMRecords ; would now be widely used, and thus a common thing that people writing ; code against htsjdk need to anticipate.; So if you go this way you should update the SAMRecord documentation to ; clearly indicate that SAMRecords can be in either a headerless or ; non-headerless (headerful?) state; and indicate how each API function is affected by this. If certain ; methods behave differently, then people writing code against SAMRecord ; need to anticipate this; and existing code may need to be updated. In other words, headerless ; SAMRecords should become ""part of the spec"". Third, although I don't know in detail about the different execution ; environments you are trying to support, there is a general strategy that ; I haven't seen discussed in these threads.; Perhaps it's impractical, but I'll mention it anyway. It seems like ; another approach would be to create (internal to the implementation) a ; ""header tag"" that could be efficiently serialized; and passed as part of the SAMRecord when you need to distribute it. The ; header tag could be used by the receiver to reattach the SAMRecord to ; its header (either proactively or on demand), but transparently to ; application code that is running against the SAMRecord API.; This would allow SAM headers to be transmitted out-of-band in a way that ; depends on the execution environment. Depending on the environment, ; this might be done by proactive broadcast, or you could think of the ; header tag as a promise to retrieve the header if/when it is needed. ; The size and com",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141451518:652,clear,clearly,652,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141451518,1,['clear'],['clearly']
Usability,"So behavior when disabled (parameter set to 0) and when set to 2 or above gives the same results for my data where smoothing iterations you say plateau at two iterations. When set to 1, the smoothing iterations increase to seven and this is the only other alternative result one can expect for this data. It is somewhat counter-intuitive. But given @samuelklee says this is the expected behavior for this parameter, then I can close this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4683#issuecomment-382863906:328,intuit,intuitive,328,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4683#issuecomment-382863906,1,['intuit'],['intuitive']
Usability,"So the long term timeline is fairly up in the air. You can check out the alpha and beta milestones for some idea of what's been prioritized. Alpha milestone is due for completion ~this week. Beta is much more up in the air and will depend at least in part on feedback from user. . Incidentally, if you're interested in CNV calling take a look at https://github.com/broadinstitute/gatk-protected/ which has some tools for CNV calling built on this engine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1198#issuecomment-160717606:259,feedback,feedback,259,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1198#issuecomment-160717606,1,['feedback'],['feedback']
Usability,"So, I tried this out and it's harder than it seems. Some calls get better, some get worse. There probably exists a simple set of heuristics to make reasonable alignments, but I don't think that it can be represented as a single set of SW parameters. We might need to have some kind post-processing to judge whether a better alignment than the Smith-Waterman one exists.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-489654799:115,simpl,simple,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-489654799,1,['simpl'],['simple']
Usability,"Some clarification questions about the field AS_RAW_MQ. In the examples provided, the header line corresponding to this field is. ##INFO=<ID=AS_RAW_MQ,Number=A,Type=Float,Description=""Allele-specfic raw data for RMS Mapping Quality"">. The data lines contain entries similar to `AS_RAW_MQ=123769.00|3600.00|46800.00|0.00`. Is the AS_RAW_MQ field simply a vector of float?; - If yes; - Why is the '|' used as the delimiter? Why not simply use ','?; - Based on the entries, shouldn't the Number descriptor in the header line be 'R' instead of 'A'; - If no, i.e. AS_RAW_MQ can be a vector of vector of float (entries such as `AS_RAW_MQ=1,2|3,4,5|6|0.00` where `[1, 2]` corresponds to allele 0 (reference allele) etc.); - Shouldn't the Type descriptor in the header line be 'String' instead of 'Float'? (similar to the AS_RAW_\*RankSum fields)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355638919:345,simpl,simply,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355638919,2,['simpl'],['simply']
Usability,"Some comments/questions for the review:; - I'll add a separate ticket to rewrite the integration tests, all of which pass and most of which are disabled since they require access to large files on the broad file system. In the meantime I need to add a couple of small tests to get the coverage back up, and would like to get the CR process started.; - I ported a bunch of support files but need feedback on whether they're in the right location.; - Somewhere I saw something that said GATK no longer supports .ped files ? If not, what should the replacement be in the tests require pedigree input?; - Is it a requirement to support Ploidy > 2 ? The current GATK tool, and thus the HB tool, do not; - I did not port the WalkerTestSpec.disableShadowVCF? Is that needed in Hellbender ?; - Are there other headers I should be applying to the output variant file ?. Command Line Arguments:; - I didn't port the GATK command line argument ""-no_cmd_line_in_header"". Should I ? And if not, should the command line args automatically be propagated to the output vcf file ? I didn't see GATK do this anywhere.; - There was one test that used --variant:dbsnp on the command line but I couldn't find the code that processed that in GATK, not sure what the means on the command line.; - I replaced ""-U LENIENT_VCF_PROCESSING"" with ""--lenient"" (testFileWithoutInfoLineInHeaderWithOverride needs this to pass).; - I replaced ""-L"" with --interval since HB seems to use -L for ""lane"" ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/792#issuecomment-128798027:395,feedback,feedback,395,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/792#issuecomment-128798027,1,['feedback'],['feedback']
Usability,"Some of the categories we are removing are still in the HelpConstants, e.g. DOC_CAT_SPARK*.; --> learned on purpose otherwise code breaks. Will be removed at later time. Here's that spreadsheet again. It's the fourth tab `categories_summaries`: https://docs.google.com/a/broadinstitute.org/spreadsheets/d/19SvP6DHyXewm8Cd47WsM3NUku_czP2rkh4L_6fd-Nac/edit?usp=sharing. I see two place holders for Picard, ReadProgramGroup and VariantProgramGroup. Are these for those categories only in Picard? Because then there is only one such category and it is the `Base Calling` category.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3924#issuecomment-349699185:97,learn,learned,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3924#issuecomment-349699185,1,['learn'],['learned']
Usability,"Some offline discussions have led us to the conclusion that this is best handled by tools upstream. Adapters should not be simply soft-clipped, so it shouldn't be the responsibility of M2 or HC to include logic to remove adapters.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6346#issuecomment-575334816:123,simpl,simply,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6346#issuecomment-575334816,1,['simpl'],['simply']
Usability,Something is discussed in the style guide about NIO.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4806#issuecomment-391724103:36,guid,guide,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4806#issuecomment-391724103,1,['guid'],['guide']
Usability,"Sorry @droazen, the previous commit had an error in the tests. I'm rebasing/squashing to make a clear PR and when all check pass (except CLOUD), you can review if you have time. Thank you very much.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-246346004:96,clear,clear,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-246346004,1,['clear'],['clear']
Usability,Sorry that sentence was not clear at all. I meant I am using an additional locus based caller in order not to miss those variants missed by haplotypecaller padding issue. I want to drop that duct tape solution from my workflows completely.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-379801534:28,clear,clear,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-379801534,1,['clear'],['clear']
Usability,"Sorry, I know this is old, but i'm currently dealing with this exact issue using `gatk-4.beta.5`. It sounds like this has been solved, but the solution isn't clear to me. . EDIT: Perhaps an upgrade to 4.1 will solve this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2944#issuecomment-474483603:158,clear,clear,158,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2944#issuecomment-474483603,1,['clear'],['clear']
Usability,"Sorry, I wasn't very clear: Spark doesn't return the user exception to the driver even as the 'cause' exception (only the exception message is preserved). So it won't be possible to do the unwrapping in the same way at the moment. I agree that #551 will help catch regressions.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/574#issuecomment-113196502:21,clear,clear,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/574#issuecomment-113196502,1,['clear'],['clear']
Usability,"Sorry, but this bug still isn't fixed as of v4.2.6.1. Reproduce as follows:. ```; --read-filter MateDistantReadFilter; --mate-too-distant-length 1500; ```. Instead of a run-time exception (as in v4.2.5.0), HaplotypeCaller simply produces no variant calls at all. Expected behavior would be to exclude paired-end mappings whose TLEN exceeds the parameterized value. Perhaps there is an implementation bug, unrelated to the original problem, that contains faulty logic for doing this. Thanks...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7701#issuecomment-1102943692:222,simpl,simply,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7701#issuecomment-1102943692,1,['simpl'],['simply']
Usability,"Sorry, just saw this now. We still don't have a simple solution for training models without pysam. We can probably do something similar to what we do with inference, but I think the current priority is to improve inference throughput so it will probably be a little while before we get to re-writing the training code. If people feel we should re-prioritize please let me know.; I have installed the conda environment on the same OSX version, without seeing this issue.; Which gcc version are you using @mwalker174 ? ; My `gcc -v` output is:; ```; Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/usr/include/c++/4.2.1; Apple LLVM version 8.0.0 (clang-800.0.42.1); Target: x86_64-apple-darwin15.6.0; Thread model: posix; InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4742#issuecomment-391014193:48,simpl,simple,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4742#issuecomment-391014193,1,['simpl'],['simple']
Usability,"Sorry, just seeing this now. ; I'm mainly looking at the sample output and it looks great!! I can't find anything wrong with it but here are some suggestions for improvement; - If its too late now maybe for later it would be nice to add a runtime block for each task so that it would executable in a cloud environment. ; - Why have inputs declared at a workflow level input block (which requires them to be repeated in the call block, and again at the task input block) when they can be declared simply at the task level?; - If it's an easy fix it would be nice to see the full parameter name instead of abbreviation for input and output (e.g. ""I"", ""O"")",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6504#issuecomment-611039729:496,simpl,simply,496,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6504#issuecomment-611039729,1,['simpl'],['simply']
Usability,"Sorry, perhaps I wasn't clear. The bamout not only output the read records realigned to the reference (thru their alignment to te best haplotype) but also the haplotype themselves as reads records. I'm not 100% sure of this is true for your run but these special records probably have a sample name ""HC"" and as read id something like ""HCXXXXXXX"" where XXXXXXX is a number. . My hope was that by grouping by sample the haplotypes would stand out and that we could then verify what haplotypes were reconstructed. . My suspicion is that haplotype with no C mutation but with downstream mutation has not be reconstructed.. You need to identify the complete list of reconstructed haplotypes to confirm that, either by grouping somehow haplotypes away from the actual reads in the bamout or perhaps looking into HaplotypeCaller's debugging output. If that is true, what is happening is that reads that contain the downstream mutation would artifactually have support for the C mutation even if the have a ref base for that position or if they don't even overlap that position. So if this is confirmed, the following step would be to figure out why this is happening (not reconstructing that obvious haplotype) and fix the issue. Hopefully someone in the GATK developer team can look into this as you may well have hit an interesting edge case that needs to be ironed out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8238#issuecomment-1483076912:24,clear,clear,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8238#issuecomment-1483076912,1,['clear'],['clear']
Usability,"Sounds good. Thanks,; Chuck. > On Mar 18, 2017, at 06:33, Geraldine Van der Auwera <notifications@github.com> wrote:; > ; > Hi Chuck, the GATK blog is set up to only accept posts from admins or moderators on the forum (or my team). If you're willing to write something up, we would do it as a guest post, where I would post the text on your behalf (with clear attribution to you). If you'd like to share a draft with us the easiest way to do it is through a google doc.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/269#issuecomment-287551239:354,clear,clear,354,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/269#issuecomment-287551239,1,['clear'],['clear']
Usability,"Status as of PR #4238:. ## Remaining wants; - Outputs should allow either .vcf or .vcf.gz compression by user-specification. Alternatively, if we want to keep it simple and hardcode, then the preference is for compressed files. Some of us prefer to save on storage.; - The version of Oncotator is not compatible with GRCh38. Please, can we have an option to switch this out with Funcotator?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360209849:162,simpl,simple,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360209849,1,['simpl'],['simple']
Usability,"Still working on my review but just wanted to respond to a couple of @davidbenjamin 's points:. - Agree that we should get rid of the hard coded paths (and I think most of those resources should live with the reference bundle rather than in GATK resources anyway). Already discussed this with @TedBrookings in person.; - IMO iterators are fine and are still idiomatic Java. Often we do have very large collections that we want to iterate over online, or at least without having to know how they are represented in the calling code. Spark APIs often return or provide iterators and using them lets you port code easily between working on RDDs and working on in memory collections. Also iterators give you the option to implement `remove` which is often important and useful. Of course, they are a little heavier than streams for simple use cases, so it's a tradeoff on whether you think the extra functionality / flexibility is useful.; - `Tuple2` and the other tuple Scala classes are used in the Java Spark API extensively and therefore is in a lot of our code, it's fine to use.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-389898045:828,simpl,simple,828,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-389898045,1,['simpl'],['simple']
Usability,Sure. But we'll probably need to use some simpler stylesheets than what the website uses.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2769#issuecomment-309642761:42,simpl,simpler,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2769#issuecomment-309642761,1,['simpl'],['simpler']
Usability,"TableReader is a dumb-dumb one-record at a time reader so it shouldn't suffer from memory leaks. . In contrast the parser() method uses a incremental ""buffer"" that accumulates the counts until the end when the actual returned table is created... The reason for this is to keep the ReadCountsCollection class constant. So at some point you need at least twice the amount of memory as compare to a solution that would simply use the returned object as the accumulator.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-316479500:416,simpl,simply,416,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-316479500,1,['simpl'],['simply']
Usability,Tell me about it :). Biggest support burden of upping the java version was due to Apple making it hard to seamlessly upgrade the java version. Users themselves didn't care all that much as long as the requirements were clear. . So far we've been lucky that no other major tool seems to dictate which version of java users should have on their machine. Otherwise collisions could happen.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/9#issuecomment-66529138:219,clear,clear,219,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/9#issuecomment-66529138,1,['clear'],['clear']
Usability,Test runs after PR feedback-based changes:. - Sample run with interval of 5k lines: https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/8ac48d8a-f2ca-4cef-bc10-271d3503d607; - Sample run with interval of 10k lines (it determined that this was too many intervals and just ran for all): https://app.terra.bio/#workspaces/gvs-dev/RSA%20-%20GVS%20Quickstart%20V2%20/job_history/b6189b51-fa16-46c2-953c-4571045eae34,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8666#issuecomment-1917906310:19,feedback,feedback-based,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8666#issuecomment-1917906310,1,['feedback'],['feedback-based']
Usability,Tests are passing using a snapshot generated while debugging https://github.com/broadinstitute/picard/pull/1904. Folks can review and give feedback. Perhaps we shouldn't merge though unless referencing a library SNAPSHOT is ok or picard 3.0.1 is released.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1655703824:139,feedback,feedback,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1655703824,1,['feedback'],['feedback']
Usability,"Tests with `TEST_DOCKER = true` failed, I'm not entirely clear why. Here's a bit of the log:. > Building 85% > :test > Resolving dependencies ':jacocoAgent'aven.org/maven2/org/jacoco/org.jacoco.agent/0.7.7.201606060606/org.jacoco.agent-0.7.7.201606060606.jar; > Building 85% > :test > 207 KB/233 KB downloaded> Building 85% > :test > 0 tests completed> Resolving dependencies ':testRuntime':test FAILED",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367:57,clear,clear,57,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367,1,['clear'],['clear']
Usability,"Thank you @SHuang-Broad, this confirms the problem: the ""convention"" has been changed so NIO's special casing needs to be adjusted to the new reality of what sort of files are created to make fake directories. In the meantime, the workaround is clear: if a tool offers to create directories in Google cloud, gently decline. It's not necessary and in some cases (like here), creates problems.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5935#issuecomment-492827551:245,clear,clear,245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5935#issuecomment-492827551,1,['clear'],['clear']
Usability,Thank you @chen42. Looking at the exception it looks like it is another issue with a seperate tool (GenotypeGVCFs as opposed to CombineGVCFs). This is clearly a seperate issue and I have created an issue to track it #6357. It would be helpful to get a snippet of the beginning of your input bam `/lustre/haven/proj/UTHSC0013/Tristan_GATK//gvcf//merged//joint_called_gvcfs_chr7.vcf` in order evaluate what is happening. Here are some instructions for sharing files: https://software.broadinstitute.org/gatk/guide/article?id=1894.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6340#issuecomment-572128609:151,clear,clearly,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6340#issuecomment-572128609,2,"['clear', 'guid']","['clearly', 'guide']"
Usability,"Thank you @cmnbroad .; > Java 17 uses strict floating point math by default. ; I didn't know this. I learned a lot. I downloaded and built gatk-4.4.0.0.; I realized that Log10Cache.java is not in gatk-4.4.0.0 but is in 4.3.0.0. In gatk-4.4.0.0, log10 value is calculated by Math.log10 directory.; Thus, I modified computeLogPenaltyScore in kBestHaplotype.java from Math.log10 to StrictMath.log10. I compared variant call results of original or modified to StrictMath class log10. ```; public static double computeLogPenaltyScore(int edgeMultiplicity, int totalOutgoingMultiplicity) {; // return Math.log10(edgeMultiplicity) - Math.log10(totalOutgoingMultiplicity);; return StrictMath.log10(edgeMultiplicity) - StrictMath.log10(totalOutgoingMultiplicity);; }; ```. Original gatk-4.4.0.0 and gatk-4.4.0.0 modified ver. from Math to StrictMath OpenJDK-17.0.6+10 output different results with this link bam ( https://pezycomputing-my.sharepoint.com/:f:/g/personal/sakai_pezy_co_jp/Eo5Gvfau1BpMszGCcfDrD14BOfMgxvk7Mt2JCFqcDfgItQ?e=wzZbpL ).; Same as gatk-4.3.0.0 openjdk-1.8.0; I previously examined Math.log10 output different result from StrictMath.log10 on x64 CPU but same result on arm CPU with following code. ```; import java.util.*;. public class log10_check {; public static void main(String[] args){; int n = 100;; for (int i = 2; i < n; ++i){; if (Math.log10(i) != StrictMath.log10(i)) {; System.out.printf(""i = %d, %20.16f, %20.16f\n"", i, Math.log10(i), StrictMath.log10(i));; } ; }; }; }; ```. Output on x64 CPU. On arm CPU, no output.; ```; i = 11, 1.0413926851582251, 1.0413926851582250; i = 40, 1.6020599913279623, 1.6020599913279625; i = 43, 1.6334684555795864, 1.6334684555795866; i = 52, 1.7160033436347992, 1.7160033436347990; i = 53, 1.7242758696007890, 1.7242758696007892; i = 85, 1.9294189257142926, 1.9294189257142929; i = 90, 1.9542425094393250, 1.9542425094393248; i = 92, 1.9637878273455553, 1.9637878273455551; i = 93, 1.9684829485539350, 1.9684829485539352; ```. Thus, gatk-4.4",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8338#issuecomment-1560470696:101,learn,learned,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8338#issuecomment-1560470696,1,['learn'],['learned']
Usability,Thank you @lbergelson for the fix! For once a dependency conflict that turns out to be simple!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-841279259:87,simpl,simple,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7203#issuecomment-841279259,1,['simpl'],['simple']
Usability,"Thank you @vruano for your diligent review. I've implemented logger classes to encapsulate the metrics classes. Unfortunately the metrics classes must remain public in order to write output using `MetricsUtils.saveMetrics()`, but at least the tools aren't using them directly. There are two logging class groups - one for Filter and one Score. For Filter, there is an interface `PSFilterLogger` that is implemented by a file-logging class `PSFilterFileLogger` and a dummy class `PSFilterEmptyLogger` that does nothing. There are analogous classes for Score, but there is no Empty logger because it's not actually necessary. This adds a lot of new classes (maybe you can think of a better way) but usage has been greatly simplified. As we discussed in person, I don't think there is a faster way to count the reads in Spark. If you wanted to count the reads as they pass through, you would have to use some kind of atomic type that would be slow. Also it may be impossible to account for cases when tasks fail and restart. @lbergelson @droazen In this PR, I wanted to use htsjdk's MetricsFile and MetricBase classes for writing metrics to a file. I notice that these classes are mostly used for picard-related things. Is this the preferred way to do things? They do force you to expose public variables and also use an upper-case naming convention. On the other hand, they are somewhat convenient.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160:720,simpl,simplified,720,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160,1,['simpl'],['simplified']
Usability,Thank you at @ldgauthier for volunteering to review and for all of the feedback. The Travis checks are still in progress but the only code change is with the logger type.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5601#issuecomment-456978262:71,feedback,feedback,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5601#issuecomment-456978262,1,['feedback'],['feedback']
Usability,"Thank you for looking into this and sharing the analysis. I always believed that there is _a lot_ to be gained from a decent coverage collection strategy. For example, I have seen Genome STRiP cleanly resolving cases that are essentially impossible to resolve from our raw data. Perhaps we should:. (1) Include genome mappability analysis tracks as a filtering strategy w/ or w/o MQ-based filtering. We can download fairly accurate mappability data based on noisy Illumina-like paired-end reads from here:; https://sourceforge.net/p/gma-bio/wiki/Home/; They have a decent publication too. (2) While a simple fragment-based coverage collection has major pitfalls, I am not quite convinced that one must throw away fragment information altogether. By theoretically considering various SV events (tandem duplication, disperse duplication, deletion, inversion, inter- and intra-contig translocation, etc.), and studying paired-end reads coming from various parts of such SVs case by case and how they would theoretically align to the reference, we can come up with a heuristic counting strategy that gives the most consistent signal for downstream tools. This analysis requires taking into account basic summary statistics such as read and fragment length distribution in order to resolve anomalous fragments to putative SV events. I have worked out a few cases and this is fairly doable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372064064:601,simpl,simple,601,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372064064,1,['simpl'],['simple']
Usability,Thank you for the feedback! I applied it all. Back to @droazen,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107677904:18,feedback,feedback,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107677904,1,['feedback'],['feedback']
Usability,Thank you for the feedback! Will update style.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/511#issuecomment-101807825:18,feedback,feedback,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/511#issuecomment-101807825,1,['feedback'],['feedback']
Usability,"Thank you so much @Neato-Nick for your feedback, highly useful indeed! I was just worried that all these locations with warning signs are getting bypassed which as per your feedback should not be the case.; Regards,; Sanjeev",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-408959663:39,feedback,feedback,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-408959663,2,['feedback'],['feedback']
Usability,Thanks @asmirnov239 for the feedback! I will incorporate these changes shortly to the forum version and here for posterity.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5829#issuecomment-478774288:28,feedback,feedback,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5829#issuecomment-478774288,1,['feedback'],['feedback']
Usability,"Thanks @davidbenjamin for the feedback and sorry for the slow response. We have been working on improving PairHMM by adding AVX-512 (#3615) and FPGA (#2725) implementations. . We are also adding AVX2 (#3701) and AVX-512 (future PR) Smith-Waterman, which will improve the performance of Mutect2. We have the data above and will provide benchmarking results of your Mutect2 command with these improvements.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2562#issuecomment-338732871:30,feedback,feedback,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2562#issuecomment-338732871,1,['feedback'],['feedback']
Usability,"Thanks @davidbenjamin, I can try that out. Any other parameters or modes that you feel might be gating any of these metrics/optimizations, which should be explored jointly with the SW parameters?. I guess the same question applies for `linked-de-bruijn-graph`, which is currently marked as experimental: what would be the procedure/criteria for changing the default behavior? Hopefully, we can answer this question for the case of a binary parameter before tackling 12 parameters! In general, I'm interested in establishing clear processes so it's easier for anybody to propose improvements. If there's no clear answer just yet, I'm happy to stop at exposing these parameters, perhaps consolidating defaults to one of the current sets if that is not too disagreeable (which is just slightly more complicated than a binary decision). Don't want to rabbit hole if there's no need. Hopefully, at the least, the blog-like documentation above will provide useful pointers to anyone that might want to tackle similar efforts in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715407619:524,clear,clear,524,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715407619,2,['clear'],['clear']
Usability,"Thanks @droazen, I suspected that was the case from looking at the history. Though it's not clear to me from @eitanbanks' commit why he would disable it for non-ERC modes. FWIW my PR looks to have only failed where the HC tests are comparing against existing files, and the existing files don't have phasing (whereas newly generated test files do). I'm going through and double-checking that that is the case, and will hopefully amend that PR shortly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470680198:92,clear,clear,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470680198,1,['clear'],['clear']
Usability,Thanks @gbggrant! @droazen @ldgauthier I just pushed a branch that resolves the error by simplifying the evidence-to-index cache.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6586#issuecomment-626448066:89,simpl,simplifying,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6586#issuecomment-626448066,1,['simpl'],['simplifying']
Usability,"Thanks @ilyasoifer ! Was the test bam you added aligned with minimap2? If not, we should make sure to add at least one simple HaplotypeCaller regression test that takes an actual minimap2-aligned input.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8337#issuecomment-1558029097:119,simpl,simple,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8337#issuecomment-1558029097,1,['simpl'],['simple']
Usability,Thanks @jean-philippe-martin! I've addressed your other feedback points and submitted a new pull request against the main repo (so that tests are run): https://github.com/broadinstitute/hellbender/pull/827. I'm closing this one now.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/804#issuecomment-131862850:56,feedback,feedback,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/804#issuecomment-131862850,1,['feedback'],['feedback']
Usability,"Thanks @jonn-smith. Is Funcotator ready for us to document now or in the next month? Meaning, is it usable by users now? Otherwise, we can release an `alpha` tutorial initially to get folks to use it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3769#issuecomment-341184664:100,usab,usable,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3769#issuecomment-341184664,1,['usab'],['usable']
Usability,"Thanks @kdatta. The branch builds now, but there are a couple of problems that cause several tests to fail, including some existing tests that used to pass. You can see the results [here](https://travis-ci.org/broadinstitute/gatk/jobs/221534229). - The main issue is that GenomicsDB fails to load. This causes the importer tests to fail, as well as the existing GenomicsDB integration tests. (Note that the importer tests fail with a null pointer exception, but that problem is secondary and only happens when the db fails to load, which is the root problem.) We can fix the NPE in code review, for now the main issue is fix the core problem of why genomics db fails to load. - The changes in OptionalVariantInputArgumentCollection and RequiredVariantInputArgumentCollection are causing argument name collisions in other tools, which is why ExampleIntervalWalkerIntegrationTest tests are failing in this branch. The simplest fix in the short term is to just revert the changes you made to those two classes, and remove the new VariantInputArgumentCollection class. These aren't being used by the importer tool anyway. It should be pretty easy to reproduce load issue, it happens on my laptop and and travis, but let me know if you need help or have questions about any of this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294148791:916,simpl,simplest,916,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294148791,1,['simpl'],['simplest']
Usability,"Thanks @lbergelson and @droazen. Could it be possible to add a simple patch to add all the reads to the returned `AlignmentContext`, instead of just add the `ReadPileup` from just one covered sample?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1752#issuecomment-213057081:63,simpl,simple,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1752#issuecomment-213057081,1,['simpl'],['simple']
Usability,"Thanks @lbergelson! I agree that it might be good to break into more layers—could be worth talking to SV team and seeing what lessons they learned in putting together their hierarchy of images. Also, note that I pushed the install of miniconda into the base, but I did not push down the setup of the GATK conda environment itself (which takes the bulk of the time during the main-image build, as it requires lots of downloading). I think I commented elsewhere that a good strategy might be to set up the conda environment with the non-GATK python dependencies in the base, and then update the environment via a pip install of the GATK python packages in the main image. This would let us make python code changes without having to rebuild the base, but might require a bit of scripting to create a final yml for non-Docker users. I also agree that it would be nice to cut down the Travis time, might be worth taking a look at other strategies to do that—could save everyone a lot of time!. Will try to add the test you suggested sometime tomorrow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-621487662:139,learn,learned,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-621487662,1,['learn'],['learned']
Usability,Thanks @samuelklee for the feedback! I will go over these and incorporate as much as I can before Monday.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5829#issuecomment-478308547:27,feedback,feedback,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5829#issuecomment-478308547,1,['feedback'],['feedback']
Usability,"Thanks JP. This is really Interesting. Unfortunately I think the vcf slice is the major motivating use case. How; large was that vcf? Do you think there's anything we can do to get some; speedup with NIO for small files when we only have 1 core? I'm not totally; clear on how data transfer over a network interacts with thread waiting.; If we are receiving data over the internet does that need cpu time or is; that handled asynchronously by the network card? I.e. if we're prefetching; in on thread, can that thread be asleep or is it consuming cpu time the; whole time a transfer is in progress?. I suspect that the immediate next question people are going to have is ""4; cores are inefficient, 1 core is slow, how about 2 cores..."". I'm curious about async and vcf. The updated slides show vcf with async on; being ~40% slower than with async off. That's; setting use_async_io_write_tribble on / off? It looks like we should just; disable it if we're on a single core, but by default we have it on.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2424#issuecomment-284076588:263,clear,clear,263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2424#issuecomment-284076588,1,['clear'],['clear']
Usability,"Thanks a lot @davidbenjamin! One of the questions that I have is how to add a new read to the `ReadLikelihoods` for a new allele that is found while iterating. A very simple example will be:. ``` java; public static PerReadAlleleLikelihoodMap flatPerReadAlleleLikelihoodsFromPileup(final ReadPileup pileup, final Allele refAllele) {; final PerReadAlleleLikelihoodMap pralm = new PerReadAlleleLikelihoodMap();; final byte ref = refAllele.getBases()[0];; for (final PileupElement e : pileup) {; final Allele current;; if (e.isDeletion()) {; current = Allele.SPAN_DEL;; } else if (e.getBase() == ref) {; current = refAllele;; } else {; current = Allele.create(e.getBase());; }; pralm.add(e, current, DEFAULT_FAKE_LIKELIHOOD);; }; return pralm;; }; ```. The solution that I found after looking at the class was this one, that it's very complicated:. ``` java; public static ReadLikelihoods<Allele> flatPerReadAlleleLikelihoodsFromPileup(final ReadPileup pileup, final Allele refAllele, final SAMFileHeader header) {; final Set<Allele> alleleSet = new TreeSet<Allele>();; final Map<String, List<GATKRead>> reads = new HashMap<>();; final byte ref = refAllele.getBases()[0];; alleleSet.add(refAllele);; for (final PileupElement e : pileup) {; if (e.isDeletion()) {; alleleSet.add(Allele.SPAN_DEL);; } else if (e.getBase() == ref) {; alleleSet.add(refAllele);; } else {; alleleSet.add(Allele.create(e.getBase()));; }; final String sample = ReadUtils.getSampleName(e.getRead(), header);; List<GATKRead> list = reads.getOrDefault(sample, null);; if(list == null) {; list = new ArrayList<>();; reads.put(sample, list);; }; list.add(e.getRead());; }; final ReadLikelihoods<Allele> likelihoods = new ReadLikelihoods<>(new IndexedSampleList(reads.keySet()), new IndexedAlleleList<Allele>(alleleSet), reads);; for(final PileupElement e: pileup) {; final String sample = ReadUtils.getSampleName(e.getRead(), header);; final LikelihoodMatrix<Allele> l = likelihoods.sampleMatrix(likelihoods.indexOfSample(sample));; f",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-249930107:167,simpl,simple,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-249930107,1,['simpl'],['simple']
Usability,"Thanks a lot for all your feedback about this @lbergelson and @droazen. From my side this could be close now, although it may be useful to have some of this information in the Wiki to avoid confusion. Thank you very much again!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2345#issuecomment-273732039:26,feedback,feedback,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2345#issuecomment-273732039,1,['feedback'],['feedback']
Usability,"Thanks a lot for your detailed information. ; I just had a look into the branch you told me, but it looks quite complicated to me at this time. I think I will wait until the official release in January and hope for some kind of best practise guidelines to come up.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3996#issuecomment-352778559:242,guid,guidelines,242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3996#issuecomment-352778559,1,['guid'],['guidelines']
Usability,"Thanks for all the feedback Adam. I got a bunch of the metrics code written; today and hopefully once I have that I can actually test this code and port; the other tests. I will merge that PR into this one and fix these changes; and get back to you. On Thu, Jul 16, 2015 at 9:04 PM, Adam Kiezun notifications@github.com; wrote:. > Assigned #631 https://github.com/broadinstitute/hellbender/pull/631 to; > @tovanadler https://github.com/tovanadler.; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/hellbender/pull/631#event-358132720.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/631#issuecomment-122149505:19,feedback,feedback,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/631#issuecomment-122149505,1,['feedback'],['feedback']
Usability,"Thanks for getting this cleared up. ; OK, what next? I'll check with colleagues who may be aware this 'feature'. Perhaps the case can be made more clearly by a group of users, including visible labs working on human evolutionary genomics. . I don't know the CA genomics community well, but my shallow poling suggests most are happily unaware that SNPs near indels will often be assigned lower quality than they might.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/269#issuecomment-279122551:24,clear,cleared,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/269#issuecomment-279122551,2,['clear'],"['cleared', 'clearly']"
Usability,"Thanks for helping me to understand why you didn't mark the metadata. This may seem like quibbling, but I'd suggest that we mark the metadata with a comment character, and let the pandas/R users remove it. They'll notice if they forget to do that, because the columns won't be named as expected, and they'll have to fix it up. Whereas the risk for automated programs is that they'll simply delete the first row, which might be real data if the file has been reordered for some reason, or if the tool implementing the standard is non-compliant. The resulting bugs will be subtle, and might easily go undetected. Building in behavior to delete lines starting with ""CHROM\t"" seems odd and fraught with peril in a way that building in behavior to strip comments, doesn't. That's my take, anyway.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-480956381:383,simpl,simply,383,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-480956381,1,['simpl'],['simply']
Usability,"Thanks for incorporating feedback. Everything looks good except I think since I last looked at this PR, `--sparkRunner` has become `--spark-runner`. If this will get fixed, then there is a tiny thing to fix in addition. The ReadsPipelineSpark example command is missing a backslash.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4029#issuecomment-355892072:25,feedback,feedback,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4029#issuecomment-355892072,1,['feedback'],['feedback']
Usability,"Thanks for reporting this @lbergelson. I've raised it internally at Cloudera, so we'll see if it can be fixed. I also had a hunt around to see if it would be possible to suppress this on the Gradle side, but I couldn't see anything. It's possible for Maven, but I don't think this applies to Gradle:. http://maven.apache.org/guides/mini/guide-http-settings.html#Ignoring_Cookies",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/610#issuecomment-118360200:325,guid,guides,325,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/610#issuecomment-118360200,2,['guid'],"['guide-http-settings', 'guides']"
Usability,"Thanks for sharing your analysis. What is your criterion for choosing the main peak? I have seen quite a few WGS samples, which before mappability filtering, have their coverage peak at 0, and/or the median count is significantly away from the main peak (due to the abundance of low mappability bins with small counts). . Also, the second peak of chrX coverage in XY samples that you show above is not a large germline event -- it is simply a low mappable PAR-like region that borrows reads from chrY. Here's how the X coverage distribution looks like on an XY sample after mappability filtering (which removes most of all approximate homologies):; ![chrx](https://user-images.githubusercontent.com/15305869/37867778-54e3d196-2f73-11e8-8345-d8964b39a17e.png). **The second spurious peak is gone and range of NB-like behavior is pretty much perfect. Without mappability filtering, all of the bins on the second mode _will_ show up as CN = 2 events (in fact, if you look at gCNV calls on a typical XY samples, there are tons of CN = 2 calls).**. Most, if not all, of the non-NB-like coverage before/after the main peak in your plots are reads from unmappable regions, many of which show up as real CNV events if we do not filter them (reads in these regions do not follow from the coverage model and we are at the mercy of BWA). I strongly believe Genome STRiP has achieved ~ 99% experimental validation accuracy because of aggressive filtering, not because of a superior model (it's an elementary Gaussian mixture mix). Garbage in, garbage out. Anyhow, I am not comfortable at all with cutting a non-Beta release without taking care of about:. 1. Mappability-based bin/read filtering (for WGS), and; 2. Trying out and evaluating a bait-based coverage collection (for WES), so that the raw coverage distribution is more NB-like to begin with. These are both perfectly achievable goals before May 15. I'd be happy to leave stuff such as different coverage collection strategies (e.g. base call coverage) ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375917669:434,simpl,simply,434,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375917669,1,['simpl'],['simply']
Usability,"Thanks for the explanation. It isn't clear to me that the SAMRecord API was ever intended to support ; headerless records (except maybe in very rare corner cases). I don't really know the scope of hellbender. If it is just for internal ; DSDE tools development, then I guess it doesn't matter.; If you ever want to leverage code/libraries from elsewhere, then those ; would have to be ""headerless-aware"", I guess. For example, a common operation in Genome STRiP is to ask for the sample ; associated with a read. This requires the header, I would think.; Anyway, my main point was just to stimulate thinking about the value of ; implementing an efficient way to transmit the headers.; It also seems to me that this generalizes to efficient patterns to ; transmit any widely shared data (that is referenced by many serialized ; individual data items) out-of-band. -Bob. On 9/21/15 11:42 AM, droazen wrote:. > @bhandsaker https://github.com/bhandsaker Thanks for chiming in with ; > your thoughts/concerns.; > ; > Under this proposal, the various classes in htsjdk that read and ; > return |SAMRecords| (eg., |SAMReader| & co.) would continue to put the ; > header inside of the records, so we would not be imposing an ; > additional burden on direct clients of htsjdk to check for null ; > headers any more than they do currently. The only difference is that ; > if downstream consumers of |SAMRecords| (like hellbender) choose to ; > strip the header from the records, there would be an explicit contract ; > governing the behavior of headerless |SAMRecords| (as opposed to the ; > status quo, in which the header may be null but behavior is totally ; > undocumented and in some cases inconsistent -- eg., the reference name ; > and index in a headerless |SAMRecord| can get out-of-sync in some cases).; > ; > In additional to documenting/clarifying the behavior of headerless ; > |SAMRecords| and fixing any consistency-related bugs we find when ; > operating without a header, we would also make an ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-142402910:37,clear,clear,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-142402910,1,['clear'],['clear']
Usability,Thanks for the feedback @cmnbroad! I could wait til #2218 is accepted to continue working and check that nothing is broked...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2195#issuecomment-261775822:15,feedback,feedback,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2195#issuecomment-261775822,1,['feedback'],['feedback']
Usability,"Thanks for the feedback @cmnbroad. I would like to have something more consistent for my own tools, independently on if I'm using `Path` or `File, but it could wait.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-275080208:15,feedback,feedback,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-275080208,1,['feedback'],['feedback']
Usability,Thanks for the feedback Brad. We'll continue to look into the core dump to make sure it doesn't cause issues in the future.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3605#issuecomment-338723352:15,feedback,feedback,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3605#issuecomment-338723352,1,['feedback'],['feedback']
Usability,Thanks for the feedback!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2315#issuecomment-278732586:15,feedback,feedback,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2315#issuecomment-278732586,1,['feedback'],['feedback']
Usability,"Thanks for the feedback, @cmnbroad.  @droazen, should I open a ticket for implement the plugin and close this issue? What's about the checking of the quals?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2084#issuecomment-245969652:15,feedback,feedback,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2084#issuecomment-245969652,1,['feedback'],['feedback']
Usability,"Thanks for the feedback, @droazen!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2177#issuecomment-288761221:15,feedback,feedback,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2177#issuecomment-288761221,1,['feedback'],['feedback']
Usability,"Thanks for the quick review, @ldgauthier!. I don't think my fix will address any non-determinism in the integration tests. I'm inclined to just do better with the new tools---there does seem to be enough duct tape in the integration tests regarding re/setting the RNG so that the exact-match tests consistently pass. As for learning how to run the WARP tests, I think that would indeed be pretty useful---for anyone that might have to update code for VQSR or the new tools in the future! Can we teach everyone to fish? Isn't this what CARROT is for?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7709#issuecomment-1061830649:324,learn,learning,324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7709#issuecomment-1061830649,1,['learn'],['learning']
Usability,"Thanks for the response, @droazen! Technically, yes, that would be satisfactory & accurate... and if that's easiest, I'm fine with that. . From a user perspective though, it might be beneficial to report the first occurrence of this error, as that's most likely where I would go back to do future testing & troubleshooting. That being said, all of the overlapping intervals are already outputted to stderr, so all the information is retained regardless, and I could just look through the logs to find that first problematic interval. As an aside, I find it a bit weird that the overlapping interval message shows up as a _warning_ even when using the `-no-overlaps` option (I would assume it would be an error, not a warning). In my experience, most errors cause the program to quit immediately. So, perhaps instead, if this warning were an _error_ when using the `-no-overlaps` option, the program would stop after the first occurrence of this error... and then the error message would be accurate. Maybe that was the original intent of this code. But, again, if that requires much more testing & changes, when a quick rewording would also suffice, there's no need. If it's simply a rewording, I'm happy to make a pull request. Let me know what you think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8103#issuecomment-1329747570:1175,simpl,simply,1175,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8103#issuecomment-1329747570,1,['simpl'],['simply']
Usability,"Thanks for the review @bshifaw. > If its too late now maybe for later it would be nice to add a runtime block for each task so that it would executable in a cloud environment. There is limited support for runtime blocks now (you can see one [here](https://github.com/broadinstitute/gatk/pull/6504/files#diff-bebfeef541c0066d7a692aae54d76f6bR263)) but it requires [annotating](https://github.com/broadinstitute/gatk/pull/6504/files#diff-7b13b03f206ff3c35e846f8a15eaf290R88) the tool with the proper values. It currently only supports the `memory` attribute, but we can certainly add support for other attributes if it makes sense for them to have static values. Perhaps we should add `docker` ? Others ?. > Why have inputs declared at a workflow level input block (which requires them to be repeated in the call block, and again at the task input block) when they can be declared simply at the task level?. I chose to make each WDL have both a workflow and a task, and generated an input JSON that contains the default values for each optional arg so that only the required args have to be provided (they're initialized with the type of value required similar to the skeleton that womtool generates). But maybe theres an alternative structure thats better. Can you point me to a WDL that uses the structure you're proposing? I'm not sure I understand how it would be used. > If it's an easy fix it would be nice to see the full parameter name instead of abbreviation for input and output (e.g. ""I"", ""O""). I used the full names wherever possible, but many of the tools have args with names that are WDL reserved works like `input` and `output`, so I had to use the short name in those cases. An alternative would be to mangle/annotate them instead, i.e., turn `input` into something like `input_` or some such thing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6504#issuecomment-612900828:879,simpl,simply,879,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6504#issuecomment-612900828,1,['simpl'],['simply']
Usability,Thanks for the review @droazen. I've addressed all your feedback in the latest commit. I'll merge once the tests pass.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1432#issuecomment-175651593:56,feedback,feedback,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1432#issuecomment-175651593,1,['feedback'],['feedback']
Usability,"Thanks for the review @lbergelson. I've addressed most of the feedback, but still have a few more to do.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2256#issuecomment-267098362:62,feedback,feedback,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2256#issuecomment-267098362,1,['feedback'],['feedback']
Usability,"Thanks for the review and running those tests, @ldgauthier! Will restore the aforementioned GnarlyGenotyperIntegrationTests and update a few other exact matches in the rebase this afternoon. You also asked above if there was a theoretical reason to change the threshold. Since it seems the original was relatively arbitrary (at least from what I've been told, happy to be corrected), I think we can leave it. The new annotation is strictly larger, so we will then be slightly more conservative about keeping sites if we leave the threshold fixed. You can think of this as a slight change in the decision boundary in genotype-count space---perhaps I can add some plots to this thread this afternoon to demonstrate. In practice, what we care about is whether: 1) many sites flicker across the change in boundary after hard filtering, and/or 2) these sites result in discrepancies post-VQSR. I think the tests you ran suggest that we don't need to worry much about the second issue, and I can take a closer look later to check about the first (which will depend simply on the number of samples and the allele frequency spectrum). We can also take a basic look at how things might change with e.g. more samples using the aforementioned plots.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-914471272:1059,simpl,simply,1059,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7394#issuecomment-914471272,1,['simpl'],['simply']
Usability,"Thanks for the suggestion!. To answer the questions:; >Would it make more sense to have a much more stringent cutoff for alignment size after de-overlap? . Yes! The filtering step is actually done in the class `AssemblyContigAlignmentsConfigPicker` in the `alignment` package, where the unique read span length filter is defaulted to 10 base. I put it this way so that the contigs won't be ""re-classified"" in `CpxVariantInterpreter` as having a simple chimera and having to be sent back to `SimpleNovelAdjacencyInterpreter`. So, the idea was to separate the concerns of alignment picking from type inference. > What's the downstream effect of changing this cutoff that you're proposing here; and would it make sense to make it something much higher, like say 19 to match the minimum BWA-MEM seed length?. I'll experiment with the new suggested length.; The idea behind settling on this size-10 filter was to be more permissive when it comes to alignment filtering in `AssemblyContigAlignmentsConfigPicker`, and filter variants later in VCF.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4962#issuecomment-403600389:445,simpl,simple,445,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4962#issuecomment-403600389,1,['simpl'],['simple']
Usability,"Thanks for the suggestions @mwalker174! That makes sense and it gives me something to think about. I'll close this issue since it's clearly not a bug. If I have more questions like this, is there a better place to ask them? Or should I just open another issue?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6687#issuecomment-653003128:132,clear,clearly,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6687#issuecomment-653003128,1,['clear'],['clearly']
Usability,"Thanks for these questions, @tfenne, and glad you are experimenting with the workflow. Several Broad-internal groups are running various WGS and WES analyses and are seeing encouraging performance, so I’m looking forward to hearing feedback from you as well. However, I am currently indisposed and may be out for the next month or so, but @mwalker174 (who has now taken over from me as CNV tech lead, with a focus on the germline workflows) and @asmirnov239 should be able to point you in the right direction and respond to you in more detail. In the meantime, you may find some pointers in various forum posts or issues here on GitHub. We’re looking into improving documentation processes for runtime/requirements GATK-wide, which should help with this sort of thing in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6166#issuecomment-532343246:232,feedback,feedback,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6166#issuecomment-532343246,1,['feedback'],['feedback']
Usability,"Thanks for your feedback, @cmnbroad. In my case, I think that `IntegrationTestSpec` is a good way of avoid complicated code to test tool results, but it is true that it have some problems (one that I had was the usage for testing programs where the outputs are determined by a prefix in the command line, but with different suffixes). I think, from the API user point of view, that a class like `IntegrationTestSpec` to facilitate program output testing (including user exceptions) will be nice for developing purposes. Nevertheless, this is just a convenience that I asked for here, but I can try to solve the issues with the `BaseTest` instead. By the way, I would love to have this interface in GATK at least for now, because several of my tools rely on the `IntegrationTestSpecs` for development...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-243124889:16,feedback,feedback,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-243124889,1,['feedback'],['feedback']
Usability,"Thanks for your feedback, @droazen. I think that it will be nice to have a better annotator engine for handling what should be on/off in which cases instead of hardcoded them when it is necessary. But I can wait til the release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2534#issuecomment-290677995:16,feedback,feedback,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2534#issuecomment-290677995,1,['feedback'],['feedback']
Usability,"Thanks for your feedback, @jamesemery! I just made some changes before I saw your last comment. I liked the idea of using the tool verbosity as the default but allowing the Spark verbosity argument to override it. Even if that has no effect at the moment, I just pushed a solution for that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5825#issuecomment-478737141:16,feedback,feedback,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5825#issuecomment-478737141,1,['feedback'],['feedback']
Usability,Thanks you for accepting it... and all the reviewers for the feedback!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3195#issuecomment-329124206:61,feedback,feedback,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3195#issuecomment-329124206,1,['feedback'],['feedback']
Usability,"Thanks! Just to be clear, the PR is incomplete. We need to determine the additional dependencies (which were previously installed along with R) required for AVX, etc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-413599300:19,clear,clear,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-413599300,1,['clear'],['clear']
Usability,"Thanks, @cmnbroad!. - You're right about gatkbase-2.1.0, that image is coming from #5026, which needs some more work. We can delete it for the time being if you think it'll cause confusion.; - Correct, I think the import statement for `reshape` in BQSR.R was always incorrect/extraneous. `reshape2` is the correct dependency for `ggplot2` (which is itself imported), and `reshape` is not explicitly used in BQSR.R. So to recap: I removed the installation of this unnecessary package, but failed to remove an unnecessary import statement since it was in an untested code path, which was then caught when users tried to run the tool. Investigation of this issue then revealed that `ggplot2` was not installed correctly in the current base image, due to a completely unrelated dependency issue.; - Good call on clearing the Travis cache. Not actually sure how to do that, do I just delete the cache at https://travis-ci.org/broadinstitute/gatk/caches for this particular branch?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5040#issuecomment-408447924:808,clear,clearing,808,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5040#issuecomment-408447924,1,['clear'],['clearing']
Usability,"Thanks, @davidbenjamin. I started learning Java over the break as planned. I'm a quarter in to my intro to Java class. So at this point, I think it best to leave the review to those who are more versed in the language.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3510#issuecomment-355053317:34,learn,learning,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3510#issuecomment-355053317,1,['learn'],['learning']
Usability,"Thanks, @droazen. While I understand the effects of the funding landscape on academic resources, it seems to me this is a full capitulation of the GATK developer team given a serious bug, especially in light of the fact that the team seems to have enough resources to continue working on Mutect3. Mutect2 has been one of the best performing variant callers of the last years and is a major reason for the Broad's good reputation in the oncology bioinformatics field. GATK and Mutect2 are used by hundreds of institutions in clinical practice, affecting thousands of real patients' lives. Almost all of these institutions are likely to use clinical WES assays due to cost reasons and will thus have been directly affected by this issue _for the last three years_. Also, almost all of these institutions will never learn of this bug since they likely trusted in the developers to have proper functional regression tests in place. If this is indeed the best the Broad can do as an institution, then I will take your offer of providing a build of Mutect2 4.1.8.1 with the log4j vulnerability patched out - thank you. The one thing that I am asking for in addition (for the sake of the overall oncology bioinformatics community), however, is that you conduct a best effort to notify organizations (universities, hospitals, and biotechs/pharmaceuticals that you know are using Mutect2) and best-practise workflow owners (Nextflow, Snakemake, WDL, CWL etc. that include Mutect2) of the forced downgrade. Also, I think it makes sense to include a very prominent warning into the Mutect2 READMEs and GATK best practice documentations and guides. I know that this is work, too, but with success comes responsibility, and I can just hope that providing proper warnings uses less developer bandwidth than applying binary search to find out which of these [10 commits between 4.1.8.1 and 4.1.9.0 that are touching variant filtering (see below)](https://github.com/broadinstitute/gatk/compare/4.1.8.1...4.1.9.0) bro",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1535909226:813,learn,learn,813,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1535909226,1,['learn'],['learn']
Usability,"Thanks, @lbergelson. I was also thinkinhg that this code is mostly deprecated, but I wanted to ported as is for the first pass review. I just need to support the new mpileup version (unique sample, because if not it is more difficult), because the consensus one is deprecated. I will update the codec and add some tests for it. In addition, ~~I was thinking to create a list of `PileupElement` inside the feature to make easier to compare the internal pileup, but with ""reads"" of one base-pair.~~ Update to this: `PileupElement`is difficult to generate without including `GATKRead` simple implementation, and I think that it is not worthy. On the other hand, I will improve the walker itself. I will tell you when I finished with the changes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1862#issuecomment-224419331:582,simpl,simple,582,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1862#issuecomment-224419331,1,['simpl'],['simple']
Usability,"Thanks, @yfarjoun, I think those are reasonable. Just to be clear, the code for the tool mentioned above is a little confusing, in that an early fail for writability when the directory does not exist prevents us from reaching code that appears to be intended to create the directory. Not a big deal in the end (and I checked that this was also the case before the PR). But minor things like this can easily break downstream scripts, etc., as was demonstrated above, so we should take some care. I agree that it's fine to leave some decisions up to each tool, but we should try to document them for the benefit of users and future devs that might need to maintain the behavior of the tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4825#issuecomment-470172806:60,clear,clear,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4825#issuecomment-470172806,1,['clear'],['clear']
Usability,"Thanks, James! I'll check that out - I think we might be able to leverage; that. best,. Brian. On Fri, Mar 8, 2024 at 2:38 PM jamesemery ***@***.***> wrote:. > Hey @brianjohnhaas <https://github.com/brianjohnhaas>. I'm not quite sure; > i fully understand what we can change to help you here. However there is a; > feature you might not be aware of in the bamout that can help you figure; > out which reads go with what haplotype. In our bamout we assign a tag (that; > for whatever reason it looks like IGV hides by default) called the XA tag.; > If you look at an IGV bamout and color by that tag you can see what reads; > were grouped by what haplotypes. If a read has no XA tag that means it was; > non-informative about any one haplotype over a second possible contender; > and thus it was not strong evidence one way or another.; >; > Below is a screenshot of what it looks like to do this in a very simple; > case. Hopefully this answers your question? I would be happy to go deeper; > into this if you would like.; >; > Screenshot.2024-03-08.at.2.35.42.PM.png (view on web); > <https://github.com/broadinstitute/gatk/assets/16102845/7d11ff5f-418e-4826-89fc-07535648a71f>; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1986302994>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABZRKX773HENZD2UVB356GDYXIHTTAVCNFSM6AAAAABD4OZKJ6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSOBWGMYDEOJZGQ>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >. -- ; --; Brian J. Haas; The Broad Institute; http://broadinstitute.org/~bhaas <http://broad.mit.edu/~bhaas>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1986909258:906,simpl,simple,906,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1986909258,1,['simpl'],['simple']
Usability,"Thanks, but I’m still not sure I understand. What are the intervals that HaplotypeCaller “sees” at each given step:; Initial calling; Assembly; Final output; . From what you wrote, HaplotypeCaller uses the assembly-region-adding regions for initial calling and assembly, but not final output. But this does not make sense. Any exome calling should also include padded regions adjacent to the targeted exome regions in order to capture potential splice variants. . Another way to rephrase the question is this:. How precisely is the HaplotypeCaller output different when using only interval-padding vs only assembly-region-padding vs both?. . Thanks. . From: droazen <notifications@github.com>; Reply-To: broadinstitute/gatk <reply@reply.github.com>; Date: Thursday, August 1, 2019 at 2:10 PM; To: broadinstitute/gatk <gatk@noreply.github.com>; Cc: gevro <g.evrony@gmail.com>, Mention <mention@noreply.github.com>; Subject: Re: [broadinstitute/gatk] Missing interval padding for HaplotypeCaller (#6071). . @gevro The --interval-padding argument is a GATK-wide argument shared by all tools that simply adds the specified amount of padding to each -L interval. The --assembly-region-padding argument is a HaplotypeCaller-specific argument that adds padding to both the -L intervals and the assembly regions created within the intervals. It allows the HaplotypeCaller to keep track of which regions are part of the main intervals for calling and which are just padding regions. So with --assembly-region-padding you shouldn't get variant calls in your VCF that are entirely contained within the padding regions, whereas with --interval-padding you would, since --interval-padding transforms the intervals before the HaplotypeCaller even sees them. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6071#issuecomment-517412587:1093,simpl,simply,1093,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6071#issuecomment-517412587,1,['simpl'],['simply']
Usability,"Thanx for feedback. I obviously don’t know much if anything about the underlying logic but; have had enough experience to look in unusual places. Have a good weekend. RDB. On Fri, Nov 1, 2019 at 4:24 PM JP Martin <notifications@github.com> wrote:. > @rdbremel <https://github.com/rdbremel> for ""mystery 1"" see issue #5447; > <https://github.com/broadinstitute/gatk/issues/5447>. This should be an; > innocuous warning that it can't initialize the Google Cloud Storage code; > and shouldn't cause a failure unless you try to access paths that start; > with ""gs://"". Going through the Cloud initialization steps described in the; > README should remove the warning (though again, this isn't required if you; > don't need to read files from the cloud).; >; > Mystery 2: For what it's worth, ""GC overhead limit exceeded"" indicates; > that the VM was spending too much time in GC. Running low on memory is a; > possible cause but generating too many small objects or being stuck in an; > infinite loop of allocation/deallocation are others. In the past these have; > been caused by inputs that were malformed in some way. This isn't the place; > for this discussion though, please file a separate issue since it's a; > separate bug.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/6182?email_source=notifications&email_token=ANCR2VHWQ6XDSUQ6KEGISFDQRSM7TA5CNFSM4I2MRFQKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEC4GNZY#issuecomment-548955879>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ANCR2VEC5ARUEQRTEDGJ3TDQRSM7TANCNFSM4I2MRFQA>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548989454:10,feedback,feedback,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548989454,1,['feedback'],['feedback']
Usability,"That sounds prudent. The new version of the GermlineCNVCaller workflow will be available at release; I think you'll find the workflow itself to be quite streamlined and hopefully easy to use. However, because the model is relatively sophisticated, there are some parameters and model priors that may need to be set appropriately to generate optimal results. We plan on spending some time shortly after release doing internal evaluations to determine some best-practices guidelines for data generated at the Broad.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3996#issuecomment-352850485:470,guid,guidelines,470,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3996#issuecomment-352850485,1,['guid'],['guidelines']
Usability,That would be a clearer error message.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/489#issuecomment-99104999:16,clear,clearer,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/489#issuecomment-99104999,1,['clear'],['clearer']
Usability,"That would not be a valid test, since it wouldn't be testing the way the code actually handles invalid intervals. All we want to know is that we throw when we encounter an invalid interval. Did I mention that this very simple change is urgently needed by many branches?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/526#issuecomment-104401315:219,simpl,simple,219,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/526#issuecomment-104401315,1,['simpl'],['simple']
Usability,"That would work, yet I don't see why we simply can focus only in codecs that return the right type. Seems that would be the same amount of work.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1184#issuecomment-163301007:40,simpl,simply,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1184#issuecomment-163301007,1,['simpl'],['simply']
Usability,"That's correct, @akiezun.; However, it's not just stripping out that code. There are a ton of optimizations that can then be made to the code to simplify it afterwards. These classes were made very bulky to accommodate the indel calibration, and we should really remove that bulk. I can help with that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1056#issuecomment-152047427:145,simpl,simplify,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1056#issuecomment-152047427,1,['simpl'],['simplify']
Usability,"That's correct. We could easily add an optional sequence-dictionary input for plotting in the WDL, if desired, but I decided to keep it simple for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4728#issuecomment-386341401:136,simpl,simple,136,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4728#issuecomment-386341401,1,['simpl'],['simple']
Usability,That's exactly what I came here to do! I checked if Picard's FixMateInformation would fix it but it doesn't look that simple.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1864#issuecomment-222236240:118,simpl,simple,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1864#issuecomment-222236240,1,['simpl'],['simple']
Usability,"That's very strange @cmnbroad -- in the test I did in front of you yesterday, I added only the exclusion above and it worked fine for me. Are you building with `gradle` or `gradlew`?. Recommend we add whatever exclusions are necessary in a separate, simple PR, independent from the GenomicsDB PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2578#issuecomment-292619716:250,simpl,simple,250,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2578#issuecomment-292619716,1,['simpl'],['simple']
Usability,"That's why I am not using in ReadTools and other developmental toolkit the base class from GATK, due to the polluted command line with unused arguments. I think that for give flexibility, some of that arguments should be configurable by extending classes. For example, some tools that does not require reads at all should be able to turn off the read arguments. That will be very useful, although I am not sure how to do it in a proper way without adding more and more interfaces for argument collections. In context case of this PR, I think that adding it does not have any real effect on the GATK codebase, and a lot is gained by downstream projects. For example, if the wrapper script adds another argument that should be parsed in `Main` and documented, the GATK team just add it to its class. If a toolkit has a similar wrapper script, it can also add its own only-doc argument by simply overriding the method...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371822090:886,simpl,simply,886,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371822090,1,['simpl'],['simply']
Usability,The PR at googleapis/google-cloud-java#5789 makes it possible to add a BigQuery dependency without having to move to the unshaded version. This should make our lives simpler.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-516181784:166,simpl,simpler,166,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-516181784,1,['simpl'],['simpler']
Usability,"The Talkowski lab version of this is in R and requires some packages that don't seem to be available anymore as well as the python tool svtk, also developed in their lab. It also localizes all the files with a separate Java program they developed. Their implementation is here (most critically gCNV_Pipeline.Rmd and gCNV_helper.jar): https://github.com/theisaacwong/talkowski/tree/master/gCNV It appears to be under active development. My simplified implementation is at https://app.terra.bio/#workspaces/broad-firecloud-dsde-methods/gCNV-CMG-test/notebooks/launch/perform_clustering.ipynb but it's still under development with some help from Brian in TAG.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5632#issuecomment-926857837:439,simpl,simplified,439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5632#issuecomment-926857837,1,['simpl'],['simplified']
Usability,"The WDL *input* parameter for any tool argument that is the name of a file that is *created* by the tool has WDL type `String` because if the input parameter were typed as `File`, cromwell would attempt to localize the (most likely non-existent) file at the start of the task. However, in the output block, the parameter has to have type `File` for the reverse reason; if it were `String`, it wouldn't be delocalized. The transformation is admittedly non-intuitive when reading the WDL code. Maybe there is some better alternative ?. The reason the parameter doesn't appear in the command block (in this case anyway) is because there is no corresponding tool parameter. Any `companion` files like this, such as input reference dictionary, input file index, etc., that don't appear as named tool parameters still have to be included in the WDL parameters, but aren't passed directly to the tool. I generally tried to keep the companion parameters adjacent to their source parameter whenever they appear in the WDL or JSON files, so they always travelled together. But since outputIndex is an *optional* companion for a *required* output, this results in it being listed under ""required"" parameters. We could separate the optional args into a separate ""Optional"" header comment as we do for (non-companinon) optional tool args, or we could just add a line comment like:; ```; # Required Arguments; String output_arg; String? outputIndex // optional companion for output_arg; ```. Agreed that it would be nice to find a robust way to prevent the name guessing required.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6984#issuecomment-736621798:455,intuit,intuitive,455,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6984#issuecomment-736621798,1,['intuit'],['intuitive']
Usability,"The `Poisson` arises because we want to our model to generate the *occurrences*, assuming that each *count bin* provides equal weight---rather than the counts themselves. As usual, modeling each bin as Poisson is close enough to modeling all bins as multinomial for our purposes. If we directly use the NB likelihood and simply weight the count likelihood by occurrences, occurrences in the peak will strongly affect the result, adversely so if the count likelihood is actually misspecified there. As an example, consider trying to fit a Poisson to data that is actually zero-inflated Poisson---fitting the histogram will actually result in a more robust estimate for the mean. Another benefit is that truncated data (as we have here) is straightforwardly handled in an unbiased way. In the special case of complete, trivially-binned data, the full, unbinned likelihood is recovered. I think this sort of histogram fitting is pretty standard in the astro/particle community. We can certainly change up the model to include strictly quantized + free-floating states as you describe (rather than the ""fuzzily quantized"" states I use here), but I just wanted to avoid having another level of mixtures/logsumexps for this quick prototype. However, note that modeling mosaicism on the autosomes is desirable, but there we also want the strong diploid prior to nail down the depth and per-contig bias. So we will have to be a little careful about how we introduce free-floating states. Also, since I was not using gcnvkernel, I had to integrate out all discrete parameters. It may be that we can write down a nice model with discrete parameters if we use your inference framework. Finally, I did not further bin the counts here (or rather, the bin size is 1), which already yields the maximum information, but I did use a maximum-count cutoff. If we use the same cutoff for all samples, this allows us to simply pass a non-ragged matrix from Java (with dimensions of samples x contigs x maximum count) as a ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522:321,simpl,simply,321,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522,1,['simpl'],['simply']
Usability,"The advantage of using SLF4J is that it is a general facade, so it makes simpler to change for one logging system to other if the bound is implemented. For the most common logging systems (log4j, jul, JLC, etc.), there are this implementation and even no-op logging. One of the nice things from slf4j is that it allows to use the logging format set by the software to every library dependency, controlling the verbosity of other libraries too. . After having a look to the gradle dependencies, it seems that ADAM and Spark use slf4j. This will allow better integration with the two libraries: now the `slf4-jdk` is completely removed, and I don't know if this will blow up at some point if some of the ADAM/Spark classes try to load them. In addition, it will make GATK4 more general. Regarding features, I'm not using more that what log4j is providing, but I'm quite familiar with logback and I have a bias to use it if possible, but the GATK framework as it is implemented now ""force"" to use log4j. But anyway, I'm happy also with using log4j and I was only suggesting this for make GATK4 more general (and to come back in my work to logback, but that is just personal taste). @lbergelson, feel free to close the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-259211054:73,simpl,simpler,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-259211054,1,['simpl'],['simpler']
Usability,"The annoyance is having to run a command on data, with proper syntax, to find out the Picard version. It should b something we can pull up via `docker inspect`, `gatk --version` or other simple command that does not involve some tool. I just assume this will not be addressed so I closed it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3645#issuecomment-386419307:187,simpl,simple,187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3645#issuecomment-386419307,1,['simpl'],['simple']
Usability,"The behavior of the GATK3 CombineVariants was very inconsistent and the arguments weren't entirely clear. I also suspect that some operations weren't possible with the arguments given. Rather than port that old broken version, I would advocate for an overhaul or rewrite. @bhanugandham it's going to be a big project to collect requirements and expected behavior for this tool. For example, what should the MQ be for the combined VCF for two different input VCFs with different MQ values? Much of the confusion stemmed from the old ability to merge VCFs containing the same sample. In the case where we take one genotype for each sample name (e.g. the old ` -genotypeMergeOptions PRIORITIZE`) then I believe the old behavior was wrong in some cases, taking the filter status from an input VCF at random. We also need to clarify `FilteredRecordMergeType` options, e.g. https://github.com/broadinstitute/gsa-unstable/issues/935",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/17#issuecomment-430229167:99,clear,clear,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/17#issuecomment-430229167,1,['clear'],['clear']
Usability,"The goal of this PR is to investigate if what needs doing to compile GATK and run its tests on Java 11. Some notes:. * The Scala 2.12 version of Spark 2.4 is needed to run on Java 11. I disabled `ADAMKryoRegistrator` in this branch since the version we are using is compiled against Scala 2.11. We might consider removing it entirely and no longer support ADAM formats directly in GATK - the workaround would be to use ADAM to convert to/from BAM/VCF. ADAM is also needed for reading 2bit files.; * Java 11 deprecates some APIs. Most of these are fairly easy to fix or suppress. The exception is the Javadoc API [com.sun.javadoc](https://docs.oracle.com/en/java/javase/11/docs/api/jdk.javadoc/com/sun/javadoc/package-summary.html), which has been replaced by [jdk.javadoc.doclet](https://docs.oracle.com/en/java/javase/11/docs/api/jdk.javadoc/jdk/javadoc/doclet/package-summary.html). The javadoc tools in `org.broadinstitute.hellbender.utils.help` may need to be re-written (and it's not clear if it's possible to support Java 8 and Java 11 simultaneously).; * Travis build. Getting this to build and test on Java 11 in addition to the current builds may be fairly involved as the matrix is already quite complicated. (The current PR just changes Java 8 to Java 11 for testing purposes - we'd need a way of getting both to run.). The vast majority of tests are passing on Java 11, the following are failing:; * Missing `TwoBitRecord` (from ADAM); * `ReferenceMultiSparkSourceUnitTest`; * `ImpreciseVariantDetectorUnitTest`; * `SVVCFWriterUnitTest`; * `DiscoverVariantsFromContigAlignmentsSAMSparkIntegrationTest`; * `StructuralVariationDiscoveryPipelineSparkIntegrationTest`; * `SvDiscoverFromLocalAssemblyContigAlignmentsSparkIntegrationTest`; * `java.lang.NoSuchMethodError: java.nio.ByteBuffer.clear()Ljava/nio/ByteBuffer;`; * `SeekableByteChannelPrefetcherTest`; * `GatherVcfsCloudIntegrationTest`; * `Could not serialize lambda`; * `ExampleAssemblyRegionWalkerSparkIntegrationTest`; * `PileupSpa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-527179359:989,clear,clear,989,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-527179359,1,['clear'],['clear']
Usability,"The javadoc for `AddContextDataToReadSpark` clearly mentions that unmapped reads are filtered out, so it hopefully shouldn't be too much of a surprise. But I agree that ideally this transform should function as an ""outer join"" and not filter unmapped reads.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/951#issuecomment-169148886:44,clear,clearly,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/951#issuecomment-169148886,1,['clear'],['clearly']
Usability,"The marginalization over all paths, not the the likeliest one, would make a small difference, but I'm not sure in which direction. In fact, I would even guess it would tend to favor the reference over a deletion because there are more contributions from things like TTTTT -> TT(DELETE A T)TT(INSERT A T)T that don't actually change the bases but do contribute to the sum. That is, if the reference has a longer poly-T, there are more places to put the cancelling deletion(s) and insertion(s). However, all this stuff incurs gap opening penalties and I would be surprised if it could make a difference as big as 0.07. I think I know what can, however. If you take a look at the top of page 3 of our pair-HMM docs https://github.com/broadinstitute/gatk/blob/master/docs/pair_hmm.pdf, you will see, as @yfarjoun guessed, that there is a preference for shorter haplotypes in the form of a 1/haplotype length factor. And in fact, this amount seems to be in the right ballpark. For example, @ldgauthier's case is a 28-base deletion. If you calculate the log_10 ratio of the 1/length factors assuming a 100-base deletion haplotype, you get log_10(128/100) = 0.107. This, by the way, would explain why we don't see this sort of thing with insertions. We could simply say that any uninformative read (a log likelihood difference of 0.2) should go to the reference if that is the second best. That's basically the prior I was talking about. The M2-only solution would be to use the somatic likelihoods model on the haplotypes and remove unsupported haplotypes from the likelihoods matrix. Similarly, I could use it to align reads to the haplotype with the greatest posterior probability.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4829#issuecomment-393547216:1252,simpl,simply,1252,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4829#issuecomment-393547216,1,['simpl'],['simply']
Usability,"The only place I’ve used them is in the malaria genotyping method, where we calculate very simple annotations for each set of breakpoints—mostly summary statistics of the posterior means, like the minimum in a segment or the segment-level mean. We also calculate a single changepoint statistic using the posterior means. Didn’t see any indicators that posterior sampling noise was causing any issues—the only real issue I had was fixed in #7261. I think the initial reason we started emitting these is because Talkowski folks wanted to use them for plotting/visualization, in which case I would be even less worried about sampling noise. But maybe you all are using them for something else now? Even then, not sure if anyone is using the posterior variances. If we ever move towards emitting this for somatic/mosaicism at the single-bin, percent level, then I might be a bit more worried—in which case, good for us for exposing it! But if you’d like to increase the default and it doesn’t seem to add significant runtime, go for it! Might also be good to get some understanding of the sampling noise level for typical data, if only for a few different parameter values.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5754#issuecomment-921954601:91,simpl,simple,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5754#issuecomment-921954601,1,['simpl'],['simple']
Usability,"The patch clears up the 503 failures due to `fetchSize()`, but we are STILL seeing 503's with other metadata operations such as `Files.exists()`:. ```; com.google.cloud.storage.StorageException: 503 Service Unavailable; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:335); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:586); at java.nio.file.Files.exists(Files.java:2385); at htsjdk.tribble.util.ParsingUtils.resourceExists(ParsingUtils.java:428); at htsjdk.tribble.AbstractFeatureReader.isTabix(AbstractFeatureReader.java:217); at htsjdk.tribble.AbstractFeatureReader$ComponentMethods.isTabix(AbstractFeatureReader.java:223); ```. I'm going to continue modifying the patch until we see all 503s go away, then post here once it's ready.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314813629:10,clear,clears,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314813629,1,['clear'],['clears']
Usability,"The previos message was written a bit quick from my phone. The concrete PR is https://github.com/samtools/htsjdk-next-beta/pull/12. @lbergelson - would like to have a look to it, or do you prefer that I open another one with the interface on top of the CIGAR part? I prefer to go step by step, as it is clearer than adding too many classes to review at once...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5267#issuecomment-428735904:303,clear,clearer,303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5267#issuecomment-428735904,1,['clear'],['clearer']
Usability,"The problem is that the catch block in `CommandLineProgram` is calling both `commandLineParser.usage()` and `printDecoratedUserExceptionMessage()` -- it should only be calling `commandLineParser.usage()`, and letting the catch block in `Main.mainEntry()` call `printDecoratedUserExceptionMessage()`. Otherwise there are cases where a `CommandLineException` will be caught without printing any error message. This is a bug and should be fixed. The distinction between ""errors that are the user's fault"" and ""errors that are not the user's fault"" is very important for our support team -- it allows them to deal with bug reports and forum questions much more efficiently. Whatever solution we come up with here should maintain that distinction, and clearly label errors like ""bad argument value"" as being a user error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268712938:747,clear,clearly,747,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268712938,1,['clear'],['clearly']
Usability,"The spark tools all end in `*Spark` and are in clearly marked groups that begin with `Spark*`, which seems pretty clear to me :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1291#issuecomment-163309365:47,clear,clearly,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1291#issuecomment-163309365,2,['clear'],"['clear', 'clearly']"
Usability,"The task here is to simply move the code while changing as little as possible, and then validate that. Once that's done, we can do whatever refactoring/changes we want to VQSR, or replace it completely.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2062#issuecomment-236014525:20,simpl,simply,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2062#issuecomment-236014525,1,['simpl'],['simply']
Usability,"The test failures in the branch build are clearly related to the recent travis key migration. The PR build (which is the one we care about) passes, so this should be safe to merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7393#issuecomment-953279491:42,clear,clearly,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7393#issuecomment-953279491,1,['clear'],['clearly']
Usability,"The tests would be very short-running, so each run should be cheap. Most of the runtime will be just spinning up the cluster. If someone malicious opened up a crazy number of PRs, he would at least quickly hit our travis quota limit which would slow him down considerably. We can look into whether other mechanisms exist on travis to deal with this sort of hypothetical situation. We do ideally want these tests to work with forked PRs, but if that's simply not going to be possible on travis then we'll obviously have to choose between having these tests in the same place as all of our other PR-related tests on travis and just skipping them for forked PRs, vs. having them in jenkins and requiring those making and reviewing PRs to deal with/check both CI environments. Let's meet early next week to chat about this issue and come to a decision.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2298#issuecomment-287544886:451,simpl,simply,451,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2298#issuecomment-287544886,1,['simpl'],['simply']
Usability,"The updates based on code review are done, but I need feedback on couple of questions above before I can finalize this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2182#issuecomment-251455000:54,feedback,feedback,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2182#issuecomment-251455000,1,['feedback'],['feedback']
Usability,"Their SNP priors are based on a point estimate of 1/1000 of being variant 0/1 or 1/1 and the 10^-3 is split between 0/1 1/1 with a 2:1 ratio. This is perhaps based on an empirical observation that the ""average"" human variant sites have a 2:1 het to hom-var ratio or simply to implement a flat prior between these two genotypes as there are two way to be a het and only one to be a hom-var. This is in high contrast with our vanilla priors which are based a AF prior and HardyWeinberg so HET would be roughtly 1/1000 and hom-var 1/1000000 !!! if the ratio of het to hom-var in the ""average"" human is close to 2:1 rather than 1000:1 then they are more right that we are. . The indel priors are based on their per-sample recalibration. . Priors are priors however simplistic or synthetic they are. And the posteriors are posterior the same. But yes, a more informative and correct prior should yield better posteriors. Answering to @ldgauthier old question (that I didn't really answer back then :P), I'm not aware if there is the possibility of provide a pop prior in DRAGEN, but is possible and a reasonable request. Now, the DRAGEN priors can be reconstructed from the reference sequence at the site, a couple of single value arguments and the DRAGstr model parameters that seats in a separate file (perhaps could be enclosed in the VCF header to make the vcf selfcontained). . The GP or (PP) is derived from PL and those priors so you don't really need those in the output. Another matter is the value that we use for the QUAL and the GT calls. Something that we have been doing wrong in vanilla GATK is to use the PL to fill GT (and perhaps GQ but I think that the VCF spec may be asking to do it that way not sure). Because it makes more (and perhaps only) sense to use posterior genotype probs to do so. By using the max PL we effectively setting a highly unrealistic flat uniform prior across genotypes. This only has a GT-noticeable effect on low coverage data though. For QUAL, vanilla GATK doe",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6269#issuecomment-790002197:266,simpl,simply,266,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6269#issuecomment-790002197,2,['simpl'],"['simplistic', 'simply']"
Usability,Then definitely have this tool fail with a clear explanation if there's no AF.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3955#issuecomment-351525468:43,clear,clear,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3955#issuecomment-351525468,1,['clear'],['clear']
Usability,Then they should be functions from `read -> ()` to make it clear that they operate via side effects I think.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/312#issuecomment-82514530:59,clear,clear,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/312#issuecomment-82514530,1,['clear'],['clear']
Usability,"There are pretty significant incompatibilities between java 8 and 11 that make it hard to run the same code on both. It affects a number of our dependencies which use features which were removed/altered from java 8 -> 11. Unfortunately despite there being significant pain in switching to 11 there aren't particularly compelling new features after 8 so there isn't much incentive for developers to move forward. That said, you CAN now run gatk on java 11 if you build it using java 11, the jars built on 8 are incompatible with 11 and vice a versa. We consider running on 11 to be a beta feature and would love to hear feedback about either success or failure.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6298#issuecomment-561371535:619,feedback,feedback,619,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6298#issuecomment-561371535,1,['feedback'],['feedback']
Usability,"There have been a few instances like this though. This one was obviously accidental, but things like the correct spelling of @magicDGS actual name seem like reasonable things to be able to include in the source. Also, testing non-ascii characters seems like something that is going to be increasingly common as we support new versions of the spec so it seems like we should learn to avoid this problem...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5936#issuecomment-492761095:374,learn,learn,374,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5936#issuecomment-492761095,1,['learn'],['learn']
Usability,"There is an existing method in GATKTool called getHeaderForSAMWriter that creates and populates the PG record, and it's called by GATKTool.createSAMWriter, so we already do this for BAMs that are created that way (which excludes the Picard tools). We should probably fix MarkDuplicates though. HaplotypeCaller and Mutect2 use HaplotypBAMWriter/SAMFileDestination/HaplotypeBAMDestination, all of which live in gatk, but create their own writers directly, so they need to be updated (and could probably be simplified a bit). We need a similar method for vcf header lines.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2269#issuecomment-278370291:504,simpl,simplified,504,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2269#issuecomment-278370291,1,['simpl'],['simplified']
Usability,"There is likely common code between the two, but we would need to pre-process the inputs to determine whether they are GVCFs: the merging algorithm is different for the two cases even if all input variants at a site are non-reference-blocks: see `ReferenceConfidenceVariantContextMerger.merge()` vs `GATKVariantContextUtils.simpleMerge()`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/16#issuecomment-66795521:324,simpl,simpleMerge,324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/16#issuecomment-66795521,1,['simpl'],['simpleMerge']
Usability,"There is. Gatk-launch should be handling --files for both yarn and dataproc. I think James found some bug with gatk-launch and multiple files passed in, can't remember exactly what it was but it should be a simple fix.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1689#issuecomment-234084913:207,simpl,simple,207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1689#issuecomment-234084913,1,['simpl'],['simple']
Usability,"There were a few issues with this case. First, the data source was not constructed 100% correctly. The config file is correct. . The index file is for the tar.gz version of the source data and not for the uncompressed version that they're using. The index should correspond to the source data in the file referenced by the config file itself (not a zipped or otherwise transformed version). Secondly, the source `tsv` data file has the header line for the table commented out. The Xsv codec is aware of leading hash marks as comments and will ignore any such lines. Because of this, the leading hash in the table header is ignored and the file cannot be properly parsed. The fix is simple - just remove the leading hash from the table header (the preceding line with the two hash marks is correctly interpreted as a file header because of the leading hashes acting as comments). Lastly, even if the user fixed the file they would still need to index it with`IndexFeatureFile`. At some point the code underlying this in `HTSJDK` was broken such that no Xsv files can currently be indexed. I have submitted a pull request in `HTSJDK` (https://github.com/samtools/htsjdk/pull/1429) for this and have another ready to go in GATK (#6224) that includes a test for this case so this reversion cannot happen again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6223#issuecomment-545186183:682,simpl,simple,682,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6223#issuecomment-545186183,1,['simpl'],['simple']
Usability,"They are all intact chromosomes. The ones still going are each one chromosome and happen to be the largest 4. Also, it isn't entirely clear if they are failing per se, just that they've been hanging for a week without anything obvious happening.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-654415271:134,clear,clear,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-654415271,1,['clear'],['clear']
Usability,"Think it might be worth saving a VariantFiltration pass for the bit of code it'd take, but up to you!. ScoreVariantAnnotations will output both the raw ""VQSLOD"" score and the converted sensitivity, so we're free to specify thresholds on either. However, given that different types of models may have scores in different ranges (e.g., BGMM vs. IsolationForest, positive/negative vs. positive-only, etc.), I think it's better to restrict all command-line options to be expressed in terms of a sensitivity. Same thing goes if you decide to filter externally with VariantFiltration for now. Even though you have both quantities available to you, just use the sensitivity. This brings us to questions related to whether we want to keep the old VQSR requirements of having both training and truth sets specified. For example, we could instead drop the distinction between training and truth for the new tools, and always calibrate sensitivity to the training set (you can essentially force this behavior with the current code by specifying training=true,truth=true for all of your resources). And yes, all of the tools should have a variety of command lines in the tests to demonstrate behavior. If you want to explore positive/negative mode, take a look at the *Unlabeled tests. Also feel free to ping me if anything isn't clear!. I'll push another round of minor updates here, too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1069376523:1318,clear,clear,1318,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1069376523,1,['clear'],['clear']
Usability,"This brings to us approximately 60 variants (without any filter applied). @cwhelan Please take time to review, another PR (supposedly dealing with simple ""translocation""s) is going to line up after this. Then the major graph-based one, but expected to take sometime to codeup. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3464#issuecomment-327882765:147,simpl,simple,147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3464#issuecomment-327882765,1,['simpl'],['simple']
Usability,"This can be described more simply as:. Ensure that intervals in GVCF traversals are END tag aware, so all reference blocks are included correctly. GATK3 considers start position only, so some reference blocks are missed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/265#issuecomment-99306834:27,simpl,simply,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/265#issuecomment-99306834,1,['simpl'],['simply']
Usability,"This can occur in cases where there was a mixup with the samples, meaning the user intended to run a properly matched normal/tumor pair, but there is a provenance error. This is how @asmoe4 and myself hit this issue. So this is not the same use case as #5821, where they know there's a deliberate mismatch. While we're not expecting the contamination check to provide something sensible in this case, may I suggest that the tool provides a user-friendly message to help debug, rather than a stack traceback. This could happen to other people if they have an accidental mismatch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483276300:440,user-friendly,user-friendly,440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483276300,1,['user-friendly'],['user-friendly']
Usability,"This difference of 20 makes sense theoretically. The old qual always has a heterozygosity prior of 1 in 1000, whereas new qual starts there but is willing to learn a different allele frequency. Very hand-wavingly, a difference of 20 or so means that new qual has learned an allele frequency in the ballpark of 1 in 10 (since log_10 1/10 = log_10 1/1000 + 2 and 2 --> 20 in phred scale). So basically, they only squeak by the old threshold because new qual has learned the *artifact* allele frequency as a true allele frequency. :thumbsup: for `stand-call-conf 30`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-395427599:158,learn,learn,158,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-395427599,3,['learn'],"['learn', 'learned']"
Usability,"This is a beta ticket -- for alpha we will just recommend conventions that promote composability when we write the guide in https://github.com/broadinstitute/gatk/issues/1016. For beta, we should probably create a Transform abstraction a la dataflow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/960#issuecomment-158207631:115,guid,guide,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/960#issuecomment-158207631,1,['guid'],['guide']
Usability,This is a very simple PR. Maybe @droazen or @lbergelson could have a quick look? Thank you very much.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2352#issuecomment-274518246:15,simpl,simple,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2352#issuecomment-274518246,1,['simpl'],['simple']
Usability,"This is a very simple patch, @cmnbroad. Could you have a look?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-268280677:15,simpl,simple,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-268280677,1,['simpl'],['simple']
Usability,"This is a very simple path, @lbergelson. Could you have a look?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2260#issuecomment-268280390:15,simpl,simple,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2260#issuecomment-268280390,1,['simpl'],['simple']
Usability,This is currently in development at Intel -- should be usable within a quarter.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1812#issuecomment-287792231:55,usab,usable,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1812#issuecomment-287792231,1,['usab'],['usable']
Usability,"This is difficult to review because there isn't any client code: I don't know how this is going to be used. I suspect I'd have a lot of ""YAGNI"" comments if I knew.; For example, you are basing all your implementations on Apache's AbstractIntegerDistribution. That class, it seems to me, is really intended to allow you to do sampling from a distribution. But I suspect you won't be sampling, you'll only be asking questions about density. If so, there's a lot of baggage that gets pulled into your anonymous implementations of this class: random number generators, boundary information, etc. Lots of extra boilerplate. Couldn't this be clearer if reorganized as an abstract class implementing AbstractIntegerDistribution, 3 concrete classes for each case (rather than the current anonymous classes), a factory that takes a spec and returns the correct distribution, and a simple enum class?. It seems weird that the distributions you allow users to realize using a spec are both two-tailed distributions, when fragment size is a one-tailed distribution. It seems awkward that failure to parse a distribution spec leads to a code path where you try to extract a file name and read serialized read metadata. Wouldn't it be clearer to have two completely distinct code paths with a different program argument for the empirical case?. The read metadata gives per library distributions. It seems suspect that you are folding them all together. Different libraries can have rather different fragment size stats. Still don't like that you're providing the possibility of reading the metadata text file. Seems fragile. Why don't you modify the ReadMetadata code to always produce just the data you need. Then you could eliminate the text-file code. And you could simplify the code that processes the serialized ReadMetadata which now has this awkward code path: CDF -> density -> sum across libs -> density+CDF stored in memory. If you have the CDF you can trivially produce density on demand. Notwithstanding",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4827#issuecomment-418420706:636,clear,clearer,636,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4827#issuecomment-418420706,2,"['clear', 'simpl']","['clearer', 'simple']"
Usability,This is great! We can solicit feedback on style at the Methods meeting as well. Feel free to spin off low-priority TODOs into issues that we can leave for after release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-344587173:30,feedback,feedback,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-344587173,1,['feedback'],['feedback']
Usability,"This is probably affecting some of the GWAS studies but in subtle ways that; haven't popped up yet. I'm cc'ing Andrea in the hopes that he has some time; to think about the issue. I'd need some uninterrupted time to work out the; details and that's hard to come by at the moment. On Feb 11, 2017 12:21 AM, ""chlangley"" <notifications@github.com> wrote:. > Thanks for getting this cleared up.; > OK, what next? I'll check with colleagues who may be aware this 'feature'.; > Perhaps the case can be made more clearly by a group of users, including; > visible labs working on human evolutionary genomics.; >; > I don't know the CA genomics community well, but my shallow poling; > suggests most are happily unaware that SNPs near indels will often be; > assigned lower quality than they might.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/269#issuecomment-279122551>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdNaqeg_h2KxcxGULyoiSO3D8EY9eks5rbUVogaJpZM4DrC8o>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/269#issuecomment-279249883:379,clear,cleared,379,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/269#issuecomment-279249883,2,['clear'],"['cleared', 'clearly']"
Usability,"This is the keypoint. ; ""Merging the gVCFs generated by HaplotypeCaller, DeepVariant, BCFtools mpileup&call and FreeBayes. "". CombineGVCFs tool's aim is not to combine GVCFs from different sources. The tool can only work with GVCFs from HaplotypeCaller. . For us to understand the issue clearly we need to get the actual command line for HaplotypeCaller for generating the GVCF file. GVCFs generated by other tools are not our concern therefore if you are doing something outside of GATK domain we cannot help. . There may be other tools doing this kind of work but we don't have extensive information on them and we cannot debug their issues either.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7147#issuecomment-1755490839:287,clear,clearly,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7147#issuecomment-1755490839,1,['clear'],['clearly']
Usability,"This issue only happens in genomes with a large number of chromosomes, such as hg38. b37 and hg19 are fine. workaround: `--conf spark.driver.extraJavaOptions=-Xss2m --conf spark.executor.extraJavaOptions=-Xss2m`. debug log:; ```; ...; 00:05 DEBUG: [kryo] Write object reference 100367: HLA-DRB1*15:03:01:01; 00:05 DEBUG: [kryo] Write object reference 100369: HLA-DRB1*15:03:01:02; 00:05 DEBUG: [kryo] Write object reference 100371: HLA-DRB1*16:02:01; 21/09/12 22:10:49 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040; 21/09/12 22:10:49 INFO StandaloneSchedulerBackend: Shutting down all executors; 21/09/12 22:10:49 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 21/09/12 22:10:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 21/09/12 22:10:49 INFO MemoryStore: MemoryStore cleared; 21/09/12 22:10:49 INFO BlockManager: BlockManager stopped; 21/09/12 22:10:49 INFO BlockManagerMaster: BlockManagerMaster stopped; 21/09/12 22:10:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 21/09/12 22:10:49 INFO SparkContext: Successfully stopped SparkContext; 22:10:49.533 INFO HaplotypeCallerSpark - Shutting down engine; [September 12, 2021 10:10:49 PM CST] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.09 minutes.; Runtime.totalMemory()=1788346368; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.util.MapReferenceResolver.useReferences(MapReferenceResolver.java:70); at com.esotericsoftware.kryo.Kryo.writeReferenceOrNull(Kryo.java:665); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:570); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectFiel",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-917650984:858,clear,cleared,858,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-917650984,1,['clear'],['cleared']
Usability,"This makes probably at least 214-59=155 test fail. The first one is [assertMatchingAnnotationsFromGenomicsDB_newMQformat](https://github.com/broadinstitute/gatk/blob/423d106612074aa3480b67b321dc66426b1c600a/src/test/java/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFsIntegrationTest.java#L405):; ```; assertMatchingAnnotationsFromGenomicsDB_newMQformat[0](src/test/resources/org/broadinstitute/hellbender/tools/GenomicsDBImport/expected.testGVCFMode.gatk4.g.vcf, src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/newMQcalc.singleSample.genotyped.vcf, 20:1-11000000, src/test/resources/large/human_g1k_v37.20.21.fasta); java.lang.AssertionError: Genotype string expected [C*|T] but found [T|C*]; 	at org.testng.Assert.fail(Assert.java:97); ```. However looking at the input file and the expected output file it is clear that the expected output is wrong here (`:PL:PS `**`0|1`**`:23,38:61:99:1` in the last line) and this PR does the right thing instead:; ```; # input:; $ bcftools view org/broadinstitute/hellbender/tools/GenomicsDBImport/expected.testGVCFMode.gatk4.g.vcf | grep -e '1|0' -e ""10007150""; 20 10007150 . G C,<NON_REF> 669.77 . BaseQRankSum=-4.476;DP=63;ExcessHet=3.0103;MLEAC=1,0;MLEAF=0.5,0;MQRankSum=0;RAW_MQandDP=226800,63;ReadPosRankSum=-0.077 GT:AD:DP:GQ:PGT:PID:PL:PS:SB 0|1:38,25,0:63:99:0|1:10007150_G_C:698,0,1479,813,1554,2366:10007150:16,22,14,11; 20 10007175 . C T,<NON_REF> 1350.77 . BaseQRankSum=2.249;DP=61;ExcessHet=3.0103;MLEAC=1,0;MLEAF=0.5,0;MQRankSum=1.319;RAW_MQandDP=216841,61;ReadPosRankSum=-1.213 GT:AD:DP:GQ:PGT:PID:PL:PS:SB 1|0:23,38,0:61:99:1|0:10007150_G_C:1379,0,780,1448,894,2343:10007150:9,14,18,20; #""expected"" output (wrong):; $ bcftools view org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/newMQcalc.singleSample.genotyped.vcf | grep -e '1|0' -e ""10007150""; 20 10007150 . G C 690.64 . AC=1;AF=0.5;AN=2;BaseQRankSum=-4.476;DP=63;ExcessHet=0;FS=5.048;MLEAC=1;MLEAF=0.5;MQ=60;MQRankSum=0;QD=10.96;ReadPosRank",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8570#issuecomment-1784915555:851,clear,clear,851,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8570#issuecomment-1784915555,1,['clear'],['clear']
Usability,"This seems like a consequence of the fact that we use `java.nio.file.Path`for a lot of things in gatk. This requires a custom `java.nio.file.spi.FileSystemProvider` to be available for each type of path you want to be able to resolve. Spark native uses `org.apache.hadoop.fs.Path` for a lot of things. It's seems likely that that maprfs provides a hadoop file system plugin, which many spark applications can consume, but it's unlikely that it also provides a java.nio.file.Path implementation. ; ; I don't think we'd be able to implement a provider for maprfs ourselves. We don't have any systems with maprfs and don't have the bandwidth to take it on right now. Implementing a file system provider isn't a terribly complicated project, but it's not a trivial one either. However, there's an implementation for hadoop here https://github.com/damiencarol/jsr203-hadoop which is sufficient for what gatk does. If maprfs provides a hadoop file system, it would probably not be too difficult to take that project as a template and modify it to use the maprfs implementation. . I think the only things you'd have to implement for the spark tools to work are the basic Path operations that support the simple operations like `Paths.get()`,`Files.exists()`, and `Path.resolve()`. (although that's not a complete list. . If you are interested in writing a plugin like that, you can add it to the gatk class path at runtime. We might also be open to packaging such a plugin with the gatk if there was wide demand for it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3936#issuecomment-350070555:1197,simpl,simple,1197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3936#issuecomment-350070555,1,['simpl'],['simple']
Usability,This should be fixed in the next release as we are now on Picard 2.25.4 in master via #7255. If you need a docker build with an updated picard dependency I would suggest checking out our nightly builds gs://gatk-nightly-builds which should have an up-to-date version of master soon or simply waiting for the next release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7254#issuecomment-841405791:285,simpl,simply,285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7254#issuecomment-841405791,1,['simpl'],['simply']
Usability,"This task is to take the training data generated in issue #3092 and learn something from it, for example a regression model that predicts a distribution of artifactual read fractions. Using the learned model in filtering is a separate issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2973#issuecomment-307680993:68,learn,learn,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2973#issuecomment-307680993,2,['learn'],"['learn', 'learned']"
Usability,This ticket should be fairly simple once https://github.com/broadinstitute/gatk/issues/1988 is implemented.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1558#issuecomment-231765000:29,simpl,simple,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1558#issuecomment-231765000,1,['simpl'],['simple']
Usability,"To add some commentary to why this is happening: It looks like multiple threads are hitting this line simultaneously and based on the overload of `ArrayList.add()` this error could be triggered by multiple calls to `ensureCapacityInternal()` inside the add method:; ```; final List<ReadsPathDataSource> readSources = new ArrayList<>(threads);; final ThreadLocal<ReadsPathDataSource> threadReadSource = ThreadLocal.withInitial(; () -> {; final ReadsPathDataSource result = new ReadsPathDataSource(readArguments.getReadPaths(), factory);; readSources.add(result);; return result;; });; ```; The fix should be simple you just have to make sure ti synchronize the initialization or swap out the readSources object to one that is itself thread safe. @vruano",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7403#issuecomment-899732721:607,simpl,simple,607,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7403#issuecomment-899732721,1,['simpl'],['simple']
Usability,"To add, just in case it wasn't clear, note that this is almost certainly overkill for most somatic applications. However, if this is going to double as a more lightweight germline pipeline (as it is for the time being, as we are using some of the results to prototype SV integration), it might be worthwhile.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4728#issuecomment-386269562:31,clear,clear,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4728#issuecomment-386269562,1,['clear'],['clear']
Usability,"To be clear, this will work perfectly fine as long as you have enough space in /dev/shm---which is typically true everywhere outside of our default Docker container. I'm loath to cripple a tool just because of limitations that are fundamentally elsewhere...let's just address those in the appropriate places. (Furthermore, I'm especially loath to write a plotting tool that takes ~5 minutes to generate a plot!) And yes, while it is not great that data.table forces us to use /dev/shm, I think `fread(""grep ..."")` is relatively standard. If `--shm-size` is indeed not exposed, why doesn't the Google backend scale /dev/shm or other tmpfs space with requested machine memory?. If there really is no other way around it, then all we're doing is filtering out the lines beginning with `@`. We could do this first by calling system commands within R to write to a temporary file, and then reading that back in with fread. This seems hacky to me, but I've confirmed that it works within the Docker. This will solve our immediate problem, but I still think it's worth taking a look at those other limitations elsewhere now as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357337827:6,clear,clear,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357337827,1,['clear'],['clear']
Usability,"To be clear, when I learned to use VariantFiltration 1.5 years ago, I was told to use the `&&` and `||` expressions and _no other formatting_. This may have been alright in GATK3 (I did not check), but it seems in GATK4 it is not.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5362#issuecomment-433233584:6,clear,clear,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5362#issuecomment-433233584,2,"['clear', 'learn']","['clear', 'learned']"
Usability,To be clear: I really appreciate the help from the GATK and GenomicsDB teams. There has just been a lot of problem and issues trying to make GenomicsDB work for this dataset,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1211424808:6,clear,clear,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1211424808,1,['clear'],['clear']
Usability,"To be fair, @vruano suggested the solution and I am simply writing code to try to make the allele-trimming work.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1868#issuecomment-223043508:52,simpl,simply,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1868#issuecomment-223043508,1,['simpl'],['simply']
Usability,"To be honest, I don't have a clear idea of why this is happening. I tried running a query with 1000 samples using the same GenomicsDB jar that GATK uses and the memory consumption stayed below 1 GB. Some suggestions/questions:; * If you were importing/querying multiple intervals at once, I would expect #4994 to be relevant. But your script shows a single interval being imported/queried.; * Would it be possible to run the SelectVariants tool using the GenomicsDB workspace as input and see how much memory is being consumed (instead of GenotypeGVCFs)? The Select tool simply extracts the data from GenomicsDB and prints out a VCF.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5024#issuecomment-406750537:29,clear,clear,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5024#issuecomment-406750537,2,"['clear', 'simpl']","['clear', 'simply']"
Usability,"To be perfectly clear, do you mean high/low confidence or high/low complexity?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-713582631:16,clear,clear,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-713582631,1,['clear'],['clear']
Usability,"To clarify this ticket: in `GATKTool.initializeReads()`, just check `readArguments.getReadFiles()` for files ending with a cram extension (should see if there's a canonical method in htsjdk for checking whether a file is cram) -- if you find any and we don't have a reference according to `hasReference()`, throw a `UserException` with a clear error message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/673#issuecomment-125265449:338,clear,clear,338,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/673#issuecomment-125265449,1,['clear'],['clear']
Usability,"To reiterate, for me, GenotypeGVCFs 4.2.4.1 gives an ```IllegalStateException``` at the exact same place regardless of whether I run GenomicsDBImport 4.2.4.0 (with the 50 max allele bug) or GenomicsDBImport 4.2.4.1 (with the fix to respect 6 max alleles). As far as I can tell, the ```IllegalStateException``` has nothing to do with GenomicsDBImport, it's simply a new bug in GenotypeGVCFs 4.2.4.1 that happens to occur when the number of ALT alleles is 1 more than the limit set in GenotypeGVCFs. As @mlathara stated: ""the AF calculation [in GenotypeGVCFs] used to [in 4.2.4.0] ignore sites if they didn't have likelihoods, but has now been updated slightly [in 4.2.4.1] to also allow sites with GQ or sites where any alleles are called+nonref+not symbolic. The stack traces above show the AlleleFrequencyCalculator as the culprit:; ```; java.lang.IllegalStateException: Genotype [T199970 ATATATAT/T GQ 49 DP 4 AD 0,2,0,0,0,2,0,0 {SB=0,0,2,2}] does not contain likelihoods necessary to calculate posteriors.; 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AlleleFrequencyCalculator.log10NormalizedGenotypePosteriors(AlleleFrequencyCalculator.java:89); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AlleleFrequencyCalculator.effectiveAlleleCounts(AlleleFrequencyCalculator.java:258); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AlleleFrequencyCalculator.calculate(AlleleFrequencyCalculator.java:141); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1023545370:356,simpl,simply,356,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1023545370,1,['simpl'],['simply']
Usability,"To summarize current state of discussions - we're going to have 3 repos, as originally planned (1 for the interfaces and 2 for Intel and IBM implementations, respectively). There will be a bit code duplication but many other aspects (some technical, some organizational) are massively simplified by such architecture. . @droazen @lbergelson @gspowley @paolonarvaez @frank-y-liu @t-ogasawara - please use this ticket to comment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1788#issuecomment-216545820:285,simpl,simplified,285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1788#issuecomment-216545820,1,['simpl'],['simplified']
Usability,"Two questions:. `getMaxClusterableStartingPositionWithParams` in `CanonicalSVLinkage` uses the `window` to determine the max clusterable position. Will setting the value to 10MB make everything look clusterable to this method, potentially bogging down the algorithm for large callsets?. Is there a reason to keep the keep the old code around if this is the intended way to disable the proximity check (setting the window very large)? Seems like an opportunity to simplify if you don't want to support that special case anymore.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8962#issuecomment-2342036804:463,simpl,simplify,463,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8962#issuecomment-2342036804,1,['simpl'],['simplify']
Usability,"Unfortunately I don't think it's practical to try to enforce that ""only the arg parser can throw `CommandLineException`"" -- there's too much downstream code and too many tools that do so already, so it would be a bit painful to treat it as a bug. Instead I think what we should do is:. * Make sure that barclay uses a separate exception class for internal errors that are not the user's fault. This internal exception class should not be usable outside of barclay (perhaps we can make it package-private?).; * Catch `CommandLineException` in GATK and present it as a user error (output should say ""A USER ERROR HAS OCCURRED"").; * Move the `printDecoratedUserExceptionMessage()` call for caught `CommandLineExceptions` from `CommandLineProgram.parseArgs()` to `Main.mainEntry()`, to ensure that a message always gets printed for `CommandLineException`. As @cmnbroad said, this will have to wait until after the holiday break (most of us are going to be away until early January).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268828854:438,usab,usable,438,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268828854,1,['usab'],['usable']
Usability,"Update on the gene list format discussion: We recently in added GFF3 support in HTSJDK and one possible path forwards for supporting more general gene list formate for DoC would be to leverage the existing implementation that was included in #6602 to allow a second source of gene objects. This could be trivially implemented if we wanted to follow the same approach as #6602 where we simply farm the decision about what feature type is important out to the user to specify. This would mean that if the user cares about genes they could specify a count for each gene object with its reported boundaries that would be output as a line. This is similar but not analogous to the current behavior for the existing gene lists where we take pains to exclude from the overlap counts bases that are intronic bases in the gene list. . Unfortunately, since the GFF3 format is hierarchical and supports a very large number of feature types it will be very difficult to extract the intron/exon boundaries without properly parsing the GFF3 format. The GFF3 format supports .obo files that lay out the feature hierarchy and through parsing of that format it would be possible to extract intron/exon boundaries but that is not currently supported by HTSJDK and would involve us merging https://github.com/kachulis/htsjdk/tree/ck_gff3_feature_evaluator first in order to support and then on top of that coming up with some rules for deciding what units exactly make up a gene that should be merged for coverage counting. . I see a few options going forwards:; - We could support GFF3 gene lists with hard coded genes/CDS features to be included. This is brittle given that there are a number of more specific names for CDS (coding sequence) exons in genes that might end up being excluded.; - We could support GFF3 format but ignore exon sequences which would mean that the behavior for counting the same genes will vary depending on which format the gene is provided.; - We could support GFF3 gene lists but allow th",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6491#issuecomment-683963413:385,simpl,simply,385,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6491#issuecomment-683963413,1,['simpl'],['simply']
Usability,"Update: we have a PoC impl. working with sharded writing and simple indexing implementation in https://github.com/googlegenomics/dataflow-java/tree/sharded-bam-writer , need to do some more benchmarking and merge to main branch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/621#issuecomment-132294611:61,simpl,simple,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/621#issuecomment-132294611,1,['simpl'],['simple']
Usability,"Updated plan. ----------; ## Small improvements in new interpretation tool; ; - [x] Output bam instead of sam for assembly alignments; - [x] Instead of creating directory, new interpretation tool writes files (behavior consistent with current interpretation tool); - [x] Prefix with sample name for output files' names; - [x] Add `INSLEN` annotation when there's `INSSEQ`; - [x] Clarify the boundary between `AlignedContig` and `AssemblyContigWithFineTunedAlignments`; - [x] Increase test coverage for `AssemblyContigAlignmentsConfigPicker`; ; ----------; ## Consolidate logic, bump test coverage and update how variants are represented. ### consolidate logic; When initially prototyped, there's redundancy in logic for simple variants, now it's time to consolidate. - [x] `AssemblyContigWithFineTunedAlignments`; - [x] `hasIncompletePicture()`. - [x] `AssemblyContigAlignmentSignatureClassifier`; - [x] Don't make so many splits; - [x] Reduce `RawTypes` into fewer cases; ; - [x] `ChimericAlignment`; - [x] update documentation; - [x] implement a `getCoordinateSortedRefSpans()`, and use in `BreakpointsInference`; - [x] `isNeitherSimpleTranslocationNorIncompletePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:720,simpl,simple,720,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021,1,['simpl'],['simple']
Usability,"Upon speaking with @davidbenjamin, it has become clear that perhaps changing `--max-genotype-count` is not the best solution, as that value is intended to bound our PL arrays from being excessively expanded. It is clear that instead if the user is looking to extract Allele Counts from their Pooled sample it would be best for the user to instead run Mutect, as that should sidestep the maximum of 2 Alleles per site problem that we observed. @bhanugandham",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5994#issuecomment-511935395:49,clear,clear,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5994#issuecomment-511935395,2,['clear'],['clear']
Usability,"User is reporting a nearly exact 2 minute pause at tool startup. Seems very suspicious, possibly some sort of gcs operation trying and timing out?. ```; 14:33:39.416 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/gatk-package-4.beta.3-local.jar!/com/intel/gkl/native/libgkl_compression.so; 14:35:46.843 INFO BaseRecalibrator - HTSJDK Defaults.COMPRESSION_LEVEL : 5; 14:35:46.843 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:35:46.843 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 14:35:46.844 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:35:46.844 INFO BaseRecalibrator - Deflater: IntelDeflater; 14:35:46.844 INFO BaseRecalibrator - Inflater: IntelInflater; 14:35:46.844 INFO BaseRecalibrator - GCS max retries/reopens: 20; 14:35:46.844 INFO BaseRecalibrator - Using google-cloud-java patch 317951be3c2e898e3916a4b1abf5a9c220d84df8; 14:35:46.844 INFO BaseRecalibrator - Initializing engine; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-325211756:42,pause,pause,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-325211756,1,['pause'],['pause']
Usability,"Using the latest version of ADAM (which has a Scala 2.12 version) fixes the 2bit failures. I also added a fix for the `java.nio.ByteBuffer.clear()` problem. All unit tests are passing, and the only integration test failures are the `Could not serialize lambda` problems. It should be possible to fix these by making the relevant classes implement `Serializable` (like in https://github.com/samtools/htsjdk/pull/1408).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-527483090:139,clear,clear,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-527483090,1,['clear'],['clear']
Usability,"Very funny! Closing, since this is clearly meant as a joke. Let's discuss after alpha ways to actually slim down our dependencies.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1120#issuecomment-157435278:35,clear,clearly,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1120#issuecomment-157435278,1,['clear'],['clearly']
Usability,"VsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-18.75%)` | `6% <0%> (ø)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...71c03a3e81f2df635e709823e1c1de96a2f5ffb5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...71c03a3e81f2df635e709823e1c1de96a2f5ffb5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...71c03a3e81f2df635e709823e1c1de96a2f5ffb5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `77.6% <0%> (-9.6%)` | `28% <0%> (-8%)` | |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/2467?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2467?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2467?src=pr&el=footer). Last update [e1e71d7...71c03a3](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...71c03a3e81f2df635e709823e1c1de96a2f5ffb5?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2467#issuecomment-287565894:4846,learn,learn,4846,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2467#issuecomment-287565894,1,['learn'],['learn']
Usability,"W9uVGVzdC5qYXZh) | `1.66% <0%> (-98.34%)` | `1% <0%> (-5%)` | |; | [...on/FindBreakpointEvidenceSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `1.75% <0%> (-98.25%)` | `1% <0%> (-6%)` | |; | [...bender/tools/spark/PileupSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QaWxldXBTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `2.04% <0%> (-97.96%)` | `2% <0%> (-13%)` | |; | [...tute/hellbender/tools/FlagStatIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9GbGFnU3RhdEludGVncmF0aW9uVGVzdC5qYXZh) | `2.08% <0%> (-97.92%)` | `1% <0%> (-5%)` | |; | [...rs/variantutils/SelectVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9TZWxlY3RWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `0.25% <0%> (-97.75%)` | `1% <0%> (-70%)` | |; | ... and [154 more](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5760?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5760?src=pr&el=footer). Last update [1d6f5b3...d98f9dc](https://codecov.io/gh/broadinstitute/gatk/pull/5760?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5760#issuecomment-469855399:4615,learn,learn,4615,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5760#issuecomment-469855399,1,['learn'],['learn']
Usability,"WRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9FdmlkZW5jZVRhcmdldExpbmsuamF2YQ==) | `70.51% <0%> (-4.12%)` | `18% <0%> (+2%)` | |; | [...ools/copynumber/CreateReadCountPanelOfNormals.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NyZWF0ZVJlYWRDb3VudFBhbmVsT2ZOb3JtYWxzLmphdmE=) | `86.07% <0%> (-3.93%)` | `11% <0%> (+2%)` | |; | [...er/tools/copynumber/formats/records/CopyRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvcmVjb3Jkcy9Db3B5UmF0aW8uamF2YQ==) | `74.35% <0%> (-1.65%)` | `17% <0%> (+8%)` | |; | [...ellbender/tools/walkers/annotator/QualByDepth.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9RdWFsQnlEZXB0aC5qYXZh) | `95.74% <0%> (-1.56%)` | `20% <0%> (+3%)` | |; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluLmphdmE=) | `70.62% <0%> (-1.32%)` | `71% <0%> (+26%)` | |; | ... and [170 more](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4498?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4498?src=pr&el=footer). Last update [9eb1704...ff52e6b](https://codecov.io/gh/broadinstitute/gatk/pull/4498?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4498#issuecomment-370663327:4415,learn,learn,4415,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4498#issuecomment-370663327,1,['learn'],['learn']
Usability,"WRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <ø> (-62.264%)` | `8% <ø> (+8%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...b1802b27996e3b0ee8a1b4a035a8ac78282b8666?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <ø> (-60.87%)` | `2% <ø> (+2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...b1802b27996e3b0ee8a1b4a035a8ac78282b8666?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `44.444% <ø> (-29.861%)` | `28% <ø> (+28%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...b1802b27996e3b0ee8a1b4a035a8ac78282b8666?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <ø> (-23.729%)` | `0% <ø> (ø)` | |; | ... and [15 more](https://codecov.io/gh/broadinstitute/gatk/pull/2385/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2385?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2385?src=pr&el=footer). Last update [14f73e2...b1802b2](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...b1802b27996e3b0ee8a1b4a035a8ac78282b8666?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2385#issuecomment-279409892:4899,learn,learn,4899,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2385#issuecomment-279409892,1,['learn'],['learn']
Usability,"Was this issue ever resolved, or was the problem clearly identified? I am currently experiencing this error, but any help would be appreciated.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-752792318:49,clear,clearly,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-752792318,1,['clear'],['clearly']
Usability,"We can add this as an option, but I think there are a few arguments against outright replacement (which may have led to this design decision in the first place):. 1) I don't believe any CNV tools take in sample name as input at the GATK command line, by design. We instead take the BAM basename as the entity ID during the CollectCounts task; this ID is then passed along at the WDL level and is only used to construct the filenames of output files. This obviates the need for tools like GetSampleName and avoids issues with parsing funky sample names at the command line, handling/passing special characters at all levels (WDL, Java, python), etc. (The implicit assumption is that the BAM basename is more likely to be well formed.). 2) I would argue that specifying a sample index is relatively user friendly, especially if we are typically running on all samples. In that case, all you need to know is the total number of samples and that we use zero indexing, and then you simply iterate over all indices. (If you want to run on a single, particular sample, then perhaps using the sample name might be more friendly, but I'd argue that this use case is not typical.). 3) If you want to go ahead and add this option, I would probably keep the directory structure of the GermlineCNVCaller output the same (i.e., with folders named ""SAMPLE_#""), and just check the sample_name.txt files at the PostprocessGermlineCNVCalls step. I don't think this should require GermlineCNVCaller code changes, right?. 4) We may require additional code at the WDL level if we want to both switch over to primarily using sample names but also get rid of bundling (i.e., by passing only the calls for each sample when needed). Locally, you can always just search all output for directories containing the appropriate sample_name.txt. But on the cloud, you'd want to make sure that the postprocessing step for a particular sample gets only its corresponding directories, which would have to happen at the WDL level; the c",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6659#issuecomment-644829765:977,simpl,simply,977,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6659#issuecomment-644829765,1,['simpl'],['simply']
Usability,"We can certainly modify IntervalListTools to make the behavior more intuitive (e.g. add a new mode for `INTERVAL_COUNT_WITH_OVREFLOW`), but I'm not sure I understand the issue. We're just trying to avoid calling the GATK command if the scatter is going to be a noop?. The GATK SplitIntervals has slightly different behavior that's helpful in some cases.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6502#issuecomment-599618889:68,intuit,intuitive,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6502#issuecomment-599618889,1,['intuit'],['intuitive']
Usability,"We can implement this, but first can you explain why your `canDecode()` methods can't unambiguously detect your file formats? The VCF/BCF codecs use a magic value at the start of the file to detect the format -- are your codecs guessing as to the intended format? Is there no way to be sure what the format is?. If we have multiple codecs able to decode a file, and only one produces `Features` that match the type parameter of the `FeatureInput`, would it solve your problem if we selected that codec rather than blow up? This would be a bit simpler/easier than a new annotation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1184#issuecomment-163297503:543,simpl,simpler,543,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1184#issuecomment-163297503,1,['simpl'],['simpler']
Usability,"We decided to remove the ""conversion"" to AllelicCapseg output from ModelSegments, since this was an ill defined procedure. The models used by AllelicCapseg and AllelicCNV/ModelSegments are simply different, so it's not possible to define a unique conversion between their model parameters. Compounding this, we also had difficulty finding up-to-date documentation about the models used by various versions of both AllelicCapseg and ABSOLUTE. That said, some of this removed functionality can be found in unsupported WDLs at https://github.com/broadinstitute/gatk/tree/master/scripts/unsupported/combine_tracks_postprocessing_cnv (specifically, see the PrototypeACSConversion task in combine_tracks.wdl). These scripts also attempt to perform rudimentary filtering of germline events found in the matched normal; see first link below for some additional caveats. Note that we cannot really answer further questions or otherwise support these scripts (and it's possible that the experimental/beta GATK tools used in the WDLs may be removed in the future), and the developer responsible for them has moved on from the Broad---use them at your own risk. See also https://gatkforums.broadinstitute.org/gatk/discussion/comment/59467 https://github.com/broadinstitute/gatk/pull/5450 https://github.com/broadinstitute/gatk/issues/5804 for additional context.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6685#issuecomment-652407603:189,simpl,simply,189,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6685#issuecomment-652407603,1,['simpl'],['simply']
Usability,"We decided to replace SparkGenomeReadCounts with a relatively simple ReadWalker to avoid various bugs we were running into (some of which were due to Hadoop-BAM). We found that these bugs gave rise to a relatively high failure rate---roughly 1 in 50 TCGA BAMs. Like any ReadWalker, you can specify custom read filters using GATK engine arguments such as `--disable-default-read-filters` and `--read-filter ...` However, because we count fragment centers (rather than read starts, as in SparkGenomeReadCounts), disabling filters which check that reads are properly paired may lead to unexpected behavior. In principle, we could write a similar ReadWalkerSpark version of the tool. However, our experience running the tool showed that CollectFragmentCounts was already faster than SparkGenomeReadCounts in Spark local mode, sometimes by a factor of ~5 (and, more importantly, it didn't run into Hadoop-BAM failures). We may do some more careful profiling and roll a ReadWalkerSpark version in the future, but these aren't too high priority at the moment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4185#issuecomment-358660583:62,simpl,simple,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4185#issuecomment-358660583,1,['simpl'],['simple']
Usability,"We don't yet have good regression tests for Spark that run on a cluster and are separate from the jenkins performance tests. https://github.com/broadinstitute/gatk/issues/2298 will satisfy part of the requirements for this ticket once it's done (by catching the most basic regressions before merge), but there's also a need for larger-scale correctness tests whose status is clearly visible on github.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2288#issuecomment-287473713:375,clear,clearly,375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2288#issuecomment-287473713,1,['clear'],['clearly']
Usability,"We ended up using jopt-simple alongside some of our existing code. It was chosen somewhat arbitrarily after examining a number of different options. It supports arguments on the style that we wanted, is under active development, and was easy to plug into our existing code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/72#issuecomment-71662187:23,simpl,simple,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/72#issuecomment-71662187,1,['simpl'],['simple']
Usability,"We have discussed this and I have shown @lbergelson the error of his ways ;). Admittedly I'm still working on improving the presentation of content on the website -- but user feedback suggests they find the current site far superior to the old wiki. Also, I hate wikis. Also also, Louis was mostly complaining about the dev zone and queue docs, which do suck.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1049#issuecomment-151957099:175,feedback,feedback,175,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1049#issuecomment-151957099,1,['feedback'],['feedback']
Usability,We'll need a simple build system + README + documented release procedure.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2208#issuecomment-253618598:13,simpl,simple,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2208#issuecomment-253618598,1,['simpl'],['simple']
Usability,"We're going to release the new model in 3.7 and have users test-drive that for quite a bit before we move to release 4.0, so we should be able to get some feedback on performance in the wild before we need to make any final decisions.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2255#issuecomment-258412589:155,feedback,feedback,155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2255#issuecomment-258412589,1,['feedback'],['feedback']
Usability,"We've filed a ticket with github support -- however, the branch has been cleared to merge in its current state, as it's had more than enough reviews. We can file tickets to improve/refactor once it's in master.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3945#issuecomment-351092625:73,clear,cleared,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3945#issuecomment-351092625,1,['clear'],['cleared']
Usability,"We've had to do that in other places... On Fri, Jan 12, 2018 at 3:20 PM, samuelklee <notifications@github.com>; wrote:. > To be clear, this will work perfectly fine as long as you have enough; > space in /dev/shm---which is typically true everywhere outside of our; > default Docker container.; >; > I'm loath to cripple a tool just because of limitations that are; > fundamentally elsewhere...let's just address those in the appropriate; > places. (Furthermore, I'm especially loath to write a plotting tool that; > takes ~5 minutes to generate a plot!) And yes, while it is not great that; > data.table forces us to use /dev/shm, I think fread(""grep ..."") is; > relatively standard.; >; > If --shm-size is indeed not exposed, why doesn't the Google backend scale; > /dev/shm or other tmpfs space with requested machine memory?; >; > If there really is no other way around it, then all we're doing is; > filtering out the lines beginning with @. We could do this first by; > calling system commands within R to write to a temporary file, and then; > reading that back in with fread. This seems hacky to me, but I've confirmed; > that it works within the Docker. This will solve our immediate problem, but; > I still think it's worth taking a look at those other limitations elsewhere; > now as well.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357337827>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXkxNvcMcJfIhdlPhdU3vLHTiAVPPSks5tJ76mgaJpZM4RclpR>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357349198:128,clear,clear,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357349198,1,['clear'],['clear']
Usability,"We've run some basic WGS tests in gatk-sv, and the results look good. Using our 161-sample 30x NYGC 1KGP test panel, here is a summary of per-sample raw calls from gCNV+cnMOPs. That is, records look like:. ```; chr1	103639835	103663835	1kgp_161_bwa_scramble_DEL_9527	HG01552	DEL	cnmops,gcnv; chr1	103643835	103645835	1kgp_161_bwa_scramble_DEL_9531	HG01494	DEL	gcnv; chr1	103643835	103652200	1kgp_161_bwa_scramble_DEL_9534	HG02236	DEL	cnmops,gcnv; chr1	103645600	103724500	1kgp_161_bwa_scramble_DEL_9538	HG03370	DEL	cnmops,gcnv; chr1	103647835	103649835	1kgp_161_bwa_scramble_DEL_9541	HG01495	DEL	gcnv; chr1	103647835	103681000	1kgp_161_bwa_scramble_DEL_9542	HG01494	DEL	cnmops,gcnv; …; ```. Master:; DEL: 641700; DUP: 699063. Branch:; DEL: 640669; Master intersection: 635178 (99.14% sensitivity); DUP: 691469; Master intersection: 677687 (98.00%). Note that this is a simple bedtools intersection requiring 90% reciprocal overlap, but not matching samples. Subsetting just to NA19420:. Master:; DEL: 4974; DUP: 4254. Branch:; DEL: 4958; Master intersection: 4797 (96.75%); DUP: 4210; Master intersection: 3802 (90.30%). Further subsetting to NA19240 variants over 5kbp, which is the default gatk-sv threshold for depth-only calls:. Master:; DEL: 1133; DUP: 916. Branch:; DEL: 1132; Master intersection: 1060 (93.64%); DUP: 893; Master intersection: 757 (84.77%). While it does appear there's an appreciable difference here, if we subset to NA19240 variants that survive gatk-sv filtering to the ""CleanVcf"" stage (in the current master), the differences are much less:. Master:; DEL: 225; DUP: 61. Branch:; DEL: 226; Master intersection: 223 (98.67%); DUP: 58; Master intersection: 58 (95.08%). I think the differences in raw calls is probably ""in the noise"" for WGS, given the high concordance in this test sample after gatk-sv filtering and genotyping are applied. Edit: Thanks to @kirtanav98 for running these tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2186896268:869,simpl,simple,869,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2186896268,1,['simpl'],['simple']
Usability,"Well, that explains that, sort of. The code snippet you're providing looks like it ought to do what you say it does (i.e., the mates have to be paired, not unmapped, mapped to the same contig, and have a difference in their start positions that is at least `mateTooDistantLength`). . But there are two problems with this:. 1) This filter's behavior is unexpected wrt HaplotypeCaller. It seems to me that an inclusive filter (i.e., process only paired-end mappings whose TLEN falls within a specified range) would be more usable. That would imply a filter implementation that accepts a pair of integers, but the expected behavior would be more obvious and in line with GATK's other range-limited parameterizations (e.g., `MappingQualityReadFilter` comes immediately to mind). 2) I can't tell from where I sit, but the code snippet looks correct only if `getStart()` and `getMateStart()` return a zero-based start position of each mate relative to the start of the strand to which the mate is mapped. If the code is just computing the difference between POS for the mates, the computation is incorrect for forward + reverse-complement (Illumina-style) pairs. In addition, computing TLEN requires not only that you consider the orientation of the individual mate mappings, but also that you make an arbitrary decision about how to handle soft-clipped reads. I hate to say this, but I think this parameter needs some attention. Its potential utility with HaplotypeCaller seems evident to me (i.e., it would be good to be able to exclude outliers with unreasonable TLENs) but its implementation and frugal documentation make it unusable in practice.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7701#issuecomment-1103199220:521,usab,usable,521,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7701#issuecomment-1103199220,1,['usab'],['usable']
Usability,"Well, when the `clearItems` call is removed from the `consumeFinalizeItems` else branch, some `HaplotypeCallerSparkIntegrationTest`s [fail](https://api.travis-ci.com/v3/job/173147001/log.txt) because `PushToPullIterator` doesn't call clearItems to reset the state when `consumeFinalizeItems` returns no items, and the next submit is rejected because eoi hasn't been reset. So, since `consumeFinalizeItems` can't reset/mutate the state when there are no items, then we can't assert the precondition that `endOfInput==false` in `submit`. So I'm removing the validation of that from both `ReservoirDownsampler` and `PositionalDownsampler`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457870723:16,clear,clearItems,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457870723,2,['clear'],['clearItems']
Usability,"When reads are mapped onto the genome short reads don't always find the best spot for indels. Sometimes reads are clipped at a position where a particular indel could have been mapped properly. Those regions you showed here are all homopolymer rich regions where assembly and variant calls are usually harder than other places. 3bp insertion within a GC rich region could easily be mapped wrong due to G and C nucleotide positioning and the way G/C nucleotide is handled by the sequencing instrument. Due to chemistry and optics reasons certain basecalls in GC rich regions may get convoluted with wrong nucleotide assertions such as 1 less G and one more C. . Reassembly, Realignment and PairHMM removes such artifacts by looking at basecalling metrics, mapping qualities, regional metrics etc. I cannot see it directly from the image however it is possible that some of those reads could have been soft/hard clipped due to such errors but yet they are still valid and usable by the assembly engine. . You may wish to read about the DepthPerAlleleBySample class and its documentation as it is the object class that calculates AD for variant contexts. ; [DepthPerAlleleBySample](https://gatk.broadinstitute.org/hc/en-us/articles/360037592411-DepthPerAlleleBySample). I hope this helps.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8959#issuecomment-2304798951:970,usab,usable,970,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8959#issuecomment-2304798951,1,['usab'],['usable']
Usability,Whew -- glad this was something simple!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2490#issuecomment-291179390:32,simpl,simple,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2490#issuecomment-291179390,1,['simpl'],['simple']
Usability,"While we normally don't recommend ignoring that wrapper, this seems like a good reason to do so. . The wrapper is pretty simple, most of what it's doing is some munging of the input to allow it to be more standardized in several different gatk use cases. The only thing I can think of that you would want to be sure to copy is that it sets a number of properties. . We set these spark `--conf` properties with the wrapper. I don't actually know how important some of them are anymore. If it works without them then you're probably good.; ```; ""spark.kryoserializer.buffer.max"" : ""512m"",; ""spark.driver.maxResultSize"" : ""0"",; ""spark.driver.userClassPathFirst"" : ""false"",; ""spark.io.compression.codec"" : ""lzf"",; ""spark.executor.memoryOverhead"" : ""600"",; ""spark.driver.extraJavaOptions"" : EXTRA_JAVA_OPTIONS_SPARK,; ""spark.executor.extraJavaOptions"" : EXTRA_JAVA_OPTIONS_SPARK; ```. These are htsjdk properties we want to set for spark. ; ```; EXTRA_JAVA_OPTIONS_SPARK= ""-DGATK_STACKTRACE_ON_USER_EXCEPTION=true "" \; ""-Dsamjdk.use_async_io_read_samtools=false "" \; ""-Dsamjdk.use_async_io_write_samtools=false "" \; ""-Dsamjdk.use_async_io_write_tribble=false "" \; ""-Dsamjdk.compression_level=2 ""; ```. If you can get this value into your spark environment variables it prevents and anying warning output. `SUPPRESS_GCLOUD_CREDS_WARNING=true`. Let us know how it works for you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6198#issuecomment-539073054:121,simpl,simple,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6198#issuecomment-539073054,1,['simpl'],['simple']
Usability,"Woohoo, knew it would be a simple fix! :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1092#issuecomment-155500559:27,simpl,simple,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1092#issuecomment-155500559,1,['simpl'],['simple']
Usability,Would it be better/simpler to just have both `./gradlew gatkDoc` and `./gradlew phpDoc`?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311465823:19,simpl,simpler,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311465823,1,['simpl'],['simpler']
Usability,"Yeah - this makes 2 assumptions: the data are evenly distributed and that progress is constant. This isn't the most accurate way to do this, but something is better than nothing. . There is another implementation that I considered - base the remaining time on the time it has taken for the last `N` updates. This would account for bursty processing times, but would also result in wildly fluctuating estimates (because it would still assume a uniform distribution of data). We cam also do something like this with a sliding window average to smooth it out. If you prefer another implementation I can change it, but again - something is better than nothing. . I don't want to have to scan the input data to make the progress bar work - that seems way too heavy-handed and would slow everything down. The tradeoff doesn't seem worth it. . For small files it doesn't matter anyway, so I'm not too concerned. . This arose for me because I've been needing to wait many hours for jobs to finish and I would like an estimate of when I cam expect it to finish.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8486#issuecomment-1684488371:715,progress bar,progress bar,715,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8486#issuecomment-1684488371,1,['progress bar'],['progress bar']
Usability,"Yeah, I don't like these new interface methods -- they make `GATKRead` significantly worse. We should cache `isUnmapped`, etc. in the adapter to accomplish the same thing, as @lbergelson suggests. Not that hard, and we can just unconditionally invalidate the cached values (using `Boolean` fields set to null) whenever the read is mutated in any way in order to simplify the logic.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235102282:362,simpl,simplify,362,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235102282,1,['simpl'],['simplify']
Usability,"Yeah, it would be useful (see https://github.com/broadinstitute/gatk/issues/2582). Not sure if/when we'll ever get around to the Barclay changes though. Another simple option that wouldn't require Barclay changes would be to implement it as just another (plugin descriptor) command line argument that could be sued alongside `--read-filter`'. So if you wanted a `ReadNameFilter` and an inverted `ReadLengthFilter`, the syntax would be:. `--read-filter ReadNameFilter --invert-read-filter ReadLengthReadFilter`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6005#issuecomment-502231306:161,simpl,simple,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6005#issuecomment-502231306,1,['simpl'],['simple']
Usability,"Yeah, the workaround was simply to add the library jar to the classpath and not try to compile them together. I created the issue to soon, Sorry. . As for the NIO library, it is for AWS S3. We are adapting this one https://github.com/Upplication/Amazon-S3-FileSystem-NIO2 to meet our needs. We didn't like the way it handles s3 endpoints because AWS EMR Spark clusters don't support s3 uri's with that particular syntax. Our version modifies it to support normal s3 uri's without endpoints, instead setting the endpoint with a configuration parameter.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308161431:25,simpl,simply,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308161431,1,['simpl'],['simply']
Usability,"Yep, sorry. Just learned that as you were closing it. On Tue, Aug 14, 2018 at 11:51 AM, Louis Bergelson <notifications@github.com>; wrote:. > It's useful to put something like fixes #5104 in the commit message. That; > way it automatically closes the issue and shows a link from the PR to the; > Issue.; >; > —; > You are receiving this because you modified the open/close state.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4932#issuecomment-412920923>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AoMkWAqeYbmnX12i6s9k_5bEWy149CPFks5uQvITgaJpZM4UyozK>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4932#issuecomment-412923593:17,learn,learned,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4932#issuecomment-412923593,1,['learn'],['learned']
Usability,"Yes, agreed @akiezun -- and as mentioned at group meeting this week, we can meet with you guys to provide guidance in setting this up in a way that GATK can easily use after we meet our June deadlines.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1914#issuecomment-227452491:106,guid,guidance,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1914#issuecomment-227452491,1,['guid'],['guidance']
Usability,"Yes, but... It looks to me as if the index files, which appear to be in the master node's Linux file system in this failing example, are probably not available to the worker nodes. You'd have to copy each of the 5 index files to each of the workers, putting them in the same location on each. The same problem would occur with the new version: The single-image index file will still need to be available to all workers. You could distribute this file with:; ```--conf spark.yarn.dist.files=<location of the image file>```; which will copy it from your local machine to all workers each time you run the program. This isn't optimal, because it's pretty large. So, instead, you could copy it to a fixed path, identical on each worker, once up front, and then run your alignment jobs to your heart's content. The new version is a little simpler, because there's just one index file, but otherwise suffers from the same issue: bwa mem only knows how to deal with ordinary file system files -- not HDFS, not GCS -- and so the file must be copied to each worker machine in the cluster.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2171#issuecomment-288545672:834,simpl,simpler,834,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2171#issuecomment-288545672,1,['simpl'],['simpler']
Usability,"Yes, that is easy to do. The guidance on how much memory to leave wasnt clear on the docs. Is there a rule of thumb on how much we should leave? We can do whatever makes sense. the command is something like:. ```. /home/exacloud/gscratch/prime-seq/java/java8/bin/java \; -Djava.io.tmpdir=/mnt/scratch/prime-seq/tmp.5E76utMagnGenomicsDB_Append_Merge_2020-11-04_09-17-56-Job1 \; -Xmx104g \; -Xms104g \; -Xss2m \; -jar /home/exacloud/gscratch/prime-seq/bin/GenomeAnalysisTK4.jar GenomicsDBImport \; -V <Repeated 183 times for gVCFs> \ ; --genomicsdb-update-workspace-path /home/exacloud/gscratch/prime-seq/workDir/9a2611e8-0112-1039-8c80-f8f3fc869aa5/Job1.work/WGS_Nov_1300.gdb \; --batch-size 50 \; --consolidate \; --genomicsdb-shared-posixfs-optimizations. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-724293565:29,guid,guidance,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-724293565,2,"['clear', 'guid']","['clear', 'guidance']"
Usability,"Yes. We should expect that PCR error shouldn't affect the base-quality, so two high quality, disagreeing bases are an indication of a PCR error, while one low-quality base, and one high quality base that have differing qualities looks more like a sequencing error. We might be able to obtain a data-driven model for that using the overlapping bases themselves (over monomorphic sites). The only problem is that this is only true when the reads haven't been processed by Consensus calling....but if we have a good model for consensus calling within haplotype caller we could avoid doing that upfront and simply deal with everything within haplotype caller. **That** would be ideal!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4958#issuecomment-400815571:603,simpl,simply,603,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4958#issuecomment-400815571,1,['simpl'],['simply']
Usability,"You are going to want to change all the ; `memory: machine_mem + "" GB""` ; lines to ; `memory: machine_mem + "" MB""`.; Otherwise you are going to be asking for massive amounts of memory 😄. Sorry if I wasn't clear the first time.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4306#issuecomment-362672065:205,clear,clear,205,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4306#issuecomment-362672065,1,['clear'],['clear']
Usability,You can consider this fixed if it passes a simple unit test where you run `ReadPosRankSumTest.getReadPosition` on a few artificial read of the form <ref match><short deletion><short ref match of 1-5 or so bases><short deletion>.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5492#issuecomment-445115098:43,simpl,simple,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5492#issuecomment-445115098,1,['simpl'],['simple']
Usability,"You're partially correct. A push build builds exactly the branch as pushed, while the PR build essentially merges the branch into master and builds that, so it's what you would get on merging. Since the only result we really care about is what happens when we merge to master, we try to skip the push builds by instantly passing them and only building the PRs. . I think there's an issue though when there is a merge conflict, because then it can't build the PR build since you have to resolve the conflict manually, but it still skips the push build, so we don't get any useful feedback.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5213#issuecomment-584454027:579,feedback,feedback,579,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5213#issuecomment-584454027,1,['feedback'],['feedback']
Usability,"Your best bet is to just start analyzing your data with this VCF. Doesn't; sound like your output log file showed any truly problematic errors. Things; like VCF Tools or vcfR (if you're familiar with R or want to start learning; it) give you some basic stats about your vcf file very quickly. This will; alleviate many of your concerns. On Tue, Jul 31, 2018, 11:10 AM sanjeevksh <notifications@github.com> wrote:. > My GenotypeGVCFs run for a single chromosome returned the following; > completion statement:; > 18:54:40.516 INFO ProgressMeter - Traversal complete. Processed 606308; > total variants in 75.2 minutes.; >; > However, there are only 46814 variant rows (excluding 52 header rows) in; > the corresponding vcf file. Does the above figure of 606308 correspond to a; > multiple of 'variants x number of samples'?; >; > Also, there are only 16863 lines in my log file, does this mean that the; > 'Current Locus' column in the log file doesn't correspond to a single; > genomic location (bp) in the fasta file?; >; > I am curious to know what is the relation between all these figures to; > fully understand what is happening while processing the gCVF files.; >; > Also, on the inbreeding coefficient warning issue, I understand from your; > @Neato-Nick <https://github.com/Neato-Nick> feedback that the variants; > with these warnings may still be fine and can be retained. However, this; > still leaves me worrying that out of 384 samples the locus doesn't even; > have 10 samples for generating the required metrics. Such variants won't be; > of any use for downstream analyses anyway where any variants with more than; > 80% missing samples will be removed. Therefore, I wish to seek some more; > information about this 10 sample thing - does it have some other context or; > does it literally mean that there are only less than 10 samples carrying; > that variant?; >; > Regards,; > Sanjeev; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, vi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409271340:219,learn,learning,219,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409271340,1,['learn'],['learning']
Usability,"Your interpretation sounds right, although I wish the language in the SAM spec were clearer - something like ""if 0x1 is unset, fields 0x2, 0x8, 0x20, 0x40, and 0x80 have no meaning and are ignored by the tools"". SAMRecord.IsValid() returns errors not only for 0x8(mate unmapped)/unpaired read, but also for the other four fields, so all of these errors would need to be removed. IsValid() also triggers an error when an unpaired read has RNEXT set, but the spec. ; doesn't appear to exclude this error. No error is triggered for the unpaired/PNEXT case. . So I agree that it looks like IsValid() should be changed to align with the spec. But I can also imagine potential pitfalls of leaving the GenomicsConverter code the way it is. The code adds spurious information to the bam that might cause problems with legacy versions of the tools. I don't know what the plans are for the state of the existing tool distribution once gatk4 is released. Is it possible that bam files produced in the cloud could make their way into gatk3 workflows, maybe via the sharing of bams between groups? If this happens, then unpaired reads processed in the cloud, with their mate unpaired flags set by the converter, could trigger validation errors when they are fed to the legacy tools. Is there a downside to altering the converter code as well as modifying the ; validator (I don't know what altering google packages entails...)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/569#issuecomment-114510392:84,clear,clearer,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/569#issuecomment-114510392,1,['clear'],['clearer']
Usability,[![Coverage Status](https://coveralls.io/builds/2381417/badge)](https://coveralls.io/builds/2381417). Coverage increased (+0.01%) to 70.37% when pulling **ddae3d1f9ca34832ab52d445f25c2e2cde2fafc3 on akiezun-README-guidelines** into **eff7d0f596502c4425366fad1985e6a1d5ad0542 on master**.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/415#issuecomment-94565460:214,guid,guidelines,214,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/415#issuecomment-94565460,1,['guid'],['guidelines']
Usability,"`-nt` is data threads, that is, threads on a single core. This is not true CPU-level parallelism but can save significant time because different threads need not be delayed by each other's memory fetches and I/O. That is, it is data parallelism but not processor parallelism. `-nct` is CPU parallelism and means multiple cores. I'm closing this issue, but feel free to re-open if I have not answered clearly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5035#issuecomment-443588742:400,clear,clearly,400,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5035#issuecomment-443588742,1,['clear'],['clearly']
Usability,"`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2416 +/- ##; ===============================================; - Coverage 76.224% 76.218% -0.006% ; + Complexity 10820 10819 -1 ; ===============================================; Files 750 750 ; Lines 39422 39420 -2 ; Branches 6883 6883 ; ===============================================; - Hits 30049 30045 -4 ; - Misses 6755 6757 +2 ; Partials 2618 2618; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2416?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...alkers/genotyper/afcalc/CustomAFPriorProvider.java](https://codecov.io/gh/broadinstitute/gatk/compare/75f633135798145079ddb32c7dc2e884d47de4b3...3f2a04aa9723a86271120755e6be8945ff103532?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvQ3VzdG9tQUZQcmlvclByb3ZpZGVyLmphdmE=) | `94.444% <ø> (-0.556%)` | `6 <ø> (-1)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/75f633135798145079ddb32c7dc2e884d47de4b3...3f2a04aa9723a86271120755e6be8945ff103532?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `66.667% <ø> (-3.333%)` | `10% <ø> (ø)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2416?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2416?src=pr&el=footer). Last update [75f6331...3f2a04a](https://codecov.io/gh/broadinstitute/gatk/compare/75f633135798145079ddb32c7dc2e884d47de4b3...3f2a04aa9723a86271120755e6be8945ff103532?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2416#issuecomment-281483092:1825,learn,learn,1825,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2416#issuecomment-281483092,1,['learn'],['learn']
Usability,"a7b8e54d20168a65?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :white_check_mark: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/521128573b0d1a01ee60725c2b84e4a4f6a12fa3...cab0d179986f7f7587e0e005a7b8e54d20168a65?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `75.694% <0%> (+2.083%)` | `36% <0%> (ø)` | :x: |; | [...oadinstitute/hellbender/utils/GenomeLocParser.java](https://codecov.io/gh/broadinstitute/gatk/compare/521128573b0d1a01ee60725c2b84e4a4f6a12fa3...cab0d179986f7f7587e0e005a7b8e54d20168a65?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vbWVMb2NQYXJzZXIuamF2YQ==) | `90.083% <0%> (+4.132%)` | `57% <0%> (+2%)` | :white_check_mark: |; | [...ellbender/utils/test/CommandLineProgramTester.java](https://codecov.io/gh/broadinstitute/gatk/compare/521128573b0d1a01ee60725c2b84e4a4f6a12fa3...cab0d179986f7f7587e0e005a7b8e54d20168a65?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0NvbW1hbmRMaW5lUHJvZ3JhbVRlc3Rlci5qYXZh) | `90.476% <0%> (+4.762%)` | `8% <0%> (+1%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2423?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2423?src=pr&el=footer). Last update [5211285...cab0d17](https://codecov.io/gh/broadinstitute/gatk/compare/521128573b0d1a01ee60725c2b84e4a4f6a12fa3...cab0d179986f7f7587e0e005a7b8e54d20168a65?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-282342687:2964,learn,learn,2964,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-282342687,1,['learn'],['learn']
Usability,"and to my thinking copying each contig's folder into a new workspace, vs. copying each contig into the same workspace is basically the same overhead. We also tend to keep the long-lived copy on our warm storage, with processing happening on our cluster's lustre filesystem. . 2) Again, i dont think it's necessarily right to assume every job will operate on the same set of intervals. We generally would use the same pattern, but there are legitimate cases in which different intervals/job would better match the cluster's availability. If we're appending a limited number of samples and our cluster is busy, we might want to scatter using more intervals/job since each job would finish fairly quickly and the practical reality is fewer total jobs would complete quicker. if we are performing an operation that requires a lot of time/job (like creating a new workspace or appending a lot of samples), we might do one job/contig. It's also worth pointing out that macaque has 1000s of small unplaced contigs, and therefore we almost never do a simple 1:1 job:contig scheme.; ; 3) When I was originally thinking about how to scatter/gather the creation of a combined gVCF, the overhead of re-merging was huge. There was zero point in taking the per-contig gVCFs and concat/bgzipping a new one, just to split it again. When I started down this road, my idea was to make a folder holding each gVCF, and a top-level JSON file to map contig->filepath, so code could intelligently work with these. The latter essentially describes the structure of a GenomicsDB workspace. Unlike concatenating gVCFS, the overhead of moving directories around is practically zero. Sure, I could make a folder of GenomicsDB workspaces, but if I'm already moving them, what's the point in not merging? . I could understand that is the workspace lived on a shared filesystem and was always going to exist in that location (which I still have trouble squaring with the recommendation to back it up prior to appending), then the s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-640881049:1299,simpl,simple,1299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-640881049,1,['simpl'],['simple']
Usability,"aps pushing a fresh branch to this repo might make it a little easier for us to check it out for review---again, not a big deal, so I'll leave it up to you. 2) We try to adhere to the Google style guide https://google.github.io/styleguide/javaguide.html, so the review may yield a lot of seemingly minor and nitpicky change requests. Don't take these personally---the goal is just to make the code base as uniform and easy to maintain as possible! If you prefer, I'm sure we can find a GATK developer to take a quick once over of your branch and make these minor changes. 3) Since the new tool borrows so heavily from CollectAllelicCounts, I think it might be worth consolidating shared code and reducing code duplication---again, with the goal of making future maintenance more straightforward. I'll try to identify some places this can be done during my review. Again, we can make these changes on our end during the once over, or you can address them after the review (or we could also do this on our end in a separate PR after this one goes in). 4) In the near future, I think we should finally make the effort to replace both GetPileupSummaries and CollectAllelicCounts with this new tool. As mentioned in our email thread, @davidbenjamin and I discussed this long ago, e.g. https://github.com/broadinstitute/gatk/issues/4717#issuecomment-386734926. From a methods perspective, we'd simply need expand the current functionality of your tool to also report the reference allele and do some quick sanity checks to make sure that the differences in count definition and read filtering don't have any undesired downstream effects. However, as we also discussed, this will come with some additional overhead---we'll need to update documentation, workshop slides, tutorials, WDLs, and make sure that any changes in output formats are clearly highlighted in the release notes. I'll leave this effort to @davidbenjamin and @mwalker174. Thanks again for doing this. Let us know how you'd like to proceed!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6543#issuecomment-610462293:1739,simpl,simply,1739,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6543#issuecomment-610462293,2,"['clear', 'simpl']","['clearly', 'simply']"
Usability,"are the most appealing, so I'll lean into those:. > Option 1 (i.e. trusting the alignments completely). Yeah, I recognize that this puts us closer in theory to the realms of a positional-based variant caller; however, I'm quite invested in the pre-/post- processing implementations I've got built around Mutect2 (not to mention the benefit of simultaneous processing of the normal and tumor samples, pre-filtering, model-based filtering, etc). If Mutect would employ this naive approach to haplotype calling, I suppose it would end up looking like the ""Platypus"" caller, _which_ again might be suited for our needs, but potentially makes option 3 more appealing. > Option 3 ( i.e. Quick-and-dirty (""FreeBayes-ian"") assembly:. This is interesting and would seem to solve my problems (I believe?) by creating a Haplotype-based, somatic variant caller with the Mutect perks/processing steps/output formats. Again, though, I could see the generation of many candidate haplotypes if things are really messy; however, could you not use a simple ""supporting reads""-based approach for haplotype selection. That would make the likelihood calculations fairly straight-forward. It would undeniably be less-sophisticated than the current De Bruijn Graph/Smith Waterman realignment-based approach but could be better for folks that want more control of the expected behaviors of the tool. > Option 5 (Disable realignment portion of assembly):. I'm going to go out on a limb with this one (feel free to shut this line of thought down quick if I'm really off-base). I've never been able to fully understand the code in the `findBestPaths` method (https://github.com/broadinstitute/gatk/blob/9ff3f8b180c063a3fa67dae129b0cbd04012448e/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/readthreading/ReadThreadingAssembler.java#L307) and I've had troubles figuring out the details of realignment from the official docs. It could be this part of the assembly process that causes me the most troub",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7064#issuecomment-771060817:1181,simpl,simple,1181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7064#issuecomment-771060817,1,['simpl'],['simple']
Usability,"as discussed with @droazen, I'm not touching this PR until he's done with his experiment. Reassigning to make it clear that I'm not working on this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/890#issuecomment-183170746:113,clear,clear,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/890#issuecomment-183170746,3,['clear'],['clear']
Usability,at org.broadinstitute.hellbender.utils.NaturalLogUtils.logSumExp(NaturalLogUtils.java:84); at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeFromLogToLinearSpace(NaturalLogUtils.java:27); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:93); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:140); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSomaticVariant(SomaticClusteringModel.java:146); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.performEMIteration(SomaticClusteringModel.java:345); at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:330); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:153); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:165); at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:44); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1095); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7276#issuecomment-1293969047:1910,learn,learnAndClearAccumulatedData,1910,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7276#issuecomment-1293969047,1,['learn'],['learnAndClearAccumulatedData']
Usability,"ationDiscoveryArgumentCollection.DiscoverVariantsFromContigsAlignmentsSparkArgumentCollection.DEFAULT_MIN_ALIGNMENT_LENGTH, StructuralVariationDiscoveryArgumentCollection.DiscoverVariantsFromContigsAlignmentsSparkArgumentCollection.CHIMERIC_ALIGNMENTS_HIGHMQ_THRESHOLD, true);. Assert.assertEquals(assembledBreakpointsFromAlignmentIntervals.size(), 1);; final ChimericAlignment chimericAlignment = assembledBreakpointsFromAlignmentIntervals.get(0);; Assert.assertEquals(chimericAlignment.sourceContigName, ""asm00001:tig0001"");; final NovelAdjacencyReferenceLocations breakpoints = new NovelAdjacencyReferenceLocations(chimericAlignment, contigSequence, SVDiscoveryTestDataProvider.seqDict);; }; ```. In versions of the code prior to #3752 (I think) this set of alignments was being filtered out by the method `isNotSimpleTranslocation` in the `parseOneContig` method of `ChimericAlignment`. Now that check's logic has changed and `isLikelySimpleTranslocation` returns false instead of true and so this alignment is not being filtered out any more. . When it gets to `NovelAdjacencyReferenceLocations.TanDupBreakpointsInference()` both `upstreamBreakpointRefPos` and `downstreamBreakpointRefPos` are being set to zero. It's not immediately clear to me how to fix this. A few thoughts:. - Are we supposed to be processing this `ChimericAlignment` through the main code path right now? ; - Why do we subtract 1 from the start position of the `rightReferenceInterval.getStart()` when setting `downstreamBreakpointRefPos`? In this case the start is 1 so we end up with an invalid coordinate of 0.; - The `upstreamBreakpointRefPos` is also being set to 0 by this line below.. why?. ```; upstreamBreakpointRefPos = leftReferenceInterval.getEnd() - homologyLen; - (complication.getDupSeqRepeatNumOnCtg() - complication.getDupSeqRepeatNumOnRef()) * complication.getDupSeqRepeatUnitRefSpan().size();; ```. @SHuang-Broad I'm not sure what the best way to fix this is, can you take a look when you have a chance?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3874#issuecomment-347627504:3593,clear,clear,3593,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3874#issuecomment-347627504,1,['clear'],['clear']
Usability,"avadoc.doclet](https://docs.oracle.com/en/java/javase/11/docs/api/jdk.javadoc/jdk/javadoc/doclet/package-summary.html). The javadoc tools in `org.broadinstitute.hellbender.utils.help` may need to be re-written (and it's not clear if it's possible to support Java 8 and Java 11 simultaneously).; * Travis build. Getting this to build and test on Java 11 in addition to the current builds may be fairly involved as the matrix is already quite complicated. (The current PR just changes Java 8 to Java 11 for testing purposes - we'd need a way of getting both to run.). The vast majority of tests are passing on Java 11, the following are failing:; * Missing `TwoBitRecord` (from ADAM); * `ReferenceMultiSparkSourceUnitTest`; * `ImpreciseVariantDetectorUnitTest`; * `SVVCFWriterUnitTest`; * `DiscoverVariantsFromContigAlignmentsSAMSparkIntegrationTest`; * `StructuralVariationDiscoveryPipelineSparkIntegrationTest`; * `SvDiscoverFromLocalAssemblyContigAlignmentsSparkIntegrationTest`; * `java.lang.NoSuchMethodError: java.nio.ByteBuffer.clear()Ljava/nio/ByteBuffer;`; * `SeekableByteChannelPrefetcherTest`; * `GatherVcfsCloudIntegrationTest`; * `Could not serialize lambda`; * `ExampleAssemblyRegionWalkerSparkIntegrationTest`; * `PileupSparkIntegrationTest`; * Native HMM library code caused the tests to crash on my Mac:; ```; Running Test: Test method testLikelihoodsFromHaplotypes[0](org.broadinstitute.hellbender.utils.pairhmm.VectorLoglessPairHMM@6282d367, true)(org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest); dyld: lazy symbol binding failed: can't resolve symbol __ZN13shacc_pairhmm9calculateERNS_5BatchE in /private/var/folders/cj/wyp4zgw17vj4m9qdmddvmcc80000gn/T/libgkl_pairhmm13775554937319419112.dylib because dependent dylib #1 could not be loaded; dyld: can't resolve symbol __ZN13shacc_pairhmm9calculateERNS_5BatchE in /private/var/folders/cj/wyp4zgw17vj4m9qdmddvmcc80000gn/T/libgkl_pairhmm13775554937319419112.dylib because dependent dylib #1 could not be loaded; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-527179359:1798,clear,clear,1798,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-527179359,1,['clear'],['clear']
Usability,"b9636?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9MaWJyYXJ5UmVhZEZpbHRlci5qYXZh) | `100% <ø> (ø)` | `4 <ø> (ø)` | :x: |; | [...institute/hellbender/tools/picard/sam/SortSam.java](https://codecov.io/gh/broadinstitute/gatk/compare/10b16a671dc2e153dbc92a16a72bdbf88eaa5ccd...d4483e8cf8d2e50e125c5340556b3eb49abb9636?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9waWNhcmQvc2FtL1NvcnRTYW0uamF2YQ==) | `94.118% <ø> (ø)` | `3 <ø> (ø)` | :x: |; | [...adinstitute/hellbender/tools/IndexFeatureFile.java](https://codecov.io/gh/broadinstitute/gatk/compare/10b16a671dc2e153dbc92a16a72bdbf88eaa5ccd...d4483e8cf8d2e50e125c5340556b3eb49abb9636?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9JbmRleEZlYXR1cmVGaWxlLmphdmE=) | `90.323% <ø> (ø)` | `12 <ø> (ø)` | :x: |; | [...org/broadinstitute/hellbender/tools/ClipReads.java](https://codecov.io/gh/broadinstitute/gatk/compare/10b16a671dc2e153dbc92a16a72bdbf88eaa5ccd...d4483e8cf8d2e50e125c5340556b3eb49abb9636?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9DbGlwUmVhZHMuamF2YQ==) | `90.385% <ø> (ø)` | `35 <ø> (ø)` | :x: |; | ... and [81 more](https://codecov.io/gh/broadinstitute/gatk/pull/2327/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2327?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2327?src=pr&el=footer). Last update [10b16a6...d4483e8](https://codecov.io/gh/broadinstitute/gatk/compare/10b16a671dc2e153dbc92a16a72bdbf88eaa5ccd...d4483e8cf8d2e50e125c5340556b3eb49abb9636?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-268877705:4836,learn,learn,4836,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-268877705,1,['learn'],['learn']
Usability,"bWVudENvbGxlY3Rpb24uamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [...tools/examples/ExampleStreamingPythonExecutor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leGFtcGxlcy9FeGFtcGxlU3RyZWFtaW5nUHl0aG9uRXhlY3V0b3IuamF2YQ==) | `0% <0%> (-96.67%)` | `0% <0%> (-8%)` | |; | [.../walkers/vqsr/CNNScoreVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `4.16% <0%> (-95.84%)` | `2% <0%> (-8%)` | |; | [...der/utils/python/PythonScriptExecutorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9weXRob24vUHl0aG9uU2NyaXB0RXhlY3V0b3JVbml0VGVzdC5qYXZh) | `3.84% <0%> (-94.24%)` | `1% <0%> (-11%)` | |; | [...number/arguments/HybridADVIArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2FyZ3VtZW50cy9IeWJyaWRBRFZJQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `0% <0%> (-94.12%)` | `0% <0%> (-3%)` | |; | ... and [36 more](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5329?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5329?src=pr&el=footer). Last update [f95b6fe...1c00f72](https://codecov.io/gh/broadinstitute/gatk/pull/5329?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5329#issuecomment-431146563:4607,learn,learn,4607,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5329#issuecomment-431146563,1,['learn'],['learn']
Usability,"bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `90% <0%> (-1.429%)` | `23% <0%> (-1%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/58cb99ec6c81917a9ac8ecf52e8fde2bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `87.2% <0%> (+0.8%)` | `36% <0%> (+1%)` | :arrow_up: |; | [...ellbender/tools/walkers/annotator/RankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/58cb99ec6c81917a9ac8ecf52e8fde2bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9SYW5rU3VtVGVzdC5qYXZh) | `86.957% <0%> (+6.401%)` | `14% <0%> (+1%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/58cb99ec6c81917a9ac8ecf52e8fde2bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `75.385% <0%> (+7.168%)` | `49% <0%> (+16%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2500?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2500?src=pr&el=footer). Last update [58cb99e...2a7f196](https://codecov.io/gh/broadinstitute/gatk/compare/58cb99ec6c81917a9ac8ecf52e8fde2bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2500#issuecomment-288139597:2544,learn,learn,2544,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2500#issuecomment-288139597,1,['learn'],['learn']
Usability,"broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `84% <100%> (+0.66%)` | `43 <4> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/PathSpecifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUGF0aFNwZWNpZmllci5qYXZh) | `67.1% <0%> (+1.31%)` | `21% <0%> (+1%)` | :arrow_up: |; | [...institute/hellbender/engine/GATKPathSpecifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1BhdGhTcGVjaWZpZXIuamF2YQ==) | `48.21% <0%> (+1.78%)` | `16% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5832?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5832?src=pr&el=footer). Last update [aa8e807...d462900](https://codecov.io/gh/broadinstitute/gatk/pull/5832?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5832#issuecomment-476229094:2741,learn,learn,2741,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5832#issuecomment-476229094,1,['learn'],['learn']
Usability,"but for fingerprinting it seems that since it is effectively random-access,; perhaps prefetching will not be worth it?. On Fri, Apr 12, 2019 at 2:32 PM droazen <notifications@github.com> wrote:. > @yfarjoun <https://github.com/yfarjoun> We should sit down at some point; > to discuss the best way to activate the prefetching in Picard. It may be a; > little less trivial than I had thought based on the above, but should still; > be fairly simple.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678256>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0ptBXdOQ-9HlXMjjpFHI_zp-cQJqks5vgNEzgaJpZM4csje4>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678782:440,simpl,simple,440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678782,1,['simpl'],['simple']
Usability,"c.). The run can be found in /dsde/working/slee/wgs-pon-test/tieout/no-gc. It completed successfully with **-Xmx32G** (in comparison, CreatePanelOfNormals crashed after 40 minutes with -Xmx128G). The runtime breakdown was as follows:. - ~45 minutes simply from reading of the 90 TSV read-count files in serial. Hopefully #3349 should greatly speed this up. (In comparison, CombineReadCounts reading 10 files in parallel at a time took ~100 minutes to create the aforementioned 20GB combined TSV file, creating 25+GB of temp files along the way.). - ~5 minutes from the preprocessing and filtering steps. We could probably further optimize some of this code in terms of speed and heap usage. (I had to throw in a call to System.gc() to avoid an OOM with -Xmx32G, which I encountered in my first attempt at the run...). - ~5 minutes from performing the SVD of the post-filtering 8643028 x 86 matrix, maintaining 30 eigensamples. I could write a quick implementation of randomized SVD, which I think could bring this down a bit (the scikit-learn implementation takes <2 minutes on a 10M x 100 matrix), but this can probably wait. Clearly making I/O faster and more space efficient is the highest priority. Luckily it's also low hanging fruit. The 8643028 x 30 matrix of eigenvectors takes <2 minutes to read from HDF5 when the WGS PoN is used in DenoiseReadCounts, which gives us a rough idea of how long it should take to read in the original ~11.5M x 90 counts from HDF5. So once #3349 is in, then I think that a **~15 minute single-core WGS PoN could easily be viable**. I believe that a PoN on the order of this size will be all that is required for WGS denoising, if it is not already overkill. To go bigger by more than an order of magnitude, we'll have to go out of core, which will require more substantial changes to the code. But since the real culprit responsible for hypersegmentation is CBS, rather than insufficient denoising, I'd rather focus on finding a viable segmentation alternative.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-317614503:1368,learn,learn,1368,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-317614503,1,['learn'],['learn']
Usability,"c0b0f318c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9HQVRLU1ZWQ0ZIZWFkZXJMaW5lcy5qYXZh) | `0% <ø> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...ute/hellbender/tools/spark/sv/AlignmentRegion.java](https://codecov.io/gh/broadinstitute/gatk/compare/9c1d1fb2cc1aeb171e01764ee69c1544698e796d...f1380fe7f813931a2eb402867b07fb1c0b0f318c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9BbGlnbm1lbnRSZWdpb24uamF2YQ==) | `63.265% <100%> (+1.16%)` | `16 <2> (ø)` | :arrow_down: |; | [...lbender/tools/spark/sv/SVVariantConsensusCall.java](https://codecov.io/gh/broadinstitute/gatk/compare/9c1d1fb2cc1aeb171e01764ee69c1544698e796d...f1380fe7f813931a2eb402867b07fb1c0b0f318c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TVlZhcmlhbnRDb25zZW5zdXNDYWxsLmphdmE=) | `85.556% <80%> (ø)` | `21 <4> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/9c1d1fb2cc1aeb171e01764ee69c1544698e796d...f1380fe7f813931a2eb402867b07fb1c0b0f318c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2512?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2512?src=pr&el=footer). Last update [9c1d1fb...f1380fe](https://codecov.io/gh/broadinstitute/gatk/compare/9c1d1fb2cc1aeb171e01764ee69c1544698e796d...f1380fe7f813931a2eb402867b07fb1c0b0f318c?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2512#issuecomment-288291739:2582,learn,learn,2582,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2512#issuecomment-288291739,1,['learn'],['learn']
Usability,"c2.internal:8020/output2.bam.parts/_temporary/0/task_20170505170341_0011_r_000000; 17/05/05 17:03:58 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1921 bytes result sent to driver; 17/05/05 17:03:58 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 10369 ms on localhost (executor driver) (4/4); 17/05/05 17:03:58 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool ; 17/05/05 17:03:58 INFO DAGScheduler: ResultStage 2 (saveAsNewAPIHadoopFile at ReadsSparkSink.java:202) finished in 10.370 s; 17/05/05 17:03:58 INFO DAGScheduler: Job 1 finished: saveAsNewAPIHadoopFile at ReadsSparkSink.java:202, took 16.702399 s; 17/05/05 17:03:58 INFO SparkUI: Stopped Spark web UI at http://172.30.0.122:46483; 17/05/05 17:03:59 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/05/05 17:03:59 INFO MemoryStore: MemoryStore cleared; 17/05/05 17:03:59 INFO BlockManager: BlockManager stopped; 17/05/05 17:03:59 INFO BlockManagerMaster: BlockManagerMaster stopped; 17/05/05 17:03:59 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/05/05 17:03:59 INFO SparkContext: Successfully stopped SparkContext; [May 5, 2017 5:03:59 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.40 minutes.; Runtime.totalMemory()=799080448; 17/05/05 17:03:59 INFO ApplicationMaster: Final app status: FAILED, exitCode: 16, (reason: Shutdown hook called before final status was reported.); 17/05/05 17:03:59 INFO ApplicationMaster: Unregistering ApplicationMaster with FAILED (diag message: Shutdown hook called before final status was reported.); 17/05/05 17:03:59 INFO ApplicationMaster: Deleting staging directory hdfs://ip-172-30-0-86.ec2.internal:8020/user/hadoop/.sparkStaging/application_1493961816416_0010; 17/05/05 17:03:59 INFO ShutdownHookManager: Shutdown hook called; 17/05/05 17:03:59 INFO ShutdownHookManager: Deleting directory /mnt1/yarn",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2666#issuecomment-299525046:17838,clear,cleared,17838,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2666#issuecomment-299525046,1,['clear'],['cleared']
Usability,"c=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwZUNhbGN1bGF0aW9uQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `100% <ø> (ø)` | `2 <0> (ø)` | :x: |; | [...nder/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/compare/5d2f859db87f60a0f5b5f0ed7f73e39ebae09bec...ed0b8cac3375023f23d5c0bd8a31ee155d707dae?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nRW5naW5lLmphdmE=) | `46.903% <33.333%> (ø)` | `32 <0> (ø)` | :x: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/5d2f859db87f60a0f5b5f0ed7f73e39ebae09bec...ed0b8cac3375023f23d5c0bd8a31ee155d707dae?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :white_check_mark: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/5d2f859db87f60a0f5b5f0ed7f73e39ebae09bec...ed0b8cac3375023f23d5c0bd8a31ee155d707dae?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :x: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2314?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2314?src=pr&el=footer). Last update [5d2f859...ed0b8ca](https://codecov.io/gh/broadinstitute/gatk/compare/5d2f859db87f60a0f5b5f0ed7f73e39ebae09bec...ed0b8cac3375023f23d5c0bd8a31ee155d707dae?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2314#issuecomment-267118800:2601,learn,learn,2601,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2314#issuecomment-267118800,1,['learn'],['learn']
Usability,"cf7fa54b8785c87a919f1951151789?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZU1hbmFnZXIuamF2YQ==) | `86.592% <ø> (+1.025%)` | `78% <ø> (+34%)` | :white_check_mark: |; | [...tute/hellbender/engine/MultiVariantDataSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/6f9de16d16eff4fe9d02dc9c6c9884d768c3cc43...7247260205cf7fa54b8785c87a919f1951151789?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvTXVsdGlWYXJpYW50RGF0YVNvdXJjZS5qYXZh) | `84.106% <ø> (+2.001%)` | `52% <ø> (+18%)` | :white_check_mark: |; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/compare/6f9de16d16eff4fe9d02dc9c6c9884d768c3cc43...7247260205cf7fa54b8785c87a919f1951151789?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `72.105% <ø> (+2.54%)` | `4% <ø> (ø)` | :x: |; | [...rg/broadinstitute/hellbender/utils/io/IOUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/6f9de16d16eff4fe9d02dc9c6c9884d768c3cc43...7247260205cf7fa54b8785c87a919f1951151789?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pby9JT1V0aWxzLmphdmE=) | `65.704% <ø> (+8.146%)` | `88% <ø> (+45%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2391?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2391?src=pr&el=footer). Last update [6f9de16...7247260](https://codecov.io/gh/broadinstitute/gatk/compare/6f9de16d16eff4fe9d02dc9c6c9884d768c3cc43...7247260205cf7fa54b8785c87a919f1951151789?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2391#issuecomment-278096683:3705,learn,learn,3705,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2391#issuecomment-278096683,1,['learn'],['learn']
Usability,"ci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nRW5naW5lLmphdmE=) | `46.491% <0%> (-2.632%)` | `32% <0%> (-9%)` | |; | [...lbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzLmphdmE=) | `77.996% <0%> (-0.179%)` | `175% <0%> (-1%)` | |; | [...ellbender/tools/walkers/annotator/QualByDepth.java](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9RdWFsQnlEZXB0aC5qYXZh) | `94.444% <0%> (-0.15%)` | `16% <0%> (-1%)` | |; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `85.484% <0%> (-0.116%)` | `49% <0%> (-1%)` | |; | [...ender/tools/walkers/annotator/InbreedingCoeff.java](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9JbmJyZWVkaW5nQ29lZmYuamF2YQ==) | `82.759% <0%> (ø)` | `11% <0%> (ø)` | :arrow_down: |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=footer). Last update [62d58c5...0492c9c](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2559#issuecomment-290845420:4184,learn,learn,4184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2559#issuecomment-290845420,1,['learn'],['learn']
Usability,clearing the milestone - our alpha does not depend on this pull req.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/936#issuecomment-151705716:0,clear,clearing,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/936#issuecomment-151705716,1,['clear'],['clearing']
Usability,"clearly, it's not working properly. @lbergelson what's the status?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1460#issuecomment-198379664:0,clear,clearly,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1460#issuecomment-198379664,1,['clear'],['clearly']
Usability,closing after discussing with the engine team that it's simpler to roll up one's own comparator; Thanks @magicDGS for looking!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4706#issuecomment-384762571:56,simpl,simpler,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4706#issuecomment-384762571,1,['simpl'],['simpler']
Usability,closing this. we'll move the code when it's more mature and usable by germline cnvs,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1373#issuecomment-166668206:60,usab,usable,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1373#issuecomment-166668206,1,['usab'],['usable']
Usability,closing. `invalid source release: 1.8` is pretty clear,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/489#issuecomment-119218019:49,clear,clear,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/489#issuecomment-119218019,1,['clear'],['clear']
Usability,"cmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `66.667% <0%> (+3.252%)` | `4% <0%> (ø)` | :arrow_down: |; | [...g/broadinstitute/hellbender/engine/AuthHolder.java](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvQXV0aEhvbGRlci5qYXZh) | `15.254% <0%> (+5.085%)` | `2% <0%> (ø)` | :arrow_down: |; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `77.703% <0%> (+6.757%)` | `22% <0%> (+4%)` | :arrow_up: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `86.4% <0%> (+8.8%)` | `35% <0%> (+7%)` | :arrow_up: |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `23.729% <0%> (+13.559%)` | `2% <0%> (+1%)` | :arrow_up: |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=footer). Last update [5ccfd00...8360cbe](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2573#issuecomment-291977600:3837,learn,learn,3837,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2573#issuecomment-291977600,1,['learn'],['learn']
Usability,"cness of the site is relevant to the false positive deletion.; >; > One could ask what in the GATK engine is responsible.; >; > - The assembly engine, perhaps? No, it is the assembly engine's job to; > propose possible haplotypes, not to call them. In any case, there *is*; > one spanning read with the deletion above the reads shown, so it is a valid; > path in the graph.; > - Pair-HMM? This one confused me for a while, but no. The engine is; > *not* saying that these reads' best alignment to the reference has a; > deletion, which would be false because there is a gap opening penalty.; > Rather, it says that they align equally well (with no deletions) to the ref; > haplotype and to the deletion haplotype. The deletion shown in IGV is the; > deletion of the alt haplotype relative to the reference, not of the reads; > relative to their best haplotype.; > - The bamout writer? Nope, that code is really straightforward and; > does the right thing.; >; > So what's the issue? Well, the bamout writer gets its read alignments from; > the readLikelihoods after the reads have been realigned to their best; > haplotype. In these cases, it turns out that the alignment of the reads to; > their best haplotype, the deletion has a log likelihood better than the; > alignment to the ref haplotype by about 0.00001. The simplest solution; > would be to give an extremely modest prior in favor of the reference and; > break these near-ties in favor of the reference. @droazen; > <https://github.com/droazen> @ldgauthier <https://github.com/ldgauthier>; > @yfarjoun <https://github.com/yfarjoun> if you think this is a good idea; > I can fix it for both HC and M2. Otherwise I'll do an M2-only fix.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4829>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0lv9nhpu6C8LQCF9jGJoX4UAmfJEks5t32IhgaJpZM4UUW5o>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4829#issuecomment-393417801:2180,simpl,simplest,2180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4829#issuecomment-393417801,1,['simpl'],['simplest']
Usability,"d from ApplyVQSR. See https://github.com/broadinstitute/gatk/pull/7954#discussion_r933570228.; - [ ] Add behavior for dealing with mixed SNP/INDEL sites in separate passes (and note that the current WDL currently does this, to allow for the use of different annotations across SNPs and INDELs). This might include rescuing previously filtered sites, etc. (e.g., by using the option to ignore the first-pass filter in the second pass). Alternatively, one could use a different FILTER name in each pass, which downstream hard-filtering steps could utilize intelligently. Or one might just split multiallelics upstream. In any case, I would hope that we could move towards running both SNPs and INDELs in a single pass with the same annotations as the default mode of operation.; - [ ] Clean up borrowed code in the `VariantType` class for classifying sites as SNP or INDEL. We mostly retained the VQSR code and logic to make head-to-head comparisons easier. Note also that we converted some switch statements to conditionals, etc. (which I think was done properly, but maybe I missed an edge case). See https://github.com/broadinstitute/gatk/pull/7954#discussion_r934776584.; - [ ] Think more about how to treat empty HDF5 arrays. It's possible we should handle this at the WDL level with optional inputs/outputs. Likely only relevant for atypical edge cases. See https://github.com/broadinstitute/gatk/pull/7954#discussion_r934845337. Next steps:. - [ ] I'll update the BGMM branch and open a PR.; - [ ] I'll start looking at implementing a simple CARROT test. We can just replicate the Cromwell/WDL test for now.; - [ ] Update that initial implementation with non-trivial data and evaluation scripts. EDIT: I see that #7982 was just filed.; - [ ] Implement a CARROT test with malaria data. We already have some evaluation scripts.; - [x] Expand the WDL to enable additional workflow modes (positive-negative, etc.) and the tests to cover them. Right now only vanilla positive-only is enabled/covered.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1209555008:2071,simpl,simple,2071,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1209555008,1,['simpl'],['simple']
Usability,"d that only include the ""official"" PARs, or also the additional ones you found?. In any case, are we comfortable calling in those regions (here I'm talking about gCNV, not ploidy)? As I show above, I don't think we need mappability to nail the baseline ploidy. Can we then rely on the per-bin bias to account for these regions in gCNV (pinning them back to the correct CN) without mappability filtering? And with mappability filtering, how substantial is the hit to coverage in these regions? Should we blacklist them for the time being?. To summarize, I think the order of events I'd like to see is this:. 1. Cut an **initial Beta** release that incorporates CollectReadCounts, streamline evaluations for the AACR poster, do a bit of tuning, establish a baseline. Hopefully the current ploidy calls suffice, if not, maybe issue a quick PR that implements the naive bin filtering (or whatever is necessary to get good ploidy calls). At the same time, get preliminary feedback from some users running on *small test cohorts* after we have some parameter recommendations.; 2. Do a round of method/model improvement. Start with quick and dirty fixes (e.g., blacklisting PARs) and work our way to more non-trivial changes. This will include many of the suggestions you have brought up, but we should also review user feedback and prioritize accordingly---they may find something that is not even on our radar. Demonstrate improvement (hopefully substantial!) over baseline, cut **second Beta** release.; 3. Run on larger cohorts, iron out remaining minor issues, and then productionize. By this time, @asmirnov239 will have hopefully made some progress on the PoN clustering front as well. **When we are ready, then we will take gCNV out of Beta.** With our current staffing situation, I do not expect this to happen before May 15, but I do enjoy pleasant surprises. :); 4. Run on gnomAD, world domination, etc. Again, getting a **initial Beta** release and some reasonable parameters to users is a high p",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639:2685,feedback,feedback,2685,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639,1,['feedback'],['feedback']
Usability,"d try to do it, as that is a relatively expensive resource to create. For example, some very naive hard filtering (red) of the histogram yields a peak that is easily fit by a negative binomial (green)---even a Poisson fit does not appear to bias the depth estimates, and certainly does not result in incorrect ploidy estimates:. ![masked_fit](https://user-images.githubusercontent.com/11076296/37863641-827a6e8a-2f37-11e8-83d5-cb4af32a898b.png). (Incidentally, it is helpful to plot on a log scale when checking the fit of these distributions.). This strategy also gives us a way to ignore low-level mosaicism or large germline events, which filtering on mappability may not address:. ![mosaic](https://user-images.githubusercontent.com/11076296/37863649-d0ac378c-2f37-11e8-8e98-45e1fa9a3d7a.png). So let's try to encapsulate changes to the ploidy tool. I agree that the histogram creation can be easily done on the Java side, to save on intermediate file writing. We can probably just cap the maximum bin to `k` and pass a samples x contig TSV where each entry is a vector with `k + 1` elements. I agree that there is still a lot of important work to be done in exploring our best practices for coverage collection, and I know that you have been interested in improving them for a while. Ultimately, we may want to consider incorporating mappability or other informative metadata, as we've discussed. However, this will require some non-trivial investment in method/tool development time. Since our preliminary evaluations show that even with the current, naive strategies the tool is performing reasonably well, I am prioritizing cutting a release and improving/automating the evaluations. As we discussed, this will both allow users to start using the tool (which will hopefully result in useful feedback) and establish a baseline for us. This will ultimately provide the necessary foundation for future exploratory work and method development---which always takes more time than we think it will!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375881040:2366,feedback,feedback,2366,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375881040,1,['feedback'],['feedback']
Usability,"dGraph only allows a single annotation/track. I'm not sure if the track definition line is intended to hold any metadata other than display parameters, either? https://genome.ucsc.edu/goldenPath/help/bedgraph.html. As for the unmarked column header line, the reason I decided this would be useful in the CNV TSV formats is that it's very easy to throw the table into a pandas or R dataframe for quick analysis, where you can then use the column names to manipulate the table. Typically, pandas/R TSV loading methods let you specify the `@` comment character to strip the SAM header (although we recently ran into some trouble with this in https://github.com/broadinstitute/gatk/pull/581). Note that we *require* a single unmarked column header, which is easy enough to skip (in the case you don't want to use it) if you know it's there. On the other hand, one could argue that if we store the type of each column in the metadata, then any analysis code should technically use that to parse the table (rather than letting pandas/R automatically infer the type of each column). So a marked column header line would make quick analyses a bit more difficult (as users would need to write parsing code), but could encourage more careful downstream code practices. @SHuang-Broad Just to be clear, the way I originally used ""annotation"" refers to any quantity that could be represented by a single type in a column (not in the sense of variant annotation). If string types are allowed, this is indeed pretty flexible! All I care about extracting is the common functionality related to the fact that we have locatable columns. I think the concerns you raise about e.g. SV representation in VCF are a separate matter, but happy to discuss further. I think once we decide what the header needs to be able to represent and what it should look like, this problem is mostly solved. There may be some things to decide about e.g. representation of doubles, NaNs, etc. but I don't think we need to be too rigid here.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-480917329:1427,clear,clear,1427,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-480917329,1,['clear'],['clear']
Usability,"ddition to sine waves of various frequency at S/N ratio 1:2 (to roughly simulate GC waves). Changepoints arising from the sine waves will be found first, since these give rise to longer segments:. ![wave-kern-no-local](https://user-images.githubusercontent.com/11076296/29322673-4dd9a1ac-81ac-11e7-94f5-5c5494e44ac5.png). CBS similarly finds many false positive breakpoints:. ![wave-cbs](https://user-images.githubusercontent.com/11076296/29322677-5576e4ba-81ac-11e7-888b-07ed5bff27e3.png). However, when we tune down the sine waves to 1:10, ApproxKernSeg still gets tripped up, but CBS looks better:. ![wave-kern-no-local-small-waves](https://user-images.githubusercontent.com/11076296/29322732-815df58c-81ac-11e7-8305-6e1798616336.png); ![wave-cbs-small-waves](https://user-images.githubusercontent.com/11076296/29322737-836b78fe-81ac-11e7-93be-753a40011203.png). To improve ApproxKernSeg, we can 1) make the cost function intensive, by simply dividing by the number of points in a segment, and 2) add to the cost function a local term, given by the cost of making each point a changepoint within a local window of a determined size. This local term was inspired by methods such as SaRa (http://c2s2.yale.edu/software/sara/). The reasoning is that with events at higher S/N ratio, we typically don't need to perform a global test to see whether any given point is a suitable changepoint; using the data locally surrounding the point typically suffices. With these modifications, ApproxKernSeg can handle both scenarios:; ![wave-kern](https://user-images.githubusercontent.com/11076296/29322762-a679dba6-81ac-11e7-9360-083a4e1da398.png); ![wave-kern-small-waves](https://user-images.githubusercontent.com/11076296/29322801-dad82010-81ac-11e7-8238-e057b0072e1b.png). This local window approach is still linear in time, so runtime is still ~1s for the above (about ~10x faster than CBS). One issue still remains, which is that even this improved approach tends to find directly adjacent possible chang",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-322502045:1593,simpl,simply,1593,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-322502045,1,['simpl'],['simply']
Usability,"der/utils/MannWhitneyU.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9NYW5uV2hpdG5leVUuamF2YQ==) | `92.793% <92.593%> (+17.237%)` | `48 <48> (+21)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `72.078% <0%> (-1.948%)` | `35% <0%> (ø)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `93.75% <0%> (-1.563%)` | `21% <0%> (-1%)` | |; | [...titute/hellbender/tools/spark/sv/ReadMetadata.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkTWV0YWRhdGEuamF2YQ==) | `84.104% <0%> (+2.358%)` | `36% <0%> (+11%)` | :arrow_up: |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `42.989% <0%> (+4.441%)` | `46% <0%> (+18%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=footer). Last update [c350a09...3b4f53e](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2605#issuecomment-294213579:3124,learn,learn,3124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2605#issuecomment-294213579,1,['learn'],['learn']
Usability,"done with my review. small edits, 1 bug, and a few performance questions. I'd like to see a simple perf run of HC with and without those changes. All those streams in math-heavy tight loops make me concerned a bit",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1979#issuecomment-231096260:92,simpl,simple,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1979#issuecomment-231096260,1,['simpl'],['simple']
Usability,done. moved getSpanningInterval to IntervalUtils and simplified + added tests for it. Moved IntervalUtilsUnitTest to the right package. No empty string in ctor. back to @lbergelson,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1497#issuecomment-186019881:53,simpl,simplified,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1497#issuecomment-186019881,1,['simpl'],['simplified']
Usability,"dsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `93.103% <100%> (+1.103%)` | `8 <1> (+1)` | :arrow_up: |; | [...adinstitute/hellbender/utils/spark/SparkUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zcGFyay9TcGFya1V0aWxzLmphdmE=) | `71.154% <63.158%> (-4.604%)` | `9 <5> (+5)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `95.313% <0%> (+1.563%)` | `22% <0%> (+1%)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `75.909% <0%> (+3.831%)` | `46% <0%> (+11%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=footer). Last update [2ecdef4...71a1b94](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2419#issuecomment-293289091:3143,learn,learn,3143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2419#issuecomment-293289091,1,['learn'],['learn']
Usability,duplicate (but probably clearer wording) of #175,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1928#issuecomment-227512681:24,clear,clearer,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1928#issuecomment-227512681,1,['clear'],['clearer']
Usability,"e being processed by a driver script using Open MPI. ```; $ tail -n 1 000?-scattered.interval_list; ==> 0000-scattered.interval_list <==; chr1 10001 990401 + .; ==> 0001-scattered.interval_list <==; chr1 990402 1970802 + .; ==> 0002-scattered.interval_list <==; chr1 1970803 2951203 + .; ==> 0003-scattered.interval_list <==; chr1 2951204 3931604 + .; ==> 0004-scattered.interval_list <==; chr1 3931605 4912005 + .; ==> 0005-scattered.interval_list <==; chr1 4912006 5892406 + .; ==> 0006-scattered.interval_list <==; chr1 5892407 6872807 + .; ==> 0007-scattered.interval_list <==; chr1 6872808 7853208 + .; ==> 0008-scattered.interval_list <==; chr1 7853209 8833609 + .; ==> 0009-scattered.interval_list <==; chr1 8833610 9814010 + .; ```. The H.P.C. administrator and I don't know what you mean by _thread names_. > I'm not sure what you mean by ""name"" of the threads. From a system perspective, threads don't have names distinct from the process as a whole. I guess it's possible that whatever code you're running attaches an internal name to the thread, but that's purely in the domain of your program – it's not something I can see at a system level.; > ; > To be clear, I'm talking about actual runnable tasks at a system level, i.e. multiple ""lightweight processes"" sharing the same address space – i.e. POSIX threads. How your application (or any runtime framework that you build upon, e.g. Java) is launching and distributing work across these, I don't know – again, that's the domain of your application.; > ; > All I can say is that multiple of these threads were active and causing a significant number of contexts switches between then. Since you're binding your processes to a single core, if multiple threads want to run at the same time the operating system needs to constantly switch between then in order for each to make progress, and this ""context switch"" between the threads is a relatively expensive operation. Any tips how I or him could view the thread names during execution?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7156#issuecomment-803684782:1465,clear,clear,1465,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7156#issuecomment-803684782,1,['clear'],['clear']
Usability,"e deleted, and its use `support = range(lo, hi)` should become `support = new IndexRange(lo, hi)`. Then `IntStream.of(support).mapToDouble(___).toArray()` becomes `range.mapToDouble(___)` and `apply(promote(support), ___)` becomes `support.mapToDouble(___)`. * `final double relErr = 1 + pow(10, -7)` should become a `static` constant. * The steps; ```java; final double maxD1 = arrayMax(d1);; final double[] d2 = apply(apply(d1, d -> d - maxD1), d -> exp(d));; final double sumD2 = sum(d2);; return apply(d2, d -> d/sumD2);; ```; inside `dnHyper` are just a home-brewed way to normalize the log-space array `d1`. Let's go throught the steps: 1) find the max. 2) subtract the max -- subtracting a constant in log-space is equivalent to dividing by a constant in real space, and since we're normalizing in the end this constant is arbitrary. It's done for numerical stability. 3) exponentiate to get an unnormalized real-space array. 4) find the sum. 5) divide by the sum to get the normalized result. The log-10 version of this is `MathUtils::normalizeFromLog10ToLinearSpace(d1)`. You could either calculate `d1` in log-10 space or convert it, replacing the above line with `return MathUtils.normalizeFromLog10ToLinearSpace(MathUtils.applyToArrayInPlace(d1, MathUtils::logToLog10))`. The latter option is simpler. * Import static should be avoided except to escape horrible clutter, which is not the case here. * The second argument of `Utils.validateArg(condition, calculated string expression)` should become `Utils.validateArg(condition, () -> calculated string expression)`. In the first version, the expression is calculated *even if* the condition is satisfied, whereas in the second it is only calculated as needed. It's not critical here but it's a good habit to get into. PS I am a zealot of the Boy Scout Rule (always leave the camp site cleaner than you found it). It is a great way to get familiar with a large code base and a great way to make the code more readable for the next person.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-266263155:1925,simpl,simpler,1925,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-266263155,1,['simpl'],['simpler']
Usability,"e is going to be a behavior different between the old iteration pattern. The existing code will iterate variants to establish whitelist of start sites, and then re-query variants overlapping those starts. This is generally identical in practice to MultiVariantWalkerGroupedOnStart; however, when -L is supplied, it can give differences. I'm not sure which I think is correct. . Example, from VariantEvalIntegrationTest.testFunctionClassWithSnpeff():. // The DbSNP VCF has two variants:; // 1 1423281 rs374004343 GGAAGC G . .; // 1 1423281 rs79849353 G A . .; // If we use 1423281 as the interval, we find both. // The SnpEff VCF has these two:; // 1 1423282 . GAAGC G; // 1 1423286 . C G. The SnpEff VCF is provided as -L when running the tool. Both SnpEff and DbSnp will be used as drivingVariants. Therefore when we hit interval 1423282, the DbSnp variant 1423281:GGAAGC>G variant will be included, but not 1423281:G>A. When using MultiVariantWalkerGroupedOnStart, this means only that variant is passed downstream. Previously, VariantEval would simply establish the whitelist of start sites (meaning the lowest from the group, or 1423281) and iterate them. This means that even though 1423282 is the interval from -L, it picks up the overlapping 1423281:GGAAGC>G, which effectively makes 1423281 a whitelisted start site. The existing behavior would iterate each start site and re-query overlapping variants in VariantEvalUtils.bindVariantContexts(). It would call:. List<VariantContext> prior = featureContext.getValues(track, referenceContext.getInterval().getStart());. In this instance, it would query on start=1423281, meaning it picked up both DbSnp sites, even though 1423281:G>A is not within the intervals supplied by -L. This is sort of a fringe case. I dont see how to fix this without reintroducing the expensive re-query step. I'm currently thinking that the existing behavior is probably what's wrong, but I'm going to consider this a little more. My last commit highlights this case",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-730697357:1052,simpl,simply,1052,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-730697357,1,['simpl'],['simply']
Usability,"ecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-07 11:34:12 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 9.419880 s; 2019-01-07 11:34:12 INFO AbstractConnector:318 - Stopped Spark@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:34:12 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-07 11:34:12 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-07 11:34:12 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-07 11:34:12 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-07 11:34:12 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-07 11:34:12 INFO BlockManager:54 - BlockManager stopped; 2019-01-07 11:34:12 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-07 11:34:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-07 11:34:12 INFO SparkContext:54 - Successfully stopped SparkContext; 11:34:12.605 INFO CountReadsSpark - Shutting down engine; [January 7, 2019 11:34:12 AM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=1003487232; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:36067,clear,cleared,36067,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['clear'],['cleared']
Usability,ed=false disableDithering=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 baq=OFF baqGapOpenPenalty=40.0 refactor_NDN_cigar_string=false fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false useOriginalQualities=false defaultBaseQualities=-1 performanceLog=null BQSR=null quantize_quals=0 static_quantized_quals=null round_down_quantized=false disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 globalQScorePrior=-1.0 validation_strictness=SILENT remove_program_records=false keep_program_records=false sample_rename_mapping_file=null unsafe=null disable_auto_index_creation_and_locking_when_reading_rods=false no_cmdline_in_header=false sites_only=false never_trim_vcf_format_field=false bcf=false bam_compression=null simplifyBAM=false disable_bam_indexing=false generate_md5=false num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false variant_index_type=DYNAMIC_SEEK variant_index_parameter=-1 reference_window_stop=0 logging_level=INFO log_to_file=null help=false version=false variant=(RodBinding name=variant source=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/GTEx_AS/GTEx_AS.recal.multialleleics.AS.recalibrated.vcf) discordance=(RodBinding name= source=UNBOUND) concordance=(RodBinding name= source=UNBOUND) out=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/GTEx_AS/GTEx_AS.recal.multialleleics.AS.recalibrated.mixed.vcf sample_name=[] sample_expressions=null sample_file=null exclude_sample_name=[] exclude_sample_file=[] exclude_sample_expressions=[] selectexpressions=[] invertselect=false excludeNonVariants=false excludeFiltered=false preserveAlleles=false removeUnusedAlternates=false restrictAllelesTo=ALL keepOriginalAC=false ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834:4577,simpl,simplifyBAM,4577,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834,1,['simpl'],['simplifyBAM']
Usability,ed=false disableDithering=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 baq=OFF baqGapOpenPenalty=40.0 refactor_NDN_cigar_string=false fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false useOriginalQualities=false defaultBaseQualities=-1 performanceLog=null BQSR=null quantize_quals=0 static_quantized_quals=null round_down_quantized=false disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 globalQScorePrior=-1.0 validation_strictness=SILENT remove_program_records=false keep_program_records=false sample_rename_mapping_file=null unsafe=null disable_auto_index_creation_and_locking_when_reading_rods=false no_cmdline_in_header=false sites_only=true never_trim_vcf_format_field=false bcf=false bam_compression=null simplifyBAM=false disable_bam_indexing=false generate_md5=false num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false variant_index_type=DYNAMIC_SEEK variant_index_parameter=-1 reference_window_stop=0 logging_level=INFO log_to_file=null help=false version=false variant=(RodBinding name=variant source=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/GTEx_AS/GTEx_AS.recal.multialleleics.AS.recalibrated.mixed.vcf) discordance=(RodBinding name= source=UNBOUND) concordance=(RodBinding name= source=UNBOUND) out=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/VQSR.AStest.input.vcf sample_name=[] sample_expressions=null sample_file=null exclude_sample_name=[] exclude_sample_file=[] exclude_sample_expressions=[] selectexpressions=[] invertselect=false excludeNonVariants=false excludeFiltered=false preserveAlleles=false removeUnusedAlternates=false restrictAllelesTo=ALL keepOriginalAC=false keepOriginalDP=false mendelianViola,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834:1469,simpl,simplifyBAM,1469,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834,1,['simpl'],['simplifyBAM']
Usability,"ee#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9mZXJtaS9GZXJtaUxpdGVBc3NlbWJsZXIuamF2YQ==) | `80.645% <80.645%> (ø)` | `8 <8> (?)` | |; | [...stitute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...d6fb1ba347fbb8042e8473870fbffec02e211349?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `92.308% <ø> (+0.447%)` | `28% <ø> (+28%)` | :white_check_mark: |; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...d6fb1ba347fbb8042e8473870fbffec02e211349?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `87.097% <ø> (+0.986%)` | `59% <ø> (+59%)` | :white_check_mark: |; | [...adinstitute/hellbender/tools/spark/sv/SVUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...d6fb1ba347fbb8042e8473870fbffec02e211349?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TVlV0aWxzLmphdmE=) | `38.462% <ø> (+5.52%)` | `12% <ø> (+12%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2381?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2381?src=pr&el=footer). Last update [8a42977...d6fb1ba](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...d6fb1ba347fbb8042e8473870fbffec02e211349?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2381#issuecomment-276803321:3296,learn,learn,3296,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2381#issuecomment-276803321,1,['learn'],['learn']
Usability,"eed up the old allele-fraction model, which is now the main bottleneck. An easy (lazy) strategy might simply be to downsample and scale likelihoods when estimating global parameters. Addresses #2884.; - [x] Even though the simple copy-ratio model is much faster, it still takes ~15-20 minutes for 100 iterations on WGS, so we can downsample here too.; - [x] Integration tests are still needed; again, these might not test for correctness.; - I've added the ability to specify a prior for the minor-allele fraction, which alleviates the problem of residual bias in balanced segments.; - I've reduced the verbosity of the modeled-segments file. I only report posterior mode and 10%, 50%, and 90% deciles. Global parameters have the full deciles output in the .param files, but I removed the mode and highest density credible interval (because of the below item).; - [x] Some residual bias remains in the estimate of the minor-allele fraction posterior mode. This is simply because we are performing kernel density estimation of a bounded quantity. One possibility would be to logit transform to an unbounded support, perform the estimation, then transform back. EDIT: Just removed kernel density estimation for now, partly due to #3599 as well.; - Hmm, actually still a tiny bit of residual bias. This is apparent e.g. in WGS normals. I think focusing on a new allele-fraction model rather than trying to figure out where the old one is failing would be best.; - [x] For small bins (250bp), the copy-ratio model is currently a bit memory intensive, since it stores an outlier indicator boolean for every data point (it gets by with -Xmx12g for 100 iterations at 250bp). There is no easy away around storing this at the GibbsSampler level (although we could make some non-trivial changes to that code, as @davidbenjamin suggested long ago at https://github.com/broadinstitute/gatk-protected/issues/195). However, I got rid of these at the CopyRatioModeller level. If we want to go down in memory, we cou",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:6594,simpl,simply,6594,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,1,['simpl'],['simply']
Usability,"egion traversal currently works. Here's a summary of what's going on:. -dcov 200 does cause LIBS to cap the depth at each locus to 200, but due to code Mark added a while back LIBS will save all of the undownsampled reads in memory during active region traversals (which kind of defeats the purpose of downsampling in the first place!). -TraverseActiveRegions gets the undownsampled reads from LIBS, and adds them to the active regions that get passed to the walker. -The HaplotypeCaller does a post-hoc downsampling pass on the reads in the active region in finalizeActiveRegion() to a hardcoded (!!!) and completely arbitrary depth of 1000, ignoring dcov. -The HaplotypeCaller does realignment of reads to the haplotypes, potentially causes the depth of coverage to vary at the locus in question. -The GenotypingEngine then computes DP based on the reads that still overlap the locus post-realignment. The end result is that DP for the HaplotypeCaller represents the undownsampled depth of coverage at the locus in question, subject to the hardcoded cap of 1000 and realignment to the haplotypes. In this particular case, the actual depth at locus 1:14464 is 561 (with no downsampling), and the DP value is 546. The difference is likely due to realignment of reads to the haplotypes by the walker. So, we basically have two options:; 1. Change the documentation for the DP annotation to mention that for ActiveRegion walkers it reflects the undownsampled depth subject to things like realignment to the haplotypes (easiest option, but doesn't fix the underlying craziness); 2. Change the ActiveRegion traversal so that it respects the dcov value (could be hard -- the LIBS downsampling process discards reads on-the-fly from previous loci when moving to a new locus, but an active region involves data for multiple loci. The potential performance win for the HC is huge, though, if we could pull this off). [...]. Alright, next step then is to figure out whether it's even feasible to make the Activ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345:3463,undo,undownsampled,3463,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345,1,['undo'],['undownsampled']
Usability,"el=desc) will **decrease** coverage by `-<.001%`.; > The diff coverage is `75%`. ```diff; @@ Coverage Diff @@; ## master #2366 +/- ##; ===============================================; - Coverage 76.201% 76.201% -<.001% ; - Complexity 10808 10812 +4 ; ===============================================; Files 750 750 ; Lines 39417 39421 +4 ; Branches 6858 6859 +1 ; ===============================================; + Hits 30036 30039 +3 ; Misses 6775 6775 ; - Partials 2606 2607 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2366?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ellbender/cmdline/StandardArgumentDefinitions.java](https://codecov.io/gh/broadinstitute/gatk/compare/f45f6a52d69fbf01541099cf737a0fc5391d584e...75c14f4c17c957aa969a69a94c966fad3d5c8f1d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL1N0YW5kYXJkQXJndW1lbnREZWZpbml0aW9ucy5qYXZh) | `0% <ø> (ø)` | `0 <ø> (ø)` | :x: |; | [...org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/compare/f45f6a52d69fbf01541099cf737a0fc5391d584e...75c14f4c17c957aa969a69a94c966fad3d5c8f1d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2wuamF2YQ==) | `92.568% <75%> (-0.488%)` | `74 <2> (+3)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2366?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2366?src=pr&el=footer). Last update [f45f6a5...75c14f4](https://codecov.io/gh/broadinstitute/gatk/compare/f45f6a52d69fbf01541099cf737a0fc5391d584e...75c14f4c17c957aa969a69a94c966fad3d5c8f1d?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2366#issuecomment-276527211:1778,learn,learn,1778,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2366#issuecomment-276527211,1,['learn'],['learn']
Usability,"el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0dlbm90eXBlR1ZDRnMuamF2YQ==) | `90.71% <0%> (-0.43%)` | `100% <0%> (-1%)` | |; | [...lbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzLmphdmE=) | `87.3% <0%> (-0.31%)` | `244% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.77% <0%> (+0.47%)` | `33% <0%> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `80% <0%> (+30%)` | `3% <0%> (+2%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5844?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5844?src=pr&el=footer). Last update [7c24e67...43708f1](https://codecov.io/gh/broadinstitute/gatk/pull/5844?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5844#issuecomment-477765576:3454,learn,learn,3454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5844#issuecomment-477765576,1,['learn'],['learn']
Usability,"eport; > Merging [#2550](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/c8ede6ef810a3d9a05c7deb8052e27ca724ce8ba?src=pr&el=desc) will **increase** coverage by `0.003%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #2550 +/- ##; ===============================================; + Coverage 76.279% 76.282% +0.003% ; - Complexity 10891 10892 +1 ; ===============================================; Files 752 752 ; Lines 39590 39590 ; Branches 6925 6925 ; ===============================================; + Hits 30199 30200 +1 ; Misses 6768 6768 ; + Partials 2623 2622 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...recalibration/RecalibrationArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWNhbGlicmF0aW9uL1JlY2FsaWJyYXRpb25Bcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `93.827% <100%> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=footer). Last update [c8ede6e...f810842](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2550#issuecomment-290461016:1666,learn,learn,1666,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2550#issuecomment-290461016,1,['learn'],['learn']
Usability,"erage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2521 +/- ##; ===============================================; + Coverage 76.256% 76.261% +0.005% ; Complexity 10864 10864 ; ===============================================; Files 750 750 ; Lines 39543 39543 ; Branches 6915 6915 ; ===============================================; + Hits 30154 30156 +2 ; + Misses 6771 6769 -2 ; Partials 2618 2618; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2521?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...notyper/GenotypeCalculationArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/compare/7ad3c91b96448c4a867451b40b7ce6ae41cef690...2622598137d07ee362c7d98cb67e89862df0276e?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwZUNhbGN1bGF0aW9uQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `100% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/7ad3c91b96448c4a867451b40b7ce6ae41cef690...2622598137d07ee362c7d98cb67e89862df0276e?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2521?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2521?src=pr&el=footer). Last update [7ad3c91...2622598](https://codecov.io/gh/broadinstitute/gatk/compare/7ad3c91b96448c4a867451b40b7ce6ae41cef690...2622598137d07ee362c7d98cb67e89862df0276e?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2521#issuecomment-288757656:1842,learn,learn,1842,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2521#issuecomment-288757656,1,['learn'],['learn']
Usability,"erent results by the first filtering step (on intervals by interval median). @LeeTL1220 @davidbenjamin what is the ""official ReCapSeg"" behavior, and do we want to keep the current behavior? In general, I think all of the standardization (i.e., filtering/imputation/truncation/transformation) steps could stand some revisiting. Evaluation:. - [ ] Revisit standardization procedure by checking with simulated data. We should make sure that the centering of the data does not rescale the true copy ratio.; - [x] <s>Investigate the effect of keeping duplicates. I am still not sure why we do this, and it may have a more drastic impact on WGS data.</s> Turns out we don't keep duplicates for WGS; see #3367.; - [ ] Check that GC-bias-correction+PCA and PCA-only perform comparably, even at small bin sizes (~300bp). From what I've seen, this is true for larger bin sizes (~3kbp), so explicit GC-bias correction may not be necessary. (That is, even at these (purportedly) large bin sizes, the effect of the read-based GC-bias correction is obvious for those samples where it is important. However, the end result is not very different from PCA-only denoising with no GC-bias correction performed.); - [x] <s>Check that changing CBS alpha parameter sufficiently reduces hypersegmentation.</s> <s>Looks like the hybrid p-value calculation in DNACopy is not accurate enough to handle WGS-size data. (Also, it's relatively slow, taking ~30 minutes on ~10M intervals.) Even if I set alpha to 0, I still get a ridiculous number of segments! So I think it's finally time to scrap CBS. I'll look into other R segmentation packages that might give us a quick drop-in solution, but we may want to roll our own simple algorithm (which we will scrap anyway once the coverage model is in for somatic).</s> I've implemented a fast kernel-segmentation method that seems very promising, see below.; - [ ] Investigate performance vs. CGA ReCapSeg pipeline on THCA samples.; - [ ] Investigate concordance with Genome STRiP.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-316894351:5610,simpl,simple,5610,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-316894351,1,['simpl'],['simple']
Usability,"es. I'll have to do some performance testing to see whether or not this is the case. Will try to get to this within the next few weeks, but the QC project has immediate priority. [...]. Discussed this with Ryan -- we agreed that the right thing to do is to move the enforcement of the hard cap on the total number of reads that can be in an active region from the HC walker to the engine, and have the size of the cap be controlled by a new argument (not dcov). That way you never pay the cost of storing the undownsampled reads for an active region in memory. We'd also have to educate users on exactly what the various downsampling arguments do for active region walkers. [...]. Making the hardcoded per-active-region cap settable from the command line is the easy part -- what seems hard is:; - Determining whether we can avoid storing all undownsampled reads in memory at once without affecting the quality of calls. Currently, as outlined in earlier comments on this ticket, we do a downsampling pass per locus which respects dcov (in LocusIteratorByState) but keep all undownsampled reads in memory anyway (defeating the main purpose of that first pass), then do a second downsampling pass per active region that does not respect dcov (uses the hardcoded per-region limit).; - If we find that we can't avoid storing all of the undownsampled reads in memory at once for some reason, then perhaps the right thing to do would be to completely disable the downsampling pass in LocusIteratorByState for active region traversals, and disallow the -dcov argument for active region walkers. Downsampling would then by controlled solely by the new argument to set the max # of reads per active region.; - Clarifying the meaning of the per-locus DP annotation for the HC given things like realignment of reads to haplotypes and region-based downsampling. ---. Eventually it was agreed that this would never be fixed in Classic GATK but should be taken into account in designing Hellbender's downsampling.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345:5940,undo,undownsampled,5940,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345,2,['undo'],['undownsampled']
Usability,"f-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `53.247% <0%> (-18.071%)` | `28% <0%> (-6%)` | |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `40.469% <0%> (-18.009%)` | `28% <0%> (ø)` | |; | ... and [42 more](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=footer). Last update [781db35...13a10e2](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2574#issuecomment-292193941:4100,learn,learn,4100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2574#issuecomment-292193941,1,['learn'],['learn']
Usability,"ference/ReferenceBases.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWZlcmVuY2UvUmVmZXJlbmNlQmFzZXMuamF2YQ==) | `38.46% <0%> (-19.24%)` | `4% <0%> (-2%)` | |; | [...oadinstitute/hellbender/engine/ReferenceShard.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVmZXJlbmNlU2hhcmQuamF2YQ==) | `62.5% <0%> (-18.75%)` | `6% <0%> (-1%)` | |; | [...broadinstitute/hellbender/engine/VariantShard.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvVmFyaWFudFNoYXJkLmphdmE=) | `63.63% <0%> (-13.64%)` | `7% <0%> (-1%)` | |; | [...ne/spark/datasources/ReferenceWindowFunctions.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVmZXJlbmNlV2luZG93RnVuY3Rpb25zLmphdmE=) | `12.5% <0%> (-12.5%)` | `1% <0%> (ø)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `79.87% <0%> (+1.21%)` | `42% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5292?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5292?src=pr&el=footer). Last update [a74e571...3768ba2](https://codecov.io/gh/broadinstitute/gatk/pull/5292?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5292#issuecomment-427904892:4202,learn,learn,4202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5292#issuecomment-427904892,1,['learn'],['learn']
Usability,first simple and naive impl merged in by pull #252,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/104#issuecomment-77252124:6,simpl,simple,6,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/104#issuecomment-77252124,1,['simpl'],['simple']
Usability,"fter which the usual modelling and smoothing steps are performed. For the 75% tumor + 25% normal mixture, this yields 122 segments (up from 83):; ![N-25-T-75-SJS modeled](https://user-images.githubusercontent.com/11076296/76558618-015bd180-6474-11ea-996a-48d39770149b.png). For the 25% tumor + 75% normal mixture, this yields 105 segments (up from 50):; ![N-75-T-25-SJS modeled](https://user-images.githubusercontent.com/11076296/76560726-34a05f80-6478-11ea-9027-a54726c46b9e.png). One could imagine that smoothing could be disabled (so that all samples retain the common segmentation after modeling) or made more aggressive (so that private events don't get inadvertently introduced into other samples due to noise, perhaps), depending on the use case. It looks like the joint segmentation allows some additional events to be resolved, although I haven't done any rigorous evaluations. We could probably cook up some evaluations using simulated toy data or in silico mixtures, but there's really no reason why this shouldn't work decently well, especially if the kernel-segmentation method works well on a single sample for your data. It would also be interesting to understand at which point changing segmentation parameters on a single sample can no longer yield the same performance as joint segmentation on a fixed number of samples; however, this is probably a function of various S/N ratios, and it might not be easy to characterize this behavior outside of toy data. The segmentation parameter space is big enough to make this unwieldy even for toy data, too. Perhaps we can get some feedback from test users---not only on performance, but also on the structure of the new workflow. It might also be worth gauging whether a new WDL is warranted. Otherwise, we just need to add some unit tests for correctness of the multisample-segmentation backend class, integration tests for plumbing of the new tool, and perhaps address some of the issues mentioned above. Then I'd say this is good to go.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-598386823:2724,feedback,feedback,2724,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-598386823,1,['feedback'],['feedback']
Usability,"g forward. Finally, I don't think we have satisfactorily demonstrated which of the functions accomplished by this code (format conversion, post-hoc blacklisting, germline/""CNLOH"" tagging and imputation) are necessary or cannot be performed by existing code or more streamlined and principled methods. (Some of these functions, such as IGV conversion, are already performed by existing code.) Of those functions, I think format conversion is the only one we should retain from this code in an unsupported fashion. So if this PR introduces a useful GISTIC conversion, no harm in merging that. This all sounds like a decision for the new tech lead! @mwalker174 any thoughts? . More detailed responses follow:. > Users are already using this branch and giving me positive feedback (definitely more positive than adjusting num_changepoints_penalty_factor). I suggest merging mostly for practical reasons. It buys us more time to put in a principled solution. And this workflow is clearly marked as an unsupported prototype anyway (as are the GATK CLIs). I want to emphasize that this whole workflow is not a long-term solution. In other words, I would like to get this in and then focus on a supported solution. While it's great that users are giving positive feedback, I refer you to CellBender team's manifesto at https://github.com/broadinstitute/CellBender/commit/28f02f8dbd716aff922bb8da1e56da29347b245b. Can these users help us definitively resolve whether these events are 1) germline with incorrectly normalized CR, or 2) mosaic CNLOH? If not, then we have not even taken the first step to correctly identify the issue. So it seems a bit premature to even prototype a method, much less merge it. I think this PR, as is, muddies the waters quite a bit. For example, it introduces a new Record class that denotes this type of ""CNLOH"" with a `C`. If we want to merge this, I suggest that we first correctly identify the issue. If these events are not mosaic CNLOH, then we should clean up all mention ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199:1538,clear,clearly,1538,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199,1,['clear'],['clearly']
Usability,"g traversal; 01:16:17.470 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 01:16:17.493 INFO ProgressMeter - unmapped 0.0 4 10434.8; 01:16:17.493 INFO ProgressMeter - Traversal complete. Processed 4 total variants in 0.0 minutes.; 01:16:17.493 INFO FilterByOrientationBias - Tagging whether genotypes are in one of the artifact modes.; 01:16:17.496 INFO ProgressMeter - Starting traversal; 01:16:17.496 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 01:16:17.497 INFO ProgressMeter - unmapped 0.0 8 480000.0; 01:16:17.498 INFO ProgressMeter - Traversal complete. Processed 8 total records in 0.0 minutes.; 01:16:17.500 INFO OrientationBiasFilterer - NORMAL: Nothing to filter.; 01:16:17.500 INFO OrientationBiasFilterer - TUMOR: Nothing to filter.; 01:16:17.500 INFO OrientationBiasFilterer - Updating genotypes and creating final list of variants...; 01:16:17.500 INFO ProgressMeter - Starting traversal; 01:16:17.501 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 01:16:17.501 INFO ProgressMeter - unmapped 0.0 4 Infinity; 01:16:17.501 INFO ProgressMeter - Traversal complete. Processed 4 total records in 0.0 minutes.; 01:16:17.501 INFO FilterByOrientationBias - Writing variants to VCF...; 01:16:17.512 INFO FilterByOrientationBias - Writing a simple summary table...; 01:16:17.576 INFO FilterByOrientationBias - Shutting down engine; [June 6, 2017 1:16:17 AM EDT] org.broadinstitute.hellbender.tools.exome.FilterByOrientationBias done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=232259584; WMCF9-CB5:hellbender shlee$ ; ```. This is the case for the file that I augmented with what the sed command was meant to do. Otherwise, the command errors. I think the tool should be able to take CollectSequencingArtifactMetrics whether run using Picard or GATK. I say this since folks may have these metrics from old runs before the as-of-yet-available Picard tools in the GATK jar.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891:5494,simpl,simple,5494,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891,1,['simpl'],['simple']
Usability,"gScores.hdf5 /repo/extract.nonAS.snpIndel.posUn.train.snpIndel.posOnly.IF.snp.trainingScores.hdf5. file1 file2; ---------------------------------------; x x / ; x x /data ; x x /data/scores . group : </> and </>; 0 differences found; group : </data> and </data>; 0 differences found; dataset: </data/scores> and </data/scores>; size: [445] [445]; position scores scores difference ; ------------------------------------------------------------; [ 60 ] -0.419202 -0.419202 5.55112e-17 ; 1 differences found; ```. Looks pretty negligible to me! :stuck_out_tongue_closed_eyes: Probably a result of the native code being called by the python/ML packages used in these tools; even minor changes in the compilers across Ubuntu versions might introduce differences like these. A quick fix might be to replace all system calls to `h5diff` in these tests with `h5diff --use-system-epsilon`; seems to do the trick here. But if that doesn't fix all test cases, then perhaps you can relax things with `h5diff -p EPSILON`, where `EPSILON` is a relative threshold. Probably OK to pick something like `1E-6`. OK if I leave it to you to try this or otherwise check the rest of the cases?. Sorry for the inconvenience! I think the exact-match test worked as intended here, but I probably could've put in better messaging originally. Unfortunately, it's a bit awkward to grab the output of system commands. And thanks for dealing with conda again (a necessary evil, unless we want to reimplement the entire field of machine learning in Java)! I'll experiment to see if I can't get the more recent version used in #8561 (23.10) working with the current environment---probably just some minor tweak to the pip version is needed to get around the error you're seeing. You could try unpinning it to see what gets pulled in. It would be great if we could get off the old version of conda, since more recent versions using the libmamba solver are *MUCH* faster and would cut down all of our Docker build times substantially.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8610#issuecomment-1848796931:2044,learn,learning,2044,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8610#issuecomment-1848796931,1,['learn'],['learning']
Usability,"given that we only have easy access to scores for positive truth---and hence, no false positives, which precludes calculation of precision and F1. I *think* we could pass a VCF for a sample with gold-standard positives and negatives and use the existing code for extracting labels, but this will require a bit of engineering and be more trouble than it's worth. There are other options---see https://ir.cwi.nl/pub/30479, for example. We might want to experiment with the LL score discussed there (see https://www.aaai.org/Papers/ICML/2003/ICML03-060.pdf for the original paper---although note that despite the paper's high citation count, I'm not sure what the canonical name for this metric actually is, but it doesn't appear to be ""LL score""---perhaps someone else knows or has better Google-fu and can figure it out) before moving on to their methods for estimating F1. Doing a literature search for other discussions of optimizing F1 or other metrics in the context of positive-unlabeled learning might be worthwhile, but I think most methods will probably involve some sort of estimation of the base rate in unlabeled data. I think we may have to add some mechanism for holding out a validation set during training if we want to automatically tune thresholds in a rigorous fashion. Shouldn't be too bad---we can just have the training tool randomly mask out a set of the truth and pass the mask to the scoring tool (or maybe just determine the threshold in the training tool, if we are running in positive/negative mode and have access to unlabeled data)---but does add a couple of parameters to the tool interfaces. This also adds additional dependence on the quality of the truth resources. I think an implicit assumption in any use of the truth---even just thresholding/calibrating by sensitivity---is that it is a random sample; however, I'm not sure how true this is in actual use. For example, in malaria, it looks like we may have to resort to using a callset that has been very conservat",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241:1060,learn,learning,1060,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241,1,['learn'],['learning']
Usability,"gments` optionally takes denoised copy ratio and/or allelic counts, `PlotModeledSegments` outputs only the corresponding plots appropriately.; - I added a dependency on the R package `data.table` to slightly speed up the reading of input files.; - Setting `pch="".""` also sped up the generation of scatter plots.; - Plotting now takes a couple of minutes, most of which is I/O (#3554).; - AAF (rather than MAF) is now plotted for allele fraction (#2957). Other:; - I've introduced a `LocatableCollection` class to unify how allelic counts, copy ratios, and segments are stored and read/written from/to TSV (#2836). Intervals are always output in lexicographical order for now, to be consistent with the old coverage collection (#2951). Once @asmirnov239's `CollectReadCounts` is in, we can change everything over to ordering determined by the sequence dictionary.; - Column headers and log2 copy ratio output have been standardized throughout (#2886).; - [x] I've also introduced a `NamedSampleFile` abstract class to tag files that have `#SAMPLE_NAME=...` as the first comment line. For `CollectAllelicCounts`, this simply uses code borrowed from `GetSampleName`. We should unify the reading and storing of sample names at some point (#2910).; - [x] We will need to replace `SimpleReadCountCollection` (which currently serves as the interface between the old coverage collection files and the new code) with one of these subclasses when `CollectReadCounts` is in. We can also change `NamedSampleFile` depending on what he's implemented.; - [x] We should eventually write proper SAM headers with useful tags to all TSV and HDF5 files generated by our tools that represent annotated intervals that can be associated with a single sample. Documentation:; - [x] I need to update class javadoc and example invocations throughout. The initial PR will already be quite massive, so I'll leave this until later. Perhaps @sooheelee might want to be involved?; - [ ] I will update the white paper at some point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:10099,simpl,simply,10099,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,1,['simpl'],['simply']
Usability,"haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...ark/sv/CallVariantsFromAlignedContigsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9DYWxsVmFyaWFudHNGcm9tQWxpZ25lZENvbnRpZ3NTQU1TcGFyay5qYXZh) | `0% <0%> (-26.087%)` | `0% <0%> (-5%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `48.837% <0%> (-24.774%)` | `27% <0%> (-9%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-18.75%)` | `6% <0%> (ø)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | ... and [27 more](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=footer). Last update [5d2f859...7a651b7](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-287020306:4172,learn,learn,4172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-287020306,1,['learn'],['learn']
Usability,"hat's happening. We wouldn't expect gatk4 haplotype caller to be that much slower. . It looks like they're running beta2 which is kind of old as well. Can you ask them what exact version they're using?. Can you ask if they have the log (stdout + stderr) for the gatk4 non-spark run? I can't tell what pairhmm they're actually running with and the logs would help with that. . Can you also find out what sort of hardware they're running on? Specifically, is it an intel machine with support for AVX?. A good setting for` --nativePairHmmThreads` is probably 4-8, you won't see any improvement after that. I also noticed that they're setting -XX:+UseParallelGC -XX:ParallelGCThreads=32 for the gatk3. They would be better off setting it to 2-4 threads. Performance gets worse beyond that typically from what I've seen. They can set the same thing for gatk4 using`--javaOptions ' -XX:+UseParallelGC -XX:ParallelGCThreads=4'`. Their spark configuration looks wrong in a number of ways which is probably a big part of why they're not seeing any improvement. In general you want executors with ~4-8 cores and at least 4g of memory per core. I don't know how much memory their nodes have, and I don't know if they're running with autoscaling turned on, but I suspect they're only allocating 1 executor on 1 node and then it's thrashing memory because it's trying to run 32 threads at once. Spark tuning for haplotype caller is going to be complicated though and I don't know how to do it will yet, we will be revisiting it in the next quarter probably. They're also running withs spark 2.1.0, we currently require spark 2.0.2 which is an unfortunately specific version, we're planning on upgrading to spark 2.2.+ in the next quarter. . You should make it clear to them that the results will not be the same between 3, 4, and 4-spark yet and that 4 is in rapid state of flux and has known performance issues that we're planning on working soon. Even so though, that slowdown they're seeing is bizarrely large.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3631#issuecomment-332879964:1784,clear,clear,1784,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3631#issuecomment-332879964,1,['clear'],['clear']
Usability,"hbmRMaW5lUHJvZ3JhbS5qYXZh) | `95.714% <0%> (+2.456%)` | `38% <0%> (+9%)` | :arrow_up: |; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/compare/88c181df462379fed902c8ae35b0ca142e2bd88d...298212c811d06554a7ad7e97e200172feef6496c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `87.156% <0%> (+2.945%)` | `66% <0%> (+13%)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/88c181df462379fed902c8ae35b0ca142e2bd88d...298212c811d06554a7ad7e97e200172feef6496c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/88c181df462379fed902c8ae35b0ca142e2bd88d...298212c811d06554a7ad7e97e200172feef6496c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `70.47% <0%> (+4.154%)` | `46% <0%> (+18%)` | :arrow_up: |; | ... and [3 more](https://codecov.io/gh/broadinstitute/gatk/pull/2495?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2495?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2495?src=pr&el=footer). Last update [88c181d...298212c](https://codecov.io/gh/broadinstitute/gatk/compare/88c181df462379fed902c8ae35b0ca142e2bd88d...298212c811d06554a7ad7e97e200172feef6496c?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2495#issuecomment-287912625:5035,learn,learn,5035,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2495#issuecomment-287912625,1,['learn'],['learn']
Usability,"he per-contig coverage histograms (unfiltered bins in blue, bins retained after filtering in red, and negative-binomial fit in green) and a heatmap of per-contig ploidy probabilities. Both the panel (first 20) and case (remaining) samples are shown:. ![prototype-result](https://user-images.githubusercontent.com/11076296/37938642-e9fbd804-312c-11e8-8a6c-02ea4e4fa704.png). Although the prototype model is clearly a good fit to the filtered data, some care in choosing the optimizer and its learning parameters is required to achieve convergence to the correct solution. This is because the problem is inherently multimodal and thus there are many local minima. I found that using AdaMax with a naive strategy of warm restarts (to help kick us out of local minima) worked decently; we can achieve convergence in <10 minutes for 60 samples x 24 contigs x 250 count bins:. ![elbo](https://user-images.githubusercontent.com/11076296/37938658-fc176f12-312c-11e8-89e2-40c68e0f9953.png). I expect that @mbabadi's annealing implementation in the gcnvkernel package will handle the local minima much better. The course of action needed to implement this model should be as follows:. 1) Alter Java code to emit per-contig histograms. Change python code to consume histograms, perform filtering, and fit using the above model (or some variation).; 2) Choose learning parameters appropriate with annealing and check that results are still good.; 3) Update gCNV model to consume the depth emitted by this model properly, if necessary, and rerun evaluations. Other improvements enabled by mappability filtering (as discussed in #4558) or coverage collection can follow this initial model revision. In the meantime, we will continue the first round of evaluations using the old ploidy model, spot checking genotype calls as necessary. This will allow us to tune gCNV parameters (which will hopefully be largely unaffected by any changes to the ploidy model). How does this sound, @ldgauthier @mbabadi @asmirnov239?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271:3370,learn,learning,3370,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271,1,['learn'],['learning']
Usability,hey @alexbarrera thanks for writing in. This is a known issue that we are aware of and we have unfortunately dealt with on several occasions (lexocographic vs. numerical sorting of readnames). Would it be possible for you to re-sort your bam using SortSam with -SO queryname to clear this up in your use-case as a workaround?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8147#issuecomment-1374035751:278,clear,clear,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8147#issuecomment-1374035751,1,['clear'],['clear']
Usability,"hhaW5QcnVuZXIuamF2YQ==) | `83.33% <0%> (-12.23%)` | `5% <0%> (-15%)` | |; | [...r/arguments/CopyNumberArgumentValidationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2FyZ3VtZW50cy9Db3B5TnVtYmVyQXJndW1lbnRWYWxpZGF0aW9uVXRpbHMuamF2YQ==) | `66.66% <0%> (-11.12%)` | `19% <0%> (-1%)` | |; | [...tools/funcotator/DataSourceFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0RhdGFTb3VyY2VGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `75.92% <0%> (-11.04%)` | `17% <0%> (ø)` | |; | [...ools/walkers/haplotypecaller/graphs/SeqVertex.java](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvU2VxVmVydGV4LmphdmE=) | `92.85% <0%> (-7.15%)` | `10% <0%> (-1%)` | |; | [...te/hellbender/tools/funcotator/OutputRenderer.java](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL091dHB1dFJlbmRlcmVyLmphdmE=) | `92.85% <0%> (-7.15%)` | `4% <0%> (ø)` | |; | ... and [170 more](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5475?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5475?src=pr&el=footer). Last update [1f6a172...623830b](https://codecov.io/gh/broadinstitute/gatk/pull/5475?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5475#issuecomment-443759397:4479,learn,learn,4479,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5475#issuecomment-443759397,1,['learn'],['learn']
Usability,how about the gatk3 diff engine? should be easy to port and seems usable here.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/190#issuecomment-96246722:66,usab,usable,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/190#issuecomment-96246722,1,['usab'],['usable']
Usability,i'm going to delete this until we have a clearer picture of locus walkers in hellbender,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/33#issuecomment-94484114:41,clear,clearer,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/33#issuecomment-94484114,1,['clear'],['clearer']
Usability,"i'm removing my assignment then. the requirements are not clear to me. 'until we're all satisfied' is pretty vague, too vague for alpha i think",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/190#issuecomment-127382644:58,clear,clear,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/190#issuecomment-127382644,1,['clear'],['clear']
Usability,"ical chromosomes, the canonical mappings are saved but the better non-canonical mappings are saved as SA tag as in SAM spec, and the VCF record produced is annotated accordingly; this is implemented in 65cdb523a2f9fa2026334713fed45381d76ffc82; * fixed a bug where sometimes an assembly contig as several alignments, only one of which has non-mediocre MQ but at the sametime this alignment contains a large gap, such contigs were previously incorrectly filtered away, they are now salvaged by commit b6b2f197b112981e00efd9d415f010c024d31b36. So, for the FN variants (FN in the sense that they are captured in the stable version of our interpretation tool but now goes missing in the experimental interpretation tool); that were curated in the above-mentioned review, only the following ones are not salvaged, with plans or comments attached. ```; asm012854:tig00000	missing	classified as ""incomplete""; fixable by finishing the last TODO in AssemblyContigAlignmentSignatureClassifier (same problem as face by group represented by asm002398:tig00001); asm014580:tig00018	missing	classified as ""incomplete""; fixable by finishing the last TODO in AssemblyContigAlignmentSignatureClassifier (same problem as face by group represented by asm002398:tig00001); asm008185:tig00000	missing	classified as ""ambiguous""; unsure of how to deal with a general rule--exact same part of read coverred by one mapping to canonical, one to non-canonical (better AS); if save the canonical, a deletion would be called; asm018220:tig00004	missing	classified as ""ambiguous""; salvagable if re-analysed through old interpretation tool; asm026229:tig00000	missing	classified as ""ambiguous""; fixable if implement a special rule making all split alignments on non-canonical chromosomes as ""bad""; ```. They are relatively simple fixes so I clumped them into a single PR.; If you prefer to review them as separate PR's. I can do that too.; Thanks!; [report.sam.gz](https://github.com/broadinstitute/gatk/files/1786690/report.sam.gz)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522:2788,simpl,simple,2788,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522,1,['simpl'],['simple']
Usability,"ied as ""incomplete"",; hence will NOT sent here for constructing SimpleChimera's.; But we may want to keep the code (and related code in BreakpointComplications) for future use. Comment by @cwhelan ; > I'm a bit confused by this comment: this method is still being called in several places, so how is it obsolete?. Reply by @SHUANG-Broad (also copied to update the ""TODO"" message; > this predicate is currently used in two places (excluding appearance in comments): `BreakpointComplications.IntraChrStrandSwitchBreakpointComplications`, where it is use to test if the input simple chimera indicates an inverse tandem duplication and trigger the logic for inferring duplicated region; and `BreakpointsInference.IntraChrStrandSwitchBreakpointInference`, where it is used for breakpoint inference. The problem is, the contig will not even be sent here, because `AssemblyContigWithFineTunedAlignments.hasIncompletePictureFromTwoAlignments()` defines a simple chimera that has strand switch and the two alignments overlaps on reference as ""incomplete"", so in practice the two uses are not going to be triggered. But when we come back later and see what can be extracted from such ""incomplete"" contigs, these code could be useful again. So it is kept. ------------; ### On the problem of writing out SAM records of ""Unknown"" contigs efficiently. First round comment by @cwhelan ; > This seems like a very inefficient way to write these three files. You end up calling collect on the RDD three different times and then traversing the local collection three times. Why not make a map of contig name to bam file, collect the rdd once, and then traverse the local collection once, writing each read to the appropriate bam file from the map?. Second round comment by @cwhelan ; > This is a better but you are still collecting the RDD and passing over the collection three times. What I meant by my original suggestion was this: Why not make the map go the other way, ie make a Map<String, ReasonForAlignmentClassi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030:3324,simpl,simple,3324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030,1,['simpl'],['simple']
Usability,"if we could pull this off). [...]. Alright, next step then is to figure out whether it's even feasible to make the ActiveRegion traversal fully respect dcov. I think Mark, in implementing the current scheme, might have been thinking that maintaining the undownsampled reads in memory is actually less expensive in typical (non-extreme) cases than reconstructing the full set of post-downsampling reads in an active region from multiple AlignmentContexts emitted by LIBS without any duplicates. I'll have to do some performance testing to see whether or not this is the case. Will try to get to this within the next few weeks, but the QC project has immediate priority. [...]. Discussed this with Ryan -- we agreed that the right thing to do is to move the enforcement of the hard cap on the total number of reads that can be in an active region from the HC walker to the engine, and have the size of the cap be controlled by a new argument (not dcov). That way you never pay the cost of storing the undownsampled reads for an active region in memory. We'd also have to educate users on exactly what the various downsampling arguments do for active region walkers. [...]. Making the hardcoded per-active-region cap settable from the command line is the easy part -- what seems hard is:; - Determining whether we can avoid storing all undownsampled reads in memory at once without affecting the quality of calls. Currently, as outlined in earlier comments on this ticket, we do a downsampling pass per locus which respects dcov (in LocusIteratorByState) but keep all undownsampled reads in memory anyway (defeating the main purpose of that first pass), then do a second downsampling pass per active region that does not respect dcov (uses the hardcoded per-region limit).; - If we find that we can't avoid storing all of the undownsampled reads in memory at once for some reason, then perhaps the right thing to do would be to completely disable the downsampling pass in LocusIteratorByState for active ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345:5374,undo,undownsampled,5374,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345,1,['undo'],['undownsampled']
Usability,"iff coverage is `66.667%`. ```diff; @@ Coverage Diff @@; ## master #2515 +/- ##; ===============================================; - Coverage 76.273% 76.268% -0.004% ; - Complexity 10876 10878 +2 ; ===============================================; Files 752 752 ; Lines 39583 39584 +1 ; Branches 6922 6922 ; ===============================================; - Hits 30191 30190 -1 ; - Misses 6772 6774 +2 ; Partials 2620 2620; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...tute/hellbender/tools/spark/sv/ReadClassifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkQ2xhc3NpZmllci5qYXZh) | `82.813% <66.667%> (-1.314%)` | `30 <0> (-1)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `66.667% <0%> (-3.333%)` | `10% <0%> (ø)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=footer). Last update [d40ccc2...d5c85bb](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2515#issuecomment-288529799:1927,learn,learn,1927,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2515#issuecomment-288529799,1,['learn'],['learn']
Usability,"iff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZHNEYXRhU291cmNlLmphdmE=) | `90.476% <0%> (+1.587%)` | `61% <0%> (+2%)` | :arrow_up: |; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `66.667% <0%> (+3.252%)` | `4% <0%> (ø)` | :arrow_down: |; | [...g/broadinstitute/hellbender/engine/AuthHolder.java](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvQXV0aEhvbGRlci5qYXZh) | `15.254% <0%> (+5.085%)` | `2% <0%> (ø)` | :arrow_down: |; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `77.703% <0%> (+6.757%)` | `22% <0%> (+4%)` | :arrow_up: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `86.4% <0%> (+8.8%)` | `35% <0%> (+7%)` | :arrow_up: |; | ... and [7 more](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=footer). Last update [5ccfd00...b1d407f](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2540#issuecomment-290122549:3831,learn,learn,3831,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2540#issuecomment-290122549,1,['learn'],['learn']
Usability,"ils/genotyper/SampleList.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nZW5vdHlwZXIvU2FtcGxlTGlzdC5qYXZh) | `75.676% <0%> (ø)` | `8% <0%> (?)` | |; | [...hellbender/tools/walkers/annotator/SampleList.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TYW1wbGVMaXN0LmphdmE=) | `81.25% <0%> (+1.658%)` | `9% <0%> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |; | [.../broadinstitute/hellbender/tools/exome/Sample.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9TYW1wbGUuamF2YQ==) | `100% <0%> (+12.308%)` | `5% <0%> (-21%)` | :arrow_down: |; | [...stitute/hellbender/engine/ReferenceFileSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVmZXJlbmNlRmlsZVNvdXJjZS5qYXZh) | `72.727% <0%> (+15.584%)` | `4% <0%> (-4%)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=footer). Last update [62d58c5...fde9d36](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2556#issuecomment-290787479:3376,learn,learn,3376,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2556#issuecomment-290787479,1,['learn'],['learn']
Usability,"implementation is different from the one in `ReadWindowWalker`: first, the overlap between windows is only in one direction; second, `SlidingWindowWalker` is more like a reference/interval walker, from the beginning of the reference (or interval) till the end, it walks in overlapping windows. One example is the following (window-size 10, window-step 5, the - represent the window):. ```; Reference: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; Windows1: _ _ _ _ _ _ _ _ _ _; Windows2: _ _ _ _ _ _ _ _ _ _; Windows3: _ _ _ _ _ _ _ _ _ _; Windows4: _ _ _ _ _ _ _ _ _ _; Windows5: _ _ _ _ _ _ _ _ _ _; ```. Of course, after having a look to `ReadWindowWalker` I think that several things could be improved in my implementation for a general `SlidingWindowWalker`:; - Apply function similar to the `ReadWindowWalker`, with `ReadWindow` being empty if reads are not provided.; - Three window options: `windowSize` (the actual size of the window), `windowStep` (how much advance for the following window) and `windowPadding` (how much extend the window in both directions). Using this abstraction, `ReadWindowWalker` could be implemented setting `windowSize=windowStep`, and the problem that I need to solve could be implemented setting `windowPadding=0`. The simplest way to acomplish this is to use the current implementation of `ReadWindowWalker` to develop a `SlidingWindowWalker` adding three abstract methods for the three parameters (`getWindowSize()`, `getWindowStep()` and `getWindowPadding()`, and implement `ReadWindowWalker` as a extension of this interface setting `getWindowStep()` to return `getWindowSize()` and `requiresReads()` to true. I can do this once the PR #1567 is accepted and generate the two interfaces (to be sure that the integration with the HC engine is working as expected with the changes), or just implement the `SlidingWindowWalker` and you can include it in the HC PR, or update afterwards to avoid redundancy in the code. What do you think, @droazen?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1528#issuecomment-198438775:1854,simpl,simplest,1854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1528#issuecomment-198438775,1,['simpl'],['simplest']
Usability,"in the count files, and perhaps fail if one is provided for any of the tools (I don’t recall exactly how VCF indexing is triggered by providing one, as seems to be indicated by the tutorial, but hopefully we can disallow external dictionaries while still taking advantage of the relevant engine features for VCF writing). EDIT: Went digging in Slack to try to remind myself of the context of these changes, and found the following PR comment from 1/7 (although it seems to have mysteriously disappeared from GitHub):. > Just so I understand, are we allowing overriding of the sequence dictionary in the shards (and skipping the consistency check) by allowing the parameter --sequence-dictionary to be specified? If so, we might want to document. Otherwise, I'd be inclined to enforce using the sequence dictionary in the shards (and ensuring the consistency check across shards is performed) by changing the null check in getBestAvailableSequenceDictionary to a check that the dictionary has not been set via the command line. EDIT^2: I think I misremembered the details of how #6330 hooked up the sequence dictionary and how getBestAvailableSequenceDictionary in GATKTool works (which probably explains why that comment was deleted...). Now that I actually go back and look, the `--sequence-dictionary` is not hooked up at all, so there is no change to revert in point 4!. Note that after all of this, it will *still* be possible to get into trouble at the gCNV step if you make funky shards (e.g., you could have shard 1 contain intervals from chr1 and chr3, and shard 2 contain intervals from chr2). I don't think it is possible to check for this case early, but you would still fail at PostprocessGermlineCNVCalls as above. Of course, all of these possibilities can be avoided by simply using the WDL, but it will be good to harden checks for those still working at the command line. @ldgauthier @droazen @mwalker174 what do you think? Happy to review later, but OK if I pass this off to you all?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6924#issuecomment-719576249:3971,simpl,simply,3971,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924#issuecomment-719576249,1,['simpl'],['simply']
Usability,"interesting - ok, that's done. and yes, the spurious commits are basically errors learning git rebase. hopefully this covers everything. the change in hasUserSuppliedIntervals() touched a lot of files, but it's a pretty trivial change in them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-405703909:82,learn,learning,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-405703909,1,['learn'],['learning']
Usability,"is 546. The difference is likely due to realignment of reads to the haplotypes by the walker. So, we basically have two options:; 1. Change the documentation for the DP annotation to mention that for ActiveRegion walkers it reflects the undownsampled depth subject to things like realignment to the haplotypes (easiest option, but doesn't fix the underlying craziness); 2. Change the ActiveRegion traversal so that it respects the dcov value (could be hard -- the LIBS downsampling process discards reads on-the-fly from previous loci when moving to a new locus, but an active region involves data for multiple loci. The potential performance win for the HC is huge, though, if we could pull this off). [...]. Alright, next step then is to figure out whether it's even feasible to make the ActiveRegion traversal fully respect dcov. I think Mark, in implementing the current scheme, might have been thinking that maintaining the undownsampled reads in memory is actually less expensive in typical (non-extreme) cases than reconstructing the full set of post-downsampling reads in an active region from multiple AlignmentContexts emitted by LIBS without any duplicates. I'll have to do some performance testing to see whether or not this is the case. Will try to get to this within the next few weeks, but the QC project has immediate priority. [...]. Discussed this with Ryan -- we agreed that the right thing to do is to move the enforcement of the hard cap on the total number of reads that can be in an active region from the HC walker to the engine, and have the size of the cap be controlled by a new argument (not dcov). That way you never pay the cost of storing the undownsampled reads for an active region in memory. We'd also have to educate users on exactly what the various downsampling arguments do for active region walkers. [...]. Making the hardcoded per-active-region cap settable from the command line is the easy part -- what seems hard is:; - Determining whether we can avoid stor",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345:4629,undo,undownsampled,4629,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345,1,['undo'],['undownsampled']
Usability,"itute.org>; Date: Fri Dec 8 00:37:24 2017 -0500. sudo travis yml. commit 89025941febd2089d426cfa1e0f0aa6a6712e2a9; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 00:23:22 2017 -0500. travis/Docker config update (g++-6, Miniconda3); python test group assignment. commit 31f96398106c2b8577b8c25d110abea3ebe7f836; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:44:53 2017 -0500. WDL test bugfix. commit 9b2fb820536ec355bea0256471bd093d547f5c99; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:20:36 2017 -0500. update WDL test JSON files. commit e3d97644d1a2c40a5c364a96f8b67246154179c9; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:18:14 2017 -0500. assertions in inference task base; removed a ASCII > 128 character in log messages. commit 526cf92e623a3bbd5f9d375132b6ca046fc47620; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:03:04 2017 -0500. redirect tqdm progress bar to python logger. commit 2e45bd30968b921fae225de3901fb97ece690b0c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 19:45:49 2017 -0500. more arg related fixes. commit bb89a3bb338d88199881e8aca65f656f2acd7c0a; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 19:41:20 2017 -0500. arg related bugfixes in WDL, python, and java CLIs. commit 23569787ee2c8cc6c9227a44170cbbd02fe4427f; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 17:21:05 2017 -0500. fixed issue with python boolean argparse (they use weird semantics). commit ae841c9ed4cd9b2ca1ac0e9082d175ff8ea98298; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 16:44:02 2017 -0500. shorter gCNV WDL tests. commit 5466b806e36df16cad2d045be074e7f9afec0957; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 16:38:15 2017 -0500. fixed arg issues in somatic WDL; exposed all missing args to java side; major update to germline WDLs; ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:4978,progress bar,progress bar,4978,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,1,['progress bar'],['progress bar']
Usability,"itute/gatk/pull/2594?src=pr&el=h1) Report; > Merging [#2594](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/2ecdef4fba1658930c388676be3e388efd67b6a3?src=pr&el=desc) will **increase** coverage by `0.002%`.; > The diff coverage is `0%`. ```diff; @@ Coverage Diff @@; ## master #2594 +/- ##; ===============================================; + Coverage 75.985% 75.987% +0.003% ; - Complexity 11033 11034 +1 ; ===============================================; Files 769 769 ; Lines 40058 40058 ; Branches 6979 6979 ; ===============================================; + Hits 30438 30439 +1 ; Misses 6981 6981 ; + Partials 2639 2638 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...tute/hellbender/tools/BwaMemIndexImageCreator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Cd2FNZW1JbmRleEltYWdlQ3JlYXRvci5qYXZh) | `71.429% <0%> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `95.313% <0%> (+1.563%)` | `22% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=footer). Last update [2ecdef4...a853f7c](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2594#issuecomment-293665515:1630,learn,learn,1630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2594#issuecomment-293665515,1,['learn'],['learn']
Usability,"ive you some basic stats about your vcf file very quickly. This will; alleviate many of your concerns. On Tue, Jul 31, 2018, 11:10 AM sanjeevksh <notifications@github.com> wrote:. > My GenotypeGVCFs run for a single chromosome returned the following; > completion statement:; > 18:54:40.516 INFO ProgressMeter - Traversal complete. Processed 606308; > total variants in 75.2 minutes.; >; > However, there are only 46814 variant rows (excluding 52 header rows) in; > the corresponding vcf file. Does the above figure of 606308 correspond to a; > multiple of 'variants x number of samples'?; >; > Also, there are only 16863 lines in my log file, does this mean that the; > 'Current Locus' column in the log file doesn't correspond to a single; > genomic location (bp) in the fasta file?; >; > I am curious to know what is the relation between all these figures to; > fully understand what is happening while processing the gCVF files.; >; > Also, on the inbreeding coefficient warning issue, I understand from your; > @Neato-Nick <https://github.com/Neato-Nick> feedback that the variants; > with these warnings may still be fine and can be retained. However, this; > still leaves me worrying that out of 384 samples the locus doesn't even; > have 10 samples for generating the required metrics. Such variants won't be; > of any use for downstream analyses anyway where any variants with more than; > 80% missing samples will be removed. Therefore, I wish to seek some more; > information about this 10 sample thing - does it have some other context or; > does it literally mean that there are only less than 10 samples carrying; > that variant?; >; > Regards,; > Sanjeev; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409255344>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AFlB0vsaHipT7i0GC5BcMgDZsS2DHbpaks5uMHNmgaJpZM4SyZJV>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409271340:1294,feedback,feedback,1294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409271340,1,['feedback'],['feedback']
Usability,"jbwa was just a proof-of-concept and a pretext to learn JNI. The algorithm was built on the ""simple"" API for BWA, but the internal 'mem' algorithm is much more complicated and the last time (2013) I looked at it, it was not easy to use it as a library (e.g. too many things in the `main`). I remember people at http://cloudgene.uibk.ac.at/ used it. . > FYI, I try to use jbwa in a MapReduce approach. If you interested, I can; > keep u posted.; > We implemented a framework for the execution of MapReduce jobs; > graphically and therefore new use cases are always nice",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1517#issuecomment-188414763:50,learn,learn,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1517#issuecomment-188414763,2,"['learn', 'simpl']","['learn', 'simple']"
Usability,"jopt-simple docs are here http://pholser.github.io/jopt-simple/. This should close #81, #111 and #67",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/135#issuecomment-70915198:5,simpl,simple,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/135#issuecomment-70915198,2,['simpl'],['simple']
Usability,"k/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9CcmVha3BvaW50RXZpZGVuY2UuamF2YQ==) | `86.025% <0%> (+4.561%)` | `30% <0%> (+6%)` | :arrow_up: |; | [...ute/hellbender/tools/spark/bwa/BwaSparkEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmtFbmdpbmUuamF2YQ==) | `94.805% <0%> (+4.805%)` | `8% <0%> (+3%)` | :arrow_up: |; | [...titute/hellbender/tools/spark/sv/ReadMetadata.java](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkTWV0YWRhdGEuamF2YQ==) | `89.297% <0%> (+7.018%)` | `33% <0%> (+11%)` | :arrow_up: |; | [...ute/hellbender/utils/bwa/BwaMemAlignmentUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9id2EvQndhTWVtQWxpZ25tZW50VXRpbHMuamF2YQ==) | `85.507% <0%> (+13.093%)` | `17% <0%> (+1%)` | :arrow_up: |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `55.233% <0%> (+14.764%)` | `38% <0%> (+10%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=footer). Last update [d054e7a...8ecb688](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2581#issuecomment-292631877:3770,learn,learn,3770,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2581#issuecomment-292631877,1,['learn'],['learn']
Usability,"kRunner SPARK --sparkMaster yarn-client --sparkSubmitCommand spark2-submit\; --driver-memory 16G \; --num-executors 5 \; --executor-cores 7 \; --executor-memory 25G; ```. What does FindBreakpointEvidenceSpark do, from the perspective of Spark?. * [runTool] filter out secondary and supplementary alignments; * [getMappedQNamesSet] filter out duplicate reads, reads that failed vendor checks, unmapped reads; * Job 0 [ReadMetadata] mapPartitions to find partition stats; * Job 1 [getIntervals] filter and multiple map partitions to find breakpoint intervals ; * Job 2 [removeHighCoverageIntervals] mapPartitionsToPair to find coverage for each interval, then reduceByKey; * Job 3 [getQNames] mapPartitions; * Job 4 [addAssemblyQNames -> getKmerIntervals] mapPartitionsToPair, then reduceByKey, then mapPartitions; * Job 5 [getAssemblyQNames] mapPartitions twice and a collect; * Job 6 [generateFastqs] mapPartitions and combineByKey, then write FASTQ to files. A few observations:; * Jobs 0,1,3 are simple map jobs - very quick 1-2 mins each.; * Job 2 is a simple MR, with a tiny shuffle to sum by key (<1MB of shuffle data); * Job 4 takes a bit longer longer (3min), and shuffles ~3GB. This is a lot faster than when I ran it before with less memory, when it took 9 min. Is it creating a lot of garbage? If you wanted to speed things up you might look at what this is doing on a local machine and see if there are any opportunities to improve CPU efficiency.; * Job 5 takes ~8 mins, and has no shuffle. CPU intensive processing again?; * Job 6 take a little over 3 mins, shuffling ~3GB. Overall, it looks like it’s performing pretty well. There is very little data being shuffled relative to the size of the input (~6GB to 133GB input), so it’s not worth looking into optimizing the data structures there. The input data is being read multiple times, so it _might_ be worth seeing if it can be cached by Spark to avoid reading from disk over and over again. This is only worth it if you have sufficie",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2458#issuecomment-292171884:1684,simpl,simple,1684,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2458#issuecomment-292171884,1,['simpl'],['simple']
Usability,"l=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9TZWxlY3RWYXJpYW50cy5qYXZh) | `80% <100%> (ø)` | `119 <0> (ø)` | :arrow_down: |; | [...nder/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...cc1b2b9e9989a18f36d2014445eadce21bef3373?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nRW5naW5lLmphdmE=) | `46.491% <20%> (-0.411%)` | `32 <0> (ø)` | |; | [...ls/walkers/genotyper/afcalc/ExactAFCalculator.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...cc1b2b9e9989a18f36d2014445eadce21bef3373?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvRXhhY3RBRkNhbGN1bGF0b3IuamF2YQ==) | `81.818% <50%> (-8.182%)` | `6 <3> (+3)` | |; | [...stitute/hellbender/utils/genotyper/AlleleList.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...cc1b2b9e9989a18f36d2014445eadce21bef3373?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nZW5vdHlwZXIvQWxsZWxlTGlzdC5qYXZh) | `89.744% <0%> (+1.282%)` | `16% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2528?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2528?src=pr&el=footer). Last update [c62914a...cc1b2b9](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...cc1b2b9e9989a18f36d2014445eadce21bef3373?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2528#issuecomment-288859643:3833,learn,learn,3833,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2528#issuecomment-288859643,1,['learn'],['learn']
Usability,"l_logp(mu_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x')),; tt.log(pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_mosaic_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x'))],; axis=0)[0]; return _logp_sjk. DensityDist(name='n_sj_obs',; logp=lambda _n_sj: tt.sum(q_ploidy_sjk * _get_logp_sjk(_n_sj), axis=2),; observed=n_sj); ````. Briefly, the model includes 1) per-contig bias (normalized to unit mean for identifiability), 2) per-sample depth, 3) per-sample probability of mosaicism, 4) per-sample-and-contig mosaicism factor `f` (in [0, 1], normalized by the per-sample max for identifiability), 5) per-contig mapping error. The likelihood is then a negative-binomial mixture of non-mosaic and mosaic contigs, where the latter have their mean count depressed by the corresponding factor `f`. This model still requires some tuning of priors (which are currently hard coded above), but seems to correctly capture most of the mosaicism in the test samples. Also, I found that it was better to run the aneuploid samples as a cohort or to run them in combination with the 20 panel samples as a cohort, rather than to run them in case mode against the panel. We don't necessarily have to emit anything on the mosaicism inferences for the first revision of this model (or we may end up stripping those parts of the model out for now), but I thought it would be good to record this version of the model for posterity. However, note that this model differs from the one currently in master in the treatment of depth. I think the treatment here is quite natural and may be more robust than the current treatment. @mbabadi is going to take over tuning and tweaking the model from this point in the sl_simple_ploidy branch. Note that I haven't cleaned up some of the code and comments yet, but hopefully the changes are relatively clear. I believe I rebased on one of your other branches, so you should remove the corresponding commit and rebase.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890:3488,clear,clear,3488,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890,1,['clear'],['clear']
Usability,"lbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `88% <86.667%> (-12%)` | `7 <2> (+7)` | |; | [...ute/hellbender/tools/spark/bwa/BwaSparkEngine.java](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmtFbmdpbmUuamF2YQ==) | `89.286% <88%> (+18.697%)` | `5 <5> (+5)` | :white_check_mark: |; | [...itute/hellbender/tools/spark/sv/ContigAligner.java](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9Db250aWdBbGlnbmVyLmphdmE=) | `88.462% <88.889%> (+6.643%)` | `8 <4> (+8)` | :white_check_mark: |; | [...g/broadinstitute/hellbender/utils/NativeUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9OYXRpdmVVdGlscy5qYXZh) | `25% <ø> (-43.75%)` | `3% <ø> (+3%)` | |; | ... and [96 more](https://codecov.io/gh/broadinstitute/gatk/pull/2367/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2367?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2367?src=pr&el=footer). Last update [9d82097...975121e](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2367#issuecomment-276460872:4931,learn,learn,4931,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2367#issuecomment-276460872,1,['learn'],['learn']
Usability,"lbmRlci91dGlscy9waWxldXAvUGlsZXVwRWxlbWVudC5qYXZh) | `96.04% <0%> (+1.865%)` | `76 <0> (ø)` | :arrow_down: |; | [...bender/tools/exome/HashedListTargetCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9IYXNoZWRMaXN0VGFyZ2V0Q29sbGVjdGlvbi5qYXZh) | `90.741% <0%> (+1.65%)` | `43 <0> (ø)` | :arrow_down: |; | [.../utils/read/markduplicates/DuplicationMetrics.java](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL0R1cGxpY2F0aW9uTWV0cmljcy5qYXZh) | `85.366% <0%> (+2.033%)` | `13 <0> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/read/CigarUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL0NpZ2FyVXRpbHMuamF2YQ==) | `89.404% <0%> (+0.588%)` | `68 <0> (ø)` | :arrow_down: |; | [...der/utils/locusiterator/AlignmentStateMachine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9sb2N1c2l0ZXJhdG9yL0FsaWdubWVudFN0YXRlTWFjaGluZS5qYXZh) | `87.879% <0%> (+1.312%)` | `27 <1> (ø)` | :arrow_down: |; | ... and [22 more](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=footer). Last update [62d58c5...cd59cde](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2543#issuecomment-290171890:4194,learn,learn,4194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2543#issuecomment-290171890,1,['learn'],['learn']
Usability,"lly a throw-away intermediate file. As far as computational time, this is not that bad (at least for very small intervals/job). I also did not bother running consolidate on these, and imported with a batchSize of 50.; - With the limited interval GenomicsDB workspaces, GenotypeGVCFs runs reasonably well. . So some open questions:. - It's unclear why running GenotypeGVCFs with a GenomicsDB workspace that has intact chromosomes, even when using -L over a small interval, fails to run or runs painfully slowly with extremely high memory. I will try to find time for actual profiling, but this is a little cumbersome since I'm not sure I can run this on my windows dev machine. As noted above, given how awkward maintaining genomicsdb workspaces is, I'm currently thinking that we should view these as transient stores and not bother saving them after one use.; - The scatter method (i.e. many workspaces where each has a very small region) seems like a huge improvement for creating the workspaces. As far as designing intervals: I understand the guidance around quasi-manually defining a genome-specific interval set that puts the borders within SNP-poor and NNNN regions. This said, I wonder if we could simply create the workspace where we take the intervals and pad them by like 1kb or so? This would make the workspaces marginally bigger and duplicate those data, but in the grand scheme of things probably doesnt make much computational difference? One thing I need to verify (and would be great if you know this upfront), is whether using GenomicsDbImport with -L would include any gVCF variant that spans the intervals or whether it just includes gVCF variants that start in those intervals. If this is the former, when it seems like simply padding when creating the workspace and then running GenotypeGVCFs with the argument for ""only-output-genotypes-starting-in-intervals"" would be a genome-agnostic method that accomplishes the same thing?. Anyway, thanks for your continued help on this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1220618297:2202,guid,guidance,2202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1220618297,3,"['guid', 'simpl']","['guidance', 'simply']"
Usability,"louises proposals seems simple and reasonable.... perhaps it should offer to provide a ```Function<R, String>``` to provide a alternative ```toString``` in case the tools natural record ```toString``` does not align well with progress reporting... or perhaps in that case the tool could use an alternative record object that is send to the progress meter instead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-577273465:24,simpl,simple,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-577273465,1,['simpl'],['simple']
Usability,"m.google.cloud.genomics.gatk.common. I've been working on this bam file issue, correcting errors in the files used for tests. Many of the errors involve reads with FLAGs that indicate that they are in pairs, but the mate is not extant in the file, causing the error. A way to fix this without deleting the offending reads is to set the FLAG to zero and also modify the RNEXT, PNEXT, and TLEN fields, if necessary, so that the read becomes single (provided that the values of all of these fields are not important for the tests). However, when I do this, I find that tests that write and then read bam files fail, because when the just-written file is read back, SAM validation complains that the mate unmapped FLAG is set for an unpaired read. It turns out that the copy of the file written by the test substitutes the value '8' for '0' as the FLAG for the modified reads. The relevant code in GenomicsConvertermakeSamRecord() (line 170) is:. flags += ((read.getNextMatePosition() == null || read.getNextMatePosition.getPosition() == null)) ? 8 : 0;. The effect of this line is that all reads which have null mate positions, even those which the FLAG specifies as unpaired, get the mate unmapped FLAG set, causing the validation errors that i'm seeing. The reason the tests have not failed before is apparently that the existing test files do not contain any reads with FLAGs that specify them as unpaired. A simple fix for this would be to convert the line above to:. flags += ( paired && (read.getNextMatePosition() == null || read.getNextMatePosition.getPosition() == null)) ? 8 : 0;. The redundant parens in the original code suggest that something like this may have been intended,but the google genomics documentation at http://google-genomics.readthedocs.org/en/latest/migrating_tips.html gives the following pseudocode:. flags += read.nextMatePosition.position == null ? 8 : 0 #mate_unmapped. so it looks like the doc supports the existing code. Should I submit this as an issue? . Thank you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/569#issuecomment-114101033:1566,simpl,simple,1566,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/569#issuecomment-114101033,1,['simpl'],['simple']
Usability,"mE=) | `96.87% <85.71%> (-1.46%)` | `15 <1> (+1)` | |; | [...lotypecaller/AssemblyBasedCallerUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHNVbml0VGVzdC5qYXZh) | `95.77% <95.28%> (-4.23%)` | `45 <43> (+43)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...te/hellbender/utils/genotyper/ReadLikelihoods.java](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nZW5vdHlwZXIvUmVhZExpa2VsaWhvb2RzLmphdmE=) | `90.14% <0%> (+0.4%)` | `143% <0%> (ø)` | :arrow_down: |; | ... and [1 more](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5215?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5215?src=pr&el=footer). Last update [8103bde...7d53fb9](https://codecov.io/gh/broadinstitute/gatk/pull/5215?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5215#issuecomment-425465744:4580,learn,learn,4580,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5215#issuecomment-425465744,1,['learn'],['learn']
Usability,"nVja2V0VXRpbHMuamF2YQ==) | `43.75% <0%> (-29.861%)` | `27% <0%> (-9%)` | |; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `76.471% <0%> (-23.529%)` | `4% <0%> (ø)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-18.75%)` | `6% <0%> (ø)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | ... and [24 more](https://codecov.io/gh/broadinstitute/gatk/pull/2401?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2401?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2401?src=pr&el=footer). Last update [51360c7...51285dc](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2401#issuecomment-279424649:4915,learn,learn,4915,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2401#issuecomment-279424649,1,['learn'],['learn']
Usability,"nd other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely necessary, as this may cause conflicts with other core dependencies; # verify that this is using numpy compiled against MKL (e.g., by checking tensorflow.pywrap_tensorflow.IsMklEnabled()); - conda-forge::scipy=1.0.0 # do not update, this will break a scipy.misc.logsumexp import (deprecated in scipy=1.0.0) in pymc3=3.1; - conda-forge::pymc3=3.1 # do not update, this will break gcnvkernel; - conda-forge::keras=2.2.4 # updated from pip-installed 2.2.0, which caused various conflicts/clobbers of conda-installed packages; # conda-installed 2.2.4 appears to be the most recent version with a consistent API and without conflicts/clobbers; # if you wish to update, note that versions of conda-forge::keras after 2.2.5; # undesirably set the environment variable KERAS_BACKEND = theano by default; - defaults::intel-openmp=2019.4; - conda-forge::scikit-learn=0.22.2; - conda-forge::matplotlib=3.2.1; - conda-forge::pandas=1.0.3. # core R dependencies; these should only be used for plotting and do not take precedence over core python dependencies!; - r-base=3.6.2; - r-data.table=1.12.8; - r-dplyr=0.8.5; - r-getopt=1.20.3; - r-ggplot2=3.3.0; - r-gplots=3.0.3; - r-gsalib=2.1; - r-optparse=1.6.4. # other python dependencies; these should be removed after functionality is moved into Java code; - biopython=1.76; - pyvcf=0.6.8; - bioconda::pysam=0.15.3 # using older conda-installed versions may result in libcrypto / openssl bugs. # pip installs should be avoided, as pip may not respect the dependencies found by the conda solver; - pip:; - gatkPythonPackageArchive.zip; ```. It seems to successfully create the environment. I'd still recommend updating the information on your README.md and the file.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:3112,learn,learn,3112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,1,['learn'],['learn']
Usability,"negligible and dates back to pre-4.0 release. Another concern is that the number of users of this unsupported code is also growing. In fact, it seems like we are actively pointing users to it. This seems unsustainable going forward. Finally, I don't think we have satisfactorily demonstrated which of the functions accomplished by this code (format conversion, post-hoc blacklisting, germline/""CNLOH"" tagging and imputation) are necessary or cannot be performed by existing code or more streamlined and principled methods. (Some of these functions, such as IGV conversion, are already performed by existing code.) Of those functions, I think format conversion is the only one we should retain from this code in an unsupported fashion. So if this PR introduces a useful GISTIC conversion, no harm in merging that. This all sounds like a decision for the new tech lead! @mwalker174 any thoughts? . More detailed responses follow:. > Users are already using this branch and giving me positive feedback (definitely more positive than adjusting num_changepoints_penalty_factor). I suggest merging mostly for practical reasons. It buys us more time to put in a principled solution. And this workflow is clearly marked as an unsupported prototype anyway (as are the GATK CLIs). I want to emphasize that this whole workflow is not a long-term solution. In other words, I would like to get this in and then focus on a supported solution. While it's great that users are giving positive feedback, I refer you to CellBender team's manifesto at https://github.com/broadinstitute/CellBender/commit/28f02f8dbd716aff922bb8da1e56da29347b245b. Can these users help us definitively resolve whether these events are 1) germline with incorrectly normalized CR, or 2) mosaic CNLOH? If not, then we have not even taken the first step to correctly identify the issue. So it seems a bit premature to even prototype a method, much less merge it. I think this PR, as is, muddies the waters quite a bit. For example, it introduc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199:1331,feedback,feedback,1331,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199,1,['feedback'],['feedback']
Usability,"nel.java:314); at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802); at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319); at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637); at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566); at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480); at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442); at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131); at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144); at java.lang.Thread.run(Thread.java:748); 18/04/24 17:42:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/04/24 17:42:11 INFO MemoryStore: MemoryStore cleared; 18/04/24 17:42:11 INFO BlockManager: BlockManager stopped; 18/04/24 17:42:11 INFO BlockManagerMaster: BlockManagerMaster stopped; 18/04/24 17:42:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/04/24 17:42:11 INFO SparkContext: Successfully stopped SparkContext; 17:42:11.053 INFO PathSeqPipelineSpark - Shutting down engine; [April 24, 2018 5:42:11 PM CEST] org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark done. Elapsed time: 2.87 minutes.; Runtime.totalMemory()=866648064; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 4 times, most recent failure: Lost task 0.3 in stage 2.0 (TID 8, xx.xx.xx.xx, executor 3): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilte",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:38456,clear,cleared,38456,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['clear'],['cleared']
Usability,"nnot reject the null, we assume the null hypothesis of hom (f = error rate or 1 - error rate) and accept a site when we can reject the null. This entire process is very similar to what @davidbenjamin does in https://github.com/broadinstitute/gatk/pull/3638. We should consider combining this code (along with `AllelicCount`/`PileupSummary`) at some point.; - [x] Added option to use matched normal.; - [ ] Rather than port over the old modeling code, I would rather expand the allele-fraction model to allow for the modeling of hom sites. I wrote up such a model in some notes I sent around a few months back. This model allows for an allelic PoN that uses all sites to learn reference bias, not just hets. Depending on how our python development proceeds, I may try to implement this model using the old `GibbsSampler` code instead.; - [x] In the meantime, we can try to speed up the old allele-fraction model, which is now the main bottleneck. An easy (lazy) strategy might simply be to downsample and scale likelihoods when estimating global parameters. Addresses #2884.; - [x] Even though the simple copy-ratio model is much faster, it still takes ~15-20 minutes for 100 iterations on WGS, so we can downsample here too.; - [x] Integration tests are still needed; again, these might not test for correctness.; - I've added the ability to specify a prior for the minor-allele fraction, which alleviates the problem of residual bias in balanced segments.; - I've reduced the verbosity of the modeled-segments file. I only report posterior mode and 10%, 50%, and 90% deciles. Global parameters have the full deciles output in the .param files, but I removed the mode and highest density credible interval (because of the below item).; - [x] Some residual bias remains in the estimate of the minor-allele fraction posterior mode. This is simply because we are performing kernel density estimation of a bounded quantity. One possibility would be to logit transform to an unbounded support, perform the ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:5732,simpl,simply,5732,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,1,['simpl'],['simply']
Usability,not much code here so simple comments only. Absence of another `ReadShard` is weird and more comments would be useful. LGTM,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2016#issuecomment-233708552:22,simpl,simple,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2016#issuecomment-233708552,1,['simpl'],['simple']
Usability,"ode for adding and removing haplotypes based on pileup alleles has become a `void` method of this class, where it belongs. Here and elsewhere I introduce snappy variable and function named referring to ""good"" and ""bad"" alleles, which I find visually much clearer. The code is basically the same as before but somewhat streamified. I extracted a `makeHaplotypeWithInsertedEvent` method to eliminate some code duplication between GGA and pileup force-calling.; - `HaplotypeCallerEngine` and `Mutect2Engine`: Force-calling alleles are split into biallelic `Events`. Duplicated code for finding all pileup events, then sifting them into good event to force-call and bad events to remove is extracted as `PileupBasedAlleles.goodAndBadPileupEvents`. Computing `allVariationEvents` is much simpler because 1) it now uses `Event` instead of `VariantContext` and 2) `Event` overrides `equals` and `hashCode`.; - `PileupBasedAlleles`: `getPileupVariantContexts` and sorting into good and bad pileup variants has been unified into `goodAndBadPileupEvents()`. It has additionally been somewhat rewritten for conciseness. Also, instead of the somewhat kludgy method of making `VariantContext` with four temporary attributes, then filtering based on those attributes, it calculates the filtering status immediately and uses `Events`. Also fixed the somewhat-misleading use of the word `alt` to mean `SNP`.; - `AssemblyBasedCallerUtils`: `applyPileupEventsAsForcedAlleles`, along with several helper methods that it calls, has been moved into `AssemblyResultResult`, where it is now a void member method.; - `GATKVariantContextUtils` mainly just using `Event` instead of `VariantContext`, which simplifies the code for splitting a `VariantContext` into biallelics. After going through this exercise I realize that it's not actually so much. The diff's bark is worse than its bite. The overwhelming majority of changes are either replacing `VariantContext` with `Event` or moving methods to more appropriate classes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574175702:1771,simpl,simplifies,1771,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574175702,1,['simpl'],['simplifies']
Usability,"ode:. -`BaseRecalibratorSpark` is the standalone BQSR tool, and calls into the `BaseRecalibratorSparkFn` (which is also called from `ReadsPipelineSpark`). -`ApplyBQSRSpark` is the standalone ApplyBQSR tool, and calls into the `ApplyBQSRSparkFn` (also called from `ReadsPipelineSpark`). -Integration tests for the above are in `BaseRecalibratorSparkIntegrationTest` and `ApplyBQSRSparkIntegrationTest`. -Almost all other changes in the branch are related to the BQSR engine refactoring, which I summarize below:; - We pulled out the guts of the walker `BaseRecalibrator` tool, combined it with all of the code from the former `RecalibrationEngine` class (now deleted) to make a new `BaseRecalibrationEngine` class under `utils/recalibration`.; - We stripped out all copies of the code in `BaseRecalibrationEngine` from the walker, dataflow, and spark versions of BQSR, and modified them to call into `BaseRecalibrationEngine`.; - We moved all auxiliary classes needed by the `BaseRecalibrationEngine` (eg., the covariates, etc.) into `utils/recalibration`.; - We refactored the argument collections. Now there is a single shared `RecalibrationArgumentCollection` that contains **only** the parameters for the `BaseRecalibrationEngine` itself, and this argument collection is exposed by all 3 versions of the tool. Input/output arguments have been removed from this argument collection and put into the individual implementations of BQSR, since they vary between the walker, dataflow, and spark versions of the tool. This eliminates awkward problems such as having both a `knownSites` argument AND a `BQSRKnownVariants` exposed at the same time, with only 1 of them usable for a given version of a tool. The dataflow-only `BaseRecalibrationArgumentCollection` has been deleted completely as no longer needed.; - We tweaked the names of some tool arguments to enforce consistency between the 3 versions of the tool as well as the rest of hellbender (eg., output arg for BQSR is now a more standard `-O`)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/911#issuecomment-142340073:1715,usab,usable,1715,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/911#issuecomment-142340073,1,['usab'],['usable']
Usability,"off-target/bin hets as well with some care.; - Old code and models are used for modeling. Since the old allele-fraction model only models hets, we perform a `GetHetCoverage`-like binomial genotyping step (and output the results) before modeling. However, instead of assuming the null hypothesis of het (f = 0.5) and accepting a site when we cannot reject the null, we assume the null hypothesis of hom (f = error rate or 1 - error rate) and accept a site when we can reject the null. This entire process is very similar to what @davidbenjamin does in https://github.com/broadinstitute/gatk/pull/3638. We should consider combining this code (along with `AllelicCount`/`PileupSummary`) at some point.; - [x] Added option to use matched normal.; - [ ] Rather than port over the old modeling code, I would rather expand the allele-fraction model to allow for the modeling of hom sites. I wrote up such a model in some notes I sent around a few months back. This model allows for an allelic PoN that uses all sites to learn reference bias, not just hets. Depending on how our python development proceeds, I may try to implement this model using the old `GibbsSampler` code instead.; - [x] In the meantime, we can try to speed up the old allele-fraction model, which is now the main bottleneck. An easy (lazy) strategy might simply be to downsample and scale likelihoods when estimating global parameters. Addresses #2884.; - [x] Even though the simple copy-ratio model is much faster, it still takes ~15-20 minutes for 100 iterations on WGS, so we can downsample here too.; - [x] Integration tests are still needed; again, these might not test for correctness.; - I've added the ability to specify a prior for the minor-allele fraction, which alleviates the problem of residual bias in balanced segments.; - I've reduced the verbosity of the modeled-segments file. I only report posterior mode and 10%, 50%, and 90% deciles. Global parameters have the full deciles output in the .param files, but I removed",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:5426,learn,learn,5426,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,1,['learn'],['learn']
Usability,"oks for the start of a BAM record within the BGZF block boundary. The latter is the part that uses heuristics to find the record start and for which we’ve fixed some bugs (https://github.com/HadoopGenomics/Hadoop-BAM/pull/25, https://github.com/HadoopGenomics/Hadoop-BAM/pull/29). The guessing algorithm is discussed in some detail in http://bioinformatics.oxfordjournals.org/content/suppl/2013/05/10/bts054.DC1/supplement.pdf. Hadoop-BAM has the concept of a “splitting” index file (with extension .splitting-bai). It contains the virtual file offsets for every nth read in a BAM (where n is 4096 by default). The input format code then uses the index to get the next read (or at least the next one in the index) that starts after the HDFS block boundary for the split. As far as I can tell, the code for creating splitting index files isn’t easy to run on files in HDFS (SplittingBAMIndexer runs on local filesystem files), so it may be that splitting index files are not widely used. . The standard BAM index (.bai) is not used by Hadoop-BAM for generating splits. ADAM has IndexedBamInputFormat (see https://github.com/bigdatagenomics/adam/pull/732 and https://github.com/bigdatagenomics/adam/issues/787), which seems to be focused on reading a subset of a file, since it doesn’t respect HDFS locality (mappers would not run on the machine hosting the input data). It's not clear to me how we could use .bai files to get an even distribution of splits, and to get decent locality. Note that Matti Niemenmaa's thesis on Hadoop-BAM states. > Note that BAM and BCF can be, and commonly are, indexed. As the; > index contains the precise positions of many records in the file, one might; > think that it could be used for aligning splits accurately. Unfortunately; > their indexing schemes are not suitable for the task, due to at least all of; > the following reasons... And the reasons are listed on p46 of https://aaltodoc.aalto.fi/bitstream/handle/123456789/11886/master_niemenmaa_matti_2013.pdf.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1091#issuecomment-156428631:1499,clear,clear,1499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1091#issuecomment-156428631,1,['clear'],['clear']
Usability,"olders named ""SAMPLE_#""), and just check the sample_name.txt files at the PostprocessGermlineCNVCalls step. I don't think this should require GermlineCNVCaller code changes, right?. 4) We may require additional code at the WDL level if we want to both switch over to primarily using sample names but also get rid of bundling (i.e., by passing only the calls for each sample when needed). Locally, you can always just search all output for directories containing the appropriate sample_name.txt. But on the cloud, you'd want to make sure that the postprocessing step for a particular sample gets only its corresponding directories, which would have to happen at the WDL level; the check against sample_name.txt at the tool level would just be a formality. I can foresee headaches with globbing and funky sample names. I'm not sure I understand your point about extending PostprocessGermlineCNVCalls to run on all samples. The point of that tool is to take results from all genomic shards for a single sample and stitch them together, right? Even if we extend this to run on a batch of multiple samples (which would just be moving the loop over samples at the WDL level to some lower level, i.e., Java or python), we still need to see all shards for those samples. Perhaps I'm misunderstanding---can you clarify?. @mwalker174 can we once and for all clearly document the issue with the transpose? Perhaps by pointing to specific WGS runs that have issues with call caching? I think being able to pinpoint the exact issue will help us identify the right solution---whether that be choosing an appropriate bundling scheme, taking advantage of #5781 to reduce the number of shards, batching during the postprocessing step, removing unnecessary outputs, etc. Recall that we'd like to be able to use the same WDL locally (when you have easy access to all GermlineCNVCaller results from all genomic shards) and in the cloud, with minimal duplication of output from bundling when running locally, if possible.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6659#issuecomment-644829765:2668,clear,clearly,2668,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6659#issuecomment-644829765,1,['clear'],['clearly']
Usability,"on profiling, it's clear that the engine adds almost no overhead on top of htsjdk iterators - see screenshot from jprofiler; ![image](https://cloud.githubusercontent.com/assets/1993519/10667806/52a4f7e6-78a7-11e5-9ad2-b11d97d4647f.png)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1036#issuecomment-150240722:19,clear,clear,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1036#issuecomment-150240722,1,['clear'],['clear']
Usability,"onTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db21wYXJlSW50ZXJ2YWxMaXN0c0ludGVncmF0aW9uVGVzdC5qYXZh) | `100% <100%> (ø)` | `4 <4> (?)` | |; | [...stitute/hellbender/tools/CompareIntervalLists.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db21wYXJlSW50ZXJ2YWxMaXN0cy5qYXZh) | `93.33% <93.33%> (ø)` | `4 <4> (?)` | |; | [...broadinstitute/hellbender/utils/IntervalUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlcnZhbFV0aWxzLmphdmE=) | `91.88% <0%> (+0.35%)` | `188% <0%> (+1%)` | :arrow_up: |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.77% <0%> (+0.47%)` | `33% <0%> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `79.87% <0%> (+1.21%)` | `42% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3702?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3702?src=pr&el=footer). Last update [a74e571...8f85021](https://codecov.io/gh/broadinstitute/gatk/pull/3702?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3702#issuecomment-337303370:2761,learn,learn,2761,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3702#issuecomment-337303370,1,['learn'],['learn']
Usability,"once we get to 0 for AyeAye, we should just change this to a style-guide item and not accept pull reqs with warnings in them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/118#issuecomment-70675377:67,guid,guide,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/118#issuecomment-70675377,1,['guid'],['guide']
Usability,"ook like LIBS is actually down-sampling. Don't have time to debug more so passing on to David. ---. @droazen said (over multiple comments):. I am looking into this. LIBS is actually calling into the downsamplers correctly in the test case that Eric provided. You can see this by examining readStates.size() for each locus -- it never exceeds the -dcov target of 200. The problem must lie elsewhere -- I'll continue to step through this in the debugger. [...]. After some more debugging and consultation with Ryan, I've found that DP values exceeding dcov are to be expected given the way the ActiveRegion traversal currently works. Here's a summary of what's going on:. -dcov 200 does cause LIBS to cap the depth at each locus to 200, but due to code Mark added a while back LIBS will save all of the undownsampled reads in memory during active region traversals (which kind of defeats the purpose of downsampling in the first place!). -TraverseActiveRegions gets the undownsampled reads from LIBS, and adds them to the active regions that get passed to the walker. -The HaplotypeCaller does a post-hoc downsampling pass on the reads in the active region in finalizeActiveRegion() to a hardcoded (!!!) and completely arbitrary depth of 1000, ignoring dcov. -The HaplotypeCaller does realignment of reads to the haplotypes, potentially causes the depth of coverage to vary at the locus in question. -The GenotypingEngine then computes DP based on the reads that still overlap the locus post-realignment. The end result is that DP for the HaplotypeCaller represents the undownsampled depth of coverage at the locus in question, subject to the hardcoded cap of 1000 and realignment to the haplotypes. In this particular case, the actual depth at locus 1:14464 is 561 (with no downsampling), and the DP value is 546. The difference is likely due to realignment of reads to the haplotypes by the walker. So, we basically have two options:; 1. Change the documentation for the DP annotation to mention that",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345:2863,undo,undownsampled,2863,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345,1,['undo'],['undownsampled']
Usability,"oposed algorithm description:. Answer: thanks for looking! That's what I intended as I'm not sure if the algorithm itself would face strong critics. If that's the case, time spent on coding is not worth it IMO. In fact ideally I'd like to write a design doc or something similar, and only code after the design is agreed on. --------. > I would of course prefer not to have to have a hard filter on length. This would mean we would never call a large inversion even if it exists. . Answer: Totally agree. Now looking back, it get clearer to me that this proposal contains two parts: the filtering part, and the breakpoint linking part, separated into two major classes `InversionBreakendPreFilter` and `LinkedInversionBreakpointsInference`. That being said, it doesn't make much sense to separate them into two PRs because _currently_ the filtering part is designed around the linking part, i.e. it is trying to check which BND's are suitable to the logic implemented in the linking part, and if the logic isn't applicable to an BND, the BND simply slips through without generating any new interpretations. So `InversionBreakendPreFilter` is a filter and a classifier at the same time, it function is really diverting different BND's to be handled by different logics, and it definitely should be improved.; If you buy this argument, I am also fully aware of the code design issue that it is preferable to NOT divert&mdash;gather&mdash;send through different handlers like it currently is for calling variants from the assembly contigs, instead it should be a single stream pass through all the BND's. I'll try to follow the preferred design. > What about some other filters more specifically aimed at the artifacts that cause these false large calls? I think it's a good idea to check annotations -- ie. do the mates lie at two regions that are segmental duplications of each other, or one side of the mate looks like a transposable element insertion? I guess it's ok to put in a tool with this limit",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4789#issuecomment-406483929:1215,simpl,simply,1215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4789#issuecomment-406483929,1,['simpl'],['simply']
Usability,options used in tests: ; --compress; -n ; --simplifyBAM; -L 1; -L unmapped; --readGroup; --sample_name,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/154#issuecomment-71864180:44,simpl,simplifyBAM,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/154#issuecomment-71864180,1,['simpl'],['simplifyBAM']
Usability,"ot sure if that was already covered. @sooheelee - this is going to be an exact port of the indel-realignment pipeline, as it is in the GATK3 code, so that means that I won't modify the interval list format or anything (although I will use the HTSJDK/Picard classes as used on GATK3). Because this will be an experimental/beta feature, I think that I can have a look to the new format after acceptance of the original port. @cmnbroad - I understand that a fully functional tool is a requirement for acceptance, but what I mean is that some specific features might require more work than others. I am only concerned about the `NWaySAMFileWriter`, which is just an specific way of output the data but does not add anything to the real realignment process (actually, I think that I've never heard about anyone around me using it). That is a nice feature, but I don't think that it is a high-priority - I care more about having the algorithm implemented to test if the actual processing of the data works, and add support for some way of output the data in a different PR. In addition, if the people still using indel-realignment does not require the n-way output, then it is pointless to spend time on it. I was also thinking about the mate-fixing algorithm in the tool, because it can be performed afterwards with Picard, which is not constraining by any distance between reads or records in RAM - nevertheless, this is really a drop of functionality that will change results, and that's why I didn't propose that. About the target-creator, known indels are really easy to port because the code is within the tool and is simpler - the only problem might be code coverage if there is no data for known indels. I will propose very soon two PRs with fully functional tools (without the n-way out feature for indel-realignment), and trying to add simple integration tests with the data already available on the repository and running with GATK3.8-1. If that is OK for you, I will proceed with this approach.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115:1952,simpl,simpler,1952,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115,2,['simpl'],"['simple', 'simpler']"
Usability,"otate(refSequenceDictionary);; > + }; > +; > + private static List<AlignmentInterval> deOverlapAlignments(final List<AlignmentInterval> originalAlignments,; > + final SAMSequenceDictionary refSequenceDictionary) {; > + final List<AlignmentInterval> result = new ArrayList<>(originalAlignments.size());; > + final Iterator<AlignmentInterval> iterator = originalAlignments.iterator();; > + AlignmentInterval one = iterator.next();; > + while (iterator.hasNext()) {; > + final AlignmentInterval two = iterator.next();; > + // TODO: 11/5/17 an edge case is possible where the best configuration contains two alignments,; > + // one of which contains a large gap, and since the gap split happens after the configuration scoring,; > I agree it is backwards. But...; > ; > The reason was that the (naive) alignment configuration scoring module rightnow uses MQ and AS (aligner score) for picking the ""best"" configuration (i.e. sub-list of the alignments given by aligner), which would be technically wrong if we were to split the gap and to simply grab the originating alignment's values.; > ; > This is especially true for AS, whose recomputing takes more time, and code, and forces us to know how AS are computed in the aligner so that there's no bias in computing the scores of naive alignments vs gap-split alignments (may not matter in practice, but still takes more code to compute).; > ; > Lots of the code in the discovery stage was devoted actually to alignment related acrobatics and edge cases so that the breakpoints we could resolve are as accurate as possible.; > I've kept in mind your wisdom that different aligners may be experimented with, but it seems unlikely in the near future (their own quirkiness, lack of API for JNI, etc); it seems more and more likely to me that eventually it's inevitable to have a custom alignment module in a high-quality SV pipeline, but again, the near future has other top priorities.; > ; > What do you think?; > ; > —; > You are receiving this because you",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3805#issuecomment-350618009:1966,simpl,simply,1966,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3805#issuecomment-350618009,1,['simpl'],['simply']
Usability,"ouldn't update the docs for `ReadWindowWalker` to clear up the confusion without mentioning `AssemblyRegion`-specific concepts.; - The `ReadShard` / `ReadWindow` was/is **only** there to prove that we can shard the data without introducing calling artifacts, and to provide a unit of parallelism for the upcoming Spark implementation. It's not something we really want to expose to users as a prominent knob, and we may hide it completely in the future once the shard size is tuned for performance.; - Inheriting from a more abstract walker type caused a number of other problems as well: methods that should have been final in the supertype could no longer be made final, with the result that tool implementations could inappropriately override engine initialization/shutdown routines. Also, there were issues with the progress meter, since both the supertype traversal and subtype traversal needed their own progress meter for their different units of processing. Ultimately it was just too awkward and forced, and the read shard is something that we eventually want to make an internal/encapsulated implementation detail anyway. GATK3 made the mistake, I think, of using long, confusing inheritance chains for its walker types, with the result that you got awkward and forced relationships like `RodWalker` inheriting from `LocusWalker`. It's better, I think, to make each traversal as standalone as possible, especially given the simplicity of writing a new walker type in GATK4. For all of these reasons we don't want `AssemblyRegionWalker` to inherit from a more abstract traversal type -- it's just going to be its own standalone thing, so that it can evolve freely without affecting anyone else. For `SlidingWindowWalker`, which we still want to merge, I recommend making the traversal do **exactly** what you want for your use case, as clearly and simply as possible, without worrying about serving as a base class for other traversals. Ping me once you're happy with it, and I'll re-review.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210806513:2317,simpl,simplicity,2317,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210806513,3,"['clear', 'simpl']","['clearly', 'simplicity', 'simply']"
Usability,"ound first, since these give rise to longer segments:. ![wave-kern-no-local](https://user-images.githubusercontent.com/11076296/29322673-4dd9a1ac-81ac-11e7-94f5-5c5494e44ac5.png). CBS similarly finds many false positive breakpoints:. ![wave-cbs](https://user-images.githubusercontent.com/11076296/29322677-5576e4ba-81ac-11e7-888b-07ed5bff27e3.png). However, when we tune down the sine waves to 1:10, ApproxKernSeg still gets tripped up, but CBS looks better:. ![wave-kern-no-local-small-waves](https://user-images.githubusercontent.com/11076296/29322732-815df58c-81ac-11e7-8305-6e1798616336.png); ![wave-cbs-small-waves](https://user-images.githubusercontent.com/11076296/29322737-836b78fe-81ac-11e7-93be-753a40011203.png). To improve ApproxKernSeg, we can 1) make the cost function intensive, by simply dividing by the number of points in a segment, and 2) add to the cost function a local term, given by the cost of making each point a changepoint within a local window of a determined size. This local term was inspired by methods such as SaRa (http://c2s2.yale.edu/software/sara/). The reasoning is that with events at higher S/N ratio, we typically don't need to perform a global test to see whether any given point is a suitable changepoint; using the data locally surrounding the point typically suffices. With these modifications, ApproxKernSeg can handle both scenarios:; ![wave-kern](https://user-images.githubusercontent.com/11076296/29322762-a679dba6-81ac-11e7-9360-083a4e1da398.png); ![wave-kern-small-waves](https://user-images.githubusercontent.com/11076296/29322801-dad82010-81ac-11e7-8238-e057b0072e1b.png). This local window approach is still linear in time, so runtime is still ~1s for the above (about ~10x faster than CBS). One issue still remains, which is that even this improved approach tends to find directly adjacent possible changepoints around a true changepoint before moving on to another true changepoint. We can probably clean this up with some simple postprocessing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-322502045:2774,simpl,simple,2774,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-322502045,1,['simpl'],['simple']
Usability,"pMapReduceWriter.scala:88, took 9.524571 s; 17/10/13 18:11:53 INFO io.SparkHadoopMapReduceWriter: Job job_20171013181144_0009 committed.; 17/10/13 18:11:53 INFO server.AbstractConnector: Stopped Spark@131ba51c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/10/13 18:11:53 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/13 18:11:54 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 17/10/13 18:11:54 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/13 18:11:54 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/13 18:11:54 INFO memory.MemoryStore: MemoryStore cleared; 17/10/13 18:11:54 INFO storage.BlockManager: BlockManager stopped; 17/10/13 18:11:54 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/13 18:11:54 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/13 18:11:54 INFO spark.SparkContext: Successfully stopped SparkContext; 18:11:54.552 INFO PrintReadsSpark - Shutting down engine; [October 13, 2017 6:11:54 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.35 minutes.; Runtime.totalMemory()=806354944; ***********************************************************************. A USER ERROR has occurred: Couldn't write file /gatk4/output_3.bam because writing failed with exception /gatk4/output_3.bam.parts/_SUCCESS: Unable to find _SUCCESS file. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$CouldNotCreateOutputFile: Couldn't write file /gatk",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:22570,clear,cleared,22570,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,1,['clear'],['cleared']
Usability,"perfect. Maybe it's as simple as switching all HashSets to LinkedHashSet; (and same for maps). On Tue, Apr 21, 2015 at 10:02 AM, Matt Sooknah notifications@github.com; wrote:. > Ah yes, I remember this now - they haven't been failing in Picard per se,; > it's just when we tried compiling under Java 8. The info in that issue; > should make the fix much easier, if it's indeed the same thing.; > ; > —; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/hellbender/issues/364#issuecomment-94805095; > .",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/364#issuecomment-94807857:23,simpl,simple,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/364#issuecomment-94807857,1,['simpl'],['simple']
Usability,"ppear to be ""LL score""---perhaps someone else knows or has better Google-fu and can figure it out) before moving on to their methods for estimating F1. Doing a literature search for other discussions of optimizing F1 or other metrics in the context of positive-unlabeled learning might be worthwhile, but I think most methods will probably involve some sort of estimation of the base rate in unlabeled data. I think we may have to add some mechanism for holding out a validation set during training if we want to automatically tune thresholds in a rigorous fashion. Shouldn't be too bad---we can just have the training tool randomly mask out a set of the truth and pass the mask to the scoring tool (or maybe just determine the threshold in the training tool, if we are running in positive/negative mode and have access to unlabeled data)---but does add a couple of parameters to the tool interfaces. This also adds additional dependence on the quality of the truth resources. I think an implicit assumption in any use of the truth---even just thresholding/calibrating by sensitivity---is that it is a random sample; however, I'm not sure how true this is in actual use. For example, in malaria, it looks like we may have to resort to using a callset that has been very conservatively filtered as truth, which will bias us towards high scores and the peaks of the positive distribution. Perhaps we can also experiment with just treating training/truth on an equal footing (I think the distinction between the two is somewhat blurry in the original VQSR design, anyway). Perhaps @davidbenjamin has some thoughts? I see some related stuff going on in ThresholdCalculator, but I have to admit that I can't tell whether that's used in a similar PU context. Also note that depending on the model used, we might not have well calibrated posteriors---the IsolationForest simply outputs scores in a unit interval, and we simply report the difference between the positive and the negative scores, for example.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241:2653,simpl,simply,2653,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1062931241,2,['simpl'],['simply']
Usability,"pr&el=h1) Report; > Merging [#2548](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/c8ede6ef810a3d9a05c7deb8052e27ca724ce8ba?src=pr&el=desc) will **increase** coverage by `0.003%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2548 +/- ##; ===============================================; + Coverage 76.279% 76.282% +0.003% ; - Complexity 10891 10893 +2 ; ===============================================; Files 752 752 ; Lines 39590 39590 ; Branches 6925 6925 ; ===============================================; + Hits 30199 30200 +1 ; Misses 6768 6768 ; + Partials 2623 2622 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...tools/walkers/genotyper/AlleleSubsettingUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9BbGxlbGVTdWJzZXR0aW5nVXRpbHMuamF2YQ==) | `85.185% <ø> (ø)` | `39 <0> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=footer). Last update [c8ede6e...b79b75d](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2548#issuecomment-290305475:1655,learn,learn,1655,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2548#issuecomment-290305475,1,['learn'],['learn']
Usability,"r definitively whether simply blacklisting common germline regions is enough to replicate/obviate most of the postprocessing. Should be straightforward to run an evaluation with and without blacklisting---and hopefully our truth data accurately reflects whether blacklisting is desirable. There are definitely events that get missed without the germline tagging, so this is an improvement over blacklisting alone. And while I have seen erroneous germline tagging (i.e. false calling a segment germline), it was only ever due to really noisy data (e.g. a bad PoN) or a poorly tuned segment caller. I am pretty sure that most common germline regions are being blacklisted already. The hotspots addressed in this PR (faux-CNLoH) could be added, but I think we will find new areas and a few of these areas were rather big. I have users that are actively using this from the branch, for reasons other than the faux-CNLoH pruning. Results are improving without an appreciable hit to sensitivity, which we got when using parameters like num_changepoints_penalty_factor. As a compromise, I can always default the CNLoH piece to `false`, since there are other useful changes on this branch. (Users did not have as strong an opinion about the faux-CNLoH pruning, since GISTIC does not use MAF and ABSOLUTE requires a manual review). > simple filtering based on CR-AF as described above could be implemented. If the normal is available, we can make IS_NORMAL calls simply based on the overlap of the ModelSegments posteriors (with corresponding qualities). If not, then some heuristic determination of the normal state from the tumor alone as in Marton's caller could be performed. This would combine the IS_NORMAL calling and filtering steps into one simple tool. The output could be a tagged/filtered ModelSegments .seg file and the corresponding VCF. And this would be a possible ""better solution"" Shall I file an issue for this? This could also allow us to obviate the TagGermline tool, which is fine by me.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461258874:2262,simpl,simple,2262,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461258874,3,['simpl'],"['simple', 'simply']"
Usability,"r&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL21hZk91dHB1dC9NYWZPdXRwdXRSZW5kZXJlckNvbnN0YW50cy5qYXZh) | `99.01% <100%> (+0.04%)` | `1 <0> (ø)` | :arrow_down: |; | [...der/tools/funcotator/metadata/TumorNormalPair.java](https://codecov.io/gh/broadinstitute/gatk/pull/4917/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL21ldGFkYXRhL1R1bW9yTm9ybWFsUGFpci5qYXZh) | `63.63% <63.63%> (ø)` | `5 <5> (?)` | |; | [...cotator/mafOutput/CustomMafFuncotationCreator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4917/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL21hZk91dHB1dC9DdXN0b21NYWZGdW5jb3RhdGlvbkNyZWF0b3IuamF2YQ==) | `90% <90%> (ø)` | `17 <17> (?)` | |; | [...tools/funcotator/metadata/SamplePairExtractor.java](https://codecov.io/gh/broadinstitute/gatk/pull/4917/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL21ldGFkYXRhL1NhbXBsZVBhaXJFeHRyYWN0b3IuamF2YQ==) | `95% <95%> (ø)` | `9 <9> (?)` | |; | [...titute/hellbender/tools/funcotator/Funcotator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4917/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3IuamF2YQ==) | `86.18% <0%> (+0.65%)` | `43% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4917?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4917?src=pr&el=footer). Last update [9d8fdac...0e8a045](https://codecov.io/gh/broadinstitute/gatk/pull/4917?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4917#issuecomment-399122987:3490,learn,learn,3490,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4917#issuecomment-399122987,1,['learn'],['learn']
Usability,"r&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvTG9jdXNXYWxrZXJTcGFyay5qYXZh) | `82.5% <83.33%> (+4.72%)` | `12 <2> (ø)` | :arrow_down: |; | [...itute/hellbender/engine/spark/ReadWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5221/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvUmVhZFdhbGtlclNwYXJrLmphdmE=) | `72.22% <85.71%> (-5.2%)` | `8 <3> (-2)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5221/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5221/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `72.51% <0%> (+0.94%)` | `38% <0%> (+1%)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5221/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `80% <0%> (+30%)` | `3% <0%> (+2%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5221?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5221?src=pr&el=footer). Last update [2ee7df3...e40ce5e](https://codecov.io/gh/broadinstitute/gatk/pull/5221?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5221#issuecomment-426308250:4360,learn,learn,4360,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5221#issuecomment-426308250,1,['learn'],['learn']
Usability,"rage Diff @@; ## master #5539 +/- ##; ============================================; - Coverage 87.06% 87.06% -0.01% ; + Complexity 31324 31322 -2 ; ============================================; Files 1921 1921 ; Lines 144579 144579 ; Branches 15949 15949 ; ============================================; - Hits 125884 125880 -4 ; - Misses 12902 12906 +4 ; Partials 5793 5793; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5539/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5539/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `79.87% <0%> (-0.61%)` | `42% <0%> (ø)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5539/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=footer). Last update [10aa8c7...3aec594](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5539#issuecomment-449065825:2178,learn,learn,2178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5539#issuecomment-449065825,1,['learn'],['learn']
Usability,"rage by `0.008%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2468 +/- ##; ===============================================; + Coverage 76.268% 76.275% +0.008% ; - Complexity 10876 10879 +3 ; ===============================================; Files 752 752 ; Lines 39583 39583 ; Branches 6922 6922 ; ===============================================; + Hits 30189 30192 +3 ; + Misses 6774 6772 -2 ; + Partials 2620 2619 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2468?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...4bebcdf005e9191206558f09e14f59d87324f1c8?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...4bebcdf005e9191206558f09e14f59d87324f1c8?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2468?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2468?src=pr&el=footer). Last update [c62914a...4bebcdf](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...4bebcdf005e9191206558f09e14f59d87324f1c8?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2468#issuecomment-288779580:1809,learn,learn,1809,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2468#issuecomment-288779580,1,['learn'],['learn']
Usability,"rage is `100%`. ```diff; @@ Coverage Diff @@; ## master #2427 +/- ##; ===============================================; + Coverage 76.218% 76.221% +0.003% ; - Complexity 10819 10821 +2 ; ===============================================; Files 750 750 ; Lines 39420 39421 +1 ; Branches 6883 6883 ; ===============================================; + Hits 30045 30047 +2 ; Misses 6757 6757 ; + Partials 2618 2617 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2427?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...tute/hellbender/tools/spark/sv/ReadClassifier.java](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...fc95362d5a29cc5738032c43aa922b491b6accf5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkQ2xhc3NpZmllci5qYXZh) | `83.607% <100%> (+0.273%)` | `31 <4> (+1)` | :white_check_mark: |; | [.../hellbender/tools/spark/sv/BreakpointEvidence.java](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...fc95362d5a29cc5738032c43aa922b491b6accf5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9CcmVha3BvaW50RXZpZGVuY2UuamF2YQ==) | `83.756% <0%> (+0.508%)` | `24% <0%> (+1%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2427?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2427?src=pr&el=footer). Last update [fcd103c...fc95362](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...fc95362d5a29cc5738032c43aa922b491b6accf5?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2427#issuecomment-282851101:1843,learn,learn,1843,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2427#issuecomment-282851101,1,['learn'],['learn']
Usability,"re falling back on Java implementations (e.g., AVX PairHMM tests). We need to determine the dependencies for these tests and install them separately. Here is the list of packages that get pulled in by the R install: ```autoconf automake autotools-dev binutils bsdmainutils build-essential; bzip2-doc cdbs cpp cpp-5 debhelper dh-strip-nondeterminism dh-translations; dpkg-dev fakeroot g++ g++-5 gcc gcc-5 gettext gettext-base gfortran; gfortran-5 groff-base ifupdown intltool intltool-debian iproute2; isc-dhcp-client isc-dhcp-common libalgorithm-diff-perl; libalgorithm-diff-xs-perl libalgorithm-merge-perl libarchive-zip-perl; libasan2 libasprintf-dev libasprintf0v5 libatm1 libatomic1; libauthen-sasl-perl libblas-common libblas-dev libblas3 libbz2-dev; libc-dev-bin libc6-dev libcc1-0 libcilkrts5 libcroco3 libcurl3; libdns-export162 libdpkg-perl libencode-locale-perl libfakeroot; libfile-basedir-perl libfile-desktopentry-perl libfile-fcntllock-perl; libfile-listing-perl libfile-mimeinfo-perl libfile-stripnondeterminism-perl; libfont-afm-perl libfontenc1 libgcc-5-dev libgdbm3 libgettextpo-dev; libgettextpo0 libgfortran-5-dev libgfortran3 libgomp1 libhtml-form-perl; libhtml-format-perl libhtml-parser-perl libhtml-tagset-perl; libhtml-tree-perl libhttp-cookies-perl libhttp-daemon-perl libhttp-date-perl; libhttp-message-perl libhttp-negotiate-perl libio-html-perl; libio-socket-ssl-perl libipc-system-simple-perl libisc-export160 libisl15; libitm1 libjpeg-dev libjpeg-turbo8-dev libjpeg8-dev liblapack-dev liblapack3; liblsan0 liblwp-mediatypes-perl liblwp-protocol-https-perl liblzma-dev; libmail-sendmail-perl libmailtools-perl libmnl0 libmpc3 libmpfr4 libmpx0; libncurses5-dev libnet-dbus-perl libnet-http-perl libnet-smtp-ssl-perl; libnet-ssleay-perl libpaper-utils libpaper1 libpcre16-3 libpcre3-dev; libpcre32-3 libpcrecpp0v5 libperl5.22 libpipeline1 libpng12-dev libquadmath0; libreadline-dev libreadline6-dev libsigsegv2 libstdc++-5-dev; libsys-hostname-long-perl libtcl8.6 libtext-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406373954:2397,simpl,simple-perl,2397,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406373954,1,['simpl'],['simple-perl']
Usability,"re first, then split. Splitting the gapped alignments was introduced originally to have a centralized logic in inferring type and location of the events. . The tension is that AS is used in the scoring but becomes practically useless after that. >> Correct, but I am having thoughts about this now (not to pick only one—that; would be wrong—but to ditch them altogether probably under some condition; and redo the alignment step), exactly because of this behavior I observe.; Think about the case where one originating gapped (say insertion); alignment, after splitting, has one of the two children contained in; another alignment (not its sibling, that's impossible) in terms of their; read span. Now the originating gapped alignment probably should be filtered; out, or not, because if we keep it, an insertion would be called but; apparently there are alternative explanations due to the other alignment.; I'm not sure how to deal with this case, and if this scenario is common; enough. It probably is the case that such alignments happen mostly in STR; regions, so getting the exact alignments correct there is no easy task.; ; > Is that enough of a concern to worry about. In such a case I feel like we; should probably just pick the longer, gapped alignment, since it explains; more of the contig. But you have a better sense of how that fits in with; the rest of your scheme. The comments I put in the code/todo was not clear (my bad). ; What the code is currently doing is what's suggested, that is: ; skipping the alignment that is BEFORE the child alignment from the gap-split, IFF that alignment contains the child alignment in terms of their spans on the read/contig; (I've updated the doc in the code as well). If you are concerned about the first child alignment from the same gapped alignment being skipped, don't worry, that is impossible because child alignments of the same gapped alignment cannot overlap on the read. --------. Do these cover your major concerns @cwhelan?; Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3805#issuecomment-354976980:2219,clear,clear,2219,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3805#issuecomment-354976980,1,['clear'],['clear']
Usability,"real patients' lives. Almost all of these institutions are likely to use clinical WES assays due to cost reasons and will thus have been directly affected by this issue _for the last three years_. Also, almost all of these institutions will never learn of this bug since they likely trusted in the developers to have proper functional regression tests in place. If this is indeed the best the Broad can do as an institution, then I will take your offer of providing a build of Mutect2 4.1.8.1 with the log4j vulnerability patched out - thank you. The one thing that I am asking for in addition (for the sake of the overall oncology bioinformatics community), however, is that you conduct a best effort to notify organizations (universities, hospitals, and biotechs/pharmaceuticals that you know are using Mutect2) and best-practise workflow owners (Nextflow, Snakemake, WDL, CWL etc. that include Mutect2) of the forced downgrade. Also, I think it makes sense to include a very prominent warning into the Mutect2 READMEs and GATK best practice documentations and guides. I know that this is work, too, but with success comes responsibility, and I can just hope that providing proper warnings uses less developer bandwidth than applying binary search to find out which of these [10 commits between 4.1.8.1 and 4.1.9.0 that are touching variant filtering (see below)](https://github.com/broadinstitute/gatk/compare/4.1.8.1...4.1.9.0) broke your flagship product enough to abandon it. (For anyone looking at this issue later, these are the commits I think are most likely to be related to this issue, and which I would propose to systematically leave out of the 4.1.9.0 build to test whether variant calling specificity is restored; assuming the 10 commits are independent and leaving each out in turn produces a working build, this would mean producing 10 Mutect2 builds for functional regression testing (the latter of which @ddrichel could do if we would receive the 10 builds from the GATK team)):. ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1535909226:1629,guid,guides,1629,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1535909226,1,['guid'],['guides']
Usability,"rn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `75%`. ```diff; @@ Coverage Diff @@; ## master #2431 +/- ##; ==========================================; Coverage ? 42.757% ; Complexity ? 5801 ; ==========================================; Files ? 750 ; Lines ? 39425 ; Branches ? 6885 ; ==========================================; Hits ? 16857 ; Misses ? 20600 ; Partials ? 1968; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2431?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...s/recalibration/covariates/ReadGroupCovariate.java](https://codecov.io/gh/broadinstitute/gatk/compare/dc15e61a728ccd4e61b139332e48c05b57e4e88c...0d5d1b12d611725c80fa572e5ffba3bf8ea45ee4?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWNhbGlicmF0aW9uL2NvdmFyaWF0ZXMvUmVhZEdyb3VwQ292YXJpYXRlLmphdmE=) | `86.667% <100%> (ø)` | `11 <0> (?)` | |; | [...dinstitute/hellbender/utils/report/GATKReport.java](https://codecov.io/gh/broadinstitute/gatk/compare/dc15e61a728ccd4e61b139332e48c05b57e4e88c...0d5d1b12d611725c80fa572e5ffba3bf8ea45ee4?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZXBvcnQvR0FUS1JlcG9ydC5qYXZh) | `40.196% <66.667%> (ø)` | `16 <0> (?)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2431?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2431?src=pr&el=footer). Last update [dc15e61...0d5d1b1](https://codecov.io/gh/broadinstitute/gatk/compare/dc15e61a728ccd4e61b139332e48c05b57e4e88c...0d5d1b12d611725c80fa572e5ffba3bf8ea45ee4?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2431#issuecomment-283404250:1678,learn,learn,1678,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2431#issuecomment-283404250,1,['learn'],['learn']
Usability,"rs 5 \; --executor-cores 7 \; --executor-memory 25G; ```. What does FindBreakpointEvidenceSpark do, from the perspective of Spark?. * [runTool] filter out secondary and supplementary alignments; * [getMappedQNamesSet] filter out duplicate reads, reads that failed vendor checks, unmapped reads; * Job 0 [ReadMetadata] mapPartitions to find partition stats; * Job 1 [getIntervals] filter and multiple map partitions to find breakpoint intervals ; * Job 2 [removeHighCoverageIntervals] mapPartitionsToPair to find coverage for each interval, then reduceByKey; * Job 3 [getQNames] mapPartitions; * Job 4 [addAssemblyQNames -> getKmerIntervals] mapPartitionsToPair, then reduceByKey, then mapPartitions; * Job 5 [getAssemblyQNames] mapPartitions twice and a collect; * Job 6 [generateFastqs] mapPartitions and combineByKey, then write FASTQ to files. A few observations:; * Jobs 0,1,3 are simple map jobs - very quick 1-2 mins each.; * Job 2 is a simple MR, with a tiny shuffle to sum by key (<1MB of shuffle data); * Job 4 takes a bit longer longer (3min), and shuffles ~3GB. This is a lot faster than when I ran it before with less memory, when it took 9 min. Is it creating a lot of garbage? If you wanted to speed things up you might look at what this is doing on a local machine and see if there are any opportunities to improve CPU efficiency.; * Job 5 takes ~8 mins, and has no shuffle. CPU intensive processing again?; * Job 6 take a little over 3 mins, shuffling ~3GB. Overall, it looks like it’s performing pretty well. There is very little data being shuffled relative to the size of the input (~6GB to 133GB input), so it’s not worth looking into optimizing the data structures there. The input data is being read multiple times, so it _might_ be worth seeing if it can be cached by Spark to avoid reading from disk over and over again. This is only worth it if you have sufficient memory available across the cluster to hold the input (which will be bigger than the on-disk size) _plus_ enou",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2458#issuecomment-292171884:1742,simpl,simple,1742,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2458#issuecomment-292171884,1,['simpl'],['simple']
Usability,"s 30169 30168 -1 ; + Misses 6771 6768 -3 ; Partials 2620 2620; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2450?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/compare/987e2f98c4f9a97d74488bf37bc902ee25274c83...05211ec9114cfb2886fe17c56fa991603241f50d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `23.729% <100%> (ø)` | `2 <0> (ø)` | :x: |; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/compare/987e2f98c4f9a97d74488bf37bc902ee25274c83...05211ec9114cfb2886fe17c56fa991603241f50d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `84.211% <100%> (-0.164%)` | `53 <0> (ø)` | |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/987e2f98c4f9a97d74488bf37bc902ee25274c83...05211ec9114cfb2886fe17c56fa991603241f50d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `66.316% <33.333%> (+2.03%)` | `28 <4> (ø)` | :x: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2450?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2450?src=pr&el=footer). Last update [987e2f9...05211ec](https://codecov.io/gh/broadinstitute/gatk/compare/987e2f98c4f9a97d74488bf37bc902ee25274c83...05211ec9114cfb2886fe17c56fa991603241f50d?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285652447:2186,learn,learn,2186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285652447,1,['learn'],['learn']
Usability,"s are not mosaic CNLOH, then we should clean up all mention of CNLOH in this code. Either way, can we quantify the level of improvement gained by filtering such events in a reproducible evaluation? If so, let's bring that into gatk-evaluation. Finally, there are many more options available to change the segmentation and/or resolution than the single one you mentioned. If the users you are working with can clearly specify their analysis goals in terms of resolution, then it might be possible to sidestep the problem entirely without adding more unsupported code. This would also buy us more time to put in a principled solution, without the risk of unsupported code getting entrenched in their workflows. > There are definitely events that get missed without the germline tagging, so this is an improvement over blacklisting alone. And while I have seen erroneous germline tagging (i.e. false calling a segment germline), it was only ever due to really noisy data (e.g. a bad PoN) or a poorly tuned segment caller. This is encouraging. This means that a straightforward approach to germline filtering, such as simply identifying overlapping posteriors as mentioned above, should work well. Prototyping this approach shouldn't take long at all, especially when the matched normal is guaranteed to be available, as it is in this workflow (tumor-only would require some work to identify the normal state, as mentioned previously). I'd rather just roll that, evaluate it, and merge it instead. Key here is that we sidestep the deficiencies of the current CR-only caller, which also shares the blame for this ""CNLOH"" issue (since these events aren't called in the normal and don't become candidates for tagging, as currently implemented). > And this would be a possible ""better solution"" Shall I file an issue for this? This could also allow us to obviate the TagGermline tool, which is fine by me. I've already expanded the scope of https://github.com/broadinstitute/gatk/issues/4115 to include this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199:3618,simpl,simply,3618,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199,1,['simpl'],['simply']
Usability,"s method than our previous probabilistic approaches. Even SNP segmentation will be much cheaper. > What is the name of this approach? ""KernSeg""?. Not sure...I couldn't find an R package, although an R/C implementation is mentioned in the paper. But the python implementation is straightforward and a pure Java implementation should not be so bad. There are some cythonized numpy methods that my python implementation used, but I think equivalent implementations of these methods should be relatively fast in pure Java as well. > What variant of the algorithm did you implement? the paper lists several. I implemented what they call ApproxKSeg. It's an approximate version that combines binary segmentation with the low-rank approximation to the Gaussian kernel. > I haven't read the paper in detail yet, but is it possible to choose a conservatively large number of possible break points and then filter bad break points, possibly based on the rapid decline of the change point probability? i.e. does the algorithm naturally produce change point probabilities?. Yes, you can oversegment and then choose which breakpoints to retain. However, there are no proper changepoint probabilities, only changepoint costs. Adding a penalty term based on the number of changepoints seems to perform relatively well in simple tests, but one could certainly devise other ways to filter changepoints (some of which could yield probabilities, if you are willing to assume a probabilistic model). I think we should just think of this as a fast, heuristic, non-parametric method for finding breakpoints in multidimensional data. > Is it possible to throw in additional change points incrementally, without doing extra work, until a certain criterion is met? (see above). The version I implemented adds changepoints via binary segmentation. The time complexity required to split a segment is linear in the number of points contained in the segment, although some care must be taken in the implementation to ensure this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-321140715:2802,simpl,simple,2802,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-321140715,1,['simpl'],['simple']
Usability,"s strategy will cause us to miss obvious hets in the tumor (~80x). This is now relevant for two reasons: 1) it seems that we will want to run the filter with more stringent parameters, as higher base error rates are causing homs to leak past the filter, which in turn affects the fit of the allele-fraction model (which only attempts to model hets) by biasing normal segments towards unbalanced, and 2) we now want to run ModelSegments separately on the normal to allow for the filtering of germline events. So we want to be more stringent with low-coverage normals without affecting our high-coverage tumors. For example, here's some hg38 NovaSeq FFPE WGS data from a ~40x normal:. ![download](https://user-images.githubusercontent.com/11076296/43977946-9bd0a1bc-9cb3-11e8-9d7f-016a99c1c173.png). Compare to an hg19 TCGA WGS ~40x normal:. ![download 1](https://user-images.githubusercontent.com/11076296/43978051-f8820770-9cb3-11e8-8e16-13b51792614f.png). The hom-ref tail in the first plot is much fatter and clearly leaks into the het cloud. Also curious is that the het cloud is far less binomial (or even beta-binomial---note also the absence of the tail extending to the origin). I am still not sure why the incoming data looks different. There are several confounding factors: NovaSeq vs. HiSeq, hg38 vs. hg19, AF > 2% gnomAD sites vs. AF > 10% 1000G sites, FFPE vs. frozen, etc. I have not seen enough examples/combinations to be able to say which are the most important factors. Changing the genotyping/filtering strategy can get around this change in the data without a corresponding change in the allele-fraction model for now, but getting the data to look as good as possible upstream would be even better. Another thought: would be nice if the strategy was easily compatible with an eventual implementation of multi-sample segmentation, which would require that the same sites are used in both the tumor and the normal. We would want to strike a balance between maximizing the number of ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3915#issuecomment-412189218:1448,clear,clearly,1448,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3915#issuecomment-412189218,1,['clear'],['clearly']
Usability,"sbGJlbmRlci90b29scy9zcGFyay9zdi9EaXNjb3ZlclN0cnVjdHVyYWxWYXJpYW50c0Zyb21BbGlnbmVkQ29udGlnc1NBTVNwYXJrLmphdmE=) | `0% <0%> (ø)` | `0 <0> (?)` | |; | [...oadinstitute/hellbender/tools/spark/sv/SvType.java](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdlR5cGUuamF2YQ==) | `100% <100%> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...e/hellbender/tools/spark/sv/ChimericAlignment.java](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9DaGltZXJpY0FsaWdubWVudC5qYXZh) | `57.831% <33.333%> (ø)` | `25 <1> (ø)` | :arrow_down: |; | [...bender/tools/spark/sv/AssemblyAlignmentParser.java](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9Bc3NlbWJseUFsaWdubWVudFBhcnNlci5qYXZh) | `66.917% <66.667%> (ø)` | `38 <1> (ø)` | :arrow_down: |; | [...er/tools/spark/sv/SVVariantConsensusDiscovery.java](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TVlZhcmlhbnRDb25zZW5zdXNEaXNjb3ZlcnkuamF2YQ==) | `82.653% <73.913%> (ø)` | `25 <1> (?)` | |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=footer). Last update [d054e7a...4ffa301](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2567#issuecomment-291643361:4153,learn,learn,4153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2567#issuecomment-291643361,1,['learn'],['learn']
Usability,"scales (noting that longer window lengths allow for more subtle changepoints to be detected) works well in practice. For example, here are what the cost functions look like for window sizes of 8, 16, 32, and 64:. ![2](https://user-images.githubusercontent.com/11076296/29582011-210d37b8-8749-11e7-9383-0c657232347e.png). ![3](https://user-images.githubusercontent.com/11076296/29582016-23fbc6a6-8749-11e7-951e-f618e8489a0b.png). ![4](https://user-images.githubusercontent.com/11076296/29582044-3eb20a1e-8749-11e7-84a0-3734bad15e1f.png). ![5](https://user-images.githubusercontent.com/11076296/29582047-410ac490-8749-11e7-8a98-b2098cf1b5ea.png); 4) For each of these cost functions, find (up to) the _C<sub>max</sub>_ most significant local minima. The problem of finding local minima of a noisy function can be solved by using topological persistence (e.g., https://people.mpi-inf.mpg.de/~weinkauf/notes/persistence1d.html and http://www2.iap.fr/users/sousbie/web/html/indexd3dd.html?post/Persistence-and-simplification). A straightforward watershed algorithm can sort all local minima by persistence in linear time after an initial sort of the data.; 5) These sets of local minima from all window sizes together provide the pool of candidate changepoints (some of which may overlap exactly or approximately). We perform backwards selection using the global segmentation cost. That is, we compute the global segmentation cost given all the candidate changepoints, calculate the cost change for removing each of the changepoints individually, remove the changepoint with the minimum cost change, and repeat. This gives the global cost as a function of the number of changepoints _C_.; 6) Add a penalty _a C + b C log(N / C)_ to the global cost and find the minimum to determine the number of changepoints. For the above simulated data, _a = 2_ and _b = 2_ works well, recovering all of the changepoints in the above example with no false positives:; ![6](https://user-images.githubusercontent.com/1107",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-324125586:2004,simpl,simplification,2004,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-324125586,1,['simpl'],['simplification']
Usability,"se** coverage by `0.003%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2511 +/- ##; ===============================================; - Coverage 76.259% 76.256% -0.003% ; + Complexity 10865 10864 -1 ; ===============================================; Files 750 750 ; Lines 39543 39543 ; Branches 6915 6915 ; ===============================================; - Hits 30155 30154 -1 ; Misses 6771 6771 ; - Partials 2617 2618 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2511?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...er/tools/walkers/variantutils/VariantsToTable.java](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...1a7a561a7da5603a607f04cd982c62fb8491403b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYXJpYW50c1RvVGFibGUuamF2YQ==) | `94.083% <ø> (ø)` | `73 <0> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...1a7a561a7da5603a607f04cd982c62fb8491403b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `90% <0%> (-1.429%)` | `23% <0%> (-1%)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2511?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2511?src=pr&el=footer). Last update [724fbd0...1a7a561](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...1a7a561a7da5603a607f04cd982c62fb8491403b?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2511#issuecomment-288267091:1800,learn,learn,1800,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2511#issuecomment-288267091,1,['learn'],['learn']
Usability,"similar same error message with ; `gatk HaplotypeCallerSpark -R ref.fa -I input.GatherBamFiles.bam -O output.g2.vcf.gz`. OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); gatk 4.1.8.1 . ```; 07:16:06.169 INFO HaplotypeCallerEngine - Tool is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 20/08/15 07:16:06 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.5 MB, free 57.3 GB); 20/08/15 07:16:06 INFO SparkUI: Stopped Spark web UI at http://e1c-050:4041; 20/08/15 07:16:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 20/08/15 07:16:06 INFO MemoryStore: MemoryStore cleared; 20/08/15 07:16:06 INFO BlockManager: BlockManager stopped; 20/08/15 07:16:06 INFO BlockManagerMaster: BlockManagerMaster stopped; 20/08/15 07:16:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 20/08/15 07:16:06 INFO SparkContext: Successfully stopped SparkContext; 07:16:06.412 INFO HaplotypeCallerSpark - Shutting down engine; [August 15, 2020 7:16:06 AM EDT] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.11 minutes.; Runtime.totalMemory()=102900432896; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:67); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-674384617:853,clear,cleared,853,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-674384617,1,['clear'],['cleared']
Usability,simple tests added in #884,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/709#issuecomment-160836902:0,simpl,simple,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/709#issuecomment-160836902,1,['simpl'],['simple']
Usability,simply rebasing does not do it. back to @lbergelson for advice,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/844#issuecomment-142767158:0,simpl,simply,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/844#issuecomment-142767158,1,['simpl'],['simply']
Usability,"ssibly as part of `PreprocessIntervals`) at some point (actually, I think we will be forced to, since `PreprocessIntervals` will output a Picard interval list, and `AnnotateTargets` outputs a target file).; - [x] Integration tests are still needed for `CreateReadCountPanelOfNormals`. These might not test for correctness, but we could possibly compare to old PoNs. Segmentation/modeling:; - Instead of separate tools for copy-ratio segmentation (`PerformSegmentation`) and allele-fraction segmentation/union/modeling (`AllelicCNV`), there is now just a single segmentation/modeling tool (`ModelSegments`).; - Input is denoised copy ratio and/or allelic counts. If only one input is provided, then we only model only the corresponding quantity.; - There is no separate allele-fraction workflow. Unlike the old approach, we do not perform any genotyping or modeling before doing kernel segmentation.; - [x] Old code and classes are used for segment union. We should port or possibly replace this with a simple method that uses kernel segmentation. EDIT: Actually, just tried running a WGS sample and this is still a major bottleneck. EDIT 2: Hmm...actually doesn't seem to be an issue on my desktop (compared to my laptop, on which the run hangs here). Will try to track down the source of the discrepancy. EDIT 3: Added segment union based on single-changepoint detection using kernel segmentation.; - [x] Segment union should be replaced by a proper joint kernel segmentation. EDIT: I've added this, but there could be some minor improvements. Right now, only use one het per copy-ratio interval and throw away those off-target/bin. There are a few percent of targets/bins that have more than one het, and we could potentially rescue the off-target/bin hets as well with some care.; - Old code and models are used for modeling. Since the old allele-fraction model only models hets, we perform a `GetHetCoverage`-like binomial genotyping step (and output the results) before modeling. However, instea",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:3676,simpl,simple,3676,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,1,['simpl'],['simple']
Usability,such tests mostly exist in VectorPairHMMUnitTest that @gspowley wrote. I think we could just move them there and add a simple java implementation of `computeLikelihoods` that is pretty much a copy of code from `LoglessPairHMM`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2030#issuecomment-234598263:119,simpl,simple,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2030#issuecomment-234598263,1,['simpl'],['simple']
Usability,"t gCNV, not ploidy)? As I show above, I don't think we need mappability to nail the baseline ploidy. Can we then rely on the per-bin bias to account for these regions in gCNV (pinning them back to the correct CN) without mappability filtering? And with mappability filtering, how substantial is the hit to coverage in these regions? Should we blacklist them for the time being?. To summarize, I think the order of events I'd like to see is this:. 1. Cut an **initial Beta** release that incorporates CollectReadCounts, streamline evaluations for the AACR poster, do a bit of tuning, establish a baseline. Hopefully the current ploidy calls suffice, if not, maybe issue a quick PR that implements the naive bin filtering (or whatever is necessary to get good ploidy calls). At the same time, get preliminary feedback from some users running on *small test cohorts* after we have some parameter recommendations.; 2. Do a round of method/model improvement. Start with quick and dirty fixes (e.g., blacklisting PARs) and work our way to more non-trivial changes. This will include many of the suggestions you have brought up, but we should also review user feedback and prioritize accordingly---they may find something that is not even on our radar. Demonstrate improvement (hopefully substantial!) over baseline, cut **second Beta** release.; 3. Run on larger cohorts, iron out remaining minor issues, and then productionize. By this time, @asmirnov239 will have hopefully made some progress on the PoN clustering front as well. **When we are ready, then we will take gCNV out of Beta.** With our current staffing situation, I do not expect this to happen before May 15, but I do enjoy pleasant surprises. :); 4. Run on gnomAD, world domination, etc. Again, getting a **initial Beta** release and some reasonable parameters to users is a high priority, so thanks for kicking off the evaluations, and thanks for your willingness to discuss our options. Let me know if you agree with the rest of the plan!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639:3031,feedback,feedback,3031,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639,1,['feedback'],['feedback']
Usability,"t shows how to utilize Spark. There is an example from ChrisW in <https://github.com/broadinstitute/gatk/issues/3853>:. ```; 	-- \; --sparkRunner GCS \; --cluster my-dataproc-spark-cluster; ```. ---; ## DiscoverVariantsFromContigAlignmentsSAMSpark. 1. ""Parse"" is vague. How about: ; Parses aligned contig assemblies of genomic breakpoints and calls structural variants. And `6. ` from above. ---; ## ExtractOriginalAlignmentRecordsByNameSpark. 1. Subsets reads by names; 2. I think you mean FilterSamReads (Picard) and not PrintReads. AFAIK, PrintReads cannot subset based on a list of read names. Rather FilterSamReads can do so as long as the reads are queryname-sorted. So then it would be good to distinguish this tool from FilterSamReads by saying (assuming true) ""Unlike FilterSamReads, this tool can take any sort-order, e.g. unsorted, to subset target reads.""; 3. ReadDataProgramGroup.java. And `6. ` from above. ---; ## FilterLongReadAlignmentsSAMSpark. 1. In the one-line summary, I'm not clear on what is meant by ""Filters"". Based on the result file, seems like it collects metrics on each contig alignment.; 2. ; 3. If metrics, then DiagnosticsAndQCProgramGroup.java. And `6. ` from above. ---; ## FindBadGenomicKmersSpark. 1. The term ""copy number"" should be reserved in reference to CNV analyses. So instead, how about:; Identify sequence contexts that occur at high frequency in a reference; 2. Please define a kmer. If only a reference fasta is required (as listed under Inputs) great. But if the tool also depends on a FAI index and DICT dictionary, please do include them. Also, it would be good to provide an example of how such information is used in SV discovery, e.g. ""the resulting file can be given to FindBreakpointEvidenceSpark, which will then ignore such sequence contexts during analysis."" Also would be good to mention that the default kmer size (--k-size 51) is optimized for human if indeed this is the case.; 3. ReferenceProgramGroup.java. And `6. ` from above. ---; ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3948#issuecomment-351467451:2421,clear,clear,2421,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3948#issuecomment-351467451,1,['clear'],['clear']
Usability,"thanks @gspowley I'll measure it again tomorrow. I see the KMP code has an array allocation - I wonder if this accounts for the relatively small difference between string and KMP. I'll also try again with my mud-room implementation and compare. Also, my Mac is clearly slower than what you're running on :) I'll try David's suggestion too and limit to active regions.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1677#issuecomment-204227646:261,clear,clearly,261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1677#issuecomment-204227646,1,['clear'],['clearly']
Usability,thanks for the review @kcibul. I made some changes accordingly. re: PrepareCallset file of sample names. That would be nice! It would make this workflow simpler and it also simplifies the access requirements for PrepareCallset. re: Dockstore. We actually ruled this out because Terra says that the definition of a method configuration can change automatically if its updated in dockstore. Which can be useful but it adds a security risk since a compromised Dockstore can change the definition of the production AoU extraction WDL which runs with highly elevated permissions. We already have a script that creates method configurations from github so I can probably add something a little hacky to resolve relative imports to the raw github file that it refers to.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7242#issuecomment-846494686:153,simpl,simpler,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7242#issuecomment-846494686,2,['simpl'],"['simpler', 'simplifies']"
Usability,"that the breakpoint is downstream of the interval end position; */; ```. What else would you like to see documented there? . - The use of the word strand in this case is largely driven by a mapping of these data structures to the BEDPE format, which is the older format for representing breakpoints implied by paired-end mapping data without assembly. If you only consider read pair mappings, strand has the natural interpretation of being the strand to which reads aligned. For example, a deletion's two intervals have strands `+` and `-` because the `+` reads align at left breakpoint and `-` reads align near the right breakpoint. Extending the concept to supplementary mappings of split reads muddies the concept a bit, which made me change the definition of strand to the existing one: whether the evidence suggests a breakpoint upstream of the interval start or downstream of the interval end. . - I created `StrandedInterval` mostly just as a data container since I was often passing around an interval and an associated strand, and using them in conjunction with the `PairedStrandedIntervalTree` data structure. My goal with those was to have them be utility classes that could be used by anyone without regards to the particular mechanics of imprecise evidence clustering I've implemented here. I'd prefer to put the definition of how we're interpreting the interval and strand in our logic classes (`BreakpointEvidence`, `EvidenceTargetLink`, and EvidenceTargetLinkClusterer`). Does that make sense?. - A ""distal target region"" can be represented by a `StrandedInterval`. So can the original, proximal (non-distal) location of the breakpoint evidence. An `EvidenceTargetLink` has the two `StrandedInterval` objects representing the proximal and distal locations, and the count of evidence types in the link cluster. Does that make things more clear?. I've added some ASCII-art visual examples to `DiscordantReadPairEvidence.getDistalTargets` and `SplitRead.getDistalTargets`. Do those help?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3628#issuecomment-333857471:2977,clear,clear,2977,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3628#issuecomment-333857471,1,['clear'],['clear']
Usability,"the design is simple - filters should filter, not blow up. There could be a tool that takes a set of filters and blows up if they fail. But the filter's job is to filter not blow up.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/193#issuecomment-76831428:14,simpl,simple,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/193#issuecomment-76831428,1,['simpl'],['simple']
Usability,"there is one thing i dont like - if i revert the change i made in removeNonRefAndUnusedAltAlleles(), the one to simplify, these tests pass locally for me, with the test files as-is. do you see this?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-582253636:112,simpl,simplify,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-582253636,1,['simpl'],['simplify']
Usability,"these users help us definitively resolve whether these events are 1) germline with incorrectly normalized CR, or 2) mosaic CNLOH? If not, then we have not even taken the first step to correctly identify the issue. So it seems a bit premature to even prototype a method, much less merge it. I think this PR, as is, muddies the waters quite a bit. For example, it introduces a new Record class that denotes this type of ""CNLOH"" with a `C`. If we want to merge this, I suggest that we first correctly identify the issue. If these events are not mosaic CNLOH, then we should clean up all mention of CNLOH in this code. Either way, can we quantify the level of improvement gained by filtering such events in a reproducible evaluation? If so, let's bring that into gatk-evaluation. Finally, there are many more options available to change the segmentation and/or resolution than the single one you mentioned. If the users you are working with can clearly specify their analysis goals in terms of resolution, then it might be possible to sidestep the problem entirely without adding more unsupported code. This would also buy us more time to put in a principled solution, without the risk of unsupported code getting entrenched in their workflows. > There are definitely events that get missed without the germline tagging, so this is an improvement over blacklisting alone. And while I have seen erroneous germline tagging (i.e. false calling a segment germline), it was only ever due to really noisy data (e.g. a bad PoN) or a poorly tuned segment caller. This is encouraging. This means that a straightforward approach to germline filtering, such as simply identifying overlapping posteriors as mentioned above, should work well. Prototyping this approach shouldn't take long at all, especially when the matched normal is guaranteed to be available, as it is in this workflow (tumor-only would require some work to identify the normal state, as mentioned previously). I'd rather just roll that, evaluate ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199:2913,clear,clearly,2913,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199,1,['clear'],['clearly']
Usability,"this for a first workflow to target?. 1) Run ExtractVariantAnnotations on a training set of chromosomes. You can keep training/truth labels as in Best Practices, for now.; 2) Run TrainVariantAnnotationsModel on that. We'll use the truth scores generated here for any sensitivity conversions---i.e., we'll be calibrating scores only to the truth sites that are contained in the training set of chromosomes.; 3) Use the trained model to run a single shard of ScoreVariantAnnotations on a validation set of chromosomes.; 4) Run some variation of the above script on the resulting outputs to determine SNP and INDEL score thresholds for optimizing the corresponding LL scores. We can also add some code to the script to use the truth scores from step 2 to convert these score thresholds into truth-sensitivity thresholds.; 5) Provide these truth-sensitivity thresholds to ScoreVariantAnnotations and use them to hard filter. Evaluate on a test set of chromosomes. If all looks good, we can later move steps 3-4 into the train tool and automate the passing of sensitivities in 5 via outputs in the model directory. This will let us keep the basic interface of ScoreVariantAnnotations the same, but we'll have to add a few basic parameters to TrainVariantAnnotationsModel to control the train/validation split. So I think all this branch is missing is step 5---we'll simply need to add command-line parameters for the SNP/INDEL sensitivity thresholds and then do the hard filtering in the VCF writing method highlighted above. Do you think you can handle implementing that in this branch, and then the rest at the WDL level? I can help with the python script for the LL stuff (or anything else), if needed. Not sure if you got a chance to check out what your collaborators are doing in the methods you're looking to compare against, but it would be good to understand if this basic scheme for train/validation/test splitting can be replicated over there. You'll want to compare apples to apples, after all!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1068345084:1440,simpl,simply,1440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1068345084,1,['simpl'],['simply']
Usability,"tire process is very similar to what @davidbenjamin does in https://github.com/broadinstitute/gatk/pull/3638. We should consider combining this code (along with `AllelicCount`/`PileupSummary`) at some point.; - [x] Added option to use matched normal.; - [ ] Rather than port over the old modeling code, I would rather expand the allele-fraction model to allow for the modeling of hom sites. I wrote up such a model in some notes I sent around a few months back. This model allows for an allelic PoN that uses all sites to learn reference bias, not just hets. Depending on how our python development proceeds, I may try to implement this model using the old `GibbsSampler` code instead.; - [x] In the meantime, we can try to speed up the old allele-fraction model, which is now the main bottleneck. An easy (lazy) strategy might simply be to downsample and scale likelihoods when estimating global parameters. Addresses #2884.; - [x] Even though the simple copy-ratio model is much faster, it still takes ~15-20 minutes for 100 iterations on WGS, so we can downsample here too.; - [x] Integration tests are still needed; again, these might not test for correctness.; - I've added the ability to specify a prior for the minor-allele fraction, which alleviates the problem of residual bias in balanced segments.; - I've reduced the verbosity of the modeled-segments file. I only report posterior mode and 10%, 50%, and 90% deciles. Global parameters have the full deciles output in the .param files, but I removed the mode and highest density credible interval (because of the below item).; - [x] Some residual bias remains in the estimate of the minor-allele fraction posterior mode. This is simply because we are performing kernel density estimation of a bounded quantity. One possibility would be to logit transform to an unbounded support, perform the estimation, then transform back. EDIT: Just removed kernel density estimation for now, partly due to #3599 as well.; - Hmm, actually still a tiny bi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:5853,simpl,simple,5853,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,1,['simpl'],['simple']
Usability,"titute/gatk/pull/2566?src=pr&el=h1) Report; > Merging [#2566](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/6859a1202a79c1b123eac73a3f70162c6a90783c?src=pr&el=desc) will **decrease** coverage by `0.015%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2566 +/- ##; ==============================================; - Coverage 76.386% 76.37% -0.015% ; + Complexity 10898 10895 -3 ; ==============================================; Files 754 754 ; Lines 39552 39552 ; Branches 6907 6907 ; ==============================================; - Hits 30212 30206 -6 ; - Misses 6727 6732 +5 ; - Partials 2613 2614 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ellbender/utils/test/CommandLineProgramTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0NvbW1hbmRMaW5lUHJvZ3JhbVRlc3Rlci5qYXZh) | `85.714% <0%> (-4.762%)` | `7% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/GenomeLocParser.java](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vbWVMb2NQYXJzZXIuamF2YQ==) | `85.95% <0%> (-4.132%)` | `55% <0%> (-2%)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=footer). Last update [6859a12...1df1909](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2566#issuecomment-291909459:1629,learn,learn,1629,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2566#issuecomment-291909459,1,['learn'],['learn']
Usability,"titute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyRW5naW5lLmphdmE=) | `89.33% <50%> (+1.17%)` | `43 <3> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.23% <0%> (-2.74%)` | `11% <0%> (ø)` | |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `89.27% <0%> (-0.39%)` | `73% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+3.22%)` | `39% <0%> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+40%)` | `3% <0%> (+2%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4139?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4139?src=pr&el=footer). Last update [e12034a...af94877](https://codecov.io/gh/broadinstitute/gatk/pull/4139?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4139#issuecomment-358285781:4447,learn,learn,4447,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4139#issuecomment-358285781,1,['learn'],['learn']
Usability,"treamlined and principled methods. (Some of these functions, such as IGV conversion, are already performed by existing code.) Of those functions, I think format conversion is the only one we should retain from this code in an unsupported fashion. So if this PR introduces a useful GISTIC conversion, no harm in merging that. This all sounds like a decision for the new tech lead! @mwalker174 any thoughts? . More detailed responses follow:. > Users are already using this branch and giving me positive feedback (definitely more positive than adjusting num_changepoints_penalty_factor). I suggest merging mostly for practical reasons. It buys us more time to put in a principled solution. And this workflow is clearly marked as an unsupported prototype anyway (as are the GATK CLIs). I want to emphasize that this whole workflow is not a long-term solution. In other words, I would like to get this in and then focus on a supported solution. While it's great that users are giving positive feedback, I refer you to CellBender team's manifesto at https://github.com/broadinstitute/CellBender/commit/28f02f8dbd716aff922bb8da1e56da29347b245b. Can these users help us definitively resolve whether these events are 1) germline with incorrectly normalized CR, or 2) mosaic CNLOH? If not, then we have not even taken the first step to correctly identify the issue. So it seems a bit premature to even prototype a method, much less merge it. I think this PR, as is, muddies the waters quite a bit. For example, it introduces a new Record class that denotes this type of ""CNLOH"" with a `C`. If we want to merge this, I suggest that we first correctly identify the issue. If these events are not mosaic CNLOH, then we should clean up all mention of CNLOH in this code. Either way, can we quantify the level of improvement gained by filtering such events in a reproducible evaluation? If so, let's bring that into gatk-evaluation. Finally, there are many more options available to change the segmentation and/or ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199:1818,feedback,feedback,1818,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199,1,['feedback'],['feedback']
Usability,"tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyRW5naW5lLmphdmE=) | `89.88% <66.66%> (-1.26%)` | `63 <3> (+3)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5442/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5442/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5442/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `81.09% <0%> (+0.6%)` | `42% <0%> (ø)` | :arrow_down: |; | [...walkers/haplotypecaller/AssemblyRegionTrimmer.java](https://codecov.io/gh/broadinstitute/gatk/pull/5442/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseVJlZ2lvblRyaW1tZXIuamF2YQ==) | `62.72% <0%> (+2.72%)` | `20% <0%> (+2%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5442?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5442?src=pr&el=footer). Last update [9c4a27b...bf39362](https://codecov.io/gh/broadinstitute/gatk/pull/5442?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5442#issuecomment-440776502:3773,learn,learn,3773,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5442#issuecomment-440776502,1,['learn'],['learn']
Usability,"ually less expensive in typical (non-extreme) cases than reconstructing the full set of post-downsampling reads in an active region from multiple AlignmentContexts emitted by LIBS without any duplicates. I'll have to do some performance testing to see whether or not this is the case. Will try to get to this within the next few weeks, but the QC project has immediate priority. [...]. Discussed this with Ryan -- we agreed that the right thing to do is to move the enforcement of the hard cap on the total number of reads that can be in an active region from the HC walker to the engine, and have the size of the cap be controlled by a new argument (not dcov). That way you never pay the cost of storing the undownsampled reads for an active region in memory. We'd also have to educate users on exactly what the various downsampling arguments do for active region walkers. [...]. Making the hardcoded per-active-region cap settable from the command line is the easy part -- what seems hard is:; - Determining whether we can avoid storing all undownsampled reads in memory at once without affecting the quality of calls. Currently, as outlined in earlier comments on this ticket, we do a downsampling pass per locus which respects dcov (in LocusIteratorByState) but keep all undownsampled reads in memory anyway (defeating the main purpose of that first pass), then do a second downsampling pass per active region that does not respect dcov (uses the hardcoded per-region limit).; - If we find that we can't avoid storing all of the undownsampled reads in memory at once for some reason, then perhaps the right thing to do would be to completely disable the downsampling pass in LocusIteratorByState for active region traversals, and disallow the -dcov argument for active region walkers. Downsampling would then by controlled solely by the new argument to set the max # of reads per active region.; - Clarifying the meaning of the per-locus DP annotation for the HC given things like realignment of ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345:5708,undo,undownsampled,5708,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/103#issuecomment-78379345,1,['undo'],['undownsampled']
Usability,"used. I suspect I'd have a lot of ""YAGNI"" comments if I knew.; For example, you are basing all your implementations on Apache's AbstractIntegerDistribution. That class, it seems to me, is really intended to allow you to do sampling from a distribution. But I suspect you won't be sampling, you'll only be asking questions about density. If so, there's a lot of baggage that gets pulled into your anonymous implementations of this class: random number generators, boundary information, etc. Lots of extra boilerplate. Couldn't this be clearer if reorganized as an abstract class implementing AbstractIntegerDistribution, 3 concrete classes for each case (rather than the current anonymous classes), a factory that takes a spec and returns the correct distribution, and a simple enum class?. It seems weird that the distributions you allow users to realize using a spec are both two-tailed distributions, when fragment size is a one-tailed distribution. It seems awkward that failure to parse a distribution spec leads to a code path where you try to extract a file name and read serialized read metadata. Wouldn't it be clearer to have two completely distinct code paths with a different program argument for the empirical case?. The read metadata gives per library distributions. It seems suspect that you are folding them all together. Different libraries can have rather different fragment size stats. Still don't like that you're providing the possibility of reading the metadata text file. Seems fragile. Why don't you modify the ReadMetadata code to always produce just the data you need. Then you could eliminate the text-file code. And you could simplify the code that processes the serialized ReadMetadata which now has this awkward code path: CDF -> density -> sum across libs -> density+CDF stored in memory. If you have the CDF you can trivially produce density on demand. Notwithstanding all this, if you're happy with the code as it stands, feel free to merge.; Back to you, review done.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4827#issuecomment-418420706:1221,clear,clearer,1221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4827#issuecomment-418420706,2,"['clear', 'simpl']","['clearer', 'simplify']"
Usability,"utor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-09 13:35:56 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 12.691336 s; 2019-01-09 13:35:56 INFO AbstractConnector:318 - Stopped Spark@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:56 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-09 13:35:56 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-09 13:35:56 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-09 13:35:56 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-09 13:35:56 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-09 13:35:56 INFO BlockManager:54 - BlockManager stopped; 2019-01-09 13:35:56 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-09 13:35:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:35819,clear,cleared,35819,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['clear'],['cleared']
Usability,"vYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NpbmsuamF2YQ==) | `73.109% <ø> (-0.84%)` | `26% <ø> (ø)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...9d80a51aa17f77bfca830472bdc4923b98151771?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `73.611% <ø> (-0.694%)` | `36% <ø> (-1%)` | |; | [...org/broadinstitute/hellbender/utils/GenomeLoc.java](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...9d80a51aa17f77bfca830472bdc4923b98151771?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vbWVMb2MuamF2YQ==) | `67.797% <ø> (-0.565%)` | `85% <ø> (-1%)` | |; | [...lbender/tools/walkers/vqsr/VariantDataManager.java](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...9d80a51aa17f77bfca830472bdc4923b98151771?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvVmFyaWFudERhdGFNYW5hZ2VyLmphdmE=) | `66.228% <ø> (-0.439%)` | `78% <ø> (-1%)` | |; | ... and [3 more](https://codecov.io/gh/broadinstitute/gatk/pull/2399/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2399?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2399?src=pr&el=footer). Last update [3c10554...9d80a51](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...9d80a51aa17f77bfca830472bdc4923b98151771?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2399#issuecomment-278182658:4890,learn,learn,4890,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2399#issuecomment-278182658,1,['learn'],['learn']
Usability,"vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-18.75%)` | `6% <0%> (ø)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `40.469% <0%> (-18.009%)` | `28% <0%> (ø)` | |; | ... and [96 more](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=footer). Last update [a85e0ff...1d6ce76](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-290039637:4051,learn,learn,4051,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-290039637,1,['learn'],['learn']
Usability,"what `merge()` returns is a `Locatable` though, so it would be clear that it isn't a `SamRecord` or a `VariantContext`. Merge is a bit of a strange one, because you would need to return some concrete implementation. I guess the most pure thing to do would be to return an anonymous implementation of Locatable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/305#issuecomment-79219917:63,clear,clear,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/305#issuecomment-79219917,1,['clear'],['clear']
Usability,"yes, it seems to. it seems this was a simple bug where GenotypeGVCFsEngine.removeNonRefAlleles() wasnt working as intended for multi-allelic sites; however, I'm not sure I understand the entire genotyping process well enough to be certain on this. we can iterate on #6406",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6263#issuecomment-577344229:38,simpl,simple,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6263#issuecomment-577344229,1,['simpl'],['simple']
Usability,"you mean, for spark? Up to you - we'll only be comparing results between runs on your setup anyway. For my experiments I used 10 nodes of 16 CPUs each and stuff runs in <10-15 minutes then. If you go for fewer cores, it'll simply take longer - not a big deal here because the requirement is that those run overnight",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1609#issuecomment-227219320:223,simpl,simply,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1609#issuecomment-227219320,1,['simpl'],['simply']
Usability,"zL2NvbnRhbWluYXRpb24vQ29udGFtaW5hdGlvbk1vZGVsLmphdmE=) | `92.39% <92.39%> (ø)` | `39 <39> (?)` | |; | [.../walkers/contamination/ContaminationSegmenter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5413/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vQ29udGFtaW5hdGlvblNlZ21lbnRlci5qYXZh) | `96.42% <96.42%> (ø)` | `9 <9> (?)` | |; | [...lbender/utils/read/SAMRecordToGATKReadAdapter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5413/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL1NBTVJlY29yZFRvR0FUS1JlYWRBZGFwdGVyLmphdmE=) | `91.6% <0%> (-2.1%)` | `144% <0%> (+6%)` | |; | [...nder/tools/funcotator/TranscriptSelectionMode.java](https://codecov.io/gh/broadinstitute/gatk/pull/5413/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL1RyYW5zY3JpcHRTZWxlY3Rpb25Nb2RlLmphdmE=) | `89.71% <0%> (-1.87%)` | `1% <0%> (ø)` | |; | [...tools/funcotator/DataSourceFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5413/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0RhdGFTb3VyY2VGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `86.95% <0%> (-1.68%)` | `17% <0%> (ø)` | |; | ... and [23 more](https://codecov.io/gh/broadinstitute/gatk/pull/5413/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5413?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5413?src=pr&el=footer). Last update [864b180...1183b3d](https://codecov.io/gh/broadinstitute/gatk/pull/5413?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5413#issuecomment-438824631:4517,learn,learn,4517,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5413#issuecomment-438824631,1,['learn'],['learn']
Usability,"zcGFyay9zdi9BbGlnbmVkQXNzZW1ibHlPckV4Y3VzZS5qYXZh) | `93.296% <100%> (+81.997%)` | `34 <2> (+30)` | :arrow_up: |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `76.994% <78.261%> (+36.525%)` | `44 <1> (+16)` | :arrow_up: |; | [.../sv/StructuralVariationDiscoveryPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5UGlwZWxpbmVTcGFyay5qYXZh) | `90.476% <90.476%> (ø)` | `4 <4> (?)` | |; | [...tructuralVariationDiscoveryArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5QXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `95.833% <95.833%> (ø)` | `0 <0> (?)` | |; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluLmphdmE=) | `50.888% <0%> (-1.183%)` | `23% <0%> (-1%)` | |; | ... and [25 more](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=footer). Last update [bf993d8...dc817a8](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2595#issuecomment-293918558:4225,learn,learn,4225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2595#issuecomment-293918558,1,['learn'],['learn']
Usability,"zdC5qYXZh) | `97.82% <100%> (+0.26%)` | `8 <1> (+1)` | :arrow_up: |; | [...er/tools/walkers/GenotypeGVCFsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4969/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0dlbm90eXBlR1ZDRnNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `78.26% <100%> (+2.45%)` | `25 <6> (+6)` | :arrow_up: |; | [...bender/tools/walkers/variantutils/ReblockGVCF.java](https://codecov.io/gh/broadinstitute/gatk/pull/4969/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9SZWJsb2NrR1ZDRi5qYXZh) | `81.52% <100%> (+1.17%)` | `46 <0> (+3)` | :arrow_up: |; | [...der/tools/walkers/annotator/RMSMappingQuality.java](https://codecov.io/gh/broadinstitute/gatk/pull/4969/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9STVNNYXBwaW5nUXVhbGl0eS5qYXZh) | `83.6% <77.35%> (-10.21%)` | `41 <25> (+1)` | |; | [...der/tools/walkers/CombineGVCFsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4969/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0NvbWJpbmVHVkNGc0ludGVncmF0aW9uVGVzdC5qYXZh) | `87.44% <83.33%> (+0.15%)` | `24 <2> (ø)` | :arrow_down: |; | ... and [19 more](https://codecov.io/gh/broadinstitute/gatk/pull/4969/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4969?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4969?src=pr&el=footer). Last update [868a32e...49c474d](https://codecov.io/gh/broadinstitute/gatk/pull/4969?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4969#issuecomment-401457112:4466,learn,learn,4466,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4969#issuecomment-401457112,1,['learn'],['learn']
Usability,"| [...g/broadinstitute/hellbender/engine/ReadWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZFdhbGtlci5qYXZh) | `100% <0%> (ø)` | `27% <0%> (+13%)` | :arrow_up: |; | [...org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2wuamF2YQ==) | `93.411% <0%> (+1.639%)` | `135% <0%> (+58%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `74.026% <0%> (+1.948%)` | `35% <0%> (ø)` | :arrow_down: |; | [...itute/hellbender/tools/walkers/bqsr/ApplyBQSR.java](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQXBwbHlCUVNSLmphdmE=) | `93.75% <0%> (+2.083%)` | `7% <0%> (+1%)` | :arrow_up: |; | [.../broadinstitute/hellbender/engine/LocusWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvTG9jdXNXYWxrZXIuamF2YQ==) | `92.188% <0%> (+2.714%)` | `26% <0%> (+12%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=footer). Last update [12c7a2d...7488ed4](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2593#issuecomment-293046056:3689,learn,learn,3689,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2593#issuecomment-293046056,1,['learn'],['learn']
