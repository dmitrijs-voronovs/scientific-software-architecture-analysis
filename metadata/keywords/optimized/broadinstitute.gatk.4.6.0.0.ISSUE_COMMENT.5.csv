quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Energy Efficiency,"How much does count collection cost at the desired bin size? How does this compare to bincov? Perhaps we could eliminate one of these steps if redundant. Note that the read counts are read once and stored in memory, so unless this takes a significant amount of time, then indexing is probably not the highest priority here (although I agree it would be nice to have in general). One related issue, as you mention, is file localization---since each shard only operates on a portion of the counts in each sample, it is a bit wasteful to localize the whole file. But how much does file localization cost? I can't imagine that it is the lowest hanging fruit. One of the more important issues, which you also mention, is optimizing parameters for inference. This includes not only the minimum number of epochs for training, but also things like the learning rate, annealing schedule, iterations per epoch, conditions for epoch convergence, etc. I'll be talking about how to tune these inference parameters---as well as other things in the pipeline---at the next BSV meeting. Let's brainstorm more things to try and prioritize them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5288#issuecomment-427562932:869,schedul,schedule,869,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5288#issuecomment-427562932,2,['schedul'],['schedule']
Energy Efficiency,I added an integration test that tries the same thing with a bucket (it works fine). Merging as soon as green (do it for me if I miss it).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2643#issuecomment-299040179:104,green,green,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2643#issuecomment-299040179,1,['green'],['green']
Energy Efficiency,"I agree it's more correct and the differences are very small. I remember; having a conversation about putting all the PRs that introduce changes; together or something, so go ahead and merge when it's convenient. On Wed, Feb 20, 2019 at 11:43 AM jamesemery <notifications@github.com>; wrote:. > @ldgauthier <https://github.com/ldgauthier> What is your verdict on this; > change? I think it reduces some of the legacy complexity in the reworked; > ReferenceConfidenceCode even if it has a small impact on the output I would; > estimate its moderately more correct given this change.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5665#issuecomment-465658667>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdG_fpzMzOhs75xfs4Fj2xe4HopRPks5vPXs-gaJpZM4a3x_f>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5665#issuecomment-465692460:390,reduce,reduces,390,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5665#issuecomment-465692460,1,['reduce'],['reduces']
Energy Efficiency,"I agree with all Chris has said, and think that it's very likely that you're running out of memory on the executors. You might try cutting back on --num-executors, and bumping up --executor-memory.; If you can figure out your adapter sequence, you can specify that as --adaptor-sequence, and sometimes that helps with this stage.; We're laying down asphalt, and you're driving on the hot pavement just behind us. Thanks for trying out this tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4635#issuecomment-380144314:226,adapt,adapter,226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4635#issuecomment-380144314,2,['adapt'],"['adapter', 'adaptor-sequence']"
Energy Efficiency,"I can confirm that in my own extensive runs of the tools I've seen it sometimes get hung when out of memory instead of exiting (resulting in bad data for that run). My own benchmarking was with PrintReads on a large file, using various cache buffer sizes. I remember seeing an increase in performance up to about 50MB buffer size and then it flattened out. I would expect a more CPU-intensive (or a more heavily loaded machine) would reduce the impact of the buffer size as I/O ceases to be the bottleneck. I also ran experiments on a 1-cpu machine with VCF and loading a single interval, which I think matches what you are asking about. In that experiment 10MB was enough, adding to the cache did not bring any improvement and of course too large a cache leads to running out of memory.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2640#issuecomment-298972380:434,reduce,reduce,434,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2640#issuecomment-298972380,1,['reduce'],['reduce']
Energy Efficiency,"I can confirm this too. When I reverted https://github.com/broadinstitute/gatk/commit/4c697e06ea33c9179840c81c843658442c82a951 the problem disappeared, so that seems to be the culprit. This is definitely a GCS issue, as I don't see the problem when running with HDFS inputs. More details: for ReadsPipelineSpark, the first job has the following stages when running OK:; * Stage ID 0, mapToPair at MarkDuplicatesSparkUtils.java:56, 147 partitions; * Stage ID 1, flatMapToPair at MarkDuplicatesSparkUtils.java:60, 1880 partitions. And the following when there's only a single partition:; * Stage ID 0, mapToPair at MarkDuplicatesSparkUtils.java:56, 294 partitions; * Stage ID 1, flatMapToPair at MarkDuplicatesSparkUtils.java:60, **_1 partition_**. I wonder if the GCS code called by `BucketUtils.dirSize` has changed somehow, since it's used by `GATKSparkTool.getRecommendedNumReducers()` to get the number of reducers.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3437#issuecomment-322485170:909,reduce,reducers,909,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3437#issuecomment-322485170,1,['reduce'],['reducers']
Energy Efficiency,"I checked, it looks like the cron job scheduling failed on the 2nd or 3rd of November last year. ""Next job scheduled 3 months ago"" being the message. I restarted the cron job and it is apparently working now. This is concerning since if this fails again we may not notice it for months again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6386#issuecomment-575736317:38,schedul,scheduling,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6386#issuecomment-575736317,2,['schedul'],"['scheduled', 'scheduling']"
Energy Efficiency,"I concur, what it looks like we have here is code that switched (accidentally?) from the GCS adapter to GCS-NIO instead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-265014643:93,adapt,adapter,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-265014643,1,['adapt'],['adapter']
Energy Efficiency,I didn't realize we hadn't been updating the changelog /releasing when we added new features anymore. . A few other things that happened recently (not sure if they were before or after last release); - high_CALIBRATION_SENSITIVITY_SNP and high_CALIBRATION_SENSITIVITY_INDEL were moved from the ##FILTER entry in the header to a ##COMMENT. No change to behavior or vcf content outside of header.; - Reduced the number of sharded vcfs coming out of beta workflow for smaller callsets. Documentation on details coming soon.; - Bug fix to correctly handle samples with chromosomes with differing ploidy for DRAGEN 3.7.8 data.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8883#issuecomment-2183251069:398,Reduce,Reduced,398,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8883#issuecomment-2183251069,1,['Reduce'],['Reduced']
Energy Efficiency,I don't have much/any experience with `ReblockGVCF` but did want to note one piece of anecdotal evidence in it's favor -- I tried it on a 1000g gvcf that was 6.1G in size. It took about 55 mins and the resulting gvcf was 1.5G in size. That amount of reduction would certainly help reduce GenomicsDB import/query runtimes and memory requirements.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1213373247:281,reduce,reduce,281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1213373247,1,['reduce'],['reduce']
Energy Efficiency,"I don't know. Do you want me to run them in GATK3?. It's hard to find bams run with GATK3 HC that needed more than 4GB memory because Zamboni has a memory retry loop, so one would have to parse the java options out of the logs like looking for a needle in a haystack. FWIW the Zamboni initial memory allocation is 3GB (https://github.com/broadinstitute/zamboni/blob/develop/Workflows/src/scala/org/broadinstitute/picard/steprunners/variantcalling/HaplotypeCaller.scala) seems to be applicable to exomes and genomes(?) I asked about finding problematic samples in green team slack.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4272#issuecomment-385672647:563,green,green,563,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4272#issuecomment-385672647,1,['green'],['green']
Energy Efficiency,"I don't think that hiding/disable arguments would work in every case: sometimes, an argument shouldn't be exposed but still available to set programmatically, or maybe just reduce visibility making it `@Hidden` and/or `@Advance`. What is the problem of making an interface for the top-level argument to the GATK? Changing the interface or the `CommadnLineProgram` has the same effect, but the API user can still behave the same as before. It is much more extensible and downstream-friendly. What's about making the `CLPConfigurationArgumentCollection` an interface always returning defaults to be able to change it in a proper way? The cycle of development of a new argument will be: 1) add a new method to the interface with a default returning what will be expected from the previous behaviour, 2) add and return by the argument in the GATK implementation, 3) use the getter in the CLP for perform the operation. This only adds the first point, and operating in 3 classes instead of 3. For API user it is really easy to maintain the previous behavior when upgrading the dependency by just using their own implementation of the class, or include the top-level new arguments by using the GATK implementation. It is much more flexible and extensible (I always think about GATK also as a library). In addition, I think that this approach is also important for evolving GATK. For example, if a new top-level argument is tagged as experimental (still not supported but requested in Barclay), removing it would allow to keep the interface (no version bump) the same and final users can still operate with the experimental argument. The same applies to the `GATKTool` base class (https://github.com/broadinstitute/gatk/issues/4341), and for downstream projects the aim should be to be able to extend safely the `CommandLineProgram` directly to implement their own toolkit using the powerful GATK framework.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-366185003:173,reduce,reduce,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-366185003,2,"['power', 'reduce']","['powerful', 'reduce']"
Energy Efficiency,I got another report of something similar in the non-spark HaplotypeCaller; stack trace below. ````; java.lang.IllegalStateException: Duplicate key [B@42515a2f; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculationEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngine.java:253); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngine.java:187); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:520); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:239); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:244); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:217); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:779); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(Com,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018#issuecomment-310805959:375,Reduce,ReduceOps,375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018#issuecomment-310805959,5,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,I guess it would cover it as long as 'unmapped' support means efficient processing of the unmapped pairs (i.e. it would just go thru the whole bam file and ignore the mapped pairs).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2572#issuecomment-292037865:62,efficient,efficient,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2572#issuecomment-292037865,1,['efficient'],['efficient']
Energy Efficiency,"I had a look at the source code of [HypergeometricDistribution](HypergeometricDistribution). If I am right, we are doing the following. We are invoking `logProbability()` for all possible `x[0][0]`. For a table with large numbers, we have to compute logBinomial for many iterations (see line 202–222 in the HypergeometricDistribution source code). Typically logBinomial calls three logGamma and each logGamma calls `log()` twice. This involves lots of computation and is not the fastest way to implement Fisher's exact test. A faster way to implement the test takes the advantage of two observations. 1) When carrying the test, we are calling hypergeo(i,m+n,m,k), hypergeo(i+1,m+n,m,k), ... in order, and we can derive hypergeo(i+1,m+n,m,k) from hypergeo(i,m+n,m,k) by simply multiplying a number. This will be much faster than doing the full hypergeo->logBionomial->logGamma->log computation for each `i`. 2) For a large table, often when `i` is sufficiently smaller or larger than `x[0][0]`, the hypergeo probability is small enough to be ignored from the sum. It is not necessary to calculate hypergeo for the full range of `lo<=i<hi`. This trick can also dramatically reduce the number of iterations for large tables. htslib has a [exact test implementation](https://github.com/samtools/htslib/blob/bf753361dab9b1640cf64f7886dbfe35357a43c5/kfunc.c#L201) that considers the two observations. I understand that the time spent on the `FisherExactTest` class probably won't show up at all in a profiler. I am not requesting to improve the implementation now. Just let you know the tricks. In addition, when we use this class for other purposes, a fast exact test may become a good thing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-266289212:1172,reduce,reduce,1172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-266289212,2,['reduce'],['reduce']
Energy Efficiency,"I have pull requests in flight for both (1) and (2). They are 1469; <https://github.com/GoogleCloudPlatform/google-cloud-java/pull/1469> and; 1470 <https://github.com/GoogleCloudPlatform/google-cloud-java/pull/1470>. Cheers,; JP. On Tue, Dec 6, 2016 at 3:54 AM, Tom White <notifications@github.com> wrote:. > Yes, Hadoop-BAM uses the NIO API to do file merging, whereas in GATK we; > were using the Hadoop APIs (and therefore the GCS<->HDFS adapter) to do it.; >; > It looks like there are a couple of things needed in GCS-NIO to use the; > NIO API for this.; >; > 1. GoogleCloudPlatform/google-cloud-java#1450; > <https://github.com/GoogleCloudPlatform/google-cloud-java/issues/1450>; > so that we don't have to special-case gs URIs to remove everything; > except the scheme and host when looking up the filesystem (see; > https://github.com/HadoopGenomics/Hadoop-BAM/; > blob/master/src/main/java/org/seqdoop/hadoop_bam/util/; > NIOFileUtil.java#L40; > <https://github.com/HadoopGenomics/Hadoop-BAM/blob/master/src/main/java/org/seqdoop/hadoop_bam/util/NIOFileUtil.java#L40>; > ); > 2. GoogleCloudPlatform/google-cloud-java#813; > <https://github.com/GoogleCloudPlatform/google-cloud-java/issues/813>; > to support path matching (https://github.com/HadoopGenomics/Hadoop-BAM/; > blob/master/src/main/java/org/seqdoop/hadoop_bam/util/; > NIOFileUtil.java#L90; > <https://github.com/HadoopGenomics/Hadoop-BAM/blob/master/src/main/java/org/seqdoop/hadoop_bam/util/NIOFileUtil.java#L90>; > ); >; > There may be more, as I stopped there. The best way forward is probably to; > go back to the old code in GATK while the deficiencies in GCS-NIO are fixed; > and then released.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-266151447:441,adapt,adapter,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-266151447,1,['adapt'],['adapter']
Energy Efficiency,"I have this class from an ancient branch that makes dealing with colors nicer in some ways. It tries to avoid printing colors to non-interactive things and it makes it harder to forget a reset:. ```; /**; * Provides ANSI colors for the terminal output *; */; public final class TerminalColors {. private TerminalColors(){};. private enum TerminalColor{; CYAN(""\u001B[36m""),; RED(""\u001B[31m""),; GREEN(""\u001B[32m""),; WHITE(""\u001B[37m""),; BOLD(""\u001B[1m""),; RESET(""\u001B[0m""); // reset the colors. private final String color;. TerminalColor(String color){; this.color = color;; }. public String getColorString(){; return color;; }. }. public static boolean isInteractive(){; return !(System.console() == null);; }. public static String cyan(String toColor){; return colorString(toColor, TerminalColor.CYAN);; }. public static String red(String toColor){; return colorString(toColor, TerminalColor.RED);; }. public static String green(String toColor){; return colorString(toColor, TerminalColor.GREEN);; }. public static String white(String toColor){; return colorString(toColor, TerminalColor.WHITE);; }. public static String bold(String toBold){; return colorString(toBold, TerminalColor.BOLD);; }. public static String colorString(String toColor, TerminalColor color) {; if(isInteractive()) {; return color.getColorString() + toColor + TerminalColor.RESET.getColorString();; } else {; return toColor;; }; }. public static String stripColorsFromString(String colorString){; String stripped = colorString;; for(TerminalColor color : TerminalColor.values()) {; stripped = stripped.replace(color.getColorString(),"""");; }; return stripped;; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4429#issuecomment-367141169:395,GREEN,GREEN,395,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4429#issuecomment-367141169,3,"['GREEN', 'green']","['GREEN', 'green']"
Energy Efficiency,"I haven't understood how multi-allele model exactly works in the old GATK, so can't comment on why it does not perform well. In general, I am supportive of making the new model the default going forward. However:. > when we remove the other models. I would suggest retaining the old model if possible. As I said on the method meeting, the old model takes the full power of population information (by full, I mean under the Wright-Fisher and HWE assumptions, you can't derive a more powerful model in theory). My understanding is that David's current model isn't. This is fine as long as the information from sequence data overwhelms the population information, which is usually true for highCov data. However, when data is thin, the population information will play a more important role. Without thorough evaluations in multiple scenarios, it is not clear when the loss of population information in the new model starts to matter. It would be good to keep the old model as a reference point, at least for biallelic SNPs, until we have more comparison.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2098#issuecomment-242810127:364,power,power,364,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2098#issuecomment-242810127,4,['power'],"['power', 'powerful']"
Energy Efficiency,I imagine that @skwalker's scripts could be adapted for the task -- I'll try to set up a meeting with her next week to discuss.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-381170947:44,adapt,adapted,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-381170947,1,['adapt'],['adapted']
Energy Efficiency,"I just pushed a branch:; https://github.com/broadinstitute/picard/tree/yf_documentation_update we; can use that for initial testing. On Tue, Dec 5, 2017 at 1:56 PM, sooheelee <notifications@github.com> wrote:. > @samuelklee <https://github.com/samuelklee>, thanks for the update and; > suggestion. I moved CollectAllelicCounts to the Coverage Analysis; > category. CollectFragmentCounts isn't on the list currently so I added it; > to the same. I hope I'm not missing a bunch of other new tools given I; > missed this one.; >; > @yfarjoun <https://github.com/yfarjoun>; >; > - You are now in charge of deciding whether we should include; > authorship in code. What the Comms team wants is for authorship to NOT show; > up in the gatkDoc/javaDoc. If you want to keep them, author lines should be; > at the bottom and formatted so they do not show up in the documentation.; > Geraldine is fine with completely removing them if you prefer that. There; > is a format trick that has javaDoc skip the author line and I can get that; > to you if you decide to keep some of these and @vdauwera; > <https://github.com/vdauwera> would know this or I can get you what I; > see in other docs. Let either of us know.; > - I can help you test your changes. I think the categories are good to; > go now so I will need to put these into both Picard and GATK; > HelpConstants.java, with the latter being a placeholder until the new; > Picard release is incorporated into the next GATK release, with variables; > that then must be included in each tool doc. I will find an example in a; > bit. Which tool do you want to test? @cmnbroad; > <https://github.com/cmnbroad> can explain the engineering details in; > engineering lingo if you need more information.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349404645>,; > or mute the thread; > <https://github.com/notifications/unsubscr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349407253:592,charge,charge,592,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349407253,1,['charge'],['charge']
Energy Efficiency,"I like the idea of the modified regexes, that seems like the best balance of usability and flexibility/power. I'd rather avoid having a slew of new special-cased arguments.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/588#issuecomment-309815640:103,power,power,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/588#issuecomment-309815640,1,['power'],['power']
Energy Efficiency,"I reproduced various out of memory errors in a Linux VM with 4G of RAM, both with the `IntelInflaterDeflaterIntegrationTest` enabled and disabled. Most resulted in the kernel killing the Java process, like this one (from `dmesg`):; ```; [38425.759992] Out of memory: Kill process 10295 (java) score 747 or sacrifice child; [38425.759998] Killed process 10295 (java) total-vm:7885212kB, anon-rss:3250892kB, file-rss:0kB; ```. Some were caught by the JVM, like this one:; ```; #; # There is insufficient memory for the Java Runtime Environment to continue.; # Native memory allocation (mmap) failed to map 90177536 bytes for committing reserved memory.; # Possible reasons:; # The system is out of physical RAM or swap space; # In 32 bit mode, the process size limit was hit; # Possible solutions:; # Reduce memory load on the system; # Increase physical memory or swap space; # Check if swap backing store is full; # Use 64 bit Java on a 64 bit OS; # Decrease Java heap size (-Xmx/-Xms); # Decrease number of Java threads; # Decrease Java thread stack sizes (-Xss); # Set larger code cache with -XX:ReservedCodeCacheSize=; # This output file may be truncated or incomplete.; #; # Out of Memory Error (os_linux.cpp:2627), pid=20484, tid=139679452493568; #; # JRE version: Java(TM) SE Runtime Environment (8.0_72-b15) (build 1.8.0_72-b15); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.72-b15 mixed mode linux-amd64 compressed oops); # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; ```. Here's my theory of what's happening. The `maxHeapSize` for test JVMs is set to 4G in `build.gradle`:; ```; maxHeapSize = ""4G""; ```. A 4G max heap size is too high for systems with 4G of RAM, because the Java heap grows until the system runs out of memory. If we decrease `maxHeapSize`, the GC should prevent the Java heap from growing too large, with the trade-off of more GC calls. I changed the `maxHeapSize` to `2G` a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2490#issuecomment-288423316:799,Reduce,Reduce,799,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2490#issuecomment-288423316,1,['Reduce'],['Reduce']
Energy Efficiency,"I think it's best not to co-opt existing formats for storing *variant calls* and *mutations* if we want to store generic annotations. Furthermore, many of the drawbacks of VCF (e.g, wasted space from repeated tags/unused fields) are really not worth dealing with if our data is strictly tabular and well structured. I think if we can settle on a format internally that satisfies all of our needs, then it'd probably a *very small* amount of effort on the part of external developers to write adapters to consume it. After all, we are only talking about metadata (hopefully in a standardized but suitably flexible format, e.g. SAM/VCF-style header) + tabular data. It may also be that there is a format out there that already fits the bill, in which case we just need to do some more research and discussion. I think this would be better than causing confusion and setting a bad example by co-opting unsuitable formats, even if this would require no additional effort for external developers.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-386578762:492,adapt,adapters,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-386578762,1,['adapt'],['adapters']
Energy Efficiency,"I think the code and tests are fine (except for the conflicts). I was just trying to empathize about updating expected GVCFs. I want to talk to the engine team about the release schedule, but we won't merge anything else in the HC->GGVCFs pipeline before this, so the tests won't need updating.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5318#issuecomment-445876386:178,schedul,schedule,178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5318#issuecomment-445876386,1,['schedul'],['schedule']
Energy Efficiency,I think we'll need to generalize the progress meter slightly to allow for different wording in the output message. (and the position column will make no sense for this tool).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2683#issuecomment-300227436:46,meter,meter,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2683#issuecomment-300227436,1,['meter'],['meter']
Energy Efficiency,"I will try that as well. I just finished building a PoN at 250bp bin size with 1k intervals per block. This produces ~10k models and the PostprocessGermlineCNVCalls WDL task gets us the following error from Cromwell:. > The task run request has exceeded the maximum PAPI request size.If you have a task with a very large number of inputs and / or outputs in your workflow you should try; > to reduce it. Depending on your case you could: 1) Zip your input files together and unzip them in the command. 2) Use a file of file names and localize the files yourself. Who knew? So, we are also going to have to modify PostprocessGermlineCNVCalls and the case mode calling task to accept a tar archive containing all the models. @samuelklee @mbabadi Let me know if you have any opinions on this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4397#issuecomment-392119427:393,reduce,reduce,393,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4397#issuecomment-392119427,1,['reduce'],['reduce']
Energy Efficiency,"I wondered how much of the time was due to parsing the VCF file. To test this, I used Kryo to serialize the `IntervalsSkipList` to a binary blob, then tried loading the binary blob directly. This reduced the load time from around 6 minutes to 4.7 minutes - so some speed improvement, but not a lot. See https://github.com/broadinstitute/gatk/tree/tw_known_sites_perf_kryo",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5103#issuecomment-412897602:196,reduce,reduced,196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5103#issuecomment-412897602,1,['reduce'],['reduced']
Energy Efficiency,"I'm also seeing this more often during the Docker build, not sure if it is related:. ````; Step 5/27 : RUN /gatk/gradlew clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:743,Meter,MeteredStream,743,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,2,['Meter'],['MeteredStream']
Energy Efficiency,"I'm going to close this issue because it's not a bug. Several things in the code of Mutect2 and FilterMutectCalls adapt as they traverse the genome and it's possible that some learned parameter shifts minutely. For example, the assembly graph pruning algorithm uses knowledge of previously assembled regions to better distinguish between errors and somatic variation. It's also possible that somewhere we forgot to give something a fixed random seed. In full honesty, I _wish_ that I knew exactly what causes the 3142 to become 3143, and I regret that I don't have time for it. Nonetheless, in principle it is not cause for alarm.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8152#issuecomment-1983783338:114,adapt,adapt,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8152#issuecomment-1983783338,2,['adapt'],['adapt']
Energy Efficiency,"I'm not entirely sure this would work, but if it does then more power to us.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2312#issuecomment-266601534:64,power,power,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2312#issuecomment-266601534,1,['power'],['power']
Energy Efficiency,INFO StructuralVariationDiscoveryPipelineSpark - DUP: 2248; 00:47:25.281 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1492; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 0; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 0; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 0; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 18/04/27 00:47:28 WARN org.apache.spark.scheduler.TaskSetManager: Stage 19 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:47:33 WARN org.apache.spark.scheduler.TaskSetManager: Stage 20 contains a task of very large size (2685 KB). The maximum recommended task size is 100 KB.; 00:47:39.417 INFO StructuralVariationDiscoveryPipelineSpark - Processing 323040 raw alignments from 254678 contigs.; 18/04/27 00:47:39 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 00:47:47.083 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 225280 contigs.; 00:47:48.135 INFO StructuralVariationDiscoveryPipelineSpark - 23702 contigs with chimeric alignments potentially giving SV signals.; 18/04/27 00:47:49 WARN org.apache.spark.scheduler.TaskSetManager: Stage 32 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:47:57 WARN org.apache.spark.scheduler.TaskSetManager: Stage 33 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:48:04 WARN org.apache.spark.scheduler.TaskSetManager: Stage 34 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 00:48:13.094 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 15964 variants.; 00:48:13.107 INFO StructuralVariationDiscoveryPipeline,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199:1509,schedul,scheduler,1509,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199,1,['schedul'],['scheduler']
Energy Efficiency,INFO StructuralVariationDiscoveryPipelineSpark - DUP: 2248; 02:20:10.138 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1492; 02:20:10.147 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 0; 02:20:10.148 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 02:20:10.148 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 0; 02:20:10.148 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 0; 02:20:10.148 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 18/04/27 02:20:12 WARN org.apache.spark.scheduler.TaskSetManager: Stage 19 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:18 WARN org.apache.spark.scheduler.TaskSetManager: Stage 20 contains a task of very large size (2599 KB). The maximum recommended task size is 100 KB.; 02:20:24.460 INFO StructuralVariationDiscoveryPipelineSpark - Processing 323040 raw alignments from 254678 contigs.; 18/04/27 02:20:24 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 02:20:32.040 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 225280 contigs.; 02:20:33.079 INFO StructuralVariationDiscoveryPipelineSpark - 23841 contigs with chimeric alignments potentially giving SV signals.; 18/04/27 02:20:34 WARN org.apache.spark.scheduler.TaskSetManager: Stage 32 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:42 WARN org.apache.spark.scheduler.TaskSetManager: Stage 33 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:49 WARN org.apache.spark.scheduler.TaskSetManager: Stage 34 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 02:20:58.973 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 15659 variants.; 02:20:58.991 INFO StructuralVariationDiscoveryPipeline,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199:5375,schedul,scheduler,5375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199,1,['schedul'],['scheduler']
Energy Efficiency,"If you want to read the entrails from running a monitoring script over the same instance of HC this was your branch:; <img width=""775"" alt=""Screenshot 2023-05-04 at 10 32 46 AM"" src=""https://user-images.githubusercontent.com/16102845/236239563-ae998bab-2948-4ef5-97ad-476f5faba925.png"">. And this was the control (so GATKNightly):; <img width=""767"" alt=""Screenshot 2023-05-04 at 10 33 46 AM"" src=""https://user-images.githubusercontent.com/16102845/236239864-d19c0fbd-44b2-441a-91e6-d5f1ffb0ea84.png"">. Your branch seems to be using more memory off the bat?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1534893120:48,monitor,monitoring,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1534893120,1,['monitor'],['monitoring']
Energy Efficiency,"If you're interested in BWASpark tool I might wait a bit. There are a lot of issues with it as it currently stands, it's one of the least tested tools we have. We have someone working on a different more efficient implementation of the bwa bindings that may eventually be integrated into mainline gatk, so we've sort of stopped most development on BWASparkEngine until we're clear on the direction that the new work is going to take.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-267119998:204,efficient,efficient,204,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-267119998,2,['efficient'],['efficient']
Energy Efficiency,Improve testing and reduce costs. Sounds right to me.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2726#issuecomment-302242076:20,reduce,reduce,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2726#issuecomment-302242076,1,['reduce'],['reduce']
Energy Efficiency,"In GATK4, the way to make a tool multithreaded is to implement it as a Spark tool. All Spark tools can be trivially parallelized across multiple threads using the local runner, and across a cluster using spark-submit or gcloud. . We wanted to avoid the complexities of implementing our own map/reduce framework, as was done in previous versions of the GATK, and instead rely on a standard, third-party framework to keep the GATK4 engine as simple as possible.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2345#issuecomment-273206164:294,reduce,reduce,294,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2345#issuecomment-273206164,2,['reduce'],['reduce']
Energy Efficiency,"In fact, setting the deploy-mode works with manual jobs as we get logs in our Hadoop monitor ( the tool to monitor the jobs on the spark cluster ) and directly on our console if deploy-mode is not set / set to client. Both `--deploy-mode` and `--conf 'spark.submit.deployMode=cluster'`. But with GATK, logs appear directly on my console and not in the Hadoop monitor even if we set with `--conf 'spark.submit.deployMode=cluster`. The other methods `--deploy-mode` and `-- --deploy-mode` having the said problems.; About the `-- --deploy-mode` and the JNI linkage error, I'm currently checking this.; All our Spark nodes have access to the mapr libraries from `/opt/mapr/...`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350676916:85,monitor,monitor,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3933#issuecomment-350676916,3,['monitor'],['monitor']
Energy Efficiency,"In terms of the two tools, I don't think it's necessary at this point to make an inheritance structure. `CallVariantsFromAlignedContigsSAMSpark` is more of a one-off for dealing with de novo assembly files and I'm not sure if it will be supported long term. However, I did extract a `callVariantsFromAlignmentRegions` method in `CallVariantsFromAlignedContigsSpark` that `CallVariantsFromAlignedContigsSAMSpark` can use, which reduces code duplication a lot. There's not much left in `CallVariantsFromAlignedContigsSAMSpark` except for the logic to convert GATKReads into AlignmentRegions, which seems appropriate.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2079#issuecomment-240514475:427,reduce,reduces,427,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2079#issuecomment-240514475,1,['reduce'],['reduces']
Energy Efficiency,"InbreedingCoeff.java](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9JbmJyZWVkaW5nQ29lZmYuamF2YQ==) | `82.759% <100%> (ø)` | `11 <1> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/utils/GenotypeCounts.java](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vdHlwZUNvdW50cy5qYXZh) | `100% <100%> (ø)` | `4 <1> (ø)` | :arrow_down: |; | [.../hellbender/tools/walkers/annotator/ExcessHet.java](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9FeGNlc3NIZXQuamF2YQ==) | `98.592% <100%> (ø)` | `22 <2> (ø)` | :arrow_down: |; | [...broadinstitute/hellbender/utils/GenotypeUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vdHlwZVV0aWxzLmphdmE=) | `94.872% <100%> (+2.767%)` | `12 <0> (+3)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=footer). Last update [c8ede6e...c63c08b](https://codecov.io/gh/broadinstitute/gatk/pull/2546?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2546#issuecomment-290509295:2672,Power,Powered,2672,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2546#issuecomment-290509295,1,['Power'],['Powered']
Energy Efficiency,"Interestingly, just adding the constant to gcloud allows gatk to proceed. Well it crashed for me a bit later:. [Stage 0:==========================================> (431 + 2) / 553]17/03/30 00:30:53 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 431.0 in stage 0.0 (TID 431, jp-test-cluster-w-0.c.genomics-pipelines.internal): com.google.cloud.storage.StorageException: 503 Service Unavailable; Service Unavailable; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:186); ...; 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.readAttributes(CloudStorageFileSystemProvider.java:571); 	at java.nio.file.Files.readAttributes(Files.java:1737); 	at java.nio.file.Files.isRegularFile(Files.java:2229); 	at htsjdk.samtools.SamFiles.lookForIndex(SamFiles.java:72). That's the same 503 we've been protecting against in reads, now rearing its head on a readAttributes call.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2517#issuecomment-290465707:220,schedul,scheduler,220,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2517#issuecomment-290465707,1,['schedul'],['scheduler']
Energy Efficiency,"It bothers me a bit that we're doing a shuffle (reduceByKey operation in FBES line 880) on the big int arrays of coverage counts. Would've been so much nicer to process each partition all the way to high-coverage intervals independently, but I understand why it's done this way: to handle counts that cross partition boundaries. Since it's a pretty quick step, and since I can't think of a straightforward way to handle partition boundary crossing any better than this, I'm giving it the thumbs up. I add a few niggles to particular lines and then add another general comment with the approval indication.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4438#issuecomment-368637030:48,reduce,reduceByKey,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4438#issuecomment-368637030,1,['reduce'],['reduceByKey']
Energy Efficiency,It reduces the size of *just* the header lines in the interval list from 581689 bytes to 3976. So 0.0068 smaller.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8829#issuecomment-2107437363:3,reduce,reduces,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8829#issuecomment-2107437363,1,['reduce'],['reduces']
Energy Efficiency,"It seems that there are a lot of soft clips that aren't bacterial reads.; What's your mean insert size? I've seen lots of aberrant soft clips when; the insert size is small and Picard doesn't catch adapter sequences with; multiple mismatches. Does the Picard percent adapter in alignment summary; metrics seem high? I've also seen lots of soft clips when the chimera rate; is high, sometimes because of bad sample extraction. What's the percent; chimeras in your alignment summary metrics? 5% is bad and I've seen up to; 15%, but that was an FFPE tumor sample. On Mon, Mar 25, 2019 at 8:48 PM jjfarrell <notifications@github.com> wrote:. > When the --dontUseSoftCliiped flag is used, the GQ=0 is much lower- N=1355; > for '0/0' calls.; >; > zcat; > A-ADC-AD004288-BL-NCR-15AD82285.hg38.realign.bqsr.dontUseSoftclipped.g.vcf.gz; > |tr '\t' '\n'|grep '0/0'|tr ':' '\t'|cut -f2,3|awk '$2 == ""0"" {print; > $0}'|cut -f1|sort -n|uniq -c; > 1355 0; > 6 0,0,0; > 7 0,0,0,0; > 602 1; > 537 2; > 520 3; > 595 4; > 441 5; > 511 6; > 583 7; > 701 8; > 403 9; > 468 10; >; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5445#issuecomment-476431178>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdA_gZKYn3vuqNDvvDadvM9tgzQqGks5vaW5IgaJpZM4YxgEF>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5445#issuecomment-476654990:198,adapt,adapter,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5445#issuecomment-476654990,2,['adapt'],['adapter']
Energy Efficiency,It would be good for progress meter to be more flexible.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-575773895:30,meter,meter,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-575773895,1,['meter'],['meter']
Energy Efficiency,"It's green, pressing ""squash and merge.""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3801#issuecomment-345372779:5,green,green,5,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3801#issuecomment-345372779,1,['green'],['green']
Energy Efficiency,"It's looking like we might have to fix the issues with NIO here after all @tomwhite @jean-philippe-martin, as @lbergelson has been unable to get this working reasonably with the GCS adapter (it runs, but veeeerrryyy slowly).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-271691417:182,adapt,adapter,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-271691417,1,['adapt'],['adapter']
Energy Efficiency,"It's not unlikely that there is something about these sites to make them not confidently reference. For example, if no reads span a repetitive reference context then the algorithm cannot be confident that there is not indel at that location. Evidence like soft clips can also reduce confidence in the reference. Have you looked at the bamout in this region?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6309#issuecomment-564166347:276,reduce,reduce,276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6309#issuecomment-564166347,1,['reduce'],['reduce']
Energy Efficiency,It's up now. Looks like it might have been down for a month! I'll set up an alert on it (we are not actively monitoring non-Prod machines).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3862#issuecomment-346133246:109,monitor,monitoring,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3862#issuecomment-346133246,1,['monitor'],['monitoring']
Energy Efficiency,"Java implementation of segmentation is now in the sl_wgs_segmentation dev branch, with a few simple unit tests. I'll expand on these and add tests for denoising in the future, but for now we have a working revised pipeline up through segmentation. The CLI is simply named ModelSegments (since my thinking is that it could eventually replace ACNV). I ran it on some old denoised exomes. Runtime is <10s, comparable to CBS. Here's a particularly noisy exome:. CBS found 1398 segments:; ![cbs](https://user-images.githubusercontent.com/11076296/30165095-cdf6251a-93ac-11e7-91fb-dcc8f48fe07f.png). Kernel segmentation with a penalty given by a = 1, b = 0 found 1018 segments:; ![kern](https://user-images.githubusercontent.com/11076296/30165106-dbbe0b40-93ac-11e7-99ec-5d58d8417d8b.png). Kernel segmentation with a penalty given by a = b = 1 (which is probably a reasonable default penalty, at least based on asymptotic theoretical arguments) reduced this to 270 segments :; ![kern-smooth](https://user-images.githubusercontent.com/11076296/30165113-e2b545a8-93ac-11e7-97a9-a692e43ebbdf.png). The number of segments can similarly be controlled in WGS. WGS runtime is ~7min for 250bp bins, ~30s of which is TSV reading, and there is one more spot in my implementation that could stand a bit of optimization, which might bring the runtime down. In contrast, I kicked off CBS 45 minutes ago, and it's still running... @LeeTL1220 this is probably ready to hand off to you for some WDL writing and preliminary evaluation. ; Although I can't guarantee that there aren't bugs, I ran about ~80 exomes with no problem. We can talk later today.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-327797936:939,reduce,reduced,939,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-327797936,2,['reduce'],['reduced']
Energy Efficiency,"Looking back into this PR... at some point you are using 'N' to pad what seem to be gaps on the read sequence. Although the end result would be the same perhaps is better to be more explicit and just use '-' instead. In that case my suggestion of using `Nucleotide.intersect` wouldn't cover for the '-' character so you need a explicity ""&&"" or ""II"". When you compare the cost of each different alignment the gap-open and gap-ext are ignored (you only look at base call mismatches). I wonder whether it would be more correct to actually take them in consideration... so imagine that there is no gaps in the original alignment what-soever and that adding a 1bp gap decreases the number of mis-matches by just 1 which is typically Q30 increase in the Lk but the gap itself default penalty is Q45 so can one say that that read wouldn't still support the reference over a 1-bp gap alternative? . Example with a 2-bp gap making the trick:; ```; Ref: ....GCATGTGATATATATATATATATATATATACACACAC....; Read: ....GCATGTG--ATATATATATATATATATATAC <end-of-the-read>; ```. That could happen in STRs with impurities... but if the original alignment did not added itself the gap to reduce the number of mismatches is because precisely due to the added cost of the gap-open and necessary extends that we would be ignoring here. This is all hypothetical until some one quantifies how often this might occur ... so I'm happy to keep ignoring the gaps for now until we get a report on a real-live dataset that would benefit of such a change or some enthusiastic dsde-methods member investigates this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5172#issuecomment-420743269:1165,reduce,reduce,1165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5172#issuecomment-420743269,1,['reduce'],['reduce']
Energy Efficiency,Looks like checks have passed but we need a green light from @droazen.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3891#issuecomment-355050118:44,green,green,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3891#issuecomment-355050118,1,['green'],['green']
Energy Efficiency,Looks like tests are green with the latest commit. Now we just need a test that would have caught https://github.com/broadinstitute/gatk/issues/6179,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1051136204:21,green,green,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1051136204,1,['green'],['green']
Energy Efficiency,MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:123); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); 	at org.apa,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:10621,schedul,scheduler,10621,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['schedul'],['scheduler']
Energy Efficiency,"Marissa Powers here -- I'm an Intel engineer on the same team as Ed. It sounds like we all agree on having Intel-optimized TF as the default and figuring out the best intervention for older machines from there. We can add the AVX flag within CNNScoreVariant (and any other AI tool). From there, we can (1) provide a detailed error output describing the issue, (2) provide a non-AVX TF build, and (3) automatically roll back TF to the provided version. @EdwardDixon, it sounds like @cmnbroad is suggesting is options (1), (2), and (3), while you're suggesting just (1). Sound right?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-429409667:8,Power,Powers,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-429409667,1,['Power'],['Powers']
Energy Efficiency,"Multiple causes can cause closed connections when reading from GCS, almost all of which are outside of our control. This will never be ""completely fixed"" in the sense that even if the code is perfect it's completely possible to send too many requests to GCS, and it'll respond by closing connections. The main factors that I know of are:. - number of concurrent accesses to the GCS bucket in question; - number of concurrent accesses to the GCP project in question; - storage class of the GCS bucket in question (the more expensive ones have more replicas, thus can handle a higher load). If you're running into those difficulties I would suggest trying to reduce the load (reduce the number of concurrent workers or threads) and making sure it's not a single-region storage bucket. If that fails, perhaps try using a different bucket that no one else is also using (to reduce other sources of load). If I understand correctly that you didn't change the version you're using but are suddenly seeing more issues than before, then perhaps the cause is a server-side change from GCS (outside of our control), a change in configuration (are you reading from a bucket of a different class from before), or perhaps just an increase of other activity on the same bucket/project. The current code is very persistent in its retries: as you can see from the messages it spent a whole half hour waiting. If it's an overload situation then you may get better performance by reducing the worker count (as they will have to retry less).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716:657,reduce,reduce,657,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716,3,['reduce'],['reduce']
Energy Efficiency,"My $0.02:. 1. In general it's ok with me to not provide a template for WDLs in the GATK repo as long as you guys help us (ie @bshifaw) produce appropriate templates to include in the gatk-workflows repo and in FireCloud. . 2. Re: Picard tools, going forward they should be invoked from the GATK jar by default. Among other benefits, that will reduce support entropy wrt possible combination of versions of tools people might be using. 3. I like the idea of focusing on the auto-generated wrappers for improvements like the string variable for adding arbitrary extra args.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358488159:343,reduce,reduce,343,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358488159,1,['reduce'],['reduce']
Energy Efficiency,"Next I set out to determine whether hellbender is slowing down on the larger interval simply because there is more data / a longer traversal, or because it's slower at processing the `1:1-10000000` interval than the `1:10000000-20000000` interval. And surprisingly, it appears that the latter is the case:. Time to process the `1:1-10000000` interval across two runs:. ```; GATK3: 5m25.983s 5m31.913s; HB: 6m2.156s 5m59.804s; ```. (Recall that HB was ~5% faster than GATK3 at processing the `1:10000000-20000000` interval). Moreover, our newly-installed progress meter shows that the rate at which we process records is unusually low at the start of the `1:1-10000000` interval, but is consistent throughout the processing of the `1:10000000-20000000` interval:. HB processing rate over 1:1-10000000:. ```; 14:22:19.520 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 14:22:29.522 INFO ProgressMeter - 1:769026 0.2 133000 797920.2; 14:22:39.531 INFO ProgressMeter - 1:1066133 0.3 298000 893553.2; 14:22:49.544 INFO ProgressMeter - 1:1389358 0.5 471000 941247.0; 14:22:59.572 INFO ProgressMeter - 1:1695902 0.7 636000 952785.2; 14:23:09.601 INFO ProgressMeter - 1:1961884 0.8 808000 968031.8; 14:23:19.636 INFO ProgressMeter - 1:2264803 1.0 985000 983099.3; 14:23:29.637 INFO ProgressMeter - 1:2583326 1.2 1162000 994352.2; 14:23:39.694 INFO ProgressMeter - 1:2817177 1.3 1297000 970638.9; 14:23:49.705 INFO ProgressMeter - 1:3095124 1.5 1467000 975993.8; 14:23:59.726 INFO ProgressMeter - 1:3372416 1.7 1637000 980190.6; 14:24:09.734 INFO ProgressMeter - 1:3678706 1.8 1810000 985355.8; 14:24:19.777 INFO ProgressMeter - 1:4087198 2.0 1984000 989880.0; 14:24:29.813 INFO ProgressMeter - 1:4341518 2.2 2165000 996983.7; 14:24:39.822 INFO ProgressMeter - 1:4598153 2.3 2350000 1004975.0; 14:24:49.834 INFO ProgressMeter - 1:4859664 2.5 2530000 1009892.7; 14:24:59.838 INFO ProgressMeter - 1:5103960 2.7 2712000 1014982.7; 14:25:09.887 INFO ProgressMeter - 1:5341742 ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1032#issuecomment-150660236:563,meter,meter,563,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1032#issuecomment-150660236,1,['meter'],['meter']
Energy Efficiency,"No problems. The walkers have no built in parallelism so there's no problem with using state. It makes it harder to adapt to spark, but that's probably not a big deal.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4447#issuecomment-368091726:116,adapt,adapt,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4447#issuecomment-368091726,1,['adapt'],['adapt']
Energy Efficiency,No validation here. I was satisfied with the validation from the Palantir report and using this as a robustness test to show that GATK4 HC isn't going to fall over. I have a matched list of GVCFs here: /humgen/gsa-hpprojects/dev/gauthier/scratch/newQualHC/check.list @skwalker could you adapt your analysis to run with this list? I'll need to give you a different jar for the GenotypeGVCFs step on my GVCFs since the annotation format is outdated.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-380822981:287,adapt,adapt,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-380822981,1,['adapt'],['adapt']
Energy Efficiency,"Nope.; I was indeed running in local mode (on a GCE VM) a Spark tool that I just wrote over the weekend.; I was able to do it via `--conf` in the end. So it seems that I misunderstood the Readme.; In order to provided these arguments, I also need to specify a non-local `--spark--runner`?. Below is how I was able to make more efficient use of the memory the VM has:. ```; gatk \; --java-options ""-Xms350G -Xmx390G"" \; ShardPacBioSubReadsUBamByZMWClusterSpark \; -I ~{input_ubam} \; --read-index ~{input_ubam}.sbi \; -O split_dir/~{split_prefix} \; -- \; --conf spark.master=""local[*]"" \; --conf spark.driver.memory=340g \; --conf spark.memory.fraction=0.85 \; --conf spark.memory.storageFraction=0.25; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6515#issuecomment-604021640:327,efficient,efficient,327,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6515#issuecomment-604021640,1,['efficient'],['efficient']
Energy Efficiency,"Not sure they are related but I noted a couple of other mysteries. . . I am running the Docker version of GATK on a high end windows workstation and have allocated about 30GB to Docker. . Mystery 1: I get a warning on some commands that it is unable to determine whether it is running on google. Related to the Funcotator issue perhaps if it can’t determine where it is running it crashes out?. . Mystery 2: CollectAllelicCounts crashes with a java memory error. The -Xmx5g is several multiples of the recommendation. . gatk --java-options ""-Xmx5g"" CollectAllelicCounts -L mydata/refs/hg19_intervals.interval_list -I mydata/P50513/Tumor_P50513_2.bam -R mydata/refs/Homo_sapiens_assembly19.fasta -O mydata/P50513/P50513_Tumor.allelicCounts.tsv . . 20:31:39.543 INFO ProgressMeter - 1:169308662 59.1 85227000 1443218.8. 20:32:01.576 INFO ProgressMeter - 1:169321662 59.4 85240000 1434518.9. 20:32:22.203 INFO ProgressMeter - 1:169334662 59.8 85253000 1426484.3. 20:32:43.007 INFO ProgressMeter - 1:169341665 60.1 85260000 1418372.5. 20:33:04.435 INFO ProgressMeter - 1:169350665 60.5 85269000 1410144.2. 20:33:29.473 INFO CollectAllelicCounts - Shutting down engine. [October 5, 2019 8:33:29 PM UTC] org.broadinstitute.hellbender.tools.copynumber.CollectAllelicCounts done. Elapsed time: 60.94 minutes. Runtime.totalMemory()=5,285,347,328. . . Exception in thread ""main"" java.lang.OutOfMemoryError: GC overhead limit exceeded. . . at java.util.Collections.unmodifiableList(Collections.java:1287). at htsjdk.samtools.Cigar.getCigarElements(Cigar.java:54). at org.broadinstitute.hellbender.utils.read.SAMRecordToGATKReadAdapter.getCigarElements(SAMRecordToGATKReadAdapter.java:336). at org.broadinstitute.hellbender.engine.filters.ReadFilterLibrary$ReadLengthEqualsCigarLengthReadFilter.test(ReadFilterLibrary.java:217). at org.broadinstitute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70). at org.broadinstitute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFil",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548929777:154,allocate,allocated,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548929777,1,['allocate'],['allocated']
Energy Efficiency,"Note to self: the gcloud API changes a bit with the new release, apply the changes in [jp_gcloud_17_snapshot](https://github.com/broadinstitute/gatk/tree/jp_gcloud_17_snapshot) to adapt.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2822#issuecomment-306241927:180,adapt,adapt,180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2822#issuecomment-306241927,1,['adapt'],['adapt']
Energy Efficiency,"OK, tests are finally passing. I think we are close to where a review is useful; however, i have three known questions:. 1) Do you have advise on dealing with raw -> generic lists/maps in StratificationManager and VariantEvalReportWriter? You'll see I put a placeholder cast() method in each that copies the collection as a placeholder. I didnt see a more elegant option. 2) From way back in this thread, there was discussion of making a proper DefaultPluginDescriptor. Currently I have a functional DefaultPluginDescriptor in the varianteval package, but this isnt fully fleshed out for general use. Would you be OK finishing this PR with that in place, after which I would be willing to do a separate PR to make that general purpose, or does this need to be done before this?. 3) What do you think about the total size of test files being added? One way to reduce some file sizes is to subset to only the sites relevant to the variant eval tests. In the case of more generic reference files this reduces size, but also lessens their potential utility for future tests that may share them. . Also, the stub from the GATK3 VariantEval3IntegrationTest is still there should you want to run it. It should pass every GATK3 test using GATK3 inputs, though it might take a little work to put all the GATK3 files in the same location (i received them as one data dump in one directory).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-431583201:859,reduce,reduce,859,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-431583201,2,['reduce'],"['reduce', 'reduces']"
Energy Efficiency,"OK. As a reference, how does GATK deal with max-alternate-alleles for normal human variant calling? Presumably really high alternate alleles would primarily happen in repetitive/index prone-regions? FWIW, When we execute GenotypeGVCFs, we run as ~1000 jobs where each takes an even chunk of the genome, by base pairs. . Yes, I did see the bypass-feature-reader option, but we have jobs in-flight and I'm reluctant to change too many things as once. We will try this when possible though. As far as number of batches imported: I would need to check, but I believe it's only ~5 batches with perhaps 50-100 samples/ea. So I guess it's not that many new batches in the scheme of things, but anecdotally we have noticed that with the last couple rounds of import we needed to reduce batch size to make it work (i.e. not get hung). It is conceivable there is some other factor that is causing that variable performance.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7542#issuecomment-964442581:771,reduce,reduce,771,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7542#issuecomment-964442581,1,['reduce'],['reduce']
Energy Efficiency,"Offhand I don't have any rule of thumb for memory usage, unfortunately. One thing that can help to reduce memory pressure is to use the `--batch-size` parameter. Also, this doesn't help you now, but we're looking to enable a feature to reduce the memory usage by 5x or more. Works for local/posix files right now, but we need a little tinkering to make it work with Google cloud files. Regarding logging for GenomicsDBImport - that is expected. A lot of the heavy lifting is done by the native layer, so we need to do a bit more work to push updates back to the progress meter. It's on our to-do list....",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-656278175:99,reduce,reduce,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-656278175,3,"['meter', 'reduce']","['meter', 'reduce']"
Energy Efficiency,"Okay, I think I've got most of it. Still want to move the monitoring script somewhere better.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8268#issuecomment-1505923062:58,monitor,monitoring,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8268#issuecomment-1505923062,1,['monitor'],['monitoring']
Energy Efficiency,"On another note, if we really have hundreds of readers in parallel it's possible they're being throttled by GCS and that may be why we're seeing opens fail. GCS is counting on us backing off to reduce its load.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300320552:194,reduce,reduce,194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300320552,1,['reduce'],['reduce']
Energy Efficiency,"One more question related to this. In playing around I've noticed that if I run HC in GVCF mode with `-A AS_StrandOddsRatio` it will output a table like this into the gVCF: `AS_SB_TABLE=0,0|34,24|21,33|0,0`. But when I run GenotypeGVCFs this gets reduced to `AS_SOR=1.085`, and the original `AS_SB_TABLE` annotation is removed. Is there any way to get `GenotypeGVCFs` to carry the table forward into the genotypes VCF?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5698#issuecomment-466563992:247,reduce,reduced,247,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5698#issuecomment-466563992,1,['reduce'],['reduced']
Energy Efficiency,"One observation that illustrates the need for care when optimizing metrics: for a few of the F1 optimizations, the haplotype-to-reference match-value parameter gets driven to its minimal value (1). Not 100% sure, but I'm guessing this might effectively boost precision by somehow cutting down on the complexity of proposed haplotypes---it depends on what the exact behavior of our SW algorithm is for negative scores. @davidbenjamin any thoughts on this behavior?. Something I don't quite understand yet is if we can impose some effective constraints on the parameters or otherwise reduce the number of independent dimensions. For example, it seems reasonable to me to fix the gap-extend penalties to -1 and let all other parameters be defined w.r.t. them. But perhaps we can also fix the match values similarly?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712268193:582,reduce,reduce,582,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712268193,1,['reduce'],['reduce']
Energy Efficiency,"Oooh, that read that's soft-clipped at both ends is super suspicious. How; many bases are ""match"" in the CIGAR? We've seen cases where contaminating; reads from bacteria (and the occasional food-derived species) have a chance; 19bp (or maybe 21bp?) match to the human reference, which is the default; minimum BWA seed size. Can you try rerunning HC with the; OverclippedReadFilter? (see; https://software.broadinstitute.org/gatk/documentation/tooldocs/current/org_broadinstitute_hellbender_engine_filters_OverclippedReadFilter.php; and https://software.broadinstitute.org/gatk/documentation/article?id=11007); It might also be more efficient if you're able to share a small snippet of; the bam just showing this region. On Sat, Mar 16, 2019 at 6:59 PM jjfarrell <notifications@github.com> wrote:. > Here is the IGV view near SNPs rs429358+rs7412; >; > [image: image]; > <https://user-images.githubusercontent.com/1960717/54482671-91454c00-481d-11e9-866f-59d1644f9fe5.png>; >; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5445#issuecomment-473599597>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdFVk4r82ciOUN3UsMca7z1-rzbNsks5vXXdVgaJpZM4YxgEF>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5445#issuecomment-476230026:632,efficient,efficient,632,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5445#issuecomment-476230026,1,['efficient'],['efficient']
Energy Efficiency,"PAkIVtQwZhlgUAHu1BgjBugFRiqg3eaPMOeOuIZBvzwoyotHIVp3XvAfivGyCW4Ke7+2cqlcX1L8kcmoWLm2fdLGlLr/lZnAjQtexMC76uLtR8udqWA0e2sqrSJs4H/blOQmHWPrl/VSG7daoVptzqXihRmXN+/Huo7mTxAjTUEjk4IOBn7sv7G5qLrEPv78AJIZhWHdhUTGLvx+YpzQvX8pE53TMi9W4ovkZTCwhSO3WYyBOY7H1xjeYb9XWTeP563Du1b0JMpQgtFLQUVXio9NzXZE55ovvGDRSLds+VfPsv4G/Whhq76dEZ+wZO3\n\nEOF\n""; },; ""cpuPlatform"":""Intel Haswell"",; ""description"":""Travis CI python test VM"",; ""disks"":[{""deviceName"":""persistent-disk-0"",""index"":0,""mode"":""READ_WRITE"",""type"":""PERSISTENT""}],; ""hostname"":""testing-gce-ec8614d2-40a2-4138-801e-d42d811590a2.c.travis-ci-prod-2.internal"",; ""id"":8221730359445041428,; ""image"":"""",; ""licenses"":[{""id"":""1000010""}],; ""machineType"":""projects/685190392835/machineTypes/n1-standard-2"",; ""maintenanceEvent"":""NONE"",; ""networkInterfaces"":[{""accessConfigs"":[{""externalIp"":""104.198.203.242"",""type"":""ONE_TO_ONE_NAT""}],""forwardedIps"":[],""ip"":""10.128.0.163"",""network"":""projects/685190392835/networks/default""}],; ""scheduling"":{""automaticRestart"":""TRUE"",""onHostMaintenance"":""MIGRATE"",""preemptible"":""FALSE""},; ""serviceAccounts"":{; ""685190392835-compute@developer.gserviceaccount.com"":{; ""aliases"":[""default""],; ""email"":""685190392835-compute@developer.gserviceaccount.com"",; ""scopes"":[""https://www.googleapis.com/auth/userinfo.email"",; ""https://www.googleapis.com/auth/devstorage.full_control"",; ""https://www.googleapis.com/auth/compute""]; },; ""default"":{; ""aliases"":[""default""],; ""email"":""685190392835-compute@developer.gserviceaccount.com"",; ""scopes"":[""https://www.googleapis.com/auth/userinfo.email"",; ""https://www.googleapis.com/auth/devstorage.full_control"",; ""https://www.googleapis.com/auth/compute""]}; },; ""tags"":[""testing""],; ""virtualClock"":{""driftToken"":""11704388862566216373""},; ""zone"":""projects/685190392835/zones/us-central1-b""; },. ""project"":{; ""attributes"":{; ""sshKeys"":""henrik:ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQChY0pdGXohYN7KRnQa3VIcDoVBrxZVHkhOFc1SROV2T+gTOunYbOW5C4V1P2MGG6FcKeoQTJzXgPbZurM5l1AfEbKeCde778QyyxbcjpYvKyY5b4qVO79nOKAg1qHIqUl",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6042#issuecomment-513242018:1794,schedul,scheduling,1794,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6042#issuecomment-513242018,1,['schedul'],['scheduling']
Energy Efficiency,"Rationale for engine changes:; This tool opens a large number of feature files (TSVs, not VariantContexts) and iterates over them simultaneously. No querying, just a single pass through each.; Issue 1: When a feature file lives in the cloud, it takes unacceptably long (several seconds, typically) to initialize it. A few seconds doesn't seem like a long time, but when there are large numbers of feature files to open, it adds up. This is caused by a large number of codecs (mostly the vcf-processing codecs) opening and reading the first few bytes of the file in the canDecode method. To avoid this I've reversed the order in which we test each codec, checking first if it produces the correct subtype of Feature, and only then calling canDecode. If you don't know what specific subtype you need, you can just ask for any Feature by passing Feature.class. It's much faster that way.; Issue 2: Each open feature source soaks up a huge amount of memory. That's because text-based feature reading is optimized for VCFs, which can have enormously long lines. So huge buffers are allocated. The problem is compounded for cloud-based feature files for which we allocate a large cloud prefetch buffer. (Though that feature can be turned off, which helps a little.) But the biggest memory hog is the TabixReader, which always reads in the index, regardless of whether it's used or not. Tabix indices are very large. To avoid this, I've created a smaller, simpler FeatureReader subclass called a TextFeatureReader that loads the index only when necessary. The revisions allow the new tool to run using an order of magnitude less memory. Faster, too.; Issue 3: The code in FeatureDataSource that creates a FeatureReader is brittle, and tests for various subclasses. To allow use of the new TextFeatureReader, I added a FeatureReaderFactory interface that allows one to ask the codec for an appropriate FeatureReader.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8031#issuecomment-1284340770:1077,allocate,allocated,1077,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8031#issuecomment-1284340770,4,['allocate'],"['allocate', 'allocated']"
Energy Efficiency,Resolved conflicts. Once tests are green I'll squash & merge (or you can do it if I forget).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2565#issuecomment-301139969:35,green,green,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2565#issuecomment-301139969,1,['green'],['green']
Energy Efficiency,"Reviving this. This will essentially be a major refactor/rewrite of CreatePanelOfNormals to make it scalable enough to handle WGS. - [x] CombineReadCounts is too cumbersome for large matrices. Change CreatePanelOfNormals to take in multiple -I instead.; - [x] Rename NormalizeSomaticReadCounts to DenoiseReadCounts and require integer read counts as input. These will still be backed by a ReadCountCollection until @asmirnov239's changes are in.; - [x] Remove optional outputs (factor-normalized and beta-hats) from DenoiseReadCounts. For now, TN and PTN output will remain in the same format (log2) to maintain compatibility with downstream tools.; - [x] Maximum number of eigensamples K to retain in the PoN is specified; the smaller of this or the number of samples remaining after filtering is used. The number actually used to denoise can be specified in DenoiseReadCounts. If we are going to spend energy computing K eigensamples, there is no reason we shouldn't expose all of them in the PoN, even if we don't want to use all of them for denoising. (Also, the current SVD utility methods do not allow for specification of K < N when performing SVD on an MxN matrix, even though the backend implementations that are called do allow for this; this is terrible. In any case, randomized SVD should be much faster than the currently available implementations, even when K = N).; - [x] Rename CreatePanelOfNormals to CreateReadCountPanelOfNormals; - [x] Refer to ""targets"" as intervals. See #3246.; - [x] Remove QC.; - [x] Refer to proportional coverage as fractional coverage.; - [x] Perform optional GC-bias correction internally if annotated intervals are passed as input.; - [x] Make standardization process for panel and case samples identical. Currently, a sample mean is taken at one point in the PoN standardization process, while a sample median is taken in the case standardization process.; - [x] HDF5 PoN will store version number, all integer read counts, all/panel intervals, all/panel ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-313921687:904,energy,energy,904,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-313921687,1,['energy'],['energy']
Energy Efficiency,"Rlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...6737d16d1f0749554cafe9f8cf869fac1fcede0c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...6737d16d1f0749554cafe9f8cf869fac1fcede0c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `77.6% <0%> (-9.6%)` | `28% <0%> (-8%)` | |; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...6737d16d1f0749554cafe9f8cf869fac1fcede0c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `70.946% <0%> (-6.757%)` | `18% <0%> (-4%)` | |; | ... and [4 more](https://codecov.io/gh/broadinstitute/gatk/pull/2433?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2433?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2433?src=pr&el=footer). Last update [92cb860...6737d16](https://codecov.io/gh/broadinstitute/gatk/compare/92cb86051b59acb6b18115135a5b5db99b617d22...6737d16d1f0749554cafe9f8cf869fac1fcede0c?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2433#issuecomment-283613034:5043,Power,Powered,5043,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2433#issuecomment-283613034,1,['Power'],['Powered']
Energy Efficiency,"Rlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...f539662b2a136507a34ea2da64e0445d6df3469d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...f539662b2a136507a34ea2da64e0445d6df3469d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `77.6% <0%> (-9.6%)` | `28% <0%> (-8%)` | |; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...f539662b2a136507a34ea2da64e0445d6df3469d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `70.946% <0%> (-6.757%)` | `18% <0%> (-4%)` | |; | ... and [4 more](https://codecov.io/gh/broadinstitute/gatk/pull/2455?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2455?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2455?src=pr&el=footer). Last update [dfa9cf1...f539662](https://codecov.io/gh/broadinstitute/gatk/compare/dfa9cf1a420490285b7be7917082222a07e2b042...f539662b2a136507a34ea2da64e0445d6df3469d?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2455#issuecomment-285859315:5008,Power,Powered,5008,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2455#issuecomment-285859315,1,['Power'],['Powered']
Energy Efficiency,"RpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvRXhhY3RBRkNhbGN1bGF0b3IuamF2YQ==) | `89.474% <0%> (-0.526%)` | `8% <0%> (+5%)` | |; | [...stitute/hellbender/utils/collections/CountSet.java](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb2xsZWN0aW9ucy9Db3VudFNldC5qYXZh) | `31.21% <0%> (-0.403%)` | `22% <0%> (ø)` | |; | [.../hellbender/tools/walkers/annotator/ExcessHet.java](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9FeGNlc3NIZXQuamF2YQ==) | `98.198% <0%> (-0.393%)` | `25% <0%> (+3%)` | |; | [...gine/spark/AddContextDataToReadSparkOptimized.java](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvQWRkQ29udGV4dERhdGFUb1JlYWRTcGFya09wdGltaXplZC5qYXZh) | `0% <0%> (ø)` | `0% <0%> (ø)` | :arrow_down: |; | [...ellbender/tools/spark/sv/GATKSVVCFHeaderLines.java](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9HQVRLU1ZWQ0ZIZWFkZXJMaW5lcy5qYXZh) | `0% <0%> (ø)` | `0% <0%> (ø)` | :arrow_down: |; | ... and [92 more](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=footer). Last update [e7c90f1...08af964](https://codecov.io/gh/broadinstitute/gatk/pull/2447?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2447#issuecomment-285197333:4277,Power,Powered,4277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2447#issuecomment-285197333,1,['Power'],['Powered']
Energy Efficiency,"RpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmtFbmdpbmUuamF2YQ==) | `82.857% <59.091%> (-6.234%)` | `6 <3> (+1)` | |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmsuamF2YQ==) | `66.667% <60%> (ø)` | `5 <1> (+1)` | :arrow_up: |; | [...e/hellbender/engine/filters/ReadFilterLibrary.java](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9SZWFkRmlsdGVyTGlicmFyeS5qYXZh) | `94.048% <66.667%> (ø)` | `1 <0> (ø)` | :arrow_down: |; | [...der/tools/walkers/annotator/RMSMappingQuality.java](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9STVNNYXBwaW5nUXVhbGl0eS5qYXZh) | `98.413% <0%> (-1.587%)` | `34% <0%> (+20%)` | |; | [...ls/walkers/genotyper/afcalc/ExactAFCalculator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvRXhhY3RBRkNhbGN1bGF0b3IuamF2YQ==) | `89.474% <0%> (-0.526%)` | `9% <0%> (+6%)` | |; | ... and [18 more](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=footer). Last update [88c181d...6a33314](https://codecov.io/gh/broadinstitute/gatk/pull/2494?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2494#issuecomment-287889612:4265,Power,Powered,4265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2494#issuecomment-287889612,1,['Power'],['Powered']
Energy Efficiency,"S9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvRXhhY3RBRkNhbGN1bGF0b3IuamF2YQ==) | `89.474% <0%> (-0.526%)` | `8% <0%> (+5%)` | |; | [...stitute/hellbender/utils/collections/CountSet.java](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb2xsZWN0aW9ucy9Db3VudFNldC5qYXZh) | `31.21% <0%> (-0.403%)` | `22% <0%> (ø)` | |; | [.../hellbender/tools/walkers/annotator/ExcessHet.java](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9FeGNlc3NIZXQuamF2YQ==) | `98.198% <0%> (-0.393%)` | `25% <0%> (+3%)` | |; | [...roadinstitute/hellbender/utils/GenotypeCounts.java](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vdHlwZUNvdW50cy5qYXZh) | `100% <0%> (ø)` | `7% <0%> (+3%)` | :arrow_up: |; | [...ols/walkers/genotyper/MinimalGenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9NaW5pbWFsR2Vub3R5cGluZ0VuZ2luZS5qYXZh) | `27.273% <0%> (ø)` | `4% <0%> (+1%)` | :arrow_up: |; | ... and [58 more](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=footer). Last update [724fbd0...a163be6](https://codecov.io/gh/broadinstitute/gatk/pull/2506?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2506#issuecomment-288240771:4262,Power,Powered,4262,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2506#issuecomment-288240771,1,['Power'],['Powered']
Energy Efficiency,"S9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQmFzZVF1YWxpdHlDbGlwUmVhZFRyYW5zZm9ybWVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-14%)` | |; | [...llbender/tools/walkers/annotator/TandemRepeat.java](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...6b3c7a9b6d6dfb45fc64613bccf1a74e85a374fe?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9UYW5kZW1SZXBlYXQuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-5%)` | |; | [...oadinstitute/hellbender/tools/spark/sv/SvType.java](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...6b3c7a9b6d6dfb45fc64613bccf1a74e85a374fe?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdlR5cGUuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-5%)` | |; | [...tute/hellbender/metrics/SAMRecordAndReference.java](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...6b3c7a9b6d6dfb45fc64613bccf1a74e85a374fe?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9tZXRyaWNzL1NBTVJlY29yZEFuZFJlZmVyZW5jZS5qYXZh) | `0% <0%> (-100%)` | `0% <0%> (-3%)` | |; | ... and [430 more](https://codecov.io/gh/broadinstitute/gatk/pull/2510?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2510?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2510?src=pr&el=footer). Last update [724fbd0...6b3c7a9](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...6b3c7a9b6d6dfb45fc64613bccf1a74e85a374fe?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2510#issuecomment-288256519:5062,Power,Powered,5062,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2510#issuecomment-288256519,1,['Power'],['Powered']
Energy Efficiency,"S9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyLmphdmE=) | `17% <0%> (-52.5%)` | `9% <0%> (-30%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5291/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5291/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `58.53% <0%> (-23.18%)` | `33% <0%> (-9%)` | |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/5291/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `77.08% <0%> (-3.13%)` | `31% <0%> (ø)` | |; | [...adinstitute/hellbender/engine/ReadsDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/5291/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZHNEYXRhU291cmNlLmphdmE=) | `89.39% <0%> (-3.04%)` | `61% <0%> (-2%)` | |; | ... and [25 more](https://codecov.io/gh/broadinstitute/gatk/pull/5291/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5291?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5291?src=pr&el=footer). Last update [626c887...a1e13fc](https://codecov.io/gh/broadinstitute/gatk/pull/5291?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-437412464:4553,Power,Powered,4553,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-437412464,1,['Power'],['Powered']
Energy Efficiency,"ST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/0e5c32ab-65e6-451f-a04e-6a3f5e7fe5c8/call-NISTSampleHeadToHead/BenchmarkComparison/ed0dc9e1-2d64-47e4-82e0-811971957020/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/0e5c32ab-65e6-451f-a04e-6a3f5e7fe5c8/call-NISTSampleHeadToHead/BenchmarkComparison/ed0dc9e1-2d64-47e4-82e0-811971957020/call-BenchmarkVCFControlSample/Benchmark/8c516721-e955-41d1-907e-fcee92f592d3/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""100.56416111111112"",; ""NIST evalHCsystemhours"": ""0.19999166666666665"",; ""NIST evalHCwallclockhours"": ""74.00048055555555"",; ""NIST evalHCwallclockmax"": ""4.007605555555555"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/0e5c32ab-65e6-451f-a04e-6a3f5e7fe5c8/call-NISTSampleHeadToHead/BenchmarkComparison/ed0dc9e1-2d64-47e4-82e0-811971957020/call-EVALRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/0e5c32ab-65e6-451f-a04e-6a3f5e7fe5c8/call-NISTSampleHeadToHead/BenchmarkComparison/ed0dc9e1-2d64-47e4-82e0-811971957020/call-BenchmarkVCFTestSample/Benchmark/427c5010-a177-42d8-81be-5a387beed653/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/0e5c32ab-65e6-451f-a04e-6a3f5e7fe5c8/call-CreateHTMLReport/cacheCopy/report.html""; },; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535104202:21396,monitor,monitoring,21396,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535104202,1,['monitor'],['monitoring']
Energy Efficiency,Scheduling that might be tricky on my end -- I'm working from home until next week then heading out to Europe & South Africa until the end of the month. I'll be onsite tomorrow morning (giving the MPG primer at 8:30) but I won't stick around very long. If you're available then we can definitely chat; otherwise I might recommend you get the conversation going with redteam and I'll provide air support over slack/email where I can.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3657#issuecomment-334187438:0,Schedul,Scheduling,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3657#issuecomment-334187438,1,['Schedul'],['Scheduling']
Energy Efficiency,"ServletContextHandler@50f4b83d{/jobs/job/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@5d66ae3a{/jobs/job,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@30159886{/jobs/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@33de7f3d{/jobs,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO ui.SparkUI: Stopped Spark web UI at http://10.48.225.55:4041; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 18/03/07 20:32:55 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 18/03/07 20:32:55 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Stopped; 18/03/07 20:32:55 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/03/07 20:32:55 INFO memory.MemoryStore: MemoryStore cleared; 18/03/07 20:32:55 INFO storage.BlockManager: BlockManager stopped; 18/03/07 20:32:55 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/03/07 20:32:55 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/03/07 20:32:55 INFO spark.SparkContext: Successfully stopped SparkContext; 20:32:55.769 INFO FlagStatSpark - Shutting down engine; [March 7, 2018 8:32:55 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.FlagStatSpark done. Elapsed time: 1.60 minutes.; Runtime.totalMemory()=2091384832; 18/03/07 20:32:55 INFO util.ShutdownHookManager: Shutdown hook called; 18/03/07 20:32:55 INFO util.ShutdownHookManager: Deleting directory /tmp/farrell/spark-9e0f0525-00f3-4b37-b1d2-4cf55b4c8cb0. real 1m41.113s; user 0m49.698s; sys 0m4.432s. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:13436,schedul,scheduler,13436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,2,['schedul'],['scheduler']
Energy Efficiency,"Some offline discussions have led us to the conclusion that this is best handled by tools upstream. Adapters should not be simply soft-clipped, so it shouldn't be the responsibility of M2 or HC to include logic to remove adapters.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6346#issuecomment-575334816:100,Adapt,Adapters,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6346#issuecomment-575334816,3,"['Adapt', 'adapt']","['Adapters', 'adapters']"
Energy Efficiency,"Some tweaking of those aforementioned rules (to make them much more conservative about using the trios to infer condition positive---namely, by requiring >30% of each column be green, i.e., non-reference Mendelian consistent) brings the F1 and LL into much better agreement:. ![image](https://user-images.githubusercontent.com/11076296/158510257-bab23346-3793-4497-8f2c-7c1cc3c3f62b.png); ![image](https://user-images.githubusercontent.com/11076296/158510274-f0cb2944-d276-4bc8-89c5-43740e3a91fb.png). ![image](https://user-images.githubusercontent.com/11076296/158510329-d6098321-821b-4690-8995-40246e9a07e2.png); ![image](https://user-images.githubusercontent.com/11076296/158510351-be86b5d3-8b39-40b7-ac84-c2619778c500.png)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1068691791:177,green,green,177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1068691791,1,['green'],['green']
Energy Efficiency,Sources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:1020); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:847); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:831); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:508); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:509); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngin,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-783746069:2571,Reduce,ReduceOps,2571,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-783746069,1,['Reduce'],['ReduceOps']
Energy Efficiency,Successful VQSR Lite Run (with monitoring summary output) [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/176b6f4d-4295-4627-ae20-ac465e3686d1); Successful VQSR Classic Run (with monitoring summary output) [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/203da881-d37d-47c4-abaa-f4795b252c0d),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8268#issuecomment-1496489050:31,monitor,monitoring,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8268#issuecomment-1496489050,2,['monitor'],['monitoring']
Energy Efficiency,"Thank you @lbergelson for your answer. The memory I'm using is specified by nextflow, but I could also force it to Java. . My machine got 64 go of memory and 24 cores. 2go by cores is ok but more could be problematic. Maybe I will try on a more powerful one and I will tell you how is it going. Does the Spark strategy really needs more memory ? I've seen memory usage peaks around 60 go before crash with the spark tool and around 25go with the ""classic"" version (which complete the run without any issue). Thank you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4515#issuecomment-373298078:245,power,powerful,245,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515#issuecomment-373298078,1,['power'],['powerful']
Energy Efficiency,"Thank you for taking a look into this. I followed recommendation of @gbrandt6 and reduced the --pruning-lod-threshold but this call is still unable to make it to the output of Mutect2. I tried different thresholds from 1.3, 0.7, 0.5 and even 0.1 but it did not lead to any difference in detecting this call.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7232#issuecomment-829649061:82,reduce,reduced,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7232#issuecomment-829649061,1,['reduce'],['reduced']
Energy Efficiency,"Thank you very much @droazen! This should take care of all the comments, so once the checks are green I'll press ""squash and merge."" Then I'll move on to the next tool to update!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4424#issuecomment-381676296:96,green,green,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4424#issuecomment-381676296,1,['green'],['green']
Energy Efficiency,"Thanks @drifty914, it sounds like you may need to limit the number of concurrent jobs that Cromwell is allowed to scatter. We typically run gCNV in the cloud and scatter across multiple VMs, so we haven't encountered this issue before. At the same time, you could also try to reduce the total number of shards (by increasing num_intervals_per_scatter), which should be fine if each shard has enough memory. We typically scatter 200 samples x 5000 intervals, which fits comfortably in VMs with 30GB of memory. We haven't gotten a chance to profile how much of this memory is being used in detail, so you might be able to get by with much less. I don't think this is a matter of a memory leak or files being left open by the tool, as it looks like your job fails during the theano compilation step. I'll try to get an idea of how many files theano opens for each compilation, but I don't think this is something we have much control over. We have thought about whether it might be possible to reuse the same compiled theano model for identically sized shards, but haven't gotten a chance to investigate this yet either.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-468502707:276,reduce,reduce,276,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-468502707,1,['reduce'],['reduce']
Energy Efficiency,Thanks Ted. I will ask @lbergelson then since he is in charge of Spark tools.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3878#issuecomment-347305479:55,charge,charge,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3878#issuecomment-347305479,1,['charge'],['charge']
Energy Efficiency,"Thanks for comments about the documentation @LeeTL1220 - I fixed them (I hope) trying to explain the logic behind the element tracker. In principle a developer shouldn't care about when to use them, because they should come from a `LocusIteratorByState` or from inside a previous tracker. In addition, the implementation should be (most of the cases) hidden from the API user, which should use `ReadPileup`. The idea of the trackers come from GATK3, so this is a custom port with some design differences. The basic idea is to cache some operations that may be time consuming for large pileups (sorting, split by sample, extract a single sample). I actually haven't test the performance in a proper way, just running some tools in development with the branch and it feels like is faster - in my case I use all the features that are cache: split by sample, retrieving several times single-samples and also calling `fixOverlaps()` (which uses using sorted pileups). I think that because the `LocusIteratorByState` is already splitting by sample, that can improve even more performance, because it will come directly in the state where it can be used by-sample in an efficient way. And maybe, if the tool does not require to split by sample at all, we can add an option to disable that behavior while creating the tracker. Looking forward for your comments and ideas about this...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2321#issuecomment-332144484:1163,efficient,efficient,1163,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2321#issuecomment-332144484,1,['efficient'],['efficient']
Energy Efficiency,"Thanks for looking into this @davidbenjamin. I followed the best practices using bwa mem, mark duplicates etc., to create these input bams for HaplotypeCaller. This is Novaseq 2 x 150 data, I ran Fastqc on the reads and everything looks really good, the only thing I can find that might explain the soft-clipping is that there's some Nextera adapter read through on a small percentage of the reads. I haven't been using -Y with bwa (I see it's used in GATK 4 wdls), so it seems like there should be less soft-clipping than normal. I'll admit these are definitely messy regions we're dealing with, but we really need to make the F5 calls for our clinical pipeline. I just tried --dont-use-soft-clipped-bases and I wasn't able to pick the SNP up in the 55-55003_F5_region.bam, but using forceActive/dontTrimActiveRegions does work on this call.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-402690747:342,adapt,adapter,342,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-402690747,1,['adapt'],['adapter']
Energy Efficiency,"Thanks for making and documenting those plots, @asmirnov239! Does seem worthwhile to sample more if it makes no difference in the runtime. Just curious, what was the shard size?. Slightly counterintuitive that the high end is more noisy, but I guess it must be due to sampling noise of low bias---I'd expect more competition from reduced noise due to higher counts. Mind sharing the num_samples = 20 and 200 dCR files for at least one sample so I can take a quick look?. Might also be nice to see the posterior standard deviations, but if it's too much work to compile those it's fine. Perhaps we should just concatenate them anyway (I don't recall why we didn't originally add this in #5823, but maybe we had a reason). In any case, the noise doesn't look crazy in the CR regime that would've been important for the CNV genotyping stuff---phew!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5754#issuecomment-944207573:330,reduce,reduced,330,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5754#issuecomment-944207573,1,['reduce'],['reduced']
Energy Efficiency,"Thanks for taking care of this. Be sure to take a look at the HDF5RandomizedSVDReadCountPanelOfNormals.IntervalHelper class in my sl_create_pon branch. I changed the way intervals are written to HDF5 to be faster and more space efficient by using a double matrix. Still a little hacky IMO, but since we can't write integer matrices it'll do for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-317523846:228,efficient,efficient,228,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-317523846,1,['efficient'],['efficient']
Energy Efficiency,"Thanks for the explanation. It isn't clear to me that the SAMRecord API was ever intended to support ; headerless records (except maybe in very rare corner cases). I don't really know the scope of hellbender. If it is just for internal ; DSDE tools development, then I guess it doesn't matter.; If you ever want to leverage code/libraries from elsewhere, then those ; would have to be ""headerless-aware"", I guess. For example, a common operation in Genome STRiP is to ask for the sample ; associated with a read. This requires the header, I would think.; Anyway, my main point was just to stimulate thinking about the value of ; implementing an efficient way to transmit the headers.; It also seems to me that this generalizes to efficient patterns to ; transmit any widely shared data (that is referenced by many serialized ; individual data items) out-of-band. -Bob. On 9/21/15 11:42 AM, droazen wrote:. > @bhandsaker https://github.com/bhandsaker Thanks for chiming in with ; > your thoughts/concerns.; > ; > Under this proposal, the various classes in htsjdk that read and ; > return |SAMRecords| (eg., |SAMReader| & co.) would continue to put the ; > header inside of the records, so we would not be imposing an ; > additional burden on direct clients of htsjdk to check for null ; > headers any more than they do currently. The only difference is that ; > if downstream consumers of |SAMRecords| (like hellbender) choose to ; > strip the header from the records, there would be an explicit contract ; > governing the behavior of headerless |SAMRecords| (as opposed to the ; > status quo, in which the header may be null but behavior is totally ; > undocumented and in some cases inconsistent -- eg., the reference name ; > and index in a headerless |SAMRecord| can get out-of-sync in some cases).; > ; > In additional to documenting/clarifying the behavior of headerless ; > |SAMRecords| and fixing any consistency-related bugs we find when ; > operating without a header, we would also make an ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-142402910:645,efficient,efficient,645,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-142402910,2,['efficient'],['efficient']
Energy Efficiency,Thanks for the information about this @meganshand. I will use this class in my use case and if it is not efficient enough I will try another solution.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-267344402:105,efficient,efficient,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-267344402,1,['efficient'],['efficient']
Energy Efficiency,"Thanks for your question, @xysj1989. You are right that it can be advantageous to use SNP data for CNV calling. In my experience, however, it is not of high importance in practice. Indeed we do use BAF in our structural variation pipeline, but only for the purpose identifying high-quality calls. We typically find that BAF support tends to be weak/noisy for all but the largest CNVs, so requiring SNP evidence would greatly reduce sensitivity. @samuelklee can probably shed some more light on this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6407#issuecomment-581659408:425,reduce,reduce,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6407#issuecomment-581659408,1,['reduce'],['reduce']
Energy Efficiency,"Thanks very much for your analysis. Job 4 does create a lot of garbage, but that appears to be inevitable whenever you are dealing with a PairRDD: You have to use a Tuple2 to represent key and value rather than using a more memory-conservative custom data object. You end up with a gazillion tiny objects that survive only during the shuffle. Too bad they didn't base PairRDD on an interface like Map.Entry. Also too bad that you cannot force a shuffle on a (plain old, non-Pair) RDD. Why not just treat it as a key-only structure and allow repartitioning? I mention this not merely to whine, but also in the faint hope that you've developed some helpful workarounds. I don't think we have enough memory to persist the reads, but we can revisit that later. Job 5 *is* doing a lot of computation. It's turning each read into kmers and testing each of those kmers to see if they exist in a large hash table. I don't think there's much opportunity for further optimization -- I knew this would be a bottleneck and tried my best to make the code efficient. The skew in task size is definitely a problem, and I'll be looking for opportunities to address that issue. Thanks again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2458#issuecomment-292230002:1042,efficient,efficient,1042,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2458#issuecomment-292230002,1,['efficient'],['efficient']
Energy Efficiency,"Thanks, @gokalpcelik ! I tested the workaround and indeed when used with a gvcf file rather than GenomicsDB the memory consumption remains reasonable. I only tried GATK 4.6 but it is probably the same with the other versions that have the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8989#issuecomment-2434583196:119,consumption,consumption,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8989#issuecomment-2434583196,1,['consumption'],['consumption']
Energy Efficiency,"That example data from the tutorial is good @sooheelee, but maybe it could be reduced in size to avoid adding it to the large file directory? It will be nice to include that example in the `RealignerTargetCreator` PR (#3112)...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-319627989:78,reduce,reduced,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-319627989,1,['reduce'],['reduced']
Energy Efficiency,"The AS_MQ never suffered from this issue because it uses AD for (allele-specific) depth instead of the INFO DP. The sum of the squared MQs there was allocated based on informative reads and the AD represents informative reads, so the data there was always in lock-step.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4969#issuecomment-415069583:149,allocate,allocated,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4969#issuecomment-415069583,1,['allocate'],['allocated']
Energy Efficiency,The FireCloud Job is here https://portal.firecloud.org/#workspaces/broad-firecloud-dsde/dsde-methods-sv-dev/monitor/ecdb3b72-7b4b-4612-9c87-1c0124f62708,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5217#issuecomment-424367893:108,monitor,monitor,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5217#issuecomment-424367893,1,['monitor'],['monitor']
Energy Efficiency,The SV discovery pipeline threw a bunch of errors seemingly related to this:; https://issues.apache.org/jira/browse/SPARK-21133. A sample error from my log:; 17/07/17 14:33:17 ERROR org.apache.spark.util.Utils: Exception encountered; java.lang.NullPointerException; 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply$mcV$sp(MapStatus.scala:171); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus.writeExternal(MapStatus.scala:167); 	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459); 	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178); 	at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1378); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174); 	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply$mcV$sp(MapOutputTracker.scala:617); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); 	at org.apache.spark.MapOutputTracker$.serializeMapStatuses(MapOutputTracker.scala:619); 	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:562); 	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:351); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.conc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491:287,schedul,scheduler,287,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491,4,['schedul'],['scheduler']
Energy Efficiency,"The problem is that the catch block in `CommandLineProgram` is calling both `commandLineParser.usage()` and `printDecoratedUserExceptionMessage()` -- it should only be calling `commandLineParser.usage()`, and letting the catch block in `Main.mainEntry()` call `printDecoratedUserExceptionMessage()`. Otherwise there are cases where a `CommandLineException` will be caught without printing any error message. This is a bug and should be fixed. The distinction between ""errors that are the user's fault"" and ""errors that are not the user's fault"" is very important for our support team -- it allows them to deal with bug reports and forum questions much more efficiently. Whatever solution we come up with here should maintain that distinction, and clearly label errors like ""bad argument value"" as being a user error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268712938:657,efficient,efficiently,657,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268712938,2,['efficient'],['efficiently']
Energy Efficiency,The progress meter is correct. There just happened to be 5 million empty no calls at the start of the file which processed very fast.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6631#issuecomment-647782238:13,meter,meter,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6631#issuecomment-647782238,1,['meter'],['meter']
Energy Efficiency,The proposal for a more officially support scatter/gather seems in theory OK to me. I was not proposing GATK make a scheduler and was agreeing that is problematic/difficult for you to realistically do that. I would tend to strongly favor keeping those more separate,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-641540201:116,schedul,scheduler,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-641540201,1,['schedul'],['scheduler']
Energy Efficiency,"The two main resources limiting how many gVCFs you can import at once will be memory and file handles. . I'm not sure if you mean incremental import or batch size when you mention the iterative approach. I assume the latter, but just want to clarify that there isn't any reason to break up the import using incremental import. The batch size parameter effectively does that, so you might as well import all gVCFs you have available (optionally using batch size if you're running out of memory). I'll throw out batch sizes of 50 or 100 as being reasonable, but the size of the intervals being imported will make a difference. It would be best to try to monitor how much memory is being used with those settings. There won't be a huge difference in import performance depending on the number of batches (ignoring memory issues) but if you have more than a 100 or so batches and you don't enable the `--consolidate` option you may see some query performance degradation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-656376952:652,monitor,monitor,652,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6688#issuecomment-656376952,1,['monitor'],['monitor']
Energy Efficiency,The vulnerabilities reduced a bit but most serious once continue to be there. Dependency upkeep is really needed to iron this out these.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1544539592:20,reduce,reduced,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1544539592,1,['reduce'],['reduced']
Energy Efficiency,"There appears to be something about this branch that is causing the tests to take ~2x longer than usual (~2 hours instead of ~1). Before merging this, we should make sure that the tests are not only green, but also back to the normal runtime for the test suite.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-462427965:199,green,green,199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-462427965,1,['green'],['green']
Energy Efficiency,"There are no error messages.; The process was interrupted without any error messages.; I attached the screenshot.; I attached chr14 variant calling (completed) and chr14 variant calling; (interrupted).; In the system monitor, when I am using GATK 4.6.0.0., they are eating up; memory continuously.; When they are reaching up to 512Gb, the process was interrupted.; I tried to run this process on only 2-3 chromosomes, and I found that the; process was completed on chr 14, and the process was interrupted on the; rest of two chromosomes (interval -L).; So I rolled back to GATK 4.5.0.0, the process was normal. I can do; GenotypeGVCFs command entire chromosome simultaneously. My machine has 512Gb memory and 64 cores (5995wx AMD threadripper) dell; 7865 workstation.; Thanks; Jinu Han. On Fri, Jul 19, 2024 at 12:08 AM Gökalp Çelik ***@***.***>; wrote:. > Can you provide your logs that shows the error message?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2236819113>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AG7IXWWGPB73BXPN4Z5E4VTZM7LAFAVCNFSM6AAAAABLBRETECVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEMZWHAYTSMJRGM>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2238806751:217,monitor,monitor,217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2238806751,1,['monitor'],['monitor']
Energy Efficiency,"These things always happen just before a 3-day weekend :) Since we're about out of time for this week, we'll have to follow up on this on Tuesday when the Broad re-opens. Hopefully the new dylib fixes the travis failures -- if not, perhaps it would be a good idea to schedule a troubleshooting session after our regular weekly meeting. Have a good weekend @kdatta @kgururaj @cmnbroad !",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294237177:267,schedul,schedule,267,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294237177,1,['schedul'],['schedule']
Energy Efficiency,This also happens when there are more reducers than reads such that at least one reducer writes an empty split bam.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2219#issuecomment-318399649:38,reduce,reducers,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2219#issuecomment-318399649,2,['reduce'],"['reducer', 'reducers']"
Energy Efficiency,"This is a hot topic recently, so I already have a doc to compare and contrast: https://docs.google.com/document/d/1qws0owSEc0XGcZGAcxmBOEk8fiWS1Dnv4tvHNgC_xVU/edit?usp=sharing. Gnarly is still a ""beta"" tool. I wanted to add some way to reduce the number of alternate alleles, but that may be easier to do after this recent GenomicsDB update.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7725#issuecomment-1069164647:236,reduce,reduce,236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7725#issuecomment-1069164647,1,['reduce'],['reduce']
Energy Efficiency,"This is causing an issue in our project with green team, due to ExAC. I will design a fix. @jonn-smith",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4792#issuecomment-400756954:45,green,green,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4792#issuecomment-400756954,1,['green'],['green']
Energy Efficiency,"This likely has to do with your spark configuration. Check on the Spark job's progress through the web interface, which should be something like http://<driver_address>:4040 (see https://spark.apache.org/docs/latest/monitoring.html). . If your BAM is very small, you can also try increasing the number of partitions by reducing --bamPartitionSize.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312316932:216,monitor,monitoring,216,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312316932,1,['monitor'],['monitoring']
Energy Efficiency,"This was an oversight on our part that we'll fix. You should also note, however, that we have a branch coming soon that will *significantly* reduce the size of the main GATK docker image (by several GB).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4610#issuecomment-377297997:141,reduce,reduce,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4610#issuecomment-377297997,1,['reduce'],['reduce']
Energy Efficiency,"To be honest, I don't have a clear idea of why this is happening. I tried running a query with 1000 samples using the same GenomicsDB jar that GATK uses and the memory consumption stayed below 1 GB. Some suggestions/questions:; * If you were importing/querying multiple intervals at once, I would expect #4994 to be relevant. But your script shows a single interval being imported/queried.; * Would it be possible to run the SelectVariants tool using the GenomicsDB workspace as input and see how much memory is being consumed (instead of GenotypeGVCFs)? The Select tool simply extracts the data from GenomicsDB and prints out a VCF.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5024#issuecomment-406750537:168,consumption,consumption,168,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5024#issuecomment-406750537,2,['consumption'],['consumption']
Energy Efficiency,"Travis is green, this is ready for review!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4695#issuecomment-383997874:10,green,green,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4695#issuecomment-383997874,1,['green'],['green']
Energy Efficiency,Travis tests failed -- rerunning. This one can be merged once it turns green.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6751#issuecomment-705685609:71,green,green,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6751#issuecomment-705685609,1,['green'],['green']
Energy Efficiency,"Turns out that the failure rate with this patch was greatly reduced, but there were still a few failures. We're trying a run now where we tell the tool to import one file at a time (as opposed to a batch of 25 or 100), and we'll see how that goes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307506558:60,reduce,reduced,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307506558,1,['reduce'],['reduced']
Energy Efficiency,Updated:; Successful VQSR Lite Run (with monitoring summary output) [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/ccdc0ec5-3737-407f-ac84-ca2309167a2b); Successful VQSR Classic Run (with monitoring summary output) [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/001671aa-21db-437a-8d92-42bced766ca6),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8268#issuecomment-1502284208:41,monitor,monitoring,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8268#issuecomment-1502284208,2,['monitor'],['monitoring']
Energy Efficiency,"VsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-18.75%)` | `6% <0%> (ø)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...71c03a3e81f2df635e709823e1c1de96a2f5ffb5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...71c03a3e81f2df635e709823e1c1de96a2f5ffb5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...71c03a3e81f2df635e709823e1c1de96a2f5ffb5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `77.6% <0%> (-9.6%)` | `28% <0%> (-8%)` | |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/2467?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2467?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2467?src=pr&el=footer). Last update [e1e71d7...71c03a3](https://codecov.io/gh/broadinstitute/gatk/compare/e1e71d7091ee703e547842d025e92ac698407ff0...71c03a3e81f2df635e709823e1c1de96a2f5ffb5?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2467#issuecomment-287565894:4983,Power,Powered,4983,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2467#issuecomment-287565894,1,['Power'],['Powered']
Energy Efficiency,"W9uVGVzdC5qYXZh) | `1.66% <0%> (-98.34%)` | `1% <0%> (-5%)` | |; | [...on/FindBreakpointEvidenceSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `1.75% <0%> (-98.25%)` | `1% <0%> (-6%)` | |; | [...bender/tools/spark/PileupSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QaWxldXBTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `2.04% <0%> (-97.96%)` | `2% <0%> (-13%)` | |; | [...tute/hellbender/tools/FlagStatIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9GbGFnU3RhdEludGVncmF0aW9uVGVzdC5qYXZh) | `2.08% <0%> (-97.92%)` | `1% <0%> (-5%)` | |; | [...rs/variantutils/SelectVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9TZWxlY3RWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `0.25% <0%> (-97.75%)` | `1% <0%> (-70%)` | |; | ... and [154 more](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5760?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5760?src=pr&el=footer). Last update [1d6f5b3...d98f9dc](https://codecov.io/gh/broadinstitute/gatk/pull/5760?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5760#issuecomment-469855399:4752,Power,Powered,4752,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5760#issuecomment-469855399,1,['Power'],['Powered']
Energy Efficiency,"WRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9FdmlkZW5jZVRhcmdldExpbmsuamF2YQ==) | `70.51% <0%> (-4.12%)` | `18% <0%> (+2%)` | |; | [...ools/copynumber/CreateReadCountPanelOfNormals.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NyZWF0ZVJlYWRDb3VudFBhbmVsT2ZOb3JtYWxzLmphdmE=) | `86.07% <0%> (-3.93%)` | `11% <0%> (+2%)` | |; | [...er/tools/copynumber/formats/records/CopyRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvcmVjb3Jkcy9Db3B5UmF0aW8uamF2YQ==) | `74.35% <0%> (-1.65%)` | `17% <0%> (+8%)` | |; | [...ellbender/tools/walkers/annotator/QualByDepth.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9RdWFsQnlEZXB0aC5qYXZh) | `95.74% <0%> (-1.56%)` | `20% <0%> (+3%)` | |; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluLmphdmE=) | `70.62% <0%> (-1.32%)` | `71% <0%> (+26%)` | |; | ... and [170 more](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4498?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4498?src=pr&el=footer). Last update [9eb1704...ff52e6b](https://codecov.io/gh/broadinstitute/gatk/pull/4498?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4498#issuecomment-370663327:4552,Power,Powered,4552,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4498#issuecomment-370663327,1,['Power'],['Powered']
Energy Efficiency,"WRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <ø> (-62.264%)` | `8% <ø> (+8%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...b1802b27996e3b0ee8a1b4a035a8ac78282b8666?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <ø> (-60.87%)` | `2% <ø> (+2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...b1802b27996e3b0ee8a1b4a035a8ac78282b8666?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `44.444% <ø> (-29.861%)` | `28% <ø> (+28%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...b1802b27996e3b0ee8a1b4a035a8ac78282b8666?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <ø> (-23.729%)` | `0% <ø> (ø)` | |; | ... and [15 more](https://codecov.io/gh/broadinstitute/gatk/pull/2385/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2385?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2385?src=pr&el=footer). Last update [14f73e2...b1802b2](https://codecov.io/gh/broadinstitute/gatk/compare/14f73e217970a1c53092dee88c409f8a6cdb6e87...b1802b27996e3b0ee8a1b4a035a8ac78282b8666?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2385#issuecomment-279409892:5036,Power,Powered,5036,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2385#issuecomment-279409892,1,['Power'],['Powered']
Energy Efficiency,"We feel that users potentially getting unexpected bills for requester-pays usage would be even more user-unfriendly than having to explicitly opt-in to such charges via a command line argument. If you're running GATK via a WDL, it seems like the billing project could be a single unified input parameter in the accompanying JSON which then gets passed to all individual tasks, which doesn't seem too cumbersome.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6669#issuecomment-647679332:157,charge,charges,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6669#issuecomment-647679332,1,['charge'],['charges']
Energy Efficiency,We have asked the green team to run their pipeline tests on this branch to at least limit the risk of more full sample failures. It will probably be a few more days before we have those results. @gbggrant,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6533#issuecomment-614126868:18,green,green,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6533#issuecomment-614126868,1,['green'],['green']
Energy Efficiency,"We recommend backing up data just because it is the ""cleanest"" way to roll back. If backing up data is really such a pain point, you could skip doing that. Just back up the callset.json file, and don't turn on `--consolidate` when you're doing incremental import. If a failure happens, just roll back the callset.json and re-do the import. The downside is that the failed import will hang around and take up disk space, but hopefully it is a rare enough occurrence that it doesn't matter - and you will have saved yourself backing up the data. In response to 2) - I guess you're implying that the overhead of cluster/job scheduling won't amortize any benefits from parallelism there? I suppose that could be true, but doesn't seem to be worth optimizing towards that. What I'm asking is whether split and merge are purely an instrument to allow you to choose the granularity of parallelism you want to use? Or is there something else? As I said before, we are considering enabling other ways to do distributed import which would work for the former. It might go something like:; - Create a workspace/initialize configuration+intervals to be imported; - Actually do the import by kicking off (multiple) import(s). User can pick the number of intervals each import is responsible for. User must ensure that no interval gets specified in multiple import processes. P.S: regarding 1000s of small contigs - the current GenomicsDBImport doesn't so so well with large number of contigs (unless you do concatenate the contigs into fewer groups). We hope to have some changes coming soon that will help with that by adding an option for the tool to merge multiple contigs into a single folder in the workspace.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-641037548:621,schedul,scheduling,621,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-641037548,1,['schedul'],['scheduling']
Energy Efficiency,"What do you mean by more automated? It looks like you're allocating space based on the input file sizes and some padding, which is already more automated than the user adjusting disk size by hand. Do you mean that Cromwell should allocate space appropriately given the inputs? The issue is that you also need space for the outputs, which is harder to predict unless you have a sense of what the task is doing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4737#issuecomment-386594579:230,allocate,allocate,230,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4737#issuecomment-386594579,1,['allocate'],['allocate']
Energy Efficiency,"Why are you running VariantRecalibrator on multiple files? In the current implementation the tool does read all the variants into memory, so merging the files somehow before would dramatically reduce the memory requirements.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6165#issuecomment-532795397:193,reduce,reduce,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6165#issuecomment-532795397,1,['reduce'],['reduce']
Energy Efficiency,"Yeah, I don't like these new interface methods -- they make `GATKRead` significantly worse. We should cache `isUnmapped`, etc. in the adapter to accomplish the same thing, as @lbergelson suggests. Not that hard, and we can just unconditionally invalidate the cached values (using `Boolean` fields set to null) whenever the read is mutated in any way in order to simplify the logic.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235102282:134,adapt,adapter,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235102282,1,['adapt'],['adapter']
Energy Efficiency,"Yeah, the workaround was simply to add the library jar to the classpath and not try to compile them together. I created the issue to soon, Sorry. . As for the NIO library, it is for AWS S3. We are adapting this one https://github.com/Upplication/Amazon-S3-FileSystem-NIO2 to meet our needs. We didn't like the way it handles s3 endpoints because AWS EMR Spark clusters don't support s3 uri's with that particular syntax. Our version modifies it to support normal s3 uri's without endpoints, instead setting the endpoint with a configuration parameter.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308161431:197,adapt,adapting,197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308161431,2,['adapt'],['adapting']
Energy Efficiency,"Yes, Hadoop-BAM uses the NIO API to do file merging, whereas in GATK we were using the Hadoop APIs (and therefore the GCS<->HDFS adapter) to do it. It looks like there are a couple of things needed in GCS-NIO to use the NIO API for this.; 1. https://github.com/GoogleCloudPlatform/google-cloud-java/issues/1450 so that we don't have to special-case `gs` URIs to remove everything except the scheme and host when looking up the filesystem (see https://github.com/HadoopGenomics/Hadoop-BAM/blob/master/src/main/java/org/seqdoop/hadoop_bam/util/NIOFileUtil.java#L40); 2. https://github.com/GoogleCloudPlatform/google-cloud-java/issues/813 to support path matching (https://github.com/HadoopGenomics/Hadoop-BAM/blob/master/src/main/java/org/seqdoop/hadoop_bam/util/NIOFileUtil.java#L90). There may be more, as I stopped there. The best way forward is probably to go back to the old code in GATK while the deficiencies in GCS-NIO are fixed and then released. The stacktrace I got for 1 was:. ```; java.lang.IllegalArgumentException: GCS FileSystem URIs mustn't have: port, userinfo, path, query, or fragment: gs://gatk-demo-tom/TEST/markdups.parts/_SUCCESS; 	at shaded.cloud-nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:146); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newFileSystem(CloudStorageFileSystemProvider.java:192); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newFileSystem(CloudStorageFileSystemProvider.java:83); 	at java.nio.file.FileSystems.newFileSystem(FileSystems.java:336); 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.asPath(NIOFileUtil.java:40); 	at org.seqdoop.hadoop_bam.util.NIOFileUtil.asPath(NIOFileUtil.java:54); 	at org.seqdoop.hadoop_bam.util.SAMFileMerger.mergeParts(SAMFileMerger.java:51); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:230); ```. And for 2:. ```; java.lang.UnsupportedOperationException; 	at com.google.cloud.s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-265132050:129,adapt,adapter,129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-265132050,1,['adapt'],['adapter']
Energy Efficiency,"Yes, it's important to realize that GenomicsDB is implemented in C (not Java), and so the memory allocated for GenomicsDB is whatever is NOT allocated to Java (ie., whatever is left over after -Xmx). So -Xmx should never claim all of the memory on the machine, and should leave enough free memory for GenomicsDB to use.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8777#issuecomment-2059629285:97,allocate,allocated,97,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8777#issuecomment-2059629285,2,['allocate'],['allocated']
Energy Efficiency,"Yes, merging GenomicsDBs with different samples in the same region. I think it may be more efficient with parallel processing for large samples. Is it possible to add the function?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6629#issuecomment-637207084:91,efficient,efficient,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6629#issuecomment-637207084,1,['efficient'],['efficient']
Energy Efficiency,"Yes, that's true in general. The -nt / -ntc flags options were never very good in gatk3. They usually scaled very poorly with number of cores, and were the cause of a lot of complexity and bugs. We decided not to try to roll our own map reduce framework for gatk4, but use an existing much better one, ie spark. . We recommend multiprocess parallelism with an external job runner like [cromwell](https://github.com/broadinstitute/cromwell) if you want parallelism in tools that aren't ready in spark yet. This is more complicated to setup and run, but it results in much more efficient use of compute resources. There are few limited multithreaded options remaining in GATK4 outside of spark. One specific one is the option to use multiple threads with HaplotypeCaller's pairHmm. This is only available on linux systems and defaults to using 4 threads.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4448#issuecomment-368051007:237,reduce,reduce,237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4448#issuecomment-368051007,2,"['efficient', 'reduce']","['efficient', 'reduce']"
Energy Efficiency,YnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zdi9jbHVzdGVyL1NWQ2x1c3RlckVuZ2luZS5qYXZh) | `93.269% <0.000%> (-1.002%)` | :arrow_down: |; | [...stitute/hellbender/tools/walkers/sv/SVCluster.java](https://codecov.io/gh/broadinstitute/gatk/pull/7858/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3N2L1NWQ2x1c3Rlci5qYXZh) | `89.773% <0.000%> (-0.881%)` | :arrow_down: |; | [...tools/walkers/sv/JointGermlineCNVSegmentation.java](https://codecov.io/gh/broadinstitute/gatk/pull/7858/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3N2L0pvaW50R2VybWxpbmVDTlZTZWdtZW50YXRpb24uamF2YQ==) | `86.047% <0.000%> (-0.752%)` | :arrow_down: |; | [...der/tools/walkers/sv/SVClusterIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7858/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3N2L1NWQ2x1c3RlckludGVncmF0aW9uVGVzdC5qYXZh) | `99.496% <0.000%> (-0.004%)` | :arrow_down: |; | [...rs/haplotypecaller/graphs/AdaptiveChainPruner.java](https://codecov.io/gh/broadinstitute/gatk/pull/7858/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvQWRhcHRpdmVDaGFpblBydW5lci5qYXZh) | `97.368% <0.000%> (+0.035%)` | :arrow_up: |; | ... and [3 more](https://codecov.io/gh/broadinstitute/gatk/pull/7858/diff?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7858#issuecomment-1130438520:4985,Adapt,AdaptiveChainPruner,4985,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7858#issuecomment-1130438520,1,['Adapt'],['AdaptiveChainPruner']
Energy Efficiency,"You know, I think I will clean up all the entangled genotype allele count caching and iterating. . I have benchmarked pretty thoroughly and discovered that caching `GenotypeAlleleCounts` for the sake of iterating in sequence is totally pointless. The `GenotypeAlleleCounts::increase` method is already so efficient that it makes no difference. In fact, caching is slower than using `increase` when the allele count and ploidy yield more than a few hundred genotypes. Caching is a bit faster for the commonest cases of 2 or 3 alleles in a diploid genotype, but the savings is less than a tenth of a second over an entire WGS run.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1067967439:305,efficient,efficient,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1067967439,1,['efficient'],['efficient']
Energy Efficiency,"Your solution doesn't address your third listed drawback to the current; approach, though I'm not sure there's any way to do that that wouldn't; require a pretty dramatic change. It's not obvious to me why we wanted the given alleles in the graph; originally. Maybe the use case was variants from UG that we didn't; necessarily believe were aligned properly?. I don't have any objections, but I'd feel better if we had a better guess; at what the original method was trying to do. On Wed, Apr 3, 2019 at 9:56 PM David Benjamin <notifications@github.com>; wrote:. > In Mutect2 and HaplotypeCaller, we force-call alleles by injecting them; > into the ref haplotype, then threading these constructed haplotypes into; > the assembly graph with a large edge weight. There are several drawbacks to; > this approach:; >; > - The strange edge weights interfere with the AdaptiveChainPruner.; > - The large edge weights may not be large enough to avoid pruning when; > depth is extremely high.; > - The alleles may be lost if assembly fails.; > - If the alleles actually exist but are in phase with another variant; > we end up putting an enormous amount of weight on a false haplotype.; >; > We can get around these issue with the following method:; >; > - assemble haplotypes without regard to the force-called alleles.; > - if an allele is present in these haplotypes, do nothing further.; > - otherwise, add a haplotype in which the allele is injected into the; > reference haplotype.; >; > @LeeTL1220 <https://github.com/LeeTL1220> I prototyped this and it seems; > to resolve the missed forced alleles that Ziao found.; >; > @ldgauthier <https://github.com/ldgauthier> Can you think of any; > objections to making this change in HaplotypeCaller?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdMcaTJg47gn",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767:862,Adapt,AdaptiveChainPruner,862,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767,1,['Adapt'],['AdaptiveChainPruner']
Energy Efficiency,\* Hangs head in shame *; I made a mistake in the buffer size computation in the Java side - over allocated .; Fixed now - consumes approximately the same amount of memory now,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4645#issuecomment-388221783:98,allocate,allocated,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4645#issuecomment-388221783,1,['allocate'],['allocated']
Energy Efficiency,"_2_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.0 MB); 17/10/13 18:11:44 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.131.101.159:44818 (size: 7.3 KB, free: 366.3 MB); 17/10/13 18:11:44 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006; 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157) (first 15 tasks are for partitions Vector(0)); 17/10/13 18:11:44 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks; 17/10/13 18:11:45 INFO spark.ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1); 17/10/13 18:11:48 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.131.101.145:54024) with ID 1; 17/10/13 18:11:48 INFO spark.ExecutorAllocationManager: New executor 1 has registered (new total is 1); 17/10/13 18:11:48 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, com2, executor 1, partition 0, NODE_LOCAL, 4877 bytes); 17/10/13 18:11:48 INFO storage.BlockManagerMasterEndpoint: Registering block manager com2:45501 with 366.3 MB RAM, BlockManagerId(1, com2, 45501, None); 17/10/13 18:11:50 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on com2:45501 (size: 7.3 KB, free: 366.3 MB); 17/10/13 18:11:51 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on com2:45501 (size: 26.0 KB, free: 366.3 MB); 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4638 ms on com2 (executor 1) (1/1); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool ; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (mapToPair at SparkUtils.java:157) finished in 8.668 s; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: looking for new",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:18347,schedul,scheduler,18347,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['schedul'],['scheduler']
Energy Efficiency,"_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.029108712999999998,Cpu time(s),0.029110260000000002; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.0073808319999999995,Cpu time(s),0.007382536; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.029078561,Cpu time(s),0.029079955999999997; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.006109087,Cpu time(s),0.006077208000000001; 13:25:54.636 INFO ProgressMeter - 20:7039750 25.4 1000 39.3; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.3064205629999998,Cpu time(s),0.30639567500000026; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.016820958,Cpu time(s),0.016806184. ```. So you'll see it's progressing, but ~38 variants/min if I read this right. A few other things to note:. - FWIW, this is using a GATK JAR I built locally using #7962, which has some minor changes to side-step a bug in GenotypeGVCFs. Those changes only touch two annotation classes. - GenomicsDB 1.4.4 mentions memory improvements - any reason to think trying that would make a difference?. - One other thing to mention is that the MMul10 genome has ~2900 contigs. I dont understand precisely why this is a problem for GenomicsDB, but that has come up. Since we're only working on one contig (and usually a fraction of a contig) per job, could I subset my workspace to coax GenomicsDB to think it only has one contig? I believe I could just copy the contig folder and touch up the metadata JSON? I realize this isnt a great solution, but we're completely blocked here in terms of genotyping our data. - If SelectVariants actually worked here, could I run SelectVariants on the GenomicsDB workspace to create a combined gVCF for my ~2m site interval, and then run GenotypeGVCFs against this subset? It's not especially efficient, but if SelectVariants can pass and produce an output that's valid for GenotypeGVCFs that would actually be quite useful.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1209854842:4739,efficient,efficient,4739,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1209854842,1,['efficient'],['efficient']
Energy Efficiency,"`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2416 +/- ##; ===============================================; - Coverage 76.224% 76.218% -0.006% ; + Complexity 10820 10819 -1 ; ===============================================; Files 750 750 ; Lines 39422 39420 -2 ; Branches 6883 6883 ; ===============================================; - Hits 30049 30045 -4 ; - Misses 6755 6757 +2 ; Partials 2618 2618; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2416?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...alkers/genotyper/afcalc/CustomAFPriorProvider.java](https://codecov.io/gh/broadinstitute/gatk/compare/75f633135798145079ddb32c7dc2e884d47de4b3...3f2a04aa9723a86271120755e6be8945ff103532?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvQ3VzdG9tQUZQcmlvclByb3ZpZGVyLmphdmE=) | `94.444% <ø> (-0.556%)` | `6 <ø> (-1)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/75f633135798145079ddb32c7dc2e884d47de4b3...3f2a04aa9723a86271120755e6be8945ff103532?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `66.667% <ø> (-3.333%)` | `10% <ø> (ø)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2416?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2416?src=pr&el=footer). Last update [75f6331...3f2a04a](https://codecov.io/gh/broadinstitute/gatk/compare/75f633135798145079ddb32c7dc2e884d47de4b3...3f2a04aa9723a86271120755e6be8945ff103532?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2416#issuecomment-281483092:1962,Power,Powered,1962,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2416#issuecomment-281483092,1,['Power'],['Powered']
Energy Efficiency,"a"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": {; ""read_from_cache"": false; },; ""test_cromwell_job_id"": ""b9fadac2-4e94-424f-a397-004684d1e51e"",; ""eval_cromwell_job_id"": ""acc9e2ac-b10a-4d6a-b586-cd3e47f04e41"",; ""created_at"": ""2023-05-16T17:15:43.799702"",; ""created_by"": null,; ""finished_at"": ""2023-05-17T02:34:53.616"",; ""results"": {; ""CHM controlHCprocesshours"": ""84.8981027777778"",; ""CHM controlHCsystemhours"": ""0.19177500000000003"",; ""CHM controlHCwallclockhours"": ""60.16600277777776"",; ""CHM controlHCwallclockmax"": ""3.0439777777777777"",; ""CHM controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-CHMSampleHeadToHead/BenchmarkComparison/1731c546-7466-4adf-9790-3f99d07df05b/call-CONTROLRuntimeTask/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-CHMSampleHeadToHead/BenchmarkComparison/1731c546-7466-4adf-9790-3f99d07df05b/call-BenchmarkVCFControlSample/Benchmark/669edf6c-76a1-4d82-8cf7-5cd104df2496/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""83.2423166666667"",; ""CHM evalHCsystemhours"": ""0.18843333333333337"",; ""CHM evalHCwallclockhours"": ""61.06540555555557"",; ""CHM evalHCwallclockmax"": ""3.1854916666666666"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/c",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1550601099:17351,monitor,monitoring,17351,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1550601099,1,['monitor'],['monitoring']
Energy Efficiency,"a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:09 INFO TaskSetManager:54 - Starting task 1.2 in stage 0.0 (TID 6, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:09 INFO TaskSetManager:54 - Lost task 3.1 in stage 0.0 (TID 4) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d) [duplicate 1]; 2019-01-07 11:34:10 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 7, scc-q12.scc.bu.edu, executor 2, partition 2, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:10 WARN TaskSetManager:66 - Lost task 9.0 in stage 0.0 (TID 5",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:28791,schedul,scheduler,28791,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['schedul'],['scheduler']
Energy Efficiency,"a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:50 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 4, scc-q20.scc.bu.edu, executor 2, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:50 WARN TaskSetManager:66 - Lost task 4.0 in stage 0.0 (TID 2, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.col",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:25889,schedul,scheduler,25889,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['schedul'],['scheduler']
Energy Efficiency,a7258df116ba2a3af7df191ebc8a?src=pr&el=desc) will **decrease** coverage by `<.001%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #5062 +/- ##; ==============================================; - Coverage 86.35% 86.349% -<.001% ; - Complexity 28824 28826 +2 ; ==============================================; Files 1791 1791 ; Lines 133601 133619 +18 ; Branches 14920 14920 ; ==============================================; + Hits 115364 115379 +15 ; - Misses 12834 12837 +3 ; Partials 5403 5403; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5062?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...bender/utils/GATKProtectedVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5062/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HQVRLUHJvdGVjdGVkVmFyaWFudENvbnRleHRVdGlscy5qYXZh) | `65.746% <ø> (ø)` | `61 <0> (ø)` | :arrow_down: |; | [...ion/basicshortmutpileup/PowerCalculationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5062/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9Qb3dlckNhbGN1bGF0aW9uVXRpbHMuamF2YQ==) | `96.667% <100%> (+1.429%)` | `18 <7> (+3)` | :arrow_up: |; | [...tmutpileup/BasicSomaticShortMutationValidator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5062/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9CYXNpY1NvbWF0aWNTaG9ydE11dGF0aW9uVmFsaWRhdG9yLmphdmE=) | `62.5% <100%> (+1.974%)` | `5 <0> (ø)` | :arrow_down: |; | [...ion/basicshortmutpileup/BasicValidationResult.java](https://codecov.io/gh/broadinstitute/gatk/pull/5062/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9CYXNpY1ZhbGlkYXRpb25SZXN1bHQuamF2YQ==) | `96.774% <10,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5062#issuecomment-408490831:1248,Power,PowerCalculationUtils,1248,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5062#issuecomment-408490831,1,['Power'],['PowerCalculationUtils']
Energy Efficiency,"a7b8e54d20168a65?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :white_check_mark: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/521128573b0d1a01ee60725c2b84e4a4f6a12fa3...cab0d179986f7f7587e0e005a7b8e54d20168a65?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `75.694% <0%> (+2.083%)` | `36% <0%> (ø)` | :x: |; | [...oadinstitute/hellbender/utils/GenomeLocParser.java](https://codecov.io/gh/broadinstitute/gatk/compare/521128573b0d1a01ee60725c2b84e4a4f6a12fa3...cab0d179986f7f7587e0e005a7b8e54d20168a65?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vbWVMb2NQYXJzZXIuamF2YQ==) | `90.083% <0%> (+4.132%)` | `57% <0%> (+2%)` | :white_check_mark: |; | [...ellbender/utils/test/CommandLineProgramTester.java](https://codecov.io/gh/broadinstitute/gatk/compare/521128573b0d1a01ee60725c2b84e4a4f6a12fa3...cab0d179986f7f7587e0e005a7b8e54d20168a65?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0NvbW1hbmRMaW5lUHJvZ3JhbVRlc3Rlci5qYXZh) | `90.476% <0%> (+4.762%)` | `8% <0%> (+1%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2423?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2423?src=pr&el=footer). Last update [5211285...cab0d17](https://codecov.io/gh/broadinstitute/gatk/compare/521128573b0d1a01ee60725c2b84e4a4f6a12fa3...cab0d179986f7f7587e0e005a7b8e54d20168a65?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-282342687:3101,Power,Powered,3101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-282342687,1,['Power'],['Powered']
Energy Efficiency,a:206); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:213); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:935); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:926); at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:866); at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:926); at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:670); at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330); at org.apache.spark.rdd.RDD.iterator(RDD.scala:281); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3013#issuecomment-308145149:4051,schedul,scheduler,4051,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3013#issuecomment-308145149,2,['schedul'],['scheduler']
Energy Efficiency,"a:220`, until we killed it. So I tried `--bamPartitionSize 4000000`, and it went through, but the Spark web interface showed errors in `sortByKey` steps:; ![sparkjob](https://user-images.githubusercontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:1144,schedul,scheduler,1144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363,1,['schedul'],['scheduler']
Energy Efficiency,abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:935); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); at org.apache.spark.rdd.RDD.collect(RDD.scala:934); at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:152); at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.scala:62); at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.scala:61); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.sc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:2366,schedul,scheduler,2366,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363,1,['schedul'],['scheduler']
Energy Efficiency,abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); at org.apache.spark.rdd.RDD.count(RDD.scala:1158); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark.runTool(PathSeqPipelineSpark.java:245); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:387); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:42550,schedul,scheduler,42550,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['schedul'],['scheduler']
Energy Efficiency,abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); at org.apache.spark.rdd.RDD.count(RDD.scala:1162); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark.runTool(CountReadsSpark.java:80); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:470); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceM,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:39608,schedul,scheduler,39608,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,4,['schedul'],['scheduler']
Energy Efficiency,"ac327-c59c-43f7-a850-21bc3e0ccf52/call-CHMSampleHeadToHead/BenchmarkComparison/cd28fe49-1672-4321-a836-47f76419c1c8/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0ccf52/call-CHMSampleHeadToHead/BenchmarkComparison/cd28fe49-1672-4321-a836-47f76419c1c8/call-BenchmarkVCFControlSample/Benchmark/d5df8455-36cf-4ecb-8dc2-ec35b974c0b7/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""78.23616944444446"",; ""CHM evalHCsystemhours"": ""0.16188333333333332"",; ""CHM evalHCwallclockhours"": ""55.167422222222214"",; ""CHM evalHCwallclockmax"": ""2.887522222222222"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0ccf52/call-CHMSampleHeadToHead/BenchmarkComparison/cd28fe49-1672-4321-a836-47f76419c1c8/call-EVALRuntimeTask/monitoring.pdf"",; ""CHM evalindelF1Score"": ""0.8724"",; ""CHM evalindelPrecision"": ""0.8814"",; ""CHM evalsnpF1Score"": ""0.9784"",; ""CHM evalsnpPrecision"": ""0.9706"",; ""CHM evalsnpRecall"": ""0.9863"",; ""CHM evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0ccf52/call-CHMSampleHeadToHead/BenchmarkComparison/cd28fe49-1672-4321-a836-47f76419c1c8/call-BenchmarkVCFTestSample/Benchmark/83a51739-dd4e-4f2d-b09a-3c78b132fbf1/call-CombineSummaries/summary.csv"",; ""EXOME1 controlindelF1Score"": ""0.727"",; ""EXOME1 controlindelPrecision"": ""0.632"",; ""EXOME1 controlsnpF1Score"": ""0.9878"",; ""EXOME1 controlsnpPrecision"": ""0.9815"",; ""EXOME1 controlsnpRecall"": ""0.9941"",; ""EXOME1 controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0ccf52/call-EXOME1SampleHead",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1182703672:17682,monitor,monitoring,17682,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1182703672,1,['monitor'],['monitoring']
Energy Efficiency,"action model to allow for the modeling of hom sites. I wrote up such a model in some notes I sent around a few months back. This model allows for an allelic PoN that uses all sites to learn reference bias, not just hets. Depending on how our python development proceeds, I may try to implement this model using the old `GibbsSampler` code instead.; - [x] In the meantime, we can try to speed up the old allele-fraction model, which is now the main bottleneck. An easy (lazy) strategy might simply be to downsample and scale likelihoods when estimating global parameters. Addresses #2884.; - [x] Even though the simple copy-ratio model is much faster, it still takes ~15-20 minutes for 100 iterations on WGS, so we can downsample here too.; - [x] Integration tests are still needed; again, these might not test for correctness.; - I've added the ability to specify a prior for the minor-allele fraction, which alleviates the problem of residual bias in balanced segments.; - I've reduced the verbosity of the modeled-segments file. I only report posterior mode and 10%, 50%, and 90% deciles. Global parameters have the full deciles output in the .param files, but I removed the mode and highest density credible interval (because of the below item).; - [x] Some residual bias remains in the estimate of the minor-allele fraction posterior mode. This is simply because we are performing kernel density estimation of a bounded quantity. One possibility would be to logit transform to an unbounded support, perform the estimation, then transform back. EDIT: Just removed kernel density estimation for now, partly due to #3599 as well.; - Hmm, actually still a tiny bit of residual bias. This is apparent e.g. in WGS normals. I think focusing on a new allele-fraction model rather than trying to figure out where the old one is failing would be best.; - [x] For small bins (250bp), the copy-ratio model is currently a bit memory intensive, since it stores an outlier indicator boolean for every data point",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828:6221,reduce,reduced,6221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-333202828,2,['reduce'],['reduced']
Energy Efficiency,"adcast_1_piece0 in memory on 10.131.101.159:44818 (size: 2.1 KB, free: 366.3 MB); 17/10/13 18:11:44 INFO spark.SparkContext: Created broadcast 1 from broadcast at ReadsSparkSink.java:195; 17/10/13 18:11:44 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1; 17/10/13 18:11:44 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 17/10/13 18:11:44 INFO spark.SparkContext: Starting job: runJob at SparkHadoopMapReduceWriter.scala:88; 17/10/13 18:11:44 INFO input.FileInputFormat: Total input paths to process : 1; 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Registering RDD 5 (mapToPair at SparkUtils.java:157); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Got job 0 (runJob at SparkHadoopMapReduceWriter.scala:88) with 1 output partitions; 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (runJob at SparkHadoopMapReduceWriter.scala:88); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157), which has no missing parents; 17/10/13 18:11:44 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 15.9 KB, free 366.0 MB); 17/10/13 18:11:44 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.0 MB); 17/10/13 18:11:44 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.131.101.159:44818 (size: 7.3 KB, free: 366.3 MB); 17/10/13 18:11:44 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006; 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:15",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:16789,schedul,scheduler,16789,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['schedul'],['scheduler']
Energy Efficiency,"alizing engine; 16:58:10.116 INFO PrintVariantsSpark - Done initializing engine; 19/02/18 16:58:10 WARN org.apache.spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 19/02/18 16:58:10 INFO org.spark_project.jetty.util.log: Logging initialized @8431ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: Started @8536ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@45c90a05{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 19/02/18 16:58:11 WARN org.apache.spark.scheduler.FairSchedulableBuilder: Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.; 19/02/18 16:58:12 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:8032; 19/02/18 16:58:13 INFO org.apache.hadoop.yarn.client.AHSProxy: Connecting to Application History server at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:10200; 19/02/18 16:58:15 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1550508751046_0004; WARNING	2019-02-18 16:58:23	AsciiLineReader	Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; WARNING	2019-02-18 16:58:23	AsciiLineReader	Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; 19/02/18 16:58:25 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total in",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:4836,schedul,scheduler,4836,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,"allclockmax"": ""3.8631972222222224"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607c8/call-NISTSampleHeadToHead/BenchmarkComparison/243c7bf2-b0d7-48ed-acd0-e2ebd74b9fd3/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607c8/call-NISTSampleHeadToHead/BenchmarkComparison/243c7bf2-b0d7-48ed-acd0-e2ebd74b9fd3/call-BenchmarkVCFControlSample/Benchmark/135b02c2-d7c5-4fd2-9cc5-cdeeed953bbc/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""103.49634722222224"",; ""NIST evalHCsystemhours"": ""0.20633611111111116"",; ""NIST evalHCwallclockhours"": ""75.91255833333332"",; ""NIST evalHCwallclockmax"": ""3.76305"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607c8/call-NISTSampleHeadToHead/BenchmarkComparison/243c7bf2-b0d7-48ed-acd0-e2ebd74b9fd3/call-EVALRuntimeTask/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607c8/call-NISTSampleHeadToHead/BenchmarkComparison/243c7bf2-b0d7-48ed-acd0-e2ebd74b9fd3/call-BenchmarkVCFTestSample/Benchmark/ad8885d7-137d-4645-b37d-f54f8362713d/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607c8/call-CreateHTMLReport/report.html""; },; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1546478988:21356,monitor,monitoring,21356,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1546478988,1,['monitor'],['monitoring']
Energy Efficiency,"allclockmax"": ""4.163775"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-NISTSampleHeadToHead/BenchmarkComparison/24ad1003-6862-4e29-9d4d-ea8e85bcc78b/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-NISTSampleHeadToHead/BenchmarkComparison/24ad1003-6862-4e29-9d4d-ea8e85bcc78b/call-BenchmarkVCFControlSample/Benchmark/7d69a7b4-2884-4b7e-9bce-fc2eab77b125/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""103.71990555555556"",; ""NIST evalHCsystemhours"": ""0.20632500000000004"",; ""NIST evalHCwallclockhours"": ""76.41897222222222"",; ""NIST evalHCwallclockmax"": ""4.163391666666667"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-NISTSampleHeadToHead/BenchmarkComparison/24ad1003-6862-4e29-9d4d-ea8e85bcc78b/call-EVALRuntimeTask/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-NISTSampleHeadToHead/BenchmarkComparison/24ad1003-6862-4e29-9d4d-ea8e85bcc78b/call-BenchmarkVCFTestSample/Benchmark/aba51ebf-90d5-44fa-8caa-0beb3cf1643b/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-CreateHTMLReport/report.html""; },; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574622123:21328,monitor,monitoring,21328,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574622123,1,['monitor'],['monitoring']
Energy Efficiency,am.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); at org.apache.spark.rdd.RDD.count(RDD.scala:1158); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tool,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:42107,schedul,scheduler,42107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['schedul'],['scheduler']
Energy Efficiency,"anies:; ![grafik](https://user-images.githubusercontent.com/1612006/35342524-94fcab50-0128-11e8-800e-840d891058ef.png). 1. How to convince people:; I agree. I think it is most effective to make people ""feel"" the difference, i.e. output like ""you have been waiting 1324s or 60% of additional processing time on this step due to compression"".; Or ""Processing still hasn't started due to compression/decompression."". GATK4, especially on Spark hides that pretty well.; For example, turning off Spark lz4 and relying on ZFS lz4 for the writing of temporary data was instructive about how much CPU was used for it (not that much). 2. Compression differences:; I might help to look at the used dictionary size for the differences and also the possible method of compression parallelization. Multi-core compression mostly cuts files into pieces and can greatly decrease compression if the data is highly repetitive. Because another core starts anew on data that the previous one might have reduced to almost nothing (zstd allows some sharing of the dictionary between cores, but most do not I think). Example about the dictionary difference: For long distance repetitive files, compression with; xz --lzma2=preset=1,dict=1500M can bringe a huge gain in compression, but still be much faster than level 9 (which has normally only a dictionary of 64MB). Compression levels are correlated with dict size for most compressors to ensure monotonically increasing memory usage, but that doesn't have to be so.; zstd, for example, allows many parameters to change this. Even more than xz. I suspect due to my experiments that quality values gain more from increased dictionary size, because they are more repetitive than the DNA data. And shorter BAMs would be different because they are less repetitive (usually less coverage), so their compression relies more on CPU-expensive crunching of the ""2bit nature"" of the DNA.; So they might logically suffer more from a lower compression level.; It might be instructive ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3413#issuecomment-360179673:1109,reduce,reduced,1109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413#issuecomment-360179673,1,['reduce'],['reduced']
Energy Efficiency,anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:38484,schedul,scheduler,38484,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,4,['schedul'],['scheduler']
Energy Efficiency,ark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:123); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); 	at org.apache.spark.scheduler.DAGSchedulerEventProces,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:10760,schedul,scheduler,10760,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['schedul'],['scheduler']
Energy Efficiency,at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); at org.apache.spark.rdd.RDD.count(RDD.scala:1162); at org.apache.spark.api.java.JavaRDDLike$cla,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:39017,schedul,scheduler,39017,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,4,['schedul'],['scheduler']
Energy Efficiency,"ated broadcast 3 from broadcast at DAGScheduler.scala:1006; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244) (first 15 tasks are for partitions Vector(0)); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks; 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, com2, executor 1, partition 0, NODE_LOCAL, 4632 bytes); 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on com2:45501 (size: 32.6 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.131.101.145:54024; 17/10/13 18:11:53 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 135 bytes; 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on com2:45501 (size: 2.1 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 565 ms on com2 (executor 1) (1/1); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: ResultStage 1 (runJob at SparkHadoopMapReduceWriter.scala:88) finished in 0.566 s; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Job 0 finished: runJob at SparkHadoopMapReduceWriter.scala:88, took 9.524571 s; 17/10/13 18:11:53 INFO io.SparkHadoopMapReduceWriter: Job job_20171013181144_0009 committed.; 17/10/13 18:11:53 INFO server.AbstractConnector: Stopped Spark@131ba51c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/10/13 18:11:53 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/13 18:11:54 INFO cluster.YarnSchedulerBackend$Ya",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:21150,schedul,scheduler,21150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['schedul'],['scheduler']
Energy Efficiency,ationFactory.java:2866); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:239); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForSegment$2(FuncotatorEngine.java:223); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForSegment(FuncotatorEngine.java:226); at org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments.apply(FuncotateSegments.java:191); at org.broadinstitute.hellbender.tools.funcotator.FuncotateSegments.apply(FuncotateSegments.java:59); at org.broadinstitute.hellbender.engine.FeatureWalker.lambda$traverse$0(FeatureWalker.java:99); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:647); at org.broadinstitute.hellbender.engine.FeatureWalker.traverse(FeatureWalker.java:97); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKT,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-1243013314:3126,Reduce,ReduceOps,3126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-1243013314,4,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,ator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:953); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:812); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:796); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:473); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:474); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:529); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:233); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:201); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:172); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036:8241,Reduce,ReduceOps,8241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036,1,['Reduce'],['ReduceOps']
Energy Efficiency,avaRDDLike.scala:153); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:123); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.ap,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:10096,schedul,scheduler,10096,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['schedul'],['scheduler']
Energy Efficiency,"ax"": ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/89508d5f-29f1-4534-9fe1-220a80de17c4/call-NISTSampleHeadToHead/BenchmarkComparison/338d644e-3327-471e-9d17-1c103fa5e01e/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/89508d5f-29f1-4534-9fe1-220a80de17c4/call-NISTSampleHeadToHead/BenchmarkComparison/338d644e-3327-471e-9d17-1c103fa5e01e/call-BenchmarkVCFControlSample/Benchmark/145d88de-5810-47e1-972a-18ff0169fe27/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""92.82975"",; ""NIST evalHCsystemhours"": ""0.17177777777777778"",; ""NIST evalHCwallclockhours"": ""66.4404388888889"",; ""NIST evalHCwallclockmax"": ""3.325327777777778"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/89508d5f-29f1-4534-9fe1-220a80de17c4/call-NISTSampleHeadToHead/BenchmarkComparison/338d644e-3327-471e-9d17-1c103fa5e01e/call-EVALRuntimeTask/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/89508d5f-29f1-4534-9fe1-220a80de17c4/call-NISTSampleHeadToHead/BenchmarkComparison/338d644e-3327-471e-9d17-1c103fa5e01e/call-BenchmarkVCFTestSample/Benchmark/e37c2b01-a62d-4b8c-9fb3-6f86d8377ca7/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/89508d5f-29f1-4534-9fe1-220a80de17c4/call-CreateHTMLReport/cacheCopy/report.html""; },; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1193038382:20668,monitor,monitoring,20668,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1193038382,1,['monitor'],['monitoring']
Energy Efficiency,"ax"": ""4.031741666666667"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/81dbf637-d90c-4111-93b9-9cec426c5a39/call-NISTSampleHeadToHead/BenchmarkComparison/3238c3ac-5e7c-4130-bb68-26871868b49e/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/81dbf637-d90c-4111-93b9-9cec426c5a39/call-NISTSampleHeadToHead/BenchmarkComparison/3238c3ac-5e7c-4130-bb68-26871868b49e/call-BenchmarkVCFControlSample/Benchmark/4121c5eb-9771-43ee-84f1-262115dcf151/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""93.23600000000005"",; ""NIST evalHCsystemhours"": ""0.2127972222222222"",; ""NIST evalHCwallclockhours"": ""62.422702777777786"",; ""NIST evalHCwallclockmax"": ""3.1571083333333334"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/81dbf637-d90c-4111-93b9-9cec426c5a39/call-NISTSampleHeadToHead/BenchmarkComparison/3238c3ac-5e7c-4130-bb68-26871868b49e/call-EVALRuntimeTask/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/81dbf637-d90c-4111-93b9-9cec426c5a39/call-NISTSampleHeadToHead/BenchmarkComparison/3238c3ac-5e7c-4130-bb68-26871868b49e/call-BenchmarkVCFTestSample/Benchmark/499d7c71-c488-4bfb-9802-34f6c5696c8d/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/81dbf637-d90c-4111-93b9-9cec426c5a39/call-CreateHTMLReport/report.html""; },; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8485#issuecomment-1684837497:21350,monitor,monitoring,21350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8485#issuecomment-1684837497,1,['monitor'],['monitoring']
Energy Efficiency,"ax"": ""4.166558333333334"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-NISTSampleHeadToHead/BenchmarkComparison/043115ef-b68a-49a3-8272-8352b304c3aa/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-NISTSampleHeadToHead/BenchmarkComparison/043115ef-b68a-49a3-8272-8352b304c3aa/call-BenchmarkVCFControlSample/Benchmark/b7031327-e5c1-4869-a5d9-98e5a8934db9/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""112.84528333333336"",; ""NIST evalHCsystemhours"": ""0.8645277777777777"",; ""NIST evalHCwallclockhours"": ""88.01737777777778"",; ""NIST evalHCwallclockmax"": ""4.8386555555555555"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-NISTSampleHeadToHead/BenchmarkComparison/043115ef-b68a-49a3-8272-8352b304c3aa/call-EVALRuntimeTask/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-NISTSampleHeadToHead/BenchmarkComparison/043115ef-b68a-49a3-8272-8352b304c3aa/call-BenchmarkVCFTestSample/Benchmark/d4de27fe-6aca-42a5-8a9f-6daff7b890e8/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-CreateHTMLReport/report.html""; },; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8467#issuecomment-1687811441:21336,monitor,monitoring,21336,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8467#issuecomment-1687811441,1,['monitor'],['monitoring']
Energy Efficiency,b.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:109); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:507); 	... 12 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931:7089,Meter,MeteredStream,7089,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931,1,['Meter'],['MeteredStream']
Energy Efficiency,"b07a68-f04f-4396-80b4-f153b2d0020d/call-BenchmarkVCFControlSample/Benchmark/efb3b5ff-3860-46c3-8c6c-9141d1ff0e0a/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.727"",; ""EXOME1 evalindelPrecision"": ""0.632"",; ""EXOME1 evalsnpF1Score"": ""0.9878"",; ""EXOME1 evalsnpPrecision"": ""0.9815"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-EXOME1SampleHeadToHead/BenchmarkComparison/85b07a68-f04f-4396-80b4-f153b2d0020d/call-BenchmarkVCFTestSample/Benchmark/272d076b-7300-4ea4-bbf7-d63f80fad94b/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""108.95665833333332"",; ""NIST controlHCsystemhours"": ""0.21568055555555551"",; ""NIST controlHCwallclockhours"": ""78.62844166666666"",; ""NIST controlHCwallclockmax"": ""4.166558333333334"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-NISTSampleHeadToHead/BenchmarkComparison/043115ef-b68a-49a3-8272-8352b304c3aa/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-NISTSampleHeadToHead/BenchmarkComparison/043115ef-b68a-49a3-8272-8352b304c3aa/call-BenchmarkVCFControlSample/Benchmark/b7031327-e5c1-4869-a5d9-98e5a8934db9/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""112.84528333333336"",; ""NIST evalHCsystemhours"": ""0.8645277777777777"",; ""NIST evalHCwallclockhours"": ""88.01737777777778"",; ""NIST evalHCwallclockmax"": ""4.8386555555555555"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8467#issuecomment-1687811441:20348,monitor,monitoring,20348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8467#issuecomment-1687811441,1,['monitor'],['monitoring']
Energy Efficiency,"b6-04bd-4344-b4fc-8a1df66bb5d9/call-CHMSampleHeadToHead/BenchmarkComparison/79d1a2a4-6b5e-424a-8528-9059bda6db1c/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-CHMSampleHeadToHead/BenchmarkComparison/79d1a2a4-6b5e-424a-8528-9059bda6db1c/call-BenchmarkVCFControlSample/Benchmark/3046acf7-ded7-40c8-9b7a-3826f480418f/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""67.35536666666667"",; ""CHM evalHCsystemhours"": ""0.1557166666666667"",; ""CHM evalHCwallclockhours"": ""42.53388888888889"",; ""CHM evalHCwallclockmax"": ""2.7197444444444443"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-CHMSampleHeadToHead/BenchmarkComparison/79d1a2a4-6b5e-424a-8528-9059bda6db1c/call-EVALRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM evalindelF1Score"": ""0.8778"",; ""CHM evalindelPrecision"": ""0.8968"",; ""CHM evalsnpF1Score"": ""0.9813"",; ""CHM evalsnpPrecision"": ""0.9774"",; ""CHM evalsnpRecall"": ""0.9852"",; ""CHM evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-CHMSampleHeadToHead/BenchmarkComparison/79d1a2a4-6b5e-424a-8528-9059bda6db1c/call-BenchmarkVCFTestSample/Benchmark/2f376005-bdfb-42bd-8736-1e6df978ab80/call-CombineSummaries/summary.csv"",; ""EXOME1 controlindelF1Score"": ""0.727"",; ""EXOME1 controlindelPrecision"": ""0.632"",; ""EXOME1 controlsnpF1Score"": ""0.9878"",; ""EXOME1 controlsnpPrecision"": ""0.9815"",; ""EXOME1 controlsnpRecall"": ""0.9941"",; ""EXOME1 controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-EXOME1Sampl",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1069765064:11456,monitor,monitoring,11456,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1069765064,1,['monitor'],['monitoring']
Energy Efficiency,"b9636?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9MaWJyYXJ5UmVhZEZpbHRlci5qYXZh) | `100% <ø> (ø)` | `4 <ø> (ø)` | :x: |; | [...institute/hellbender/tools/picard/sam/SortSam.java](https://codecov.io/gh/broadinstitute/gatk/compare/10b16a671dc2e153dbc92a16a72bdbf88eaa5ccd...d4483e8cf8d2e50e125c5340556b3eb49abb9636?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9waWNhcmQvc2FtL1NvcnRTYW0uamF2YQ==) | `94.118% <ø> (ø)` | `3 <ø> (ø)` | :x: |; | [...adinstitute/hellbender/tools/IndexFeatureFile.java](https://codecov.io/gh/broadinstitute/gatk/compare/10b16a671dc2e153dbc92a16a72bdbf88eaa5ccd...d4483e8cf8d2e50e125c5340556b3eb49abb9636?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9JbmRleEZlYXR1cmVGaWxlLmphdmE=) | `90.323% <ø> (ø)` | `12 <ø> (ø)` | :x: |; | [...org/broadinstitute/hellbender/tools/ClipReads.java](https://codecov.io/gh/broadinstitute/gatk/compare/10b16a671dc2e153dbc92a16a72bdbf88eaa5ccd...d4483e8cf8d2e50e125c5340556b3eb49abb9636?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9DbGlwUmVhZHMuamF2YQ==) | `90.385% <ø> (ø)` | `35 <ø> (ø)` | :x: |; | ... and [81 more](https://codecov.io/gh/broadinstitute/gatk/pull/2327/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2327?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2327?src=pr&el=footer). Last update [10b16a6...d4483e8](https://codecov.io/gh/broadinstitute/gatk/compare/10b16a671dc2e153dbc92a16a72bdbf88eaa5ccd...d4483e8cf8d2e50e125c5340556b3eb49abb9636?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-268877705:4973,Power,Powered,4973,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-268877705,1,['Power'],['Powered']
Energy Efficiency,"bWVudENvbGxlY3Rpb24uamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [...tools/examples/ExampleStreamingPythonExecutor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leGFtcGxlcy9FeGFtcGxlU3RyZWFtaW5nUHl0aG9uRXhlY3V0b3IuamF2YQ==) | `0% <0%> (-96.67%)` | `0% <0%> (-8%)` | |; | [.../walkers/vqsr/CNNScoreVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `4.16% <0%> (-95.84%)` | `2% <0%> (-8%)` | |; | [...der/utils/python/PythonScriptExecutorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9weXRob24vUHl0aG9uU2NyaXB0RXhlY3V0b3JVbml0VGVzdC5qYXZh) | `3.84% <0%> (-94.24%)` | `1% <0%> (-11%)` | |; | [...number/arguments/HybridADVIArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2FyZ3VtZW50cy9IeWJyaWRBRFZJQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `0% <0%> (-94.12%)` | `0% <0%> (-3%)` | |; | ... and [36 more](https://codecov.io/gh/broadinstitute/gatk/pull/5329/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5329?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5329?src=pr&el=footer). Last update [f95b6fe...1c00f72](https://codecov.io/gh/broadinstitute/gatk/pull/5329?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5329#issuecomment-431146563:4744,Power,Powered,4744,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5329#issuecomment-431146563,1,['Power'],['Powered']
Energy Efficiency,"bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `90% <0%> (-1.429%)` | `23% <0%> (-1%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/58cb99ec6c81917a9ac8ecf52e8fde2bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `87.2% <0%> (+0.8%)` | `36% <0%> (+1%)` | :arrow_up: |; | [...ellbender/tools/walkers/annotator/RankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/compare/58cb99ec6c81917a9ac8ecf52e8fde2bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9SYW5rU3VtVGVzdC5qYXZh) | `86.957% <0%> (+6.401%)` | `14% <0%> (+1%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/58cb99ec6c81917a9ac8ecf52e8fde2bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `75.385% <0%> (+7.168%)` | `49% <0%> (+16%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2500?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2500?src=pr&el=footer). Last update [58cb99e...2a7f196](https://codecov.io/gh/broadinstitute/gatk/compare/58cb99ec6c81917a9ac8ecf52e8fde2bd763850b...2a7f1965dff4d460667e64ead68b52d462b125b6?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2500#issuecomment-288139597:2681,Power,Powered,2681,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2500#issuecomment-288139597,1,['Power'],['Powered']
Energy Efficiency,"bert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; >; > 16:17:04.407 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression7506152962158874866.so: /tmp/libgkl_compression7506152962158874866.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)); >; > Sep 04, 2020 4:17:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; >; > INFO: Failed to detect whether we are running on Google Compute Engine.; >; > 16:17:05.842 INFO HaplotypeCaller - ------------------------------------------------------------; >; > 16:17:05.843 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.1; >; > 16:17:05.843 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; >; > 16:17:05.843 INFO HaplotypeCaller - Executing as robert@powerlinux on Linux v4.4.0-184-generic ppc64le; >; > 16:17:05.843 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_252-8u252-b09-1~16.04-b09; >; > 16:17:05.843 INFO HaplotypeCaller - Start Date/Time: September 4, 2020 4:17:04 PM UTC; >; > 16:17:05.843 INFO HaplotypeCaller - ------------------------------------------------------------; >; > 16:17:05.843 INFO HaplotypeCaller - ------------------------------------------------------------; >; > 16:17:05.844 INFO HaplotypeCaller - HTSJDK Version: 2.23.0; >; > 16:17:05.844 INFO HaplotypeCaller - Picard Version: 2.22.8; >; > 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; >; > 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; >; > 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; >; > 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; >; > 16:17:05.844 INFO Hapl",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6794#issuecomment-687344600:3034,power,powerlinux,3034,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794#issuecomment-687344600,1,['power'],['powerlinux']
Energy Efficiency,broadinstitute) (9aa31e4) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/72684d0fae3326398c80e2f47d78eeff1fcc14fe?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) (72684d0) will **decrease** coverage by `0.001%`.; > The diff coverage is `100.000%`. ```diff; @@ Coverage Diff @@; ## master #7851 +/- ##; ===============================================; - Coverage 86.948% 86.947% -0.001% ; Complexity 36927 36927 ; ===============================================; Files 2219 2219 ; Lines 173673 173674 +1 ; Branches 18755 18755 ; ===============================================; - Hits 151006 151005 -1 ; + Misses 16055 16054 -1 ; - Partials 6612 6615 +3 ; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/7851?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute) | Coverage Δ | |; |---|---|---|; | [...rs/haplotypecaller/graphs/AdaptiveChainPruner.java](https://codecov.io/gh/broadinstitute/gatk/pull/7851/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvQWRhcHRpdmVDaGFpblBydW5lci5qYXZh) | `97.368% <100.000%> (+0.035%)` | :arrow_up: |; | [.../hellbender/utils/python/PythonUnitTestRunner.java](https://codecov.io/gh/broadinstitute/gatk/pull/7851/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9weXRob24vUHl0aG9uVW5pdFRlc3RSdW5uZXIuamF2YQ==) | `75.410% <0.000%> (-3.279%)` | :arrow_down: |; | [...itute/hellbender/tools/LocalAssemblerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7851/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7851#issuecomment-1126424538:1373,Adapt,AdaptiveChainPruner,1373,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7851#issuecomment-1126424538,1,['Adapt'],['AdaptiveChainPruner']
Energy Efficiency,"broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `84% <100%> (+0.66%)` | `43 <4> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/PathSpecifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUGF0aFNwZWNpZmllci5qYXZh) | `67.1% <0%> (+1.31%)` | `21% <0%> (+1%)` | :arrow_up: |; | [...institute/hellbender/engine/GATKPathSpecifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1BhdGhTcGVjaWZpZXIuamF2YQ==) | `48.21% <0%> (+1.78%)` | `16% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5832?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5832?src=pr&el=footer). Last update [aa8e807...d462900](https://codecov.io/gh/broadinstitute/gatk/pull/5832?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5832#issuecomment-476229094:2878,Power,Powered,2878,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5832#issuecomment-476229094,1,['Power'],['Powered']
Energy Efficiency,"bu.edu, executor 1, partition 2, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 0.0 (TID 5, scc-q11.scc.bu.edu, executor 6, partition 17, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 5, partition 0, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 7, scc-q02.scc.bu.edu, executor 8, partition 3, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 0.0 (TID 8, scc-q03.scc.bu.edu, executor 4, partition 13, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 9, scc-q13.scc.bu.edu, executor 3, partition 7, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 0.0 (TID 10, scc-q14.scc.bu.edu, executor 7, partition 8, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 0.0 (TID 11, scc-q12.scc.bu.edu, executor 2, partition 14, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 0.0 (TID 12, scc-q09.scc.bu.edu, executor 1, parti; ```. Processed 1,2 billion reads in less than 2 minutes..... ```; 18/03/07 20:32:55 INFO scheduler.DAGScheduler: Job 0 finished: aggregate at FlagStatSpark.java:73, took 64.566359 s; 1205535516 in total; 0 QC failure; 37791118 duplicates; 1157122594 mapped (95.98%); 1205535516 paired in sequencing; 602767758 read1; 602767758 read2; 1145853318 properly paired (95.05%); 1150449216 with itself and mate mapped; 6673378 singletons (0.55%); 4595898 with mate mapped to a different chr; 3316623 with mate mapped to a different chr (mapQ>=5); 18/03/07 20:32:55 INFO server.ServerConnector: Stopped ServerConnector@79f5a6ed{HTTP/1.1}{0.0.0.0:4041}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:8446,schedul,scheduler,8446,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,2,['schedul'],['scheduler']
Energy Efficiency,"c.). The run can be found in /dsde/working/slee/wgs-pon-test/tieout/no-gc. It completed successfully with **-Xmx32G** (in comparison, CreatePanelOfNormals crashed after 40 minutes with -Xmx128G). The runtime breakdown was as follows:. - ~45 minutes simply from reading of the 90 TSV read-count files in serial. Hopefully #3349 should greatly speed this up. (In comparison, CombineReadCounts reading 10 files in parallel at a time took ~100 minutes to create the aforementioned 20GB combined TSV file, creating 25+GB of temp files along the way.). - ~5 minutes from the preprocessing and filtering steps. We could probably further optimize some of this code in terms of speed and heap usage. (I had to throw in a call to System.gc() to avoid an OOM with -Xmx32G, which I encountered in my first attempt at the run...). - ~5 minutes from performing the SVD of the post-filtering 8643028 x 86 matrix, maintaining 30 eigensamples. I could write a quick implementation of randomized SVD, which I think could bring this down a bit (the scikit-learn implementation takes <2 minutes on a 10M x 100 matrix), but this can probably wait. Clearly making I/O faster and more space efficient is the highest priority. Luckily it's also low hanging fruit. The 8643028 x 30 matrix of eigenvectors takes <2 minutes to read from HDF5 when the WGS PoN is used in DenoiseReadCounts, which gives us a rough idea of how long it should take to read in the original ~11.5M x 90 counts from HDF5. So once #3349 is in, then I think that a **~15 minute single-core WGS PoN could easily be viable**. I believe that a PoN on the order of this size will be all that is required for WGS denoising, if it is not already overkill. To go bigger by more than an order of magnitude, we'll have to go out of core, which will require more substantial changes to the code. But since the real culprit responsible for hypersegmentation is CBS, rather than insufficient denoising, I'd rather focus on finding a viable segmentation alternative.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-317614503:1499,efficient,efficient,1499,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-317614503,2,['efficient'],['efficient']
Energy Efficiency,"c.bu.edu, executor 7, partition 4, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 0.0 (TID 3, scc-q12.scc.bu.edu, executor 2, partition 5, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 4, scc-q09.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 0.0 (TID 5, scc-q11.scc.bu.edu, executor 6, partition 17, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 5, partition 0, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 7, scc-q02.scc.bu.edu, executor 8, partition 3, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 0.0 (TID 8, scc-q03.scc.bu.edu, executor 4, partition 13, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 9, scc-q13.scc.bu.edu, executor 3, partition 7, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 0.0 (TID 10, scc-q14.scc.bu.edu, executor 7, partition 8, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 0.0 (TID 11, scc-q12.scc.bu.edu, executor 2, partition 14, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 0.0 (TID 12, scc-q09.scc.bu.edu, executor 1, parti; ```. Processed 1,2 billion reads in less than 2 minutes..... ```; 18/03/07 20:32:55 INFO scheduler.DAGScheduler: Job 0 finished: aggregate at FlagStatSpark.java:73, took 64.566359 s; 1205535516 in total; 0 QC failure; 37791118 duplicates; 1157122594 mapped (95.98%); 1205535516 paired in sequencing; 602767758 read1; 602767758 read2; 1145853318 properly paired (95.05%); 1150449216 w",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:8129,schedul,scheduler,8129,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,2,['schedul'],['scheduler']
Energy Efficiency,"c/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_libs__7473738539612638927.zip; 2019-01-07 11:33:38 INFO Client:54 - Uploading resource file:/tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed/__spark_conf__4147634812449814799.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_conf__.zip; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-07 11:33:38 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:38 INFO Client:54 - Submitting application application_1542127286896_0153 to ResourceManager; 2019-01-07 11:33:38 INFO YarnClientImpl:251 - Submitted application application_1542127286896_0153; 2019-01-07 11:33:38 INFO SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1542127286896_0153 and attemptId None; 2019-01-07 11:33:39 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:39 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1546878818531; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0153/; user: farrell; 2019-01-07 11:33:40 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:41 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:42 INFO Client:54 - Applic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:13021,Schedul,SchedulerExtensionServices,13021,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Schedul'],['SchedulerExtensionServices']
Energy Efficiency,"c/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_libs__7821719163562430010.zip; 2019-01-09 13:35:22 INFO Client:54 - Uploading resource file:/tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0/__spark_conf__4520928824604875683.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_conf__.zip; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-09 13:35:22 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:22 INFO Client:54 - Submitting application application_1542127286896_0166 to ResourceManager; 2019-01-09 13:35:22 INFO YarnClientImpl:251 - Submitted application application_1542127286896_0166; 2019-01-09 13:35:22 INFO SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1542127286896_0166 and attemptId None; 2019-01-09 13:35:23 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:23 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1547058922320; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0166/; user: farrell; 2019-01-09 13:35:24 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:25 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:26 INFO Client:54 - Applic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:12760,Schedul,SchedulerExtensionServices,12760,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Schedul'],['SchedulerExtensionServices']
Energy Efficiency,"c0b0f318c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9HQVRLU1ZWQ0ZIZWFkZXJMaW5lcy5qYXZh) | `0% <ø> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...ute/hellbender/tools/spark/sv/AlignmentRegion.java](https://codecov.io/gh/broadinstitute/gatk/compare/9c1d1fb2cc1aeb171e01764ee69c1544698e796d...f1380fe7f813931a2eb402867b07fb1c0b0f318c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9BbGlnbm1lbnRSZWdpb24uamF2YQ==) | `63.265% <100%> (+1.16%)` | `16 <2> (ø)` | :arrow_down: |; | [...lbender/tools/spark/sv/SVVariantConsensusCall.java](https://codecov.io/gh/broadinstitute/gatk/compare/9c1d1fb2cc1aeb171e01764ee69c1544698e796d...f1380fe7f813931a2eb402867b07fb1c0b0f318c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TVlZhcmlhbnRDb25zZW5zdXNDYWxsLmphdmE=) | `85.556% <80%> (ø)` | `21 <4> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/9c1d1fb2cc1aeb171e01764ee69c1544698e796d...f1380fe7f813931a2eb402867b07fb1c0b0f318c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2512?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2512?src=pr&el=footer). Last update [9c1d1fb...f1380fe](https://codecov.io/gh/broadinstitute/gatk/compare/9c1d1fb2cc1aeb171e01764ee69c1544698e796d...f1380fe7f813931a2eb402867b07fb1c0b0f318c?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2512#issuecomment-288291739:2719,Power,Powered,2719,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2512#issuecomment-288291739,1,['Power'],['Powered']
Energy Efficiency,c=pr&el=desc) will **increase** coverage by `0.012%`.; > The diff coverage is `86.42%`. ```diff; @@ Coverage Diff @@; ## master #5462 +/- ##; ===============================================; + Coverage 87.075% 87.087% +0.012% ; + Complexity 31334 31225 -109 ; ===============================================; Files 1921 1915 -6 ; Lines 144602 144079 -523 ; Branches 15951 15891 -60 ; ===============================================; - Hits 125912 125474 -438 ; + Misses 12896 12834 -62 ; + Partials 5794 5771 -23; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5462?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...s/walkers/haplotypecaller/graphs/PathUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5462/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvUGF0aFVuaXRUZXN0LmphdmE=) | `93.258% <ø> (-0.22%)` | `7 <0> (ø)` | |; | [...rs/haplotypecaller/graphs/AdaptiveChainPruner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5462/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvQWRhcHRpdmVDaGFpblBydW5lci5qYXZh) | `95.349% <100%> (ø)` | `16 <0> (ø)` | :arrow_down: |; | [...ller/readthreading/ReadThreadingGraphUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5462/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9yZWFkdGhyZWFkaW5nL1JlYWRUaHJlYWRpbmdHcmFwaFVuaXRUZXN0LmphdmE=) | `95.238% <100%> (+0.018%)` | `55 <0> (ø)` | :arrow_down: |; | [...rs/haplotypecaller/graphs/ChainPrunerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5462/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvQ2hhaW5QcnVuZXJVbml0VGVzdC5qYXZh) | `99.194% <100%> (-0.006%)` | `40 <0> (ø)` | |; | [...der/t,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5462#issuecomment-450062027:1281,Adapt,AdaptiveChainPruner,1281,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5462#issuecomment-450062027,1,['Adapt'],['AdaptiveChainPruner']
Energy Efficiency,"c=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwZUNhbGN1bGF0aW9uQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `100% <ø> (ø)` | `2 <0> (ø)` | :x: |; | [...nder/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/compare/5d2f859db87f60a0f5b5f0ed7f73e39ebae09bec...ed0b8cac3375023f23d5c0bd8a31ee155d707dae?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nRW5naW5lLmphdmE=) | `46.903% <33.333%> (ø)` | `32 <0> (ø)` | :x: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/5d2f859db87f60a0f5b5f0ed7f73e39ebae09bec...ed0b8cac3375023f23d5c0bd8a31ee155d707dae?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :white_check_mark: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/5d2f859db87f60a0f5b5f0ed7f73e39ebae09bec...ed0b8cac3375023f23d5c0bd8a31ee155d707dae?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :x: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2314?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2314?src=pr&el=footer). Last update [5d2f859...ed0b8ca](https://codecov.io/gh/broadinstitute/gatk/compare/5d2f859db87f60a0f5b5f0ed7f73e39ebae09bec...ed0b8cac3375023f23d5c0bd8a31ee155d707dae?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2314#issuecomment-267118800:2738,Power,Powered,2738,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2314#issuecomment-267118800,1,['Power'],['Powered']
Energy Efficiency,catable); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:144); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:362); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.NullPointerException; 	at htsjdk.variant.variantcontext.LazyGenotypesContext.decode(LazyGenotypesContext.java:158); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.invalidateSampleOrdering(LazyGenotypesContext.java:205); 	at htsjdk.variant.variantcontext.GenotypesContext.add(GenotypesContext.java:353,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:7198,schedul,scheduler,7198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,"cc.bu.edu, executor 3, partition 6, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 2, scc-q14.scc.bu.edu, executor 7, partition 4, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 0.0 (TID 3, scc-q12.scc.bu.edu, executor 2, partition 5, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 4, scc-q09.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 0.0 (TID 5, scc-q11.scc.bu.edu, executor 6, partition 17, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 5, partition 0, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 7, scc-q02.scc.bu.edu, executor 8, partition 3, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 0.0 (TID 8, scc-q03.scc.bu.edu, executor 4, partition 13, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 9, scc-q13.scc.bu.edu, executor 3, partition 7, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 0.0 (TID 10, scc-q14.scc.bu.edu, executor 7, partition 8, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 0.0 (TID 11, scc-q12.scc.bu.edu, executor 2, partition 14, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 0.0 (TID 12, scc-q09.scc.bu.edu, executor 1, parti; ```. Processed 1,2 billion reads in less than 2 minutes..... ```; 18/03/07 20:32:55 INFO scheduler.DAGScheduler: Job 0 finished: aggregate at FlagStatSpark.java:73, took 64.566359 s; 1205535516 in total; 0 QC failure; 37791",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:7969,schedul,scheduler,7969,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,2,['schedul'],['scheduler']
Energy Efficiency,"cc.bu.edu, executor 4, partition 1, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 0.0 (TID 1, scc-q13.scc.bu.edu, executor 3, partition 6, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 2, scc-q14.scc.bu.edu, executor 7, partition 4, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 0.0 (TID 3, scc-q12.scc.bu.edu, executor 2, partition 5, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 4, scc-q09.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 0.0 (TID 5, scc-q11.scc.bu.edu, executor 6, partition 17, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 5, partition 0, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 7, scc-q02.scc.bu.edu, executor 8, partition 3, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 0.0 (TID 8, scc-q03.scc.bu.edu, executor 4, partition 13, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 9, scc-q13.scc.bu.edu, executor 3, partition 7, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 0.0 (TID 10, scc-q14.scc.bu.edu, executor 7, partition 8, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 0.0 (TID 11, scc-q12.scc.bu.edu, executor 2, partition 14, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 0.0 (TID 12, scc-q09.scc.bu.edu, executor 1, parti; ```. Processed 1,2 billion reads in less than 2 minutes..... ```;",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:7811,schedul,scheduler,7811,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,2,['schedul'],['scheduler']
Energy Efficiency,"ce326-baa5-4052-bff9-bd684393ff6c/call-CHMSampleHeadToHead/BenchmarkComparison/a1db35b8-cc7b-4019-bdd0-9f423762542e/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd684393ff6c/call-CHMSampleHeadToHead/BenchmarkComparison/a1db35b8-cc7b-4019-bdd0-9f423762542e/call-BenchmarkVCFControlSample/Benchmark/7195c554-534f-43ef-80c2-77bdafa1827f/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""78.10181666666668"",; ""CHM evalHCsystemhours"": ""0.16157500000000005"",; ""CHM evalHCwallclockhours"": ""55.006172222222226"",; ""CHM evalHCwallclockmax"": ""2.8554194444444443"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd684393ff6c/call-CHMSampleHeadToHead/BenchmarkComparison/a1db35b8-cc7b-4019-bdd0-9f423762542e/call-EVALRuntimeTask/monitoring.pdf"",; ""CHM evalindelF1Score"": ""0.8724"",; ""CHM evalindelPrecision"": ""0.8814"",; ""CHM evalsnpF1Score"": ""0.9784"",; ""CHM evalsnpPrecision"": ""0.9706"",; ""CHM evalsnpRecall"": ""0.9863"",; ""CHM evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd684393ff6c/call-CHMSampleHeadToHead/BenchmarkComparison/a1db35b8-cc7b-4019-bdd0-9f423762542e/call-BenchmarkVCFTestSample/Benchmark/5c4f9069-86b3-4d8c-b765-38a67169e4b4/call-CombineSummaries/summary.csv"",; ""EXOME1 controlindelF1Score"": ""0.727"",; ""EXOME1 controlindelPrecision"": ""0.632"",; ""EXOME1 controlsnpF1Score"": ""0.9878"",; ""EXOME1 controlsnpPrecision"": ""0.9815"",; ""EXOME1 controlsnpRecall"": ""0.9941"",; ""EXOME1 controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd684393ff6c/call-EXOME1SampleHead",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1194801748:17683,monitor,monitoring,17683,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1194801748,1,['monitor'],['monitoring']
Energy Efficiency,"ce:54 - Server created on scc-hadoop.bu.edu:45270; 2019-01-07 11:33:53 INFO BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 2019-01-07 11:33:53 INFO BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, scc-hadoop.bu.edu, 45270, None); 2019-01-07 11:33:53 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-hadoop.bu.edu:45270 with 408.6 MB RAM, BlockManagerId(driver, scc-hadoop.bu.edu, 45270, None); 2019-01-07 11:33:53 INFO BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, scc-hadoop.bu.edu, 45270, None); 2019-01-07 11:33:53 INFO BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, scc-hadoop.bu.edu, 45270, None); 2019-01-07 11:33:54 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60251ddb{/metrics/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:58 INFO YarnClientSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms); 2019-01-07 11:33:59 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.18.196:49862) with ID 2; 2019-01-07 11:33:59 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-q12.scc.bu.edu:38418 with 366.3 MB RAM, BlockManagerId(2, scc-q12.scc.bu.edu, 38418, None); 2019-01-07 11:33:59 INFO MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 1229.0 KB, free 407.4 MB); 2019-01-07 11:34:00 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.18.229:59962) with ID 1; 2019-01-07 11:34:00 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-q21.scc.bu.edu:41630 with 366.3 MB RAM, BlockManagerId(1, scc-q21.scc.bu.edu, 41630, None); 2019-01-07 11:34:00 INFO MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 113.9 KB, free 40",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:17343,schedul,scheduling,17343,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,3,"['Schedul', 'schedul']","['SchedulerBackend', 'scheduling']"
Energy Efficiency,"cf7fa54b8785c87a919f1951151789?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZU1hbmFnZXIuamF2YQ==) | `86.592% <ø> (+1.025%)` | `78% <ø> (+34%)` | :white_check_mark: |; | [...tute/hellbender/engine/MultiVariantDataSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/6f9de16d16eff4fe9d02dc9c6c9884d768c3cc43...7247260205cf7fa54b8785c87a919f1951151789?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvTXVsdGlWYXJpYW50RGF0YVNvdXJjZS5qYXZh) | `84.106% <ø> (+2.001%)` | `52% <ø> (+18%)` | :white_check_mark: |; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/compare/6f9de16d16eff4fe9d02dc9c6c9884d768c3cc43...7247260205cf7fa54b8785c87a919f1951151789?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `72.105% <ø> (+2.54%)` | `4% <ø> (ø)` | :x: |; | [...rg/broadinstitute/hellbender/utils/io/IOUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/6f9de16d16eff4fe9d02dc9c6c9884d768c3cc43...7247260205cf7fa54b8785c87a919f1951151789?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pby9JT1V0aWxzLmphdmE=) | `65.704% <ø> (+8.146%)` | `88% <ø> (+45%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2391?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2391?src=pr&el=footer). Last update [6f9de16...7247260](https://codecov.io/gh/broadinstitute/gatk/compare/6f9de16d16eff4fe9d02dc9c6c9884d768c3cc43...7247260205cf7fa54b8785c87a919f1951151789?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2391#issuecomment-278096683:3842,Power,Powered,3842,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2391#issuecomment-278096683,1,['Power'],['Powered']
Energy Efficiency,che.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.s,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690:7080,schedul,scheduler,7080,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690,1,['schedul'],['scheduler']
Energy Efficiency,"ci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nRW5naW5lLmphdmE=) | `46.491% <0%> (-2.632%)` | `32% <0%> (-9%)` | |; | [...lbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzLmphdmE=) | `77.996% <0%> (-0.179%)` | `175% <0%> (-1%)` | |; | [...ellbender/tools/walkers/annotator/QualByDepth.java](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9RdWFsQnlEZXB0aC5qYXZh) | `94.444% <0%> (-0.15%)` | `16% <0%> (-1%)` | |; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `85.484% <0%> (-0.116%)` | `49% <0%> (-1%)` | |; | [...ender/tools/walkers/annotator/InbreedingCoeff.java](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9JbmJyZWVkaW5nQ29lZmYuamF2YQ==) | `82.759% <0%> (ø)` | `11% <0%> (ø)` | :arrow_down: |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=footer). Last update [62d58c5...0492c9c](https://codecov.io/gh/broadinstitute/gatk/pull/2559?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2559#issuecomment-290845420:4321,Power,Powered,4321,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2559#issuecomment-290845420,1,['Power'],['Powered']
Energy Efficiency,"ck manager 10.131.101.159:44818 with 366.3 MB RAM, BlockManagerId(driver, 10.131.101.159, 44818, None); 17/10/13 18:11:42 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.131.101.159, 44818, None); 17/10/13 18:11:42 INFO storage.BlockManager: external shuffle service port = 7337; 17/10/13 18:11:42 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.131.101.159, 44818, None); 17/10/13 18:11:42 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@544300a6{/metrics/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:42 INFO scheduler.EventLoggingListener: Logging events to hdfs://mg:8020/user/spark/spark2ApplicationHistory/application_1507856833944_0003; 17/10/13 18:11:42 INFO util.Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances; 17/10/13 18:11:43 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8; 17/10/13 18:11:43 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 286.0 KB, free 366.0 MB); 17/10/13 18:11:44 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 26.0 KB, free 366.0 MB); 17/10/13 18:11:44 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.131.101.159:44818 (size: 26.0 KB, free: 366.3 MB); 17/10/13 18:11:44 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 17/10/13 18:11:44 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.5 KB, free 366.0 MB); 17/10/13 18:11:44 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.0 MB); 17/10/13 18:11:44 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.131.101.159:44818 (size: 2.1 KB, free: 366.3 MB); 17/10/13 18",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:14866,schedul,scheduling,14866,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,3,"['Schedul', 'schedul']","['SchedulerBackend', 'scheduling']"
Energy Efficiency,cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:515); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	... 41 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 47 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727:5383,Meter,MeteredStream,5383,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727,1,['Meter'],['MeteredStream']
Energy Efficiency,cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:515); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	... 49 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:8871,Meter,MeteredStream,8871,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138,1,['Meter'],['MeteredStream']
Energy Efficiency,"cmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `66.667% <0%> (+3.252%)` | `4% <0%> (ø)` | :arrow_down: |; | [...g/broadinstitute/hellbender/engine/AuthHolder.java](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvQXV0aEhvbGRlci5qYXZh) | `15.254% <0%> (+5.085%)` | `2% <0%> (ø)` | :arrow_down: |; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `77.703% <0%> (+6.757%)` | `22% <0%> (+4%)` | :arrow_up: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `86.4% <0%> (+8.8%)` | `35% <0%> (+7%)` | :arrow_up: |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `23.729% <0%> (+13.559%)` | `2% <0%> (+1%)` | :arrow_up: |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=footer). Last update [5ccfd00...8360cbe](https://codecov.io/gh/broadinstitute/gatk/pull/2573?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2573#issuecomment-291977600:3974,Power,Powered,3974,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2573#issuecomment-291977600,1,['Power'],['Powered']
Energy Efficiency,"cotationFactory.createDefaultFuncotationsOnVariant(GencodeFuncotationFactory.java:499); 22 Jun 2023 14:54:27,163 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:217); 22 Jun 2023 14:54:27,164 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); 22 Jun 2023 14:54:27,166 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:152); 22 Jun 2023 14:54:27,167 DEBUG: 		at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197); 22 Jun 2023 14:54:27,168 DEBUG: 		at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:179); 22 Jun 2023 14:54:27,170 DEBUG: 		at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1625); 22 Jun 2023 14:54:27,171 DEBUG: 		at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509); 22 Jun 2023 14:54:27,172 DEBUG: 		at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499); 22 Jun 2023 14:54:27,174 DEBUG: 		at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:921); 22 Jun 2023 14:54:27,175 DEBUG: 		at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 22 Jun 2023 14:54:27,177 DEBUG: 		at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:682); 22 Jun 2023 14:54:27,178 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:162); 22 Jun 2023 14:54:27,180 DEBUG: 		at com.github.discvrseq.walkers.ExtendedFuncotator.enqueueAndHandleVariant(ExtendedFuncotator.java:209); 22 Jun 2023 14:54:27,181 DEBUG: 		at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:878); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1603412226:2901,Reduce,ReduceOps,2901,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8363#issuecomment-1603412226,3,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:1025); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:847); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:831); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:508); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:509); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.Fun,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680:2169,Reduce,ReduceOps,2169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680,1,['Reduce'],['ReduceOps']
Energy Efficiency,culateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-29T18:18:04.001846904Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-29T18:18:04.002024760Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002358113Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-29T18:18:04.002377342Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-29T18:18:04.002383406Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002431769Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePas,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:1934,Reduce,ReduceOps,1934,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300,1,['Reduce'],['ReduceOps']
Energy Efficiency,culateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-30T13:35:51.792905235Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-30T13:35:51.793072365Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-30T13:35:51.793261944Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-30T13:35:51.793456807Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-30T13:35:51.793619935Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-30T13:35:51.793810301Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.794006885Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.794191116Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-30T13:35:51.794367593Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-30T13:35:51.794548129Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-30T13:35:51.794722501Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-30T13:35:51.794896154Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-30T13:35:51.795082090Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-30T13:35:51.795253632Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-30T13:35:51.795448274Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePas,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:1935,Reduce,ReduceOps,1935,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227,1,['Reduce'],['ReduceOps']
Energy Efficiency,"d by some of the discussion and work by @mbabadi in #4558, I quickly revisited the revision of the ploidy model. The key difference is now we use the per-contig coverage *histogram* (rather than just the per-contig total coverage). This histogram conveys a lot more information and, with some naive filtering (see more discussion in #4558), provides relatively easy peaks to fit. I think this is a better solution than subsampling intervals and fitting a model that would require modeling per-interval bias. Another key change I added was to provide *per-genotype* priors, rather than per-contig priors. For the autosomes, this is immaterial, but it's extremely useful for the allosomes. That is, we currently provide per-contig priors like so:. ````; CONTIG PLOIDY_0 PLOIDY_1 PLOIDY_2 PLOIDY_3; 1 0.0 0.0 1.0 0.0; ...; X 0.01 0.48 0.48 0.01; Y 0.48 0.48 0.01 0.01; ````. However, note that this implies that X and XXY are just as probable as XX and XY! It's much more powerful to be able to specify *per-genotype* priors (although this requires a bit more bookkeeping when translating to implications for per-contig histograms):. ````; CONTIG_SET PLOIDY_STATE RELATIVE_PROBABILITY; (1) (2) 1.0; ...; (X,Y) (2,0) 1.0; (X,Y) (1,1) 1.0; (X,Y) (1,0) 0.01; (X,Y) (2,1) 0.01; (X,Y) (1,2) 0.01; (X,Y) (3,0) 0.01; ````. We then fit the per-contig coverage histograms across all samples with the appropriate negative-binomial distributions corresponding to a sparse mixture of genotypes, while accounting for 1) sample-specific depth (which determines the means of the negative-binomial distributions), 2) multiplicative contig-specific bias (which is mild, at least for WGS), and 3) additive sample-contig-specific mosaicism or bias (note that the above genotype priors imply that mosaicism/bias on top of a baseline of CN = 2 is the only deviation allowed for the autosomes, which is somewhat restrictive but greatly aids convergence). I put together a pure PyMC3 prototype that seems to work relatively wel",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271:977,power,powerful,977,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271,2,['power'],['powerful']
Energy Efficiency,d in https://github.com/samtools/htsjdk/pull/724. . ```; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); 	at org.apache.spark.rdd.RDD.c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285797337:1108,schedul,scheduler,1108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285797337,1,['schedul'],['scheduler']
Energy Efficiency,d); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); at org.apache.spark.rdd.RDD.count(RDD.scala:1158); at org.apache.spark.api.java.JavaRDDLike$cla,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:41959,schedul,scheduler,41959,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['schedul'],['scheduler']
Energy Efficiency,d.test(ReadFilter.java:70); 	at org.broadinstitute.hellbender.engine.filters.WellformedReadFilter.test(WellformedReadFilter.java:77); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.lambda$getReads$e4b35a40$1(GATKSparkTool.java:213); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool$$Lambda$93/2063469002.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:76); 	at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:76); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn.lambda$apply$5412c5cb$1(ApplyBQSRSparkFn.java:22); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn$$Lambda$214/1243271334.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.sca,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:2447,Reduce,ReduceOps,2447,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"dToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-CHMSampleHeadToHead/BenchmarkComparison/deb85607-d693-4232-a4da-0fb88dd29cad/call-CONTROLRuntimeTask/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-CHMSampleHeadToHead/BenchmarkComparison/deb85607-d693-4232-a4da-0fb88dd29cad/call-BenchmarkVCFControlSample/Benchmark/c0877490-fd2d-4f42-bb92-f06210e94d95/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""84.33091111111112"",; ""CHM evalHCsystemhours"": ""0.18621944444444444"",; ""CHM evalHCwallclockhours"": ""61.43"",; ""CHM evalHCwallclockmax"": ""3.073069444444444"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-CHMSampleHeadToHead/BenchmarkComparison/deb85607-d693-4232-a4da-0fb88dd29cad/call-EVALRuntimeTask/monitoring.pdf"",; ""CHM evalindelF1Score"": ""0.8724"",; ""CHM evalindelPrecision"": ""0.8814"",; ""CHM evalsnpF1Score"": ""0.9784"",; ""CHM evalsnpPrecision"": ""0.9706"",; ""CHM evalsnpRecall"": ""0.9863"",; ""CHM evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-CHMSampleHeadToHead/BenchmarkComparison/deb85607-d693-4232-a4da-0fb88dd29cad/call-BenchmarkVCFTestSample/Benchmark/a15fdeb6-16e8-48d7-82cb-168726f4dc18/call-CombineSummaries/summary.csv"",; ""EXOME1 controlindelF1Score"": ""0.727"",; ""EXOME1 controlindelPrecision"": ""0.632"",; ""EXOME1 controlsnpF1Score"": ""0.9878"",; ""EXOME1 controlsnpPrecision"": ""0.9815"",; ""EXOME1 controlsnpRecall"": ""0.9941"",; ""EXOME1 controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-EXOME1SampleHead",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1549231169:18345,monitor,monitoring,18345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1549231169,1,['monitor'],['monitoring']
Energy Efficiency,"de06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:07 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 3, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:07 WARN TaskSetManager:66 - Lost task 3.0 in stage 0.0 (TID 2, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.coll",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:24865,schedul,scheduler,24865,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['schedul'],['scheduler']
Energy Efficiency,"de06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:49 INFO TaskSetManager:54 - Starting task 7.0 in stage 0.0 (TID 3, scc-q01.scc.bu.edu, executor 1, partition 7, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:49 WARN TaskSetManager:66 - Lost task 2.0 in stage 0.0 (TID 1, scc-q01.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.co",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:24152,schedul,scheduler,24152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['schedul'],['scheduler']
Energy Efficiency,"de06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-07 11:34:12 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 9.419880 s; 2019-01-07 11:34:12 INFO AbstractConnector:318 - Stopped Spark@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:34:12 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-07 11:34:12 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-07 11:34:12 INFO SchedulerExtensionServices:54 - Stopping SchedulerExten",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:34770,schedul,scheduler,34770,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['schedul'],['scheduler']
Energy Efficiency,"de06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-09 13:35:56 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 12.691336 s; 2019-01-09 13:35:56 INFO AbstractConnector:318 - Stopped Spark@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:56 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-09 13:35:56 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-09 13:35:56 INFO SchedulerExtensionServices:54 - Stopping SchedulerExt",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:34520,schedul,scheduler,34520,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['schedul'],['scheduler']
Energy Efficiency,de06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:37986,schedul,scheduler,37986,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,4,['schedul'],['scheduler']
Energy Efficiency,de06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-ed279998-3783-4f41-8fe5-f44a4fac3ee4; ```. CountReads runs fine..... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:42881,schedul,scheduler,42881,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['schedul'],['scheduler']
Energy Efficiency,"de06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-0bd07e00-4f6d-43bd-b9d2-b1999376c72b; ```. Just to verify, the non-spark version still runs fine with the compressed fasta.... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference GRCh38_full_analysis_set_plus_decoy_hla.fa.gz; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:42633,schedul,scheduler,42633,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['schedul'],['scheduler']
Energy Efficiency,"der/utils/MannWhitneyU.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9NYW5uV2hpdG5leVUuamF2YQ==) | `92.793% <92.593%> (+17.237%)` | `48 <48> (+21)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `72.078% <0%> (-1.948%)` | `35% <0%> (ø)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `93.75% <0%> (-1.563%)` | `21% <0%> (-1%)` | |; | [...titute/hellbender/tools/spark/sv/ReadMetadata.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkTWV0YWRhdGEuamF2YQ==) | `84.104% <0%> (+2.358%)` | `36% <0%> (+11%)` | :arrow_up: |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `42.989% <0%> (+4.441%)` | `46% <0%> (+18%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=footer). Last update [c350a09...3b4f53e](https://codecov.io/gh/broadinstitute/gatk/pull/2605?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2605#issuecomment-294213579:3261,Power,Powered,3261,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2605#issuecomment-294213579,1,['Power'],['Powered']
Energy Efficiency,"dpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.131.101.145:54024) with ID 1; 17/10/13 18:11:48 INFO spark.ExecutorAllocationManager: New executor 1 has registered (new total is 1); 17/10/13 18:11:48 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, com2, executor 1, partition 0, NODE_LOCAL, 4877 bytes); 17/10/13 18:11:48 INFO storage.BlockManagerMasterEndpoint: Registering block manager com2:45501 with 366.3 MB RAM, BlockManagerId(1, com2, 45501, None); 17/10/13 18:11:50 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on com2:45501 (size: 7.3 KB, free: 366.3 MB); 17/10/13 18:11:51 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on com2:45501 (size: 26.0 KB, free: 366.3 MB); 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4638 ms on com2 (executor 1) (1/1); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool ; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (mapToPair at SparkUtils.java:157) finished in 8.668 s; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: looking for newly runnable stages; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: running: Set(); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: failed: Set(); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/13 18:11:53 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.8 KB, free 365.9 MB); 17/10/13 18:11:53 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KB, free 365.8 MB); 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.131.101.159:44818 (size: 32.6 KB, free: 366.2 MB); 17/10/13 18:11:53 I",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:19143,schedul,scheduler,19143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['schedul'],['scheduler']
Energy Efficiency,"dsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `93.103% <100%> (+1.103%)` | `8 <1> (+1)` | :arrow_up: |; | [...adinstitute/hellbender/utils/spark/SparkUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zcGFyay9TcGFya1V0aWxzLmphdmE=) | `71.154% <63.158%> (-4.604%)` | `9 <5> (+5)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `95.313% <0%> (+1.563%)` | `22% <0%> (+1%)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `75.909% <0%> (+3.831%)` | `46% <0%> (+11%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=footer). Last update [2ecdef4...71a1b94](https://codecov.io/gh/broadinstitute/gatk/pull/2419?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2419#issuecomment-293289091:3280,Power,Powered,3280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2419#issuecomment-293289091,1,['Power'],['Powered']
Energy Efficiency,e(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690:7315,schedul,scheduler,7315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690,1,['schedul'],['scheduler']
Energy Efficiency,"e40-2025-46fd-9aa0-d591a3799007/call-CHMSampleHeadToHead/BenchmarkComparison/f65a7960-7b66-4a5d-a346-bd188a1b3830/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-CHMSampleHeadToHead/BenchmarkComparison/f65a7960-7b66-4a5d-a346-bd188a1b3830/call-BenchmarkVCFControlSample/Benchmark/8d0e47ca-66f5-42a0-8785-6aa8d2db2663/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""80.5165222222222"",; ""CHM evalHCsystemhours"": ""0.1713305555555555"",; ""CHM evalHCwallclockhours"": ""53.10978888888891"",; ""CHM evalHCwallclockmax"": ""2.7458416666666667"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-CHMSampleHeadToHead/BenchmarkComparison/f65a7960-7b66-4a5d-a346-bd188a1b3830/call-EVALRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM evalindelF1Score"": ""0.8724"",; ""CHM evalindelPrecision"": ""0.8814"",; ""CHM evalsnpF1Score"": ""0.9784"",; ""CHM evalsnpPrecision"": ""0.9706"",; ""CHM evalsnpRecall"": ""0.9863"",; ""CHM evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-CHMSampleHeadToHead/BenchmarkComparison/f65a7960-7b66-4a5d-a346-bd188a1b3830/call-BenchmarkVCFTestSample/Benchmark/96c96714-3ac6-4d2b-a79c-57086cda6373/call-CombineSummaries/summary.csv"",; ""EXOME1 controlindelF1Score"": ""0.727"",; ""EXOME1 controlindelPrecision"": ""0.632"",; ""EXOME1 controlsnpF1Score"": ""0.9878"",; ""EXOME1 controlsnpPrecision"": ""0.9815"",; ""EXOME1 controlsnpRecall"": ""0.9941"",; ""EXOME1 controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-EXOME1Sampl",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069378815:11455,monitor,monitoring,11455,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069378815,1,['monitor'],['monitoring']
Energy Efficiency,eFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:152); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:162); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:924); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:878); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.Iterator.forEa,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680:3759,Reduce,ReduceOps,3759,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680,1,['Reduce'],['ReduceOps']
Energy Efficiency,eader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at org.seqdoop.hadoop_bam.BAMRecordReader.nextKeyValue(BAMRecordReader.java:225); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:182); 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn.lambda$apply$5412c5cb$1(ApplyBQSRSparkFn.java:22); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn$$Lambda$214/1243271334.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.sca,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:7498,Reduce,ReduceOps,7498,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,eatureDataSource.java:324); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:304); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:256); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:230); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:214); 	at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.openFeatureSource(JoinReadsWithVariants.java:63); 	at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$null$0(JoinReadsWithVariants.java:44); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$join$60e5b476$1(JoinReadsWithVariants.java:44); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49); 	at org.apache.spark.rdd.RDD.compu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5979#issuecomment-498620174:2152,Reduce,ReduceOps,2152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5979#issuecomment-498620174,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"ecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-07 11:34:12 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 9.419880 s; 2019-01-07 11:34:12 INFO AbstractConnector:318 - Stopped Spark@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:34:12 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-07 11:34:12 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-07 11:34:12 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-07 11:34:12 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-07 11:34:12 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-07 11:34:12 INFO BlockManager:54 - BlockManager stopped; 2019-01-07 11:34:12 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-07 11:34:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-07 11:34:12 INFO SparkContext:54 - Successfully stopped SparkContext; 11:34:12.605 INFO CountReadsSpark - Shutting down engine; [January 7, 2019 11:34:12 AM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=1003487232; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:35488,monitor,monitor,35488,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,4,"['Schedul', 'monitor']","['SchedulerExtensionServices', 'monitor']"
Energy Efficiency,ed time: 0.34 minutes.; Runtime.totalMemory()=1106771968; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: java.lang.NullPointerException; Serialization trace:; genotypes (htsjdk.variant.variantcontext.VariantContext); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074); 	at org.apache.spark.SparkContext.runJob(Spar,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:9950,schedul,scheduler,9950,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,ed=false disableDithering=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 baq=OFF baqGapOpenPenalty=40.0 refactor_NDN_cigar_string=false fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false useOriginalQualities=false defaultBaseQualities=-1 performanceLog=null BQSR=null quantize_quals=0 static_quantized_quals=null round_down_quantized=false disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 globalQScorePrior=-1.0 validation_strictness=SILENT remove_program_records=false keep_program_records=false sample_rename_mapping_file=null unsafe=null disable_auto_index_creation_and_locking_when_reading_rods=false no_cmdline_in_header=false sites_only=false never_trim_vcf_format_field=false bcf=false bam_compression=null simplifyBAM=false disable_bam_indexing=false generate_md5=false num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false variant_index_type=DYNAMIC_SEEK variant_index_parameter=-1 reference_window_stop=0 logging_level=INFO log_to_file=null help=false version=false variant=(RodBinding name=variant source=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/GTEx_AS/GTEx_AS.recal.multialleleics.AS.recalibrated.vcf) discordance=(RodBinding name= source=UNBOUND) concordance=(RodBinding name= source=UNBOUND) out=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/GTEx_AS/GTEx_AS.recal.multialleleics.AS.recalibrated.mixed.vcf sample_name=[] sample_expressions=null sample_file=null exclude_sample_name=[] exclude_sample_file=[] exclude_sample_expressions=[] selectexpressions=[] invertselect=false excludeNonVariants=false excludeFiltered=false preserveAlleles=false removeUnusedAlternates=false restrictAllelesTo=ALL keepOriginalAC=false ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834:4706,monitor,monitorThreadEfficiency,4706,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834,2,['monitor'],['monitorThreadEfficiency']
Energy Efficiency,ed=false disableDithering=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 baq=OFF baqGapOpenPenalty=40.0 refactor_NDN_cigar_string=false fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false useOriginalQualities=false defaultBaseQualities=-1 performanceLog=null BQSR=null quantize_quals=0 static_quantized_quals=null round_down_quantized=false disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 globalQScorePrior=-1.0 validation_strictness=SILENT remove_program_records=false keep_program_records=false sample_rename_mapping_file=null unsafe=null disable_auto_index_creation_and_locking_when_reading_rods=false no_cmdline_in_header=false sites_only=true never_trim_vcf_format_field=false bcf=false bam_compression=null simplifyBAM=false disable_bam_indexing=false generate_md5=false num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false variant_index_type=DYNAMIC_SEEK variant_index_parameter=-1 reference_window_stop=0 logging_level=INFO log_to_file=null help=false version=false variant=(RodBinding name=variant source=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/GTEx_AS/GTEx_AS.recal.multialleleics.AS.recalibrated.mixed.vcf) discordance=(RodBinding name= source=UNBOUND) concordance=(RodBinding name= source=UNBOUND) out=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/VQSR.AStest.input.vcf sample_name=[] sample_expressions=null sample_file=null exclude_sample_name=[] exclude_sample_file=[] exclude_sample_expressions=[] selectexpressions=[] invertselect=false excludeNonVariants=false excludeFiltered=false preserveAlleles=false removeUnusedAlternates=false restrictAllelesTo=ALL keepOriginalAC=false keepOriginalDP=false mendelianViola,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834:1598,monitor,monitorThreadEfficiency,1598,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834,2,['monitor'],['monitorThreadEfficiency']
Energy Efficiency,"ee#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9mZXJtaS9GZXJtaUxpdGVBc3NlbWJsZXIuamF2YQ==) | `80.645% <80.645%> (ø)` | `8 <8> (?)` | |; | [...stitute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...d6fb1ba347fbb8042e8473870fbffec02e211349?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `92.308% <ø> (+0.447%)` | `28% <ø> (+28%)` | :white_check_mark: |; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...d6fb1ba347fbb8042e8473870fbffec02e211349?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `87.097% <ø> (+0.986%)` | `59% <ø> (+59%)` | :white_check_mark: |; | [...adinstitute/hellbender/tools/spark/sv/SVUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...d6fb1ba347fbb8042e8473870fbffec02e211349?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TVlV0aWxzLmphdmE=) | `38.462% <ø> (+5.52%)` | `12% <ø> (+12%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2381?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2381?src=pr&el=footer). Last update [8a42977...d6fb1ba](https://codecov.io/gh/broadinstitute/gatk/compare/8a42977d248c4257e4fcbf2f69e21ab787ba3866...d6fb1ba347fbb8042e8473870fbffec02e211349?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2381#issuecomment-276803321:3433,Power,Powered,3433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2381#issuecomment-276803321,1,['Power'],['Powered']
Energy Efficiency,"el=desc) will **decrease** coverage by `-<.001%`.; > The diff coverage is `75%`. ```diff; @@ Coverage Diff @@; ## master #2366 +/- ##; ===============================================; - Coverage 76.201% 76.201% -<.001% ; - Complexity 10808 10812 +4 ; ===============================================; Files 750 750 ; Lines 39417 39421 +4 ; Branches 6858 6859 +1 ; ===============================================; + Hits 30036 30039 +3 ; Misses 6775 6775 ; - Partials 2606 2607 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2366?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ellbender/cmdline/StandardArgumentDefinitions.java](https://codecov.io/gh/broadinstitute/gatk/compare/f45f6a52d69fbf01541099cf737a0fc5391d584e...75c14f4c17c957aa969a69a94c966fad3d5c8f1d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL1N0YW5kYXJkQXJndW1lbnREZWZpbml0aW9ucy5qYXZh) | `0% <ø> (ø)` | `0 <ø> (ø)` | :x: |; | [...org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/compare/f45f6a52d69fbf01541099cf737a0fc5391d584e...75c14f4c17c957aa969a69a94c966fad3d5c8f1d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2wuamF2YQ==) | `92.568% <75%> (-0.488%)` | `74 <2> (+3)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2366?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2366?src=pr&el=footer). Last update [f45f6a5...75c14f4](https://codecov.io/gh/broadinstitute/gatk/compare/f45f6a52d69fbf01541099cf737a0fc5391d584e...75c14f4c17c957aa969a69a94c966fad3d5c8f1d?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2366#issuecomment-276527211:1915,Power,Powered,1915,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2366#issuecomment-276527211,1,['Power'],['Powered']
Energy Efficiency,"el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0dlbm90eXBlR1ZDRnMuamF2YQ==) | `90.71% <0%> (-0.43%)` | `100% <0%> (-1%)` | |; | [...lbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzLmphdmE=) | `87.3% <0%> (-0.31%)` | `244% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.77% <0%> (+0.47%)` | `33% <0%> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `80% <0%> (+30%)` | `3% <0%> (+2%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5844?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5844?src=pr&el=footer). Last update [7c24e67...43708f1](https://codecov.io/gh/broadinstitute/gatk/pull/5844?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5844#issuecomment-477765576:3591,Power,Powered,3591,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5844#issuecomment-477765576,1,['Power'],['Powered']
Energy Efficiency,ellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363); 	at org.apache.spark.rdd.RDD.c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:10295,schedul,scheduler,10295,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,"emoved TaskSet 1.0, whose tasks have all completed, from pool ; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: ResultStage 1 (runJob at SparkHadoopMapReduceWriter.scala:88) finished in 0.566 s; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Job 0 finished: runJob at SparkHadoopMapReduceWriter.scala:88, took 9.524571 s; 17/10/13 18:11:53 INFO io.SparkHadoopMapReduceWriter: Job job_20171013181144_0009 committed.; 17/10/13 18:11:53 INFO server.AbstractConnector: Stopped Spark@131ba51c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/10/13 18:11:53 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/13 18:11:54 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 17/10/13 18:11:54 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/13 18:11:54 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 17/10/13 18:11:54 INFO memory.MemoryStore: MemoryStore cleared; 17/10/13 18:11:54 INFO storage.BlockManager: BlockManager stopped; 17/10/13 18:11:54 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 17/10/13 18:11:54 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 17/10/13 18:11:54 INFO spark.SparkContext: Successfully stopped SparkContext; 18:11:54.552 INFO PrintReadsSpark - Shutting down engine; [October 13, 2017 6:11:54 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark done. Elapsed time: 0.35 minutes.; Runtime.totalMemory()=806354944; ***********************************************************************. A USER ERROR has occurred: Couldn't write file /gatk4/output_3.bam becau",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:22224,Schedul,SchedulerExtensionServices,22224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['Schedul'],['SchedulerExtensionServices']
Energy Efficiency,"en.); ; ```bash; ./gatk-launch FindBreakpointEvidenceSpark \; -I hdfs:///user/$USER/broad-svdev-test-data/data/NA12878_PCR-_30X.bam \; -O hdfs:///user/$USER/broad-svdev-test-data/assembly \; --exclusionIntervals hdfs:///user/$USER/broad-svdev-test-data/reference/GRCh37.kill.intervals \; --kmersToIgnore hdfs:///user/$USER/broad-svdev-test-data/reference/Homo_sapiens_assembly38.dups \; -- \; --sparkRunner SPARK --sparkMaster yarn-client --sparkSubmitCommand spark2-submit\; --driver-memory 16G \; --num-executors 5 \; --executor-cores 7 \; --executor-memory 25G; ```. What does FindBreakpointEvidenceSpark do, from the perspective of Spark?. * [runTool] filter out secondary and supplementary alignments; * [getMappedQNamesSet] filter out duplicate reads, reads that failed vendor checks, unmapped reads; * Job 0 [ReadMetadata] mapPartitions to find partition stats; * Job 1 [getIntervals] filter and multiple map partitions to find breakpoint intervals ; * Job 2 [removeHighCoverageIntervals] mapPartitionsToPair to find coverage for each interval, then reduceByKey; * Job 3 [getQNames] mapPartitions; * Job 4 [addAssemblyQNames -> getKmerIntervals] mapPartitionsToPair, then reduceByKey, then mapPartitions; * Job 5 [getAssemblyQNames] mapPartitions twice and a collect; * Job 6 [generateFastqs] mapPartitions and combineByKey, then write FASTQ to files. A few observations:; * Jobs 0,1,3 are simple map jobs - very quick 1-2 mins each.; * Job 2 is a simple MR, with a tiny shuffle to sum by key (<1MB of shuffle data); * Job 4 takes a bit longer longer (3min), and shuffles ~3GB. This is a lot faster than when I ran it before with less memory, when it took 9 min. Is it creating a lot of garbage? If you wanted to speed things up you might look at what this is doing on a local machine and see if there are any opportunities to improve CPU efficiency.; * Job 5 takes ~8 mins, and has no shuffle. CPU intensive processing again?; * Job 6 take a little over 3 mins, shuffling ~3GB. Overall, it loo",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2458#issuecomment-292171884:1344,reduce,reduceByKey,1344,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2458#issuecomment-292171884,4,['reduce'],['reduceByKey']
Energy Efficiency,enFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more; 18/04/24 17:42:11 INFO ShutdownHookManager: Shutdown hook called; 18/04/24 17:42:11 INFO ShutdownHookManager: Deleting directory /tmp/username/spark-99d4cb79-5c44-425b-8f72-9476e7fd884c; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:45837,schedul,scheduler,45837,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,4,['schedul'],['scheduler']
Energy Efficiency,"ence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:07 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 3, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:07 WARN TaskSetManager:66 - Lost task 3.0 in stage 0.0 (TID 2, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseI",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:24794,schedul,scheduler,24794,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['schedul'],['scheduler']
Energy Efficiency,"ence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:49 INFO TaskSetManager:54 - Starting task 7.0 in stage 0.0 (TID 3, scc-q01.scc.bu.edu, executor 1, partition 7, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:49 WARN TaskSetManager:66 - Lost task 2.0 in stage 0.0 (TID 1, scc-q01.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.Autoclos",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:24081,schedul,scheduler,24081,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['schedul'],['scheduler']
Energy Efficiency,"ence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-07 11:34:12 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 9.419880 s; 2019-01-07 11:34:12 INFO AbstractConnector:318 - Stopped Spark@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:34:12 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-07 11:34:12 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-0",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:34699,schedul,scheduler,34699,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['schedul'],['scheduler']
Energy Efficiency,"ence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-09 13:35:56 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 12.691336 s; 2019-01-09 13:35:56 INFO AbstractConnector:318 - Stopped Spark@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:56 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-09 13:35:56 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:34449,schedul,scheduler,34449,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['schedul'],['scheduler']
Energy Efficiency,"ence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.schedule",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:37915,schedul,scheduler,37915,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,4,['schedul'],['scheduler']
Energy Efficiency,"ence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-ed279998-3783-4f41-8fe5-f44a4fac3ee4; ```. CountReads runs fine..... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:42810,schedul,scheduler,42810,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['schedul'],['scheduler']
Energy Efficiency,"ence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-0bd07e00-4f6d-43bd-b9d2-b1999376c72b; ```. Just to verify, the non-spark version still runs fine with the compressed fasta.... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference GRCh38_full_analysis_set_plus_decoy_hla.fa.gz; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:42562,schedul,scheduler,42562,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['schedul'],['scheduler']
Energy Efficiency,"ence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:51 INFO TaskSetManager:54 - Starting task 4.1 in stage 0.0 (TID 5, scc-q20.scc.bu.edu, executor 2, partition 4, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:51 INFO TaskSetManager:54 - Lost task 1.1 in stage 0.0 (TID 4) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 1]; 2019-01-09 13:35:52 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 6, scc-q01.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 7992 bytes); 2019-0",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:27554,schedul,scheduler,27554,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['schedul'],['scheduler']
Energy Efficiency,"ence id 3, start 97885291, span 192458, expected MD5 ef90368731b6e0be845bc82cd92b0c6a; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:10 INFO TaskSetManager:54 - Starting task 3.2 in stage 0.0 (TID 8, scc-q21.scc.bu.edu, executor 1, partition 3, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:10 INFO TaskSetManager:54 - Lost task 1.2 in stage 0.0 (TID 6) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 2]; 2019-01-07 11:34:11 INFO TaskSetManager:54 - Starting task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-0",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:30909,schedul,scheduler,30909,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['schedul'],['scheduler']
Energy Efficiency,"eport; > Merging [#2550](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/c8ede6ef810a3d9a05c7deb8052e27ca724ce8ba?src=pr&el=desc) will **increase** coverage by `0.003%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #2550 +/- ##; ===============================================; + Coverage 76.279% 76.282% +0.003% ; - Complexity 10891 10892 +1 ; ===============================================; Files 752 752 ; Lines 39590 39590 ; Branches 6925 6925 ; ===============================================; + Hits 30199 30200 +1 ; Misses 6768 6768 ; + Partials 2623 2622 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...recalibration/RecalibrationArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWNhbGlicmF0aW9uL1JlY2FsaWJyYXRpb25Bcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `93.827% <100%> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=footer). Last update [c8ede6e...f810842](https://codecov.io/gh/broadinstitute/gatk/pull/2550?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2550#issuecomment-290461016:1803,Power,Powered,1803,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2550#issuecomment-290461016,1,['Power'],['Powered']
Energy Efficiency,er.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:911); 	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:3,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285797337:1206,schedul,scheduler,1206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285797337,1,['schedul'],['scheduler']
Energy Efficiency,er.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:944); 	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:3,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:10393,schedul,scheduler,10393,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,er.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114); 	at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:78); 	... 87 more; Caused by: java.util.ConcurrentModificationException; 	at java.util.ArrayList.sort(ArrayList.java:1464); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.<init>(ReadThreadingAssembler.java:81); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerReadThreadingAssemblerArgumentCollection.makeReadThreadingAsse,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:11636,schedul,scheduler,11636,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['schedul'],['scheduler']
Energy Efficiency,er.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:1020); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:847); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:831); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:508); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:509); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); 	at org.broadinstitute.hellbender.tools.fu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-783746069:2533,Reduce,ReduceOps,2533,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-783746069,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,erArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWFkVGhyZWFkaW5nQXNzZW1ibGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `94.118% <ø> (ø)` | `1 <0> (ø)` | :arrow_down: |; | [...kers/haplotypecaller/AssemblyBasedCallerUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHMuamF2YQ==) | `76.923% <ø> (-0.946%)` | `34 <0> (-1)` | |; | [...walkers/haplotypecaller/HaplotypeCallerEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJFbmdpbmUuamF2YQ==) | `78.425% <100%> (ø)` | `76 <0> (ø)` | :arrow_down: |; | [...rs/haplotypecaller/graphs/AdaptiveChainPruner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvQWRhcHRpdmVDaGFpblBydW5lci5qYXZh) | `95.349% <100%> (+0.111%)` | `16 <0> (ø)` | :arrow_down: |; | [...hellbender/tools/walkers/mutect/Mutect2Engine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyRW5naW5lLmphdmE=) | `90.173% <100%> (ø)` | `65 <0> (ø)` | :arrow_down: |; | [...otypecaller/HaplotypeCallerArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `100% <100%> (ø)` | `3 <1> (+1)` | :arrow_up: |; | [...r/tools/walkers/mutect/Mutect2Integrati,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5544#issuecomment-449424951:2272,Adapt,AdaptiveChainPruner,2272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5544#issuecomment-449424951,1,['Adapt'],['AdaptiveChainPruner']
Energy Efficiency,"erage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2521 +/- ##; ===============================================; + Coverage 76.256% 76.261% +0.005% ; Complexity 10864 10864 ; ===============================================; Files 750 750 ; Lines 39543 39543 ; Branches 6915 6915 ; ===============================================; + Hits 30154 30156 +2 ; + Misses 6771 6769 -2 ; Partials 2618 2618; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2521?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...notyper/GenotypeCalculationArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/compare/7ad3c91b96448c4a867451b40b7ce6ae41cef690...2622598137d07ee362c7d98cb67e89862df0276e?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwZUNhbGN1bGF0aW9uQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `100% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/7ad3c91b96448c4a867451b40b7ce6ae41cef690...2622598137d07ee362c7d98cb67e89862df0276e?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2521?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2521?src=pr&el=footer). Last update [7ad3c91...2622598](https://codecov.io/gh/broadinstitute/gatk/compare/7ad3c91b96448c4a867451b40b7ce6ae41cef690...2622598137d07ee362c7d98cb67e89862df0276e?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2521#issuecomment-288757656:1979,Power,Powered,1979,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2521#issuecomment-288757656,1,['Power'],['Powered']
Energy Efficiency,"erent results by the first filtering step (on intervals by interval median). @LeeTL1220 @davidbenjamin what is the ""official ReCapSeg"" behavior, and do we want to keep the current behavior? In general, I think all of the standardization (i.e., filtering/imputation/truncation/transformation) steps could stand some revisiting. Evaluation:. - [ ] Revisit standardization procedure by checking with simulated data. We should make sure that the centering of the data does not rescale the true copy ratio.; - [x] <s>Investigate the effect of keeping duplicates. I am still not sure why we do this, and it may have a more drastic impact on WGS data.</s> Turns out we don't keep duplicates for WGS; see #3367.; - [ ] Check that GC-bias-correction+PCA and PCA-only perform comparably, even at small bin sizes (~300bp). From what I've seen, this is true for larger bin sizes (~3kbp), so explicit GC-bias correction may not be necessary. (That is, even at these (purportedly) large bin sizes, the effect of the read-based GC-bias correction is obvious for those samples where it is important. However, the end result is not very different from PCA-only denoising with no GC-bias correction performed.); - [x] <s>Check that changing CBS alpha parameter sufficiently reduces hypersegmentation.</s> <s>Looks like the hybrid p-value calculation in DNACopy is not accurate enough to handle WGS-size data. (Also, it's relatively slow, taking ~30 minutes on ~10M intervals.) Even if I set alpha to 0, I still get a ridiculous number of segments! So I think it's finally time to scrap CBS. I'll look into other R segmentation packages that might give us a quick drop-in solution, but we may want to roll our own simple algorithm (which we will scrap anyway once the coverage model is in for somatic).</s> I've implemented a fast kernel-segmentation method that seems very promising, see below.; - [ ] Investigate performance vs. CGA ReCapSeg pipeline on THCA samples.; - [ ] Investigate concordance with Genome STRiP.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-316894351:5171,reduce,reduces,5171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-316894351,2,['reduce'],['reduces']
Energy Efficiency,"estrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-CHMSampleHeadToHead/BenchmarkComparison/1731c546-7466-4adf-9790-3f99d07df05b/call-CONTROLRuntimeTask/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-CHMSampleHeadToHead/BenchmarkComparison/1731c546-7466-4adf-9790-3f99d07df05b/call-BenchmarkVCFControlSample/Benchmark/669edf6c-76a1-4d82-8cf7-5cd104df2496/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""83.2423166666667"",; ""CHM evalHCsystemhours"": ""0.18843333333333337"",; ""CHM evalHCwallclockhours"": ""61.06540555555557"",; ""CHM evalHCwallclockmax"": ""3.1854916666666666"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-CHMSampleHeadToHead/BenchmarkComparison/1731c546-7466-4adf-9790-3f99d07df05b/call-EVALRuntimeTask/monitoring.pdf"",; ""CHM evalindelF1Score"": ""0.8724"",; ""CHM evalindelPrecision"": ""0.8814"",; ""CHM evalsnpF1Score"": ""0.9784"",; ""CHM evalsnpPrecision"": ""0.9706"",; ""CHM evalsnpRecall"": ""0.9863"",; ""CHM evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-CHMSampleHeadToHead/BenchmarkComparison/1731c546-7466-4adf-9790-3f99d07df05b/call-BenchmarkVCFTestSample/Benchmark/8e83736f-3023-4bee-9c42-36c836b75297/call-CombineSummaries/summary.csv"",; ""EXOME1 controlindelF1Score"": ""0.727"",; ""EXOME1 controlindelPrecision"": ""0.632"",; ""EXOME1 controlsnpF1Score"": ""0.9878"",; ""EXOME1 controlsnpPrecision"": ""0.9815"",; ""EXOME1 controlsnpRecall"": ""0.9941"",; ""EXOME1 controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-EXOME1SampleHead",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1550601099:18325,monitor,monitoring,18325,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1550601099,1,['monitor'],['monitoring']
Energy Efficiency,"estrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-CHMSampleHeadToHead/BenchmarkComparison/b7ddd5f2-fded-4076-b163-33ad637fb5bd/call-CONTROLRuntimeTask/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-CHMSampleHeadToHead/BenchmarkComparison/b7ddd5f2-fded-4076-b163-33ad637fb5bd/call-BenchmarkVCFControlSample/Benchmark/10080eab-b0ad-4752-80cb-fc6d34bd9ad9/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""93.63756388888888"",; ""CHM evalHCsystemhours"": ""0.6379805555555556"",; ""CHM evalHCwallclockhours"": ""70.50882222222222"",; ""CHM evalHCwallclockmax"": ""3.5186027777777777"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-CHMSampleHeadToHead/BenchmarkComparison/b7ddd5f2-fded-4076-b163-33ad637fb5bd/call-EVALRuntimeTask/monitoring.pdf"",; ""CHM evalindelF1Score"": ""0.8724"",; ""CHM evalindelPrecision"": ""0.8814"",; ""CHM evalsnpF1Score"": ""0.9784"",; ""CHM evalsnpPrecision"": ""0.9706"",; ""CHM evalsnpRecall"": ""0.9863"",; ""CHM evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-CHMSampleHeadToHead/BenchmarkComparison/b7ddd5f2-fded-4076-b163-33ad637fb5bd/call-BenchmarkVCFTestSample/Benchmark/c718736b-bf86-491f-9f9c-56c07cbd0c90/call-CombineSummaries/summary.csv"",; ""EXOME1 controlindelF1Score"": ""0.727"",; ""EXOME1 controlindelPrecision"": ""0.632"",; ""EXOME1 controlsnpF1Score"": ""0.9878"",; ""EXOME1 controlsnpPrecision"": ""0.9815"",; ""EXOME1 controlsnpRecall"": ""0.9941"",; ""EXOME1 controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/ba9f32d5-7b46-462c-8d1f-5692eee05534/call-EXOME1SampleHead",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8467#issuecomment-1687811441:18315,monitor,monitoring,18315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8467#issuecomment-1687811441,1,['monitor'],['monitoring']
Energy Efficiency,"f-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `53.247% <0%> (-18.071%)` | `28% <0%> (-6%)` | |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `40.469% <0%> (-18.009%)` | `28% <0%> (ø)` | |; | ... and [42 more](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=footer). Last update [781db35...13a10e2](https://codecov.io/gh/broadinstitute/gatk/pull/2574?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2574#issuecomment-292193941:4237,Power,Powered,4237,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2574#issuecomment-292193941,1,['Power'],['Powered']
Energy Efficiency,"f_genome/GCA_905319855.2_mCanLor1.2_genomic.fa \; -V gendb://Wolf_Genome_Variantsdb \; -O All_Wolf_Samples_Joint_Genotypes_Raw.vcf.gz \; -L /scratch/dan/Wolf_reads_raw/Wolf_GenCov300_Q20_Merged.interval_list \; -imr ALL \; --genomicsdb-max-alternate-alleles 10 \; --max-alternate-alleles 6 . This runs perfectly until it reaches the 2 millionth variant mark whereupon everything stops, and all processes are terminated. You will notice this isn't occurring at chr1= ~200k (as in previous reports), but instead on the variants processed = ~2million. It seems odd that previous posts had a similar error (reported alternately as chr position ~200k or 2m). ; ; If I try running ""SelectVariants"" on any interval in the database ; ; gatk SelectVariants \; -R /home/dan_vanderpool/Wolf_raw_reads/Wolf_genome/GCA_905319855.2_mCanLor1.2_genomic.fa \; -V gendb://Wolf_Genome_Variantsdb \; -select-type SNP \; -O test_error1m.vcf.gz; -L chr1:1000000-2000000. The process stalls (doesn't terminate) without reporting any variants with the progress meter as below. . 18:46:19.529 INFO SelectVariants - Done initializing engine; 18:46:19.574 INFO ProgressMeter - Starting traversal; 18:46:19.574 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute. The stack trace on the stalled ""SelectVariants"" command looks like:. ""G1 Refine#78"" os_prio=0 tid=0x00007ff536ea6000 nid=0x1af0e0 runnable . ""G1 Refine#79"" os_prio=0 tid=0x00007ff536ea8000 nid=0x1af0e1 runnable . ""G1 Refine#80"" os_prio=0 tid=0x00007ff536ea9800 nid=0x1af0e2 runnable . ""G1 Refine#81"" os_prio=0 tid=0x00007ff536eab800 nid=0x1af0e3 runnable . ""G1 Refine#82"" os_prio=0 tid=0x00007ff536ead000 nid=0x1af0e4 runnable . ""G1 Young RemSet Sampling"" os_prio=0 tid=0x00007ff536eaf000 nid=0x1af0e5 runnable ; ""VM Periodic Task Thread"" os_prio=0 tid=0x00007ff5310eb000 nid=0x1af101 waiting on condition . JNI global references: 13. Heap; garbage-first heap total 5378048K, used 1388875K [0x0000000082000000, 0x0000000800000000)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1049112454:1827,meter,meter,1827,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1049112454,1,['meter'],['meter']
Energy Efficiency,"ference/ReferenceBases.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWZlcmVuY2UvUmVmZXJlbmNlQmFzZXMuamF2YQ==) | `38.46% <0%> (-19.24%)` | `4% <0%> (-2%)` | |; | [...oadinstitute/hellbender/engine/ReferenceShard.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVmZXJlbmNlU2hhcmQuamF2YQ==) | `62.5% <0%> (-18.75%)` | `6% <0%> (-1%)` | |; | [...broadinstitute/hellbender/engine/VariantShard.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvVmFyaWFudFNoYXJkLmphdmE=) | `63.63% <0%> (-13.64%)` | `7% <0%> (-1%)` | |; | [...ne/spark/datasources/ReferenceWindowFunctions.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVmZXJlbmNlV2luZG93RnVuY3Rpb25zLmphdmE=) | `12.5% <0%> (-12.5%)` | `1% <0%> (ø)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `79.87% <0%> (+1.21%)` | `42% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5292?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5292?src=pr&el=footer). Last update [a74e571...3768ba2](https://codecov.io/gh/broadinstitute/gatk/pull/5292?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5292#issuecomment-427904892:4339,Power,Powered,4339,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5292#issuecomment-427904892,1,['Power'],['Powered']
Energy Efficiency,"file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; >; > 16:17:04.397 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression3825249225068031371.so: /tmp/libgkl_compression3825249225068031371.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)); >; > 16:17:04.402 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; >; > 16:17:04.407 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression7506152962158874866.so: /tmp/libgkl_compression7506152962158874866.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)); >; > Sep 04, 2020 4:17:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; >; > INFO: Failed to detect whether we are running on Google Compute Engine.; >; > 16:17:05.842 INFO HaplotypeCaller - ------------------------------------------------------------; >; > 16:17:05.843 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.1; >; > 16:17:05.843 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; >; > 16:17:05.843 INFO HaplotypeCaller - Executing as robert@powerlinux on Linux v4.4.0-184-generic ppc64le; >; > 16:17:05.843 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_252-8u252-b09-1~16.04-b09; >; > 16:17:05.843 INFO HaplotypeCaller - Start Date/Time: September 4, 2020 4:17:04 PM UTC; >; > 16:17:05.843 INFO HaplotypeCaller - ------------------------------------------------------------; >; > 16:17:05.843 INFO HaplotypeCaller - -----------------------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6794#issuecomment-687344600:2437,Power,Power,2437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794#issuecomment-687344600,1,['Power'],['Power']
Energy Efficiency,fn$4$1.apply(JavaRDDLike.scala:153); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.s,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690:6562,schedul,scheduler,6562,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690,1,['schedul'],['scheduler']
Energy Efficiency,g.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:123); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:10661,schedul,scheduler,10661,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['schedul'],['scheduler']
Energy Efficiency,g.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 2019-10-29T18:18:04.001518160Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 2019-10-29T18:18:04.001673083Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-29T18:18:04.001846904Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-29T18:18:04.002024760Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002358113Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:1489,Reduce,ReduceOps,1489,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300,1,['Reduce'],['ReduceOps']
Energy Efficiency,g.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 2019-10-30T13:35:51.792559803Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 2019-10-30T13:35:51.792736667Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-30T13:35:51.792905235Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-30T13:35:51.793072365Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-30T13:35:51.793261944Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-30T13:35:51.793456807Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-30T13:35:51.793619935Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-30T13:35:51.793810301Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.794006885Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.794191116Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-30T13:35:51.794367593Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-30T13:35:51.794548129Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-30T13:35:51.794722501Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-30T13:35:51.794896154Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:1490,Reduce,ReduceOps,1490,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227,1,['Reduce'],['ReduceOps']
Energy Efficiency,"gate at FlagStatSpark.java:73) with 252 output partitions; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 1148.4 KB, free 8.4 GB); 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 345.8 KB, free 8.4 GB); 18/03/07 13:59:26 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:32895 (size: 345.8 KB, free: 8.4 GB); 18/03/07 13:59:26 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting 252 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 13:59:26 INFO cluster.YarnScheduler: Adding task set 0.0 with 252 tasks; 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 0, scc-q05.scc.bu.edu, executor 4, partition 2, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 25.0 in stage 0.0 (TID 1, scc-q10.scc.bu.edu, executor 3, partition 25, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 15.0 in stage 0.0 (TID 2, scc-q07.scc.bu.edu, executor 1, partition 15, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 3, scc-q16.scc.bu.edu, executor 8, partition 4, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 4, scc-q14.scc.bu.edu, executor 2, partition 3, NODE_L",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304:2897,schedul,scheduler,2897,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304,1,['schedul'],['scheduler']
Energy Efficiency,"ges/stage/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:33:27 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:46828/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1546878807984; 2019-01-07 11:33:28 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-07 11:33:29 WARN DomainSocketFactory:117 - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-07 11:33:30 INFO Client:54 - Requesting a new application from cluster with 21 NodeManagers; 2019-01-07 11:33:30 INFO Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (204800 MB per container); 2019-01-07 11:33:30 INFO Client:54 - Will allocate AM container, with 896 MB memory including 384 MB overhead; 2019-01-07 11:33:30 INFO Client:54 - Setting up container launch context for our AM; 2019-01-07 11:33:30 INFO Client:54 - Setting up the launch environment for our AM container; 2019-01-07 11:33:30 INFO Client:54 - Preparing resources for our AM container; 2019-01-07 11:33:30 INFO HadoopFSDelegationTokenProvider:54 - getting token for: DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-1883879239_1, ugi=farrell@AD.BU.EDU (auth:KERBEROS)]]; 2019-01-07 11:33:30 INFO DFSClient:1023 - Created HDFS_DELEGATION_TOKEN token 11334 for farrell on ha-hdfs:scc; 2019-01-07 11:33:32 WARN Client:66 - Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 2019-01-07 11:33:36 INFO Client:54 - Uploading resource file:/tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed/__spark_libs__7473738539612638927.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_libs__7473738539612638927.zip; 2019-01-07 11:33:38 INFO Client:54 - Uploading resource file:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:10934,allocate,allocate,10934,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['allocate'],['allocate']
Energy Efficiency,"ges/stage/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:12 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:42689/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1547058912934; 2019-01-09 13:35:13 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-09 13:35:13 WARN DomainSocketFactory:117 - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-09 13:35:14 INFO Client:54 - Requesting a new application from cluster with 21 NodeManagers; 2019-01-09 13:35:14 INFO Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (204800 MB per container); 2019-01-09 13:35:14 INFO Client:54 - Will allocate AM container, with 896 MB memory including 384 MB overhead; 2019-01-09 13:35:14 INFO Client:54 - Setting up container launch context for our AM; 2019-01-09 13:35:14 INFO Client:54 - Setting up the launch environment for our AM container; 2019-01-09 13:35:14 INFO Client:54 - Preparing resources for our AM container; 2019-01-09 13:35:14 INFO HadoopFSDelegationTokenProvider:54 - getting token for: DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-682487019_1, ugi=farrell@AD.BU.EDU (auth:KERBEROS)]]; 2019-01-09 13:35:14 INFO DFSClient:1023 - Created HDFS_DELEGATION_TOKEN token 11353 for farrell on ha-hdfs:scc; 2019-01-09 13:35:16 WARN Client:66 - Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 2019-01-09 13:35:20 INFO Client:54 - Uploading resource file:/tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0/__spark_libs__7821719163562430010.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_libs__7821719163562430010.zip; 2019-01-09 13:35:22 INFO Client:54 - Uploading resource file:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:10674,allocate,allocate,10674,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['allocate'],['allocate']
Energy Efficiency,"ggregate at FlagStatSpark.java:73) with 629 output partitions; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 53.9 KB, free 8.4 GB); 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 15.5 KB, free 8.4 GB); 18/03/07 20:31:51 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:41567 (size: 15.5 KB, free: 8.4 GB); 18/03/07 20:31:51 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting 629 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 20:31:51 INFO cluster.YarnScheduler: Adding task set 0.0 with 629 tasks; 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 0, scc-q03.scc.bu.edu, executor 4, partition 1, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 0.0 (TID 1, scc-q13.scc.bu.edu, executor 3, partition 6, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 2, scc-q14.scc.bu.edu, executor 7, partition 4, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 0.0 (TID 3, scc-q12.scc.bu.edu, executor 2, partition 5, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 4, scc-q09.scc.bu.edu, executor 1, partition 2, NODE_LOCAL",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:6467,schedul,scheduler,6467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,2,['schedul'],['scheduler']
Energy Efficiency,"gistering block manager xx.xx.xx.xx:42081 with 366.3 MB RAM, BlockManagerId(driver, xx.xx.xx.xx, 42081, None); 18/04/24 17:39:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/0 is now RUNNING; 18/04/24 17:39:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/1 is now RUNNING; 18/04/24 17:39:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/2 is now RUNNING; 18/04/24 17:39:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, xx.xx.xx.xx, 42081, None); 18/04/24 17:39:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, xx.xx.xx.xx, 42081, None); 18/04/24 17:39:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/6 is now RUNNING; 18/04/24 17:39:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/4 is now RUNNING; 18/04/24 17:39:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/3 is now RUNNING; 18/04/24 17:39:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20180424173921-0001/5 is now RUNNING; 18/04/24 17:39:22 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0; 18/04/24 17:39:22 INFO GoogleHadoopFileSystemBase: GHFS version: 1.6.3-hadoop2; 18/04/24 17:39:25 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 276.0 KB, free 366.0 MB); 00:08 DEBUG: [kryo] Write: SerializableConfiguration; 18/04/24 17:39:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.1 KB, free 366.0 MB); 18/04/24 17:39:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on xx.xx.xx.xx:42081 (size: 23.1 KB, free: 366.3 MB); 18/04/24 17:39:27 INFO SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:113; 18/04/24 17:39:27 INFO FileInputFormat: Total input p",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:13425,schedul,scheduling,13425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,3,"['Schedul', 'schedul']","['SchedulerBackend', 'scheduling']"
Energy Efficiency,"haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...ark/sv/CallVariantsFromAlignedContigsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9DYWxsVmFyaWFudHNGcm9tQWxpZ25lZENvbnRpZ3NTQU1TcGFyay5qYXZh) | `0% <0%> (-26.087%)` | `0% <0%> (-5%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `48.837% <0%> (-24.774%)` | `27% <0%> (-9%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-18.75%)` | `6% <0%> (ø)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | ... and [27 more](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=footer). Last update [5d2f859...7a651b7](https://codecov.io/gh/broadinstitute/gatk/pull/2355?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-287020306:4309,Power,Powered,4309,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2355#issuecomment-287020306,1,['Power'],['Powered']
Energy Efficiency,"hbmRMaW5lUHJvZ3JhbS5qYXZh) | `95.714% <0%> (+2.456%)` | `38% <0%> (+9%)` | :arrow_up: |; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/compare/88c181df462379fed902c8ae35b0ca142e2bd88d...298212c811d06554a7ad7e97e200172feef6496c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `87.156% <0%> (+2.945%)` | `66% <0%> (+13%)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/88c181df462379fed902c8ae35b0ca142e2bd88d...298212c811d06554a7ad7e97e200172feef6496c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/88c181df462379fed902c8ae35b0ca142e2bd88d...298212c811d06554a7ad7e97e200172feef6496c?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `70.47% <0%> (+4.154%)` | `46% <0%> (+18%)` | :arrow_up: |; | ... and [3 more](https://codecov.io/gh/broadinstitute/gatk/pull/2495?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2495?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2495?src=pr&el=footer). Last update [88c181d...298212c](https://codecov.io/gh/broadinstitute/gatk/compare/88c181df462379fed902c8ae35b0ca142e2bd88d...298212c811d06554a7ad7e97e200172feef6496c?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2495#issuecomment-287912625:5172,Power,Powered,5172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2495#issuecomment-287912625,1,['Power'],['Powered']
Energy Efficiency,"he superclass, but for `AssemblyRegionWalker` it was the unit of I/O and `AssemblyRegion` was the unit of processing, and I couldn't update the docs for `ReadWindowWalker` to clear up the confusion without mentioning `AssemblyRegion`-specific concepts.; - The `ReadShard` / `ReadWindow` was/is **only** there to prove that we can shard the data without introducing calling artifacts, and to provide a unit of parallelism for the upcoming Spark implementation. It's not something we really want to expose to users as a prominent knob, and we may hide it completely in the future once the shard size is tuned for performance.; - Inheriting from a more abstract walker type caused a number of other problems as well: methods that should have been final in the supertype could no longer be made final, with the result that tool implementations could inappropriately override engine initialization/shutdown routines. Also, there were issues with the progress meter, since both the supertype traversal and subtype traversal needed their own progress meter for their different units of processing. Ultimately it was just too awkward and forced, and the read shard is something that we eventually want to make an internal/encapsulated implementation detail anyway. GATK3 made the mistake, I think, of using long, confusing inheritance chains for its walker types, with the result that you got awkward and forced relationships like `RodWalker` inheriting from `LocusWalker`. It's better, I think, to make each traversal as standalone as possible, especially given the simplicity of writing a new walker type in GATK4. For all of these reasons we don't want `AssemblyRegionWalker` to inherit from a more abstract traversal type -- it's just going to be its own standalone thing, so that it can evolve freely without affecting anyone else. For `SlidingWindowWalker`, which we still want to merge, I recommend making the traversal do **exactly** what you want for your use case, as clearly and simply as possible,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210806513:1712,meter,meter,1712,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-210806513,2,['meter'],['meter']
Energy Efficiency,he.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114); 	at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:78); 	... 87 more; Caused by: java.util.ConcurrentModificationExcepti,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:11299,schedul,scheduler,11299,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['schedul'],['scheduler']
Energy Efficiency,"he.spark.storage.BlockManager.reportAllBlocks(BlockManager.scala:217); 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:236); 	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:522); 	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:547); 	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); 	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1953); 	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:547); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308); 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180); 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); 17/10/18 17:35:58 INFO BlockManagerMaster: BlockManagerMaster stopped; 17/10/18 17:35:58 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker-1,5,main]; java.lang.OutOfMemoryError: Java heap space; 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:208); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:5595,Schedul,ScheduledThreadPoolExecutor,5595,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,2,['Schedul'],"['ScheduledFutureTask', 'ScheduledThreadPoolExecutor']"
Energy Efficiency,heduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.sca,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:38912,schedul,scheduler,38912,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,4,['schedul'],['scheduler']
Energy Efficiency,"heduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, com2, executor 1, partition 0, NODE_LOCAL, 4632 bytes); 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on com2:45501 (size: 32.6 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.131.101.145:54024; 17/10/13 18:11:53 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 135 bytes; 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on com2:45501 (size: 2.1 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 565 ms on com2 (executor 1) (1/1); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: ResultStage 1 (runJob at SparkHadoopMapReduceWriter.scala:88) finished in 0.566 s; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Job 0 finished: runJob at SparkHadoopMapReduceWriter.scala:88, took 9.524571 s; 17/10/13 18:11:53 INFO io.SparkHadoopMapReduceWriter: Job job_20171013181144_0009 committed.; 17/10/13 18:11:53 INFO server.AbstractConnector: Stopped Spark@131ba51c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/10/13 18:11:53 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/13 18:11:54 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 17/10/13 18:11:54 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Stopped; 17/10/13 18:11:54 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint st",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:21517,schedul,scheduler,21517,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['schedul'],['scheduler']
Energy Efficiency,hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:1020); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:847); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:831); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:508); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:509); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653:3239,Reduce,ReduceOps,3239,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"hhaW5QcnVuZXIuamF2YQ==) | `83.33% <0%> (-12.23%)` | `5% <0%> (-15%)` | |; | [...r/arguments/CopyNumberArgumentValidationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2FyZ3VtZW50cy9Db3B5TnVtYmVyQXJndW1lbnRWYWxpZGF0aW9uVXRpbHMuamF2YQ==) | `66.66% <0%> (-11.12%)` | `19% <0%> (-1%)` | |; | [...tools/funcotator/DataSourceFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0RhdGFTb3VyY2VGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `75.92% <0%> (-11.04%)` | `17% <0%> (ø)` | |; | [...ools/walkers/haplotypecaller/graphs/SeqVertex.java](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvU2VxVmVydGV4LmphdmE=) | `92.85% <0%> (-7.15%)` | `10% <0%> (-1%)` | |; | [...te/hellbender/tools/funcotator/OutputRenderer.java](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL091dHB1dFJlbmRlcmVyLmphdmE=) | `92.85% <0%> (-7.15%)` | `4% <0%> (ø)` | |; | ... and [170 more](https://codecov.io/gh/broadinstitute/gatk/pull/5475/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5475?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5475?src=pr&el=footer). Last update [1f6a172...623830b](https://codecov.io/gh/broadinstitute/gatk/pull/5475?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5475#issuecomment-443759397:4616,Power,Powered,4616,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5475#issuecomment-443759397,1,['Power'],['Powered']
Energy Efficiency,ibution.java](https://codecov.io/gh/broadinstitute/gatk/pull/3755?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9CZXRhQmlub21pYWxEaXN0cmlidXRpb24uamF2YQ==) | `68.182% <68.182%> (ø)` | `4 <4> (?)` | |; | [...ation/basicshortmutpileup/AllelePileupCounter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3755?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9BbGxlbGVQaWxldXBDb3VudGVyLmphdmE=) | `81.25% <81.25%> (ø)` | `12 <12> (?)` | |; | [...tmutpileup/ValidateBasicSomaticShortMutations.java](https://codecov.io/gh/broadinstitute/gatk/pull/3755?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9WYWxpZGF0ZUJhc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zLmphdmE=) | `85.965% <85.965%> (ø)` | `7 <7> (?)` | |; | [...ion/basicshortmutpileup/PowerCalculationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3755?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9Qb3dlckNhbGN1bGF0aW9uVXRpbHMuamF2YQ==) | `95.238% <95.238%> (ø)` | `15 <15> (?)` | |; | [...bender/utils/GATKProtectedVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3755?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HQVRLUHJvdGVjdGVkVmFyaWFudENvbnRleHRVdGlscy5qYXZh) | `77.901% <95.833%> (+6.472%)` | `70 <23> (+23)` | :arrow_up: |; | [...ion/basicshortmutpileup/BasicValidationResult.java](https://codecov.io/gh/broadinstitute/gatk/pull/3755?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9CYXNpY1ZhbGlkYXRpb25SZXN1bHQuamF2YQ==) | `96.552% <96.552%> (ø)` | `15 <15> (?)` | |; | ... and [9 more](https://codecov.io/gh/broa,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3755#issuecomment-341515732:3190,Power,PowerCalculationUtils,3190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3755#issuecomment-341515732,1,['Power'],['PowerCalculationUtils']
Energy Efficiency,"iff coverage is `66.667%`. ```diff; @@ Coverage Diff @@; ## master #2515 +/- ##; ===============================================; - Coverage 76.273% 76.268% -0.004% ; - Complexity 10876 10878 +2 ; ===============================================; Files 752 752 ; Lines 39583 39584 +1 ; Branches 6922 6922 ; ===============================================; - Hits 30191 30190 -1 ; - Misses 6772 6774 +2 ; Partials 2620 2620; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...tute/hellbender/tools/spark/sv/ReadClassifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkQ2xhc3NpZmllci5qYXZh) | `82.813% <66.667%> (-1.314%)` | `30 <0> (-1)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `66.667% <0%> (-3.333%)` | `10% <0%> (ø)` | |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=footer). Last update [d40ccc2...d5c85bb](https://codecov.io/gh/broadinstitute/gatk/pull/2515?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2515#issuecomment-288529799:2064,Power,Powered,2064,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2515#issuecomment-288529799,1,['Power'],['Powered']
Energy Efficiency,"iff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZHNEYXRhU291cmNlLmphdmE=) | `90.476% <0%> (+1.587%)` | `61% <0%> (+2%)` | :arrow_up: |; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `66.667% <0%> (+3.252%)` | `4% <0%> (ø)` | :arrow_down: |; | [...g/broadinstitute/hellbender/engine/AuthHolder.java](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvQXV0aEhvbGRlci5qYXZh) | `15.254% <0%> (+5.085%)` | `2% <0%> (ø)` | :arrow_down: |; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `77.703% <0%> (+6.757%)` | `22% <0%> (+4%)` | :arrow_up: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `86.4% <0%> (+8.8%)` | `35% <0%> (+7%)` | :arrow_up: |; | ... and [7 more](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=footer). Last update [5ccfd00...b1d407f](https://codecov.io/gh/broadinstitute/gatk/pull/2540?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2540#issuecomment-290122549:3968,Power,Powered,3968,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2540#issuecomment-290122549,1,['Power'],['Powered']
Energy Efficiency,"ile or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 02:12 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:28724,schedul,scheduler,28724,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['schedul'],['scheduler']
Energy Efficiency,"ile or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 02:34 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:31423,schedul,scheduler,31423,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['schedul'],['scheduler']
Energy Efficiency,"ile or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 18/04/24 17:40:52 INFO TaskSetManager: Lost task 0.0 in stage 2.0 (TID 3) on xx.xx.xx.25, executor 2: org.broadins",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:25537,schedul,scheduler,25537,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['schedul'],['scheduler']
Energy Efficiency,"ile or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; 18/04/24 17:42:02 INFO DAGScheduler: Job 2 failed: count at PathSeqPipelineSpark.java:245, too",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:35161,schedul,scheduler,35161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['schedul'],['scheduler']
Energy Efficiency,ile or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAnd,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:40357,schedul,scheduler,40357,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['schedul'],['scheduler']
Energy Efficiency,ile or directory); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more; 18/04/24 17:42:11 INFO ShutdownHookManager: Shutdown hook called; 18/04/24 17:42:11 INFO ShutdownHookManager: Dele,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:45758,schedul,scheduler,45758,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['schedul'],['scheduler']
Energy Efficiency,"ile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 02:12 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:41:31 INFO TaskSetManager: Start",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:28803,schedul,scheduler,28803,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['schedul'],['scheduler']
Energy Efficiency,"ile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 02:34 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:41:53 INFO TaskSetManager: Start",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:31502,schedul,scheduler,31502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['schedul'],['scheduler']
Energy Efficiency,"ile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 18/04/24 17:40:52 INFO TaskSetManager: Lost task 0.0 in stage 2.0 (TID 3) on xx.xx.xx.25, executor 2: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:25616,schedul,scheduler,25616,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['schedul'],['scheduler']
Energy Efficiency,"ile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; 18/04/24 17:42:02 INFO DAGScheduler: Job 2 failed: count at PathSeqPipelineSpark.java:245, took 117.869179 s; 18/04/24 17:42:02 INFO SparkUI: Stopped Spark web UI at http://",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:35240,schedul,scheduler,35240,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['schedul'],['scheduler']
Energy Efficiency,ile(BucketUtils.java:112); at org.broadinstitute.hellbender.tools.spark.pathseq.PSKmerUtils.readKmerFilter(PSKmerUtils.java:131); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilter.<init>(ContainsKmerReadFilter.java:27); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:35); at org.broadinstitute.hellbender.tools.spark.pathseq.ContainsKmerReadFilterSpark.call(ContainsKmerReadFilterSpark.java:15); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:78); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGSc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:40436,schedul,scheduler,40436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['schedul'],['scheduler']
Energy Efficiency,"ils/genotyper/SampleList.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nZW5vdHlwZXIvU2FtcGxlTGlzdC5qYXZh) | `75.676% <0%> (ø)` | `8% <0%> (?)` | |; | [...hellbender/tools/walkers/annotator/SampleList.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TYW1wbGVMaXN0LmphdmE=) | `81.25% <0%> (+1.658%)` | `9% <0%> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |; | [.../broadinstitute/hellbender/tools/exome/Sample.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9TYW1wbGUuamF2YQ==) | `100% <0%> (+12.308%)` | `5% <0%> (-21%)` | :arrow_down: |; | [...stitute/hellbender/engine/ReferenceFileSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVmZXJlbmNlRmlsZVNvdXJjZS5qYXZh) | `72.727% <0%> (+15.584%)` | `4% <0%> (-4%)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=footer). Last update [62d58c5...fde9d36](https://codecov.io/gh/broadinstitute/gatk/pull/2556?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2556#issuecomment-290787479:3513,Power,Powered,3513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2556#issuecomment-290787479,1,['Power'],['Powered']
Energy Efficiency,"in memory (estimated size 25.3 KB, free 8.4 GB); 18/03/07 20:31:50 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:41567 (size: 25.3 KB, free: 8.4 GB); 18/03/07 20:31:50 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 18/03/07 20:31:50 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 7175 for farrell on ha-hdfs:scc; 18/03/07 20:31:50 INFO security.TokenCache: Got dt for hdfs://scc; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:scc, Ident: (HDFS_DELEGATION_TOKEN token 7175 for farrell); 18/03/07 20:31:50 INFO input.FileInputFormat: Total input paths to process : 1; 18/03/07 20:31:51 INFO spark.SparkContext: Starting job: aggregate at FlagStatSpark.java:73; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Got job 0 (aggregate at FlagStatSpark.java:73) with 629 output partitions; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 53.9 KB, free 8.4 GB); 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 15.5 KB, free 8.4 GB); 18/03/07 20:31:51 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:41567 (size: 15.5 KB, free: 8.4 GB); 18/03/07 20:31:51 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting 629 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 20:31:51 INFO cluster.YarnScheduler",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:5653,schedul,scheduler,5653,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,2,['schedul'],['scheduler']
Energy Efficiency,"in memory (estimated size 25.5 KB, free 8.4 GB); 18/03/07 13:24:28 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:32895 (size: 25.5 KB, free: 8.4 GB); 18/03/07 13:24:28 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 18/03/07 13:24:28 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 7164 for farrell on ha-hdfs:scc; 18/03/07 13:24:28 INFO security.TokenCache: Got dt for hdfs://scc; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:scc, Ident: (HDFS_DELEGATION_TOKEN token 7164 for farrell); 18/03/07 13:24:28 INFO input.FileInputFormat: Total input paths to process : 1; 18/03/07 13:59:26 INFO spark.SparkContext: Starting job: aggregate at FlagStatSpark.java:73; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Got job 0 (aggregate at FlagStatSpark.java:73) with 252 output partitions; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 1148.4 KB, free 8.4 GB); 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 345.8 KB, free 8.4 GB); 18/03/07 13:59:26 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:32895 (size: 345.8 KB, free: 8.4 GB); 18/03/07 13:59:26 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting 252 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 13:59:26 INFO cluster.YarnSched",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304:2079,schedul,scheduler,2079,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304,1,['schedul'],['scheduler']
Energy Efficiency,"ing: PrintVariantsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!?[0m. 16:58:10.116 INFO PrintVariantsSpark - Initializing engine; 16:58:10.116 INFO PrintVariantsSpark - Done initializing engine; 19/02/18 16:58:10 WARN org.apache.spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 19/02/18 16:58:10 INFO org.spark_project.jetty.util.log: Logging initialized @8431ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.Server: Started @8536ms; 19/02/18 16:58:11 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@45c90a05{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 19/02/18 16:58:11 WARN org.apache.spark.scheduler.FairSchedulableBuilder: Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.; 19/02/18 16:58:12 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:8032; 19/02/18 16:58:13 INFO org.apache.hadoop.yarn.client.AHSProxy: Connecting to Application History server at gatk-test-2495f43b-04fc-49e7-aa0a-7108cc876246-m/10.240.0.11:10200; 19/02/18 16:58:15 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1550508751046_0004; WARNING	2019-02-18 16:58:23	AsciiLineReader	Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; WARNING	2019-02-18 16:58:23	AsciiLineReader	Creating an indexable source for an Asc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:4643,schedul,scheduler,4643,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,irHMM - Total compute time in PairHMM computeLogLikelihoods() : 6.453042841; 15:48:19.347 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 10.39 sec; 15:48:19.348 INFO Mutect2 - Shutting down engine; [28 novembre 2019 15:48:19 CET] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.72 minutes.; Runtime.totalMemory()=3822583808; java.lang.IllegalArgumentException: Cannot construct fragment from more than two reads; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:725); 	at org.broadinstitute.hellbender.utils.read.Fragment.create(Fragment.java:36); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods.groupEvidence(AlleleLikelihoods.java:595); 	at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:93); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:251); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:320); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:308); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:281); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	a,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6271#issuecomment-559553558:4319,Reduce,ReduceOps,4319,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6271#issuecomment-559553558,1,['Reduce'],['ReduceOps']
Energy Efficiency,"irst 15 tasks are for partitions Vector(0)); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks; 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, com2, executor 1, partition 0, NODE_LOCAL, 4632 bytes); 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on com2:45501 (size: 32.6 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.131.101.145:54024; 17/10/13 18:11:53 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 135 bytes; 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on com2:45501 (size: 2.1 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 565 ms on com2 (executor 1) (1/1); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: ResultStage 1 (runJob at SparkHadoopMapReduceWriter.scala:88) finished in 0.566 s; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Job 0 finished: runJob at SparkHadoopMapReduceWriter.scala:88, took 9.524571 s; 17/10/13 18:11:53 INFO io.SparkHadoopMapReduceWriter: Job job_20171013181144_0009 committed.; 17/10/13 18:11:53 INFO server.AbstractConnector: Stopped Spark@131ba51c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/10/13 18:11:53 INFO ui.SparkUI: Stopped Spark web UI at http://10.131.101.159:4040; 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 17/10/13 18:11:54 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 17/10/13 18:11:54 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 17/10/13 18:11:54 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 17/10/13 18:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:21387,schedul,scheduler,21387,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['schedul'],['scheduler']
Energy Efficiency,ite(BypassMergeSortShuffleWriter.java:125); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.s,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:41288,schedul,scheduler,41288,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['schedul'],['scheduler']
Energy Efficiency,"itions; 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (runJob at SparkHadoopMapReduceWriter.scala:88); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157), which has no missing parents; 17/10/13 18:11:44 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 15.9 KB, free 366.0 MB); 17/10/13 18:11:44 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.0 MB); 17/10/13 18:11:44 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.131.101.159:44818 (size: 7.3 KB, free: 366.3 MB); 17/10/13 18:11:44 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006; 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157) (first 15 tasks are for partitions Vector(0)); 17/10/13 18:11:44 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks; 17/10/13 18:11:45 INFO spark.ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1); 17/10/13 18:11:48 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.131.101.145:54024) with ID 1; 17/10/13 18:11:48 INFO spark.ExecutorAllocationManager: New executor 1 has registered (new total is 1); 17/10/13 18:11:48 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, com2, executor 1, partition 0, NODE_LOCAL, 4877 bytes); 17/10/13 18:11:48 INFO storage.BlockManagerMasterEndpoint: Registering block manager com2:45501 with 366.3 MB RAM, BlockManagerId(1, com2, 45501, None); 17/10/13 18:11:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:17648,schedul,scheduler,17648,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['schedul'],['scheduler']
Energy Efficiency,"itute/gatk/pull/2594?src=pr&el=h1) Report; > Merging [#2594](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/2ecdef4fba1658930c388676be3e388efd67b6a3?src=pr&el=desc) will **increase** coverage by `0.002%`.; > The diff coverage is `0%`. ```diff; @@ Coverage Diff @@; ## master #2594 +/- ##; ===============================================; + Coverage 75.985% 75.987% +0.003% ; - Complexity 11033 11034 +1 ; ===============================================; Files 769 769 ; Lines 40058 40058 ; Branches 6979 6979 ; ===============================================; + Hits 30438 30439 +1 ; Misses 6981 6981 ; + Partials 2639 2638 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...tute/hellbender/tools/BwaMemIndexImageCreator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Cd2FNZW1JbmRleEltYWdlQ3JlYXRvci5qYXZh) | `71.429% <0%> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `95.313% <0%> (+1.563%)` | `22% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=footer). Last update [2ecdef4...a853f7c](https://codecov.io/gh/broadinstitute/gatk/pull/2594?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2594#issuecomment-293665515:1767,Power,Powered,1767,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2594#issuecomment-293665515,1,['Power'],['Powered']
Energy Efficiency,"java:125); 	... 18 more; 19/02/18 16:58:29 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@45c90a05{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 16:58:29.970 INFO PrintVariantsSpark - Shutting down engine; [February 18, 2019 4:58:29 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.34 minutes.; Runtime.totalMemory()=1106771968; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: java.lang.NullPointerException; Serialization trace:; genotypes (htsjdk.variant.variantcontext.VariantContext); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:9615,schedul,scheduler,9615,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,"java:157) finished in 8.668 s; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: looking for newly runnable stages; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: running: Set(); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: failed: Set(); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/13 18:11:53 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.8 KB, free 365.9 MB); 17/10/13 18:11:53 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KB, free 365.8 MB); 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.131.101.159:44818 (size: 32.6 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244) (first 15 tasks are for partitions Vector(0)); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks; 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, com2, executor 1, partition 0, NODE_LOCAL, 4632 bytes); 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on com2:45501 (size: 32.6 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.131.101.145:54024; 17/10/13 18:11:53 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 135 bytes; 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on com2:45501 (size: 2.1 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:20223,schedul,scheduler,20223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['schedul'],['scheduler']
Energy Efficiency,"java:73) with 252 output partitions; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 1148.4 KB, free 8.4 GB); 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 345.8 KB, free 8.4 GB); 18/03/07 13:59:26 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:32895 (size: 345.8 KB, free: 8.4 GB); 18/03/07 13:59:26 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting 252 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 13:59:26 INFO cluster.YarnScheduler: Adding task set 0.0 with 252 tasks; 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 0, scc-q05.scc.bu.edu, executor 4, partition 2, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 25.0 in stage 0.0 (TID 1, scc-q10.scc.bu.edu, executor 3, partition 25, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 15.0 in stage 0.0 (TID 2, scc-q07.scc.bu.edu, executor 1, partition 15, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 3, scc-q16.scc.bu.edu, executor 8, partition 4, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 4, scc-q14.scc.bu.edu, executor 2, partition 3, NODE_LOCAL, 6147 bytes). ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304:3133,schedul,scheduler,3133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304,5,['schedul'],['scheduler']
Energy Efficiency,k.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:41523,schedul,scheduler,41523,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['schedul'],['scheduler']
Energy Efficiency,"k/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9CcmVha3BvaW50RXZpZGVuY2UuamF2YQ==) | `86.025% <0%> (+4.561%)` | `30% <0%> (+6%)` | :arrow_up: |; | [...ute/hellbender/tools/spark/bwa/BwaSparkEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmtFbmdpbmUuamF2YQ==) | `94.805% <0%> (+4.805%)` | `8% <0%> (+3%)` | :arrow_up: |; | [...titute/hellbender/tools/spark/sv/ReadMetadata.java](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkTWV0YWRhdGEuamF2YQ==) | `89.297% <0%> (+7.018%)` | `33% <0%> (+11%)` | :arrow_up: |; | [...ute/hellbender/utils/bwa/BwaMemAlignmentUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9id2EvQndhTWVtQWxpZ25tZW50VXRpbHMuamF2YQ==) | `85.507% <0%> (+13.093%)` | `17% <0%> (+1%)` | :arrow_up: |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `55.233% <0%> (+14.764%)` | `38% <0%> (+10%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=footer). Last update [d054e7a...8ecb688](https://codecov.io/gh/broadinstitute/gatk/pull/2581?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2581#issuecomment-292631877:3907,Power,Powered,3907,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2581#issuecomment-292631877,1,['Power'],['Powered']
Energy Efficiency,"l is 1); 17/10/13 18:11:48 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, com2, executor 1, partition 0, NODE_LOCAL, 4877 bytes); 17/10/13 18:11:48 INFO storage.BlockManagerMasterEndpoint: Registering block manager com2:45501 with 366.3 MB RAM, BlockManagerId(1, com2, 45501, None); 17/10/13 18:11:50 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on com2:45501 (size: 7.3 KB, free: 366.3 MB); 17/10/13 18:11:51 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on com2:45501 (size: 26.0 KB, free: 366.3 MB); 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4638 ms on com2 (executor 1) (1/1); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool ; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (mapToPair at SparkUtils.java:157) finished in 8.668 s; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: looking for newly runnable stages; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: running: Set(); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: failed: Set(); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/13 18:11:53 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.8 KB, free 365.9 MB); 17/10/13 18:11:53 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KB, free 365.8 MB); 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.131.101.159:44818 (size: 32.6 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:19346,schedul,scheduler,19346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['schedul'],['scheduler']
Energy Efficiency,"l=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9TZWxlY3RWYXJpYW50cy5qYXZh) | `80% <100%> (ø)` | `119 <0> (ø)` | :arrow_down: |; | [...nder/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...cc1b2b9e9989a18f36d2014445eadce21bef3373?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nRW5naW5lLmphdmE=) | `46.491% <20%> (-0.411%)` | `32 <0> (ø)` | |; | [...ls/walkers/genotyper/afcalc/ExactAFCalculator.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...cc1b2b9e9989a18f36d2014445eadce21bef3373?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvRXhhY3RBRkNhbGN1bGF0b3IuamF2YQ==) | `81.818% <50%> (-8.182%)` | `6 <3> (+3)` | |; | [...stitute/hellbender/utils/genotyper/AlleleList.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...cc1b2b9e9989a18f36d2014445eadce21bef3373?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nZW5vdHlwZXIvQWxsZWxlTGlzdC5qYXZh) | `89.744% <0%> (+1.282%)` | `16% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2528?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2528?src=pr&el=footer). Last update [c62914a...cc1b2b9](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...cc1b2b9e9989a18f36d2014445eadce21bef3373?src=pr&el=footer&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2528#issuecomment-288859643:3970,Power,Powered,3970,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2528#issuecomment-288859643,1,['Power'],['Powered']
Energy Efficiency,lVariationDiscoveryPipelineSpark - Used 3957 evidence target links to annotate assembled breakpoints; 00:47:25.226 INFO StructuralVariationDiscoveryPipelineSpark - Called 336 imprecise deletion variants; 00:47:25.264 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 9651 variants.; 00:47:25.280 INFO StructuralVariationDiscoveryPipelineSpark - INV: 281; 00:47:25.281 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 5630; 00:47:25.281 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 2248; 00:47:25.281 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1492; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 0; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 0; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 0; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 18/04/27 00:47:28 WARN org.apache.spark.scheduler.TaskSetManager: Stage 19 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:47:33 WARN org.apache.spark.scheduler.TaskSetManager: Stage 20 contains a task of very large size (2685 KB). The maximum recommended task size is 100 KB.; 00:47:39.417 INFO StructuralVariationDiscoveryPipelineSpark - Processing 323040 raw alignments from 254678 contigs.; 18/04/27 00:47:39 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 00:47:47.083 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 225280 contigs.; 00:47:48.135 INFO StructuralVariationDiscoveryPipelineSpark - 23702 contigs with chimeric alignments potentially giving SV signals.; 18/04/27 00:47:49 WARN org.apache.spark.scheduler.TaskSetManager: Stage 32 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:47:57 WARN org.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199:1058,schedul,scheduler,1058,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199,1,['schedul'],['scheduler']
Energy Efficiency,lVariationDiscoveryPipelineSpark - Used 3957 evidence target links to annotate assembled breakpoints; 02:20:10.082 INFO StructuralVariationDiscoveryPipelineSpark - Called 336 imprecise deletion variants; 02:20:10.121 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 9651 variants.; 02:20:10.138 INFO StructuralVariationDiscoveryPipelineSpark - INV: 281; 02:20:10.138 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 5630; 02:20:10.138 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 2248; 02:20:10.138 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1492; 02:20:10.147 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 0; 02:20:10.148 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 02:20:10.148 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 0; 02:20:10.148 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 0; 02:20:10.148 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 18/04/27 02:20:12 WARN org.apache.spark.scheduler.TaskSetManager: Stage 19 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:18 WARN org.apache.spark.scheduler.TaskSetManager: Stage 20 contains a task of very large size (2599 KB). The maximum recommended task size is 100 KB.; 02:20:24.460 INFO StructuralVariationDiscoveryPipelineSpark - Processing 323040 raw alignments from 254678 contigs.; 18/04/27 02:20:24 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 02:20:32.040 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 225280 contigs.; 02:20:33.079 INFO StructuralVariationDiscoveryPipelineSpark - 23841 contigs with chimeric alignments potentially giving SV signals.; 18/04/27 02:20:34 WARN org.apache.spark.scheduler.TaskSetManager: Stage 32 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:42 WARN org.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199:4924,schedul,scheduler,4924,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199,1,['schedul'],['scheduler']
Energy Efficiency,la:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690:7120,schedul,scheduler,7120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690,1,['schedul'],['scheduler']
Energy Efficiency,"latter positives/negatives, and hence some arbitrariness in the F1 score itself. But I'd expect using gold-standard GIAB truth would be more straightforward. Not sure how much we can conclude, but that the validation and test F1s are similar and that the validation LL score isn't *too* far off are encouraging. That said, there is a pretty big drop in recall when optimizing LL. But we should also expect some discrepancy between LL and F1, according to one of the papers linked above. I would hope that with more variants or reliable training/truth (as in your data), things might stabilize or line up better. I'll try running with more malaria data, as well. The following trios x sites heatmap (top plot) for the validation set might better illustrate the arbitrariness in F1 (click to enlarge):. ![image](https://user-images.githubusercontent.com/11076296/158385585-1a0dfe8e-d4b7-4770-aed0-19ad81162c92.png). Here, yellow = het errors (since these are supposed to be clonal malaria samples), red = Mendelian errors, grey = no calls, green = Mendelian consistency, white = reference. The second plot shows the training/truth positives used to train the model and to calculate the LL score in the validation shard. The third plot shows the ""orthogonal truth"" positives/negatives used to calculate F1. So we can see that the difficulty in deriving F1 as a function of the score along the horizontal axis to give the third plot lies in collapsing the columns in the top plot into a single condition positive or condition negative status. Again, hard to do so without some arbitrariness; I simply came up with some rules to convert various amounts of red, yellow, green, etc. in each column to a red/white/green status. If you're using a single gold-standard sample, this should definitely be more straightforward. In any case, the optimal validation LL score at ~0.02 does appear to line up quite well visually with where one might manually set a threshold. It corresponds pretty well with the trans",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1067396431:1980,green,green,1980,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1067396431,2,['green'],['green']
Energy Efficiency,"lbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `88% <86.667%> (-12%)` | `7 <2> (+7)` | |; | [...ute/hellbender/tools/spark/bwa/BwaSparkEngine.java](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmtFbmdpbmUuamF2YQ==) | `89.286% <88%> (+18.697%)` | `5 <5> (+5)` | :white_check_mark: |; | [...itute/hellbender/tools/spark/sv/ContigAligner.java](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9Db250aWdBbGlnbmVyLmphdmE=) | `88.462% <88.889%> (+6.643%)` | `8 <4> (+8)` | :white_check_mark: |; | [...g/broadinstitute/hellbender/utils/NativeUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9OYXRpdmVVdGlscy5qYXZh) | `25% <ø> (-43.75%)` | `3% <ø> (+3%)` | |; | ... and [96 more](https://codecov.io/gh/broadinstitute/gatk/pull/2367/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2367?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2367?src=pr&el=footer). Last update [9d82097...975121e](https://codecov.io/gh/broadinstitute/gatk/compare/9d82097641f160e00fa1ef4236d9bcdccbfa38b0...975121efa109472c00cd8aa9b03359647b71749b?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2367#issuecomment-276460872:5068,Power,Powered,5068,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2367#issuecomment-276460872,1,['Power'],['Powered']
Energy Efficiency,"lbmRlci91dGlscy9waWxldXAvUGlsZXVwRWxlbWVudC5qYXZh) | `96.04% <0%> (+1.865%)` | `76 <0> (ø)` | :arrow_down: |; | [...bender/tools/exome/HashedListTargetCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9IYXNoZWRMaXN0VGFyZ2V0Q29sbGVjdGlvbi5qYXZh) | `90.741% <0%> (+1.65%)` | `43 <0> (ø)` | :arrow_down: |; | [.../utils/read/markduplicates/DuplicationMetrics.java](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL0R1cGxpY2F0aW9uTWV0cmljcy5qYXZh) | `85.366% <0%> (+2.033%)` | `13 <0> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/read/CigarUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL0NpZ2FyVXRpbHMuamF2YQ==) | `89.404% <0%> (+0.588%)` | `68 <0> (ø)` | :arrow_down: |; | [...der/utils/locusiterator/AlignmentStateMachine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9sb2N1c2l0ZXJhdG9yL0FsaWdubWVudFN0YXRlTWFjaGluZS5qYXZh) | `87.879% <0%> (+1.312%)` | `27 <1> (ø)` | :arrow_down: |; | ... and [22 more](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=footer). Last update [62d58c5...cd59cde](https://codecov.io/gh/broadinstitute/gatk/pull/2543?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2543#issuecomment-290171890:4331,Power,Powered,4331,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2543#issuecomment-290171890,1,['Power'],['Powered']
Energy Efficiency,"ld stuck at the first step `collect at ReadsSparkSource.java:220`, until we killed it. So I tried `--bamPartitionSize 4000000`, and it went through, but the Spark web interface showed errors in `sortByKey` steps:; ![sparkjob](https://user-images.githubusercontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:1104,schedul,scheduler,1104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363,1,['schedul'],['scheduler']
Energy Efficiency,led 336 imprecise deletion variants; 00:47:25.264 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 9651 variants.; 00:47:25.280 INFO StructuralVariationDiscoveryPipelineSpark - INV: 281; 00:47:25.281 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 5630; 00:47:25.281 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 2248; 00:47:25.281 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1492; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 0; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 0; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 0; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 18/04/27 00:47:28 WARN org.apache.spark.scheduler.TaskSetManager: Stage 19 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:47:33 WARN org.apache.spark.scheduler.TaskSetManager: Stage 20 contains a task of very large size (2685 KB). The maximum recommended task size is 100 KB.; 00:47:39.417 INFO StructuralVariationDiscoveryPipelineSpark - Processing 323040 raw alignments from 254678 contigs.; 18/04/27 00:47:39 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 00:47:47.083 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 225280 contigs.; 00:47:48.135 INFO StructuralVariationDiscoveryPipelineSpark - 23702 contigs with chimeric alignments potentially giving SV signals.; 18/04/27 00:47:49 WARN org.apache.spark.scheduler.TaskSetManager: Stage 32 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:47:57 WARN org.apache.spark.scheduler.TaskSetManager: Stage 33 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:48:04 WARN org.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199:1225,schedul,scheduler,1225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199,1,['schedul'],['scheduler']
Energy Efficiency,led 336 imprecise deletion variants; 02:20:10.121 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 9651 variants.; 02:20:10.138 INFO StructuralVariationDiscoveryPipelineSpark - INV: 281; 02:20:10.138 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 5630; 02:20:10.138 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 2248; 02:20:10.138 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1492; 02:20:10.147 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 0; 02:20:10.148 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 02:20:10.148 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 0; 02:20:10.148 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 0; 02:20:10.148 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 18/04/27 02:20:12 WARN org.apache.spark.scheduler.TaskSetManager: Stage 19 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:18 WARN org.apache.spark.scheduler.TaskSetManager: Stage 20 contains a task of very large size (2599 KB). The maximum recommended task size is 100 KB.; 02:20:24.460 INFO StructuralVariationDiscoveryPipelineSpark - Processing 323040 raw alignments from 254678 contigs.; 18/04/27 02:20:24 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 02:20:32.040 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 225280 contigs.; 02:20:33.079 INFO StructuralVariationDiscoveryPipelineSpark - 23841 contigs with chimeric alignments potentially giving SV signals.; 18/04/27 02:20:34 WARN org.apache.spark.scheduler.TaskSetManager: Stage 32 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:42 WARN org.apache.spark.scheduler.TaskSetManager: Stage 33 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:49 WARN org.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199:5091,schedul,scheduler,5091,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199,1,['schedul'],['scheduler']
Energy Efficiency,"ler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@64a1116a{/stages/stage,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@c5e69a5{/stages/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@10131289{/stages,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@50f4b83d{/jobs/job/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@5d66ae3a{/jobs/job,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@30159886{/jobs/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@33de7f3d{/jobs,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO ui.SparkUI: Stopped Spark web UI at http://10.48.225.55:4041; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 18/03/07 20:32:55 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 18/03/07 20:32:55 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Stopped; 18/03/07 20:32:55 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/03/07 20:32:55 INFO memory.MemoryStore: MemoryStore cleared; 18/03/07 20:32:55 INFO storage.BlockManager: BlockManager stopped; 18/03/07 20:32:55 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/03/07 20:32:55 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/03/07 20:32:55 INFO spark.SparkContext: Successfully stopped SparkContext; 20:32:55.769 INFO FlagStatSpark - Shutting down engine; [M",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:12670,monitor,monitor,12670,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,2,['monitor'],['monitor']
Energy Efficiency,lerArgumentCollection.createReadThreadingAssembler(AssemblyBasedCallerArgumentCollection.java:36); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.initialize(HaplotypeCallerEngine.java:231); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.<init>(HaplotypeCallerEngine.java:166); 	at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$assemblyFunction$29848511$1(HaplotypeCallerSpark.java:174); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:123); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	... 1 more; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:14264,schedul,scheduler,14264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,2,['schedul'],['scheduler']
Energy Efficiency,"llclockmax"": ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-NISTSampleHeadToHead/BenchmarkComparison/8e62c1c2-cf9c-4530-846e-1e0d6c6d8acf/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-NISTSampleHeadToHead/BenchmarkComparison/8e62c1c2-cf9c-4530-846e-1e0d6c6d8acf/call-BenchmarkVCFControlSample/Benchmark/e71074a5-27ad-4a8b-a533-cdc111c0374f/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""73.06777222222223"",; ""NIST evalHCsystemhours"": ""0.1622555555555555"",; ""NIST evalHCwallclockhours"": ""46.65241388888888"",; ""NIST evalHCwallclockmax"": ""2.7461055555555554"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-NISTSampleHeadToHead/BenchmarkComparison/8e62c1c2-cf9c-4530-846e-1e0d6c6d8acf/call-EVALRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9843"",; ""NIST evalindelPrecision"": ""0.9895"",; ""NIST evalsnpF1Score"": ""0.9908"",; ""NIST evalsnpPrecision"": ""0.992"",; ""NIST evalsnpRecall"": ""0.9896"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-NISTSampleHeadToHead/BenchmarkComparison/8e62c1c2-cf9c-4530-846e-1e0d6c6d8acf/call-BenchmarkVCFTestSample/Benchmark/d39f91bf-295b-4a15-bd0b-2b7c6b43a347/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-CreateHTMLReport/report.html""; }; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1069765064:14477,monitor,monitoring,14477,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1069765064,1,['monitor'],['monitoring']
Energy Efficiency,llerSpark.java:174); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.m,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690:6491,schedul,scheduler,6491,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690,1,['schedul'],['scheduler']
Energy Efficiency,"locks(BlockManager.scala:217); 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:236); 	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:522); 	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:547); 	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); 	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1953); 	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:547); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308); 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180); 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); 17/10/18 17:35:58 INFO BlockManagerMaster: BlockManagerMaster stopped; 17/10/18 17:35:58 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker-1,5,main]; java.lang.OutOfMemoryError: Java heap space; 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:208); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at org.seqdoop.hado",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:5647,Schedul,ScheduledThreadPoolExecutor,5647,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,1,['Schedul'],['ScheduledThreadPoolExecutor']
Energy Efficiency,loud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:109); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:507); 	... 12 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketIm,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931:7065,Meter,MeteredStream,7065,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931,1,['Meter'],['MeteredStream']
Energy Efficiency,"louises proposals seems simple and reasonable.... perhaps it should offer to provide a ```Function<R, String>``` to provide a alternative ```toString``` in case the tools natural record ```toString``` does not align well with progress reporting... or perhaps in that case the tool could use an alternative record object that is send to the progress meter instead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-577273465:349,meter,meter,349,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-577273465,2,['meter'],['meter']
Energy Efficiency,ls.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); at org.apache.spark.rdd.RDD.count(RDD.scala:1158); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.spark.pathseq.PathSeqPipelineSpark.runTool(PathSeqPipelineSpark.java:245); at org.broa,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:42195,schedul,scheduler,42195,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['schedul'],['scheduler']
Energy Efficiency,"mE=) | `96.87% <85.71%> (-1.46%)` | `15 <1> (+1)` | |; | [...lotypecaller/AssemblyBasedCallerUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHNVbml0VGVzdC5qYXZh) | `95.77% <95.28%> (-4.23%)` | `45 <43> (+43)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...te/hellbender/utils/genotyper/ReadLikelihoods.java](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nZW5vdHlwZXIvUmVhZExpa2VsaWhvb2RzLmphdmE=) | `90.14% <0%> (+0.4%)` | `143% <0%> (ø)` | :arrow_down: |; | ... and [1 more](https://codecov.io/gh/broadinstitute/gatk/pull/5215/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5215?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5215?src=pr&el=footer). Last update [8103bde...7d53fb9](https://codecov.io/gh/broadinstitute/gatk/pull/5215?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5215#issuecomment-425465744:4717,Power,Powered,4717,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5215#issuecomment-425465744,1,['Power'],['Powered']
Energy Efficiency,"max"": ""3.457286111111111"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-NISTSampleHeadToHead/BenchmarkComparison/8286c085-644b-44b0-aebc-84ef994ec99b/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-NISTSampleHeadToHead/BenchmarkComparison/8286c085-644b-44b0-aebc-84ef994ec99b/call-BenchmarkVCFControlSample/Benchmark/9033775b-223e-4c4a-8dc8-28b281b3f2e1/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""102.1011388888889"",; ""NIST evalHCsystemhours"": ""0.20356111111111105"",; ""NIST evalHCwallclockhours"": ""74.47628888888889"",; ""NIST evalHCwallclockmax"": ""4.013952777777778"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-NISTSampleHeadToHead/BenchmarkComparison/8286c085-644b-44b0-aebc-84ef994ec99b/call-EVALRuntimeTask/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-NISTSampleHeadToHead/BenchmarkComparison/8286c085-644b-44b0-aebc-84ef994ec99b/call-BenchmarkVCFTestSample/Benchmark/79b5d82e-a482-465f-a161-f82a21b0436f/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-CreateHTMLReport/report.html""; },; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535665125:21368,monitor,monitoring,21368,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535665125,1,['monitor'],['monitoring']
Energy Efficiency,"max"": ""3.995058333333333"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-NISTSampleHeadToHead/BenchmarkComparison/56974c24-19c8-4f87-b7b1-b71028109732/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-NISTSampleHeadToHead/BenchmarkComparison/56974c24-19c8-4f87-b7b1-b71028109732/call-BenchmarkVCFControlSample/Benchmark/670f9cb4-5bb0-48e2-95c9-15a2e1ae7dee/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""103.23083611111107"",; ""NIST evalHCsystemhours"": ""0.2083694444444444"",; ""NIST evalHCwallclockhours"": ""76.16374166666664"",; ""NIST evalHCwallclockmax"": ""3.743883333333333"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-NISTSampleHeadToHead/BenchmarkComparison/56974c24-19c8-4f87-b7b1-b71028109732/call-EVALRuntimeTask/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-NISTSampleHeadToHead/BenchmarkComparison/56974c24-19c8-4f87-b7b1-b71028109732/call-BenchmarkVCFTestSample/Benchmark/b84fd1b7-a21e-4098-aeaf-05de3b35b2df/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/acc9e2ac-b10a-4d6a-b586-cd3e47f04e41/call-CreateHTMLReport/report.html""; },; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1550601099:21344,monitor,monitoring,21344,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1550601099,1,['monitor'],['monitoring']
Energy Efficiency,"mparison/bec4eb1e-a99f-4e27-a91c-a56274c3824a/call-BenchmarkVCFControlSample/Benchmark/4d248a53-86e2-46f5-9d28-3364c82b9d0c/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.727"",; ""EXOME1 evalindelPrecision"": ""0.632"",; ""EXOME1 evalsnpF1Score"": ""0.9878"",; ""EXOME1 evalsnpPrecision"": ""0.9815"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607c8/call-EXOME1SampleHeadToHead/BenchmarkComparison/bec4eb1e-a99f-4e27-a91c-a56274c3824a/call-BenchmarkVCFTestSample/Benchmark/fcd023fe-e278-475d-8fce-613b57518972/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""96.55857222222222"",; ""NIST controlHCsystemhours"": ""0.1707444444444444"",; ""NIST controlHCwallclockhours"": ""69.28645"",; ""NIST controlHCwallclockmax"": ""3.8631972222222224"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607c8/call-NISTSampleHeadToHead/BenchmarkComparison/243c7bf2-b0d7-48ed-acd0-e2ebd74b9fd3/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607c8/call-NISTSampleHeadToHead/BenchmarkComparison/243c7bf2-b0d7-48ed-acd0-e2ebd74b9fd3/call-BenchmarkVCFControlSample/Benchmark/135b02c2-d7c5-4fd2-9cc5-cdeeed953bbc/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""103.49634722222224"",; ""NIST evalHCsystemhours"": ""0.20633611111111116"",; ""NIST evalHCwallclockhours"": ""75.91255833333332"",; ""NIST evalHCwallclockmax"": ""3.76305"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1546478988:20378,monitor,monitoring,20378,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1546478988,1,['monitor'],['monitoring']
Energy Efficiency,"my quickfix was to reduce the intervals to target regions of my WES (instead of using the full genome region) and give it to funcotator. Remark: The GATK mutect2 WDL does not give the default intervals to funcotator, only to mutect2.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1183119853:19,reduce,reduce,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1183119853,1,['reduce'],['reduce']
Energy Efficiency,n.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:38386,schedul,scheduler,38386,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,4,['schedul'],['scheduler']
Energy Efficiency,"nVja2V0VXRpbHMuamF2YQ==) | `43.75% <0%> (-29.861%)` | `27% <0%> (-9%)` | |; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `76.471% <0%> (-23.529%)` | `4% <0%> (ø)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-18.75%)` | `6% <0%> (ø)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | ... and [24 more](https://codecov.io/gh/broadinstitute/gatk/pull/2401?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2401?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2401?src=pr&el=footer). Last update [51360c7...51285dc](https://codecov.io/gh/broadinstitute/gatk/compare/51360c7357f47f1ce602e0a682aab3e37047440c...51285dcfa305e66b4af0c3e4a6c76376d6faeba9?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2401#issuecomment-279424649:5052,Power,Powered,5052,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2401#issuecomment-279424649,1,['Power'],['Powered']
Energy Efficiency,"nce id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:09 INFO TaskSetManager:54 - Starting task 1.2 in stage 0.0 (TID 6, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:09 INFO TaskSetManager:54 - Lost task 3.1 in stage 0.0 (TID 4) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d) [duplicate 1]; 2019-01-07 11:34:10 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 7, scc-q12.scc.bu.edu, executor 2, partition 2, NODE_LOCAL, 7992 bytes); 2019-01",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:28720,schedul,scheduler,28720,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['schedul'],['scheduler']
Energy Efficiency,"nce id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:50 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 4, scc-q20.scc.bu.edu, executor 2, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:50 WARN TaskSetManager:66 - Lost task 4.0 in stage 0.0 (TID 2, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.Autoclose",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:25818,schedul,scheduler,25818,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['schedul'],['scheduler']
Energy Efficiency,"nce id 2, start 131325815, span 181534, expected MD5 c240a972d49aa89fb57dae94d1d90d36; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:52 INFO TaskSetManager:54 - Starting task 1.2 in stage 0.0 (TID 7, scc-q20.scc.bu.edu, executor 2, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:52 INFO TaskSetManager:54 - Lost task 4.1 in stage 0.0 (TID 5) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683) [duplicate 1]; 2019-01-09 13:35:53 INFO TaskSetManager:54 - Starting task 7.1 in stage 0.0 (TID 8, scc-q01.scc.bu.edu, executor 1, partition 7, NODE_LOCAL, 7992 bytes); 2019-0",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:29745,schedul,scheduler,29745,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,2,['schedul'],['scheduler']
Energy Efficiency,nch manually on gcs and get a new error which I believe is a GCS NIO bug that we discussed in https://github.com/samtools/htsjdk/pull/724. . ```; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:11,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285797337:1019,schedul,scheduler,1019,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285797337,1,['schedul'],['scheduler']
Energy Efficiency,ncodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:1025); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:847); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:831); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:508); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:509); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellben,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680:2131,Reduce,ReduceOps,2131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,nds 11 --gvcf-gq-bands 12 --gvcf-gq-bands 13 --gvcf-gq-bands 14 --gvcf-gq-bands 15 --gvcf-gq-bands 16 --gvcf-gq-bands 17 --gvc; f-gq-bands 18 --gvcf-gq-bands 19 --gvcf-gq-bands 20 --gvcf-gq-bands 21 --gvcf-gq-bands 22 --gvcf-gq-bands 23 --gvcf-gq-bands 24 --gvcf-gq-bands 25 --gvcf-gq-bands 26 --gvcf-gq-bands 27 --g; vcf-gq-bands 28 --gvcf-gq-bands 29 --gvcf-gq-bands 30 --gvcf-gq-bands 31 --gvcf-gq-bands 32 --gvcf-gq-bands 33 --gvcf-gq-bands 34 --gvcf-gq-bands 35 --gvcf-gq-bands 36 --gvcf-gq-bands 37 -; -gvcf-gq-bands 38 --gvcf-gq-bands 39 --gvcf-gq-bands 40 --gvcf-gq-bands 41 --gvcf-gq-bands 42 --gvcf-gq-bands 43 --gvcf-gq-bands 44 --gvcf-gq-bands 45 --gvcf-gq-bands 46 --gvcf-gq-bands 47; --gvcf-gq-bands 48 --gvcf-gq-bands 49 --gvcf-gq-bands 50 --gvcf-gq-bands 51 --gvcf-gq-bands 52 --gvcf-gq-bands 53 --gvcf-gq-bands 54 --gvcf-gq-bands 55 --gvcf-gq-bands 56 --gvcf-gq-bands ; 57 --gvcf-gq-bands 58 --gvcf-gq-bands 59 --gvcf-gq-bands 60 --gvcf-gq-bands 70 --gvcf-gq-bands 80 --gvcf-gq-bands 90 --gvcf-gq-bands 99 --floor-blocks false --indel-size-to-eliminate-in-re; f-model 10 --disable-optimizations false --dragen-mode false --flow-mode NONE --apply-bqd false --apply-frd false --disable-spanning-event-genotyping false --transform-dragen-mapping-quali; ty false --mapping-quality-threshold-for-genotyping 20 --max-effective-depth-adjustment-for-frd 0 --just-determine-active-regions false --dont-genotype false --do-not-run-physical-phasing ; false --do-not-correct-overlapping-quality false --use-filtered-reads-for-annotations false --use-flow-aligner-for-stepwise-hc-filtering false --adaptive-pruning false --do-not-recover-dan; gling-branches false --recover-dangling-heads false --kmer-size 10 --kmer-size 25 --dont-increase-kmer-sizes-for-cycles false --allow-non-unique-kmers-in-ref false --num-pruning-samples 1 ; --min-dangling-branch-length 4 --recover-all-dangling-branches false --max-num-haplotypes-in-population 128 --min-pruning 2 --adaptive-pruning-initial-error-rate 0.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8574#issuecomment-1793390789:4845,adapt,adaptive-pruning,4845,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8574#issuecomment-1793390789,2,['adapt'],"['adaptive-pruning', 'adaptive-pruning-initial-error-rate']"
Energy Efficiency,nfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114); at org.apache.spark.internal.io.SparkHadoopWriter$.write,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690:7646,schedul,scheduler,7646,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690,1,['schedul'],['scheduler']
Energy Efficiency,nsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:123); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:10858,schedul,scheduler,10858,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['schedul'],['scheduler']
Energy Efficiency,nstitute.hellbender.utils.MathUtils.normalizeLog10(MathUtils.java:1098); 	at org.broadinstitute.hellbender.utils.MathUtils.normalizeFromLog10ToLinearSpace(MathUtils.java:1074); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:91); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:76); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:60); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:140); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:31); 	at or,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887:1436,Reduce,ReduceOps,1436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887,1,['Reduce'],['ReduceOps']
Energy Efficiency,"nt; > info for the following problem is that it is a ppc64le system. When I use; > HaplotypeCaller, I see the following messages on the screen:; >; > Running:; > java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx50G -jar /home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCaller -R ref.fa -I mybam.bam -O mycalls.vcf.gz -L snps.vcf -ip 100; >; > 16:17:04.377 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; >; > 16:17:04.397 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression3825249225068031371.so: /tmp/libgkl_compression3825249225068031371.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)); >; > 16:17:04.402 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; >; > 16:17:04.407 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression7506152962158874866.so: /tmp/libgkl_compression7506152962158874866.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)); >; > Sep 04, 2020 4:17:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; >; > INFO: Failed to detect whether we are running on Google Compute Engine.; >; > 16:17:05.842 INFO HaplotypeCaller - ------------------------------------------------------------; >; > 16:17:05.843 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.1; >; > 16:17:05.843 INFO HaplotypeCaller - For support and doc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6794#issuecomment-687344600:1894,Power,Power,1894,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794#issuecomment-687344600,1,['Power'],['Power']
Energy Efficiency,nterval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:144); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:362); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.NullPointerException; 	at htsjdk.variant.variantcontext.LazyGenotypesContext.decode(LazyGenotypesContext.java:158); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.invalidateSampleOrdering(LazyGenotypesContext.java:205); 	at ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:7122,schedul,scheduler,7122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,"o how is it obsolete?. Reply by @SHUANG-Broad (also copied to update the ""TODO"" message; > this predicate is currently used in two places (excluding appearance in comments): `BreakpointComplications.IntraChrStrandSwitchBreakpointComplications`, where it is use to test if the input simple chimera indicates an inverse tandem duplication and trigger the logic for inferring duplicated region; and `BreakpointsInference.IntraChrStrandSwitchBreakpointInference`, where it is used for breakpoint inference. The problem is, the contig will not even be sent here, because `AssemblyContigWithFineTunedAlignments.hasIncompletePictureFromTwoAlignments()` defines a simple chimera that has strand switch and the two alignments overlaps on reference as ""incomplete"", so in practice the two uses are not going to be triggered. But when we come back later and see what can be extracted from such ""incomplete"" contigs, these code could be useful again. So it is kept. ------------; ### On the problem of writing out SAM records of ""Unknown"" contigs efficiently. First round comment by @cwhelan ; > This seems like a very inefficient way to write these three files. You end up calling collect on the RDD three different times and then traversing the local collection three times. Why not make a map of contig name to bam file, collect the rdd once, and then traverse the local collection once, writing each read to the appropriate bam file from the map?. Second round comment by @cwhelan ; > This is a better but you are still collecting the RDD and passing over the collection three times. What I meant by my original suggestion was this: Why not make the map go the other way, ie make a Map<String, ReasonForAlignmentClassificationFailure> that maps contig names to their reasons? Then make a Map<ReasonForAlignmentClassificationFailure, SAMFileWriter> with three entries. Then you only have to iterate over the collection of reads once to write everything out (you just look up the writer for each entry). Reply ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030:3703,efficient,efficiently,3703,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-387899030,2,['efficient'],['efficiently']
Energy Efficiency,oadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:338); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:138); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:113); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.lambda$enqueueAndHandleVariant$0(Funcotator.java:502); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:504); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:399); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:109); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequenti,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-811170886:1292,Reduce,ReduceOps,1292,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-811170886,1,['Reduce'],['ReduceOps']
Energy Efficiency,"ok, got it. sorry, i missed 'install' in that command. my initial impression is that VariantQC will be able to adapt fine to VariantEvalEngine. I wrote VariantEvalEngine with this is mind, but it's good to formally test it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-759645374:111,adapt,adapt,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-759645374,1,['adapt'],['adapt']
Energy Efficiency,"olders named ""SAMPLE_#""), and just check the sample_name.txt files at the PostprocessGermlineCNVCalls step. I don't think this should require GermlineCNVCaller code changes, right?. 4) We may require additional code at the WDL level if we want to both switch over to primarily using sample names but also get rid of bundling (i.e., by passing only the calls for each sample when needed). Locally, you can always just search all output for directories containing the appropriate sample_name.txt. But on the cloud, you'd want to make sure that the postprocessing step for a particular sample gets only its corresponding directories, which would have to happen at the WDL level; the check against sample_name.txt at the tool level would just be a formality. I can foresee headaches with globbing and funky sample names. I'm not sure I understand your point about extending PostprocessGermlineCNVCalls to run on all samples. The point of that tool is to take results from all genomic shards for a single sample and stitch them together, right? Even if we extend this to run on a batch of multiple samples (which would just be moving the loop over samples at the WDL level to some lower level, i.e., Java or python), we still need to see all shards for those samples. Perhaps I'm misunderstanding---can you clarify?. @mwalker174 can we once and for all clearly document the issue with the transpose? Perhaps by pointing to specific WGS runs that have issues with call caching? I think being able to pinpoint the exact issue will help us identify the right solution---whether that be choosing an appropriate bundling scheme, taking advantage of #5781 to reduce the number of shards, batching during the postprocessing step, removing unnecessary outputs, etc. Recall that we'd like to be able to use the same WDL locally (when you have easy access to all GermlineCNVCaller results from all genomic shards) and in the cloud, with minimal duplication of output from bundling when running locally, if possible.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6659#issuecomment-644829765:2968,reduce,reduce,2968,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6659#issuecomment-644829765,2,['reduce'],['reduce']
Energy Efficiency,ols.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:152); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:162); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:924); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:878); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); at java.base/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680:3721,Reduce,ReduceOps,3721,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6345#issuecomment-1695460680,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"omparison/1269d993-e13f-4635-a12a-e65fdaa4ed16/call-BenchmarkVCFControlSample/Benchmark/492b823a-1e34-46cd-b842-5f042bb31ee8/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.727"",; ""EXOME1 evalindelPrecision"": ""0.632"",; ""EXOME1 evalsnpF1Score"": ""0.9878"",; ""EXOME1 evalsnpPrecision"": ""0.9815"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/89508d5f-29f1-4534-9fe1-220a80de17c4/call-EXOME1SampleHeadToHead/BenchmarkComparison/1269d993-e13f-4635-a12a-e65fdaa4ed16/call-BenchmarkVCFTestSample/Benchmark/834b6562-65d7-4daf-857a-d9118a6456b7/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""90.94291388888888"",; ""NIST controlHCsystemhours"": ""0.182125"",; ""NIST controlHCwallclockhours"": ""63.56370277777778"",; ""NIST controlHCwallclockmax"": ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/89508d5f-29f1-4534-9fe1-220a80de17c4/call-NISTSampleHeadToHead/BenchmarkComparison/338d644e-3327-471e-9d17-1c103fa5e01e/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/89508d5f-29f1-4534-9fe1-220a80de17c4/call-NISTSampleHeadToHead/BenchmarkComparison/338d644e-3327-471e-9d17-1c103fa5e01e/call-BenchmarkVCFControlSample/Benchmark/145d88de-5810-47e1-972a-18ff0169fe27/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""92.82975"",; ""NIST evalHCsystemhours"": ""0.17177777777777778"",; ""NIST evalHCwallclockhours"": ""66.4404388888889"",; ""NIST evalHCwallclockmax"": ""3.325327777777778"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/89508d5f-29f1-4534-9fe1-220a80de17c",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1193038382:19691,monitor,monitoring,19691,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1193038382,1,['monitor'],['monitoring']
Energy Efficiency,"omparison/3b586c16-feb0-4cdd-8850-8426205cced2/call-BenchmarkVCFControlSample/Benchmark/31dfb54a-9ecc-4af2-9fcd-ea9af745342e/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.727"",; ""EXOME1 evalindelPrecision"": ""0.632"",; ""EXOME1 evalsnpF1Score"": ""0.9878"",; ""EXOME1 evalsnpPrecision"": ""0.9815"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0ccf52/call-EXOME1SampleHeadToHead/BenchmarkComparison/3b586c16-feb0-4cdd-8850-8426205cced2/call-BenchmarkVCFTestSample/Benchmark/7c7e45ee-4fe9-48e6-b8ed-cd4372c9e726/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""90.94291388888888"",; ""NIST controlHCsystemhours"": ""0.182125"",; ""NIST controlHCwallclockhours"": ""63.56370277777778"",; ""NIST controlHCwallclockmax"": ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0ccf52/call-NISTSampleHeadToHead/BenchmarkComparison/d1a60d2b-8100-459a-9b05-72a22afccb4a/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0ccf52/call-NISTSampleHeadToHead/BenchmarkComparison/d1a60d2b-8100-459a-9b05-72a22afccb4a/call-BenchmarkVCFControlSample/Benchmark/9f6d4e85-981d-4607-8ff6-97495034807f/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""96.65376666666666"",; ""NIST evalHCsystemhours"": ""0.17881944444444442"",; ""NIST evalHCwallclockhours"": ""68.38394444444445"",; ""NIST evalHCwallclockmax"": ""3.8226138888888888"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1182703672:19704,monitor,monitoring,19704,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1182703672,1,['monitor'],['monitoring']
Energy Efficiency,"omparison/3ba68beb-5853-4beb-b31c-cbef12825001/call-BenchmarkVCFControlSample/Benchmark/18840f82-6653-4365-8e02-daf8790ea4f0/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.727"",; ""EXOME1 evalindelPrecision"": ""0.632"",; ""EXOME1 evalsnpF1Score"": ""0.9878"",; ""EXOME1 evalsnpPrecision"": ""0.9815"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/6ea2705f-a3fa-41fc-8d17-a2c55d875eab/call-EXOME1SampleHeadToHead/BenchmarkComparison/3ba68beb-5853-4beb-b31c-cbef12825001/call-BenchmarkVCFTestSample/Benchmark/194337cf-f57b-46fa-812c-e6510f51fd8d/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""90.94291388888888"",; ""NIST controlHCsystemhours"": ""0.182125"",; ""NIST controlHCwallclockhours"": ""63.56370277777778"",; ""NIST controlHCwallclockmax"": ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/6ea2705f-a3fa-41fc-8d17-a2c55d875eab/call-NISTSampleHeadToHead/BenchmarkComparison/a39481f5-0969-4891-a843-f3c3fd7437d1/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/6ea2705f-a3fa-41fc-8d17-a2c55d875eab/call-NISTSampleHeadToHead/BenchmarkComparison/a39481f5-0969-4891-a843-f3c3fd7437d1/call-BenchmarkVCFControlSample/Benchmark/0c99102a-bca1-4426-97c6-5a311ace93c1/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""95.62183055555556"",; ""NIST evalHCsystemhours"": ""0.18361111111111117"",; ""NIST evalHCwallclockhours"": ""64.22846111111112"",; ""NIST evalHCwallclockmax"": ""3.3683277777777776"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/6ea2705f-a3fa-41fc-8d17-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069766207:13477,monitor,monitoring,13477,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069766207,1,['monitor'],['monitoring']
Energy Efficiency,"omparison/4803682b-a3c6-46d6-924b-dbc96a877e16/call-BenchmarkVCFControlSample/Benchmark/dd059ca4-251d-4793-bbff-10dd76123882/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.727"",; ""EXOME1 evalindelPrecision"": ""0.632"",; ""EXOME1 evalsnpF1Score"": ""0.9878"",; ""EXOME1 evalsnpPrecision"": ""0.9815"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-EXOME1SampleHeadToHead/BenchmarkComparison/4803682b-a3c6-46d6-924b-dbc96a877e16/call-BenchmarkVCFTestSample/Benchmark/e3563584-017d-476b-bbca-775128c80272/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""90.94291388888888"",; ""NIST controlHCsystemhours"": ""0.182125"",; ""NIST controlHCwallclockhours"": ""63.56370277777778"",; ""NIST controlHCwallclockmax"": ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-NISTSampleHeadToHead/BenchmarkComparison/ccdb901c-fb8f-49e4-b542-cf42e011a623/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-NISTSampleHeadToHead/BenchmarkComparison/ccdb901c-fb8f-49e4-b542-cf42e011a623/call-BenchmarkVCFControlSample/Benchmark/6d64f12a-ca50-4ecd-8608-93dc53d241bb/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""95.62183055555556"",; ""NIST evalHCsystemhours"": ""0.18361111111111117"",; ""NIST evalHCwallclockhours"": ""64.22846111111112"",; ""NIST evalHCwallclockmax"": ""3.3683277777777776"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069378815:13477,monitor,monitoring,13477,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069378815,1,['monitor'],['monitoring']
Energy Efficiency,"omparison/5bf5f11a-64cb-4b50-8d05-b61b7f4c803c/call-BenchmarkVCFControlSample/Benchmark/c64dbce6-4a90-42c0-a84b-59857afb98a5/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.727"",; ""EXOME1 evalindelPrecision"": ""0.632"",; ""EXOME1 evalsnpF1Score"": ""0.9878"",; ""EXOME1 evalsnpPrecision"": ""0.9815"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9bc521dc-3c4c-4274-972c-9d1e4be850d5/call-EXOME1SampleHeadToHead/BenchmarkComparison/5bf5f11a-64cb-4b50-8d05-b61b7f4c803c/call-BenchmarkVCFTestSample/Benchmark/d501a36a-a881-4e5c-9499-ef7dea22980f/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""90.94291388888888"",; ""NIST controlHCsystemhours"": ""0.182125"",; ""NIST controlHCwallclockhours"": ""63.56370277777778"",; ""NIST controlHCwallclockmax"": ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9bc521dc-3c4c-4274-972c-9d1e4be850d5/call-NISTSampleHeadToHead/BenchmarkComparison/4ffa2353-b1bc-4960-a5a4-96291208a7eb/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9bc521dc-3c4c-4274-972c-9d1e4be850d5/call-NISTSampleHeadToHead/BenchmarkComparison/4ffa2353-b1bc-4960-a5a4-96291208a7eb/call-BenchmarkVCFControlSample/Benchmark/8cf95ec9-48a7-4e20-a8fe-816dc3e652ae/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""100.56416111111112"",; ""NIST evalHCsystemhours"": ""0.19999166666666665"",; ""NIST evalHCwallclockhours"": ""74.00048055555555"",; ""NIST evalHCwallclockmax"": ""4.007605555555555"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9bc521dc-3c4c-4274-972c-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1533946590:20364,monitor,monitoring,20364,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1533946590,1,['monitor'],['monitoring']
Energy Efficiency,"omparison/688ca200-89b9-479b-b701-5fa0b0854778/call-BenchmarkVCFControlSample/Benchmark/59d8f8b1-1323-4e56-a1b1-0b1b2c8f2cc0/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.727"",; ""EXOME1 evalindelPrecision"": ""0.632"",; ""EXOME1 evalsnpF1Score"": ""0.9878"",; ""EXOME1 evalsnpPrecision"": ""0.9815"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd684393ff6c/call-EXOME1SampleHeadToHead/BenchmarkComparison/688ca200-89b9-479b-b701-5fa0b0854778/call-BenchmarkVCFTestSample/Benchmark/1b8ccc58-1ead-4443-b6a8-64f767abfc70/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""90.94291388888888"",; ""NIST controlHCsystemhours"": ""0.182125"",; ""NIST controlHCwallclockhours"": ""63.56370277777778"",; ""NIST controlHCwallclockmax"": ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd684393ff6c/call-NISTSampleHeadToHead/BenchmarkComparison/d1047505-b7bc-455d-851f-fbed8d81e895/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd684393ff6c/call-NISTSampleHeadToHead/BenchmarkComparison/d1047505-b7bc-455d-851f-fbed8d81e895/call-BenchmarkVCFControlSample/Benchmark/5388d7b6-6bcd-451d-9a4e-925b386ecd0c/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""95.03499722222222"",; ""NIST evalHCsystemhours"": ""0.17304166666666665"",; ""NIST evalHCwallclockhours"": ""67.81165555555557"",; ""NIST evalHCwallclockmax"": ""3.691061111111111"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-b",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1194801748:19705,monitor,monitoring,19705,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1194801748,1,['monitor'],['monitoring']
Energy Efficiency,"omparison/ba4f3a3f-c40c-4037-837a-0bf9a85d0ece/call-BenchmarkVCFControlSample/Benchmark/61548750-761a-42ff-8d40-c80f94866dcd/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.727"",; ""EXOME1 evalindelPrecision"": ""0.632"",; ""EXOME1 evalsnpF1Score"": ""0.9878"",; ""EXOME1 evalsnpPrecision"": ""0.9815"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-EXOME1SampleHeadToHead/BenchmarkComparison/ba4f3a3f-c40c-4037-837a-0bf9a85d0ece/call-BenchmarkVCFTestSample/Benchmark/476aa516-7233-4df2-8fc5-83b3f2df9eb6/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""95.8154"",; ""NIST controlHCsystemhours"": ""0.1727638888888889"",; ""NIST controlHCwallclockhours"": ""69.03862222222223"",; ""NIST controlHCwallclockmax"": ""3.457286111111111"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-NISTSampleHeadToHead/BenchmarkComparison/8286c085-644b-44b0-aebc-84ef994ec99b/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-NISTSampleHeadToHead/BenchmarkComparison/8286c085-644b-44b0-aebc-84ef994ec99b/call-BenchmarkVCFControlSample/Benchmark/9033775b-223e-4c4a-8dc8-28b281b3f2e1/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""102.1011388888889"",; ""NIST evalHCsystemhours"": ""0.20356111111111105"",; ""NIST evalHCwallclockhours"": ""74.47628888888889"",; ""NIST evalHCwallclockmax"": ""4.013952777777778"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535665125:20381,monitor,monitoring,20381,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535665125,1,['monitor'],['monitoring']
Energy Efficiency,"omparison/efb51584-614a-4702-bc80-17a6a388e888/call-BenchmarkVCFControlSample/Benchmark/ea5e6517-663b-4cfb-b264-0dc933da9ae3/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.727"",; ""EXOME1 evalindelPrecision"": ""0.632"",; ""EXOME1 evalsnpF1Score"": ""0.9878"",; ""EXOME1 evalsnpPrecision"": ""0.9815"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/0e5c32ab-65e6-451f-a04e-6a3f5e7fe5c8/call-EXOME1SampleHeadToHead/BenchmarkComparison/efb51584-614a-4702-bc80-17a6a388e888/call-BenchmarkVCFTestSample/Benchmark/086dd5e8-74c8-4603-b618-a70d77398545/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""90.94291388888888"",; ""NIST controlHCsystemhours"": ""0.182125"",; ""NIST controlHCwallclockhours"": ""63.56370277777778"",; ""NIST controlHCwallclockmax"": ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/0e5c32ab-65e6-451f-a04e-6a3f5e7fe5c8/call-NISTSampleHeadToHead/BenchmarkComparison/ed0dc9e1-2d64-47e4-82e0-811971957020/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/0e5c32ab-65e6-451f-a04e-6a3f5e7fe5c8/call-NISTSampleHeadToHead/BenchmarkComparison/ed0dc9e1-2d64-47e4-82e0-811971957020/call-BenchmarkVCFControlSample/Benchmark/8c516721-e955-41d1-907e-fcee92f592d3/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""100.56416111111112"",; ""NIST evalHCsystemhours"": ""0.19999166666666665"",; ""NIST evalHCwallclockhours"": ""74.00048055555555"",; ""NIST evalHCwallclockmax"": ""4.007605555555555"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/0e5c32ab-65e6-451f-a04e-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535104202:20398,monitor,monitoring,20398,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535104202,1,['monitor'],['monitoring']
Energy Efficiency,"on **data representation**:. @laserson: yes, I think it makes total sense to eventually move to a better format. The requirements seem to be: (a) efficient serialization/deserialization, and (b) can easily convert to a SAMRecord for compatibility with existing code. We can make things extra efficient by only deserializing things if they are needed (if a phase doesn't need the CIGAR-related structures, no need to deserialize that). We can achieve this by having the deserialization be lazy. The LazyBAMRecord is a step in that direction since it looks up the reference name only if we ask for it, but we could go a lot further in this direction. But before we do that, having an efficient coder for SAMRecords (I vote for @tomwhite's approach of using the BAMEncoder) will get us 80% of the way for 20% of the effort. Then we can introduce our OptimizedSAMRecord incrementally. . on **headers**:. I agree with @tomwhite that adding the header back after a shuffle is the right thing to do. We know where that happens and we control that code.; @davidadamsphd, you worry about newcomers. But we've already decided that we were going to provide our own API for them (one that does the Dataflow copying for them so they don't have to worry about it). This same API will provide them with header-filled reads, so they don't have to worry about this detail. This falls into the general category of ""the 3rd party devs won't have to even know about Dataflow/Spark: they just need to know our nice, simple interface and use that"". If they know more and want to do fancier things then more power to them, but those users will surely be able to fill in headers, too. We have library functions to use the reads without the headers, but the problem is that (at least for the sort of code I'm writing), I'm handing off a SAMRecord to a big black box and I can't force it to use the library functions - it's going to work on the SAMRecord directly. So at least in this case it's important to fill in the header ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141151451:146,efficient,efficient,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141151451,3,['efficient'],['efficient']
Energy Efficiency,"onTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db21wYXJlSW50ZXJ2YWxMaXN0c0ludGVncmF0aW9uVGVzdC5qYXZh) | `100% <100%> (ø)` | `4 <4> (?)` | |; | [...stitute/hellbender/tools/CompareIntervalLists.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db21wYXJlSW50ZXJ2YWxMaXN0cy5qYXZh) | `93.33% <93.33%> (ø)` | `4 <4> (?)` | |; | [...broadinstitute/hellbender/utils/IntervalUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlcnZhbFV0aWxzLmphdmE=) | `91.88% <0%> (+0.35%)` | `188% <0%> (+1%)` | :arrow_up: |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.77% <0%> (+0.47%)` | `33% <0%> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3702/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `79.87% <0%> (+1.21%)` | `42% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3702?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3702?src=pr&el=footer). Last update [a74e571...8f85021](https://codecov.io/gh/broadinstitute/gatk/pull/3702?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3702#issuecomment-337303370:2898,Power,Powered,2898,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3702#issuecomment-337303370,1,['Power'],['Powered']
Energy Efficiency,or$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.s,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:38346,schedul,scheduler,38346,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,4,['schedul'],['scheduler']
Energy Efficiency,or.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(Sp,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:41774,schedul,scheduler,41774,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['schedul'],['scheduler']
Energy Efficiency,org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690:7218,schedul,scheduler,7218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601702690,1,['schedul'],['scheduler']
Energy Efficiency,org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 14 more,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:2221,Meter,MeteredStream,2221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,2,['Meter'],['MeteredStream']
Energy Efficiency,"orted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:935); at org.apache.spark.rdd.RD",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:1775,schedul,scheduler,1775,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363,1,['schedul'],['scheduler']
Energy Efficiency,ory.java:564); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:907); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:861); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-783746069:4057,Reduce,ReduceOps,4057,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-783746069,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,otFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); at org.apache.spark.SparkContext.runJob(SparkContext.sca,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:41854,schedul,scheduler,41854,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['schedul'],['scheduler']
Energy Efficiency,oud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:507); 	... 12 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 15 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.ja,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931:8501,Meter,MeteredStream,8501,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-301610931,1,['Meter'],['MeteredStream']
Energy Efficiency,oud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 47 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 50 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.ja,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727:6795,Meter,MeteredStream,6795,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727,1,['Meter'],['MeteredStream']
Energy Efficiency,oud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 58 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:209); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketI,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:10283,Meter,MeteredStream,10283,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138,1,['Meter'],['MeteredStream']
Energy Efficiency,"our cluster is centos7, but i could work with whatever you're able to most efficiently create. we really appreciate the help here.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-722660469:75,efficient,efficiently,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-722660469,1,['efficient'],['efficiently']
Energy Efficiency,"parison/113b01be-9124-41dd-acc0-5732ef2c7b38/call-BenchmarkVCFControlSample/Benchmark/7222f3cf-155c-423f-bc1e-8194e87ff05f/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.7573"",; ""EXOME1 evalindelPrecision"": ""0.6882"",; ""EXOME1 evalsnpF1Score"": ""0.9896"",; ""EXOME1 evalsnpPrecision"": ""0.9852"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e372bd14-cd1f-4563-8d8a-abf6b6ca7883/call-EXOME1SampleHeadToHead/BenchmarkComparison/113b01be-9124-41dd-acc0-5732ef2c7b38/call-BenchmarkVCFTestSample/Benchmark/e929ad45-5026-4630-8b85-19f6205f068c/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""90.94291388888888"",; ""NIST controlHCsystemhours"": ""0.182125"",; ""NIST controlHCwallclockhours"": ""63.56370277777778"",; ""NIST controlHCwallclockmax"": ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e372bd14-cd1f-4563-8d8a-abf6b6ca7883/call-NISTSampleHeadToHead/BenchmarkComparison/103cd89c-b177-4a0b-84fc-9553a1f8161f/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9843"",; ""NIST controlindelPrecision"": ""0.9895"",; ""NIST controlsnpF1Score"": ""0.9908"",; ""NIST controlsnpPrecision"": ""0.992"",; ""NIST controlsnpRecall"": ""0.9896"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e372bd14-cd1f-4563-8d8a-abf6b6ca7883/call-NISTSampleHeadToHead/BenchmarkComparison/103cd89c-b177-4a0b-84fc-9553a1f8161f/call-BenchmarkVCFControlSample/Benchmark/eaf4d582-e197-4e13-8122-5e1ec22591ae/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""73.06777222222223"",; ""NIST evalHCsystemhours"": ""0.1622555555555555"",; ""NIST evalHCwallclockhours"": ""46.65241388888888"",; ""NIST evalHCwallclockmax"": ""2.7461055555555554"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e372bd14-cd1f-4563-8d8a-ab",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1069381494:13482,monitor,monitoring,13482,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1069381494,1,['monitor'],['monitoring']
Energy Efficiency,"parison/7b11647c-6643-4c47-8e1c-3f07bd97e371/call-BenchmarkVCFControlSample/Benchmark/086348b1-f09c-49b0-b830-587e28eec63d/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.7573"",; ""EXOME1 evalindelPrecision"": ""0.6882"",; ""EXOME1 evalsnpF1Score"": ""0.9896"",; ""EXOME1 evalsnpPrecision"": ""0.9852"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-EXOME1SampleHeadToHead/BenchmarkComparison/7b11647c-6643-4c47-8e1c-3f07bd97e371/call-BenchmarkVCFTestSample/Benchmark/47d80f67-4375-460f-9ce0-8186eec9fe5b/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""90.94291388888888"",; ""NIST controlHCsystemhours"": ""0.182125"",; ""NIST controlHCwallclockhours"": ""63.56370277777778"",; ""NIST controlHCwallclockmax"": ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-NISTSampleHeadToHead/BenchmarkComparison/8e62c1c2-cf9c-4530-846e-1e0d6c6d8acf/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-NISTSampleHeadToHead/BenchmarkComparison/8e62c1c2-cf9c-4530-846e-1e0d6c6d8acf/call-BenchmarkVCFControlSample/Benchmark/e71074a5-27ad-4a8b-a533-cdc111c0374f/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""73.06777222222223"",; ""NIST evalHCsystemhours"": ""0.1622555555555555"",; ""NIST evalHCwallclockhours"": ""46.65241388888888"",; ""NIST evalHCwallclockmax"": ""2.7461055555555554"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1069765064:13480,monitor,monitoring,13480,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1069765064,1,['monitor'],['monitoring']
Energy Efficiency,park.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(JavaPairRDD.scala:1037); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); at scala.collection.Iterator$class.foreach(Iterator.scala:891); at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334); at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214); at scala.collection.AbstractIterator.aggregate(Iterator.scala:1334); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(RDD.scala:1190); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(RDD.scala:1190); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$27.apply(RDD.scala:1191); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$27.apply(RDD.scala:1191); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5854#issuecomment-808817724:2571,schedul,scheduler,2571,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854#issuecomment-808817724,2,['schedul'],['scheduler']
Energy Efficiency,park.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:41426,schedul,scheduler,41426,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['schedul'],['scheduler']
Energy Efficiency,park.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:41328,schedul,scheduler,41328,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,2,['schedul'],['scheduler']
Energy Efficiency,"piens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": ""050d2d6e-4a50-4145-a9da-8a39731ebdd2"",; ""eval_cromwell_job_id"": ""0e5c32ab-65e6-451f-a04e-6a3f5e7fe5c8"",; ""created_at"": ""2023-05-04T15:40:52.834692"",; ""created_by"": null,; ""finished_at"": ""2023-05-04T17:03:53.525"",; ""results"": {; ""CHM controlHCprocesshours"": ""75.88741944444445"",; ""CHM controlHCsystemhours"": ""0.1663777777777778"",; ""CHM controlHCwallclockhours"": ""52.24009722222222"",; ""CHM controlHCwallclockmax"": ""2.852152777777778"",; ""CHM controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/0e5c32ab-65e6-451f-a04e-6a3f5e7fe5c8/call-CHMSampleHeadToHead/BenchmarkComparison/a332776f-175a-4595-bdeb-ab62e7f89921/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/0e5c32ab-65e6-451f-a04e-6a3f5e7fe5c8/call-CHMSampleHeadToHead/BenchmarkComparison/a332776f-175a-4595-bdeb-ab62e7f89921/call-BenchmarkVCFControlSample/Benchmark/06cbfab4-17a7-4415-9118-d0ebbe156bfd/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""84.26158888888888"",; ""CHM evalHCsystemhours"": ""0.19243055555555555"",; ""CHM evalHCwallclockhours"": ""60.242008333333345"",; ""CHM evalHCwallclockmax"": ""3.176513888888889"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/0e5c32ab-65e6-451f-a04e-6a3f5e7f",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535104202:17391,monitor,monitoring,17391,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535104202,1,['monitor'],['monitoring']
Energy Efficiency,"piens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": ""07271d7b-729d-4db9-862d-5f992a60a598"",; ""eval_cromwell_job_id"": ""89508d5f-29f1-4534-9fe1-220a80de17c4"",; ""created_at"": ""2022-07-22T17:23:11.546971"",; ""created_by"": null,; ""finished_at"": ""2022-07-23T02:09:23.327"",; ""results"": {; ""CHM controlHCprocesshours"": ""75.88741944444445"",; ""CHM controlHCsystemhours"": ""0.1663777777777778"",; ""CHM controlHCwallclockhours"": ""52.24009722222222"",; ""CHM controlHCwallclockmax"": ""2.852152777777778"",; ""CHM controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/89508d5f-29f1-4534-9fe1-220a80de17c4/call-CHMSampleHeadToHead/BenchmarkComparison/a2a2515a-b32a-44a6-a6d1-9a6d0d2199bb/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/89508d5f-29f1-4534-9fe1-220a80de17c4/call-CHMSampleHeadToHead/BenchmarkComparison/a2a2515a-b32a-44a6-a6d1-9a6d0d2199bb/call-BenchmarkVCFControlSample/Benchmark/2c4ad666-e885-4e23-bd5c-d54ca521ffbf/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""78.99195555555558"",; ""CHM evalHCsystemhours"": ""0.16168333333333337"",; ""CHM evalHCwallclockhours"": ""55.43875833333334"",; ""CHM evalHCwallclockmax"": ""2.913311111111111"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/89508d5f-29f1-4534-9fe1-220a80de1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1193038382:16695,monitor,monitoring,16695,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1193038382,1,['monitor'],['monitoring']
Energy Efficiency,"piens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": ""410a88f6-62ca-4745-89fd-df6e30aac65b"",; ""eval_cromwell_job_id"": ""bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9"",; ""created_at"": ""2022-03-16T19:53:45.833854"",; ""created_by"": null,; ""finished_at"": ""2022-03-17T00:11:38.702"",; ""results"": {; ""CHM controlHCprocesshours"": ""75.88741944444445"",; ""CHM controlHCsystemhours"": ""0.1663777777777778"",; ""CHM controlHCwallclockhours"": ""52.24009722222222"",; ""CHM controlHCwallclockmax"": ""2.852152777777778"",; ""CHM controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-CHMSampleHeadToHead/BenchmarkComparison/79d1a2a4-6b5e-424a-8528-9059bda6db1c/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb5d9/call-CHMSampleHeadToHead/BenchmarkComparison/79d1a2a4-6b5e-424a-8528-9059bda6db1c/call-BenchmarkVCFControlSample/Benchmark/3046acf7-ded7-40c8-9b7a-3826f480418f/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""67.35536666666667"",; ""CHM evalHCsystemhours"": ""0.1557166666666667"",; ""CHM evalHCwallclockhours"": ""42.53388888888889"",; ""CHM evalHCwallclockmax"": ""2.7197444444444443"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/bf86d5b6-04bd-4344-b4fc-8a1df66bb",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1069765064:10472,monitor,monitoring,10472,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1069765064,1,['monitor'],['monitoring']
Energy Efficiency,"piens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": ""54997ade-421d-439f-acc9-abf50b3f9cb5"",; ""eval_cromwell_job_id"": ""6ea2705f-a3fa-41fc-8d17-a2c55d875eab"",; ""created_at"": ""2022-03-16T19:52:46.276978"",; ""created_by"": null,; ""finished_at"": ""2022-03-17T00:13:17.198"",; ""results"": {; ""CHM controlHCprocesshours"": ""75.88741944444445"",; ""CHM controlHCsystemhours"": ""0.1663777777777778"",; ""CHM controlHCwallclockhours"": ""52.24009722222222"",; ""CHM controlHCwallclockmax"": ""2.852152777777778"",; ""CHM controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/6ea2705f-a3fa-41fc-8d17-a2c55d875eab/call-CHMSampleHeadToHead/BenchmarkComparison/1fb97a8b-caee-4184-8e36-be21e6c43549/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/6ea2705f-a3fa-41fc-8d17-a2c55d875eab/call-CHMSampleHeadToHead/BenchmarkComparison/1fb97a8b-caee-4184-8e36-be21e6c43549/call-BenchmarkVCFControlSample/Benchmark/3b068fb2-7140-4c1e-8860-df8df21821ec/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""80.5165222222222"",; ""CHM evalHCsystemhours"": ""0.1713305555555555"",; ""CHM evalHCwallclockhours"": ""53.10978888888891"",; ""CHM evalHCwallclockmax"": ""2.7458416666666667"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/6ea2705f-a3fa-41fc-8d17-a2c55d875e",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069766207:10472,monitor,monitoring,10472,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069766207,1,['monitor'],['monitoring']
Energy Efficiency,"piens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": ""5e9a598e-1e80-4622-b153-78e97491a478"",; ""eval_cromwell_job_id"": ""f7eac327-c59c-43f7-a850-21bc3e0ccf52"",; ""created_at"": ""2022-07-12T17:28:58.385152"",; ""created_by"": null,; ""finished_at"": ""2022-07-13T02:47:47.016"",; ""results"": {; ""CHM controlHCprocesshours"": ""75.88741944444445"",; ""CHM controlHCsystemhours"": ""0.1663777777777778"",; ""CHM controlHCwallclockhours"": ""52.24009722222222"",; ""CHM controlHCwallclockmax"": ""2.852152777777778"",; ""CHM controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0ccf52/call-CHMSampleHeadToHead/BenchmarkComparison/cd28fe49-1672-4321-a836-47f76419c1c8/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0ccf52/call-CHMSampleHeadToHead/BenchmarkComparison/cd28fe49-1672-4321-a836-47f76419c1c8/call-BenchmarkVCFControlSample/Benchmark/d5df8455-36cf-4ecb-8dc2-ec35b974c0b7/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""78.23616944444446"",; ""CHM evalHCsystemhours"": ""0.16188333333333332"",; ""CHM evalHCwallclockhours"": ""55.167422222222214"",; ""CHM evalHCwallclockmax"": ""2.887522222222222"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f7eac327-c59c-43f7-a850-21bc3e0c",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1182703672:16707,monitor,monitoring,16707,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1182703672,1,['monitor'],['monitoring']
Energy Efficiency,"piens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": ""5f0f8f34-cdc7-46ff-a59d-2368edcdf007"",; ""eval_cromwell_job_id"": ""e6f57e40-2025-46fd-9aa0-d591a3799007"",; ""created_at"": ""2022-03-16T14:20:46.087600"",; ""created_by"": null,; ""finished_at"": ""2022-03-16T17:21:08.639"",; ""results"": {; ""CHM controlHCprocesshours"": ""75.88741944444445"",; ""CHM controlHCsystemhours"": ""0.1663777777777778"",; ""CHM controlHCwallclockhours"": ""52.24009722222222"",; ""CHM controlHCwallclockmax"": ""2.852152777777778"",; ""CHM controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-CHMSampleHeadToHead/BenchmarkComparison/f65a7960-7b66-4a5d-a346-bd188a1b3830/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-CHMSampleHeadToHead/BenchmarkComparison/f65a7960-7b66-4a5d-a346-bd188a1b3830/call-BenchmarkVCFControlSample/Benchmark/8d0e47ca-66f5-42a0-8785-6aa8d2db2663/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""80.5165222222222"",; ""CHM evalHCsystemhours"": ""0.1713305555555555"",; ""CHM evalHCwallclockhours"": ""53.10978888888891"",; ""CHM evalHCwallclockmax"": ""2.7458416666666667"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a37990",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069378815:10472,monitor,monitoring,10472,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069378815,1,['monitor'],['monitoring']
Energy Efficiency,"piens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": ""9886a710-334a-41eb-a495-6968d322730a"",; ""eval_cromwell_job_id"": ""9bc521dc-3c4c-4274-972c-9d1e4be850d5"",; ""created_at"": ""2023-05-03T15:51:41.295461"",; ""created_by"": null,; ""finished_at"": ""2023-05-04T01:24:02.606"",; ""results"": {; ""CHM controlHCprocesshours"": ""75.88741944444445"",; ""CHM controlHCsystemhours"": ""0.1663777777777778"",; ""CHM controlHCwallclockhours"": ""52.24009722222222"",; ""CHM controlHCwallclockmax"": ""2.852152777777778"",; ""CHM controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9bc521dc-3c4c-4274-972c-9d1e4be850d5/call-CHMSampleHeadToHead/BenchmarkComparison/092bfb4f-d978-4964-a8ae-e5a7f7362f7c/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9bc521dc-3c4c-4274-972c-9d1e4be850d5/call-CHMSampleHeadToHead/BenchmarkComparison/092bfb4f-d978-4964-a8ae-e5a7f7362f7c/call-BenchmarkVCFControlSample/Benchmark/6ab078fb-b668-452c-bbaa-8fb1fd8e25ba/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""84.26158888888888"",; ""CHM evalHCsystemhours"": ""0.19243055555555555"",; ""CHM evalHCwallclockhours"": ""60.242008333333345"",; ""CHM evalHCwallclockmax"": ""3.176513888888889"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9bc521dc-3c4c-4274-972c-9d1e4be8",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1533946590:17367,monitor,monitoring,17367,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1533946590,1,['monitor'],['monitoring']
Energy Efficiency,"piens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": ""a8ee297d-9fd6-433f-ac22-14488a09b832"",; ""eval_cromwell_job_id"": ""2a8ce326-baa5-4052-bff9-bd684393ff6c"",; ""created_at"": ""2022-07-25T15:10:00.795227"",; ""created_by"": null,; ""finished_at"": ""2022-07-26T00:11:26.646"",; ""results"": {; ""CHM controlHCprocesshours"": ""75.88741944444445"",; ""CHM controlHCsystemhours"": ""0.1663777777777778"",; ""CHM controlHCwallclockhours"": ""52.24009722222222"",; ""CHM controlHCwallclockmax"": ""2.852152777777778"",; ""CHM controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd684393ff6c/call-CHMSampleHeadToHead/BenchmarkComparison/a1db35b8-cc7b-4019-bdd0-9f423762542e/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd684393ff6c/call-CHMSampleHeadToHead/BenchmarkComparison/a1db35b8-cc7b-4019-bdd0-9f423762542e/call-BenchmarkVCFControlSample/Benchmark/7195c554-534f-43ef-80c2-77bdafa1827f/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""78.10181666666668"",; ""CHM evalHCsystemhours"": ""0.16157500000000005"",; ""CHM evalHCwallclockhours"": ""55.006172222222226"",; ""CHM evalHCwallclockmax"": ""2.8554194444444443"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/2a8ce326-baa5-4052-bff9-bd68439",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1194801748:16707,monitor,monitoring,16707,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1194801748,1,['monitor'],['monitoring']
Energy Efficiency,"piens_assembly38.fasta"",; ""BenchmarkVCFsHeadToHeadOrchestrated.referenceVersion"": ""HG38"",; ""BenchmarkVCFsHeadToHeadOrchestrated.stratIntervals"": [; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/HCR_hg38.bed"",; ""gs://dsp-methods-carrot-data/test_data/haplotypecaller_tests/LCR_Hg38.interval_list""; ],; ""BenchmarkVCFsHeadToHeadOrchestrated.stratLabels"": [; ""HCR"",; ""LCR""; ]; },; ""eval_options"": null,; ""test_cromwell_job_id"": ""d6f96a63-9657-4ff6-9934-fe1ab3cea617"",; ""eval_cromwell_job_id"": ""e372bd14-cd1f-4563-8d8a-abf6b6ca7883"",; ""created_at"": ""2022-03-16T14:19:54.192086"",; ""created_by"": null,; ""finished_at"": ""2022-03-16T17:26:08.529"",; ""results"": {; ""CHM controlHCprocesshours"": ""75.88741944444445"",; ""CHM controlHCsystemhours"": ""0.1663777777777778"",; ""CHM controlHCwallclockhours"": ""52.24009722222222"",; ""CHM controlHCwallclockmax"": ""2.852152777777778"",; ""CHM controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e372bd14-cd1f-4563-8d8a-abf6b6ca7883/call-CHMSampleHeadToHead/BenchmarkComparison/7ff0db7c-0871-4cda-95f3-fa75436cbb21/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8778"",; ""CHM controlindelPrecision"": ""0.8968"",; ""CHM controlsnpF1Score"": ""0.9813"",; ""CHM controlsnpPrecision"": ""0.9774"",; ""CHM controlsnpRecall"": ""0.9852"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e372bd14-cd1f-4563-8d8a-abf6b6ca7883/call-CHMSampleHeadToHead/BenchmarkComparison/7ff0db7c-0871-4cda-95f3-fa75436cbb21/call-BenchmarkVCFControlSample/Benchmark/16cd1efe-5cea-403e-8e85-aec15e71bd1d/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""67.35536666666667"",; ""CHM evalHCsystemhours"": ""0.1557166666666667"",; ""CHM evalHCwallclockhours"": ""42.53388888888889"",; ""CHM evalHCwallclockmax"": ""2.7197444444444443"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e372bd14-cd1f-4563-8d8a-abf6b6ca7",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1069381494:10472,monitor,monitoring,10472,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7723#issuecomment-1069381494,1,['monitor'],['monitoring']
Energy Efficiency,"port 44818.; 17/10/13 18:11:42 INFO netty.NettyBlockTransferService: Server created on 10.131.101.159:44818; 17/10/13 18:11:42 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 17/10/13 18:11:42 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.131.101.159, 44818, None); 17/10/13 18:11:42 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.131.101.159:44818 with 366.3 MB RAM, BlockManagerId(driver, 10.131.101.159, 44818, None); 17/10/13 18:11:42 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.131.101.159, 44818, None); 17/10/13 18:11:42 INFO storage.BlockManager: external shuffle service port = 7337; 17/10/13 18:11:42 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.131.101.159, 44818, None); 17/10/13 18:11:42 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@544300a6{/metrics/json,null,AVAILABLE,@Spark}; 17/10/13 18:11:42 INFO scheduler.EventLoggingListener: Logging events to hdfs://mg:8020/user/spark/spark2ApplicationHistory/application_1507856833944_0003; 17/10/13 18:11:42 INFO util.Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances; 17/10/13 18:11:43 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8; 17/10/13 18:11:43 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 286.0 KB, free 366.0 MB); 17/10/13 18:11:44 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 26.0 KB, free 366.0 MB); 17/10/13 18:11:44 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.131.101.159:44818 (size: 26.0 KB, free: 366.3 MB); 17/10/13 18:11:44 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:14464,schedul,scheduler,14464,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['schedul'],['scheduler']
Energy Efficiency,"pr&el=h1) Report; > Merging [#2548](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/c8ede6ef810a3d9a05c7deb8052e27ca724ce8ba?src=pr&el=desc) will **increase** coverage by `0.003%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2548 +/- ##; ===============================================; + Coverage 76.279% 76.282% +0.003% ; - Complexity 10891 10893 +2 ; ===============================================; Files 752 752 ; Lines 39590 39590 ; Branches 6925 6925 ; ===============================================; + Hits 30199 30200 +1 ; Misses 6768 6768 ; + Partials 2623 2622 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...tools/walkers/genotyper/AlleleSubsettingUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9BbGxlbGVTdWJzZXR0aW5nVXRpbHMuamF2YQ==) | `85.185% <ø> (ø)` | `39 <0> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=footer). Last update [c8ede6e...b79b75d](https://codecov.io/gh/broadinstitute/gatk/pull/2548?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2548#issuecomment-290305475:1792,Power,Powered,1792,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2548#issuecomment-290305475,1,['Power'],['Powered']
Energy Efficiency,ps://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F416C69676E6D656E74526567696F6E2E6A617661) |; | •••••• 60% | [...ute/hellbender/tools/spark/sv/ChimericAlignment.java](https://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F4368696D65726963416C69676E6D656E742E6A617661) |; | ••••••• 72% | *new* [...llbender/tools/spark/sv/AssemblyAlignmentParser.java](https://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F417373656D626C79416C69676E6D656E745061727365722E6A617661) |; | •••••••••• 100% | [.../hellbender/tools/spark/sv/SVVariantCallerUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F535656617269616E7443616C6C65725574696C732E6A617661) |; | •••••••••• 100% | [...tute/hellbender/tools/spark/sv/BreakpointAllele.java](https://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F427265616B706F696E74416C6C656C652E6A617661) |; | •••••••••• 100% | [...institute/hellbender/tools/spark/sv/SVConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F5356436F6E7374616E74732E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [cb48a6e...073dabb](https://codecov.io/gh/broadinstitute/gatk/compare/cb48a6e4d524355c8ed312a622cbfae69f8ce26b...073dabbdf1e44a0c76e6c64adcc7570c9f310cc0?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2285#issuecomment-263705162:3607,Power,Powered,3607,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2285#issuecomment-263705162,1,['Power'],['Powered']
Energy Efficiency,"q06.scc.bu.edu:39736 with 25.4 GB RAM, BlockManagerId(5, scc-q06.scc.bu.edu, 39736, None); 18/03/07 20:31:48 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.193:34094) with ID 1; 18/03/07 20:31:48 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q09.scc.bu.edu:38854 with 25.4 GB RAM, BlockManagerId(1, scc-q09.scc.bu.edu, 38854, None); 18/03/07 20:31:49 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.187:33854) with ID 4; 18/03/07 20:31:49 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.198:41138) with ID 7; 18/03/07 20:31:49 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q03.scc.bu.edu:35635 with 25.4 GB RAM, BlockManagerId(4, scc-q03.scc.bu.edu, 35635, None); 18/03/07 20:31:49 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8; 18/03/07 20:31:49 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q14.scc.bu.edu:36726 with 25.4 GB RAM, BlockManagerId(7, scc-q14.scc.bu.edu, 36726, None); 18/03/07 20:31:49 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.195:47862) with ID 6; 18/03/07 20:31:49 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q11.scc.bu.edu:46002 with 25.4 GB RAM, BlockManagerId(6, scc-q11.scc.bu.edu, 46002, None); 18/03/07 20:31:49 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 246.6 KB, free 8.4 GB); 18/03/07 20:31:50 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.3 KB, free 8.4 GB); 18/03/07 20:31:50 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:41567 (size: 25.3 KB, free: 8.4 GB); 18/03/07 20:31:50 INFO sp",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:3848,schedul,scheduling,3848,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,3,"['Schedul', 'schedul']","['SchedulerBackend', 'scheduling']"
Energy Efficiency,"r&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL21hZk91dHB1dC9NYWZPdXRwdXRSZW5kZXJlckNvbnN0YW50cy5qYXZh) | `99.01% <100%> (+0.04%)` | `1 <0> (ø)` | :arrow_down: |; | [...der/tools/funcotator/metadata/TumorNormalPair.java](https://codecov.io/gh/broadinstitute/gatk/pull/4917/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL21ldGFkYXRhL1R1bW9yTm9ybWFsUGFpci5qYXZh) | `63.63% <63.63%> (ø)` | `5 <5> (?)` | |; | [...cotator/mafOutput/CustomMafFuncotationCreator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4917/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL21hZk91dHB1dC9DdXN0b21NYWZGdW5jb3RhdGlvbkNyZWF0b3IuamF2YQ==) | `90% <90%> (ø)` | `17 <17> (?)` | |; | [...tools/funcotator/metadata/SamplePairExtractor.java](https://codecov.io/gh/broadinstitute/gatk/pull/4917/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL21ldGFkYXRhL1NhbXBsZVBhaXJFeHRyYWN0b3IuamF2YQ==) | `95% <95%> (ø)` | `9 <9> (?)` | |; | [...titute/hellbender/tools/funcotator/Funcotator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4917/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3IuamF2YQ==) | `86.18% <0%> (+0.65%)` | `43% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4917?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4917?src=pr&el=footer). Last update [9d8fdac...0e8a045](https://codecov.io/gh/broadinstitute/gatk/pull/4917?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4917#issuecomment-399122987:3627,Power,Powered,3627,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4917#issuecomment-399122987,1,['Power'],['Powered']
Energy Efficiency,"r&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvTG9jdXNXYWxrZXJTcGFyay5qYXZh) | `82.5% <83.33%> (+4.72%)` | `12 <2> (ø)` | :arrow_down: |; | [...itute/hellbender/engine/spark/ReadWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5221/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvUmVhZFdhbGtlclNwYXJrLmphdmE=) | `72.22% <85.71%> (-5.2%)` | `8 <3> (-2)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5221/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5221/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `72.51% <0%> (+0.94%)` | `38% <0%> (+1%)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5221/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `80% <0%> (+30%)` | `3% <0%> (+2%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5221?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5221?src=pr&el=footer). Last update [2ee7df3...e40ce5e](https://codecov.io/gh/broadinstitute/gatk/pull/5221?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5221#issuecomment-426308250:4497,Power,Powered,4497,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5221#issuecomment-426308250,1,['Power'],['Powered']
Energy Efficiency,r(Mutect2FilteringEngine.java:91); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:76); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:60); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:140); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:31); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:68); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.uti,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887:1719,Reduce,ReduceOps,1719,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,r: Stage 19 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:47:33 WARN org.apache.spark.scheduler.TaskSetManager: Stage 20 contains a task of very large size (2685 KB). The maximum recommended task size is 100 KB.; 00:47:39.417 INFO StructuralVariationDiscoveryPipelineSpark - Processing 323040 raw alignments from 254678 contigs.; 18/04/27 00:47:39 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 00:47:47.083 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 225280 contigs.; 00:47:48.135 INFO StructuralVariationDiscoveryPipelineSpark - 23702 contigs with chimeric alignments potentially giving SV signals.; 18/04/27 00:47:49 WARN org.apache.spark.scheduler.TaskSetManager: Stage 32 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:47:57 WARN org.apache.spark.scheduler.TaskSetManager: Stage 33 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:48:04 WARN org.apache.spark.scheduler.TaskSetManager: Stage 34 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 00:48:13.094 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 15964 variants.; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 6920; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 264; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 268; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 4680; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 487; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - INS: 3345; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - INV: 0; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 00:48:13.107 INFO Structu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199:2076,schedul,scheduler,2076,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199,1,['schedul'],['scheduler']
Energy Efficiency,r: Stage 19 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:18 WARN org.apache.spark.scheduler.TaskSetManager: Stage 20 contains a task of very large size (2599 KB). The maximum recommended task size is 100 KB.; 02:20:24.460 INFO StructuralVariationDiscoveryPipelineSpark - Processing 323040 raw alignments from 254678 contigs.; 18/04/27 02:20:24 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 02:20:32.040 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 225280 contigs.; 02:20:33.079 INFO StructuralVariationDiscoveryPipelineSpark - 23841 contigs with chimeric alignments potentially giving SV signals.; 18/04/27 02:20:34 WARN org.apache.spark.scheduler.TaskSetManager: Stage 32 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:42 WARN org.apache.spark.scheduler.TaskSetManager: Stage 33 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:49 WARN org.apache.spark.scheduler.TaskSetManager: Stage 34 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 02:20:58.973 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 15659 variants.; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 6920; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 264; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 268; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 5019; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1793; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1395; 02:20:58.992 INFO StructuralVariationDiscoveryPipelineSpark - INV: 0; 02:20:58.992 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 02:20:58.992 INFO Struct,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199:5942,schedul,scheduler,5942,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199,1,['schedul'],['scheduler']
Energy Efficiency,r: Stage 20 contains a task of very large size (2599 KB). The maximum recommended task size is 100 KB.; 02:20:24.460 INFO StructuralVariationDiscoveryPipelineSpark - Processing 323040 raw alignments from 254678 contigs.; 18/04/27 02:20:24 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 02:20:32.040 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 225280 contigs.; 02:20:33.079 INFO StructuralVariationDiscoveryPipelineSpark - 23841 contigs with chimeric alignments potentially giving SV signals.; 18/04/27 02:20:34 WARN org.apache.spark.scheduler.TaskSetManager: Stage 32 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:42 WARN org.apache.spark.scheduler.TaskSetManager: Stage 33 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:49 WARN org.apache.spark.scheduler.TaskSetManager: Stage 34 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 02:20:58.973 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 15659 variants.; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 6920; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 264; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 268; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 5019; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1793; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1395; 02:20:58.992 INFO StructuralVariationDiscoveryPipelineSpark - INV: 0; 02:20:58.992 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 02:20:58.992 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 02:21:46.603 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 1334 variants.; 02:21:46.604 INFO StructuralVari,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199:6109,schedul,scheduler,6109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199,1,['schedul'],['scheduler']
Energy Efficiency,r: Stage 20 contains a task of very large size (2685 KB). The maximum recommended task size is 100 KB.; 00:47:39.417 INFO StructuralVariationDiscoveryPipelineSpark - Processing 323040 raw alignments from 254678 contigs.; 18/04/27 00:47:39 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 00:47:47.083 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 225280 contigs.; 00:47:48.135 INFO StructuralVariationDiscoveryPipelineSpark - 23702 contigs with chimeric alignments potentially giving SV signals.; 18/04/27 00:47:49 WARN org.apache.spark.scheduler.TaskSetManager: Stage 32 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:47:57 WARN org.apache.spark.scheduler.TaskSetManager: Stage 33 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:48:04 WARN org.apache.spark.scheduler.TaskSetManager: Stage 34 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 00:48:13.094 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 15964 variants.; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 6920; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 264; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 268; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 4680; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 487; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - INS: 3345; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - INV: 0; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - DUP_INV: 0; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 00:48:47.955 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 1334 variants.; 00:48:47.956 INFO StructuralVaria,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199:2243,schedul,scheduler,2243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199,1,['schedul'],['scheduler']
Energy Efficiency,"rage Diff @@; ## master #5539 +/- ##; ============================================; - Coverage 87.06% 87.06% -0.01% ; + Complexity 31324 31322 -2 ; ============================================; Files 1921 1921 ; Lines 144579 144579 ; Branches 15949 15949 ; ============================================; - Hits 125884 125880 -4 ; - Misses 12902 12906 +4 ; Partials 5793 5793; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5539/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5539/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `79.87% <0%> (-0.61%)` | `42% <0%> (ø)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5539/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=footer). Last update [10aa8c7...3aec594](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5539#issuecomment-449065825:2315,Power,Powered,2315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5539#issuecomment-449065825,1,['Power'],['Powered']
Energy Efficiency,"rage by `0.008%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2468 +/- ##; ===============================================; + Coverage 76.268% 76.275% +0.008% ; - Complexity 10876 10879 +3 ; ===============================================; Files 752 752 ; Lines 39583 39583 ; Branches 6922 6922 ; ===============================================; + Hits 30189 30192 +3 ; + Misses 6774 6772 -2 ; + Partials 2620 2619 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2468?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...4bebcdf005e9191206558f09e14f59d87324f1c8?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `91.429% <0%> (+1.429%)` | `24% <0%> (+1%)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...4bebcdf005e9191206558f09e14f59d87324f1c8?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2468?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2468?src=pr&el=footer). Last update [c62914a...4bebcdf](https://codecov.io/gh/broadinstitute/gatk/compare/c62914a72df31653f801072d9d5b63ef44ecc248...4bebcdf005e9191206558f09e14f59d87324f1c8?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2468#issuecomment-288779580:1946,Power,Powered,1946,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2468#issuecomment-288779580,1,['Power'],['Powered']
Energy Efficiency,"rage is `100%`. ```diff; @@ Coverage Diff @@; ## master #2427 +/- ##; ===============================================; + Coverage 76.218% 76.221% +0.003% ; - Complexity 10819 10821 +2 ; ===============================================; Files 750 750 ; Lines 39420 39421 +1 ; Branches 6883 6883 ; ===============================================; + Hits 30045 30047 +2 ; Misses 6757 6757 ; + Partials 2618 2617 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2427?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...tute/hellbender/tools/spark/sv/ReadClassifier.java](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...fc95362d5a29cc5738032c43aa922b491b6accf5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkQ2xhc3NpZmllci5qYXZh) | `83.607% <100%> (+0.273%)` | `31 <4> (+1)` | :white_check_mark: |; | [.../hellbender/tools/spark/sv/BreakpointEvidence.java](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...fc95362d5a29cc5738032c43aa922b491b6accf5?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9CcmVha3BvaW50RXZpZGVuY2UuamF2YQ==) | `83.756% <0%> (+0.508%)` | `24% <0%> (+1%)` | :white_check_mark: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2427?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2427?src=pr&el=footer). Last update [fcd103c...fc95362](https://codecov.io/gh/broadinstitute/gatk/compare/fcd103c48afd0443512e1c490ea487278abe0332...fc95362d5a29cc5738032c43aa922b491b6accf5?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2427#issuecomment-282851101:1980,Power,Powered,1980,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2427#issuecomment-282851101,1,['Power'],['Powered']
Energy Efficiency,rce.java:324); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:304); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:256); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:230); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:214); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.openFeatureSource(JoinReadsWithVariants.java:63); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$null$0(JoinReadsWithVariants.java:44); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$join$60e5b476$1(JoinReadsWithVariants.java:44); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); a,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-570992855:3039,Reduce,ReduceOps,3039,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-570992855,1,['Reduce'],['ReduceOps']
Energy Efficiency,"readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	... 18 more; 19/02/18 16:58:29 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@45c90a05{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 16:58:29.970 INFO PrintVariantsSpark - Shutting down engine; [February 18, 2019 4:58:29 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.34 minutes.; Runtime.totalMemory()=1106771968; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: java.lang.NullPointerException; Serialization trace:; genotypes (htsjdk.variant.variantcontext.VariantContext); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821); 	at org.apache.spark.scheduler.DAGSchedulerEventProces",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:9517,schedul,scheduler,9517,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:362); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.NullPointerException; 	at htsjdk.variant.variantcontext.LazyGenotypesContext.decode(LazyGenotypesContext.java:158); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.invalidateSampleOrdering(LazyGenotypesContext.java:205); 	at htsjdk.variant.variantcontext.GenotypesContext.add(GenotypesContext.java:353); 	at htsjdk.variant.variantcontext.GenotypesContext.add(GenotypesContext.java:46); 	at com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:134); 	at com.esotericsoftware.kryo.se,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:7415,schedul,scheduler,7415,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,reamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); 	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); 	at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); 	at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:215); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1038); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1029); 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:969); 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1029); 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:760); 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4661#issuecomment-408874230:3317,schedul,scheduler,3317,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4661#issuecomment-408874230,2,['schedul'],['scheduler']
Energy Efficiency,ree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...bender/tools/spark/pathseq/PathSeqFilterSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFGaWx0ZXJTcGFyay5qYXZh) | `70.968% <ø> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...itute/hellbender/tools/spark/pathseq/PSFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyLmphdmE=) | `92.617% <100%> (+0.531%)` | `33 <1> (+1)` | :arrow_up: |; | [...ools/spark/pathseq/PSFilterArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `80% <100%> (+1.429%)` | `2 <0> (ø)` | :arrow_down: |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <92.857%> (ø)` | `12 <12> (?)` | |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <94.286%> (ø)` | `11 <11> (?)` | |; | [...nstitute/hellbender/utils/clipping/ClippingOp.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jbGlwcGluZy9DbGlwcGluZ09wLmphdmE=) | `84.365% <0%> (+1.629%)` | `91% <0%> (+2%)` | :arrow_up: |; | [...stitute/hellbender/utils/clipping/ReadClipper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3354#issuecomment-317586310:1867,Adapt,AdapterTrimTransformer,1867,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3354#issuecomment-317586310,1,['Adapt'],['AdapterTrimTransformer']
Energy Efficiency,rg.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.34 minutes.; Runtime.totalMemory()=1106771968; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: java.lang.NullPointerException; Serialization trace:; genotypes (htsjdk.variant.variantcontext.VariantContext); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1821); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1810); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055); 	at org.apache.spark.SparkConte,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:9869,schedul,scheduler,9869,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,rializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:362); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.NullPointerException; 	at htsjdk.variant.variantcontext.LazyGenotypesContext.decode(LazyGenotypesContext.java:158); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.invalidateSampleOrdering(LazyGenotypesContext.java:205); 	at htsjdk.variant.variantcontext.GenotypesContext.add(GenotypesContext.java:353); 	at htsjdk.variant.variantcontext.GenotypesContext.add(GenotypesContext.java:46); 	at com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:134); 	at com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:40); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectFi,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:7594,schedul,scheduler,7594,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,"rializer.read(CollectionSerializer.java:40); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	... 18 more; 19/02/18 16:58:29 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@45c90a05{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 16:58:29.970 INFO PrintVariantsSpark - Shutting down engine; [February 18, 2019 4:58:29 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.PrintVariantsSpark done. Elapsed time: 0.34 minutes.; Runtime.totalMemory()=1106771968; org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: com.esotericsoftware.kryo.KryoException: java.lang.NullPointerException; Serialization trace:; genotypes (htsjdk.variant.variantcontext.VariantContext); interval (org.broadinstitute.hellbender.engine.spark.SparkSharder$PartitionLocatable); 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1651); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1639); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1638); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1638); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1872); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:9418,schedul,scheduler,9418,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,"rn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `75%`. ```diff; @@ Coverage Diff @@; ## master #2431 +/- ##; ==========================================; Coverage ? 42.757% ; Complexity ? 5801 ; ==========================================; Files ? 750 ; Lines ? 39425 ; Branches ? 6885 ; ==========================================; Hits ? 16857 ; Misses ? 20600 ; Partials ? 1968; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2431?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...s/recalibration/covariates/ReadGroupCovariate.java](https://codecov.io/gh/broadinstitute/gatk/compare/dc15e61a728ccd4e61b139332e48c05b57e4e88c...0d5d1b12d611725c80fa572e5ffba3bf8ea45ee4?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWNhbGlicmF0aW9uL2NvdmFyaWF0ZXMvUmVhZEdyb3VwQ292YXJpYXRlLmphdmE=) | `86.667% <100%> (ø)` | `11 <0> (?)` | |; | [...dinstitute/hellbender/utils/report/GATKReport.java](https://codecov.io/gh/broadinstitute/gatk/compare/dc15e61a728ccd4e61b139332e48c05b57e4e88c...0d5d1b12d611725c80fa572e5ffba3bf8ea45ee4?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZXBvcnQvR0FUS1JlcG9ydC5qYXZh) | `40.196% <66.667%> (ø)` | `16 <0> (?)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2431?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2431?src=pr&el=footer). Last update [dc15e61...0d5d1b1](https://codecov.io/gh/broadinstitute/gatk/compare/dc15e61a728ccd4e61b139332e48c05b57e4e88c...0d5d1b12d611725c80fa572e5ffba3bf8ea45ee4?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2431#issuecomment-283404250:1815,Power,Powered,1815,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2431#issuecomment-283404250,1,['Power'],['Powered']
Energy Efficiency,roadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:907); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:861); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-783746069:4095,Reduce,ReduceOps,4095,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-783746069,1,['Reduce'],['ReduceOps']
Energy Efficiency,ry.java:281); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:338); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:138); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:113); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.lambda$enqueueAndHandleVariant$0(Funcotator.java:502); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:504); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:399); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:109); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$Fo,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-811170886:1254,Reduce,ReduceOps,1254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-811170886,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"s 30169 30168 -1 ; + Misses 6771 6768 -3 ; Partials 2620 2620; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2450?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/compare/987e2f98c4f9a97d74488bf37bc902ee25274c83...05211ec9114cfb2886fe17c56fa991603241f50d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `23.729% <100%> (ø)` | `2 <0> (ø)` | :x: |; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/compare/987e2f98c4f9a97d74488bf37bc902ee25274c83...05211ec9114cfb2886fe17c56fa991603241f50d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `84.211% <100%> (-0.164%)` | `53 <0> (ø)` | |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/compare/987e2f98c4f9a97d74488bf37bc902ee25274c83...05211ec9114cfb2886fe17c56fa991603241f50d?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `66.316% <33.333%> (+2.03%)` | `28 <4> (ø)` | :x: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2450?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2450?src=pr&el=footer). Last update [987e2f9...05211ec](https://codecov.io/gh/broadinstitute/gatk/compare/987e2f98c4f9a97d74488bf37bc902ee25274c83...05211ec9114cfb2886fe17c56fa991603241f50d?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285652447:2323,Power,Powered,2323,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2450#issuecomment-285652447,1,['Power'],['Powered']
Energy Efficiency,"s for per-contig histograms):. ````; CONTIG_SET PLOIDY_STATE RELATIVE_PROBABILITY; (1) (2) 1.0; ...; (X,Y) (2,0) 1.0; (X,Y) (1,1) 1.0; (X,Y) (1,0) 0.01; (X,Y) (2,1) 0.01; (X,Y) (1,2) 0.01; (X,Y) (3,0) 0.01; ````. We then fit the per-contig coverage histograms across all samples with the appropriate negative-binomial distributions corresponding to a sparse mixture of genotypes, while accounting for 1) sample-specific depth (which determines the means of the negative-binomial distributions), 2) multiplicative contig-specific bias (which is mild, at least for WGS), and 3) additive sample-contig-specific mosaicism or bias (note that the above genotype priors imply that mosaicism/bias on top of a baseline of CN = 2 is the only deviation allowed for the autosomes, which is somewhat restrictive but greatly aids convergence). I put together a pure PyMC3 prototype that seems to work relatively well. Here are the per-contig coverage histograms (unfiltered bins in blue, bins retained after filtering in red, and negative-binomial fit in green) and a heatmap of per-contig ploidy probabilities. Both the panel (first 20) and case (remaining) samples are shown:. ![prototype-result](https://user-images.githubusercontent.com/11076296/37938642-e9fbd804-312c-11e8-8a6c-02ea4e4fa704.png). Although the prototype model is clearly a good fit to the filtered data, some care in choosing the optimizer and its learning parameters is required to achieve convergence to the correct solution. This is because the problem is inherently multimodal and thus there are many local minima. I found that using AdaMax with a naive strategy of warm restarts (to help kick us out of local minima) worked decently; we can achieve convergence in <10 minutes for 60 samples x 24 contigs x 250 count bins:. ![elbo](https://user-images.githubusercontent.com/11076296/37938658-fc176f12-312c-11e8-89e2-40c68e0f9953.png). I expect that @mbabadi's annealing implementation in the gcnvkernel package will handle the local minima",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271:2149,green,green,2149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271,2,['green'],['green']
Energy Efficiency,s.iterators.PushToPullIterator.advanceToNextElement(PushToPullIterator.java:58); 	at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.<init>(PushToPullIterator.java:37); 	at org.broadinstitute.hellbender.utils.variant.writers.GVCFBlockCombiningIterator.<init>(GVCFBlockCombiningIterator.java:14); 	at org.broadinstitute.hellbender.engine.spark.datasources.VariantsSparkSink.lambda$writeVariantsSingle$516343c4$1(VariantsSparkSink.java:127); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:801); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:121); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745)`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2554#issuecomment-530773994:4022,schedul,scheduler,4022,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2554#issuecomment-530773994,2,['schedul'],['scheduler']
Energy Efficiency,"sbGJlbmRlci90b29scy9zcGFyay9zdi9EaXNjb3ZlclN0cnVjdHVyYWxWYXJpYW50c0Zyb21BbGlnbmVkQ29udGlnc1NBTVNwYXJrLmphdmE=) | `0% <0%> (ø)` | `0 <0> (?)` | |; | [...oadinstitute/hellbender/tools/spark/sv/SvType.java](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdlR5cGUuamF2YQ==) | `100% <100%> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...e/hellbender/tools/spark/sv/ChimericAlignment.java](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9DaGltZXJpY0FsaWdubWVudC5qYXZh) | `57.831% <33.333%> (ø)` | `25 <1> (ø)` | :arrow_down: |; | [...bender/tools/spark/sv/AssemblyAlignmentParser.java](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9Bc3NlbWJseUFsaWdubWVudFBhcnNlci5qYXZh) | `66.917% <66.667%> (ø)` | `38 <1> (ø)` | :arrow_down: |; | [...er/tools/spark/sv/SVVariantConsensusDiscovery.java](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TVlZhcmlhbnRDb25zZW5zdXNEaXNjb3ZlcnkuamF2YQ==) | `82.653% <73.913%> (ø)` | `25 <1> (?)` | |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=footer). Last update [d054e7a...4ffa301](https://codecov.io/gh/broadinstitute/gatk/pull/2567?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2567#issuecomment-291643361:4290,Power,Powered,4290,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2567#issuecomment-291643361,1,['Power'],['Powered']
Energy Efficiency,scala:797); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); 17:43:23.161 INFO FeatureManager - Using codec VCFCodec to read file file:///scratch/tmp/spark-ecd63991-68be-4879-b481-68e6789a2004/userFiles-b72d4821-5e36-4d36-aa79-aa6263768669/1000G_phase1.indels.hg19.sites.vcf; 20/01/05 17:43:23 INFO NewHadoopRDD: Input split: file:/panfs/roc/groups/6/clinicalmdl/shared/wgs_exome_v1.0/projects/BT_WGS_Flex_S1/data/exome_dedup_reads.bam:167436615680+33554432; 20/01/05 17:43:23 ERROR Executor: Exception in task 4990.0 in stage 0.0 (TID 4990); java.io.FileNotFoundException: /panfs/roc/groups/6/clinicalmdl/shared/v1.0/projects/BT_WGS_Flex_S1/data/exome_dedup_reads.ba,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-570992855:4581,schedul,scheduler,4581,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-570992855,1,['schedul'],['scheduler']
Energy Efficiency,"se** coverage by `0.003%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2511 +/- ##; ===============================================; - Coverage 76.259% 76.256% -0.003% ; + Complexity 10865 10864 -1 ; ===============================================; Files 750 750 ; Lines 39543 39543 ; Branches 6915 6915 ; ===============================================; - Hits 30155 30154 -1 ; Misses 6771 6771 ; - Partials 2617 2618 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2511?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...er/tools/walkers/variantutils/VariantsToTable.java](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...1a7a561a7da5603a607f04cd982c62fb8491403b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYXJpYW50c1RvVGFibGUuamF2YQ==) | `94.083% <ø> (ø)` | `73 <0> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/ProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...1a7a561a7da5603a607f04cd982c62fb8491403b?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlci5qYXZh) | `90% <0%> (-1.429%)` | `23% <0%> (-1%)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2511?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2511?src=pr&el=footer). Last update [724fbd0...1a7a561](https://codecov.io/gh/broadinstitute/gatk/compare/724fbd08b213454c996815d4ab22ff1ab517921c...1a7a561a7da5603a607f04cd982c62fb8491403b?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2511#issuecomment-288267091:1937,Power,Powered,1937,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2511#issuecomment-288267091,1,['Power'],['Powered']
Energy Efficiency,"ser-images.githubusercontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:1339,schedul,scheduler,1339,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363,1,['schedul'],['scheduler']
Energy Efficiency,sk.scala:123); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.SparkConte,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:11112,schedul,scheduler,11112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['schedul'],['scheduler']
Energy Efficiency,"son/fa676046-ddfe-4ce8-9193-87025fd9a49b/call-BenchmarkVCFControlSample/Benchmark/8c5c120e-b932-47b0-a592-a719021e6bf9/call-CombineSummaries/summary.csv"",; ""EXOME1 evalindelF1Score"": ""0.727"",; ""EXOME1 evalindelPrecision"": ""0.632"",; ""EXOME1 evalsnpF1Score"": ""0.9878"",; ""EXOME1 evalsnpPrecision"": ""0.9815"",; ""EXOME1 evalsnpRecall"": ""0.9941"",; ""EXOME1 evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-EXOME1SampleHeadToHead/BenchmarkComparison/fa676046-ddfe-4ce8-9193-87025fd9a49b/call-BenchmarkVCFTestSample/Benchmark/b683956e-cbfb-4550-978b-cd6a28bf12a4/call-CombineSummaries/summary.csv"",; ""NIST controlHCprocesshours"": ""103.80716111111109"",; ""NIST controlHCsystemhours"": ""0.20777777777777773"",; ""NIST controlHCwallclockhours"": ""76.1228972222222"",; ""NIST controlHCwallclockmax"": ""4.163775"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-NISTSampleHeadToHead/BenchmarkComparison/24ad1003-6862-4e29-9d4d-ea8e85bcc78b/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-NISTSampleHeadToHead/BenchmarkComparison/24ad1003-6862-4e29-9d4d-ea8e85bcc78b/call-BenchmarkVCFControlSample/Benchmark/7d69a7b4-2884-4b7e-9bce-fc2eab77b125/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""103.71990555555556"",; ""NIST evalHCsystemhours"": ""0.20632500000000004"",; ""NIST evalHCwallclockhours"": ""76.41897222222222"",; ""NIST evalHCwallclockmax"": ""4.163391666666667"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b48",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574622123:20340,monitor,monitoring,20340,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574622123,1,['monitor'],['monitoring']
Energy Efficiency,squashed + rebased. Will merge once tests are green.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2101#issuecomment-249293885:46,green,green,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2101#issuecomment-249293885,1,['green'],['green']
Energy Efficiency,"st and there's no batch api for it? Multi layer docker builds are pretty standard from what I understand. . It sounds like your suggestions are talking about 2 slightly different issues to me. 1. Too many layers:. We typically have squashed the GATK docker images, but we recently switched to building our release images with google cloud build. Since squash is *STILL* an experimental feature in docker we've had trouble getting it to work there. Since the size reduction was pretty minimal from squashing we figured it would be ok to not prioritize it. It's definitely possible for us to consolidate various layers in the build. Or manually squash the images. We can take a look for our next release. Wide workflows on azure are something we need to support. 2. Docker size reduction:; I've spend a lot of time looking at this in the past. Our docker image is huge, but it's mostly due to the massive size of our python and R dependencies. I've done a bunch of work reducing temporary files in independent layers and using multiple stages to reduce the size. There's not much low hanging fruit left there. Similarly, moving to alpine is tricky an has limited benefit. GATK packages a number of C libraries which do not work out of the box on alpine due to the different C runtime. (At least that was the case the last time I investigated it a few years ago. ) I suspect there's a way to port things so they work on it, but it's not something we can do now. It also wouldn't be much of a help, the base image is completely dwarfed by piles of python and R dependencies which are very difficult to safely trim. Anyway, that's the state of things. We've considered a java only image for a while which would be much smaller than the current one. (although still fat by most docker standards...). We've never released one publicly because it seemed like it might cause confusion, but it's a reasonable possibility. . If you have any secret methods to reduce the size of python or R installations we're ha",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1934859427:1239,reduce,reduce,1239,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1934859427,1,['reduce'],['reduce']
Energy Efficiency,"st_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 366.0 MB); 17/10/13 18:11:44 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.131.101.159:44818 (size: 2.1 KB, free: 366.3 MB); 17/10/13 18:11:44 INFO spark.SparkContext: Created broadcast 1 from broadcast at ReadsSparkSink.java:195; 17/10/13 18:11:44 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1; 17/10/13 18:11:44 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false; 17/10/13 18:11:44 INFO spark.SparkContext: Starting job: runJob at SparkHadoopMapReduceWriter.scala:88; 17/10/13 18:11:44 INFO input.FileInputFormat: Total input paths to process : 1; 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Registering RDD 5 (mapToPair at SparkUtils.java:157); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Got job 0 (runJob at SparkHadoopMapReduceWriter.scala:88) with 1 output partitions; 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (runJob at SparkHadoopMapReduceWriter.scala:88); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0); 17/10/13 18:11:44 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at mapToPair at SparkUtils.java:157), which has no missing parents; 17/10/13 18:11:44 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 15.9 KB, free 366.0 MB); 17/10/13 18:11:44 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.3 KB, free 366.0 MB); 17/10/13 18:11:44 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.131.101.159:44818 (size: 7.3 KB, free: 366.3 MB); 17/10/13 18:11:44 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006; 17/10/13 18:11:44",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:16666,schedul,scheduler,16666,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['schedul'],['scheduler']
Energy Efficiency,"stitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(Sp",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:1590,schedul,scheduler,1590,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363,1,['schedul'],['scheduler']
Energy Efficiency,"strated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-CHMSampleHeadToHead/BenchmarkComparison/258eacc8-3768-44a8-86dc-1b2b0516a553/call-CONTROLRuntimeTask/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-CHMSampleHeadToHead/BenchmarkComparison/258eacc8-3768-44a8-86dc-1b2b0516a553/call-BenchmarkVCFControlSample/Benchmark/b89e3e0d-4f93-4b2d-9008-041545f2764c/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""87.0306027777778"",; ""CHM evalHCsystemhours"": ""0.19828888888888896"",; ""CHM evalHCwallclockhours"": ""62.522422222222225"",; ""CHM evalHCwallclockmax"": ""3.293238888888889"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-CHMSampleHeadToHead/BenchmarkComparison/258eacc8-3768-44a8-86dc-1b2b0516a553/call-EVALRuntimeTask/monitoring.pdf"",; ""CHM evalindelF1Score"": ""0.8724"",; ""CHM evalindelPrecision"": ""0.8814"",; ""CHM evalsnpF1Score"": ""0.9784"",; ""CHM evalsnpPrecision"": ""0.9706"",; ""CHM evalsnpRecall"": ""0.9863"",; ""CHM evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-CHMSampleHeadToHead/BenchmarkComparison/258eacc8-3768-44a8-86dc-1b2b0516a553/call-BenchmarkVCFTestSample/Benchmark/6b8eb5cf-ee16-48e8-a24f-de149e2eded2/call-CombineSummaries/summary.csv"",; ""EXOME1 controlindelF1Score"": ""0.727"",; ""EXOME1 controlindelPrecision"": ""0.632"",; ""EXOME1 controlsnpF1Score"": ""0.9878"",; ""EXOME1 controlsnpPrecision"": ""0.9815"",; ""EXOME1 controlsnpRecall"": ""0.9941"",; ""EXOME1 controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/43bcefb2-f38b-413d-9b65-06b489e64af1/call-EXOME1SampleHead",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574622123:18317,monitor,monitoring,18317,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1574622123,1,['monitor'],['monitoring']
Energy Efficiency,"strated/81dbf637-d90c-4111-93b9-9cec426c5a39/call-CHMSampleHeadToHead/BenchmarkComparison/3609bc35-c943-4006-8b6f-9d71e6c68ef5/call-CONTROLRuntimeTask/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/81dbf637-d90c-4111-93b9-9cec426c5a39/call-CHMSampleHeadToHead/BenchmarkComparison/3609bc35-c943-4006-8b6f-9d71e6c68ef5/call-BenchmarkVCFControlSample/Benchmark/96b872e8-26c0-4406-a7d0-addf04f4ad0e/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""78.10857222222224"",; ""CHM evalHCsystemhours"": ""0.28728055555555554"",; ""CHM evalHCwallclockhours"": ""52.84132777777778"",; ""CHM evalHCwallclockmax"": ""2.9151722222222225"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/81dbf637-d90c-4111-93b9-9cec426c5a39/call-CHMSampleHeadToHead/BenchmarkComparison/3609bc35-c943-4006-8b6f-9d71e6c68ef5/call-EVALRuntimeTask/monitoring.pdf"",; ""CHM evalindelF1Score"": ""0.8724"",; ""CHM evalindelPrecision"": ""0.8814"",; ""CHM evalsnpF1Score"": ""0.9784"",; ""CHM evalsnpPrecision"": ""0.9706"",; ""CHM evalsnpRecall"": ""0.9863"",; ""CHM evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/81dbf637-d90c-4111-93b9-9cec426c5a39/call-CHMSampleHeadToHead/BenchmarkComparison/3609bc35-c943-4006-8b6f-9d71e6c68ef5/call-BenchmarkVCFTestSample/Benchmark/a2486748-6d71-463f-bf78-84627e64f2d1/call-CombineSummaries/summary.csv"",; ""EXOME1 controlindelF1Score"": ""0.727"",; ""EXOME1 controlindelPrecision"": ""0.632"",; ""EXOME1 controlsnpF1Score"": ""0.9878"",; ""EXOME1 controlsnpPrecision"": ""0.9815"",; ""EXOME1 controlsnpRecall"": ""0.9941"",; ""EXOME1 controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/81dbf637-d90c-4111-93b9-9cec426c5a39/call-EXOME1SampleHead",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8485#issuecomment-1684837497:18330,monitor,monitoring,18330,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8485#issuecomment-1684837497,1,['monitor'],['monitoring']
Energy Efficiency,"strated/beb77715-227e-4dbd-803f-4458c83607c8/call-CHMSampleHeadToHead/BenchmarkComparison/f1b0b4cf-1a3f-47b3-84fa-529f118419ce/call-CONTROLRuntimeTask/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607c8/call-CHMSampleHeadToHead/BenchmarkComparison/f1b0b4cf-1a3f-47b3-84fa-529f118419ce/call-BenchmarkVCFControlSample/Benchmark/fb68536c-eb99-4d0d-a5c3-4f5accf94546/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""84.94748611111112"",; ""CHM evalHCsystemhours"": ""0.19002777777777768"",; ""CHM evalHCwallclockhours"": ""61.06326111111111"",; ""CHM evalHCwallclockmax"": ""3.2047833333333333"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607c8/call-CHMSampleHeadToHead/BenchmarkComparison/f1b0b4cf-1a3f-47b3-84fa-529f118419ce/call-EVALRuntimeTask/monitoring.pdf"",; ""CHM evalindelF1Score"": ""0.8724"",; ""CHM evalindelPrecision"": ""0.8814"",; ""CHM evalsnpF1Score"": ""0.9784"",; ""CHM evalsnpPrecision"": ""0.9706"",; ""CHM evalsnpRecall"": ""0.9863"",; ""CHM evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607c8/call-CHMSampleHeadToHead/BenchmarkComparison/f1b0b4cf-1a3f-47b3-84fa-529f118419ce/call-BenchmarkVCFTestSample/Benchmark/4353eabb-b85f-4cce-a275-4dba68f9d644/call-CombineSummaries/summary.csv"",; ""EXOME1 controlindelF1Score"": ""0.727"",; ""EXOME1 controlindelPrecision"": ""0.632"",; ""EXOME1 controlsnpF1Score"": ""0.9878"",; ""EXOME1 controlsnpPrecision"": ""0.9815"",; ""EXOME1 controlsnpRecall"": ""0.9941"",; ""EXOME1 controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/beb77715-227e-4dbd-803f-4458c83607c8/call-EXOME1SampleHead",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1546478988:18355,monitor,monitoring,18355,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1546478988,1,['monitor'],['monitoring']
Energy Efficiency,"strated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-CHMSampleHeadToHead/BenchmarkComparison/394f0e4c-4f60-420b-8477-3199ef269728/call-CONTROLRuntimeTask/monitoring.pdf"",; ""CHM controlindelF1Score"": ""0.8724"",; ""CHM controlindelPrecision"": ""0.8814"",; ""CHM controlsnpF1Score"": ""0.9784"",; ""CHM controlsnpPrecision"": ""0.9706"",; ""CHM controlsnpRecall"": ""0.9863"",; ""CHM controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-CHMSampleHeadToHead/BenchmarkComparison/394f0e4c-4f60-420b-8477-3199ef269728/call-BenchmarkVCFControlSample/Benchmark/2aec499d-c11f-4a23-912b-8a61f9982437/call-CombineSummaries/summary.csv"",; ""CHM evalHCprocesshours"": ""86.06659722222223"",; ""CHM evalHCsystemhours"": ""0.19141388888888877"",; ""CHM evalHCwallclockhours"": ""60.83952500000001"",; ""CHM evalHCwallclockmax"": ""3.1510444444444445"",; ""CHM evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-CHMSampleHeadToHead/BenchmarkComparison/394f0e4c-4f60-420b-8477-3199ef269728/call-EVALRuntimeTask/monitoring.pdf"",; ""CHM evalindelF1Score"": ""0.8724"",; ""CHM evalindelPrecision"": ""0.8814"",; ""CHM evalsnpF1Score"": ""0.9784"",; ""CHM evalsnpPrecision"": ""0.9706"",; ""CHM evalsnpRecall"": ""0.9863"",; ""CHM evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-CHMSampleHeadToHead/BenchmarkComparison/394f0e4c-4f60-420b-8477-3199ef269728/call-BenchmarkVCFTestSample/Benchmark/02bfdee5-dde8-4c1d-b628-b21e4512fd42/call-CombineSummaries/summary.csv"",; ""EXOME1 controlindelF1Score"": ""0.727"",; ""EXOME1 controlindelPrecision"": ""0.632"",; ""EXOME1 controlsnpF1Score"": ""0.9878"",; ""EXOME1 controlsnpPrecision"": ""0.9815"",; ""EXOME1 controlsnpRecall"": ""0.9941"",; ""EXOME1 controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/f61c0caa-70a3-4ee5-8542-e78ba8364985/call-EXOME1SampleHead",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535665125:18360,monitor,monitoring,18360,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1535665125,1,['monitor'],['monitoring']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114); 	at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:78); 	... 87 more; Caused by: java.util.ConcurrentModificationException; 	at java.util.ArrayList.sort(ArrayList.java:1464); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAsse,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:11449,schedul,scheduler,11449,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['schedul'],['scheduler']
Energy Efficiency,"t through, but the Spark web interface showed errors in `sortByKey` steps:; ![sparkjob](https://user-images.githubusercontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:1242,schedul,scheduler,1242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363,1,['schedul'],['scheduler']
Energy Efficiency,tationFactory.java:529); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:233); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:201); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:172); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:903); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:857); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.S,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036:9713,Reduce,ReduceOps,9713,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6598#issuecomment-664565036,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,tationFactory.java:564); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:152); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:162); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:924); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:878); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.S,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653:4749,Reduce,ReduceOps,4749,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"te 2975,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 3141,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 3256,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 3330,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 3413,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 3443,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 3534,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 3564,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 3594,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 3662,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 3720,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 3818,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 4256,245760 /BaseQRankSum.tdb; > 1583360232 192.168.6.75:58626 nfsd.proc4.write 297,249856 /BaseQRankSum.tdb. Note the following about the above I/O:. - The position (the 2nd number) is *NOT* changing, so each write seeks to a position and overwrites that block; - As a result the previous 34 writes are thrown away and are useless, only the 35th write makes it to the resulting file.; - Even the last IO of 4256 bytes, only moves the position up by 4096 bytes.; - This problem turns a relatively I/O friendly sequential workload turns into a bunch of tiny writes with seeks for each one. *TERRIBLE* for spinning disks. The solution I propose is just to have two 64KB buffers and only write 64KB when the first buffer is full with the overflow going into the second buffer. This would not only eliminate the seeks, but also reduce the IOP rate by a factor of 600-700 and change this random workload to a mostly sequential. I can write an example code that outputs 100 bytes into a buffer and then writes 64KB at a time if that's helpful.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6487#issuecomment-595367364:3889,reduce,reduce,3889,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6487#issuecomment-595367364,1,['reduce'],['reduce']
Energy Efficiency,"ted at http://10.131.101.159:4040; 17/10/13 18:11:34 INFO spark.SparkContext: Added JAR file:/opt/Software/gatk/build/libs/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar at spark://10.131.101.159:45754/jars/gatk-package-4.beta.5-70-gdc3237e-SNAPSHOT-spark.jar with timestamp 1507889494965; 17/10/13 18:11:35 INFO util.Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances; 17/10/13 18:11:35 INFO gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/10/13 18:11:36 INFO client.RMProxy: Connecting to ResourceManager at mg/10.131.101.159:8032; 17/10/13 18:11:36 INFO yarn.Client: Requesting a new application from cluster with 3 NodeManagers; 17/10/13 18:11:36 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (164726 MB per container); 17/10/13 18:11:36 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 17/10/13 18:11:36 INFO yarn.Client: Setting up container launch context for our AM; 17/10/13 18:11:36 INFO yarn.Client: Setting up the launch environment for our AM container; 17/10/13 18:11:36 INFO yarn.Client: Preparing resources for our AM container; 17/10/13 18:11:37 INFO yarn.Client: Uploading resource file:/tmp/hdfs/spark-c7e5eece-205e-4bce-a69b-4168c9b79045/__spark_conf__2918234914787361986.zip -> hdfs://mg:8020/user/hdfs/.sparkStaging/application_1507856833944_0003/__spark_conf__.zip; 17/10/13 18:11:37 INFO spark.SecurityManager: Changing view acls to: hdfs; 17/10/13 18:11:37 INFO spark.SecurityManager: Changing modify acls to: hdfs; 17/10/13 18:11:37 INFO spark.SecurityManager: Changing view acls groups to: ; 17/10/13 18:11:37 INFO spark.SecurityManager: Changing modify acls groups to: ; 17/10/13 18:11:37 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hdfs); groups with view pe",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:9962,allocate,allocate,9962,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['allocate'],['allocate']
Energy Efficiency,"terator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at org.apache.spark.storage.BlockManager.reportAllBlocks(BlockManager.scala:217); 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:236); 	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:522); 	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:547); 	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); 	at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:547); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1953); 	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:547); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308); 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180); 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); 17/10/18 17:35:58 INFO BlockManagerMaster: BlockManagerMaster stopped; 17/10/18 17:35:58 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker-1,5,main]; java.lang.OutOfMemoryError: Java heap space; 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:208); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtoo",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:5472,Schedul,ScheduledThreadPoolExecutor,5472,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,2,['Schedul'],"['ScheduledFutureTask', 'ScheduledThreadPoolExecutor']"
Energy Efficiency,"th 1 tasks; 17/10/13 18:11:45 INFO spark.ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1); 17/10/13 18:11:48 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.131.101.145:54024) with ID 1; 17/10/13 18:11:48 INFO spark.ExecutorAllocationManager: New executor 1 has registered (new total is 1); 17/10/13 18:11:48 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, com2, executor 1, partition 0, NODE_LOCAL, 4877 bytes); 17/10/13 18:11:48 INFO storage.BlockManagerMasterEndpoint: Registering block manager com2:45501 with 366.3 MB RAM, BlockManagerId(1, com2, 45501, None); 17/10/13 18:11:50 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on com2:45501 (size: 7.3 KB, free: 366.3 MB); 17/10/13 18:11:51 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on com2:45501 (size: 26.0 KB, free: 366.3 MB); 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4638 ms on com2 (executor 1) (1/1); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool ; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (mapToPair at SparkUtils.java:157) finished in 8.668 s; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: looking for newly runnable stages; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: running: Set(); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: failed: Set(); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/13 18:11:53 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.8 KB, free 365.9 MB); 17/10/13 18:11:53 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:18905,schedul,scheduler,18905,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['schedul'],['scheduler']
Energy Efficiency,"titute/gatk/pull/2566?src=pr&el=h1) Report; > Merging [#2566](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/6859a1202a79c1b123eac73a3f70162c6a90783c?src=pr&el=desc) will **decrease** coverage by `0.015%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2566 +/- ##; ==============================================; - Coverage 76.386% 76.37% -0.015% ; + Complexity 10898 10895 -3 ; ==============================================; Files 754 754 ; Lines 39552 39552 ; Branches 6907 6907 ; ==============================================; - Hits 30212 30206 -6 ; - Misses 6727 6732 +5 ; - Partials 2613 2614 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ellbender/utils/test/CommandLineProgramTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0NvbW1hbmRMaW5lUHJvZ3JhbVRlc3Rlci5qYXZh) | `85.714% <0%> (-4.762%)` | `7% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/GenomeLocParser.java](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vbWVMb2NQYXJzZXIuamF2YQ==) | `85.95% <0%> (-4.132%)` | `55% <0%> (-2%)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=footer). Last update [6859a12...1df1909](https://codecov.io/gh/broadinstitute/gatk/pull/2566?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2566#issuecomment-291909459:1766,Power,Powered,1766,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2566#issuecomment-291909459,1,['Power'],['Powered']
Energy Efficiency,"titute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyRW5naW5lLmphdmE=) | `89.33% <50%> (+1.17%)` | `43 <3> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.23% <0%> (-2.74%)` | `11% <0%> (ø)` | |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `89.27% <0%> (-0.39%)` | `73% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+3.22%)` | `39% <0%> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+40%)` | `3% <0%> (+2%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4139?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4139?src=pr&el=footer). Last update [e12034a...af94877](https://codecov.io/gh/broadinstitute/gatk/pull/4139?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4139#issuecomment-358285781:4584,Power,Powered,4584,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4139#issuecomment-358285781,1,['Power'],['Powered']
Energy Efficiency,tor.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:1020); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:847); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:831); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:508); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:509); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653:3277,Reduce,ReduceOps,3277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-1182102653,1,['Reduce'],['ReduceOps']
Energy Efficiency,"torAllocationManager: New executor 1 has registered (new total is 1); 17/10/13 18:11:48 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, com2, executor 1, partition 0, NODE_LOCAL, 4877 bytes); 17/10/13 18:11:48 INFO storage.BlockManagerMasterEndpoint: Registering block manager com2:45501 with 366.3 MB RAM, BlockManagerId(1, com2, 45501, None); 17/10/13 18:11:50 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on com2:45501 (size: 7.3 KB, free: 366.3 MB); 17/10/13 18:11:51 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on com2:45501 (size: 26.0 KB, free: 366.3 MB); 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4638 ms on com2 (executor 1) (1/1); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool ; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (mapToPair at SparkUtils.java:157) finished in 8.668 s; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: looking for newly runnable stages; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: running: Set(); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: failed: Set(); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/13 18:11:53 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.8 KB, free 365.9 MB); 17/10/13 18:11:53 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KB, free 365.8 MB); 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.131.101.159:44818 (size: 32.6 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Submitt",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:19264,schedul,scheduler,19264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['schedul'],['scheduler']
Energy Efficiency,tps://codecov.io/gh/broadinstitute/gatk/pull/2348/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F46696E6442616447656E6F6D69634B6D657273537061726B2E6A617661) |; | ••••••• 71% | [...nder/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2348/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F46696E64427265616B706F696E7445766964656E6365537061726B2E6A617661) |; | ••••••••• 90% | *new* [...ellbender/tools/spark/sv/SVDUSTFilteredKmerizer.java](https://codecov.io/gh/broadinstitute/gatk/pull/2348/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F53564455535446696C74657265644B6D6572697A65722E6A617661) |; | •••••••••• 100% | [...broadinstitute/hellbender/tools/spark/sv/SVKmer.java](https://codecov.io/gh/broadinstitute/gatk/pull/2348/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F53564B6D65722E6A617661) |; | •••••••••• 100% | [...institute/hellbender/tools/spark/sv/SVConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/2348/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F5356436F6E7374616E74732E6A617661) |; | •••••••••• 100% | [...dinstitute/hellbender/tools/spark/sv/SVKmerLong.java](https://codecov.io/gh/broadinstitute/gatk/pull/2348/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F53564B6D65724C6F6E672E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [f72f9da...5782fa3](https://codecov.io/gh/broadinstitute/gatk/compare/f72f9dae42824175b047d9c46c89a9d919ea8dc1...5782fa36a142b2daceed6686d822f935cdb968c0?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2348#issuecomment-273320758:3461,Power,Powered,3461,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2348#issuecomment-273320758,1,['Power'],['Powered']
Energy Efficiency,"tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyRW5naW5lLmphdmE=) | `89.88% <66.66%> (-1.26%)` | `63 <3> (+3)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5442/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5442/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5442/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `81.09% <0%> (+0.6%)` | `42% <0%> (ø)` | :arrow_down: |; | [...walkers/haplotypecaller/AssemblyRegionTrimmer.java](https://codecov.io/gh/broadinstitute/gatk/pull/5442/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseVJlZ2lvblRyaW1tZXIuamF2YQ==) | `62.72% <0%> (+2.72%)` | `20% <0%> (+2%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5442?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5442?src=pr&el=footer). Last update [9c4a27b...bf39362](https://codecov.io/gh/broadinstitute/gatk/pull/5442?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5442#issuecomment-440776502:3910,Power,Powered,3910,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5442#issuecomment-440776502,1,['Power'],['Powered']
Energy Efficiency,"ts header (either proactively or on demand), but transparently to ; application code that is running against the SAMRecord API.; This would allow SAM headers to be transmitted out-of-band in a way that ; depends on the execution environment. Depending on the environment, ; this might be done by proactive broadcast, or you could think of the ; header tag as a promise to retrieve the header if/when it is needed. ; The size and complexity of the header tag might also depend on the ; execution environment. If the execution environment only supports a ; small finite number of headers, the header tag could be a small integer, ; or in a different execution environment it could be; a unique hash of the header or something like that. Memory footprint in ; the receiver is minimized because many SAMRecords can all share the same ; header object.; This requires more work to support in each execution environment, but it ; seems like it could be efficient and allows application code written to ; operate on SAMRecords to be portable; across different execution environments without having to contend with ; the possible presence of headerless SAMRecords. -Bob. On 9/17/15 4:28 PM, droazen wrote:. > @davidadamsphd https://github.com/davidadamsphd, @lbergelson ; > https://github.com/lbergelson, and myself met for an hour or two ; > just now to discuss this issue, and after reviewing all the options I ; > think we were convinced by the following argument:; > ; > The |SAMRecord| class currently allows its header to be set to null, ; > so if there are cases where the class won't function properly or can ; > enter into an inconsistent state when a header is not present these ; > should be treated as bugs and patched, and we should add unit tests to ; > htsjdk to prove that headerless |SAMRecords| function properly. Then ; > in hellbender we can freely use headerless |SAMRecords| everywhere, ; > only restoring the header to the record when writing out the final bam ; > (since our bam writers",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141451518:2515,efficient,efficient,2515,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141451518,1,['efficient'],['efficient']
Energy Efficiency,tureInput(FeatureDataSource.java:324); at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:304); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:256); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:230); at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:214); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.openFeatureSource(JoinReadsWithVariants.java:63); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$null$0(JoinReadsWithVariants.java:44); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.utils.spark.JoinReadsWithVariants.lambda$join$60e5b476$1(JoinReadsWithVariants.java:44); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$7$1.apply(JavaRDDLike.scala:186); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadChec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-570992855:3001,Reduce,ReduceOps,3001,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5316#issuecomment-570992855,2,['Reduce'],"['ReduceOp', 'ReduceOps']"
Energy Efficiency,"u.edu, 42456, None); 18/03/07 13:24:27 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 247.0 KB, free 8.4 GB); 18/03/07 13:24:28 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.5 KB, free 8.4 GB); 18/03/07 13:24:28 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:32895 (size: 25.5 KB, free: 8.4 GB); 18/03/07 13:24:28 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 18/03/07 13:24:28 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 7164 for farrell on ha-hdfs:scc; 18/03/07 13:24:28 INFO security.TokenCache: Got dt for hdfs://scc; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:scc, Ident: (HDFS_DELEGATION_TOKEN token 7164 for farrell); 18/03/07 13:24:28 INFO input.FileInputFormat: Total input paths to process : 1; 18/03/07 13:59:26 INFO spark.SparkContext: Starting job: aggregate at FlagStatSpark.java:73; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Got job 0 (aggregate at FlagStatSpark.java:73) with 252 output partitions; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 1148.4 KB, free 8.4 GB); 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 345.8 KB, free 8.4 GB); 18/03/07 13:59:26 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:32895 (size: 345.8 KB, free: 8.4 GB); 18/03/07 13:59:26 INFO spark.SparkContext: Created broadcast 1 fr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304:1845,schedul,scheduler,1845,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304,1,['schedul'],['scheduler']
Energy Efficiency,"u.edu, 46002, None); 18/03/07 20:31:49 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 246.6 KB, free 8.4 GB); 18/03/07 20:31:50 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.3 KB, free 8.4 GB); 18/03/07 20:31:50 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:41567 (size: 25.3 KB, free: 8.4 GB); 18/03/07 20:31:50 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 18/03/07 20:31:50 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 7175 for farrell on ha-hdfs:scc; 18/03/07 20:31:50 INFO security.TokenCache: Got dt for hdfs://scc; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:scc, Ident: (HDFS_DELEGATION_TOKEN token 7175 for farrell); 18/03/07 20:31:50 INFO input.FileInputFormat: Total input paths to process : 1; 18/03/07 20:31:51 INFO spark.SparkContext: Starting job: aggregate at FlagStatSpark.java:73; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Got job 0 (aggregate at FlagStatSpark.java:73) with 629 output partitions; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 53.9 KB, free 8.4 GB); 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 15.5 KB, free 8.4 GB); 18/03/07 20:31:51 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:41567 (size: 15.5 KB, free: 8.4 GB); 18/03/07 20:31:51 INFO spark.SparkContext: Created broadcast 1 from b",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:5419,schedul,scheduler,5419,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,2,['schedul'],['scheduler']
Energy Efficiency,"u.edu, executor 6, partition 17, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 5, partition 0, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 7, scc-q02.scc.bu.edu, executor 8, partition 3, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 0.0 (TID 8, scc-q03.scc.bu.edu, executor 4, partition 13, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 9, scc-q13.scc.bu.edu, executor 3, partition 7, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 0.0 (TID 10, scc-q14.scc.bu.edu, executor 7, partition 8, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 0.0 (TID 11, scc-q12.scc.bu.edu, executor 2, partition 14, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 0.0 (TID 12, scc-q09.scc.bu.edu, executor 1, parti; ```. Processed 1,2 billion reads in less than 2 minutes..... ```; 18/03/07 20:32:55 INFO scheduler.DAGScheduler: Job 0 finished: aggregate at FlagStatSpark.java:73, took 64.566359 s; 1205535516 in total; 0 QC failure; 37791118 duplicates; 1157122594 mapped (95.98%); 1205535516 paired in sequencing; 602767758 read1; 602767758 read2; 1145853318 properly paired (95.05%); 1150449216 with itself and mate mapped; 6673378 singletons (0.55%); 4595898 with mate mapped to a different chr; 3316623 with mate mapped to a different chr (mapQ>=5); 18/03/07 20:32:55 INFO server.ServerConnector: Stopped ServerConnector@79f5a6ed{HTTP/1.1}{0.0.0.0:4041}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@221ca495{/stages/stage/kill,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:8607,schedul,scheduler,8607,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888,2,['schedul'],['scheduler']
Energy Efficiency,"uence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:08 INFO TaskSetManager:54 - Starting task 3.1 in stage 0.0 (TID 4, scc-q21.scc.bu.edu, executor 1, partition 3, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:08 INFO TaskSetManager:54 - Lost task 1.1 in stage 0.0 (TID 3) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 1]; 2019-01-07 11:34:09 INFO TaskSetManager:54 - Starting task 9.0 in stage 0.0 (TID 5, scc-q12.scc.bu.edu, executor 2, partition 9, NODE_LOCAL, 7992 bytes); 2019-0",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:26529,schedul,scheduler,26529,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['schedul'],['scheduler']
Energy Efficiency,"uler.DAGScheduler: failed: Set(); 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244), which has no missing parents; 17/10/13 18:11:53 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 86.8 KB, free 365.9 MB); 17/10/13 18:11:53 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 32.6 KB, free 365.8 MB); 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.131.101.159:44818 (size: 32.6 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at mapToPair at ReadsSparkSink.java:244) (first 15 tasks are for partitions Vector(0)); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks; 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, com2, executor 1, partition 0, NODE_LOCAL, 4632 bytes); 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on com2:45501 (size: 32.6 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.131.101.145:54024; 17/10/13 18:11:53 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 135 bytes; 17/10/13 18:11:53 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on com2:45501 (size: 2.1 KB, free: 366.2 MB); 17/10/13 18:11:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 565 ms on com2 (executor 1) (1/1); 17/10/13 18:11:53 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool ; 17/10/13 18:11:53 INFO scheduler.DAGScheduler: ResultStage 1 (runJob at SparkHadoopMapReduceWriter.scala:88) finished in 0.566 ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775:20505,schedul,scheduler,20505,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-336412775,2,['schedul'],['scheduler']
Energy Efficiency,"utor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-09 13:35:56 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 12.691336 s; 2019-01-09 13:35:56 INFO AbstractConnector:318 - Stopped Spark@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:56 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-09 13:35:56 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-09 13:35:56 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-09 13:35:56 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-09 13:35:56 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-09 13:35:56 INFO BlockManager:54 - BlockManager stopped; 2019-01-09 13:35:56 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-09 13:35:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:35240,monitor,monitor,35240,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,4,"['Schedul', 'monitor']","['SchedulerExtensionServices', 'monitor']"
Energy Efficiency,"v"",; ""NIST controlHCprocesshours"": ""90.94291388888888"",; ""NIST controlHCsystemhours"": ""0.182125"",; ""NIST controlHCwallclockhours"": ""63.56370277777778"",; ""NIST controlHCwallclockmax"": ""3.701625"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-NISTSampleHeadToHead/BenchmarkComparison/ccdb901c-fb8f-49e4-b542-cf42e011a623/call-CONTROLRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-NISTSampleHeadToHead/BenchmarkComparison/ccdb901c-fb8f-49e4-b542-cf42e011a623/call-BenchmarkVCFControlSample/Benchmark/6d64f12a-ca50-4ecd-8608-93dc53d241bb/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""95.62183055555556"",; ""NIST evalHCsystemhours"": ""0.18361111111111117"",; ""NIST evalHCwallclockhours"": ""64.22846111111112"",; ""NIST evalHCwallclockmax"": ""3.3683277777777776"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-NISTSampleHeadToHead/BenchmarkComparison/ccdb901c-fb8f-49e4-b542-cf42e011a623/call-EVALRuntimeTask/cacheCopy/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/e6f57e40-2025-46fd-9aa0-d591a3799007/call-NISTSampleHeadToHead/BenchmarkComparison/ccdb901c-fb8f-49e4-b542-cf42e011a623/call-BenchmarkVCFTestSample/Benchmark/f0709402-e72d-4013-a781-e50d8d46e2c3/call-CombineSummaries/summary.csv""; }; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069378815:14475,monitor,monitoring,14475,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7651#issuecomment-1069378815,1,['monitor'],['monitoring']
Energy Efficiency,"vYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NpbmsuamF2YQ==) | `73.109% <ø> (-0.84%)` | `26% <ø> (ø)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...9d80a51aa17f77bfca830472bdc4923b98151771?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `73.611% <ø> (-0.694%)` | `36% <ø> (-1%)` | |; | [...org/broadinstitute/hellbender/utils/GenomeLoc.java](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...9d80a51aa17f77bfca830472bdc4923b98151771?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vbWVMb2MuamF2YQ==) | `67.797% <ø> (-0.565%)` | `85% <ø> (-1%)` | |; | [...lbender/tools/walkers/vqsr/VariantDataManager.java](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...9d80a51aa17f77bfca830472bdc4923b98151771?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvVmFyaWFudERhdGFNYW5hZ2VyLmphdmE=) | `66.228% <ø> (-0.439%)` | `78% <ø> (-1%)` | |; | ... and [3 more](https://codecov.io/gh/broadinstitute/gatk/pull/2399/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2399?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2399?src=pr&el=footer). Last update [3c10554...9d80a51](https://codecov.io/gh/broadinstitute/gatk/compare/3c10554709a4f254300a3d38f24216c42da5913c...9d80a51aa17f77bfca830472bdc4923b98151771?el=footer&src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2399#issuecomment-278182658:5027,Power,Powered,5027,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2399#issuecomment-278182658,1,['Power'],['Powered']
Energy Efficiency,va.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114); 	at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:78); 	... 87 more; Caused by: java.util.ConcurrentModificationException; 	at java.util.ArrayList.sort(ArrayList.java:1464); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.readthreading.ReadThreadingAssembler.<init>(ReadThreadingAssembler.java:81); 	at org.broadinstitute.hellbender.tools.wal,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:11538,schedul,scheduler,11538,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['schedul'],['scheduler']
Energy Efficiency,va:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); at org.apache.spark.rdd.RDD.count(RDD.scala:1162); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tool,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:39165,schedul,scheduler,39165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,4,['schedul'],['scheduler']
Energy Efficiency,"vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-18.75%)` | `6% <0%> (ø)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `55.556% <0%> (-18.519%)` | `8% <0%> (-1%)` | |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `40.469% <0%> (-18.009%)` | `28% <0%> (ø)` | |; | ... and [96 more](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=footer). Last update [a85e0ff...1d6ce76](https://codecov.io/gh/broadinstitute/gatk/pull/2085?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-290039637:4188,Power,Powered,4188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-290039637,1,['Power'],['Powered']
Energy Efficiency,veryPipelineSpark - BND_INV55: 0; 00:47:25.291 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 18/04/27 00:47:28 WARN org.apache.spark.scheduler.TaskSetManager: Stage 19 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:47:33 WARN org.apache.spark.scheduler.TaskSetManager: Stage 20 contains a task of very large size (2685 KB). The maximum recommended task size is 100 KB.; 00:47:39.417 INFO StructuralVariationDiscoveryPipelineSpark - Processing 323040 raw alignments from 254678 contigs.; 18/04/27 00:47:39 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 00:47:47.083 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 225280 contigs.; 00:47:48.135 INFO StructuralVariationDiscoveryPipelineSpark - 23702 contigs with chimeric alignments potentially giving SV signals.; 18/04/27 00:47:49 WARN org.apache.spark.scheduler.TaskSetManager: Stage 32 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:47:57 WARN org.apache.spark.scheduler.TaskSetManager: Stage 33 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 00:48:04 WARN org.apache.spark.scheduler.TaskSetManager: Stage 34 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 00:48:13.094 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 15964 variants.; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 6920; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 264; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 268; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 4680; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 487; 00:48:13.107 INFO StructuralVariationDiscoveryPipelineSpark - INS: 3345; 00,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199:1909,schedul,scheduler,1909,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199,1,['schedul'],['scheduler']
Energy Efficiency,veryPipelineSpark - BND_INV55: 0; 02:20:10.148 INFO StructuralVariationDiscoveryPipelineSpark - CPX: 0; 18/04/27 02:20:12 WARN org.apache.spark.scheduler.TaskSetManager: Stage 19 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:18 WARN org.apache.spark.scheduler.TaskSetManager: Stage 20 contains a task of very large size (2599 KB). The maximum recommended task size is 100 KB.; 02:20:24.460 INFO StructuralVariationDiscoveryPipelineSpark - Processing 323040 raw alignments from 254678 contigs.; 18/04/27 02:20:24 WARN org.apache.spark.scheduler.TaskSetManager: Stage 22 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 02:20:32.040 INFO StructuralVariationDiscoveryPipelineSpark - Filtering on MQ left 225280 contigs.; 02:20:33.079 INFO StructuralVariationDiscoveryPipelineSpark - 23841 contigs with chimeric alignments potentially giving SV signals.; 18/04/27 02:20:34 WARN org.apache.spark.scheduler.TaskSetManager: Stage 32 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:42 WARN org.apache.spark.scheduler.TaskSetManager: Stage 33 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 18/04/27 02:20:49 WARN org.apache.spark.scheduler.TaskSetManager: Stage 34 contains a task of very large size (2262 KB). The maximum recommended task size is 100 KB.; 02:20:58.973 INFO StructuralVariationDiscoveryPipelineSpark - Discovered 15659 variants.; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - BND_NOSS: 6920; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV33: 264; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - BND_INV55: 268; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - DEL: 5019; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - DUP: 1793; 02:20:58.991 INFO StructuralVariationDiscoveryPipelineSpark - INS: 1395; 0,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199:5775,schedul,scheduler,5775,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4663#issuecomment-384848199,1,['schedul'],['scheduler']
Energy Efficiency,ware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125); 	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551); 	at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:396); 	at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.read(DefaultArraySerializers.java:307); 	at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); 	at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:362); 	at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63); 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1992); 	at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.lang.NullPointerException; 	at htsjdk.variant.variantcontext.LazyGenotypesContext.decode(LazyGenotypesContext.java:158); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.invalidateSampleOrdering(LazyGenotypesContext.java:205); 	at htsjdk.variant.variantcontext.GenotypesContext.add(GenotypesContext.java:353); 	at htsjdk.variant.variantcontext.GenotypesContext.add(GenotypesContext.java:46); 	at com.esotericsoftware.kr,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765:7310,schedul,scheduler,7310,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3840#issuecomment-464825765,1,['schedul'],['scheduler']
Energy Efficiency,"x"": ""3.8036305555555554"",; ""NIST controlMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-NISTSampleHeadToHead/BenchmarkComparison/75625b9d-e48b-4859-803e-58989e3ccf62/call-CONTROLRuntimeTask/monitoring.pdf"",; ""NIST controlindelF1Score"": ""0.9902"",; ""NIST controlindelPrecision"": ""0.9903"",; ""NIST controlsnpF1Score"": ""0.9899"",; ""NIST controlsnpPrecision"": ""0.9887"",; ""NIST controlsnpRecall"": ""0.9911"",; ""NIST controlsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-NISTSampleHeadToHead/BenchmarkComparison/75625b9d-e48b-4859-803e-58989e3ccf62/call-BenchmarkVCFControlSample/Benchmark/21373bda-c620-4200-ad29-1e3886ea52ad/call-CombineSummaries/summary.csv"",; ""NIST evalHCprocesshours"": ""104.20126111111112"",; ""NIST evalHCsystemhours"": ""0.20587777777777783"",; ""NIST evalHCwallclockhours"": ""76.10080000000004"",; ""NIST evalHCwallclockmax"": ""3.949438888888889"",; ""NIST evalMonitoringLogs"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-NISTSampleHeadToHead/BenchmarkComparison/75625b9d-e48b-4859-803e-58989e3ccf62/call-EVALRuntimeTask/monitoring.pdf"",; ""NIST evalindelF1Score"": ""0.9902"",; ""NIST evalindelPrecision"": ""0.9903"",; ""NIST evalsnpF1Score"": ""0.9899"",; ""NIST evalsnpPrecision"": ""0.9887"",; ""NIST evalsnpRecall"": ""0.9911"",; ""NIST evalsummary"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-NISTSampleHeadToHead/BenchmarkComparison/75625b9d-e48b-4859-803e-58989e3ccf62/call-BenchmarkVCFTestSample/Benchmark/b91bffd4-8057-453f-a8e2-4767648da91a/call-CombineSummaries/summary.csv"",; ""ROC_Plots_Reported"": ""gs://dsde-methods-carrot-prod-cromwell/BenchmarkVCFsHeadToHeadOrchestrated/9c49383b-01a9-4bc0-90fa-cde7e1090a47/call-CreateHTMLReport/report.html""; },; ""errors"": null; } ; </pre> </details>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1549231169:21366,monitor,monitoring,21366,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1549231169,1,['monitor'],['monitoring']
Energy Efficiency,xt(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at org.seqdoop.hadoop_bam.BAMRecordReader.nextKeyValue(BAMRecordReader.java:225); 	at org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:182); 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); 	at scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn.lambda$apply$5412c5cb$1(ApplyBQSRSparkFn.java:22); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn$$Lambda$214/1243271334.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:7536,Reduce,ReduceOps,7536,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,1,['Reduce'],['ReduceOps']
Energy Efficiency,y(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114); 	at org.apache.spark.internal.io.SparkHadoopW,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:11193,schedul,scheduler,11193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['schedul'],['scheduler']
Energy Efficiency,"zL2NvbnRhbWluYXRpb24vQ29udGFtaW5hdGlvbk1vZGVsLmphdmE=) | `92.39% <92.39%> (ø)` | `39 <39> (?)` | |; | [.../walkers/contamination/ContaminationSegmenter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5413/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vQ29udGFtaW5hdGlvblNlZ21lbnRlci5qYXZh) | `96.42% <96.42%> (ø)` | `9 <9> (?)` | |; | [...lbender/utils/read/SAMRecordToGATKReadAdapter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5413/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL1NBTVJlY29yZFRvR0FUS1JlYWRBZGFwdGVyLmphdmE=) | `91.6% <0%> (-2.1%)` | `144% <0%> (+6%)` | |; | [...nder/tools/funcotator/TranscriptSelectionMode.java](https://codecov.io/gh/broadinstitute/gatk/pull/5413/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL1RyYW5zY3JpcHRTZWxlY3Rpb25Nb2RlLmphdmE=) | `89.71% <0%> (-1.87%)` | `1% <0%> (ø)` | |; | [...tools/funcotator/DataSourceFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5413/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0RhdGFTb3VyY2VGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `86.95% <0%> (-1.68%)` | `17% <0%> (ø)` | |; | ... and [23 more](https://codecov.io/gh/broadinstitute/gatk/pull/5413/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5413?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5413?src=pr&el=footer). Last update [864b180...1183b3d](https://codecov.io/gh/broadinstitute/gatk/pull/5413?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5413#issuecomment-438824631:4654,Power,Powered,4654,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5413#issuecomment-438824631,1,['Power'],['Powered']
Energy Efficiency,"zcGFyay9zdi9BbGlnbmVkQXNzZW1ibHlPckV4Y3VzZS5qYXZh) | `93.296% <100%> (+81.997%)` | `34 <2> (+30)` | :arrow_up: |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `76.994% <78.261%> (+36.525%)` | `44 <1> (+16)` | :arrow_up: |; | [.../sv/StructuralVariationDiscoveryPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5UGlwZWxpbmVTcGFyay5qYXZh) | `90.476% <90.476%> (ø)` | `4 <4> (?)` | |; | [...tructuralVariationDiscoveryArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5QXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `95.833% <95.833%> (ø)` | `0 <0> (?)` | |; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluLmphdmE=) | `50.888% <0%> (-1.183%)` | `23% <0%> (-1%)` | |; | ... and [25 more](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=footer). Last update [bf993d8...dc817a8](https://codecov.io/gh/broadinstitute/gatk/pull/2595?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2595#issuecomment-293918558:4362,Power,Powered,4362,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2595#issuecomment-293918558,1,['Power'],['Powered']
Energy Efficiency,"zdC5qYXZh) | `97.82% <100%> (+0.26%)` | `8 <1> (+1)` | :arrow_up: |; | [...er/tools/walkers/GenotypeGVCFsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4969/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0dlbm90eXBlR1ZDRnNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `78.26% <100%> (+2.45%)` | `25 <6> (+6)` | :arrow_up: |; | [...bender/tools/walkers/variantutils/ReblockGVCF.java](https://codecov.io/gh/broadinstitute/gatk/pull/4969/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9SZWJsb2NrR1ZDRi5qYXZh) | `81.52% <100%> (+1.17%)` | `46 <0> (+3)` | :arrow_up: |; | [...der/tools/walkers/annotator/RMSMappingQuality.java](https://codecov.io/gh/broadinstitute/gatk/pull/4969/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9STVNNYXBwaW5nUXVhbGl0eS5qYXZh) | `83.6% <77.35%> (-10.21%)` | `41 <25> (+1)` | |; | [...der/tools/walkers/CombineGVCFsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4969/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0NvbWJpbmVHVkNGc0ludGVncmF0aW9uVGVzdC5qYXZh) | `87.44% <83.33%> (+0.15%)` | `24 <2> (ø)` | :arrow_down: |; | ... and [19 more](https://codecov.io/gh/broadinstitute/gatk/pull/4969/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4969?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4969?src=pr&el=footer). Last update [868a32e...49c474d](https://codecov.io/gh/broadinstitute/gatk/pull/4969?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4969#issuecomment-401457112:4603,Power,Powered,4603,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4969#issuecomment-401457112,1,['Power'],['Powered']
Energy Efficiency,"| [...g/broadinstitute/hellbender/engine/ReadWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZFdhbGtlci5qYXZh) | `100% <0%> (ø)` | `27% <0%> (+13%)` | :arrow_up: |; | [...org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2wuamF2YQ==) | `93.411% <0%> (+1.639%)` | `135% <0%> (+58%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `74.026% <0%> (+1.948%)` | `35% <0%> (ø)` | :arrow_down: |; | [...itute/hellbender/tools/walkers/bqsr/ApplyBQSR.java](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQXBwbHlCUVNSLmphdmE=) | `93.75% <0%> (+2.083%)` | `7% <0%> (+1%)` | :arrow_up: |; | [.../broadinstitute/hellbender/engine/LocusWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvTG9jdXNXYWxrZXIuamF2YQ==) | `92.188% <0%> (+2.714%)` | `26% <0%> (+12%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=footer). Last update [12c7a2d...7488ed4](https://codecov.io/gh/broadinstitute/gatk/pull/2593?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2593#issuecomment-293046056:3826,Power,Powered,3826,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2593#issuecomment-293046056,1,['Power'],['Powered']
Energy Efficiency,| `86.667% <83.333%> (-2.222%)` | `4 <1> (+1)` | |; | [...bender/tools/walkers/annotator/ReferenceBases.java](https://codecov.io/gh/broadinstitute/gatk/pull/5082/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9SZWZlcmVuY2VCYXNlcy5qYXZh) | `87.5% <0%> (-12.5%)` | `9% <0%> (+4%)` | |; | [...institute/hellbender/utils/test/ReadTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5082/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1JlYWRUZXN0VXRpbHMuamF2YQ==) | `94.34% <0%> (-2.803%)` | `5% <0%> (+2%)` | |; | [...itute/hellbender/tools/walkers/mutect/Mutect2.java](https://codecov.io/gh/broadinstitute/gatk/pull/5082/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyLmphdmE=) | `87.273% <0%> (-2.013%)` | `35% <0%> (+17%)` | |; | [...ils/read/markduplicates/sparkrecords/Fragment.java](https://codecov.io/gh/broadinstitute/gatk/pull/5082/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL3NwYXJrcmVjb3Jkcy9GcmFnbWVudC5qYXZh) | `92% <0%> (-1.75%)` | `14% <0%> (+7%)` | |; | [...r/tools/spark/sv/utils/GATKSVVCFUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5082/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9HQVRLU1ZWQ0ZVdGlsc1VuaXRUZXN0LmphdmE=) | `91.379% <0%> (-1.644%)` | `18% <0%> (+5%)` | |; | [...ion/basicshortmutpileup/PowerCalculationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5082/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9Qb3dlckNhbGN1bGF0aW9uVXRpbHMuamF2YQ==) | `95.122% <0%> (-1.545%)` | `31% <0%> (+13%)` | |; | ... and [81 more](https://codecov.io/gh/broadinstitute/gatk/pull/5082/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5082#issuecomment-410074867:3741,Power,PowerCalculationUtils,3741,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5082#issuecomment-410074867,1,['Power'],['PowerCalculationUtils']
Energy Efficiency,•••••••• 100% | [...bender/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F42617365526563616C69627261746F72537061726B536861726465642E6A617661) |; | •••••••••• 100% | [...lbender/tools/spark/pipelines/SortReadFileSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F706970656C696E65732F536F72745265616446696C65537061726B2E6A617661) |; | •••••••••• 100% | [...nes/metrics/CollectBaseDistributionByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F706970656C696E65732F6D6574726963732F436F6C6C65637442617365446973747269627574696F6E42794379636C65537061726B2E6A617661) |; | •••••••••• 100% | [...dline/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F4741544B506C7567696E2F4741544B5265616446696C746572506C7567696E44657363726970746F722E6A617661) |; | •••••••••• 100% | [.../hellbender/tools/walkers/bqsr/BaseRecalibrator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F627173722F42617365526563616C69627261746F722E6A617661) |; > [Review all 30 files changed](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare). > Powered by [Codecov](https://codecov.io?src=pr). Last update [c5851a0...517230c](https://codecov.io/gh/broadinstitute/gatk/compare/c5851a00f972bacaff751cbebad20ed1dc64ebbe...517230cca0aa73c4b9b935a94a8fc576aca7dedc?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2218#issuecomment-254678913:4105,Power,Powered,4105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2218#issuecomment-254678913,1,['Power'],['Powered']
Integrability,	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); 	at com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); 	at com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); 	at com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); 	at com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127); 	at com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:100); 	at com.luz.push.util,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:13973,protocol,protocol,13973,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,3,['protocol'],['protocol']
Integrability,	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnectio,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1509,wrap,wrapper,1509,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['wrap'],['wrapper']
Integrability,[39m[0K. java.lang.IllegalStateException: Something went wrong: [0K. at org.broadinstitute.hellbender.tools.walkers.gnarlyGenotyper.GnarlyGenotyperEngine.finalizeGenotype(GnarlyGenotyperEngine.java:131). at org.broadinstitute.hellbender.tools.walkers.gnarlyGenotyper.GnarlyGenotyper.apply(GnarlyGenotyper.java:287). at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104). at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193). at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193). at java.util.Iterator.forEachRemaining(Iterator.java:116). at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801). at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482). at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472). at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151). at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174). at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234). at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418). at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102). at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048). at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139). at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191). at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210). at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163). at org.broadinstitute.hellbender.Main.instanceMain(Main.java:149). at org.broadinstitute.hellben,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6079#issuecomment-539518973:1545,wrap,wrapAndCopyInto,1545,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6079#issuecomment-539518973,1,['wrap'],['wrapAndCopyInto']
Integrability," 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 3]; 2019-01-07 11:34:12 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Cancelling stage 0; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Stage 0 was cancelled; 2019-01-07 11:34:12 INFO DAGScheduler:54 - ResultStage 0 (count at CountReadsSpark.java:80) failed in 9.293 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:34055,Wrap,Wrappers,34055,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Wrap'],['Wrappers']
Integrability," : 8 : current limit : 6. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location.; Chromosome chr1 position 271413 (TileDB column 271412) has too many alleles in the combined VCF record : 7 : current limit : 6. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location.; Chromosome chr1 position 275583 (TileDB column 275582) has too many alleles in the combined VCF record : 7 : current limit : 6. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location.; Chromosome chr1 position 275664 (TileDB column 275663) has too many alleles in the combined VCF record : 7 : current limit : 6. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location.; Chromosome chr1 position 285109 (TileDB column 285108) has too many alleles in the combined VCF record : 7 : current limit : 6. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location. 20:40:00.698 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.6447453060000009,Cpu time(s),0.6353685659999999; [January 14, 2022 8:40:00 PM MST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 1.40 minutes.; Runtime.totalMemory()=2523922432; java.lang.IllegalStateException: Genotype [1057-01 CTT*/* GQ 99 DP 67 AD 34,21,3,6,1,0,2,0 {SB=7,27,15,18}] does not contain likelihoods necessary to calculate posteriors.; ```. So in my case, it is also failing after a site where number of alt alleles (7) is exactly 1 more than --max-alternate-alleles (6), but not always on the first such variant with 7 alt alleles, depending on other command line options. If I revert GenotypeGVCFs to previous versions from 4.1.9.0 to 4.2.4.0 they all work (using the same GVCF database from GenomicsDBImport 4.2.4.1), so this apparent bug is new in GenotypeGVCFs 4.2.4.1.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1015835315:4687,depend,depending,4687,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1015835315,1,['depend'],['depending']
Integrability," DP=72;ECNT=2;MBQ=0,0;MFRL=0,0;MMQ=0,0;MPOS=0;POPAF=7.30;REF_BASES=GGTATACAAGGTTTGACATCT;SAAF=0.00,0.00,NaN;SAPP=0.025,0.025,0.950;TLOD=6.82 GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:P_PRIOR_RO:P_RO:ROF_TYPE 0|1:0,0:0.962:0:0,0:0,0:0|1:53302899_G_C:53302899:1.444e-05:2.931e-03:F2R1; ```. Stacktrace:; ```; java.lang.IllegalArgumentException: errorRateLog10 must be good probability but got NaN; at org.broadinstitute.hellbender.utils.QualityUtils.phredScaleLog10ErrorRate(QualityUtils.java:321); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.lambda$applyGermlineVariantFilter$16(Mutect2FilteringEngine.java:286); at java.util.stream.DoublePipeline$3$1.accept(DoublePipeline.java:231); at java.util.Spliterators$DoubleArraySpliterator.forEachRemaining(Spliterators.java:1198); at java.util.Spliterator$OfDouble.forEachRemaining(Spliterator.java:822); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); at java.util.stream.IntPipeline.toArray(IntPipeline.java:502); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyGermlineVariantFilter(Mutect2FilteringEngine.java:286); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:519); at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:130); at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpli",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452818901:1307,wrap,wrapAndCopyInto,1307,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452818901,1,['wrap'],['wrapAndCopyInto']
Integrability, Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [2935907552.11](https://github.com/broadinstitute/gatk/runs/8042744893?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.11/tests/test/index.html) |; | cloud | 8 | [2935907552.10](https://github.com/broadinstitute/gatk/runs/8042744743?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.10/tests/test/index.html) |; | unit | 11 | [2935907552.13](https://github.com/broadinstitute/gatk/runs/8042745129?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.13/tests/test/index.html) |; | integration | 11 | [2935907552.12](https://github.com/broadinstitute/gatk/runs/8042744999?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.12/tests/test/index.html) |; | conda | 8 | [2935907552.3](https://github.com/broadinstitute/gatk/runs/8043019512?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.3/tests/test/index.html) |; | unit | 8 | [2935907552.1](https://github.com/broadinstitute/gatk/runs/8043019322?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.1/tests/test/index.html) |; | variantcalling | 8 | [2935907552.2](https://github.com/broadinstitute/gatk/runs/8043019429?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.2/tests/test/index.html) |; | integration | 8 | [2935907552.0](https://github.com/broadinstitute/gatk/runs/8043019196?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1228829876:1904,integrat,integration,1904,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1228829876,1,['integrat'],['integration']
Integrability, Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [3002176541.11](https://github.com/broadinstitute/gatk/runs/8212856906?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.11/tests/test/index.html) |; | cloud | 8 | [3002176541.10](https://github.com/broadinstitute/gatk/runs/8212856796?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.10/tests/test/index.html) |; | unit | 11 | [3002176541.13](https://github.com/broadinstitute/gatk/runs/8212857102?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.13/tests/test/index.html) |; | integration | 11 | [3002176541.12](https://github.com/broadinstitute/gatk/runs/8212857016?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.12/tests/test/index.html) |; | unit | 8 | [3002176541.1](https://github.com/broadinstitute/gatk/runs/8213287905?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.1/tests/test/index.html) |; | integration | 8 | [3002176541.0](https://github.com/broadinstitute/gatk/runs/8213287794?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.0/tests/test/index.html) |; | variantcalling | 8 | [3002176541.2](https://github.com/broadinstitute/gatk/runs/8213288012?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.2/tests/test/index.html) |; | conda | 8 | [3002176541.3](https://github.com/broadinstitute/gatk/runs/8213288138?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1238473387:1429,integrat,integration,1429,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1238473387,1,['integrat'],['integration']
Integrability," a better format. The requirements seem to be: (a) efficient serialization/deserialization, and (b) can easily convert to a SAMRecord for compatibility with existing code. We can make things extra efficient by only deserializing things if they are needed (if a phase doesn't need the CIGAR-related structures, no need to deserialize that). We can achieve this by having the deserialization be lazy. The LazyBAMRecord is a step in that direction since it looks up the reference name only if we ask for it, but we could go a lot further in this direction. But before we do that, having an efficient coder for SAMRecords (I vote for @tomwhite's approach of using the BAMEncoder) will get us 80% of the way for 20% of the effort. Then we can introduce our OptimizedSAMRecord incrementally. . on **headers**:. I agree with @tomwhite that adding the header back after a shuffle is the right thing to do. We know where that happens and we control that code.; @davidadamsphd, you worry about newcomers. But we've already decided that we were going to provide our own API for them (one that does the Dataflow copying for them so they don't have to worry about it). This same API will provide them with header-filled reads, so they don't have to worry about this detail. This falls into the general category of ""the 3rd party devs won't have to even know about Dataflow/Spark: they just need to know our nice, simple interface and use that"". If they know more and want to do fancier things then more power to them, but those users will surely be able to fill in headers, too. We have library functions to use the reads without the headers, but the problem is that (at least for the sort of code I'm writing), I'm handing off a SAMRecord to a big black box and I can't force it to use the library functions - it's going to work on the SAMRecord directly. So at least in this case it's important to fill in the header (unless I happen to know that the ""black box"" won't call any of the header-requiring methods).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141151451:1502,interface,interface,1502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141151451,1,['interface'],['interface']
Integrability," and capturing/resolving these BND's that are not suitable for _THIS PARTICULAR_ logic. I guess in general my personal preference is to put less algorithm-related information in VCF for analysts (less reading for them), and produce add on files for tool developers. What's your thoughts?. > Does this even have to be a spark tool? It looks like you are just reading the variants into a parallel spark context, filtering, and then collecting them to actually process them. Why not just make this a non-spark tool and process it all in memory on one node?. Answer: Agree. It doesn't have to be, at least in theory, and it probably is going to be faster as we don't need to incur the Spark overhead for such a typically small job. But (I'm saying too many buts....) up to this point all SV tools are under the package `hellbender.tools.spark.sv`, so I'm following suit here. Note the two classes's main interface methods mentions nothing about RDDs (that's on purpose). ; On the other hand, this is an engineering question I believe, and it depends on whether we want to put as much of discovery code as possible into `StructuralVariationDiscoveryPipelineSpark` (the last commit actually hooks the two classes into it, so a single invocation of the tool produces more variants), or we go wdl in pipelining the whole process. -------. All in all, I think the comments and critics are generally about the ""filtering""/""classifying"" part, and the most serious concern about it is false negatives. Am I understanding correctly? If so, given that the filtering step is only picking the BND's that are suitable to the linking logic, I can imagine the false negative problem be solved in the future by other logics (e.g. more relaxed requirement on pair matching, or not even requiring matching INV55/INV33 pairs, etc.) In fact, that's what I'm planning on.; Another part of the problem is how much I can accomplish in this single PR, and how large it should be&mdash;the forever existing problem for new tools.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4789#issuecomment-406483929:6278,depend,depends,6278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4789#issuecomment-406483929,2,['depend'],['depends']
Integrability, args to java side; major update to germline WDLs; all optional python args exposed to WDLs as optional args. commit 50cb6fd08de15469a9080cbb27ff30c8b7ee7e21; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 13:50:45 2017 -0500. missing serialVersionUID. commit 5f0f31eab63b0e6f6105708ded7f86c96c830781; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 13:35:33 2017 -0500. annotated intervals kebab case; updated germline WDL workflows. commit 29cc6234dbfb8db12559217a650c6ceb170c5797; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 13:15:28 2017 -0500. cleanup test files. commit 08a35bb4e65eceb735adcd41a91132e9a34d2b66; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 02:50:19 2017 -0500. update WDL scripts. commit 12bcfa192ee6fa6da21239ebf5b513633efe974f; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 02:47:33 2017 -0500. significant updates to GermlineCNVCaller; integration tests for GermlineCNVCaller w/ sim data in both run modes. commit 151416a4af735ca721bd75e4b54a780c17ac9397; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 01:42:05 2017 -0500. hybrid ADVI abstract argument collection w/ flexible default values; hybrid ADVI argument collection for contig ploidy model; hybrid ADVI argument collection for germline denoising and calling model. commit 56e21bf955d3dc0c52aceb384f28cf6173959de0; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Wed Dec 6 23:18:39 2017 -0500. rewritten python-side coverage metadata table reader using pandas to fix the issues with comment line; change criterion for cohort/case based on whether a contig-ploidy model is provided or not; simulated test files for ploidy determination tool; proper integration test for ploidy determination tool and all edge cases; updated docs for ploidy determination tool. commit 7fa104b2e9170770cfc5b338835e41215d7fd39c; Author: Mehrtash Babadi <mehrtash@broadinstitut,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:6922,integrat,integration,6922,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,2,['integrat'],['integration']
Integrability," as a line. This is similar but not analogous to the current behavior for the existing gene lists where we take pains to exclude from the overlap counts bases that are intronic bases in the gene list. . Unfortunately, since the GFF3 format is hierarchical and supports a very large number of feature types it will be very difficult to extract the intron/exon boundaries without properly parsing the GFF3 format. The GFF3 format supports .obo files that lay out the feature hierarchy and through parsing of that format it would be possible to extract intron/exon boundaries but that is not currently supported by HTSJDK and would involve us merging https://github.com/kachulis/htsjdk/tree/ck_gff3_feature_evaluator first in order to support and then on top of that coming up with some rules for deciding what units exactly make up a gene that should be merged for coverage counting. . I see a few options going forwards:; - We could support GFF3 gene lists with hard coded genes/CDS features to be included. This is brittle given that there are a number of more specific names for CDS (coding sequence) exons in genes that might end up being excluded.; - We could support GFF3 format but ignore exon sequences which would mean that the behavior for counting the same genes will vary depending on which format the gene is provided.; - We could support GFF3 gene lists but allow the user to specify exactly what feature types they want to include. This would probably be the best stop-gap solution but we would have to think hard about how to have the user specify ""I want to count genes (with these possible sub-names for what a gene is) and here is a list of CDS elements that could possibly constitute gene exons."" seems complicated to implement correctly but it has the added advantage of probably allowing the user to do much more interesting/fancy analyses with DoC.; - We could wait for the .obo file to be implemented and attempt to parse intron/exon boundaries by reading the ontology provided.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6491#issuecomment-683963413:1905,depend,depending,1905,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6491#issuecomment-683963413,2,['depend'],['depending']
Integrability," at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:49 INFO TaskSetManager:54 - Starting task 7.0 in stage 0.0 (TID 3, scc-q01.scc.bu.edu, executor 1, partition 7, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:49 WARN TaskSetManager:66 - Lost task 2.0 in stage 0.0 (TID 1, scc-q01.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:25174,Wrap,Wrappers,25174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Wrap'],['Wrappers']
Integrability," batch api for it? Multi layer docker builds are pretty standard from what I understand. . It sounds like your suggestions are talking about 2 slightly different issues to me. 1. Too many layers:. We typically have squashed the GATK docker images, but we recently switched to building our release images with google cloud build. Since squash is *STILL* an experimental feature in docker we've had trouble getting it to work there. Since the size reduction was pretty minimal from squashing we figured it would be ok to not prioritize it. It's definitely possible for us to consolidate various layers in the build. Or manually squash the images. We can take a look for our next release. Wide workflows on azure are something we need to support. 2. Docker size reduction:; I've spend a lot of time looking at this in the past. Our docker image is huge, but it's mostly due to the massive size of our python and R dependencies. I've done a bunch of work reducing temporary files in independent layers and using multiple stages to reduce the size. There's not much low hanging fruit left there. Similarly, moving to alpine is tricky an has limited benefit. GATK packages a number of C libraries which do not work out of the box on alpine due to the different C runtime. (At least that was the case the last time I investigated it a few years ago. ) I suspect there's a way to port things so they work on it, but it's not something we can do now. It also wouldn't be much of a help, the base image is completely dwarfed by piles of python and R dependencies which are very difficult to safely trim. Anyway, that's the state of things. We've considered a java only image for a while which would be much smaller than the current one. (although still fat by most docker standards...). We've never released one publicly because it seemed like it might cause confusion, but it's a reasonable possibility. . If you have any secret methods to reduce the size of python or R installations we're happy to take PRs!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1934859427:1752,depend,dependencies,1752,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8684#issuecomment-1934859427,1,['depend'],['dependencies']
Integrability," burden. The parties interested in working on a specific architecture will contribute code directly to the respective architecture-specific repo and gatk will take occasional updates of those repos. The gatk repo will depend on the other two. The PPC repo will depend on the AVX repo (and any other native repos will depend on the AVX one). The avx and ppc repos will have their own build systems and unit tests against the new interface. The AVX repo will expose something like the following Java API (to be worked out in detail). ```; //Used to copy references to byteArrays to JNI from reads; public final class JNIReadDataHolderClass {; public byte[] readBases = null;; public byte[] readQuals = null;; public byte[] insertionGOP = null;; public byte[] deletionGOP = null;; public byte[] overallGCP = null;; }. //Used to copy references to byteArrays to JNI from haplotypes; public final class JNIHaplotypeDataHolderClass {; public byte[] haplotypeBases = null;; }. public interface NativePairHMMKernel extends AutoCloseable { . /**; * Function to initialize the fields of JNIReadDataHolderClass and JNIHaplotypeDataHolderClass from JVM.; * C++ code gets FieldIDs for these classes once and re-uses these IDs for the remainder of the program. Field IDs do not; * change per JVM session; *; * @param readDataHolderClass class type of JNIReadDataHolderClass; * @param haplotypeDataHolderClass class type of JNIHaplotypeDataHolderClass; */; void jniInitializeClassFields(Class<JNIReadDataHolderClass> readDataHolderClass, Class<JNIHaplotypeDataHolderClass> haplotypeDataHolderClass);. /**; * Real compute kernel; */; void jniComputeLikelihoods(int numReads, int numHaplotypes, JNIReadDataHolderClass[] readDataArray,; JNIHaplotypeDataHolderClass[] haplotypeDataArray, double[] likelihoodArray, int maxNumThreadsToUse);. /**; * Print final profiling information from native code. ; */; default void close() { jniClose(); }. void jniClose();; }; ```. and a class that implements those as native methods",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-214914864:1650,interface,interface,1650,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-214914864,1,['interface'],['interface']
Integrability," current = Allele.create(e.getBase());; }; pralm.add(e, current, DEFAULT_FAKE_LIKELIHOOD);; }; return pralm;; }; ```. The solution that I found after looking at the class was this one, that it's very complicated:. ``` java; public static ReadLikelihoods<Allele> flatPerReadAlleleLikelihoodsFromPileup(final ReadPileup pileup, final Allele refAllele, final SAMFileHeader header) {; final Set<Allele> alleleSet = new TreeSet<Allele>();; final Map<String, List<GATKRead>> reads = new HashMap<>();; final byte ref = refAllele.getBases()[0];; alleleSet.add(refAllele);; for (final PileupElement e : pileup) {; if (e.isDeletion()) {; alleleSet.add(Allele.SPAN_DEL);; } else if (e.getBase() == ref) {; alleleSet.add(refAllele);; } else {; alleleSet.add(Allele.create(e.getBase()));; }; final String sample = ReadUtils.getSampleName(e.getRead(), header);; List<GATKRead> list = reads.getOrDefault(sample, null);; if(list == null) {; list = new ArrayList<>();; reads.put(sample, list);; }; list.add(e.getRead());; }; final ReadLikelihoods<Allele> likelihoods = new ReadLikelihoods<>(new IndexedSampleList(reads.keySet()), new IndexedAlleleList<Allele>(alleleSet), reads);; for(final PileupElement e: pileup) {; final String sample = ReadUtils.getSampleName(e.getRead(), header);; final LikelihoodMatrix<Allele> l = likelihoods.sampleMatrix(likelihoods.indexOfSample(sample));; final int alleleIndex;; if (e.isDeletion()) {; alleleIndex = likelihoods.indexOfAllele(Allele.SPAN_DEL);; } else if (e.getBase() != ref) {; alleleIndex = likelihoods.indexOfAllele(Allele.create(e.getBase());; } else {; alleleIndex = likelihoods.indexOfReference();; }. l.set(alleleIndex, l.indexOfRead(e.getRead()), DEFAULT_FAKE_LIKELIHOOD);; }; return likelihoods;; }; ```. This example is very simple, but in my case what I need its to assign an unique likelihood to each read after calling the variant for that read. I want to use the variant annotation engine for annotate this likelihood map because it is using this interface.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-249930107:2622,interface,interface,2622,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-249930107,2,['interface'],['interface']
Integrability," java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:42200,Wrap,Wrappers,42200,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,2,['Wrap'],['Wrappers']
Integrability," might be a hundred or so reads; and each cell is only contributing one to three reads. For other; mutations, maybe there's less than 10 reads corresponding to less than 10; cells, and it can vary pretty dramatically. The total number of cells; represented in a single sample can be thousands to tens of thousands,; usually - but could be many more as the tech advances. My hack for it at the moment is to encode both the cell barcode and the UMI; information into the read name. Then, for each variant, I query the reads; that overlap that variant in the bam file and analyze each read for; supporting the variant or the REF allele - then I can count the reads; according to the specific cells and also deal with any UMI redundancy per; cell. This works pretty well except for the cases where the HC reassembly; provides evidence for the variant and I can't track it to the originally; aligned reads. Also, mostly I think the difficulty here relates to indels; around homopolymers with our pacbio long isoform reads in our rna-seq; variant pipeline that leverages the gatk rna-seq protocol with HC. On Thu, Feb 29, 2024 at 8:58 AM Gökalp Çelik ***@***.***>; wrote:. > Since each cell has a barcode wouldn't it be nice to use them as their; > Read Group ID and Sample Name within the BAM so that variant callers will; > distinguish each cell from their Sample Name and produce a multisample VCF; > for that variant site. Once IDs and Sample Names are split per cell you may; > be able to color them differently in IGV to even visually observe those; > events.; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1971203108>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABZRKX6LYHUXDUMGDU3AIFLYV4ZZLAVCNFSM6AAAAABD4OZKJ6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSNZRGIYDGMJQHA>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >. -- ; --; Brian J. Haas; The Br",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1971223953:1126,protocol,protocol,1126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8703#issuecomment-1971223953,1,['protocol'],['protocol']
Integrability," operation in Genome STRiP is to ask for the sample ; associated with a read. This requires the header, I would think.; Anyway, my main point was just to stimulate thinking about the value of ; implementing an efficient way to transmit the headers.; It also seems to me that this generalizes to efficient patterns to ; transmit any widely shared data (that is referenced by many serialized ; individual data items) out-of-band. -Bob. On 9/21/15 11:42 AM, droazen wrote:. > @bhandsaker https://github.com/bhandsaker Thanks for chiming in with ; > your thoughts/concerns.; > ; > Under this proposal, the various classes in htsjdk that read and ; > return |SAMRecords| (eg., |SAMReader| & co.) would continue to put the ; > header inside of the records, so we would not be imposing an ; > additional burden on direct clients of htsjdk to check for null ; > headers any more than they do currently. The only difference is that ; > if downstream consumers of |SAMRecords| (like hellbender) choose to ; > strip the header from the records, there would be an explicit contract ; > governing the behavior of headerless |SAMRecords| (as opposed to the ; > status quo, in which the header may be null but behavior is totally ; > undocumented and in some cases inconsistent -- eg., the reference name ; > and index in a headerless |SAMRecord| can get out-of-sync in some cases).; > ; > In additional to documenting/clarifying the behavior of headerless ; > |SAMRecords| and fixing any consistency-related bugs we find when ; > operating without a header, we would also make an effort to document ; > when a class in htsjdk that consumes |SAMRecords| requires that a ; > header be present in the records (such as the various writer classes).; > ; > Does this sound reasonable? It's actually a much more conservative ; > proposal than it may have initially sounded :); > ; > —; > Reply to this email directly or view it on GitHub ; > https://github.com/broadinstitute/hellbender/issues/900#issuecomment-142020109.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-142402910:1496,contract,contract,1496,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-142402910,1,['contract'],['contract']
Integrability, org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:31); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:108); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); org.gradle.api.internal.classpath.UnknownModuleException: Cannot locate JAR for module 'ant' in distribution directory '/home/travis/.gradle/wrapper/dists/gradle-3.1-bin/37qejo6a26ua35lyn7h1u9v2n/gradle-3.1'.; 	at org.gradle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:31); 	at org.gradle.wrappe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482:1478,wrap,wrapper,1478,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482,1,['wrap'],['wrapper']
Integrability," that. Sincerely,; Emily. From: ldgauthier ***@***.***>; Sent: Monday, March 28, 2022 2:39 PM; To: broadinstitute/gatk ***@***.***>; Cc: Emily Elizabeth Puckett (puckett3) ***@***.***>; Mention ***@***.***>; Subject: Re: [broadinstitute/gatk] CombineGVCFs: ERROR input alleles must contain <NON_REF> (Issue #7737). CAUTION: This email originated from outside of the organization. Do not click links or open attachments unless you recognize the sender and trust the content is safe. If I'm reading the process correctly, I don't actually think this should work. CombineGVCFs is specifically for combining GVCFs and it expects GVCFs to have <NON_REF> alleles. If you've already run the data through GenotypeGVCFs then you can't use CombineGVCFs again because the <NON_REF> likelihoods have been applied and those alleles are gone. The vcfcombine tool from bcftools is quite fast if all you want to do is join the samples together. -; Reply to this email directly, view it on GitHub<https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fbroadinstitute%2Fgatk%2Fissues%2F7737%23issuecomment-1081062021&data=04%7C01%7CEmily.Puckett%40memphis.edu%7C51db6aa9f41b483e1ce408da10f2aa5d%7Cae145aeacdb2446ab05a7858dde5ddba%7C0%7C0%7C637840931685525269%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&sdata=Pxg8joQfE51l5e3cUUbKA9bQEYDZjp0AxdX0aqDG1MY%3D&reserved=0>, or unsubscribe<https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FALDFEHAXSKZ7YHSFGISLPUTVCIDGZANCNFSM5RZSK5PA&data=04%7C01%7CEmily.Puckett%40memphis.edu%7C51db6aa9f41b483e1ce408da10f2aa5d%7Cae145aeacdb2446ab05a7858dde5ddba%7C0%7C0%7C637840931685525269%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&sdata=6Dkb6rbHDZpS05bYUHhlIRHJitgVtR%2FPB5rNHHFMg%2FQ%3D&reserved=0>.; You are receiving this because you were mentioned.Message ID: ***@***.******@***.***>>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7737#issuecomment-1082170127:1992,Message,Message,1992,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7737#issuecomment-1082170127,1,['Message'],['Message']
Integrability," the count likelihood is actually misspecified there. As an example, consider trying to fit a Poisson to data that is actually zero-inflated Poisson---fitting the histogram will actually result in a more robust estimate for the mean. Another benefit is that truncated data (as we have here) is straightforwardly handled in an unbiased way. In the special case of complete, trivially-binned data, the full, unbinned likelihood is recovered. I think this sort of histogram fitting is pretty standard in the astro/particle community. We can certainly change up the model to include strictly quantized + free-floating states as you describe (rather than the ""fuzzily quantized"" states I use here), but I just wanted to avoid having another level of mixtures/logsumexps for this quick prototype. However, note that modeling mosaicism on the autosomes is desirable, but there we also want the strong diploid prior to nail down the depth and per-contig bias. So we will have to be a little careful about how we introduce free-floating states. Also, since I was not using gcnvkernel, I had to integrate out all discrete parameters. It may be that we can write down a nice model with discrete parameters if we use your inference framework. Finally, I did not further bin the counts here (or rather, the bin size is 1), which already yields the maximum information, but I did use a maximum-count cutoff. If we use the same cutoff for all samples, this allows us to simply pass a non-ragged matrix from Java (with dimensions of samples x contigs x maximum count) as a TSV. However, we may run into trouble if we hit a case sample with very high depth. So some sort of sparse representation of the histogram might indeed be desirable, but I think it should be an exact representation of the full histogram. This would require us to sync up code to emit and consume the representation in both Java and python, so I'd like to avoid it if possible---I think I'd prefer just emitting the ragged matrix, in that case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522:1529,integrat,integrate,1529,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522,2,['integrat'],['integrate']
Integrability," the inconsistency was introduced in the GermlineCNVCaller step. It’s possible that you could edit the files manually so that you don’t have to rerun all GermlineCNVCaller shards; for example, you could check that all dictionaries in the output of the good shards (i.e., those that contain intervals that are correctly ordered with respect to either dictionary) are the correct dictionary used to generate the count files, reshard/reorder the intervals in the failing shards and rerun GermlineCNVCaller, then stitch everything back together with PostprocessGermlineCNVCalls. However, I think this will be a rather delicate surgery and it may be easy to mess up. I would just recommend fresh runs of GermlineCNVCaller with the correct dictionary and an appropriately ordered interval list. I would go so far as to recommend you delete and/or never use that dictionary again—such incorrectly ordered dictionaries are a frequent source of heartbreak!. I would say that the code is working as intended and that the error message is sufficiently informative. However, we could certainly fail earlier, before the expensive GermlineCNVCaller step. As mentioned above, we will need to do some work to enable this; I would suggest:. 1) we enable passing of dictionaries from `-L` Picard interval lists at the engine level (and I would add consistency checks if multiple interval lists are provided here as well),; 2) we add checks to all relevant gCNV tools of read-count dictionaries against the intervals dictionary,; 3) we change the behavior of `CopyNumberArgumentValidationUtils.resolveIntervals` so that it fails if provided an unsorted IAC, rather than sorting the contained intervals w.r.t. the count dictionary upon creation of the returned `SimpleIntervalCollection` (this can be done independently of the first two items and would have caused the failing shard to fail earlier; however, the other two items are required to cause all shards to fail earlier),; 4) we revert the change made to Postproc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6924#issuecomment-719576249:1093,message,message,1093,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924#issuecomment-719576249,2,['message'],['message']
Integrability," the last developer who left this in a reasonable state a beverage of their choice.; # (This may be yourself, and you'll appreciate that beverage while you tinker with dependencies!); #; # When changing dependencies or versions in this file, check to see if the ""supportedPythonPackages"" DataProvider; # used by the testGATKPythonEnvironmentPackagePresent test in PythonEnvironmentIntegrationTest needs to be updated; # to reflect the changes.; #; name: gatk; channels:; # if channels other than conda-forge are added and the channel order is changed (note that conda channel_priority is currently set to flexible),; # verify that key dependencies are installed from the correct channel and compiled against MKL; - conda-forge; - defaults; dependencies:. # core python dependencies; - conda-forge::python=3.6.10 # do not update; - pip=20.0.2 # specifying channel may cause a warning to be emitted by conda; - conda-forge::mkl=2019.5 # MKL typically provides dramatic performance increases for theano, tensorflow, and other key dependencies; - conda-forge::mkl-service=2.3.0; - conda-forge::numpy=1.17.5 # do not update, this will break scipy=0.19.1; # verify that numpy is compiled against MKL (e.g., by checking *_mkl_info using numpy.show_config()); # and that it is used in tensorflow, theano, and other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely necessary, as this may cause conflicts with other core dependencies; # verify that this is using numpy compiled against MKL (e.g., by checking tensorflow.pywrap_tensorflow.IsMklEnabled()); - conda-forge::scipy=1.0.0 # do not update, this will break a scipy.misc.logsumexp import (deprecated in scipy=1.0.0) in pymc3=3.1; - conda-forge::pymc3=3.1 # do not update, this will break gcnvkernel; - conda-forge:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:1692,depend,dependencies,1692,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,2,['depend'],['dependencies']
Integrability," tool, MosaicHunter. The option you suggest looks great. Do you mean that I should establish the GATK 4 developing environment and develop the MosaicHunterFilter tool? I may do that when I have some time. I found the document of GATK 4 at https://github.com/broadinstitute/gatk. Do you have any further advices?. Best regards,; Adam Yongxin Ye; Center for Bioinformatics; Peking University. At 2018-07-07 01:43:05, ""Geraldine Van der Auwera"" <notifications@github.com> wrote:. Hi @Yyx2626, I'm Geraldine, you may remember me from the Beijing training. It was great visiting your team! I'm sorry it took me so long to follow up on this discussion, and I want to thank you again for reaching out to us about integrating the tool that you developed into GATK. We are certainly very interested in providing this enhancement to the research community, and we are now ready to talk about the next steps. After examining your paper and the source code in Github, we think that the most efficient way to integrate the functionality you developed would be to adapt the filtering parts of your tool to run on the output of Mutect2. So this would be a standalone tool that you would run after Mutect2, much like the current FilterMutectCalls tool. If the results are comparable to your current tool, then we would take that into the official distribution of GATK. If somehow that integration does not yield satisfactory results, then we would look at integrating the entire tool, though we're hoping it won't be necessary, so we can avoid maintaining duplicate functionality for some of the boilerplate data transformations. David @davidbenjamin can provide some advice on how to implement this in GATK4; in brief you would need to write some code that applies the filters you developed to a variant context. Let us know if this is an option you'd like to explore; we'd be happy to help. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4632#issuecomment-404104349:1221,integrat,integrate,1221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4632#issuecomment-404104349,3,['integrat'],"['integrate', 'integrating', 'integration']"
Integrability," unnecessary copies of the data (now fixed: https://github.com/cloudera/spark-dataflow/pull/60), which caused OOM errors when trying to broadcast the 3GB reference data. With this fixed, I ran a [pipeline called JoinReferencesDataflow](https://github.com/tomwhite/hellbender/blob/hadoop-references/src/main/java/org/broadinstitute/hellbender/tools/dataflow/pipelines/JoinReferencesDataflow.java) on a small cluster that broadcasts the reference as a dataflow view. The code is a modified version of CountReadsDataflow that simply sends the view, and then doesn't use it, so we can see the cost of doing a broadcast (See the rest of the code in this branch: https://github.com/tomwhite/hellbender/tree/hadoop-references). JoinReferencesDataflow took 2 min 25s to run, of which 18s were for reading the reference from the local filesystem in the driver. For comparison, CountReadsDataflow took 17s on the same cluster. So broadcasting the reference takes less than 2 minutes. Note that this was just for one task, but Spark has [an efficient protocol for sending broadcast variables](http://www.cs.berkeley.edu/~agearh/cs267.sp10/files/mosharaf-spark-bc-report-spring10.pdf), which scales well with the number of nodes, so the approach looks feasible. Having said all that, we might still want to use the sharding approach, in order to share more code between the Google and Spark dataflow implementations. One way this could work would be to generalize `RefAPISource` and `RefAPIMetadata` to support reading reference data from a [ReferenceHadoopSource](https://github.com/tomwhite/hellbender/blob/hadoop-references/src/main/java/org/broadinstitute/hellbender/engine/dataflow/datasources/ReferenceHadoopSource.java), which is in line with @droazen's last comment. Am I right in thinking that the read pipeline work is being completed in https://github.com/broadinstitute/hellbender/tree/da_read_pipeline? Is that at a point where I could try with pipeline on Spark, or should I wait until it's merged?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/567#issuecomment-120001353:1158,protocol,protocol,1158,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/567#issuecomment-120001353,1,['protocol'],['protocol']
Integrability, we are running on Google Compute Engine.; java.net.ConnectException: Connection refused (Connection refused); at java.net.PlainSocketImpl.socketConnect(Native Method); at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); at shaded.cloud_nio.com.goo,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843:1594,protocol,protocol,1594,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843,1,['protocol'],['protocol']
Integrability, |; | [...tools/copynumber/ModelSegmentsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5048/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL01vZGVsU2VnbWVudHNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `89.308% <100%> (+0.206%)` | `20 <0> (ø)` | :arrow_down: |; | [...ools/copynumber/formats/records/LegacySegment.java](https://codecov.io/gh/broadinstitute/gatk/pull/5048/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvcmVjb3Jkcy9MZWdhY3lTZWdtZW50LmphdmE=) | `46.875% <46.875%> (ø)` | `7 <7> (?)` | |; | [...r/formats/collections/LegacySegmentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5048/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvTGVnYWN5U2VnbWVudENvbGxlY3Rpb24uamF2YQ==) | `72.222% <72.222%> (ø)` | `4 <4> (?)` | |; | [.../sv/integration/SVIntegrationTestDataProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/5048/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9TVkludGVncmF0aW9uVGVzdERhdGFQcm92aWRlci5qYXZh) | `90.909% <0%> (-3.209%)` | `2% <0%> (+1%)` | |; | [...te/hellbender/tools/spark/sv/utils/SVInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/5048/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TVkludGVydmFsLmphdmE=) | `85.507% <0%> (-1.993%)` | `48% <0%> (+12%)` | |; | [...on/FindBreakpointEvidenceSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5048/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `100% <0%> (ø)` | `13% <0%> (+6%)` | :arrow_up: |; | [...spark/sv/evidence/BreakpointDensityFilterTest.jav,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5048#issuecomment-407457135:2892,integrat,integration,2892,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5048#issuecomment-407457135,1,['integrat'],['integration']
Integrability,"""D:\Program Files\Java\jdk1.8.0_121\bin\java.exe"" -agentlib:jdwp=transport=dt_socket,address=127.0.0.1:62530,suspend=y,server=n -XX:TieredStopAtLevel=1 -noverify -Dspring.output.ansi.enabled=always -Dcom.sun.management.jmxremote -Dspring.jmx.enabled=true -Dspring.liveBeansView.mbeanDomain -Dspring.application.admin.enabled=true -javaagent:C:\Users\Sweet\AppData\Local\JetBrains\IntelliJIdea2020.1\captureAgent\debugger-agent.jar -Dfile.encoding=UTF-8 -classpath ""D:\Program Files\Java\jdk1.8.0_121\jre\lib\charsets.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\deploy.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\access-bridge-64.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\cldrdata.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\dnsns.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\jaccess.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\jfxrt.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\localedata.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\nashorn.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunec.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunjce_provider.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunmscapi.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\sunpkcs11.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_121\jre\lib\rt.jar;C:\project\push\target\classes;E:\repository\org\springframework\boot\spring-boot-starter-jdbc\2.3.0.RELEASE\spring-boot-starter-jdbc-2.3.0.RELEASE.jar;E:\repository\org\springframework\boot\spring-boot-starter\2.3",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233:629,bridg,bridge-,629,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-635805233,1,['bridg'],['bridge-']
Integrability,"## Update:. ### A [broad institute forum post](https://gatk.broadinstitute.org/hc/en-us/community/posts/360061666671/comments/360010377231) gave the solution:. #### If you paste this text into the `gatkcondaenv.yaml` file:. ```; # Conda environment for GATK Python Tools; #; # Only update this environment if there is a *VERY* good reason to do so!; # If the build is broken but could be fixed by doing something else, then do that thing instead.; # Ensuring the correct environment for canonical (or otherwise reasonable) usage of our standard Docker takes precedence over edge cases.; # If you break the environment, you are responsible for fixing it and also owe the last developer who left this in a reasonable state a beverage of their choice.; # (This may be yourself, and you'll appreciate that beverage while you tinker with dependencies!); #; # When changing dependencies or versions in this file, check to see if the ""supportedPythonPackages"" DataProvider; # used by the testGATKPythonEnvironmentPackagePresent test in PythonEnvironmentIntegrationTest needs to be updated; # to reflect the changes.; #; name: gatk; channels:; # if channels other than conda-forge are added and the channel order is changed (note that conda channel_priority is currently set to flexible),; # verify that key dependencies are installed from the correct channel and compiled against MKL; - conda-forge; - defaults; dependencies:. # core python dependencies; - conda-forge::python=3.6.10 # do not update; - pip=20.0.2 # specifying channel may cause a warning to be emitted by conda; - conda-forge::mkl=2019.5 # MKL typically provides dramatic performance increases for theano, tensorflow, and other key dependencies; - conda-forge::mkl-service=2.3.0; - conda-forge::numpy=1.17.5 # do not update, this will break scipy=0.19.1; # verify that numpy is compiled against MKL (e.g., by checking *_mkl_info using numpy.show_config()); # and that it is used in tensorflow, theano, and other key dependencies; - conda-for",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:833,depend,dependencies,833,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,4,['depend'],['dependencies']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2101?src=pr) is 74.094% (diff: 32.595%). > Merging [#2101](https://codecov.io/gh/broadinstitute/gatk/pull/2101?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.345%**. ``` diff; @@ master #2101 diff @@; ==========================================; Files 706 711 +5 ; Lines 37972 38288 +316 ; Methods 0 0 ; Messages 0 0 ; Branches 8008 8057 +49 ; ==========================================; + Hits 28266 28369 +103 ; - Misses 7330 7537 +207 ; - Partials 2376 2382 +6 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2101/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | 0% | _new_ [.../hellbender/tools/examples/ExampleNioCountReads.java](https://codecov.io/gh/broadinstitute/gatk/pull/2101/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F6578616D706C65732F4578616D706C654E696F436F756E7452656164732E6A617661) |; | 0% | _new_ [...oadinstitute/hellbender/utils/nio/ReadsIterable.java](https://codecov.io/gh/broadinstitute/gatk/pull/2101/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F6E696F2F52656164734974657261626C652E6A617661) |; | 0% | _new_ [...te/hellbender/utils/nio/ChannelAsSeekableStream.java](https://codecov.io/gh/broadinstitute/gatk/pull/2101/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F6E696F2F4368616E6E656C41735365656B61626C6553747265616D2E6A617661) |; | 0% | [...broadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2101/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F6763732F4275636B65745574696C732E6A617661) |; | 0% | _new_ [.../org/broadinstitute/hellbender/utils/nio/NioBam.java](,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2101#issuecomment-249299231:441,Message,Messages,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2101#issuecomment-249299231,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2133?src=pr) is 75.711% (diff: 83.505%); > Merging [#2133](https://codecov.io/gh/broadinstitute/gatk/pull/2133?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.009%**. ```diff; @@ master #2133 diff @@; ==========================================; Files 728 729 +1 ; Lines 38451 38515 +64 ; Methods 0 0 ; Messages 0 0 ; Branches 8027 8040 +13 ; ==========================================; + Hits 29108 29160 +52 ; - Misses 6840 6847 +7 ; - Partials 2503 2508 +5 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2133/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; |---|---|; | •••••••• 83% | *new* [...rg/broadinstitute/hellbender/utils/SATagBuilder.java](https://codecov.io/gh/broadinstitute/gatk/pull/2133/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F53415461674275696C6465722E6A617661) |; | •••••••••• 100% | [...ellbender/tools/walkers/rnaseq/SplitNCigarReads.java](https://codecov.io/gh/broadinstitute/gatk/pull/2133/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F726E617365712F53706C69744E436967617252656164732E6A617661) |; | •••••••••• 100% | [.../broadinstitute/hellbender/utils/read/ReadUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2133/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F726561642F526561645574696C732E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [ffc26bb...36e06a7](https://codecov.io/gh/broadinstitute/gatk/compare/ffc26bbb4d89d995396ff7b025a798daf1061c9d...36e06a7d50089927fb966586c7e131fba99a534c?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2133#issuecomment-266102980:439,Message,Messages,439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2133#issuecomment-266102980,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2154?src=pr) is 73.987% (diff: 89.286%). > Merging [#2154](https://codecov.io/gh/broadinstitute/gatk/pull/2154?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.452%**. ``` diff; @@ master #2154 diff @@; ==========================================; Files 706 706 ; Lines 37972 38008 +36 ; Methods 0 0 ; Messages 0 0 ; Branches 8008 8014 +6 ; ==========================================; - Hits 28266 28121 -145 ; - Misses 7330 7506 +176 ; - Partials 2376 2381 +5 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2154/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | ••••••• 72% | [...bender/utils/locusiterator/LocusIteratorByState.java](https://codecov.io/gh/broadinstitute/gatk/pull/2154/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F6C6F6375736974657261746F722F4C6F6375734974657261746F72427953746174652E6A617661) |; | •••••••• 83% | [...rg/broadinstitute/hellbender/engine/LocusWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2154/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4C6F63757357616C6B65722E6A617661) |; | •••••••• 87% | [...stitute/hellbender/tools/walkers/qc/CheckPileup.java](https://codecov.io/gh/broadinstitute/gatk/pull/2154/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F71632F436865636B50696C6575702E6A617661) |; | ••••••••• 96% | [...oadinstitute/hellbender/utils/pileup/ReadPileup.java](https://codecov.io/gh/broadinstitute/gatk/pull/2154/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F70696C6575702F5265616450696C6575702E6A617661) |; | •••••••••• 100% | [...broadinstitute/hellbender/engine/Ass,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2154#issuecomment-252230207:437,Message,Messages,437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2154#issuecomment-252230207,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2170?src=pr) is 74.268% (diff: 89.474%). > Merging [#2170](https://codecov.io/gh/broadinstitute/gatk/pull/2170?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.059%**. ``` diff; @@ master #2170 diff @@; ==========================================; Files 705 705 ; Lines 37924 37933 +9 ; Methods 0 0 ; Messages 0 0 ; Branches 8002 8005 +3 ; ==========================================; + Hits 28143 28172 +29 ; + Misses 7420 7396 -24 ; - Partials 2361 2365 +4 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2170/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | •••••••• 89% | [...r/tools/walkers/genotyper/AlleleSubsettingUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2170/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F416C6C656C6553756273657474696E675574696C732E6A617661) |; | •••••••••• 100% | [...ellbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2170/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F76617269616E742F4741544B56617269616E74436F6E746578745574696C732E6A617661) |; | •••••••••• 100% | [.../java/org/broadinstitute/hellbender/utils/Utils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2170/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F5574696C732E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [491f7f2...3ac63b8](https://codecov.io/gh/broadinstitute/gatk/compare/491f7f2436421c53204be5c0fb5226bed2b4842a...3ac63b82465b1e7fe1ac8a3b0542e321286d217c?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2170#issuecomment-248102291:436,Message,Messages,436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2170#issuecomment-248102291,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2179?src=pr) is 74.416% (diff: 84.211%). > Merging [#2179](https://codecov.io/gh/broadinstitute/gatk/pull/2179?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.148%**. ``` diff; @@ master #2179 diff @@; ==========================================; Files 705 706 +1 ; Lines 37933 38012 +79 ; Methods 0 0 ; Messages 0 0 ; Branches 8005 8030 +25 ; ==========================================; + Hits 28172 28287 +115 ; + Misses 7396 7349 -47 ; - Partials 2365 2376 +11 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2179/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | •••••••• 82% | _new_ [...nder/tools/examples/ExampleAssemblyRegionWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2179/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F6578616D706C65732F4578616D706C65417373656D626C79526567696F6E57616C6B65722E6A617661) |; | •••••••••• 100% | [...nstitute/hellbender/engine/AssemblyRegionWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2179/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F417373656D626C79526567696F6E57616C6B65722E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [b4d9fb2...bdf6dc1](https://codecov.io/gh/broadinstitute/gatk/compare/b4d9fb2f6d9b487789bdd9405debdc260b58a229...bdf6dc1cb16f1d058575fec25667712974b46a96?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2179#issuecomment-248132733:440,Message,Messages,440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2179#issuecomment-248132733,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2182?src=pr) is 75.950% (diff: 86.093%). > Merging [#2182](https://codecov.io/gh/broadinstitute/gatk/pull/2182?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.024%**. ``` diff; @@ master #2182 diff @@; ==========================================; Files 709 712 +3 ; Lines 38116 38241 +125 ; Methods 0 0 ; Messages 0 0 ; Branches 8009 8030 +21 ; ==========================================; + Hits 28940 29044 +104 ; - Misses 6711 6723 +12 ; - Partials 2465 2474 +9 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2182/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | •••• 40% | [...llbender/tools/walkers/vqsr/VariantRecalibrator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2182/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F767173722F56617269616E74526563616C69627261746F722E6A617661) |; | •••••••• 82% | _new_ [...titute/hellbender/engine/MultiVariantDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2182/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4D756C746956617269616E7444617461536F757263652E6A617661) |; | ••••••••• 95% | _new_ [...dinstitute/hellbender/engine/MultiVariantWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2182/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4D756C746956617269616E7457616C6B65722E6A617661) |; | •••••••••• 100% | _new_ [...adinstitute/hellbender/engine/VariantWalkerBase.java](https://codecov.io/gh/broadinstitute/gatk/pull/2182/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F56617269616E7457616C6B6572426173652E6A617661) |; | •••••••••• 100% | [...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2182#issuecomment-248405018:441,Message,Messages,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2182#issuecomment-248405018,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2184?src=pr) is 74.446% (diff: 66.667%). > Merging [#2184](https://codecov.io/gh/broadinstitute/gatk/pull/2184?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.007%**. ``` diff; @@ master #2184 diff @@; ==========================================; Files 706 706 ; Lines 37972 37974 +2 ; Methods 0 0 ; Messages 0 0 ; Branches 8008 8009 +1 ; ==========================================; + Hits 28266 28270 +4 ; + Misses 7330 7328 -2 ; Partials 2376 2376 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2184/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | •••••• 66% | [...calc/IndependentAllelesDiploidExactAFCalculator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2184/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F616663616C632F496E646570656E64656E74416C6C656C65734469706C6F69644578616374414643616C63756C61746F722E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [3e20270...54f8615](https://codecov.io/gh/broadinstitute/gatk/compare/3e202701dc55ab49857643926a86a79680c96fc8...54f86158d4d727fe97d266cb99957991ff823229?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2184#issuecomment-249189120:436,Message,Messages,436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2184#issuecomment-249189120,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2185?src=pr) is 75.926% (diff: 68.939%). > Merging [#2185](https://codecov.io/gh/broadinstitute/gatk/pull/2185?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.061%**. ``` diff; @@ master #2185 diff @@; ==========================================; Files 711 709 -2 ; Lines 38346 38116 -230 ; Methods 0 0 ; Messages 0 0 ; Branches 8066 8009 -57 ; ==========================================; - Hits 29138 28940 -198 ; + Misses 6731 6711 -20 ; + Partials 2477 2465 -12 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2185/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | 0% | [...ers/annotator/allelespecific/AS_StrandOddsRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/2185/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F616C6C656C6573706563696669632F41535F537472616E644F646473526174696F2E6A617661) |; | 0% | [...bender/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2185/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F47656E6F747970696E67456E67696E652E6A617661) |; | 0% | [...alkers/annotator/allelespecific/AS_FisherStrand.java](https://codecov.io/gh/broadinstitute/gatk/pull/2185/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F616C6C656C6573706563696669632F41535F466973686572537472616E642E6A617661) |; | •••• 40% | [...bender/tools/walkers/annotator/DepthPerSampleHC.java](https://codecov.io/gh/broadinstitute/gatk/pull/2185/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-249258490:441,Message,Messages,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-249258490,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2186?src=pr) is 75.926% (diff: 100%). > Merging [#2186](https://codecov.io/gh/broadinstitute/gatk/pull/2186?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.003%**. ``` diff; @@ master #2186 diff @@; ==========================================; Files 712 712 ; Lines 38214 38219 +5 ; Methods 0 0 ; Messages 0 0 ; Branches 8022 8022 ; ==========================================; + Hits 29013 29018 +5 ; Misses 6726 6726 ; Partials 2475 2475 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2186/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | •••••••••• 100% | [...llbender/tools/walkers/vqsr/VariantRecalibrator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2186/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F767173722F56617269616E74526563616C69627261746F722E6A617661) |; | •••••••••• 100% | [...lbender/tools/walkers/vqsr/GaussianMixtureModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/2186/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F767173722F476175737369616E4D6978747572654D6F64656C2E6A617661) |; | •••••••••• 100% | [...er/tools/walkers/vqsr/VariantRecalibratorEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2186/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F767173722F56617269616E74526563616C69627261746F72456E67696E652E6A617661) |; | •••••••••• 100% | [...lbender/tools/walkers/vqsr/MultivariateGaussian.java](https://codecov.io/gh/broadinstitute/gatk/pull/2186/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F767173722F4D756C7469766172696174,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2186#issuecomment-249924338:433,Message,Messages,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2186#issuecomment-249924338,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2187?src=pr) is 75.892% (diff: 100%). > Merging [#2187](https://codecov.io/gh/broadinstitute/gatk/pull/2187?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.011%**. ``` diff; @@ master #2187 diff @@; ==========================================; Files 711 711 ; Lines 38290 38315 +25 ; Methods 0 0 ; Messages 0 0 ; Branches 8058 8066 +8 ; ==========================================; + Hits 29055 29078 +23 ; Misses 6765 6765 ; - Partials 2470 2472 +2 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2187/graphs/sunburst.svg?size=150&src=pr). > Powered by [Codecov](https://codecov.io?src=pr). Last update [c925d2c...30e9a42](https://codecov.io/gh/broadinstitute/gatk/compare/c925d2c3b53eb4e348b2bb3a852a708ef3fd724d...30e9a4244a26e00ae4d02b378f63dc30f6bb0e20?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2187#issuecomment-250553572:434,Message,Messages,434,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2187#issuecomment-250553572,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2188?src=pr) is 75.894% (diff: 100%). > Merging [#2188](https://codecov.io/gh/broadinstitute/gatk/pull/2188?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.012%**. ``` diff; @@ master #2188 diff @@; ==========================================; Files 711 711 ; Lines 38290 38301 +11 ; Methods 0 0 ; Messages 0 0 ; Branches 8058 8058 ; ==========================================; + Hits 29055 29068 +13 ; + Misses 6765 6763 -2 ; Partials 2470 2470 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2188/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | •••••••••• 100% | [...itute/hellbender/utils/variant/GATKVCFConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/2188/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F76617269616E742F4741544B564346436F6E7374616E74732E6A617661) |; | •••••••••• 100% | [...ute/hellbender/utils/variant/GATKVCFHeaderLines.java](https://codecov.io/gh/broadinstitute/gatk/pull/2188/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F76617269616E742F4741544B5643464865616465724C696E65732E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [c925d2c...3b78e79](https://codecov.io/gh/broadinstitute/gatk/compare/c925d2c3b53eb4e348b2bb3a852a708ef3fd724d...3b78e792b93605bfdaabe8db24219783d3df9209?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2188#issuecomment-249994221:434,Message,Messages,434,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2188#issuecomment-249994221,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2189?src=pr) is 75.924% (diff: 58.123%). > Merging [#2189](https://codecov.io/gh/broadinstitute/gatk/pull/2189?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.034%**. ``` diff; @@ master #2189 diff @@; ==========================================; Files 711 718 +7 ; Lines 38303 38781 +478 ; Methods 0 0 ; Messages 0 0 ; Branches 8058 8120 +62 ; ==========================================; + Hits 29068 29444 +376 ; - Misses 6765 6845 +80 ; - Partials 2470 2492 +22 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2189/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | 0% | [...e/hellbender/tools/spark/sv/BreakpointAlignment.java](https://codecov.io/gh/broadinstitute/gatk/pull/2189/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F427265616B706F696E74416C69676E6D656E742E6A617661) |; | 0% | [...broadinstitute/hellbender/utils/pairhmm/PairHMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/2189/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F70616972686D6D2F50616972484D4D2E6A617661) |; | 0% | [...ender/tools/spark/sv/AlignAssembledContigsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2189/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F416C69676E417373656D626C6564436F6E74696773537061726B2E6A617661) |; | 0% | [...nder/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2189/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F46696E64427265616B706F696E7445766964656E6365537061726B2E6A617661) |; | 0% | [...r/tools/spark/sv/RunSGAVia,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2189#issuecomment-251449369:441,Message,Messages,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2189#issuecomment-251449369,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2190?src=pr) is 76.076% (diff: 90.258%). > Merging [#2190](https://codecov.io/gh/broadinstitute/gatk/pull/2190?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.138%**. ``` diff; @@ master #2190 diff @@; ==========================================; Files 712 719 +7 ; Lines 38219 38560 +341 ; Methods 0 0 ; Messages 0 0 ; Branches 8022 8071 +49 ; ==========================================; + Hits 29023 29335 +312 ; - Misses 6721 6735 +14 ; - Partials 2475 2490 +15 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2190/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | •• 25% | [...institute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/2190/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F436F6D6D616E644C696E6550726F6772616D2E6A617661) |; | •• 25% | [...dline/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/2190/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F4741544B506C7567696E2F4741544B5265616446696C746572506C7567696E44657363726970746F722E6A617661) |; | •••••••• 83% | [...llbender/engine/spark/AddContextDataToReadSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2190/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F416464436F6E7465787444617461546F52656164537061726B2E6A617661) |; | •••••••• 84% | _new_ [...titute/hellbender/engine/spark/LocusWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2190/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F4C6F63757357616C6B6572537061726B2E6A617661,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2190#issuecomment-250756828:441,Message,Messages,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2190#issuecomment-250756828,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2194?src=pr) is 75.893% (diff: 0.000%). > Merging [#2194](https://codecov.io/gh/broadinstitute/gatk/pull/2194?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.003%**. ``` diff; @@ master #2194 diff @@; ==========================================; Files 711 711 ; Lines 38303 38300 -3 ; Methods 0 0 ; Messages 0 0 ; Branches 8058 8057 -1 ; ==========================================; - Hits 29068 29067 -1 ; + Misses 6765 6763 -2 ; Partials 2470 2470 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2194/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | 0% | [...bender/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2194/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F47656E6F747970696E67456E67696E652E6A617661) |; | •••••••••• 100% | [...genotyper/GenotypeCalculationArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2194/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F47656E6F7479706543616C63756C6174696F6E417267756D656E74436F6C6C656374696F6E2E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [cdc484c...a7af494](https://codecov.io/gh/broadinstitute/gatk/compare/cdc484cc8978b28421e1beeddc4eeb97f44dbafd...a7af494115524062df232c7b0cfb59e07124184e?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2194#issuecomment-250791184:435,Message,Messages,435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2194#issuecomment-250791184,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2205?src=pr) is 75.752% (diff: 100%); > Merging [#2205](https://codecov.io/gh/broadinstitute/gatk/pull/2205?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.013%**. ```diff; @@ master #2205 diff @@; ==========================================; Files 728 728 ; Lines 38433 38441 +8 ; Methods 0 0 ; Messages 0 0 ; Branches 8025 8026 +1 ; ==========================================; + Hits 29109 29120 +11 ; + Misses 6822 6820 -2 ; + Partials 2502 2501 -1 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2205/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | •••••••••• 100% | [...roadinstitute/hellbender/engine/ReadsDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2205/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F526561647344617461536F757263652E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [dd7e19a...8a7c17f](https://codecov.io/gh/broadinstitute/gatk/compare/dd7e19a58fece8d165f5f8d2d17f88ad3ddf2666...8a7c17fad0808d6a40a07b4734f083d82951f136?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2205#issuecomment-257956634:432,Message,Messages,432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2205#issuecomment-257956634,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2215?src=pr) is 75.903% (diff: 100%). > Merging [#2215](https://codecov.io/gh/broadinstitute/gatk/pull/2215?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.014%**. ``` diff; @@ master #2215 diff @@; ==========================================; Files 711 711 ; Lines 38303 38304 +1 ; Methods 0 0 ; Messages 0 0 ; Branches 8058 8058 ; ==========================================; + Hits 29068 29074 +6 ; + Misses 6765 6762 -3 ; + Partials 2470 2468 -2 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2215/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | •••••••••• 100% | [...ellbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2215/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F76617269616E742F4741544B56617269616E74436F6E746578745574696C732E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [cdc484c...d0ce3c9](https://codecov.io/gh/broadinstitute/gatk/compare/cdc484cc8978b28421e1beeddc4eeb97f44dbafd...d0ce3c966be8ba767c0da18c995c3be27b9af1d0?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2215#issuecomment-253694345:433,Message,Messages,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2215#issuecomment-253694345,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2218?src=pr) is 76.091% (diff: 98.734%); > Merging [#2218](https://codecov.io/gh/broadinstitute/gatk/pull/2218?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.004%**. ```diff; @@ master #2218 diff @@; ==========================================; Files 742 742 ; Lines 38819 38822 +3 ; Methods 0 0 ; Messages 0 0 ; Branches 8087 8091 +4 ; ==========================================; + Hits 29536 29540 +4 ; Misses 6719 6719 ; + Partials 2564 2563 -1 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2218/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | 0% | [...spark/sv/CallVariantsFromAlignedContigsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F43616C6C56617269616E747346726F6D416C69676E6564436F6E7469677353414D537061726B2E6A617661) |; | •••••••••• 100% | [...institute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F4741544B537061726B546F6F6C2E6A617661) |; | •••••••••• 100% | [...der/tools/walkers/genotyper/afcalc/AFCalculator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F616663616C632F414643616C63756C61746F722E6A617661) |; | •••••••••• 100% | [...lbender/tools/spark/pipelines/BQSRPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2218/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F706970656C696E65732F42515352506970656C696,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2218#issuecomment-254678913:435,Message,Messages,435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2218#issuecomment-254678913,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2220?src=pr) is 56.082% (diff: 76.119%). > Merging [#2220](https://codecov.io/gh/broadinstitute/gatk/pull/2220?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **45.285%**. ``` diff; @@ master #2220 diff @@; ==========================================; Files 719 717 -2 ; Lines 38566 38515 -51 ; Methods 0 0 ; Messages 0 0 ; Branches 8071 8070 -1 ; ==========================================; + Hits 4164 21600 +17436 ; + Misses 33820 14667 -19153 ; - Partials 582 2248 +1666 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2220/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | 0% | [...nsforms/bqsr/BaseRecalibratorEngineSparkWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/2220/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F7472616E73666F726D732F627173722F42617365526563616C69627261746F72456E67696E65537061726B577261707065722E6A617661) |; | 0% | [...ls/spark/sv/CallVariantsFromAlignedContigsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2220/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F43616C6C56617269616E747346726F6D416C69676E6564436F6E74696773537061726B2E6A617661) |; | 0% | [...ute/hellbender/tools/spark/sv/ContigsCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2220/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F436F6E74696773436F6C6C656374696F6E2E6A617661) |; | 0% | [...nder/engine/spark/datasources/VariantsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/2220/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F64617461,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2220#issuecomment-258497747:441,Message,Messages,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2220#issuecomment-258497747,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2224?src=pr) is 76.531% (diff: 72.500%). > Merging [#2224](https://codecov.io/gh/broadinstitute/gatk/pull/2224?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.640%**. ``` diff; @@ master #2224 diff @@; ==========================================; Files 711 711 ; Lines 38304 41305 +3001 ; Methods 0 0 ; Messages 0 0 ; Branches 8058 9401 +1343 ; ==========================================; + Hits 29069 31611 +2542 ; - Misses 6765 7086 +321 ; - Partials 2470 2608 +138 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2224/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | 0% | [.../org/broadinstitute/hellbender/utils/nio/NioBam.java](https://codecov.io/gh/broadinstitute/gatk/pull/2224/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F6E696F2F4E696F42616D2E6A617661) |; | 0% | [...oadinstitute/hellbender/utils/nio/ReadsIterable.java](https://codecov.io/gh/broadinstitute/gatk/pull/2224/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F6E696F2F52656164734974657261626C652E6A617661) |; | ••••••• 71% | [...collections/RequiredReadInputArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2224/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F617267756D656E74636F6C6C656374696F6E732F526571756972656452656164496E707574417267756D656E74436F6C6C656374696F6E2E6A617661) |; | ••••••• 71% | [...collections/OptionalReadInputArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2224/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F617267756D656E74636F6C6C656374696F6E732F4F7074696F6E616C52656164496E707574417267756D656,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2224#issuecomment-257041772:439,Message,Messages,439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2224#issuecomment-257041772,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2227?src=pr) is 75.906% (diff: 100%). > Merging [#2227](https://codecov.io/gh/broadinstitute/gatk/pull/2227?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.016%**. ``` diff; @@ master #2227 diff @@; ==========================================; Files 711 711 ; Lines 38304 38304 ; Methods 0 0 ; Messages 0 0 ; Branches 8058 8058 ; ==========================================; + Hits 29069 29075 +6 ; + Misses 6765 6762 -3 ; + Partials 2470 2467 -3 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2227/graphs/sunburst.svg?size=150&src=pr). > Powered by [Codecov](https://codecov.io?src=pr). Last update [13f88ae...7a4f692](https://codecov.io/gh/broadinstitute/gatk/compare/13f88aec9e10e76eb2445b7d2e430d33f24726ed...7a4f6927d2f4de11e24b2862a6223dd966ddc5c7?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2227#issuecomment-255795005:430,Message,Messages,430,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2227#issuecomment-255795005,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2228?src=pr) is 75.890% (diff: 100%). > Merging [#2228](https://codecov.io/gh/broadinstitute/gatk/pull/2228?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will not change coverage. ``` diff; @@ master #2228 diff @@; ==========================================; Files 711 711 ; Lines 38304 38304 ; Methods 0 0 ; Messages 0 0 ; Branches 8058 8058 ; ==========================================; Hits 29069 29069 ; Misses 6765 6765 ; Partials 2470 2470 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2228/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | •••••••••• 100% | [...picard/analysis/directed/RnaSeqMetricsCollector.java](https://codecov.io/gh/broadinstitute/gatk/pull/2228/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F7069636172642F616E616C797369732F64697265637465642F526E615365714D657472696373436F6C6C6563746F722E6A617661) |; | •••••••••• 100% | [...gealignment/BestEndMapqPrimaryAlignmentStrategy.java](https://codecov.io/gh/broadinstitute/gatk/pull/2228/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F726561642F6D65726765616C69676E6D656E742F42657374456E644D6170715072696D617279416C69676E6D656E7453747261746567792E6A617661) |; | •••••••••• 100% | [...nstitute/hellbender/tools/picard/sam/SamToFastq.java](https://codecov.io/gh/broadinstitute/gatk/pull/2228/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F7069636172642F73616D2F53616D546F46617374712E6A617661) |; | •••••••••• 100% | [...a/org/broadinstitute/hellbender/utils/GenomeLoc.java](https://codecov.io/gh/broadinstitute/gatk/pull/2228/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F47656E6F6D654C6F632E6A617661,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2228#issuecomment-255478068:418,Message,Messages,418,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2228#issuecomment-255478068,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2234?src=pr) is 56.038% (diff: 0.000%). > Merging [#2234](https://codecov.io/gh/broadinstitute/gatk/pull/2234?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.060%**. ``` diff; @@ master #2234 diff @@; ==========================================; Files 717 718 +1 ; Lines 38536 38579 +43 ; Methods 0 0 ; Messages 0 0 ; Branches 8073 8081 +8 ; ==========================================; + Hits 21618 21619 +1 ; - Misses 14670 14712 +42 ; Partials 2248 2248 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2234/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | 0% | _new_ [...alkers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/2234/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F76617269616E747574696C732F55706461746556434653657175656E636544696374696F6E6172792E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [5e17764...3107aa4](https://codecov.io/gh/broadinstitute/gatk/compare/5e17764f74fdf110d4ea09cc0b5508fbad9a1305...3107aa4310a538a66b41ddf19528787714a86a03?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2234#issuecomment-259310243:439,Message,Messages,439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2234#issuecomment-259310243,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2235?src=pr) is 76.323% (diff: 95.082%). > Merging [#2235](https://codecov.io/gh/broadinstitute/gatk/pull/2235?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.431%**. ``` diff; @@ master #2235 diff @@; ==========================================; Files 711 711 ; Lines 38306 39012 +706 ; Methods 0 0 ; Messages 0 0 ; Branches 8058 8278 +220 ; ==========================================; + Hits 29071 29775 +704 ; + Misses 6765 6744 -21 ; - Partials 2470 2493 +23 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2235/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | 0% | [...er/tools/walkers/variantutils/FamilyLikelihoods.java](https://codecov.io/gh/broadinstitute/gatk/pull/2235/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F76617269616E747574696C732F46616D696C794C696B656C69686F6F64732E6A617661) |; | •••••••• 83% | [...a/org/broadinstitute/hellbender/utils/MathUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2235/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F4D6174685574696C732E6A617661) |; | •••••••••• 100% | [...kers/genotyper/afcalc/AlleleFrequencyCalculator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2235/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F616663616C632F416C6C656C654672657175656E637943616C63756C61746F722E6A617661) |; | •••••••••• 100% | [...r/tools/walkers/genotyper/AlleleSubsettingUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2235/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F416C6C656C655375,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2235#issuecomment-256761095:438,Message,Messages,438,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2235#issuecomment-256761095,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2237?src=pr) is 76.001% (diff: 74.298%). > Merging [#2237](https://codecov.io/gh/broadinstitute/gatk/pull/2237?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.076%**. ``` diff; @@ master #2237 diff @@; ==========================================; Files 719 732 +13 ; Lines 38560 38926 +366 ; Methods 0 0 ; Messages 0 0 ; Branches 8071 8136 +65 ; ==========================================; + Hits 29335 29584 +249 ; - Misses 6735 6837 +102 ; - Partials 2490 2505 +15 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2237/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | 0% | _new_ [...der/tools/spark/utils/ReadTransformerSparkifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/2237/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F7574696C732F526561645472616E73666F726D6572537061726B69666965722E6A617661) |; | 0% | _new_ [...llbender/tools/spark/utils/ReadFilterSparkifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/2237/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F7574696C732F5265616446696C746572537061726B69666965722E6A617661) |; | 0% | _new_ [...llbender/tools/spark/pathseq/PathSeqFilterSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2237/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F706174687365712F5061746853657146696C746572537061726B2E6A617661) |; | •• 20% | [.../hellbender/engine/filters/ReadLengthReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2237/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F66696C746572732F526561644C656E6774685265616446696C74,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2237#issuecomment-256969944:442,Message,Messages,442,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2237#issuecomment-256969944,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2239?src=pr) is 75.932% (diff: 87.500%). > Merging [#2239](https://codecov.io/gh/broadinstitute/gatk/pull/2239?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.003%**. ``` diff; @@ master #2239 diff @@; ==========================================; Files 712 712 ; Lines 38201 38204 +3 ; Methods 0 0 ; Messages 0 0 ; Branches 8019 8018 -1 ; ==========================================; + Hits 29008 29009 +1 ; - Misses 6720 6722 +2 ; Partials 2473 2473 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2239/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | ••••••• 75% | [...bender/tools/walkers/annotator/DepthPerSampleHC.java](https://codecov.io/gh/broadinstitute/gatk/pull/2239/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F446570746850657253616D706C6548432E6A617661) |; | •••••••••• 100% | [.../tools/walkers/annotator/DepthPerAlleleBySample.java](https://codecov.io/gh/broadinstitute/gatk/pull/2239/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F4465707468506572416C6C656C65427953616D706C652E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [028c361...9f7c142](https://codecov.io/gh/broadinstitute/gatk/compare/028c3610f7414279f454c6bb2c1404d5d6ca0403...9f7c14286c7abfc63eebb85961199359cd5db21f?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2239#issuecomment-257505571:436,Message,Messages,436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2239#issuecomment-257505571,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2242?src=pr) is 75.938% (diff: 35.714%). > Merging [#2242](https://codecov.io/gh/broadinstitute/gatk/pull/2242?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **65.051%**. ``` diff; @@ master #2242 diff @@; ==========================================; Files 712 712 ; Lines 38211 38214 +3 ; Methods 0 0 ; Messages 0 0 ; Branches 8019 8022 +3 ; ==========================================; + Hits 4160 29019 +24859 ; + Misses 33469 6721 -26748 ; - Partials 582 2474 +1892 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2242/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; | --- | --- |; | ••• 35% | [...llbender/engine/datasources/ReferenceFileSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2242/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F64617461736F75726365732F5265666572656E636546696C65536F757263652E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [bc8318e...40072ed](https://codecov.io/gh/broadinstitute/gatk/compare/bc8318e1086f0ea9a6b67f0f658725baae6f0e90...40072ed1e8326e4698b2c6d0a06d3340ee298539?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2242#issuecomment-257627160:437,Message,Messages,437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2242#issuecomment-257627160,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2256?src=pr) is 75.861% (diff: 84.830%); > Merging [#2256](https://codecov.io/gh/broadinstitute/gatk/pull/2256?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.159%**. ```diff; @@ master #2256 diff @@; ==========================================; Files 729 742 +13 ; Lines 38506 38954 +448 ; Methods 0 0 ; Messages 0 0 ; Branches 8039 8123 +84 ; ==========================================; + Hits 29150 29551 +401 ; - Misses 6848 6858 +10 ; - Partials 2508 2545 +37 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2256/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | ••• 33% | [...er/engine/spark/datasources/VariantsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2256/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F64617461736F75726365732F56617269616E7473537061726B536F757263652E6A617661) |; | ••••••• 72% | *new* [...tute/hellbender/engine/spark/VariantWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2256/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F56617269616E7457616C6B6572537061726B2E6A617661) |; | ••••••• 74% | *new* [...bender/tools/examples/ExampleVariantWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2256/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F6578616D706C65732F4578616D706C6556617269616E7457616C6B6572537061726B2E6A617661) |; | ••••••• 75% | *new* [...ute/hellbender/engine/spark/IntervalWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2256/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F496E74657276616C57616C6B65,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2256#issuecomment-259098722:441,Message,Messages,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2256#issuecomment-259098722,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2258?src=pr) is 75.976% (diff: 48.896%); > Merging [#2258](https://codecov.io/gh/broadinstitute/gatk/pull/2258?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **19.894%**. ```diff; @@ master #2258 diff @@; ==========================================; Files 717 734 +17 ; Lines 38515 39614 +1099 ; Methods 0 0 ; Messages 0 0 ; Branches 8070 8354 +284 ; ==========================================; + Hits 21600 30097 +8497 ; + Misses 14667 6969 -7698 ; - Partials 2248 2548 +300 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2258/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | 0% | [...spark/sv/CallVariantsFromAlignedContigsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2258/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F43616C6C56617269616E747346726F6D416C69676E6564436F6E7469677353414D537061726B2E6A617661) |; | 0% | [...ls/spark/sv/CallVariantsFromAlignedContigsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2258/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F43616C6C56617269616E747346726F6D416C69676E6564436F6E74696773537061726B2E6A617661) |; | 0% | *new* [...institute/hellbender/tools/spark/sv/SVVCFWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2258/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F53565643465772697465722E6A617661) |; | •••• 40% | *new* [...ute/hellbender/tools/spark/sv/ChimericAlignment.java](https://codecov.io/gh/broadinstitute/gatk/pull/2258/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F4368696D6572696341,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2258#issuecomment-259324427:443,Message,Messages,443,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2258#issuecomment-259324427,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2259?src=pr) is 75.907% (diff: 37.500%); > Merging [#2259](https://codecov.io/gh/broadinstitute/gatk/pull/2259?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.026%**. ```diff; @@ master #2259 diff @@; ==========================================; Files 731 731 ; Lines 38966 38994 +28 ; Methods 0 0 ; Messages 0 0 ; Branches 8151 8154 +3 ; ==========================================; + Hits 29588 29599 +11 ; - Misses 6855 6870 +15 ; - Partials 2523 2525 +2 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2259/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | •• 22% | [...broadinstitute/hellbender/utils/pairhmm/PairHMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/2259/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F70616972686D6D2F50616972484D4D2E6A617661) |; | •••••• 64% | [...e/hellbender/utils/pairhmm/VectorLoglessPairHMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/2259/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F70616972686D6D2F566563746F724C6F676C65737350616972484D4D2E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [7679749...558160e](https://codecov.io/gh/broadinstitute/gatk/compare/767974906e91c90079cefa4512b463138ca09f68...558160ea5bfde8be3b6e4bdd5283c529fb905fca?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2259#issuecomment-261320519:436,Message,Messages,436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2259#issuecomment-261320519,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2262?src=pr) is 76.058% (diff: 100%). > Merging [#2262](https://codecov.io/gh/broadinstitute/gatk/pull/2262?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **20.023%**. ``` diff; @@ master #2262 diff @@; ==========================================; Files 718 718 ; Lines 38581 38581 ; Methods 0 0 ; Messages 0 0 ; Branches 8081 8081 ; ==========================================; + Hits 21619 29344 +7725 ; + Misses 14714 6743 -7971 ; - Partials 2248 2494 +246 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2262/graphs/sunburst.svg?size=150&src=pr). > Powered by [Codecov](https://codecov.io?src=pr). Last update [bd8f1cb...e0d7613](https://codecov.io/gh/broadinstitute/gatk/compare/bd8f1cbc92b061132e1dc7332cc0f67e84044fee...e0d761361fb9deb1b0b02cd995b02f6fea37b3e9?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2262#issuecomment-260673866:431,Message,Messages,431,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2262#issuecomment-260673866,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2263?src=pr) is 56.035% (diff: 100%). > Merging [#2263](https://codecov.io/gh/broadinstitute/gatk/pull/2263?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will not change coverage. ``` diff; @@ master #2263 diff @@; ==========================================; Files 718 718 ; Lines 38581 38581 ; Methods 0 0 ; Messages 0 0 ; Branches 8081 8081 ; ==========================================; Hits 21619 21619 ; Misses 14714 14714 ; Partials 2248 2248 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2263/graphs/sunburst.svg?size=150&src=pr). > Powered by [Codecov](https://codecov.io?src=pr). Last update [bd8f1cb...fb5f66b](https://codecov.io/gh/broadinstitute/gatk/compare/bd8f1cbc92b061132e1dc7332cc0f67e84044fee...fb5f66bd59c692950cf2c2a588685dd60888f10b?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2263#issuecomment-260673945:418,Message,Messages,418,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2263#issuecomment-260673945,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2264?src=pr) is 56.035% (diff: 100%). > Merging [#2264](https://codecov.io/gh/broadinstitute/gatk/pull/2264?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will not change coverage. ``` diff; @@ master #2264 diff @@; ==========================================; Files 718 718 ; Lines 38581 38581 ; Methods 0 0 ; Messages 0 0 ; Branches 8081 8081 ; ==========================================; Hits 21619 21619 ; Misses 14714 14714 ; Partials 2248 2248 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2264/graphs/sunburst.svg?src=pr&size=150). > Powered by [Codecov](https://codecov.io?src=pr). Last update [bd8f1cb...6d8ef09](https://codecov.io/gh/broadinstitute/gatk/compare/bd8f1cbc92b061132e1dc7332cc0f67e84044fee...6d8ef0980f0294a65354d6376bdea2d44ff3aed0?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2264#issuecomment-260674364:418,Message,Messages,418,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2264#issuecomment-260674364,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2271?src=pr) is 76.024% (diff: 75.000%). > Merging [#2271](https://codecov.io/gh/broadinstitute/gatk/pull/2271?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.028%**. ``` diff; @@ master #2271 diff @@; ==========================================; Files 731 731 ; Lines 38948 39102 +154 ; Methods 0 0 ; Messages 0 0 ; Branches 8146 8177 +31 ; ==========================================; + Hits 29599 29727 +128 ; - Misses 6840 6865 +25 ; - Partials 2509 2510 +1 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2271/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; | --- | --- |; | ••••••• 75% | [...rg/broadinstitute/hellbender/utils/LoggingUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2271/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F4C6F6767696E675574696C732E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [a9e304f...e0bd30d](https://codecov.io/gh/broadinstitute/gatk/compare/a9e304fd7dd2ad854c2115f23eb507eb6c502324...e0bd30d79bf2b0831e731bc74c35c7796708c5bb?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2271#issuecomment-261380512:438,Message,Messages,438,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2271#issuecomment-261380512,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2272?src=pr) is 75.941% (diff: 100%); > Merging [#2272](https://codecov.io/gh/broadinstitute/gatk/pull/2272?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.008%**. ```diff; @@ master #2272 diff @@; ==========================================; Files 731 731 ; Lines 38966 38966 ; Methods 0 0 ; Messages 0 0 ; Branches 8151 8151 ; ==========================================; + Hits 29588 29591 +3 ; + Misses 6855 6852 -3 ; Partials 2523 2523 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2272/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | •••••••••• 100% | [...stitute/hellbender/engine/spark/GATKRegistrator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2272/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F4741544B5265676973747261746F722E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [7679749...60902e5](https://codecov.io/gh/broadinstitute/gatk/compare/767974906e91c90079cefa4512b463138ca09f68...60902e55e33ebca62d204b7b5f808293e204e7f2?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2272#issuecomment-261381856:429,Message,Messages,429,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2272#issuecomment-261381856,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2275?src=pr) is 75.937% (diff: 100%); > Merging [#2275](https://codecov.io/gh/broadinstitute/gatk/pull/2275?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.066%**. ```diff; @@ master #2275 diff @@; ==========================================; Files 731 731 ; Lines 38956 38961 +5 ; Methods 0 0 ; Messages 0 0 ; Branches 8147 8149 +2 ; ==========================================; - Hits 29608 29586 -22 ; - Misses 6838 6853 +15 ; - Partials 2510 2522 +12 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2275/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; |---|---|; | •••••••••• 100% | [...dinstitute/hellbender/cmdline/CommandLineParser.java](https://codecov.io/gh/broadinstitute/gatk/pull/2275/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F436F6D6D616E644C696E655061727365722E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [4d29cf7...9c8ec35](https://codecov.io/gh/broadinstitute/gatk/compare/4d29cf7a9e1d6c9ee936303d452aa2ca92febae0...9c8ec352770b67bd2cfd9203a86253b088875ed3?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2275#issuecomment-262073323:432,Message,Messages,432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2275#issuecomment-262073323,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2279?src=pr) is 76.012% (diff: 100%); > Merging [#2279](https://codecov.io/gh/broadinstitute/gatk/pull/2279?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.008%**. ```diff; @@ master #2279 diff @@; ==========================================; Files 731 731 ; Lines 38948 39094 +146 ; Methods 0 0 ; Messages 0 0 ; Branches 8146 8176 +30 ; ==========================================; + Hits 29602 29716 +114 ; - Misses 6837 6867 +30 ; - Partials 2509 2511 +2 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2279/graphs/sunburst.svg?size=150&src=pr). > Powered by [Codecov](https://codecov.io?src=pr). Last update [4a844f0...c606f66](https://codecov.io/gh/broadinstitute/gatk/compare/4a844f03a080e68ccb2fd0bc0987f56fa2b7e6ed...c606f6695338bc38b01221760f26596ffe9a7fba?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2279#issuecomment-262013440:434,Message,Messages,434,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2279#issuecomment-262013440,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2285?src=pr) is 56.143% (diff: 41.199%); > Merging [#2285](https://codecov.io/gh/broadinstitute/gatk/pull/2285?src=pr) into [sh_rewind_refactor](https://codecov.io/gh/broadinstitute/gatk/branch/sh_rewind_refactor?src=pr) will increase coverage by **0.098%**. ```diff; @@ sh_rewind_refactor #2285 diff @@; ====================================================; Files 722 723 +1 ; Lines 38556 38651 +95 ; Methods 0 0 ; Messages 0 0 ; Branches 8072 8105 +33 ; ====================================================; + Hits 21609 21700 +91 ; + Misses 14708 14701 -7 ; - Partials 2239 2250 +11 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2285/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | 0% | [...ls/spark/sv/CallVariantsFromAlignedContigsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F43616C6C56617269616E747346726F6D416C69676E6564436F6E74696773537061726B2E6A617661) |; | 0% | [.../hellbender/tools/spark/sv/GATKSVVCFHeaderLines.java](https://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F4741544B53565643464865616465724C696E65732E6A617661) |; | 0% | *new* [...ellbender/tools/spark/sv/SVVariantConsensusCall.java](https://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F535656617269616E74436F6E73656E73757343616C6C2E6A617661) |; | •••• 45% | [...itute/hellbender/tools/spark/sv/AlignmentRegion.java](https://codecov.io/gh/broadinstitute/gatk/pull/2285/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2285#issuecomment-263705162:485,Message,Messages,485,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2285#issuecomment-263705162,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2286?src=pr) is 75.922% (diff: 100%); > Merging [#2286](https://codecov.io/gh/broadinstitute/gatk/pull/2286?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **65.200%**. ```diff; @@ master #2286 diff @@; ==========================================; Files 731 731 ; Lines 38994 38994 ; Methods 0 0 ; Messages 0 0 ; Branches 8154 8154 ; ==========================================; + Hits 4181 29605 +25424 ; + Misses 34231 6866 -27365 ; - Partials 582 2523 +1941 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2286/graphs/sunburst.svg?src=pr&size=150). > Powered by [Codecov](https://codecov.io?src=pr). Last update [625ed04...5abaa38](https://codecov.io/gh/broadinstitute/gatk/compare/625ed042b6c6f4d9609e15064b494aa4bbd74f70...5abaa38b0a61d03626d57d625d459c259b1606a6?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2286#issuecomment-265002678:430,Message,Messages,430,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2286#issuecomment-265002678,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2293?src=pr) is 75.740% (diff: 56.410%); > Merging [#2293](https://codecov.io/gh/broadinstitute/gatk/pull/2293?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.164%**. ```diff; @@ master #2293 diff @@; ==========================================; Files 731 728 -3 ; Lines 38994 38433 -561 ; Methods 0 0 ; Messages 0 0 ; Branches 8154 8025 -129 ; ==========================================; - Hits 29598 29109 -489 ; + Misses 6871 6822 -49 ; + Partials 2525 2502 -23 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2293/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | 0% | [...llbender/tools/walkers/vqsr/VariantRecalibrator.java](https://codecov.io/gh/broadinstitute/gatk/pull/2293/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F767173722F56617269616E74526563616C69627261746F722E6A617661) |; | 0% | [...rg/broadinstitute/hellbender/engine/LocusWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2293/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4C6F63757357616C6B65722E6A617661) |; | 0% | [...lbender/tools/walkers/filters/VariantFiltration.java](https://codecov.io/gh/broadinstitute/gatk/pull/2293/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F66696C746572732F56617269616E7446696C74726174696F6E2E6A617661) |; | 0% | [...bender/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2293/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F47656E6F747970696E67456E67696E652E6A617661) |; | 0% | [...nstitute/hellbender/engine/AssemblyR,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2293#issuecomment-265198632:440,Message,Messages,440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2293#issuecomment-265198632,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2305?src=pr) is 75.702% (diff: 95.652%); > Merging [#2305](https://codecov.io/gh/broadinstitute/gatk/pull/2305?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.036%**. ```diff; @@ master #2305 diff @@; ==========================================; Files 728 728 ; Lines 38435 38451 +16 ; Methods 0 0 ; Messages 0 0 ; Branches 8024 8027 +3 ; ==========================================; + Hits 29082 29108 +26 ; + Misses 6854 6840 -14 ; - Partials 2499 2503 +4 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2305/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; |---|---|; | •••••• 66% | [...argumentcollections/ReadInputArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2305/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F617267756D656E74636F6C6C656374696F6E732F52656164496E707574417267756D656E74436F6C6C656374696F6E2E6A617661) |; | •••••••••• 100% | [...a/org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/2305/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4741544B546F6F6C2E6A617661) |; | •••••••••• 100% | [...collections/OptionalReadInputArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/2305/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F617267756D656E74636F6C6C656374696F6E732F4F7074696F6E616C52656164496E707574417267756D656E74436F6C6C656374696F6E2E6A617661) |; | •••••••••• 100% | [...roadinstitute/hellbender/engine/ReadsDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2305/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F5265616473446,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2305#issuecomment-265868366:436,Message,Messages,436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2305#issuecomment-265868366,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2306?src=pr) is 75.760% (diff: 89.744%); > Merging [#2306](https://codecov.io/gh/broadinstitute/gatk/pull/2306?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.058%**. ```diff; @@ master #2306 diff @@; ==========================================; Files 728 729 +1 ; Lines 38451 38622 +171 ; Methods 0 0 ; Messages 0 0 ; Branches 8027 8073 +46 ; ==========================================; + Hits 29108 29260 +152 ; - Misses 6840 6847 +7 ; - Partials 2503 2515 +12 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2306/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | •••••••• 89% | [...lbender/engine/spark/datasources/ReadsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/2306/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F64617461736F75726365732F5265616473537061726B53696E6B2E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [ffc26bb...3381f1c](https://codecov.io/gh/broadinstitute/gatk/compare/ffc26bbb4d89d995396ff7b025a798daf1061c9d...3381f1c44a38f48a3a3d56358e41c57c3ef7396e?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-266849166:440,Message,Messages,440,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-266849166,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2307?src=pr) is 75.698% (diff: 80.000%); > Merging [#2307](https://codecov.io/gh/broadinstitute/gatk/pull/2307?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.008%**. ```diff; @@ master #2307 diff @@; ==========================================; Files 729 729 ; Lines 38515 38503 -12 ; Methods 0 0 ; Messages 0 0 ; Branches 8040 8039 -1 ; ==========================================; - Hits 29158 29146 -12 ; Misses 6849 6849 ; Partials 2508 2508 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2307/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | •••••••• 80% | [...broadinstitute/hellbender/utils/FisherExactTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2307/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F4669736865724578616374546573742E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [2e5a15a...3348b9e](https://codecov.io/gh/broadinstitute/gatk/compare/2e5a15ac4bc9774e853abb6d26c2acb60f2f9c20...3348b9ee3f9d12a2c6898f344ffa1c290f439f17?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-266028932:436,Message,Messages,436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2307#issuecomment-266028932,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2318?src=pr) is 75.706% (diff: 100%); > Merging [#2318](https://codecov.io/gh/broadinstitute/gatk/pull/2318?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.003%**. ```diff; @@ master #2318 diff @@; ==========================================; Files 729 729 ; Lines 38506 38507 +1 ; Methods 0 0 ; Messages 0 0 ; Branches 8039 8039 ; ==========================================; + Hits 29150 29152 +2 ; Misses 6848 6848 ; + Partials 2508 2507 -1 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2318/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | •••••••••• 100% | [...nder/tools/walkers/annotator/ReadPosRankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2318/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F52656164506F7352616E6B53756D546573742E6A617661) |; | •••••••••• 100% | [.../hellbender/tools/walkers/annotator/RankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2318/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F52616E6B53756D546573742E6A617661) |; | •••••••••• 100% | [.../annotator/allelespecific/AS_ReadPosRankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/2318/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F616E6E6F7461746F722F616C6C656C6573706563696669632F41535F52656164506F7352616E6B53756D546573742E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [e1b4c8f...9a3e91c](https://codecov.io/gh/broadinstitute/gatk/compare/e1b4c8f4b781c6867e1eaea2dbb5587c6a6125a7...9a3e91c78ca9b0ce5f0da22a3cebd7199f255ff0?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2318#issuecomment-267388046:432,Message,Messages,432,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2318#issuecomment-267388046,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2320?src=pr) is 75.644% (diff: 70.923%); > Merging [#2320](https://codecov.io/gh/broadinstitute/gatk/pull/2320?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.494%**. ```diff; @@ master #2320 diff @@; ==========================================; Files 743 723 -20 ; Lines 38991 38841 -150 ; Methods 0 0 ; Messages 0 0 ; Branches 8120 8136 +16 ; ==========================================; - Hits 29687 29381 -306 ; - Misses 6734 6929 +195 ; + Partials 2570 2531 -39 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2320/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | 0% | [.../hellbender/tools/spark/sv/GATKSVVCFHeaderLines.java](https://codecov.io/gh/broadinstitute/gatk/pull/2320/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F4741544B53565643464865616465724C696E65732E6A617661) |; | 0% | [...spark/sv/CallVariantsFromAlignedContigsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2320/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F43616C6C56617269616E747346726F6D416C69676E6564436F6E7469677353414D537061726B2E6A617661) |; | 0% | [...er/utils/read/mergealignment/SamAlignmentMerger.java](https://codecov.io/gh/broadinstitute/gatk/pull/2320/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F726561642F6D65726765616C69676E6D656E742F53616D416C69676E6D656E744D65726765722E6A617661) |; | 0% | *new* [...institute/hellbender/tools/spark/sv/SVVCFWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2320/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F53565643465772697465722E6A61766,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2320#issuecomment-267857623:441,Message,Messages,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2320#issuecomment-267857623,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2323?src=pr) is 76.172% (diff: 100%); > Merging [#2323](https://codecov.io/gh/broadinstitute/gatk/pull/2323?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **65.997%**. ```diff; @@ master #2323 diff @@; ==========================================; Files 743 743 ; Lines 38960 38958 -2 ; Methods 0 0 ; Messages 0 0 ; Branches 8114 8114 ; ==========================================; + Hits 3964 29675 +25711 ; + Misses 34451 6711 -27740 ; - Partials 545 2572 +2027 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2323/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | •••••••••• 100% | [...lbender/tools/walkers/filters/VariantFiltration.java](https://codecov.io/gh/broadinstitute/gatk/pull/2323/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F66696C746572732F56617269616E7446696C74726174696F6E2E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [cf77bda...4a1a5e4](https://codecov.io/gh/broadinstitute/gatk/compare/cf77bdade1dfc64d5ae1d487dfe974508fa68b1f...4a1a5e4f9e909019226ac53ba1ab9d030a0c5463?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2323#issuecomment-268516777:433,Message,Messages,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2323#issuecomment-268516777,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2325?src=pr) is 76.365% (diff: 90.845%); > Merging [#2325](https://codecov.io/gh/broadinstitute/gatk/pull/2325?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.625%**. ```diff; @@ master #2325 diff @@; ==========================================; Files 729 743 +14 ; Lines 38479 40288 +1809 ; Methods 0 0 ; Messages 0 0 ; Branches 8036 8510 +474 ; ==========================================; + Hits 29144 30766 +1622 ; - Misses 6830 6887 +57 ; - Partials 2505 2635 +130 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2325/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; |---|---|; | ••••••••• 90% | [...oadinstitute/hellbender/utils/pileup/ReadPileup.java](https://codecov.io/gh/broadinstitute/gatk/pull/2325/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F70696C6575702F5265616450696C6575702E6A617661) |; | ••••••••• 90% | *new* [.../hellbender/tools/walkers/rnaseq/ASEReadCounter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2325/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F726E617365712F41534552656164436F756E7465722E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [3eff9c1...d5f64bc](https://codecov.io/gh/broadinstitute/gatk/compare/3eff9c131f78bb80f55d1b27f7554d3b035af931...d5f64bceb32ac10ce42b09f6ff377cad0e446ced?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2325#issuecomment-268811473:442,Message,Messages,442,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2325#issuecomment-268811473,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2326?src=pr) is 76.019% (diff: 86.111%); > Merging [#2326](https://codecov.io/gh/broadinstitute/gatk/pull/2326?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.279%**. ```diff; @@ master #2326 diff @@; ==========================================; Files 729 729 ; Lines 38479 38505 +26 ; Methods 0 0 ; Messages 0 0 ; Branches 8036 8045 +9 ; ==========================================; + Hits 29144 29271 +127 ; + Misses 6830 6703 -127 ; - Partials 2505 2531 +26 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2326/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | •••••••• 86% | [...bender/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/2326/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F67656E6F74797065722F47656E6F747970696E67456E67696E652E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [3eff9c1...f3d1e15](https://codecov.io/gh/broadinstitute/gatk/compare/3eff9c131f78bb80f55d1b27f7554d3b035af931...f3d1e158ca9dbf071e83a293e4e52bcae2be38c9?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2326#issuecomment-268849703:436,Message,Messages,436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2326#issuecomment-268849703,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2330?src=pr) is 76.012% (diff: 88.235%); > Merging [#2330](https://codecov.io/gh/broadinstitute/gatk/pull/2330?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.006%**. ```diff; @@ master #2330 diff @@; ==========================================; Files 729 729 ; Lines 38505 38506 +1 ; Methods 0 0 ; Messages 0 0 ; Branches 8045 8045 ; ==========================================; + Hits 29266 29269 +3 ; + Misses 6706 6704 -2 ; Partials 2533 2533 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2330/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | ••••• 50% | [...ools/spark/sv/SVKmerizerWithLowComplexityFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2330/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F53564B6D6572697A6572576974684C6F77436F6D706C657869747946696C7465722E6A617661) |; | •••••••••• 100% | [.../broadinstitute/hellbender/engine/FeatureWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2330/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4665617475726557616C6B65722E6A617661) |; | •••••••••• 100% | [...org/broadinstitute/hellbender/engine/ReadWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2330/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F5265616457616C6B65722E6A617661) |; | •••••••••• 100% | [...dinstitute/hellbender/tools/spark/sv/SVKmerizer.java](https://codecov.io/gh/broadinstitute/gatk/pull/2330/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F53564B6D6572697A65722E6A617661) |; | •••••••••• 100% | [...lbender/tools/spark/transforms/ApplyBQSRSparkF,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2330#issuecomment-270462994:435,Message,Messages,435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2330#issuecomment-270462994,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2331?src=pr) is 76.116% (diff: 72.222%); > Merging [#2331](https://codecov.io/gh/broadinstitute/gatk/pull/2331?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.023%**. ```diff; @@ master #2331 diff @@; ==========================================; Files 743 744 +1 ; Lines 38991 39038 +47 ; Methods 0 0 ; Messages 0 0 ; Branches 8120 8130 +10 ; ==========================================; + Hits 29687 29714 +27 ; - Misses 6734 6749 +15 ; - Partials 2570 2575 +5 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2331/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | •••••• 66% | [...a/org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/2331/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4741544B546F6F6C2E6A617661) |; | •••••• 68% | [...roadinstitute/hellbender/engine/ReadsDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/2331/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F526561647344617461536F757263652E6A617661) |; | ••••••• 73% | *new* [...broadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/2331/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F746573742F586F72577261707065722E6A617661) |; | •••••••••• 100% | [.../hellbender/cmdline/StandardArgumentDefinitions.java](https://codecov.io/gh/broadinstitute/gatk/pull/2331/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F5374616E64617264417267756D656E74446566696E6974696F6E732E6A617661) |; | •••••••••• 100% | [...lbender/utils/nio/SeekableByteChannelPrefetcher.java](https://codec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2331#issuecomment-271027025:439,Message,Messages,439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2331#issuecomment-271027025,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2339?src=pr) is 76.230% (diff: 100%); > Merging [#2339](https://codecov.io/gh/broadinstitute/gatk/pull/2339?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **66.055%**. ```diff; @@ master #2339 diff @@; ==========================================; Files 743 743 ; Lines 38960 39112 +152 ; Methods 0 0 ; Messages 0 0 ; Branches 8114 8193 +79 ; ==========================================; + Hits 3964 29815 +25851 ; + Misses 34451 6719 -27732 ; - Partials 545 2578 +2033 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2339/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | •••••••••• 100% | [...oadinstitute/hellbender/utils/pileup/ReadPileup.java](https://codecov.io/gh/broadinstitute/gatk/pull/2339/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F7574696C732F70696C6575702F5265616450696C6575702E6A617661) |; | •••••••••• 100% | [.../hellbender/tools/walkers/rnaseq/ASEReadCounter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2339/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F77616C6B6572732F726E617365712F41534552656164436F756E7465722E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [cf77bda...d0c671e](https://codecov.io/gh/broadinstitute/gatk/compare/cf77bdade1dfc64d5ae1d487dfe974508fa68b1f...d0c671e931c010f240af5c3a822af19052545b11?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2339#issuecomment-274917279:435,Message,Messages,435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2339#issuecomment-274917279,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2340?src=pr) is 76.190% (diff: 56.098%); > Merging [#2340](https://codecov.io/gh/broadinstitute/gatk/pull/2340?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **66.015%**. ```diff; @@ master #2340 diff @@; ==========================================; Files 743 751 +8 ; Lines 38960 40319 +1359 ; Methods 0 0 ; Messages 0 0 ; Branches 8114 8477 +363 ; ==========================================; + Hits 3964 30719 +26755 ; + Misses 34451 6955 -27496 ; - Partials 545 2645 +2100 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2340/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | • 10% | [...rc/main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/2340/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F4D61696E2E6A617661) |; | •••••••••• 100% | [...institute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/2340/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F737061726B2F4741544B537061726B546F6F6C2E6A617661) |; | •••••••••• 100% | [...institute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/2340/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F636D646C696E652F436F6D6D616E644C696E6550726F6772616D2E6A617661) |; | •••••••••• 100% | [...a/org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/2340/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4741544B546F6F6C2E6A617661) |; | •••••••••• 100% | [...adinstitute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/pull/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2340#issuecomment-275000241:442,Message,Messages,442,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2340#issuecomment-275000241,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2342?src=pr) is 76.191% (diff: 100%); > Merging [#2342](https://codecov.io/gh/broadinstitute/gatk/pull/2342?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will increase coverage by **0.001%**. ```diff; @@ master #2342 diff @@; ==========================================; Files 743 743 ; Lines 38962 38972 +10 ; Methods 0 0 ; Messages 0 0 ; Branches 8113 8118 +5 ; ==========================================; + Hits 29685 29693 +8 ; - Misses 6708 6710 +2 ; Partials 2569 2569 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2342/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; |---|---|; | •••••••••• 100% | [...lbender/engine/filters/MappingQualityReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/2342/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F66696C746572732F4D617070696E675175616C6974795265616446696C7465722E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [29569a9...51e6426](https://codecov.io/gh/broadinstitute/gatk/compare/29569a9ffae87623e3eeffaae3effc965c8307a7...51e64264cb8ae0ce96b446eec9eea5e9c721a870?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2342#issuecomment-272990133:433,Message,Messages,433,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2342#issuecomment-272990133,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2348?src=pr) is 76.138% (diff: 67.133%); > Merging [#2348](https://codecov.io/gh/broadinstitute/gatk/pull/2348?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.037%**. ```diff; @@ master #2348 diff @@; ==========================================; Files 743 743 ; Lines 38960 38991 +31 ; Methods 0 0 ; Messages 0 0 ; Branches 8113 8120 +7 ; ==========================================; + Hits 29678 29687 +9 ; - Misses 6711 6734 +23 ; + Partials 2571 2570 -1 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2348/graphs/sunburst.svg?size=150&src=pr). | Diff Coverage | File Path |; |---|---|; | ••••• 50% | [...roadinstitute/hellbender/tools/spark/sv/SVUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/2348/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F53565574696C732E6A617661) |; | ••••• 50% | [...institute/hellbender/tools/spark/sv/SVKmerShort.java](https://codecov.io/gh/broadinstitute/gatk/pull/2348/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F53564B6D657253686F72742E6A617661) |; | ••••• 50% | [...dinstitute/hellbender/tools/spark/sv/SVKmerizer.java](https://codecov.io/gh/broadinstitute/gatk/pull/2348/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F53564B6D6572697A65722E6A617661) |; | ••••• 55% | [...lbender/tools/spark/sv/FindBadGenomicKmersSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/2348/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F737061726B2F73762F46696E6442616447656E6F6D69634B6D657273537061726B2E6A617661) |; | ••••••• 71% | [...nder/tools/spark/sv/FindBreakpointEvidenceSpark.java](,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2348#issuecomment-273320758:436,Message,Messages,436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2348#issuecomment-273320758,1,['Message'],['Messages']
Integrability,## [Current coverage](https://codecov.io/gh/broadinstitute/gatk/pull/2374?src=pr) is 76.232% (diff: 0.000%); > Merging [#2374](https://codecov.io/gh/broadinstitute/gatk/pull/2374?src=pr) into [master](https://codecov.io/gh/broadinstitute/gatk/branch/master?src=pr) will decrease coverage by **0.161%**. ```diff; @@ master #2374 diff @@; ==========================================; Files 748 750 +2 ; Lines 39318 39401 +83 ; Methods 0 0 ; Messages 0 0 ; Branches 8196 8214 +18 ; ==========================================; Hits 30036 30036 ; - Misses 6686 6769 +83 ; Partials 2596 2596 ; ```. ![Sunburst](https://codecov.io/gh/broadinstitute/gatk/pull/2374/graphs/sunburst.svg?src=pr&size=150). | Diff Coverage | File Path |; |---|---|; | 0% | *new* [...nstitute/hellbender/engine/MultiPassLocusWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2374/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4D756C7469506173734C6F63757357616C6B65722E6A617661) |; | 0% | *new* [...nder/tools/examples/ExampleMultiPassLocusWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/2374/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F746F6F6C732F6578616D706C65732F4578616D706C654D756C7469506173734C6F63757357616C6B65722E6A617661) |; | •••••••••• 100% | [...a/org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/2374/compare#diff-7372632F6D61696E2F6A6176612F6F72672F62726F6164696E737469747574652F68656C6C62656E6465722F656E67696E652F4741544B546F6F6C2E6A617661) |. > Powered by [Codecov](https://codecov.io?src=pr). Last update [2c85e82...d7e18ea](https://codecov.io/gh/broadinstitute/gatk/compare/2c85e8241179f03f71a0b2442caa4ba68373c03d...d7e18eac4f0edcf1c0352861a49444cb597b40fb?src=pr),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2374#issuecomment-275746509:438,Message,Messages,438,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2374#issuecomment-275746509,1,['Message'],['Messages']
Integrability,(Host unreachable); at java.net.PlainSocketImpl.socketConnect(Native Method); at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127); at sha,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441873417:1534,protocol,protocol,1534,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441873417,3,['protocol'],['protocol']
Integrability,(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Failed to read bam header from /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; Caused by:File does not exist: /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:72); 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:237); 	at org.broadinstitute.hellbender.engine.spark.GAT,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:2951,protocol,protocolPB,2951,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['protocol'],['protocolPB']
Integrability,) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.6/tests/test/index.html) |; | python | openjdk8 | [29984.5](https://travis-ci.com/broadinstitute/gatk/jobs/317851323) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.5/tests/test/index.html) |; | integration | oraclejdk8 | [29984.12](https://travis-ci.com/broadinstitute/gatk/jobs/317851330) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.12/tests/test/index.html) |; | integration | openjdk11 | [29984.13](https://travis-ci.com/broadinstitute/gatk/jobs/317851331) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.13/tests/test/index.html) |; | cloud | openjdk8 | [29984.1](https://travis-ci.com/broadinstitute/gatk/jobs/317851319) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.1/tests/test/index.html) |; | cloud | openjdk11 | [29984.15](https://travis-ci.com/broadinstitute/gatk/jobs/317851333) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.15/tests/test/index.html) |; | unit | openjdk11 | [29984.14](https://travis-ci.com/broadinstitute/gatk/jobs/317851332) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.14/tests/test/index.html) |; | integration | openjdk8 | [29984.2](https://travis-ci.com/broadinstitute/gatk/jobs/317851320) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.2/tests/test/index.html) |; | variantcalling | openjdk8 | [29984.4](https://travis-ci.com/broadinstitute/gatk/jobs/317851322) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.4/tests/test/index.html) |; | unit | openjdk8 | [29984.3](https://travis-ci.com/broadinstitute/gatk/jobs/317851321) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29984.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611695380:1674,integrat,integration,1674,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611695380,1,['integrat'],['integration']
Integrability,) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.6/tests/test/index.html) |; | integration | oraclejdk8 | [29988.12](https://travis-ci.com/broadinstitute/gatk/jobs/317861697) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.12/tests/test/index.html) |; | python | openjdk8 | [29988.5](https://travis-ci.com/broadinstitute/gatk/jobs/317861683) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.5/tests/test/index.html) |; | integration | openjdk11 | [29988.13](https://travis-ci.com/broadinstitute/gatk/jobs/317861698) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.13/tests/test/index.html) |; | cloud | openjdk11 | [29988.15](https://travis-ci.com/broadinstitute/gatk/jobs/317861700) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.15/tests/test/index.html) |; | cloud | openjdk8 | [29988.1](https://travis-ci.com/broadinstitute/gatk/jobs/317861676) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.1/tests/test/index.html) |; | unit | openjdk11 | [29988.14](https://travis-ci.com/broadinstitute/gatk/jobs/317861699) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.14/tests/test/index.html) |; | integration | openjdk8 | [29988.2](https://travis-ci.com/broadinstitute/gatk/jobs/317861680) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.2/tests/test/index.html) |; | variantcalling | openjdk8 | [29988.4](https://travis-ci.com/broadinstitute/gatk/jobs/317861682) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.4/tests/test/index.html) |; | unit | openjdk8 | [29988.3](https://travis-ci.com/broadinstitute/gatk/jobs/317861681) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29988.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611710351:1674,integrat,integration,1674,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611710351,1,['integrat'],['integration']
Integrability,) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.6/tests/test/index.html) |; | integration | oraclejdk8 | [29990.12](https://travis-ci.com/broadinstitute/gatk/jobs/317870159) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.12/tests/test/index.html) |; | python | openjdk8 | [29990.5](https://travis-ci.com/broadinstitute/gatk/jobs/317870152) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.5/tests/test/index.html) |; | cloud | openjdk8 | [29990.1](https://travis-ci.com/broadinstitute/gatk/jobs/317870147) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.1/tests/test/index.html) |; | cloud | openjdk11 | [29990.15](https://travis-ci.com/broadinstitute/gatk/jobs/317870162) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.15/tests/test/index.html) |; | integration | openjdk11 | [29990.13](https://travis-ci.com/broadinstitute/gatk/jobs/317870160) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.13/tests/test/index.html) |; | integration | openjdk8 | [29990.2](https://travis-ci.com/broadinstitute/gatk/jobs/317870149) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.2/tests/test/index.html) |; | unit | openjdk11 | [29990.14](https://travis-ci.com/broadinstitute/gatk/jobs/317870161) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.14/tests/test/index.html) |; | variantcalling | openjdk8 | [29990.4](https://travis-ci.com/broadinstitute/gatk/jobs/317870151) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.4/tests/test/index.html) |; | unit | openjdk8 | [29990.3](https://travis-ci.com/broadinstitute/gatk/jobs/317870150) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611720629:1467,integrat,integration,1467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611720629,1,['integrat'],['integration']
Integrability,) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.6/tests/test/index.html) |; | python | openjdk8 | [29992.5](https://travis-ci.com/broadinstitute/gatk/jobs/317887705) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.5/tests/test/index.html) |; | integration | oraclejdk8 | [29992.12](https://travis-ci.com/broadinstitute/gatk/jobs/317887712) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.12/tests/test/index.html) |; | integration | openjdk11 | [29992.13](https://travis-ci.com/broadinstitute/gatk/jobs/317887713) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.13/tests/test/index.html) |; | cloud | openjdk8 | [29992.1](https://travis-ci.com/broadinstitute/gatk/jobs/317887701) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.1/tests/test/index.html) |; | cloud | openjdk11 | [29992.15](https://travis-ci.com/broadinstitute/gatk/jobs/317887715) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.15/tests/test/index.html) |; | integration | openjdk8 | [29992.2](https://travis-ci.com/broadinstitute/gatk/jobs/317887702) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.2/tests/test/index.html) |; | unit | openjdk11 | [29992.14](https://travis-ci.com/broadinstitute/gatk/jobs/317887714) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.14/tests/test/index.html) |; | variantcalling | openjdk8 | [29992.4](https://travis-ci.com/broadinstitute/gatk/jobs/317887704) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.4/tests/test/index.html) |; | unit | openjdk8 | [29992.3](https://travis-ci.com/broadinstitute/gatk/jobs/317887703) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29992.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611733065:1467,integrat,integration,1467,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611733065,1,['integrat'],['integration']
Integrability,"); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:07 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 3, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:07 WARN TaskSetManager:66 - Lost task 3.0 in stage 0.0 (TID 2, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:25885,Wrap,Wrappers,25885,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Wrap'],['Wrappers']
Integrability,"* The performance should be fine - TileDB/GenomicsDB stores each field in a separate file (columnar storage) and so adding MIN_DP file to the list of queried fields (~5-10 INFO fields) should be fine.; * One possible source of performance improvement - I was querying the PL field in the sites only query (not producing it in the output VariantContext objects). I think it can be dropped from the query. I was assuming that the PL field would be needed to correctly handle spanning deletions (spanning deletion corresponds to deletion allele with min PL). However, for spanning deletions, all INFO fields are dropped. Hence, any INFO fields that depend on the allele order (allele specific annotations) would be dropped for the spanning deletion. Hence, the exact deletion allele corresponding to the spanning deletion is irrelevant making it possible to drop the PL field from the query as well. Is that correct?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3688#issuecomment-377305568:646,depend,depend,646,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3688#issuecomment-377305568,1,['depend'],['depend']
Integrability,"* _Large number of open file handles_: this was an issue in TileDB which got fixed as part of the restructuring that @nalinigans did for supporting HDFS/S3/GCS (#5017). I was too lazy to fix this again. If it's going to take some time for PR #5017 to be merged, I can submit a separate fix for this. This would fix any crashes/termination issues.; * _Performance of a single import process with a large number of intervals_; * Restating the obvious, but this is a single process (and by default, a single thread) with many intervals to import. As you increase the number of samples, this will become a performance pain point.; * More important than the number of intervals is the amount of data imported per interval. Each interval import involves opening the VCF files (loading index structures while creating FeatureReader objects), writing to TileDB/GenomicsDB. and closing the VCF file handles (destroying FeatureReader objects). If the amount of data written for each interval is sufficiently large, the cost of opening/closing the VCF files (creating/destroying FeatureReaders) is small relative to the total time taken.; * In the test cases I and Chris were trying, the amount of data written per interval was small (or 0 in many cases). The time taken in opening/closing the VCF files (and loading/destroying the index) dominates the total time.; * For a single import process (single thread), creating a large interval is better (or no worse) than passing several small intervals. TileDB/GenomicsDB has 0 overhead for regions with no data (for example, WES gVCFs). Having larger intervals will likely avoid issues described above. Hence, an advisory message will be beneficial.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5066#issuecomment-410576757:1659,message,message,1659,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5066#issuecomment-410576757,1,['message'],['message']
Integrability,**increase** coverage by `0.139%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #5251 +/- ##; ===============================================; + Coverage 86.903% 87.042% +0.139% ; - Complexity 30311 32163 +1852 ; ===============================================; Files 1849 1974 +125 ; Lines 140507 147466 +6959 ; Branches 15475 16232 +757 ; ===============================================; + Hits 122105 128358 +6253 ; - Misses 12793 13189 +396 ; - Partials 5609 5919 +310; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5251?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.563% <0%> (-95.313%)` | `1% <0%> (-6%)` | |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `0% <0%> (-95.238%)` | `0% <0%> (-5%)` | |; | [...spark/ReadsPreprocessingPipelineSparkTestData.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvUmVhZHNQcmVwcm9jZXNzaW5nUGlwZWxpbmVTcGFya1Rlc3REYXRhLmphdmE=) | `0% <0%> (-94.03%)` | `0% <0%> (-11%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <0%> (-89.583%)` | `0% <0%> (-12%)` | |; | [...adinstitute/hellbender/engine/ReadContextData.java](https://codecov.io/gh/broadinstitute/gatk/pull/5251/diff?src=pr&el=tr,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5251#issuecomment-426437671:1303,Integrat,IntegrationUtils,1303,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5251#issuecomment-426437671,1,['Integrat'],['IntegrationUtils']
Integrability,*increase** coverage by `0.104%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #5040 +/- ##; ==============================================; + Coverage 86.38% 86.485% +0.104% ; - Complexity 28640 29299 +659 ; ==============================================; Files 1782 1791 +9 ; Lines 132603 135334 +2731 ; Branches 14761 15341 +580 ; ==============================================; + Hits 114543 117043 +2500 ; - Misses 12740 12841 +101 ; - Partials 5320 5450 +130; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5040?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...walkers/bqsr/AnalyzeCovariatesIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5040/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQW5hbHl6ZUNvdmFyaWF0ZXNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `93.846% <100%> (+1.783%)` | `24 <0> (+2)` | :arrow_up: |; | [.../sv/integration/SVIntegrationTestDataProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/5040/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9TVkludGVncmF0aW9uVGVzdERhdGFQcm92aWRlci5qYXZh) | `90.909% <0%> (-1.399%)` | `2% <0%> (+1%)` | |; | [...lignment/AssemblyContigAlignmentsConfigPicker.java](https://codecov.io/gh/broadinstitute/gatk/pull/5040/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0Fzc2VtYmx5Q29udGlnQWxpZ25tZW50c0NvbmZpZ1BpY2tlci5qYXZh) | `92.857% <0%> (-0.658%)` | `125% <0%> (+30%)` | |; | [.../AssemblyContigAlignmentsConfigPickerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5040/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0Fzc2VtYmx5Q29udGlnQWxpZ25tZW50c0NvbmZpZ1BpY2tlclVuaXRUZXN0LmphdmE=) | `99.279% <0%> (-0.326%)` | `42% <0%> (+22,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5040#issuecomment-406636430:1279,integrat,integration,1279,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5040#issuecomment-406636430,1,['integrat'],['integration']
Integrability,"- Add a CLI flag `--exclude-field-name` which can be specified multiple times.; For example `... --exclude-field-name Clinvar_bar --exclude-field-name Clinvar_foo ...`. We will specify the column names with the full field name: `<datasourcename>_<fieldname>`. For now, we specify via an `exclude`. If nothing is specified, then show everything. - Make sure that this new parameter is integrated into the config file framework as implemented by #4581",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4359#issuecomment-400394943:384,integrat,integrated,384,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4359#issuecomment-400394943,1,['integrat'],['integrated']
Integrability,"- I changed some capitalization depending on what a google search brought up for terms, e.g. Fisher's Exact Test --> Fisher's exact test. But I only did so for the summary and did not touch the rest of the doc.; - Again, I did not touch any other portion of the annotation docs. ---; ### Examining the gatkDocs via a browser:. - [ ] StrandOddsRatio equations looking odd with `$$` surrounding them, e.g.; ```; Odds Ratios in the 2x2 contingency table below are; $$ R = \frac{X[0][0] * X[1][1]}{X[0][1] * X[1][0]} $$; ```; - Docs with minimal content and author showing (DavidB or TakutoS):; - [ ] BaseQuality; - [ ] FragmentLength; - [ ] MappingQuality; - [ ] ReadPosition; - [ ] ReferenceBases; - [ ] StrandArtifact; - Docs with just minimal content; - ExcessHet; - SampleList; - [ ] OxoGReadCounts hypertext link at bottom should include a doi, title should be italicized not quoted and hypertext should be limited to title.; - Some of the docs have a ""Caveat"" section while others have ""Related annotations"" and others neither. This seems inconsistently applied.; - [ ] UniqueAltReadCount's content is one giant long paragraph that could use formatting. Also, again, not sure if UniqueAltReadCount.java's acronym is actually UNIQ_ALT_READ_COUNT.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-344711871:32,depend,depending,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-344711871,1,['depend'],['depending']
Integrability,--|; | [...ender/tools/walkers/annotator/StrandOddsRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TdHJhbmRPZGRzUmF0aW8uamF2YQ==) | `94.737% <ø> (ø)` | `8 <0> (ø)` | :arrow_down: |; | [...s/annotator/allelespecific/AS\_StrandOddsRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9hbGxlbGVzcGVjaWZpYy9BU19TdHJhbmRPZGRzUmF0aW8uamF2YQ==) | `80% <ø> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.563% <0%> (-95.313%)` | `1% <0%> (-6%)` | |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `0% <0%> (-95.238%)` | `0% <0%> (-5%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <0%> (-90.741%)` | `0% <0%> (-13%)` | |; | [...titute/hellbender/engine/TwoPassVariantWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvVHdvUGFzc1ZhcmlhbnRXYWxrZXIuamF2YQ==) | `69.231% <0%> (-26.007%)` | `6% <0%> (+2%)` | |; | [...itute/hellbender/utils/runtime/ScriptExecutor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5703#issuecomment-466098961:1934,Integrat,IntegrationUtils,1934,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5703#issuecomment-466098961,1,['Integrat'],['IntegrationUtils']
Integrability,"-listing-perl libfile-mimeinfo-perl libfile-stripnondeterminism-perl; libfont-afm-perl libfontenc1 libgcc-5-dev libgdbm3 libgettextpo-dev; libgettextpo0 libgfortran-5-dev libgfortran3 libgomp1 libhtml-form-perl; libhtml-format-perl libhtml-parser-perl libhtml-tagset-perl; libhtml-tree-perl libhttp-cookies-perl libhttp-daemon-perl libhttp-date-perl; libhttp-message-perl libhttp-negotiate-perl libio-html-perl; libio-socket-ssl-perl libipc-system-simple-perl libisc-export160 libisl15; libitm1 libjpeg-dev libjpeg-turbo8-dev libjpeg8-dev liblapack-dev liblapack3; liblsan0 liblwp-mediatypes-perl liblwp-protocol-https-perl liblzma-dev; libmail-sendmail-perl libmailtools-perl libmnl0 libmpc3 libmpfr4 libmpx0; libncurses5-dev libnet-dbus-perl libnet-http-perl libnet-smtp-ssl-perl; libnet-ssleay-perl libpaper-utils libpaper1 libpcre16-3 libpcre3-dev; libpcre32-3 libpcrecpp0v5 libperl5.22 libpipeline1 libpng12-dev libquadmath0; libreadline-dev libreadline6-dev libsigsegv2 libstdc++-5-dev; libsys-hostname-long-perl libtcl8.6 libtext-iconv-perl libtie-ixhash-perl; libtimedate-perl libtinfo-dev libtk8.6 libtsan0 libubsan0 libunistring0; liburi-perl libwww-perl libwww-robotrules-perl libx11-protocol-perl libxaw7; libxcb-shape0 libxft2 libxml-parser-perl libxml-twig-perl; libxml-xpathengine-perl libxmu6 libxmuu1 libxpm4 libxss1 libxtables11 libxv1; libxxf86dga1 linux-libc-dev m4 make man-db manpages manpages-dev netbase; patch perl perl-modules-5.22 po-debconf python-pkg-resources python-scour; python-six r-base-core r-base-dev r-doc-html rename tzdata x11-utils; x11-xserver-utils xdg-utils zip zlib1g-dev```. -Not sure if moving the R install to the conda environment (which is not in the base image) will increase Travis time, but it doesn't appear to from the limited number of builds that have run so far. At some point we may want to move conda into the base image. However, I think that this would require that the base be rebuilt with every python code change, which is not optimal.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406373954:3144,protocol,protocol-perl,3144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406373954,2,['protocol'],['protocol-perl']
Integrability,"...I didn't run the spark version for quite some time, and it might also depend on the size of the BAM file being processed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6578#issuecomment-621277739:73,depend,depend,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6578#issuecomment-621277739,1,['depend'],['depend']
Integrability,..llbender/tools/genomicsdb/GenomicsDBConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9nZW5vbWljc2RiL0dlbm9taWNzREJDb25zdGFudHMuamF2YQ==) | `0% <0%> (ø)` | `0% <0%> (ø)` | :arrow_down: |; | [...r/tools/walkers/annotator/ClippingRankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9DbGlwcGluZ1JhbmtTdW1UZXN0LmphdmE=) | `100% <0%> (ø)` | `4% <0%> (ø)` | :arrow_down: |; | [...ender/engine/spark/datasources/ReadsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NpbmsuamF2YQ==) | `77.027% <0%> (+0.676%)` | `33% <0%> (+1%)` | :arrow_up: |; | [...spark/sv/evidence/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `69.485% <0%> (+0.825%)` | `61% <0%> (+1%)` | :arrow_up: |; | [...utils/test/ReadsPreprocessingPipelineTestData.java](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1JlYWRzUHJlcHJvY2Vzc2luZ1BpcGVsaW5lVGVzdERhdGEuamF2YQ==) | `0.862% <0%> (+0.862%)` | `1% <0%> (+1%)` | :arrow_up: |; | [...ute/hellbender/utils/test/IntegrationTestSpec.java](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0ludGVncmF0aW9uVGVzdFNwZWMuamF2YQ==) | `73.118% <0%> (+1.075%)` | `25% <0%> (ø)` | :arrow_down: |; | ... and [588 more](https://codecov.io/gh/broadinstitute/gatk/pull/4970/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4970#issuecomment-401503431:3926,Integrat,IntegrationTestSpec,3926,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4970#issuecomment-401503431,1,['Integrat'],['IntegrationTestSpec']
Integrability,".; # Ensuring the correct environment for canonical (or otherwise reasonable) usage of our standard Docker takes precedence over edge cases.; # If you break the environment, you are responsible for fixing it and also owe the last developer who left this in a reasonable state a beverage of their choice.; # (This may be yourself, and you'll appreciate that beverage while you tinker with dependencies!); #; # When changing dependencies or versions in this file, check to see if the ""supportedPythonPackages"" DataProvider; # used by the testGATKPythonEnvironmentPackagePresent test in PythonEnvironmentIntegrationTest needs to be updated; # to reflect the changes.; #; name: gatk; channels:; # if channels other than conda-forge are added and the channel order is changed (note that conda channel_priority is currently set to flexible),; # verify that key dependencies are installed from the correct channel and compiled against MKL; - conda-forge; - defaults; dependencies:. # core python dependencies; - conda-forge::python=3.6.10 # do not update; - pip=20.0.2 # specifying channel may cause a warning to be emitted by conda; - conda-forge::mkl=2019.5 # MKL typically provides dramatic performance increases for theano, tensorflow, and other key dependencies; - conda-forge::mkl-service=2.3.0; - conda-forge::numpy=1.17.5 # do not update, this will break scipy=0.19.1; # verify that numpy is compiled against MKL (e.g., by checking *_mkl_info using numpy.show_config()); # and that it is used in tensorflow, theano, and other key dependencies; - conda-forge::theano=1.0.4 # it is unlikely that new versions of theano will be released; # verify that this is using numpy compiled against MKL (e.g., by the presence of -lmkl_rt in theano.config.blas.ldflags); - defaults::tensorflow=1.15.0 # update only if absolutely necessary, as this may cause conflicts with other core dependencies; # verify that this is using numpy compiled against MKL (e.g., by checking tensorflow.pywrap_tensorflow.IsMklEnabled(",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868:1434,depend,dependencies,1434,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656#issuecomment-643526868,2,['depend'],['dependencies']
Integrability,".Main.main(Main.java:292); ```. ## Cases when the error does not occur; * If I rename `test a` folder in `test-a` as previously said.; * If I copy my current `test a` in the `/tmp/` directory (`/tmp/test a/`). This may suggest that the path length plays a role.; * If I renamed the VCF files (first VCF becomes `a.vcf.gz`, second `b.vcf.gz`) (`gatk MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O out.vcf.gz`).; * If I rename the first VCF file with as many `a` character as characters found in the original filename. (aaaaaaaaaaaaaaaaaa.vcf.gz).; * If I rename the first VCF by replacing all alphabetical character with a (aaaa_aaaa2.aa_a7_1.vcf.gz); * If I introduce random `_` in the file name (aaaa_aaa_aaaa_aaaa.vcf.gz).; * If I rename the first VCF file by removing the first character (`cerc_prod2.SM_V7_1.vcf.gz` -> `erc_prod2.SM_V7_1.vcf.gz`); * If I rename the first VCF file by introducing a letter at the beginning (`cerc_prod2.SM_V7_1.vcf.gz` -> `ccerc_prod2.SM_V7_1.vcf.gz`). It really seems that the combination of the path lengh, white space and particular filename triggers this. I cannot get my head around this. I don't think this is coming from the content of the VCF as it works well in some cases. Let me know if you need me to make other tests. Fred. ----. ## Update. I investigated a little further after thinking about the tests I did. Because modifying the VCF filename did not trigger the issue and because of the presence of `tabix` related modules in the traces, I decided to see if removing `tbi` file will avoid having the error message. And it did!. After recreating the `tbi` file (`tabix data/calling/cerc_prod2.SM_V7_1.vcf.gz`), the error message appeared again. So it does not seem related to malformed index file. However, index file seems part of the problem. After renaming `test a` folder in `test-a` with the old or new index file, I did not get any error (as usual). Here is my tabix version in case:; ```bash; $ tabix -h. Version: 1.10.2; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6664#issuecomment-647808241:8630,message,message,8630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664#issuecomment-647808241,2,['message'],['message']
Integrability,.SocketTimeoutException: Read timed out; 	at java.net.SocketInputStream.socketRead0(Native Method); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:171); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300298180:7206,protocol,protocol,7206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-300298180,1,['protocol'],['protocol']
Integrability,".executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:50 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 4, scc-q20.scc.bu.edu, executor 2, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:50 WARN TaskSetManager:66 - Lost task 4.0 in stage 0.0 (TID 2, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:26944,Wrap,Wrappers,26944,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Wrap'],['Wrappers']
Integrability,".java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 5.0 failed 1 times, most recent failure: Lost task 1.0 in stage 5.0 (TID 12, localhost, executor driver): java.util.ConcurrentModificationException; 	at java.util.ArrayList.sort(ArrayList.java:1464); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.re",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429:7173,Message,MessageHubBackedObjectConnection,7173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6633#issuecomment-639136429,1,['Message'],['MessageHubBackedObjectConnection']
Integrability,.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:436); 2019-01-04T14:02:27.236174900Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:120); 2019-01-04T14:02:27.236322702Z 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); 2019-01-04T14:02:27.237171464Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 2019-01-04T14:02:27.237239651Z 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 2019-01-04T14:02:27.237250455Z 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 2019-01-04T14:02:27.237256726Z 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 2019-01-04T14:02:27.237294098Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-01-04T14:02:27.237302853Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-01-04T14:02:27.237308231Z 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 2019-01-04T14:02:27.237342232Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 2019-01-04T14:02:27.237377382Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-01-04T14:02:27.237384696Z 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 2019-01-04T14:02:27.237442143Z 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverseVariants(TwoPassVariantWalker.java:74); 2019-01-04T14:02:27.237452377Z 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverse(TwoPassVariantWalker.java:27); 2019-01-04T14:02:27.237457367Z 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 2019-01-04T14:02:27.237461597Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 2019-01-04T14:,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451464446:2923,wrap,wrapAndCopyInto,2923,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451464446,1,['wrap'],['wrapAndCopyInto']
Integrability,.open(DistributedFileSystem.java:312); 	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769); 	at org.seqdoop.hadoop_bam.util.SAMHeaderReader.readSAMHeaderFrom(SAMHeaderReader.java:51); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:235); 	... 15 more; Caused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): File does not exist: /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:72); 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). 	at org.apache.hadoop.ipc.Client.call(Client.java:1475); 	at org.apache.hadoop.ipc.Client.call(Client.java:1412); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoke,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:9109,protocol,protocolPB,9109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['protocol'],['protocolPB']
Integrability,".samuel.k@gmail.com>; Date: Fri Dec 8 00:55:14 2017 -0500. updated somatic PoNs for PreprocessIntervals drop Ns. commit cff64984d9fb42364001bda4c73d54cf68d85a5c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 00:37:24 2017 -0500. sudo travis yml. commit 89025941febd2089d426cfa1e0f0aa6a6712e2a9; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Fri Dec 8 00:23:22 2017 -0500. travis/Docker config update (g++-6, Miniconda3); python test group assignment. commit 31f96398106c2b8577b8c25d110abea3ebe7f836; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:44:53 2017 -0500. WDL test bugfix. commit 9b2fb820536ec355bea0256471bd093d547f5c99; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:20:36 2017 -0500. update WDL test JSON files. commit e3d97644d1a2c40a5c364a96f8b67246154179c9; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:18:14 2017 -0500. assertions in inference task base; removed a ASCII > 128 character in log messages. commit 526cf92e623a3bbd5f9d375132b6ca046fc47620; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 20:03:04 2017 -0500. redirect tqdm progress bar to python logger. commit 2e45bd30968b921fae225de3901fb97ece690b0c; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 19:45:49 2017 -0500. more arg related fixes. commit bb89a3bb338d88199881e8aca65f656f2acd7c0a; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 19:41:20 2017 -0500. arg related bugfixes in WDL, python, and java CLIs. commit 23569787ee2c8cc6c9227a44170cbbd02fe4427f; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 17:21:05 2017 -0500. fixed issue with python boolean argparse (they use weird semantics). commit ae841c9ed4cd9b2ca1ac0e9082d175ff8ea98298; Author: Mehrtash Babadi <mehrtash@broadinstitute.org>; Date: Thu Dec 7 16:44:02 2017 -0500. shorter gCNV WDL tests. commit 5466b806e36df16cad2d045be074e7f",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598:4813,message,messages,4813,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-354805598,2,['message'],['messages']
Integrability,.utils.recalibration.BaseRecalibrationEngine.calculateSkipArray(BaseRecalibrationEngine.java:324); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.processRead(BaseRecalibrationEngine.java:139); at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(BaseRecalibrator.java:185); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.m,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5807#issuecomment-691600264:4038,wrap,wrapAndCopyInto,4038,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807#issuecomment-691600264,1,['wrap'],['wrapAndCopyInto']
Integrability,"/7,(-A<<=B?A*9:(-2.<<=:@;C-)76?C8<MC:Z:45S106MMD:Z:24PG:Z:MarkDuplicates.1FRG:Z:HK35M.3NM:i:0MQ:i:37OQ:Z:,AFAFKKKFKKAAF<; A,7AKAFK,,7,AF,77FFF<A,7AKKK,,FFKKKFFFKKKK7,F<,,,,,77,,,FAFFAFK,A7(,7,A<AAAFF,,77FK7F###################################################UQ:i; :0AS:i:24. at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.finalizeRegion(AssemblyBasedCallerUtils.java:91); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.assembleReads(AssemblyBasedCallerUtils.java:246); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:493); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.lambda$regionToVariants$1326(HaplotypeCallerSpark.java:223); at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267); at java.util.Spliterators$IteratorSpliterator.tryAdvance(Spliterators.java:1812); at java.util.stream.StreamSpliterators$WrappingSpliterator.lambda$initPartialTraversalState$0(StreamSpliterators.java:294); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.fillBuffer(StreamSpliterators.java:206); at java.util.stream.StreamSpliterators$AbstractWrappingSpliterator.doAdvance(StreamSpliterators.java:169); at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:300); at java.util.Spliterators$1Adapter.hasNext(Spliterators.java:681); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:213); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:935); at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:926); at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:866); at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:926); at org.apache.s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3013#issuecomment-308145149:2259,Wrap,WrappingSpliterator,2259,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3013#issuecomment-308145149,1,['Wrap'],['WrappingSpliterator']
Integrability,/broadinstitute/gatk/jobs/317870153) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.6/tests/test/index.html) |; | integration | oraclejdk8 | [29990.12](https://travis-ci.com/broadinstitute/gatk/jobs/317870159) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.12/tests/test/index.html) |; | python | openjdk8 | [29990.5](https://travis-ci.com/broadinstitute/gatk/jobs/317870152) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.5/tests/test/index.html) |; | cloud | openjdk8 | [29990.1](https://travis-ci.com/broadinstitute/gatk/jobs/317870147) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.1/tests/test/index.html) |; | cloud | openjdk11 | [29990.15](https://travis-ci.com/broadinstitute/gatk/jobs/317870162) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.15/tests/test/index.html) |; | integration | openjdk11 | [29990.13](https://travis-ci.com/broadinstitute/gatk/jobs/317870160) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.13/tests/test/index.html) |; | integration | openjdk8 | [29990.2](https://travis-ci.com/broadinstitute/gatk/jobs/317870149) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.2/tests/test/index.html) |; | unit | openjdk11 | [29990.14](https://travis-ci.com/broadinstitute/gatk/jobs/317870161) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.14/tests/test/index.html) |; | variantcalling | openjdk8 | [29990.4](https://travis-ci.com/broadinstitute/gatk/jobs/317870151) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29990.4/tests/test/index.html) |; | unit | openjdk8 | [29990.3](https://travis-ci.com/broadinstitute/gatk/jobs/317870150) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/mast,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611720629:1253,integrat,integration,1253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-611720629,1,['integrat'],['integration']
Integrability,/spark/sv/evidence/BreakpointDensityFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4769/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9CcmVha3BvaW50RGVuc2l0eUZpbHRlci5qYXZh) | `97.183% <100%> (ø)` | `27 <0> (ø)` | :arrow_down: |; | [...ute/hellbender/tools/spark/utils/IntHistogram.java](https://codecov.io/gh/broadinstitute/gatk/pull/4769/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay91dGlscy9JbnRIaXN0b2dyYW0uamF2YQ==) | `91.2% <100%> (+0.291%)` | `19 <0> (ø)` | :arrow_down: |; | [...spark/sv/evidence/BreakpointDensityFilterTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4769/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9CcmVha3BvaW50RGVuc2l0eUZpbHRlclRlc3QuamF2YQ==) | `100% <100%> (ø)` | `17 <0> (ø)` | :arrow_down: |; | [...te/hellbender/tools/spark/sv/utils/SVInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4769/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TVkludGVydmFsLmphdmE=) | `89.362% <100%> (+6.383%)` | `33 <1> (+1)` | :arrow_up: |; | [.../sv/integration/SVIntegrationTestDataProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/4769/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9TVkludGVncmF0aW9uVGVzdERhdGFQcm92aWRlci5qYXZh) | `94.118% <100%> (+1.81%)` | `1 <1> (ø)` | :arrow_down: |; | [...er/tools/spark/sv/evidence/BreakpointEvidence.java](https://codecov.io/gh/broadinstitute/gatk/pull/4769/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9CcmVha3BvaW50RXZpZGVuY2UuamF2YQ==) | `78.86% <57.303%> (-2.985%)` | `20 <4> (+8)` | |; | ... and [40 more](https://codecov.io/gh/broadinstitute/gatk/pull/4769/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-395889530:3554,integrat,integration,3554,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-395889530,1,['integrat'],['integration']
Integrability,"/xx.xx.xx.xx:4040; 18/04/24 17:42:02 INFO StandaloneSchedulerBackend: Shutting down all executors; 18/04/24 17:42:02 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 18/04/24 17:42:02 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/gatk-package-4.0.3.0-spark.jar, byteCount=138618122, body=FileSegmentManagedBuffer{file=/scratch/home/int/eva/username/bin/gatk-4.0.3.0/gatk-package-4.0.3.0-spark.jar, offset=0, length=138618122}} to /xx.xx.xx.25:57139; closing connection; java.io.IOException: Connection reset by peer; at sun.nio.ch.FileChannelImpl.transferTo0(Native Method); at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428); at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493); at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608); at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139); at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121); at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287); at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237); at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314); at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802); at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319); at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637); at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566); at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480); at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442); at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131); at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(Defaul",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:37235,Message,MessageWithHeader,37235,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Message'],['MessageWithHeader']
Integrability,0-29T18:18:04.001673083Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-29T18:18:04.001846904Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-29T18:18:04.002024760Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002358113Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-29T18:18:04.002377342Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-29T18:18:04.002383406Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.00,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:1800,wrap,wrapAndCopyInto,1800,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300,1,['wrap'],['wrapAndCopyInto']
Integrability,0-30T13:35:51.792736667Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-30T13:35:51.792905235Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-30T13:35:51.793072365Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-30T13:35:51.793261944Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-30T13:35:51.793456807Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-30T13:35:51.793619935Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-30T13:35:51.793810301Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.794006885Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.794191116Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-30T13:35:51.794367593Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-30T13:35:51.794548129Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-30T13:35:51.794722501Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-30T13:35:51.794896154Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-30T13:35:51.795082090Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-30T13:35:51.795253632Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-30T13:35:51.79,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:1801,wrap,wrapAndCopyInto,1801,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227,1,['wrap'],['wrapAndCopyInto']
Integrability,"019-01-07 11:34:05 INFO BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on scc-q12.scc.bu.edu:38418 (size: 25.4 KB, free: 365.9 MB); 2019-01-07 11:34:05 INFO BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on scc-q12.scc.bu.edu:38418 (size: 113.9 KB, free: 365.8 MB); 2019-01-07 11:34:06 INFO TaskSetManager:54 - Starting task 3.0 in stage 0.0 (TID 2, scc-q21.scc.bu.edu, executor 1, partition 3, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:06 WARN TaskSetManager:66 - Lost task 1.0 in stage 0.0 (TID 1, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:24150,Wrap,Wrappers,24150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Wrap'],['Wrappers']
Integrability,"019-01-09 13:35:46 INFO BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on scc-q01.scc.bu.edu:41129 (size: 25.4 KB, free: 365.9 MB); 2019-01-09 13:35:46 INFO BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on scc-q01.scc.bu.edu:41129 (size: 113.9 KB, free: 365.8 MB); 2019-01-09 13:35:48 INFO TaskSetManager:54 - Starting task 4.0 in stage 0.0 (TID 2, scc-q20.scc.bu.edu, executor 2, partition 4, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:48 WARN TaskSetManager:66 - Lost task 1.0 in stage 0.0 (TID 0, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:23437,Wrap,Wrappers,23437,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Wrap'],['Wrappers']
Integrability,"06834861e7ae) [duplicate 3]; 2019-01-07 11:34:12 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Cancelling stage 0; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Stage 0 was cancelled; 2019-01-07 11:34:12 INFO DAGScheduler:54 - ResultStage 0 (count at CountReadsSpark.java:80) failed in 9.293 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:34089,Wrap,Wrappers,34089,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Wrap'],['Wrappers']
Integrability,"08); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); Caused by: java.io.FileNotFoundException: hg19mini.hss (No such file or directory); at java.io.FileInputStream.open0(Native Method); at java.io.FileInputStream.open(FileInputStream.java:195); at java.io.FileInputStream.<init>(FileInputStream.java:138); at java.io.FileInputStream.<init>(FileInputStream.java:93); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.openFile(BucketUtils.java:103); ... 16 more. 18/04/24 17:40:52 INFO TaskSetManager: Lost task 0.0 in stage 2.0 (TID 3) on xx.xx.xx.25, executor 2: org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile (Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such file or directory)) [duplicate 1]; 01:33 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:40:52 INFO TaskSetManager: Starting task 0.1 in stage 2.0 (TID 5, xx.xx.xx.24, executor 4, partition 0, PROCESS_LOCAL, 6010 bytes); 01:33 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:40:52 INFO TaskSetManager: Starting task 1.1 in stage 2.0 (TID 6, xx.xx.xx.24, executor 1, partition 1, PROCESS_LOCAL, 5371 bytes); 18/04/24 17:41:19 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.24:49115 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:41:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on xx.xx.xx.24:49115 (size: 23.1 KB, free: 366.3 MB); 18/04/24 17:41:31 WARN TaskSetManager: Lost task 0.1 in stage 2.0 (TID 5, xx.xx.xx.24, executor 4): org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file. Error was: hg19mini.hss with exception: hg19mini.hss (No such",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:26752,Wrap,WrappedArray,26752,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Wrap'],['WrappedArray']
Integrability,"1. AF in the FORMAT column can be used to represent heteroplasmy levels. ; 2. Currently the genotype is always reported as het (0/1). There is a request to change this but it hasn't been implemented yet: https://github.com/broadinstitute/gatk/issues/6257 If you'd like to fix this feel free to make a PR and I'd be happy to review it.; 3. Mitochondria mode in Mutect alone does not automatically shift the reference. However, you can use the full pipeline which does the shift automatically. You can find the WDL here: https://github.com/broadinstitute/gatk/blob/master/scripts/mitochondria_m2_wdl/MitochondriaPipeline.wdl or the Terra workspace here: https://app.terra.bio/#workspaces/help-gatk/Mitochondria-SNPs-Indels-hg38 Depending on the coverage of your data, if you don't need high sensitivity over the region with the breakpoint it also might not be worth doing the full realignment. You'll still be able to make calls on the edges of the linearized reference, you just might not have the full sensitivity you would if you realigned. I hope that helps!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7350#issuecomment-880714297:726,Depend,Depending,726,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7350#issuecomment-880714297,1,['Depend'],['Depending']
Integrability,"1. After removing `chr` the tool output still indicates 0 bp from the interval.; 2. I tried omitting the `--sequence-dictionary` argument but the tool output still indicates 0 bp from the interval.; 3. If I check my command by which I generated the vcf files. I used the following mutext2 (in tumor only mode) command for normal samples:; ` $gatk Mutect2 --native-pair-hmm-threads 8 -R /refs/ucsc.hg19.fasta -I normal1.bam -tumor normal1 --disable-read-filter MateOnSameContigOrNoMappedMateReadFilter -O nornam1.vcf.gz`; The above command worked well for all 80 normals. Please let me know if I missed anything here to make vcf files compatible with the GenomicDB module. Other than using the hg19 fasta file from gatk resources, I also tried the same UCSC hg19 (both fasta and dict) but GenomeDB indicates the same 0 bp message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7037#issuecomment-760677622:821,message,message,821,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7037#issuecomment-760677622,1,['message'],['message']
Integrability,"1. Why can't standard tools operate on the distributed workspaces? You could run `GenotypeGVCFs` on these workspaces in a distributed fashion and then concatenate the results together if you want. I think you were initially considering this route - and still think it would be more performant. 2. Again, you can process/query a whatever set of intervals you want -- in a distributed fashion, right?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-640791782:241,rout,route,241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-640791782,1,['rout'],['route']
Integrability,14810448Z Runtime.totalMemory()=407896064; 2019-01-04T14:02:27.215613324Z java.lang.IllegalArgumentException: errorRateLog10 must be good probability but got NaN; 2019-01-04T14:02:27.216082142Z 	at org.broadinstitute.hellbender.utils.QualityUtils.phredScaleLog10ErrorRate(QualityUtils.java:321); 2019-01-04T14:02:27.216288993Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.lambda$applyGermlineVariantFilter$10(Mutect2FilteringEngine.java:207); 2019-01-04T14:02:27.216482786Z 	at java.util.stream.DoublePipeline$3$1.accept(DoublePipeline.java:231); 2019-01-04T14:02:27.216675396Z 	at java.util.Spliterators$DoubleArraySpliterator.forEachRemaining(Spliterators.java:1198); 2019-01-04T14:02:27.216858104Z 	at java.util.Spliterator$OfDouble.forEachRemaining(Spliterator.java:822); 2019-01-04T14:02:27.217027544Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-01-04T14:02:27.234512924Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-01-04T14:02:27.234886181Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); 2019-01-04T14:02:27.235138770Z 	at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); 2019-01-04T14:02:27.235509109Z 	at java.util.stream.IntPipeline.toArray(IntPipeline.java:502); 2019-01-04T14:02:27.235661751Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyGermlineVariantFilter(Mutect2FilteringEngine.java:207); 2019-01-04T14:02:27.235931663Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:436); 2019-01-04T14:02:27.236174900Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:120); 2019-01-04T14:02:27.236322702Z 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); 2019-01-04T14:02:27.2371714,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451464446:1329,wrap,wrapAndCopyInto,1329,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451464446,1,['wrap'],['wrapAndCopyInto']
Integrability,"30.861 INFO ProgressMeter - chr21:48065662 88.1 10112630 114731.5; 22:45:30.976 INFO HaplotypeCaller - 0 read(s) filtered by: MappingQualityReadFilter; 0 read(s) filtered by: MappingQualityAvailableReadFilter; 0 read(s) filtered by: MappedReadFilter; 0 read(s) filtered by: NotSecondaryAlignmentReadFilter; 0 read(s) filtered by: NotDuplicateReadFilter; 0 read(s) filtered by: PassesVendorQualityCheckReadFilter; 0 read(s) filtered by: NonZeroReferenceLengthAlignmentReadFilter; 0 read(s) filtered by: GoodCigarReadFilter; 0 read(s) filtered by: WellformedReadFilter; 0 total reads filtered; 22:45:30.976 INFO ProgressMeter - chr21:48129366 88.1 10112861 114731.7; 22:45:30.976 INFO ProgressMeter - Traversal complete. Processed 10112861 total regions in 88.1 minutes.; 22:45:31.288 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.864119336; 22:45:31.288 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 115.66789462000001; 22:45:31.288 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 90.73 sec; 22:45:31.289 INFO HaplotypeCaller - Shutting down engine; [August 31, 2020 10:45:31 PM CDT] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 88.19 minutes.; Runtime.totalMemory()=2630352896. And now the header looks like:; ```; @SQ SN:chr1 LN:249250621; @SQ SN:chr2 LN:243199373; @SQ SN:chr3 LN:198022430; @SQ SN:chr4 LN:191154276; @SQ SN:chr5 LN:180915260; @SQ SN:chr6 LN:171115067; @SQ SN:chr7 LN:159138663; @SQ SN:chr8 LN:146364022; @SQ SN:chr9 LN:141213431; @SQ SN:chr10 LN:135534747; @SQ SN:chr11 LN:135006516; @SQ SN:chr12 LN:133851895; @SQ SN:chr13 LN:115169878; @SQ SN:chr14 LN:107349540; @SQ SN:chr15 LN:102531392; @SQ SN:chr16 LN:90354753; @SQ SN:chr17 LN:81195210; @SQ SN:chr18 LN:78077248; @SQ SN:chr20 LN:63025520; @SQ SN:chr19 LN:59128983; @SQ SN:chr22 LN:51304566; @SQ SN:chr21 LN:48129895; ```. So I still think it is the header in BAM that is causing the error message.; Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6783#issuecomment-684831011:2311,message,message,2311,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783#issuecomment-684831011,1,['message'],['message']
Integrability,3348> (a java.net.SocksSocketImpl); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at java.net.Socket.connect(Socket.java:538); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:180); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	- locked <0x0000000584a62640> (a sun.net.www.http.HttpClient); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1546); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at com.google.cloud.MetadataConfig.getAttribute(MetadataConfig.java:65); 	at com.google.cloud.MetadataConfig.getProjectId(MetadataConfig.java:41); 	at com.google.cloud.ServiceOptions.getGoogleCloudProjectId(ServiceOptions.java:376); 	at com.google.cloud.ServiceOptions.getDefaultProjectId(ServiceOptions.java:311); 	at com.google.cloud.ServiceOptions.getDefaultProject(ServiceOptions.java:284); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:238); 	at com.google.cloud.storage.Stor,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670:1377,protocol,protocol,1377,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670,1,['protocol'],['protocol']
Integrability,35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstan,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:1892,Message,MessageHub,1892,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858,1,['Message'],['MessageHub']
Integrability,3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYXJpYW50c1RvVGFibGUuamF2YQ==) | `93.333% <0.000%> (-0.063%)` | :arrow_down: |; | [...itute/hellbender/tools/LocalAssemblerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7926/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Mb2NhbEFzc2VtYmxlclVuaXRUZXN0LmphdmE=) | `92.448% <0.000%> (ø)` | |; | [...s/variantutils/VariantsToTableIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7926/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYXJpYW50c1RvVGFibGVJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `100.000% <0.000%> (ø)` | |; | [...s/solver/SynchronizedUnivariateSolverUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7926/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zb2x2ZXIvU3luY2hyb25pemVkVW5pdmFyaWF0ZVNvbHZlclVuaXRUZXN0LmphdmE=) | | |; | [...r/utils/solver/UnivariateSolverSpecifications.java](https://codecov.io/gh/broadinstitute/gatk/pull/7926/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zb2x2ZXIvVW5pdmFyaWF0ZVNvbHZlclNwZWNpZmljYXRpb25zLmphdmE=) | | |; | [...r/utils/solver/UnivariateSolverJobDescription.java](https://codecov.io/gh/broadinstitute/gatk/pull/7926/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvY,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7926#issuecomment-1170548167:4307,Synchroniz,SynchronizedUnivariateSolverUnitTest,4307,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7926#issuecomment-1170548167,1,['Synchroniz'],['SynchronizedUnivariateSolverUnitTest']
Integrability,3Zxc3IvVHJhbmNoZS5qYXZh) | `62.921% <0%> (-7.349%)` | `18% <0%> (ø)` | |; | [.../hellbender/tools/walkers/vqsr/TrancheManager.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvVHJhbmNoZU1hbmFnZXIuamF2YQ==) | `67.347% <0%> (-2.983%)` | `18% <0%> (+3%)` | |; | [...ols/walkers/contamination/ContaminationRecord.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vQ29udGFtaW5hdGlvblJlY29yZC5qYXZh) | `87.302% <0%> (-2.698%)` | `9% <0%> (+4%)` | |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <0%> (ø)` | `11% <0%> (?)` | |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <0%> (ø)` | `12% <0%> (?)` | |; | [...ools/spark/pathseq/PSFilterArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `80% <0%> (+1.429%)` | `2% <0%> (ø)` | :arrow_down: |; | [...s/spark/pathseq/PSBuildReferenceTaxonomyUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTQnVpbGRSZWZlcmVuY2VUYXhvbm9teVV0aWxzLmphdmE=) | `90.541% <0%> (+1.579%)` | `80% <0%> (+41%)` | :arrow_up: |; | ... and [7 more](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3388#issuecomment-319175054:3054,Adapter,AdapterTrimTransformer,3054,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3388#issuecomment-319175054,1,['Adapter'],['AdapterTrimTransformer']
Integrability,"4.2 KB, free 366.0 MB); 00:45 DEBUG: [kryo] Write: byte[]; 18/04/24 17:40:04 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.4 KB, free 366.0 MB); 18/04/24 17:40:04 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.xx:42081 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:40:04 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006; 18/04/24 17:40:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[19] at mapToPair at PSFilter.java:125) (first 15 tasks are for partitions Vector(0, 1)); 18/04/24 17:40:04 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks; 00:45 DEBUG: [kryo] Write: WrappedArray([NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED, NC_000913.3_127443_127875_0:0:0_0:0:0_a507 UNMAPPED]); 18/04/24 17:40:04 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 3, xx.xx.xx.25, executor 2, partition 0, PROCESS_LOCAL, 6010 bytes); 00:45 DEBUG: [kryo] Write: WrappedArray(null); 18/04/24 17:40:04 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 4, xx.xx.xx.23, executor 5, partition 1, PROCESS_LOCAL, 5371 bytes); 18/04/24 17:40:21 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (xx.xx.xx.24:44437) with ID 1; 18/04/24 17:40:21 INFO BlockManagerMasterEndpoint: Registering block manager xx.xx.xx.24:44322 with 366.3 MB RAM, BlockManagerId(1, xx.xx.xx.24, 44322, None); 18/04/24 17:40:27 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (xx.xx.xx.24:44439) with ID 4; 18/04/24 17:40:27 INFO BlockManagerMasterEndpoint: Registering block manager xx.xx.xx.24:49115 with 366.3 MB RAM, BlockManagerId(4, xx.xx.xx.24, 49115, None); 18/04/24 17:40:50 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on xx.xx.xx.25:39218 (size: 6.4 KB, free: 366.3 MB); 18/04/24 17:40:50 INFO BlockManagerInfo: Added broadcas",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:22951,Wrap,WrappedArray,22951,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Wrap'],['WrappedArray']
Integrability,"4/24 17:42:02 INFO StandaloneSchedulerBackend: Shutting down all executors; 18/04/24 17:42:02 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 18/04/24 17:42:02 ERROR TransportRequestHandler: Error sending result StreamResponse{streamId=/jars/gatk-package-4.0.3.0-spark.jar, byteCount=138618122, body=FileSegmentManagedBuffer{file=/scratch/home/int/eva/username/bin/gatk-4.0.3.0/gatk-package-4.0.3.0-spark.jar, offset=0, length=138618122}} to /xx.xx.xx.25:57139; closing connection; java.io.IOException: Connection reset by peer; at sun.nio.ch.FileChannelImpl.transferTo0(Native Method); at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428); at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493); at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:608); at io.netty.channel.DefaultFileRegion.transferTo(DefaultFileRegion.java:139); at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:121); at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:287); at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:237); at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:314); at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:802); at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.forceFlush(AbstractNioChannel.java:319); at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:637); at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566); at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480); at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442); at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131); at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616:37264,Message,MessageWithHeader,37264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4694#issuecomment-383986616,1,['Message'],['MessageWithHeader']
Integrability,4668988887 Oct 4 11:27 /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; ```. Here is SPARK information. ```; A USER ERROR has occurred: Failed to read bam header from; /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; Caused by:File does not exist: /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:72); 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Failed to read bam header from /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; Caused by:File does not exist: /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; 	at org.apa,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:1445,protocol,protocol,1445,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['protocol'],['protocol']
Integrability,"4:08 INFO TaskSetManager:54 - Lost task 1.1 in stage 0.0 (TID 3) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 1]; 2019-01-07 11:34:09 INFO TaskSetManager:54 - Starting task 9.0 in stage 0.0 (TID 5, scc-q12.scc.bu.edu, executor 2, partition 9, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:09 WARN TaskSetManager:66 - Lost task 2.0 in stage 0.0 (TID 0, scc-q12.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:28076,Wrap,Wrappers,28076,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Wrap'],['Wrappers']
Integrability,"4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZURhdGFTb3VyY2UuamF2YQ==) | `77.477% <ø> (+0.901%)` | `38% <ø> (+2%)` | :white_check_mark: |; | [...tools/walkers/genotyper/AlleleSubsettingUtils.java](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...09a6f249352cd17f9214fccb5a4b3ac2c31f2cce?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9BbGxlbGVTdWJzZXR0aW5nVXRpbHMuamF2YQ==) | `87.037% <ø> (+0.926%)` | `40% <ø> (+1%)` | :white_check_mark: |; | [...ark/pipelines/metrics/MeanQualityByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...09a6f249352cd17f9214fccb5a4b3ac2c31f2cce?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9NZWFuUXVhbGl0eUJ5Q3ljbGVTcGFyay5qYXZh) | `91.667% <ø> (+1.042%)` | `10% <ø> (ø)` | :x: |; | [...ute/hellbender/utils/test/IntegrationTestSpec.java](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...09a6f249352cd17f9214fccb5a4b3ac2c31f2cce?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0ludGVncmF0aW9uVGVzdFNwZWMuamF2YQ==) | `74.194% <ø> (+1.075%)` | `26% <ø> (+1%)` | :white_check_mark: |; | ... and [3 more](https://codecov.io/gh/broadinstitute/gatk/pull/2404/changes?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2404?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/2404?src=pr&el=footer). Last update [30365e7...09a6f24](https://codecov.io/gh/broadinstitute/gatk/compare/30365e7bea2d081204a11e7d916026cb3494961f...09a6f249352cd17f9214fccb",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2404#issuecomment-279082842:4367,Integrat,IntegrationTestSpec,4367,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2404#issuecomment-279082842,1,['Integrat'],['IntegrationTestSpec']
Integrability,"594.9; 14:36:53.704 INFO ProgressMeter - chr1:235080870 4.3 494000 114959.0; 14:37:03.729 INFO ProgressMeter - chr1:244961323 4.5 518000 116032.5; 14:37:09.228 INFO CalibrateDragstrModel - Shutting down engine; [April 17, 2021 2:37:09 PM EDT] org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel done. Elapsed time: 4.58 minutes.; Runtime.totalMemory()=2153775104; java.lang.IllegalArgumentException: Start cannot exceed end.; at htsjdk.samtools.util.IntervalTree.put(IntervalTree.java:74); at htsjdk.samtools.util.IntervalTree.merge(IntervalTree.java:137); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel$ShardReadBuffer.add(CalibrateDragstrModel.java:949); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel$1.tryAdvance(CalibrateDragstrModel.java:798); at java.util.Spliterator.forEachRemaining(Spliterator.java:326); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.collectCaseStatsSequencial(CalibrateDragstrModel.java:459); at org.broadinstitute.hellbender.tools.dragstr.CalibrateDragstrModel.traverse(CalibrateDragstrModel.java:159); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1058); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitut",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7182#issuecomment-821876394:5480,wrap,wrapAndCopyInto,5480,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7182#issuecomment-821876394,1,['wrap'],['wrapAndCopyInto']
Integrability,"5:51 INFO TaskSetManager:54 - Lost task 1.1 in stage 0.0 (TID 4) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 1]; 2019-01-09 13:35:52 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 6, scc-q01.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:52 WARN TaskSetManager:66 - Lost task 7.0 in stage 0.0 (TID 3, scc-q01.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 2, start 131325815, span 181534, expected MD5 c240a972d49aa89fb57dae94d1d90d36; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:29101,Wrap,Wrappers,29101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Wrap'],['Wrappers']
Integrability,"6 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 104.303087949; 23:24:11.546 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 78.48 sec; 23:24:11.553 INFO Mutect2 - Shutting down engine; [October 5, 2021 11:24:11 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 172.32 minutes.; Runtime.totalMemory()=4052746240; java.lang.IndexOutOfBoundsException: Index: 0, Size: 0; at java.util.ArrayList.rangeCheck(ArrayList.java:657); at java.util.ArrayList.get(ArrayList.java:433); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.lambda$getGermlineAltAlleleFrequencies$27(SomaticGenotypingEngine.java:352); at java.util.stream.ReferencePipeline$6$1.accept(ReferencePipeline.java:244); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:546); at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); at java.util.stream.DoublePipeline.toArray(DoublePipeline.java:530); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.getGermlineAltAlleleFrequencies(SomaticGenotypingEngine.java:354); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.getNegativeLogPopulationAFAnnotation(SomaticGenotypingEngine.java:337); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:155); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:259); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:306); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:200); at org.broadinstitute.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7494#issuecomment-936771625:1228,wrap,wrapAndCopyInto,1228,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7494#issuecomment-936771625,1,['wrap'],['wrapAndCopyInto']
Integrability,6); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.regenotypeVC(GenotypeGVCFs.java:222); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:201); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:151); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase$$Lambda$91/1033850902.accept(Unknown Source); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:149); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:984); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); Using GATK jar /gatk/gatk-package-4.0.6.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsa,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-612103255:3658,wrap,wrapAndCopyInto,3658,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-612103255,1,['wrap'],['wrapAndCopyInto']
Integrability,64); 	at org.broadinstitute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70); 	at org.broadinstitute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70); 	at org.broadinstitute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70); 	at org.broadinstitute.hellbender.engine.filters.ReadFilter$ReadFilterAnd.test(ReadFilter.java:70); 	at org.broadinstitute.hellbender.engine.filters.WellformedReadFilter.test(WellformedReadFilter.java:77); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.lambda$getReads$e4b35a40$1(GATKSparkTool.java:213); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool$$Lambda$93/2063469002.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:76); 	at org.apache.spark.api.java.JavaRDD$$anonfun$filter$1.apply(JavaRDD.scala:76); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at scala.collection.convert.Wrappers$IteratorWrapper.hasNext(Wrappers.scala:30); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn.lambda$apply$5412c5cb$1(ApplyBQSRSparkFn.java:22); 	at org.broadinstitute.hellbender.tools.spark.transforms.ApplyBQSRSparkFn$$Lambda$214/1243271334.call(Unknown Source); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:152); 	at,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749:2067,Wrap,Wrappers,2067,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3686#issuecomment-337554749,1,['Wrap'],['Wrappers']
Integrability,"673 INFO FilterMutectCalls - Done initializing engine; 10:00:21.734 INFO ProgressMeter - Starting traversal; 10:00:21.734 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 10:00:22.290 INFO FilterMutectCalls - Shutting down engine; [March 7, 2018 10:00:22 AM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=934805504; org.broadinstitute.hellbender.exceptions.GATKException: INFO annotation 'MFRL' contains a non-int value '2.1472e+08'; 	at org.broadinstitute.hellbender.utils.GATKProtectedVariantContextUtils.lambda$attributeValueToIntArray$1(GATKProtectedVariantContextUtils.java:134); 	at java.util.stream.ReferencePipeline$4$1.accept(ReferencePipeline.java:210); 	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); 	at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); 	at java.util.stream.IntPipeline.toArray(IntPipeline.java:502); 	at org.broadinstitute.hellbender.utils.GATKProtectedVariantContextUtils.attributeValueToIntArray(GATKProtectedVariantContextUtils.java:154); 	at org.broadinstitute.hellbender.utils.GATKProtectedVariantContextUtils.getAttributeAsIntArray(GATKProtectedVariantContextUtils.java:81); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.getIntArrayTumorField(Mutect2FilteringEngine.java:235); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyMedianFragmentLengthDifferenceFilter(Mutect2FilteringEngine.java:106); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:228); 	at org.broadinstitute.hellbender.tools.walkers.mu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787:3702,wrap,wrapAndCopyInto,3702,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787,1,['wrap'],['wrapAndCopyInto']
Integrability,6ua35lyn7h1u9v2n/gradle-3.1'.; 	at org.gradle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:31); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:108); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); org.gradle.api.internal.classpath.UnknownModuleException: Cannot locate JAR for module 'ant' in distribution directory '/home/travis/.gradle/wrapper/dists/gradle-3.1-bin/37qejo6a26ua35lyn7h1u9v2n/gradle-3.1'.; 	at org.gradle.api.internal.classpath.DefaultModuleRegistry.getExternalModule(DefaultModuleRegistry.java:69); 	at org.gradle.api.internal.DefaultClassPathProvider.findClassPath(DefaultClassPathProvider.java:46); 	at org.gradle.api.internal.DefaultClassPathRegistry.getClassPath(DefaultClassPathRegistry.java:34); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:48); 	at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:37); 	at org.gradle.launcher.GradleMain.main(GradleMain.java:23); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482:1236,Wrap,WrapperExecutor,1236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5194#issuecomment-422122482,1,['Wrap'],['WrapperExecutor']
Integrability,7 <0> (ø)` | :arrow_down: |; | [...bender/tools/walkers/annotator/PossibleDeNovo.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9Qb3NzaWJsZURlTm92by5qYXZh) | `73.214% <61.905%> (-2.976%)` | `23 <5> (+9)` | |; | [...er/tools/walkers/annotator/PedigreeAnnotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9QZWRpZ3JlZUFubm90YXRpb24uamF2YQ==) | `89.189% <84.211%> (-6.463%)` | `13 <4> (+5)` | |; | [...ct/CreateSomaticPanelOfNormalsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9DcmVhdGVTb21hdGljUGFuZWxPZk5vcm1hbHNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `3.448% <0%> (-96.552%)` | `2% <0%> (-1%)` | |; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.563% <0%> (-95.313%)` | `1% <0%> (-6%)` | |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `0% <0%> (-95.238%)` | `0% <0%> (-5%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <0%> (-90.741%)` | `0% <0%> (-13%)` | |; | ... and [220 more](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-462850860:3541,Integrat,IntegrationUtils,3541,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-462850860,1,['Integrat'],['IntegrationUtils']
Integrability,"8.2; 23:10:12.683 INFO CountReadsSpark - Picard Version: 2.18.25; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:10:12.684 INFO CountReadsSpark - Deflater: IntelDeflater; 23:10:12.684 INFO CountReadsSpark - Inflater: IntelInflater; 23:10:12.684 INFO CountReadsSpark - GCS max retries/reopens: 20; 23:10:12.684 INFO CountReadsSpark - Requester pays: disabled; 23:10:12.684 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 23:10:12.685 INFO CountReadsSpark - Initializing engine; 23:10:12.685 INFO CountReadsSpark - Done initializing engine; 19/02/05 23:10:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 19/02/05 23:10:15 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 19/02/05 23:10:18 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 806177853; 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(6,WrappedArray()); 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(13,WrappedArray()); 23:11:51.429 INFO CountReadsSpark - Shutting down engine; [February 5, 2019 11:11:51 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 1.67 minutes.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912:6011,Wrap,WrappedArray,6011,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912,2,['Wrap'],['WrappedArray']
Integrability,"834861e7ae) [duplicate 3]; 2019-01-09 13:35:56 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job; 2019-01-09 13:35:56 INFO YarnScheduler:54 - Cancelling stage 0; 2019-01-09 13:35:56 INFO YarnScheduler:54 - Stage 0 was cancelled; 2019-01-09 13:35:56 INFO DAGScheduler:54 - ResultStage 0 (count at CountReadsSpark.java:80) failed in 12.543 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:33839,Wrap,Wrappers,33839,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Wrap'],['Wrappers']
Integrability,"8cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredS",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1225,wrap,wrapper,1225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['wrap'],['wrapper']
Integrability,"92a29f6d7d6fcaf8dde06834861e7ae) [duplicate 3]; 2019-01-09 13:35:56 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job; 2019-01-09 13:35:56 INFO YarnScheduler:54 - Cancelling stage 0; 2019-01-09 13:35:56 INFO YarnScheduler:54 - Stage 0 was cancelled; 2019-01-09 13:35:56 INFO DAGScheduler:54 - ResultStage 0 (count at CountReadsSpark.java:80) failed in 12.543 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:33805,Wrap,Wrappers,33805,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Wrap'],['Wrappers']
Integrability,93YWxrZXJzL3Zxc3IvVHJhbmNoZU1hbmFnZXIuamF2YQ==) | `67.347% <0%> (-2.983%)` | `18% <0%> (+3%)` | |; | [...hellbender/utils/haplotype/HaplotypeBAMWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oYXBsb3R5cGUvSGFwbG90eXBlQkFNV3JpdGVyLmphdmE=) | `97.531% <0%> (-0.546%)` | `15% <0%> (+5%)` | |; | [...kers/haplotypecaller/AssemblyBasedCallerUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHMuamF2YQ==) | `68.595% <0%> (-0.092%)` | `29% <0%> (+5%)` | |; | [...r/transformers/BaseQualityClipReadTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQmFzZVF1YWxpdHlDbGlwUmVhZFRyYW5zZm9ybWVyLmphdmE=) | `100% <0%> (ø)` | `19% <0%> (+5%)` | :arrow_up: |; | [...hellbender/utils/haplotype/SAMFileDestination.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oYXBsb3R5cGUvU0FNRmlsZURlc3RpbmF0aW9uLmphdmE=) | `100% <0%> (ø)` | `6% <0%> (+3%)` | :arrow_up: |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <0%> (ø)` | `11% <0%> (?)` | |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <0%> (ø)` | `12% <0%> (?)` | |; | ... and [14 more](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3398#issuecomment-319512377:3668,Adapter,AdapterTrimTransformer,3668,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3398#issuecomment-319512377,1,['Adapter'],['AdapterTrimTransformer']
Integrability,"96/76560439-85638880-6477-11ea-8d8d-f0f9a11d70a6.png). We can compare against the new workflow, in which we run SegmentJointSamples to jointly segment on the two mixtures. This yields a joint-sample segmentation with 162 segments, which can be passed as an additional input to individual ModelSegments runs on the two mixtures. It is used as the initial segmentation for both runs, after which the usual modelling and smoothing steps are performed. For the 75% tumor + 25% normal mixture, this yields 122 segments (up from 83):; ![N-25-T-75-SJS modeled](https://user-images.githubusercontent.com/11076296/76558618-015bd180-6474-11ea-996a-48d39770149b.png). For the 25% tumor + 75% normal mixture, this yields 105 segments (up from 50):; ![N-75-T-25-SJS modeled](https://user-images.githubusercontent.com/11076296/76560726-34a05f80-6478-11ea-9027-a54726c46b9e.png). One could imagine that smoothing could be disabled (so that all samples retain the common segmentation after modeling) or made more aggressive (so that private events don't get inadvertently introduced into other samples due to noise, perhaps), depending on the use case. It looks like the joint segmentation allows some additional events to be resolved, although I haven't done any rigorous evaluations. We could probably cook up some evaluations using simulated toy data or in silico mixtures, but there's really no reason why this shouldn't work decently well, especially if the kernel-segmentation method works well on a single sample for your data. It would also be interesting to understand at which point changing segmentation parameters on a single sample can no longer yield the same performance as joint segmentation on a fixed number of samples; however, this is probably a function of various S/N ratios, and it might not be easy to characterize this behavior outside of toy data. The segmentation parameter space is big enough to make this unwieldy even for toy data, too. Perhaps we can get some feedback from test users-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-598386823:1859,depend,depending,1859,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6499#issuecomment-598386823,2,['depend'],['depending']
Integrability,: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1435,wrap,wrapper,1435,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['wrap'],['wrapper']
Integrability,":+1: on this one from me, although I think we should eventually move away from use of `IntegrationTestSpec`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-245957788:87,Integrat,IntegrationTestSpec,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-245957788,1,['Integrat'],['IntegrationTestSpec']
Integrability,":34:09 INFO TaskSetManager:54 - Lost task 3.1 in stage 0.0 (TID 4) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d) [duplicate 1]; 2019-01-07 11:34:10 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 7, scc-q12.scc.bu.edu, executor 2, partition 2, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:10 WARN TaskSetManager:66 - Lost task 9.0 in stage 0.0 (TID 5, scc-q12.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 3, start 97885291, span 192458, expected MD5 ef90368731b6e0be845bc82cd92b0c6a; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:30265,Wrap,Wrappers,30265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Wrap'],['Wrappers']
Integrability,":38 2023 -0500. minor pymc/pytensor version upgrades, fix 2-interval edge case, update some theano docs. commit 9c9d0c570dd2712631739e0a9d41e90c4ccd3456; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 23:36:55 2023 -0500. update VETS expected, verbose conda env create, pin torch CPU MKL, add pysam, fixed more tests. commit c0a17dfcf9fa1139927570d2f16125bc15a2c19f; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 20:07:08 2023 -0500. fix CNV plotting. commit dd2dd503a92e6fbb5a49be6a88d2e813eb8bf85b; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 15:14:08 2023 -0500. update gCNV expected results, generated on WSL Ubuntu 20.04.2. commit 27d76e8f22d61df90eeb337e033ae128ce07ab90; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 14:53:04 2023 -0500. update python env integration tests. commit 348df9192235f7d1ea941d0b31e5c96acc0d6491; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 10:59:23 2023 -0500. disable CNN tests, add deprecation message. commit ed59372b4be226785af1d3fb1b1a39a9ad3b4f6a; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 09:55:24 2023 -0500. clean up rebase. commit 18e530db26f803ee46a0006843cb36d4ed4194b4; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 11:31:46 2023 -0500. postprocess fixed. commit f510c2e9f10d7066c15f1835669d676964b8a4cb; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 10:13:01 2023 -0500. fix deprecated np.int in optimizer. commit 939a032f356f2f8f67b5aae426fc427d1d1ea6c4; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:50:57 2023 -0500. remove unnecessary seeding in cohort denoising script. commit cf82ea5c99250f1784f8b1a9279e7dbb8841fa89; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:38:08 2023 -0500. add back setup.py files. commit 8348f546de6b3d32e1f02f6851730226c0dbffc9; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:37:09 2023 -0500. update pymc version in init. commit 85",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1854434322:1622,message,message,1622,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1854434322,1,['message'],['message']
Integrability,":39:44 INFO org.spark_project.jetty.server.Server: Started @3988ms; 17/11/27 20:39:44 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@7fbe38a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 17/11/27 20:39:44 INFO com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.1-hadoop2; 17/11/27 20:39:45 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at droazen-test-cluster-m/10.240.0.10:8032; 17/11/27 20:39:47 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1511814592376_0002; 17/11/27 20:39:52 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@7fbe38a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 20:39:52.363 INFO CountReadsSpark - Shutting down engine; [November 27, 2017 8:39:52 PM UTC] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.16 minutes.; Runtime.totalMemory()=630718464; code: 0; message: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:340); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:197); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:194); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:89); 	at com.google.cloud.RetryHelper.run(RetryHelper.java:74); 	at com.google.cloud.RetryHelper.runWithRetries(Ret",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994:5672,message,message,5672,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3855#issuecomment-347320994,1,['message'],['message']
Integrability,":49.226 INFO GenomicsDBImport - Done importing batch 2/5; 23 Feb 2022 18:26:19,107 DEBUG: 	18:26:19.105 INFO GenomicsDBImport - Done importing batch 3/5; 23 Feb 2022 19:20:18,500 DEBUG: 	19:20:18.478 INFO GenomicsDBImport - Done importing batch 4/5; 24 Feb 2022 16:51:19,017 DEBUG: 	[TileDB::utils] Error: (gzip_handle_error) Cannot decompress with GZIP: inflateInit error: Z_MEM_ERROR; 24 Feb 2022 16:51:19,048 DEBUG: 	[TileDB::Codec] Error: Could not decompress with GZIP.; 24 Feb 2022 16:51:19,056 DEBUG: 	[TileDB::ReadState] Error: Cannot decompress tile for /home/exacloud/gscratch/prime-seq/workDir/0950f56b-7565-103a-a738-f8f3fc8675d2/Job2.work/WGS_1852_consolidated.gdb/2$1$196197964/__e7217c9e-767d-4295-b75a-9162c22c6996139785909643008_1613563029631/END.tdb.; 24 Feb 2022 16:51:51,388 DEBUG: 	16:51:51.388 erro NativeGenomicsDB - pid=225263 tid=225739 VariantStorageManagerException exception : Error while consolidating TileDB array 2$1$196197964; 24 Feb 2022 16:51:51,405 DEBUG: 	TileDB error message : ; 24 Feb 2022 16:51:51,412 DEBUG: 	terminate called after throwing an instance of 'VariantStorageManagerException'; 24 Feb 2022 16:51:51,419 DEBUG: 	 what(): VariantStorageManagerException exception : Error while consolidating TileDB array 2$1$196197964; 24 Feb 2022 16:51:51,427 DEBUG: 	TileDB error message : ; 24 Feb 2022 16:52:27,478 WARN : 	process exited with non-zero value: 134; ```. Does that give anything to suggest troubleshooting steps?. The full command is:; ```; /home/exacloud/gscratch/prime-seq/java/java8/bin/java \; 	Xmx497g -Xms497g -Xss2m \; 	-jar /home/exacloud/gscratch/prime-seq/bin/GenomeAnalysisTK4.jar \; 	GenomicsDBImport \; 	-V 25780.g.vcf.gz \; 	-V <total of 92 gVCFs> \; 	--genomicsdb-update-workspace-path WGS_1852_consolidated.gdb \; 	--batch-size 10 \; 	--reader-threads 12 \; 	--consolidate \; 	--genomicsdb-shared-posixfs-optimizations \; 	--bypass-feature-reader \; 	-R 128_Mmul_10.fasta; ```. this is GATK v4.2.5.0. Thanks i advance for any ideas.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1050434022:2063,message,message,2063,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1050434022,2,['message'],['message']
Integrability,; 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverseVariants(MultiplePassVariantWalker.java:75); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitute.hellbender.Main.main(Main.java:292); Caused by: java.util.concurrent.ExecutionException: org.broadinstitute.hellbender.exceptions.GATKException: Expected message of length 3 but only found 0 bytes; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at org.broadinstitute.hellbender.utils.runtime.StreamingProcessController.waitForAck(StreamingProcessController.java:228); 	... 26 more; Caused by: org.broadinstitute.hellbender.exceptions.GATKException: Expected message of length 3 but only found 0 bytes; 	at org.broadinstitute.hellbender.utils.runtime.StreamingProcessController.getBytesFromStream(StreamingProcessController.java:261); 	at org.broadinstitute.hellbender.utils.runtime.StreamingProcessController.lambda$waitForAck$0(StreamingProcessController.java:208); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). but if I change memory as below: it works. ; qlogin -l s_vmem=20G -l mem_req=20G,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7397#issuecomment-895854147:3928,message,message,3928,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7397#issuecomment-895854147,1,['message'],['message']
Integrability,"; Date: Wed Dec 13 00:14:34 2023 -0500. staged base rc1. commit 74f8fa724dfac142ccd7ac79a757c0e5ac3bb06c; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Wed Dec 13 00:01:38 2023 -0500. minor pymc/pytensor version upgrades, fix 2-interval edge case, update some theano docs. commit 9c9d0c570dd2712631739e0a9d41e90c4ccd3456; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 23:36:55 2023 -0500. update VETS expected, verbose conda env create, pin torch CPU MKL, add pysam, fixed more tests. commit c0a17dfcf9fa1139927570d2f16125bc15a2c19f; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 20:07:08 2023 -0500. fix CNV plotting. commit dd2dd503a92e6fbb5a49be6a88d2e813eb8bf85b; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 15:14:08 2023 -0500. update gCNV expected results, generated on WSL Ubuntu 20.04.2. commit 27d76e8f22d61df90eeb337e033ae128ce07ab90; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 14:53:04 2023 -0500. update python env integration tests. commit 348df9192235f7d1ea941d0b31e5c96acc0d6491; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 10:59:23 2023 -0500. disable CNN tests, add deprecation message. commit ed59372b4be226785af1d3fb1b1a39a9ad3b4f6a; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Tue Dec 12 09:55:24 2023 -0500. clean up rebase. commit 18e530db26f803ee46a0006843cb36d4ed4194b4; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 11:31:46 2023 -0500. postprocess fixed. commit f510c2e9f10d7066c15f1835669d676964b8a4cb; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 10:13:01 2023 -0500. fix deprecated np.int in optimizer. commit 939a032f356f2f8f67b5aae426fc427d1d1ea6c4; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:50:57 2023 -0500. remove unnecessary seeding in cohort denoising script. commit cf82ea5c99250f1784f8b1a9279e7dbb8841fa89; Author: Samuel Lee <lee.samuel.k@gmail.com>; Date: Fri Dec 8 09:38:08 2023 -0500. add back setup.py file",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1854434322:1436,integrat,integration,1436,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1854434322,1,['integrat'],['integration']
Integrability,"; and indicate how each API function is affected by this. If certain ; methods behave differently, then people writing code against SAMRecord ; need to anticipate this; and existing code may need to be updated. In other words, headerless ; SAMRecords should become ""part of the spec"". Third, although I don't know in detail about the different execution ; environments you are trying to support, there is a general strategy that ; I haven't seen discussed in these threads.; Perhaps it's impractical, but I'll mention it anyway. It seems like ; another approach would be to create (internal to the implementation) a ; ""header tag"" that could be efficiently serialized; and passed as part of the SAMRecord when you need to distribute it. The ; header tag could be used by the receiver to reattach the SAMRecord to ; its header (either proactively or on demand), but transparently to ; application code that is running against the SAMRecord API.; This would allow SAM headers to be transmitted out-of-band in a way that ; depends on the execution environment. Depending on the environment, ; this might be done by proactive broadcast, or you could think of the ; header tag as a promise to retrieve the header if/when it is needed. ; The size and complexity of the header tag might also depend on the ; execution environment. If the execution environment only supports a ; small finite number of headers, the header tag could be a small integer, ; or in a different execution environment it could be; a unique hash of the header or something like that. Memory footprint in ; the receiver is minimized because many SAMRecords can all share the same ; header object.; This requires more work to support in each execution environment, but it ; seems like it could be efficient and allows application code written to ; operate on SAMRecords to be portable; across different execution environments without having to contend with ; the possible presence of headerless SAMRecords. -Bob. On 9/17/15 4:28 PM, dr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141451518:1773,depend,depends,1773,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141451518,1,['depend'],['depends']
Integrability,"; at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:50 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 4, scc-q20.scc.bu.edu, executor 2, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:50 WARN TaskSetManager:66 - Lost task 4.0 in stage 0.0 (TID 2, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:26910,Wrap,Wrappers,26910,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Wrap'],['Wrappers']
Integrability,"; chr8; chr9; chr10; chr11; chr12; chr13; chr14; chr15; chr16; chr17; chr18; chr20; chr19; chr22; chr21; ```; and my reference file:; ```; zcat hg19.fa.gz|grep '>'; >chr1; >chr2; >chr3; >chr4; >chr5; >chr6; >chr7; >chrX; >chr8; >chr9; >chr10; >chr11; >chr12; >chr13; >chr14; >chr15; >chr16; >chr17; >chr18; >chr20; >chrY; >chr19; >chr22; >chr21; >chr6_ssto_hap7; >chr6_mcf_hap5; >chr6_cox_hap2; >chr6_mann_hap4; >chr6_apd_hap1; >chr6_qbl_hap6; >chr6_dbb_hap3; >chr17_ctg5_hap1; >chr4_ctg9_hap1; >chr1_gl000192_random; >chrUn_gl000225; >chr4_gl000194_random; >chr4_gl000193_random; >chr9_gl000200_random; >chrUn_gl000222; >chrUn_gl000212; >chr7_gl000195_random; >chrUn_gl000223; >chrUn_gl000224; >chrUn_gl000219; >chr17_gl000205_random; >chrUn_gl000215; >chrUn_gl000216; >chrUn_gl000217; >chr9_gl000199_random; >chrUn_gl000211; >chrUn_gl000213; >chrUn_gl000220; >chrUn_gl000218; >chr19_gl000209_random; >chrUn_gl000221; >chrUn_gl000214; >chrUn_gl000228; >chrUn_gl000227; >chr1_gl000191_random; >chr19_gl000208_random; >chr9_gl000198_random; >chr17_gl000204_random; >chrUn_gl000233; >chrUn_gl000237; >chrUn_gl000230; >chrUn_gl000242; >chrUn_gl000243; >chrUn_gl000241; >chrUn_gl000236; >chrUn_gl000240; >chr17_gl000206_random; >chrUn_gl000232; >chrUn_gl000234; >chr11_gl000202_random; >chrUn_gl000238; >chrUn_gl000244; >chrUn_gl000248; >chr8_gl000196_random; >chrUn_gl000249; >chrUn_gl000246; >chr17_gl000203_random; >chr8_gl000197_random; >chrUn_gl000245; >chrUn_gl000247; >chr9_gl000201_random; >chrUn_gl000235; >chrUn_gl000239; >chr21_gl000210_random; >chrUn_gl000231; >chrUn_gl000229; >chrM; >chrUn_gl000226; >chr18_gl000207_random; ```; So there is no contig in the SAM file itself that is not included in the reference. But I pre-filtered my SAM file using samtools, but there are some contigs in the header of SAM that does not exist in the reference. So it seems that this message comes from the header? I can also use the original reference used for mapping, which also contains e. coli genome.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6783#issuecomment-684119509:2035,message,message,2035,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783#issuecomment-684119509,1,['message'],['message']
Integrability,<https://github.com/broadinstitute/gatk/issues/3853> is dependent on this issue.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2596#issuecomment-346106885:56,depend,dependent,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2596#issuecomment-346106885,1,['depend'],['dependent']
Integrability,====================; Files 1058 1057 -1 ; Lines 59682 59712 +30 ; Branches 9712 9723 +11 ; ===============================================; + Hits 46584 46879 +295 ; + Misses 9349 9078 -271 ; - Partials 3749 3755 +6; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4152?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...hellbender/utils/linalg/FourierLinearOperator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9saW5hbGcvRm91cmllckxpbmVhck9wZXJhdG9yLmphdmE=) | `78.378% <ø> (ø)` | `12 <0> (ø)` | :arrow_down: |; | [...bender/utils/GATKProtectedVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HQVRLUHJvdGVjdGVkVmFyaWFudENvbnRleHRVdGlscy5qYXZh) | `65.746% <0%> (ø)` | `61 <0> (ø)` | :arrow_down: |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `95.238% <100%> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...bender/tools/walkers/annotator/StrandArtifact.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TdHJhbmRBcnRpZmFjdC5qYXZh) | `100% <100%> (ø)` | `29 <0> (ø)` | :arrow_down: |; | [...llbender/tools/walkers/annotator/ReadPosition.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9SZWFkUG9zaXRpb24uamF2YQ==) | `100% <100%> (ø)` | `8 <2> (ø)` | :arrow_down: |; | [...s/copynumber/models/AlleleFractionLikelihoods.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4152#issuecomment-357485658:1571,Integrat,IntegrationUtils,1571,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4152#issuecomment-357485658,1,['Integrat'],['IntegrationUtils']
Integrability,> * `gatk_override`. this will need to be a parameter (but can be optional and have a default) in order to have our integration tests run `GvsJointVariantCalling.wdl` anyway. > * `interval_list`. this will need to be a parameter (but can be optional and have a default) in order to have our integration tests run `GvsJointVariantCalling.wdl` on exomes. > * `use_VQSR_lite`; > * `extract_do_not_filter_override`. these two will need to be a parameter (but can be optional and have a default) in order to have our integration tests run `GvsJointVariantCalling.wdl` with VQSR classic anyway. > * `filter_set_name`; > * `extract_table_prefix`. these two can just default to the `call_set_identifier` with weird characters parsed out,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1634174283:116,integrat,integration,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1634174283,3,['integrat'],['integration']
Integrability,"> > I've manually kicked off our integration tests on this branch. If that passes (it should take a couple of hours), I'll give this a thumb.; > ; > SG! I also pushed this to Agora and will test it out using our genomic extraction workflow. our error is resolved with this PR",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9023#issuecomment-2447390883:33,integrat,integration,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9023#issuecomment-2447390883,1,['integrat'],['integration']
Integrability,"> @Siadjeu Don't worry about the ""Failed to detect"" message. It indicates some internal state in one of the google libraries but not an error we need to worry about. Generally you shouldn't worry about INFO messages if everything else is going fine and they don't say something particular about what you're doing. A WARNING or ERROR message would indicate a problem. This should maybe be downgraded to be a DEBUG level message or something but it's in a third library and convincing them to change it might be a hassle. Although there are results, but the size of the results is wrong, the results are too small.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-1598239834:52,message,message,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-1598239834,4,['message'],"['message', 'messages']"
Integrability,"> @colinhercus I was able to re-run your command successfully on the latest master branch (not in a release yet). I believe PR #6240 fixed the issue. @Rohit-Satyam @danielecook there's a good chance the errors you encountered are also fixed. If not, please let me know. In reference to your reply, I wish to inform you the problem still stands. > java.lang.IllegalArgumentException: Cannot construct fragment from more than two reads; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:725); at org.broadinstitute.hellbender.utils.read.Fragment.create(Fragment.java:36); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1376); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods.groupEvidence(AlleleLikelihoods.java:595); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:93); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:251); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:320); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:308); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:281); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLinePro",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-595805643:860,wrap,wrapAndCopyInto,860,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6230#issuecomment-595805643,1,['wrap'],['wrapAndCopyInto']
Integrability,"> Can has! Please ignore the confusingness of the branch name 🙈; > https://job-manager.dsde-prod.broadinstitute.org/jobs/245e1b69-a628-41c0-8e64-ebd3ae37ce30. Sorry if this is a dumb question, but how do I verify that the new image is being used since we can't see the WDLs of the subworkflows that are being called by the integration WDL?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8085#issuecomment-1307363971:323,integrat,integration,323,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8085#issuecomment-1307363971,1,['integrat'],['integration']
Integrability,"> Chris Norman. >Well, its a fair amount of work to do in the current htsjdk (there are some details in the ticket.). We recently have been discussing some possible options, but right now there is no work scheduled. If its an isue for you I’d suggest updating the ticket so we can keep track of how much demand there is for it. Consider this me updating the ticket because my key software depends on parsing VCFs with this API.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2602#issuecomment-476776569:389,depend,depends,389,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2602#issuecomment-476776569,1,['depend'],['depends']
Integrability,"> GATK depends on gradle 3.1.: download shaw256. It currently works with gradle-4.6, no need to go back to 3.1.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444210781:7,depend,depends,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444210781,1,['depend'],['depends']
Integrability,"> Hey @ccartermices. Looking at that error message it appears that the genotype given alleles has tried to insert a '*' allele into an assembled haplotype. (""TTTTGAC*TTCGC"" in the error message). I suspect this is because the code is missing a check to filter symbolic alleles out of GGA inputs. Can you check your input `db_raw_call_bbe_6largest.vcf` for `\*` alleles? It should be possible to filter those out of your input file. Thanks，if i want to make a filter on it, should i use which tool? VQSR?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6260#issuecomment-553776381:43,message,message,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6260#issuecomment-553776381,2,['message'],['message']
Integrability,"> How can I install GATK4 successful?. If you just want to install (as opposed to build), you can download a [release .zip or .tar](https://github.com/broadinstitute/gatk/releases) directly. If you want to build, then as @magicDGS suggested, you need to have git-lfs installed. If you already have that, I would try manually running the command `git lfs pull --include src/main/resources/large` from the root of the repo clone and see if you get a more detailed failure message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4669#issuecomment-382363528:470,message,message,470,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4669#issuecomment-382363528,1,['message'],['message']
Integrability,> I also encounter this error when most samples have been imported. I ran importing in batches '--batch-size 50 --consolidate '. The error occured at the last batch. Can I reuse some of the imported data files or have to rerun the whole importing again?. ...; 13:13:26.069 INFO GenomicsDBImport - Done importing batch 21/22; 13:13:26.069 INFO GenomicsDBImport - Starting batch input file preload; 13:13:27.440 INFO GenomicsDBImport - Finished batch preload; 13:13:27.440 INFO GenomicsDBImport - Importing batch 22 with 22 samples; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed.; terminate called after throwing an instance of 'VariantStorageManagerException'; what(): VariantStorageManagerException exception : Error while consolidating TileDB array chrY$1$57227415; TileDB error message : [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6519#issuecomment-641091886:890,message,message,890,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6519#issuecomment-641091886,1,['message'],['message']
Integrability,"> I have no objection to these changes, especially since this is just bringing us back to where we were in genomicsDB in the last release. We should spawn a ticket to track reintroducing these improvements and perhaps we should also add a macos test to our travis array so we can catch this kind of issue in the future? I think there is a macOS VM availible on travis that we could rerun some of the integration tests on. Yes, travis has macOS VM. It is very slow, so would recommend only sanity checks on it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6204#issuecomment-539574124:400,integrat,integration,400,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6204#issuecomment-539574124,1,['integrat'],['integration']
Integrability,"> I've manually kicked off our integration tests on this branch. If that passes (it should take a couple of hours), I'll give this a thumb. SG! I also pushed this to Agora and will test it out using our genomic extraction workflow",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9023#issuecomment-2447173093:31,integrat,integration,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9023#issuecomment-2447173093,1,['integrat'],['integration']
Integrability,"> In case mode you already have the filtered intervals, so why collect coverage over the full set?. Since coverage collection is relatively expensive, it's better to collect coverage over the same set of intervals for all samples just once and call it a day. Then we can run these samples in whatever mode we please, adjust filtering parameters, etc. in subsequent analyses without having to go back and recollect coverage at any point. > Also, in cnv_germline_case_workflow.wdl it really doesn't look like ploidy determination uses the filtered intervals. Are the intervals wrapped into the model tar there too? If that's true, then that should be documented somewhere. Yup, that's correct. Added some more docs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5307#issuecomment-431494002:575,wrap,wrapped,575,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5307#issuecomment-431494002,1,['wrap'],['wrapped']
Integrability,"> In this case, allele-specific annotations are outputted to GVCFs files by 'HaplotypeCaller -ERC GVCF -G AS_StandardAnnotation' command.; > ; > Although some warning message of 'HaplotypeCaller -ERC GVCF -G AS_StandardAnnotation' command.; > ; > ```; > WARN:StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; > ```; > ; > This warning message does not happen in all of my cases, but the FORMAT/AD error happen in all of my cases. hello , i met the warning message:; `DepthPerSampleHC - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null`; `WARN:StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null`. could you help me ? i just am a fresh . So i don't know what should i do next step and why it reported some warning messages. ; Thank you very much !",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4691#issuecomment-727523636:167,message,message,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4691#issuecomment-727523636,4,['message'],"['message', 'messages']"
Integrability,"> Is it possible to add an integration test to this? Since the change did not fail any test, it seems that the integrationtest is missing. Unit test fixed to include checking of variant type (which it did not include before - hence the non-failure). Test data adjusted accordingly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8442#issuecomment-1806779412:27,integrat,integration,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8442#issuecomment-1806779412,2,['integrat'],"['integration', 'integrationtest']"
Integrability,> Is there a successful integration run?. yes [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/6c033078-f6d3-47c8-926a-07176478823d),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8915#issuecomment-2245636330:24,integrat,integration,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8915#issuecomment-2245636330,1,['integrat'],['integration']
Integrability,"> Looks good. Have you run the integration tests. I didn't run the integration test because it didn't seem necessary (no changes that effect the data, just the table(s) TTL). If you think I should, happy to kick it off.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8595#issuecomment-1834388772:31,integrat,integration,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8595#issuecomment-1834388772,2,['integrat'],['integration']
Integrability,"> One final thing: i'm happy to try to debug this, and was going to write a test case based on the existing GenomicsDB integration tests. However, when I try to run any integration test involving genomicsdb, I get an exception like the following. I am on windows, so perhaps this is the issue?; > ; > 09:03:37.460 FATAL GenomicsDBLibLoader -; > java.io.FileNotFoundException: File /tiledbgenomicsdb.dll was not found inside JAR.; > at org.genomicsdb.GenomicsDBLibLoader.loadLibraryFromJar(GenomicsDBLibLoader.java:118) ~[genomicsdb-1.3.2.jar:?]; > at org.genomicsdb.GenomicsDBLibLoader.loadLibrary(GenomicsDBLibLoader.java:55) [genomicsdb-1.3.2.jar:?]; > at org.genomicsdb.GenomicsDBUtilsJni.(GenomicsDBUtilsJni.java:30) [genomicsdb-1.3.2.jar:?]; > at org.genomicsdb.GenomicsDBUtils.createTileDBWorkspace(GenomicsDBUtils.java:46) [genomicsdb-1.3.2.jar:?]; > at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.overwriteCreateOrCheckWorkspace(GenomicsDBImport.java:1005) [classes/:?]; > at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.onTraversalStart(GenomicsDBImport.java:661) [classes/:?]; > at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1056) [classes/:?]. Yes, Windows is not supported by GenomicsDB. This is mentioned obliquely in the requirements for gatk too -; ```; Operating system. The GATK runs natively on most if not all flavors of UNIX, which includes MacOSX, Linux and BSD. It is possible to get it ; running on some recent versions of Windows, but we don't provide any support nor instructions for that. If you need to run on; a Windows machine, consider using Docker.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7005#issuecomment-754106359:119,integrat,integration,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7005#issuecomment-754106359,2,['integrat'],['integration']
Integrability,> Those warning messages are totally fine. Not all variant contexts contain those 2 annotations therefore they are not counted against those sites but other parameters are counted. The results also shows that your filtering is working and variants are marked as expected. Thank you very much!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8964#issuecomment-2312349275:16,message,messages,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8964#issuecomment-2312349275,1,['message'],['messages']
Integrability,"> Your solution doesn't address your third listed drawback to the current; approach. Ah, but I believe it does if you're careful. We have this code:; ```; for ( final AssemblyResult result : assemble(correctedReads, refHaplotype, givenHaplotypes, header, aligner) ) {; if ( result.getStatus() == AssemblyResult.Status.ASSEMBLED_SOME_VARIATION ) {; // do some QC on the graph; sanityCheckGraph(result.getGraph(), refHaplotype);; // add it to graphs with meaningful non-reference features; assemblyResultByGraph.put(result.getGraph(),result);; nonRefGraphs.add(result.getGraph());; }; }. findBestPaths(nonRefGraphs, refHaplotype, refLoc, activeRegionExtendedLocation, assemblyResultByGraph, resultSet, aligner);; ```; If assembly fails eg due to cycles at every kmer then there's nothing to iterate over in the `for` loop but it still reaches `findBestPaths` (this puts assembled haplotypes into `resultSet` as a side effect, and it forces the reference haplotype in by fiat if there are no graphs). As long as the new GGA haplotypes are added after `findBestPaths` and not anywhere inside the `assemble` method or in that `for` loop it should be okay. Would you like me to write an integration test for this case?. > It's not obvious to me why we wanted the given alleles in the graph; originally. . . Regardless of the reason, I think the new proposal captures any benefit of putting them in the graph, because if they *are* in the graph it leaves them alone. If they're not in the graph, then we get a haplotype that's as close to the reference as possible, which is what the current code does. In such a case there's nothing gained by putting it in the graph. > I'd feel better if we had a better guess at what the original method was trying to do. Despite my optimism about theoretically beautiful things, me too. Who wrote the original GGA code?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479931906:1181,integrat,integration,1181,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479931906,1,['integrat'],['integration']
Integrability,"> actually it looks like there are legit failing tests. Yup, it looks like a hunk of the integration tests are operating in TSV mode (which we don't officially support any longer... but I suppose they can stay). So in order to make those pass, I had to put some things behind an explicit check for BQ being set as the output type",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8994#issuecomment-2457960879:89,integrat,integration,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8994#issuecomment-2457960879,1,['integrat'],['integration']
Integrability,"> do you have a run of the integration test for this branch?. Yup, [this run](https://app.terra.bio/#workspaces/broad-firecloud-dsde/VS-415%20GVS%20Quickstart%20Default%20Extract%20Scatter/job_history/ff9d7466-79f1-4c96-a7b9-dd2354dc1c76) utilized this `vs_464_update_quickstart_integration` branch to test the `vs_415_default_extract_scatter_width` changes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7881#issuecomment-1150403388:27,integrat,integration,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7881#issuecomment-1150403388,1,['integrat'],['integration']
Integrability,">--af_of_alleles_not_in_resource: is this allele frequency used only in certain contexts, e.g. with matched normal analyses, or towards tumor sample variant alleles, etc.? I need to add to the doc details how this argument factors into calculations. This is the population AF assigned to a variant not found in the germline resource and is inversely proportional to the number of samples used to create that resource. For example, gnomAD contains about 16,000 wgs samples, or 32,000 homologs per locus. Thus the AF of an allele not found in gnomAD is probably 1/32,000 or less. This is useful because it lets us use absence from the germline resource as evidence that an allele is *not* a germline variant. >I need a sentence or two describing the new algorithmic improvement on the new Mutect2 integration over uncertainty. Since allele depths (ADs) are subject to statistical error -- i.e. the exact number of reads for an allele is a random variable -- alleles' allele fractions are not known. Previously, M2 estimated allele fractions ffrom the ADs and proceeded with the likelihoods calculation. Now M2 uses nifty math to account for the uncertainty in the allele fraction when calculating likelihoods. In statistical language (which *will* be familiar to a decent-sized minority of users) we marginalize over allele fractions instead of using a maximum likelihood estimate. >The WDLs do not include use of a contamination.table and so I did not include it in the commands. Is this something we want to nudge users to use, i.e. should I put in a sentence in the documentation section about the new tool CalculateContamination?. `CalculateContamination` is invoked inside the `Filter` task in mutect2.wdl. We want users to use the new tool. You might mention that in the interest of speed you can pass it `-L 1` to use only variants on chromosome 1, which gives a very good estimate in a couple of minutes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2816#issuecomment-306107618:795,integrat,integration,795,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2816#issuecomment-306107618,1,['integrat'],['integration']
Integrability,">> interval_list. > this will need to be a parameter (but can be optional and have a default) in order to have our integration tests run GvsJointVariantCalling.wdl on exomes. Genomes too, the integration test specifies a 20/X/Y interval list. >> filter_set_name; >> extract_table_prefix. > these two can just default to the call_set_identifier with weird characters parsed out. Yeah I think that would work for the integration test(s), each variation goes into a different BQ dataset anyway. @RoriCremer can correct me if I'm wrong, but I thought the raison d'être of the beta WDL was specifically to hardcode away as many parameters as possible (even optional ones with defaults) to present a simplified interface for non-expert users. I agree we'll probably have to allow some additional parameters for testability (`gatk_override` at a minimum), but do we really want to add all of these?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1634248008:115,integrat,integration,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1634248008,8,"['integrat', 'interface']","['integration', 'interface']"
Integrability,">Integration test plz. Hmm, the existing integration test does not exercise `process_vcf_headers` so it wouldn't test these changes. However, in the spirit of ""the VDS integration tests should exercise what we intend to use for AoU"", perhaps at least the VDS integration tests should be modified to exercise this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8533#issuecomment-1739135880:1,Integrat,Integration,1,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8533#issuecomment-1739135880,4,"['Integrat', 'integrat']","['Integration', 'integration']"
Integrability,"@DanishIntizar Hello! Thank you for this pr. This is great to see an official plugin from amazon available. I appreciate that you took the time to make it an optional include. I think if we're going to include it we might as well just add it as one of our normal dependencies though. Assuming there aren't any dependency conflicts it **should** (always a risky statement) be independent from everything else. . Thanks also for identifying the different issues you mentioned. It's expected that it won't work with most picard tools as you discovered, but we're actively in the process of updating more of them too support Paths instead of Files so that will slowly improve. The second issue is more worrisome. We regularly use an equivalent provider with google to read reference files through the exact same code, so I suspect there is either some sort of mismatched assumptions in the way they are handling things. Maybe something strange with the Path.resolve methods or the like. (Or in in the much worse potential case a bug in their look ahead caching.). I'd like to look into that before we'd merge this. Ideally we would have tests for this. Are there any public AWS paths we could read from without any secret authentication?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8672#issuecomment-1930094721:263,depend,dependencies,263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8672#issuecomment-1930094721,2,['depend'],"['dependencies', 'dependency']"
Integrability,@DonFreed Both of these changes look more correct than what we were doing before. But as louis pointed out two of the integration tests failed on parsing the header. You should fix these tests.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324062155:118,integrat,integration,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324062155,1,['integrat'],['integration']
Integrability,"@DonFreed, I agree with @magicDGS's assessment about it. This feels like a fix that was applied to Gatk3 but doesn't translate to 4? Of course, there could be implementations of GATKRead that don't obey the given contract about copying, but it's worth fixing those since we were more careful to think about copy/no copy when we wrote the new interface. . Of note: if you haven't seen it, `GATKRead` provides a set of unsafe `getBaseQualitiesNoCopy()` methods for times when the copy is a performance bottleneck and you can guarantee safe use of the underlying array. . I'm going to close this. Feel free to reopen if you disagree / can provide a unit test that demonstrates the issue still exists.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4926#issuecomment-399219562:213,contract,contract,213,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4926#issuecomment-399219562,2,"['contract', 'interface']","['contract', 'interface']"
Integrability,"@EdwardDixon Isn't this a dupe of https://github.com/broadinstitute/gatk/pull/5142? Have you addressed our original concerns from that PR's discussion thread, some of which I've reproduced below?. ```; droazen commented on Aug 30; @EdwardDixon We have a fair number of GATK users who are stuck with older hardware (including; university clusters that they have no power to upgrade), and we can't just cut these users off by ; imposing such a minimum hardware requirement. The best we can do is to use AVX when it's ; available, and fall back to slower codepaths when it's not. Also, actual crashes in native code impose a significant support burden on our comms team, as they; are often hard to diagnose and deal with. Things like SIGSEGV or SIGILL are a nightmare for our ; support staff. At a minimum we'd need a graceful failure with an easy-to-understand error message; when AVX is not present rather than a crash, before we could make this the default in GATK. ldgauthier commented on Aug 30; Aside from the users with old hardware, very few of the GCS zones guarantee processors that ; support AVX, which would lead to sporadic failures except in central-1f, for example.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-428265950:865,message,message,865,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-428265950,1,['message'],['message']
Integrability,"@EdwardDixon Thanks for trying this - it would be great if we were able to have a single conda env, but a couple of questions:. - We'd need to understand the affect of this change on our build times. It looks like the travis builds are failing because the dependency downloads are resulting in so many progress messages that we're exceeding the allowable log length, probably because the download is either large or slow. I'm not sure if thats transient or not.; - We try to carefully control the size of our (already sizable) docker image. We'll need to understand how this impacts that.; - @lucidtronix Any thoughts on moving from tensorflow 1.4 to 1.9 ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-416943910:256,depend,dependency,256,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-416943910,2,"['depend', 'message']","['dependency', 'messages']"
Integrability,"@EdwardDixon We have a fair number of GATK users who are stuck with older hardware (including university clusters that they have no power to upgrade), and we can't just cut these users off by imposing such a minimum hardware requirement. The best we can do is to use AVX when it's available, and fall back to slower codepaths when it's not. Also, actual crashes in native code impose a significant support burden on our comms team, as they are often hard to diagnose and deal with. Things like `SIGSEGV` or `SIGILL` are a nightmare for our support staff. At a minimum we'd need a graceful failure with an easy-to-understand error message when AVX is not present rather than a crash, before we could make this the default in GATK.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-417383038:630,message,message,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-417383038,1,['message'],['message']
Integrability,"@EdwardDixon Well, you'd be surprised at some of the hardware we have to deal with. Even some machines here at the Broad don't have AVX. In general, our policy with hardware-dependent optimizations in GATK has been to insist on having a transparent fallback mechanism when the required hardware isn't present -- I'd really prefer not to start making exceptions to that rule. Could the Intel-optimized Tensorflow be patched to fall back to vanilla tensorflow when AVX is not present? Is that an option? Or could it at least be patched to not actually crash in that case?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-417073151:174,depend,dependent,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5142#issuecomment-417073151,1,['depend'],['dependent']
Integrability,"@Emmalynchen I wouldn't worry about the `log4j:WARN` messages discussed in this thread---they're just harmless annoyances that pop up because we haven't gotten around to making sure the HDF5Library dependency uses the same logger as the rest of the GATK. Looking at your initial post (before you edited it), it looks like DenoiseReadCounts is failing because the panel of normals contains different intervals than those in the read-count collection you are trying to denoise:. ```; 22:50:58.635 INFO SVDDenoisingUtils - Validating sample intervals against original intervals used to build panel of normals...; 22:50:59.487 INFO DenoiseReadCounts - Shutting down engine; [May 7, 2019 10:50:59 PM UTC] org.broadinstitute.hellbender.tools.copynumber.DenoiseReadCounts done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=894959616; java.lang.IllegalArgumentException: Sample intervals must be identical to the original intervals used to build the panel of normals.; ```. You might try asking for more pointers over in the GATK Forums (https://gatkforums.broadinstitute.org/gatk), if you need them. Good luck!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3763#issuecomment-491473550:53,message,messages,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3763#issuecomment-491473550,2,"['depend', 'message']","['dependency', 'messages']"
Integrability,"@Ismaelfermir The message about ""Flush-to-zero"" is normal, and not an error. The problem is likely that your BAM doesn't have read groups in its header, or if it does, those read groups may lack sample names.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4665#issuecomment-486384034:18,message,message,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4665#issuecomment-486384034,1,['message'],['message']
Integrability,@LeeTL1220 Added in a specific integration test for the `FILTER` field. Also rebased on master to fix the unrelated R test failures.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5598#issuecomment-456984341:31,integrat,integration,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5598#issuecomment-456984341,1,['integrat'],['integration']
Integrability,"@LeeTL1220 Can you review, or appoint someone to review, the Mutect2 WDL and the tools/exome and tools/picard/analysis/artifacts packages part of this. Basically, I replaced most of the classes in the artifacts package with their Picard analogs, which also affected some embedded class names in metrics files (SequencingArtifactMetrics IIRC). The are multiple commits in here that delete various things, but the substantive changes are the last commit (""Integrate actual Picard tools via Picard""). Also, once this is in, we'll probably want to do [this](https://github.com/broadinstitute/gatk/issues/3625) separately as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3620#issuecomment-332637122:454,Integrat,Integrate,454,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3620#issuecomment-332637122,1,['Integrat'],['Integrate']
Integrability,@LeeTL1220 Does GATK have a dependency on this change ? If so this will definitely need to be made in Picard as well since these GATK copies of the Picard tool are soon to be obsoleted.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3250#issuecomment-315760322:28,depend,dependency,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3250#issuecomment-315760322,1,['depend'],['dependency']
Integrability,"@LeeTL1220 I have a fast python implementation of the above. It'll take a little bit of additional code to make it output segment files. I can add that and start running some validation data, or I can just go ahead and start coding up the Java implementation, depending on how long you think it'll take to put together some validation runs up through DenoiseReadCounts. Do we want to improve the ReCapSegCaller behind CallSegments while we're at it? @davidbenjamin perhaps you can briefly remind me of the idea behind your initial caller and of the issues it had.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-324128827:260,depend,depending,260,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-324128827,1,['depend'],['depending']
Integrability,@LeeTL1220 I will merge now and open a separate ticket to update the multi sample wdl and all wdls that depend on it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3386#issuecomment-319074608:104,depend,depend,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3386#issuecomment-319074608,1,['depend'],['depend']
Integrability,"@LeeTL1220 Just noticed integration tests are failing...perhaps I should continue reviewing, and you can address comments and the tests at the same time?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4205#issuecomment-358979126:24,integrat,integration,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4205#issuecomment-358979126,1,['integrat'],['integration']
Integrability,"@LeeTL1220 OK, tweaked the message a bit. I think I'm OK with this going in for the next point release. This is the sort of thing for which it will be nice to have the automatic validations, as a sanity check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-363828979:27,message,message,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-363828979,1,['message'],['message']
Integrability,"@LeeTL1220 do you have any opinions on making the somatic CNV workflow scatter by contig? This could allow WGS to complete basically ~20x faster and could allow us to avoid issues such as #4734. A few issues:. 1) Do we want a single WDL that can optionally scatter, depending on WES vs. WGS? It would be nicer to have just one workflow, but I haven't thought about how an optional scatter might look in WDL. 2) For segmentation and modeling, scattering should have little impact on the final result (although there are a few global-level quantities in the models that would be reduced to contig-level quantities, which might slightly affect the quality of their inference). However, we'd want to concatenate all per-contig results for both plotting and segment calling. It'd be relatively easy to either have a separate tool to concatenate AbstractLocatableCollections (there is already a method to do this that is used for the gCNV pipeline), or to make the plotting and calling tools take in parallel inputs and combine them. I'd tend towards the former, just so we don't have to deliver per-contig files.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4728#issuecomment-386268150:266,depend,depending,266,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4728#issuecomment-386268150,1,['depend'],['depending']
Integrability,"@LeeTL1220 done. I put it in the M2 integration test because it is part of a bigger potential issue, that of phantom alleles from the likelihoods that don't make it into the variant call. Back to you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3636#issuecomment-333874263:36,integrat,integration,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3636#issuecomment-333874263,1,['integrat'],['integration']
Integrability,@LeeTL1220 reminds me that there is also some code for reading/writing intervals that I introduced that probably belongs in the wrapper as well.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-317834727:128,wrap,wrapper,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-317834727,1,['wrap'],['wrapper']
Integrability,"@MartonKN I've labeled the update of the caller as a ""reach"", so I'm not expecting that it gets done before release. However, I expect that the tutorial data should be updated well before release. The tutorial data runs quickly (~1 hr for coverage collection, which is mostly limited by the slowest samples or cloud preemptions, and then ~minutes once collection has been call cached), so we should have plenty of time. Whether or not the actual tutorial itself will be ready depends on whether @sooheelee has available bandwidth and if it is a high priority for comms.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3826#issuecomment-353730988:476,depend,depends,476,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3826#issuecomment-353730988,1,['depend'],['depends']
Integrability,"@MartonKN One more thing: the PR title is currently not very informative, so when you merge, be sure to write a descriptive commit message. These are very useful when we come out with release notes, among other things.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5489#issuecomment-444951052:131,message,message,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5489#issuecomment-444951052,1,['message'],['message']
Integrability,@NeginValizadegan For some reason you appear to be running very old Picard versions. This most recent error message you posted is coming from an even older version of Picard (`2.9.0-1-gf5b9f50-SNAPSHOT`) than the first one you posted (which you said was `2.10.1`). I would suggest upgrading to [2.27.5](https://github.com/broadinstitute/picard/releases).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419101274:108,message,message,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419101274,1,['message'],['message']
Integrability,"@NeginValizadegan Thanks for looking into it, and sorry you're still seeing the issue. . Is that error message from the 2.10.1 version? It doesn't line up with the code in 2.27.1 so either you're posting your original error, or you're not getting the version of picard you expect. Would it be possible to include the entire program log, and the command line to run it here?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414024739:103,message,message,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414024739,1,['message'],['message']
Integrability,"@SHuang-Broad . Nice hack using the cluster name. I don't see any other way to pass an arg to an initialization action. I have one suggestion to consider, but if you think it's too much work or not worth it feel free to skip: what if we separated out the reference bundle to copy from the data by specifying them both in the cluster name? That way we could, say, load either the hg19 or hg38 reference depending on the data we might be working with. So you could say ""cluster-hg38"" or ""cluster-hg19"" or ""cluster-hg19-na12878"". . Carrying it further, if we had a special convention for specifying data, like ""data-$SAMPLE"", we could just map $SAMPLE to a subdirectory on the bucket. That would provide a ton of flexibility. One minor note while you are messing with these scripts: the createCluster.sh script comment says ""This script deletes a Google Dataproc cluster used for running the GATK-SV pipeline."" Could you change to say it creates rather than deletes a cluster?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2456#issuecomment-286876038:402,depend,depending,402,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2456#issuecomment-286876038,1,['depend'],['depending']
Integrability,"@SHuang-Broad ; I have addressed comments and changed the SSRAligner interface to make it more general in terms of the type of inputs (base sequence providers) and the type of outputs that it will generate. . Also I added and example as to how to address your SVFastqUtil.FastqRead to SAMRecord realigner may look like but is untested. perhaps you can take on that commit and add the test, . does not need to be part of this PR push though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4780#issuecomment-390809079:69,interface,interface,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4780#issuecomment-390809079,1,['interface'],['interface']
Integrability,@SHuang-Broad looks good. I still think you should rename that integration test though.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2452#issuecomment-288187411:63,integrat,integration,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2452#issuecomment-288187411,1,['integrat'],['integration']
Integrability,"@SebastianHollizeck I believe the bug is not in `FilterMutectCalls` but upstream in `LearnReadOrientationModel` in the edge case of 3-base contexts that have no data in some of the samples. It's strange because we have an integration test for this already, and I would appreciate getting your input files to `LearnReadOrientationModel` for debugging. I think the following quick fix will work: untar your artifact priors, delete all but sample b, and re-tar, then run `FilterMutectCalls` as before. Is there a reason why all samples except b have very little data, and have no data at all for most 3-base contexts? To be clear, we want to fix the bug even if the data are weird, but I want to double-check that this is expected.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6202#issuecomment-597735514:222,integrat,integration,222,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6202#issuecomment-597735514,2,['integrat'],['integration']
Integrability,"@Siadjeu Could you try running the latest 4.1.9.0 release and reporting whether you get the same error? We updated a number of our dependencies for that release, including the Google cloud NIO library that the error is coming from.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-707916225:131,depend,dependencies,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-707916225,1,['depend'],['dependencies']
Integrability,"@Siadjeu Don't worry about the ""Failed to detect"" message. It indicates some internal state in one of the google libraries but not an error we need to worry about. Generally you shouldn't worry about INFO messages if everything else is going fine and they don't say something particular about what you're doing. A WARNING or ERROR message would indicate a problem. This should maybe be downgraded to be a DEBUG level message or something but it's in a third library and convincing them to change it might be a hassle.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-708443156:50,message,message,50,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-708443156,4,['message'],"['message', 'messages']"
Integrability,"@TearsWillFall @LRFreeborn I suspect that the environment you're running in has the wrong tensorflow version for some reason. The keras issue is a known TF/keras version incompatibility (see for example [this explanation](https://tensorexamples.com/2020/08/02/Keras.backend-has-no-attribute-get_session.html)). I'd guess that somehow you're getting TF 2.x as opposed to the TF 1.15 that GATK uses. I would recommend against directly modifying the python code - we use that same code and conda environment every day in our CI environment and on our docker, and it works there, so I suspect this is a dependency issue that is somewhat platform dependent. You might try checking the tensorflow version in your activated conda environment as a place to start - you can see the versions our current dependencies [here](https://github.com/broadinstitute/gatk/blob/master/scripts/gatkcondaenv.yml.template). Also @LRFreeborn - are you certain your issue is exactly the same as the original report (do you see the `AttributeError: module 'keras.backend' has no attribute 'clear_session'`) ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7250#issuecomment-941031682:599,depend,dependency,599,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7250#issuecomment-941031682,3,['depend'],"['dependencies', 'dependency', 'dependent']"
Integrability,"@TedBrookings which formats are you using, in particular? If there is a format out there that nicely fits our needs, we should adopt it. In the CNV package, I've taken pains to unify how tabular data are represented in Java, depending on whether each record is Locatable or whether the collection of records can be associated with a sample name or sequence dictionary. This allows us to represent records that extend Locatable with *multidimensional numerical or non-numerical annotations* along with some metadata (sample name and sequence dictionary) with a minimum of boilerplate. There are also base methods for producing interval trees, etc. This pretty much satisfies all of the CNV team's needs (and is, in my opinion, a necessary improvement over the horrowshow of read/write utility methods for each file format that we had previously...). However, this unification effort was a quick push I made before release, so some polishing or redesigning may be warranted. We may also want to add more forms of metadata, etc. if other teams would require more features. Another downside is that this code lacks the indexing, NIO support, etc. that some of the other standardized/Tribble formats enjoy. For CNV data, this isn't a huge issue, but I think it would be nice to unify how we represent such data GATK-wide. As I said above, I don't think VCF is the correct answer, but certainly it could fit into whatever framework we adopt or come up with.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385656468:225,depend,depending,225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-385656468,1,['depend'],['depending']
Integrability,"@Unip0rn Thank you for the pr. I'm not sure I understand what you're trying to do here though. currently when I run `./gatk --list` it prints the list of gatk tools. ex:; ```; USAGE: <program name> [-h]. Available Programs:; --------------------------------------------------------------------------------------; Base Calling: Tools that process sequencing machine data, e.g. Illumina base calls, and detect sequencing level attributes, e.g. adapters; CheckIlluminaDirectory (Picard) Asserts the validity for specified Illumina basecalling data.; CollectIlluminaBasecallingMetrics (Picard) Collects Illumina Basecalling metrics for a sequencing run.; CollectIlluminaLaneMetrics (Picard) Collects Illumina lane metrics for the given BaseCalling analysis directory.; ExtractIlluminaBarcodes (Picard) Tool determines the barcode for each read in an Illumina lane.; IlluminaBasecallsToFastq (Picard) Generate FASTQ file(s) from Illumina basecall read data. ...; ```. With this change it instead prints the gatk launcher help, which is not the intended result. ; ```; Usage template for all tools (uses --spark-runner LOCAL when used with a Spark tool); gatk AnyTool toolArgs. Usage template for Spark tools (will NOT work on non-Spark tools); gatk SparkTool toolArgs [ -- --spark-runner <LOCAL | SPARK | GCS> sparkArgs ]. Getting help; gatk --list Print the list of available tools. gatk Tool --help Print help on a particular tool. Configuration File Specification; --gatk-config-file PATH/TO/GATK/PROPERTIES/FILE. gatk forwards commands to GATK and adds some sugar for submitting spark jobs. --spark-runner <target> controls how spark tools are run; valid targets are:; LOCAL: run using the in-memory spark runner; SPARK: run using spark-submit on an existing cluster; --spark-master must be specified; --spark-submit-command may be specified to control the Spark submit command; arguments to spark-submit may optionally be specified after --; GCS: run using Google cloud dataproc; commands after the --",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030:442,adapter,adapters,442,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030,1,['adapter'],['adapters']
Integrability,"@Zepeng-Mu You say the original mapping contained contigs not in your reference but you filtered it with samtools to remove those contigs? I wonder if somehow some mappings to other contigs remain. I opened a PR ( #6781 ) to improve the error message. If you wanted to debug it further and ( have the time and inclination) you could build that commit and rerun with it to get the new error message. Alternatives to proceed would be to use the original reference you mapped it with, or run HaplotypeCaller with an intervals file that only contains the contigs that match the hg19 reference.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6783#issuecomment-684130877:243,message,message,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783#issuecomment-684130877,2,['message'],['message']
Integrability,"@adamjorr We'd like to support newer versions of Java, but have historically been held back by our Apache Spark dependency. We'll take another look at our dependency situation, however, and see if an upgrade is possible at this point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6053#issuecomment-514364684:112,depend,dependency,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6053#issuecomment-514364684,2,['depend'],['dependency']
Integrability,"@aderzelle The CNN tool requires some Python packages - you may not have the correct set of dependencies. There are instructions [here](https://github.com/broadinstitute/gatk#requirements) on how to establish the required environment via the Conda package manager. See the 3rd bullet point in the ""Optional but recommended"" section. Hope that helps.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4591#issuecomment-376503318:92,depend,dependencies,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4591#issuecomment-376503318,1,['depend'],['dependencies']
Integrability,"@ahaessly I've asked @jamesemery to review, as this touches some of his code. In the mean time, though, could you please add at least one good integration test for the new `ShiftFasta` tool?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6694#issuecomment-773489477:143,integrat,integration,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6694#issuecomment-773489477,1,['integrat'],['integration']
Integrability,"@ahaessly This error message indicates a corrupt .crai index file - you should see the same message if you try to read the file with any other GATK tool. Regenerating the index should fix it. Also, let me know if you happen to know what software/version created the index.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7152#issuecomment-804045945:21,message,message,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7152#issuecomment-804045945,2,['message'],['message']
Integrability,"@ahwanpandey the way I've worked around this in my workflows is to filter very large REF/ALT lengths. However from what I can tell the critical length is inconsistent, somewhere between 100-150 from memory, depending on the variant/data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8699#issuecomment-2403844997:207,depend,depending,207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8699#issuecomment-2403844997,1,['depend'],['depending']
Integrability,"@akiezun I have switched a lot so far; currently I'm stuck on `GenotypeLikelihoodCalculator`, which relies on `GenotypeLikelihoods` in htsjdk, which is log10. I could write a simple wrapper class to present a natural log interface. Is there a better solution?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/917#issuecomment-149321469:182,wrap,wrapper,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/917#issuecomment-149321469,2,"['interface', 'wrap']","['interface', 'wrapper']"
Integrability,"@akiezun Instead of adding these overloads would we see the same speedup if we cached the result of isUnmapped and isPaired in the adapter? That would have the downside of complicating the adapter but it might avoid adding these strange methods to the interface. . If caching seems like a bad alternative, I think maybe these methods should have names that make it clear that they're some sort of performance hack and you should generally prefer the standard ones. 'getContigUnsafe` for instance.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235101307:131,adapter,adapter,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235101307,3,"['adapter', 'interface']","['adapter', 'interface']"
Integrability,"@akiezun Yes, it's true that there's no way to prevent that, short of doing deep copies every time a read is wrapped in an adapter. But we can make it clear in the GATKRead contract that the backing reads should not be directly modified after wrapping within an adapter, and if they are they need to be re-wrapped in a new adapter.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235291718:109,wrap,wrapped,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2032#issuecomment-235291718,9,"['adapter', 'contract', 'wrap']","['adapter', 'contract', 'wrapped', 'wrapping']"
Integrability,"@apete Thanks for the PR! That's really helpful to update and any svd improvements are definitely something we want. . It's failing to build though, because it can't locate `ojalgo-extensions-1.0.0`. I get the following error:; ```; Build file '/Users/louisb/Workspace/gatk/build.gradle' line: 511. * What went wrong:; A problem occurred evaluating root project 'gatk'.; > Could not resolve all dependencies for configuration ':runtime'.; > Could not resolve org.ojalgo:ojalgo-commons-math3:1.0.0.; Required by:; project :; > Could not resolve org.ojalgo:ojalgo-commons-math3:1.0.0.; > Could not parse POM https://repo1.maven.org/maven2/org/ojalgo/ojalgo-commons-math3/1.0.0/ojalgo-commons-math3-1.0.0.pom; > Could not find org.ojalgo:ojalgo-extensions:1.0.0.; Searched in the following locations:; https://repo1.maven.org/maven2/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.pom; https://repo1.maven.org/maven2/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.jar; https://jcenter.bintray.com/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.pom; https://jcenter.bintray.com/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.jar; https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.pom; https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.jar; file:/Users/louisb/.m2/repository/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.pom; file:/Users/louisb/.m2/repository/org/ojalgo/ojalgo-extensions/1.0.0/ojalgo-extensions-1.0.0.jar; > Could not resolve org.ojalgo:ojalgo-commons-math3:1.0.0.; > Could not parse POM https://jcenter.bintray.com/org/ojalgo/ojalgo-commons-math3/1.0.0/ojalgo-commons-math3-1.0.0.pom; > Could not find org.ojalgo:ojalgo-extensions:1.0.0.; > Could not resolve org.ojalgo:ojalgo-commons-math3:1.0.0.; > Could not parse POM https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/org/o",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3970#issuecomment-351825206:395,depend,dependencies,395,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3970#issuecomment-351825206,1,['depend'],['dependencies']
Integrability,"@asmirnov239 Thanks for implementing this. After our conversation, I realized that the GATK3 version of the `--force-active` argument works a bit differently: it sets all of the individual per-locus probabilities of being active to 1.0, rather than preserving the true probabilities and just setting every region's `isActive` flag to true, as you're doing here. Ie., GATK3 does this:. ```; private void addIsActiveResult(final ActiveRegionWalker<M, T> walker,; final RefMetaDataTracker tracker, final ReferenceContext refContext,; final AlignmentContext locus) {; // must be called, even if we won't use the result, to satisfy walker contract; final ActivityProfileState state = walker.isActive( tracker, refContext, locus );; if ( walker.forceActive) state.isActiveProb = 1.0;; if ( ! walkerHasPresetRegions ) {; activityProfile.add(state);; }; }; ```. I'm not convinced that the GATK3 behavior is actually better. It almost seems preferable to me to keep the true ""is active"" probabilities intact (so that you get realistic region boundaries), and just tell the `HaplotypeCallerEngine` to treat all of the resulting regions as active, as you're doing in this branch, instead of overwriting all of the isActive probabilities with 1.0 as GATK3 did. But maybe there is a good argument in favor of the GATK 3 behavior. Let's see what other people think -- @ldgauthier @davidbenjamin could you please weigh in as to which of the two `--force-active` implementations described above you'd prefer? Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5635#issuecomment-461577642:634,contract,contract,634,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5635#issuecomment-461577642,1,['contract'],['contract']
Integrability,"@bbimber File locking doesn't work on all the filesystems GenomicsDB supports (hdfs/cloud, for instance) and is a pain on others (NFS, for instance -- painful enough that we've sometimes had to recommend users disable the existing file locking). For that reason, I wouldn't want users to depend on file locking for correctness. Unfortunately, I think the cleanest approach is for the user to ensure correctness by avoiding the read/write conflicts themselves.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6558#issuecomment-617448100:288,depend,depend,288,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6558#issuecomment-617448100,1,['depend'],['depend']
Integrability,"@bbimber I believe we resolve it from jcenter. There were some issues around it because we removed jcenter resolution from our build at one point when it was slated to shut down. Testing didn't see any issue because it was being silently mirrored through our artifactory instance and we didn't realize that. Jcenter changed their plans from shutting down to going into indefinite read only mode, so we re-added it. . I think if you're seeing problems it's either because:; 1. You are building on a version of gatk which removed jcenter; 2. Your custom build doesn't resolve from jcenter; 3. We have a new issue I don't know about yet. . Can you rule out 1 and 2 before we start debugging 3? . In your build.gradle you should should see ` jcenter()` in your `repositories {}` block. It's very possible that we're relying on an outdated version and maybe we should update to a new one which isn't on the ill fated Jcenter only. @TedBrookings any thoughts about that? I think this is your dependency.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7839#issuecomment-1122757145:986,depend,dependency,986,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7839#issuecomment-1122757145,1,['depend'],['dependency']
Integrability,"@bbimber I don't think `IntegrationTestSpec` has any provisions for this, and it has a number of other limitations around output files as well. We mostly only keep it around to make it easier to port GATK3 test - I'd recommend writing new tests using `ArgumentsBuilder` and `runCommandLine`, and checking results manually, perhaps by delegating to the static assert* methods in `IntegrationTestSpec`. Take a look at `HaplotypeCallerIntegrationTest` as an example. For the case of multiple outputs, create a temporary directory and specify that for the prefix input.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5446#issuecomment-441636281:24,Integrat,IntegrationTestSpec,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5446#issuecomment-441636281,2,['Integrat'],['IntegrationTestSpec']
Integrability,"@bbimber Just so you're aware, I expect this PR to be merged in the next couple of weeks - we're mostly just waiting on a couple of downstream dependencies. If you're still using Barclay docgen, there were some pretty significant [changes to the doclets](https://github.com/broadinstitute/barclay/pull/188) - not sure if that will affect your code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1430413869:143,depend,dependencies,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1430413869,1,['depend'],['dependencies']
Integrability,"@bbimber This issue is caused by an incompatibility between the version of snappy htsjdk uses and the versions that the rest of the world use. The workaround was to add the system property`-Dsnappy.disable=true` which is set automatically by gatk-launch. However, we just fixed the underlying problem in htsjdk and upgraded to use new version of snappy there, so it's a better idea to update to a newer gatk version that incorporates the newest htsjdk. . Annoyingly, we've been unable to publish the newer beta releases to maven central because they rely on snapshot builds of dependencies that aren't in central. We're working to fix that issue, but until then, we publish continuous snapshots of every commit on our artifactory https://broadinstitute.jfrog.io/. If you're using gradle you can add our repository to your project by adding this in your `repositories` block of the build file. ```; maven {; url ""https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot/"" ; }; ```; (this url was updated to address the comment below) . Then you can add a newer gatk dependency to your project:. ```; compile(group: 'org.broadinstitute', name: 'gatk', version: '4.beta.5-53-g0598843-20170929.153234-1'); ```. There should be a similar solution if you use maven or a different build tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-333627036:577,depend,dependencies,577,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-333627036,2,['depend'],"['dependencies', 'dependency']"
Integrability,"@bbimber Yes, most of those travis jobs are unique and do not overlap in terms of coverage. The unit and integration tests are each run in two separate jobs, one on Java 8 and one on Java 11, but the other jobs run python tools, cloud tests, WDL tests, etc. and do not overlap.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827951442:105,integrat,integration,105,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827951442,1,['integrat'],['integration']
Integrability,"@bbimber question for you - what is the primary motivation for wanting to merge the scattered workspaces back into a single workspace here? I'm assuming the scatter is because you have a large enough dataset that you need multiple nodes to run the import in parallel. (side note: we're planning on enabling reading vcfs through native htslib in GenomicsDBImport which should drive down memory usage for cases that are able to take advantage of that route. This might make it more feasible to use `--max-intervals-to-import-in-parallel` for multiple threads on a single node ). If the large dataset is the primary reason, wouldn't you want the benefits of distributed processing on the query side as well? You mentioned in the previous thread that you saw the fact that a single workspace is a valid GenomicsDB workspace as a benefit...and that's certainly true - but if performance is the driving factor then it might be worth it to keep the workspace separate. @droazen Could you elaborate on what you envision we should do here? This approach should work as long as the same command line is used for each import with a different/unique interval list each time. Are you asking for a test case to be run just for sanity? Or add test cases to GATK? Or add a tool to do this...?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-635081015:449,rout,route,449,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6620#issuecomment-635081015,1,['rout'],['route']
Integrability,"@bbimber, sorry that the import with consolidate did not complete. If you are amenable to using a native tool, please download the tool from [here](https://github.com/GenomicsDB/GenomicsDB/releases/download/v1.4.3/consolidate_genomicsdb_array) for consolidation. This executable will consolidate a given array in a GenomicsDB workspace, it has been instrumented to output memory stats to help tune the segment size. Note that the executable is for Centos 7, if you find any unresolved shared library dependencies during usage, please let me know and I will work on getting another one to you. For usage from a bash shell:; ```; ~/GenomicsDB: ./consolidate_genomicsdb_array; Usage: consolidate_genomicsdb_array [options]; where options include:; 	 --help, -h Print a usage message summarizing options available and exit; 	 --workspace=<GenomicsDB workspace URI>, -w <GenomicsDB workspace URI>; 		 Specify path to GenomicsDB workspace; 	 --array-name=<Array Name>, -a <Array Name>; 		 Specify name of array that requires consolidation; 	 --segment-size=<Segment Size>, -z <Segment Size>; 		 Optional, default is 10M. Specify a buffer size for consolidation; 	 --shared-posixfs-optimizations, -p; 		 Optional, default is false. If specified, the array folder is not locked for read/write and file handles are kept open until a final close for write; 	 --version Print version and exit; ```. ```; ~/GenomicsDB.: ./consolidate_genomicsdb_array -w /Users/xxx/WGS.gdb/ -a ""1\$1\$249250621"" -z 1048576 -p; 21:09:47.100 info consolidate_genomicsdb_array - pid=30881 tid=30881 Starting consolidation of 1$1$249250621 in ws; Using buffer_size=1048576 for consolidation; 21:9:47 Memory stats(pages) beginning consolidation size=45821 resident=18998 share=1824 text=3530 lib=0 data=16810 dt=0; 21:9:47 Memory stats(pages) after alloc for attribute=END size=45821 resident=19009 share=1835 text=3530 lib=0 data=16810 dt=0; 21:9:48 Memory stats(pages) after alloc for attribute=REF size=46788 resident=19743 share=18",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1057680354:500,depend,dependencies,500,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7674#issuecomment-1057680354,2,"['depend', 'message']","['dependencies', 'message']"
Integrability,"@bhandsaker Thanks for chiming in with your thoughts/concerns. Under this proposal, the various classes in htsjdk that read and return `SAMRecords` (eg., `SAMReader` & co.) would continue to put the header inside of the records, so we would not be imposing an additional burden on direct clients of htsjdk to check for null headers any more than they do currently. The only difference is that if downstream consumers of `SAMRecords` (like hellbender) choose to strip the header from the records, there would be an explicit contract governing the behavior of headerless `SAMRecords` (as opposed to the status quo, in which the header may be null but behavior is totally undocumented and in some cases inconsistent -- eg., the reference name and index in a headerless `SAMRecord` can get out-of-sync in some cases). . In addition to documenting/clarifying the behavior of headerless `SAMRecords` and fixing any consistency-related bugs we find when operating without a header, we would also make an effort to document when a class in htsjdk that consumes `SAMRecords` requires that a header be present in the records (such as the various writer classes). Does this sound reasonable? It's actually a much more conservative proposal than it may have initially sounded :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-142020109:523,contract,contract,523,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-142020109,1,['contract'],['contract']
Integrability,"@bhanugandham This message itself is harmless and won't affect results directly, but it can mask warning/error messages coming from Jexl (such as missing variable names!). I wouldn't expect a user to see it when running from a normal installation, and I'm not sure why it seems to be intermittent. I'll need to do some debugging.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4637#issuecomment-439434139:19,message,message,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4637#issuecomment-439434139,2,['message'],"['message', 'messages']"
Integrability,@biovia-rohit Thanks for reporting this! We'll look at our Apache Commons dependency and see if we can upgrade to a version not affected by this vulnerability.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8060#issuecomment-1289491679:74,depend,dependency,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8060#issuecomment-1289491679,1,['depend'],['dependency']
Integrability,"@chandrans I'm not sure if this is related or not, but I would love to get a test case from them. That's an unhelpful error message at the very least.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2116#issuecomment-410702793:124,message,message,124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2116#issuecomment-410702793,1,['message'],['message']
Integrability,"@cmnbroad - I am not concern about the methods, because they are perfectly configurable, and actually this issue is not that important for some of my projects (e.g., `ReadTools`), which does not use the base walker clases from GATK. Nevertheless, I guess that what @droazen is suggesting is quite important and I appreciate the interest for making better the downstream toolkits integration. Here, a real use case: I've just started to write a new toolkit that will use some walker classes from GATK (by now, `LocusWalker` or the `ReadSliderWalker` from #4682). With the current way of configuring the output, I will need to implement a layer for both walker classes (e.g., `MyLocusWalker` and `MyReadSliderWalker`) and use them in my implemented tools. In addition, I would like to bundle some tools from the GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still n",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:379,integrat,integration,379,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646,2,"['integrat', 'message']","['integration', 'messages']"
Integrability,"@cmnbroad . 1. We could write tests for some parts of the python package, e.g. those relating to I/O. The code also contains a number of stand-alone compiled theano functions that could be tested (e.g. forward-backward algorithm). Beyond that, most of the code juggle symbolic tensors that ultimately get compiled by theano into one giant _step function_. It is going to be hard to write surgical unit tests for such a code (and possibly unnecessary/wasteful). The ultimate requirement from the computational core is to (1) make correct inferences on simulated data, (2) pass certain sensitivity/specificity requirements on real data.; I vote for _not_ unit testing the python package (except for I/O), and to treat it as a black box with certain required specifications. The java-side integration tests can test most of the relevant cases. 2. Regarding logging, the scripts log both to console and optionally to a logfile at specified verbosity levels. At the moment, I am using the following formatter `%(asctime)s %(name)-12s %(levelname)-8s %(message)s`. We can easily change it to match GATK-style logs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-345778623:786,integrat,integration,786,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-345778623,2,"['integrat', 'message']","['integration', 'message']"
Integrability,@cmnbroad @droazen will there be any action on this? I'm not sure if #5714 might be related (although I'm not sure why we get a ulimit message there instead of a permission denied)?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-467113459:135,message,message,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-467113459,1,['message'],['message']
Integrability,"@cmnbroad After looking more, I have two comments: . 1) I agree that override of toString() was awkward. @ldgauthier or someone else at GATK might have more comments, but I think it can be dropped. 2) Some kind of getSimpleName() method directly on the interface, defaulting to getClass().getSimpleName() would be reasonable; however, it needs to be on Annotation, not VariantAnnotation, to be useful. . In this updated PR, I remoted the override of toString(), removed AbstractInfoFieldAnnotation, and left just the two interfaces: InfoFieldAnnotation and GenotypeAnnotation. The results in a relatively minor overall change.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7041#issuecomment-767872455:253,interface,interface,253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7041#issuecomment-767872455,2,['interface'],"['interface', 'interfaces']"
Integrability,"@cmnbroad Any further thoughts on this? when removing the toString() override (which did not appear to do anything so far as I could see), this Class -> Interface change ends up being fairly minor.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7041#issuecomment-774234474:153,Interface,Interface,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7041#issuecomment-774234474,1,['Interface'],['Interface']
Integrability,@cmnbroad Can you have a look at this when you get a chance and provide high-level feedback related to eventual integration with the `PythonScriptExecutor` and any dependency-related issues? Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-344692455:112,integrat,integration,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-344692455,4,"['depend', 'integrat']","['dependency-related', 'integration']"
Integrability,"@cmnbroad Depending on whether you like my changes in VariantEvalEngine.createVariantStratifier() and createVariantEvaluator() or not, I think I just committed changes for all your comments. I actually have not built another project using a local GATK JAR - would you mind saying a little more on that? I agree that would be important here to make sure our VariantQC tool can work with this VariantEvalEngine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-759118836:10,Depend,Depending,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-759118836,1,['Depend'],['Depending']
Integrability,@cmnbroad Great - thanks for working with us on this. One related question: our VariantQC tool is a separate project (gradle) that depends on GATK4. Is there a way to depend on some kind of dev version of GATK4 that will include the VariantEval code?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-440739574:131,depend,depends,131,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-440739574,2,['depend'],"['depend', 'depends']"
Integrability,"@cmnbroad I [tried to convince you](https://github.com/broadinstitute/gatk/pull/5378#issuecomment-443382334) that a test on jimfs was better than an integration test, because it exercises the same code (from the parts we want to test, I assume we're not interested in testing GCS itself) but runs faster. Since you insist, I can certainly do the same as an actual integration test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-455658014:149,integrat,integration,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-455658014,2,['integrat'],['integration']
Integrability,"@cmnbroad I figured I'd bump an old issue rather than create a new one, but my group would also appreciate if more gatk tools supported stdin / stdout. I've noticed that several of the Picard versions of tools support reading from stdin, but the Spark gatk replacements do not. MarkDuplicates is a big one, MarkDuplicates accepts /dev/stdin as input, but MarkDuplicateSpark does not. For the spark tools, this may be more work because they are chunking the file and splitting it across threads / processes, but it would be great if there were a solution for GATKPath / HtsPath to identify that we're operating on stdin / stdout and not use Files.newInputStream, and instead did something like wrap System.in in a BufferedReader if that's more appropriate. I realize that not all tools will be able to do this, because clearly you can't get random I/O to a file through a pipe, but there are plenty of tools that just read a single large file once through. There's a collection of older issues around better stdin/stdout support or at the least documentation around this:; https://github.com/broadinstitute/gatk/issues/5779; https://github.com/broadinstitute/gatk/issues/2236",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6749#issuecomment-1092237787:693,wrap,wrap,693,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6749#issuecomment-1092237787,2,['wrap'],['wrap']
Integrability,@cmnbroad I moved this message so it runs during the actual task execution rather than at configuration time.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4147#issuecomment-357371881:23,message,message,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4147#issuecomment-357371881,1,['message'],['message']
Integrability,"@cmnbroad I put in a test in GATK that should fail if the dependency is moved to Picard. So, you are 100% correct that these changes will need to go into Picard.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3250#issuecomment-316558645:58,depend,dependency,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3250#issuecomment-316558645,1,['depend'],['dependency']
Integrability,"@cmnbroad I refactored the training java wrapper into separate wrappers to write tensors (CNNVariantWriteTensors.java) and to train (CNNVariantTrain.java) I think this simplified the meaning/necessity of many of the arguments, which was unclear when all those tools were rolled together. . I'm working on a release-style integration test that chains all the tools together, like @droazen discussed a few meetings ago, but for this PR I think I will have to do something simpler. Because of some issues with the GSA5 environment and GPU, I still have to write in a Python2/3 agnostic way, which precludes the use of type hints. I would like to update, but I'm blocked by BITs in the short term.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432:41,wrap,wrapper,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432,6,"['integrat', 'wrap']","['integration', 'wrapper', 'wrappers']"
Integrability,"@cmnbroad I think this proposal is good provided that the error message people get clearly explains what they need to do to resolve things when this happens (eg., explains which dependencies have changed and how to mark the changes as ""ok"")",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2592#issuecomment-300897729:64,message,message,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2592#issuecomment-300897729,4,"['depend', 'message']","['dependencies', 'message']"
Integrability,"@cmnbroad I understand that I could have retained a bunch of single-use text files, but it seemed like the more permutations one adds, the less it makes sense to have a separate, very redundant, static text file to check each scenario. There's a ton of VariantContext-related tests that parse the output VCF to test some feature as opposed to checking in a bunch of VCF text files.... While I'll grant the 4th test case I added (where we pass chr 2) isnt especially compelling over just testing chr 1, one could argue more breadth is a good thing here. if you want clarity, pulling that VariantEval report parsing code into a method called extractUniqueContigsFromEvalReport(), or simply adding a comment line, supports this goal. Anyway, I'm checking in slightly clarified version of this now, simply to get tests running. If you respond to the above, maybe we go with that. In the interest of time, I'll stage and check in the version which restores the text files and goes that route.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7238#issuecomment-831459741:981,rout,route,981,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7238#issuecomment-831459741,2,['rout'],['route']
Integrability,"@cmnbroad OK, considerable progress here. I was able to adjust behavior such that only two tests have changed behavior from GATK4/master. I think this is now correct. One instance of changed behavior is the Snpeff/overlap one we discussed above. The second is the one where we now provide the full genome as REF, not the truncated genome. I think this difference is justified since the tool now requires a reference, and the prior version was arguably too lenient on validation of contigs. Anyway, this branch now also removes by debugging code and comments. I think it is ready for a review. To some other questions you had above:. 1) The HashMap<FeatureInput<VariantContext>, HashMap<String, Collection<VariantContext>>> can be wrapped in a class with just a couple of methods, so we don't have to manifest that long type all over the place. I realize that's non-optimal, but this isnt anything I introduced here. I would really like to keep this PR as limited as we can, and address some larger refactoring in a different PR, once we've migrated to MultiVariantWalkerGroupedOnStart. 2) I know this PR still in an interim state, but passing the VariantWalker in as an argument to the comp methods doesn't seem like a step forward to me. If we can't solve that problem completely in this PR (which is fine, I'm all for trying to contain this), are those changes necessary ? Perhaps that part should just wait for the next round. As noted above, I'd like to propose this as iterative, with a second PR coming soon. I did this b/c it moved us toward not needing to pass around the walker. It minimizes the code that has access to the walker (as opposed to setting it after creating the instance of the Evaluator, etc. Yes, it exposes it for two methods, but those classes no longer hang on to it. I would like to ultimately remove this entirely. 3) To re-iterate testEvalTrackWithoutGenotypesWithSampleFields: the input file, noGenotypes.vcf, has a header dictionary with the full set of contigs, and a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-747619130:730,wrap,wrapped,730,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-747619130,1,['wrap'],['wrapped']
Integrability,"@cmnbroad OK, so I see that I can supply a custom --gatk-config file on the command line, and I suppose I would also provide my other JAR on the classpath with my additional VariantAnnotation classes? That is useful, but also a little unclean given I am already building our DISCVRseq JAR, which includes the GATK4 dependency. I'm still inclined to make our tool that extends GATK's VariantAnnotation, and override makeVariantAnnotations(). I could either manipulate GATKAnnotationPluginDescriptor, or make my own to scan the expected package(s). It seems pretty surgical and less would be required of the user to run it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6929#issuecomment-720610784:315,depend,dependency,315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6929#issuecomment-720610784,1,['depend'],['dependency']
Integrability,"@cmnbroad On these blocking PRs. The core point is to provide a way to link FeatureInput to VariantContext. The existing PRs stash FeatureInput name as the VariantContext source. I dont know if there are internal deliberations or anything holding up getting those done, or blocking my offer to try to implement that. However, I wonder what you think about a possible alternate approach. The driving use for this feature is MultiVariantWalkers and their subclasses. Another way to tackle this might be to hook into MultiVariantDataSource. One could create a wrapper class:. ```; public class VariantContextWithSource {; VariantContext variant;; FeatureInput source;; }. ```; And the iterator layer would wrap the VariantContext objects with this class, making a non-text link to FeatureInput. And perhaps either a) apply() would get called with this wrapper instead of VariantContext, or b) MultiVariantWalker might be able to get converted into MultiVariantWalker<T> where T is the class provided to apply(). I havent fully explored this, but it might be a more convenient way to share implementations. I could try to make this more concrete and propose something, but I dont want to spend work if the concept of wrapping VariantContext into something like VariantContextWithSource isnt going to go anywhere.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-795835307:557,wrap,wrapper,557,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-795835307,4,['wrap'],"['wrap', 'wrapper', 'wrapping']"
Integrability,"@cmnbroad Sorry I should have been clearer. I meant unzipping the gatk release file. Unzipping the gatk release file places both files in the sample directory as below. I tried to create the gatk conda environment in the directory, which was failed due to the path issue.; ```; $ unzip src/gatk-4.0.0.0.zip; Archive: src/gatk-4.0.0.0.zip; creating: gatk-4.0.0.0/; inflating: gatk-4.0.0.0/gatk-package-4.0.0.0-local.jar; inflating: gatk-4.0.0.0/gatk-package-4.0.0.0-spark.jar; inflating: gatk-4.0.0.0/gatk; inflating: gatk-4.0.0.0/README.md; inflating: gatk-4.0.0.0/gatk-completion.sh; inflating: gatk-4.0.0.0/gatkcondaenv.yml; inflating: gatk-4.0.0.0/gatkPythonPackageArchive.zip; $ cd gatk-4.0.0.0; $ conda env create -n gatk -f gatkcondaenv.yml; ```. It appears simpler to have conda manage both Python and R dependencies. I am not sure if it's easily possible to move away from R-3.2.5 though. Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359073267:811,depend,dependencies,811,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359073267,2,['depend'],['dependencies']
Integrability,@cmnbroad That is correct. Once upon a time it was waiting on the VariantAnnotator to be integrated before advancing on it but now its being held in place by newtons first law. I will take a look at updating the branch.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4604#issuecomment-376909187:89,integrat,integrated,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4604#issuecomment-376909187,1,['integrat'],['integrated']
Integrability,"@cmnbroad The path to the c++ compiler can be specifically provided to theano by setting `theano.config.cxx` in python scripts, or by creating a `.theanorc` in the home directory, or by setting the environmental variable `THEANO_FLAGS=cxx=<path_to_g++>,...`. If a working c++ compiler exists and provided to theano, it is fair to assume that the graph _will_ compile. If the c++ compiler is not explicitly specified, theano will try to discover it. It first tries to execute `g++ -v` in the present environment and if it succeeds, it resolves the absolute path to the executable. On darwin, it further searches for `clang++` and on Win32, it looks for a working mingw gcc setup. We could _enforce_ the presence of a c++ compiler at the beginning of all python scripts and throw an exception and an informative message instead of numpy/python fallback. If we do so, the integration tests (and all gCNV CLI tools) will fail and will force the user to install a c++ compiler. In your opinion, is this fail-fast strategy a better approach, given that python fallback runs 2~3 orders of magnitude slower?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350193484:810,message,message,810,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350193484,2,"['integrat', 'message']","['integration', 'message']"
Integrability,@cmnbroad ignore the previous message -- I managed to add MKL to the docker.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350290589:30,message,message,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350290589,1,['message'],['message']
Integrability,"@cmnbroad rebasing is done. To summarize changes since your last review:. - I backed out the earlier changes to FeatureInput/FeatureDataSource in favor of those from #7219 ; - I dont entirely know why this didnt hit before, but I made an update to VariantStratifiers to make tests pass. See: https://github.com/broadinstitute/gatk/pull/6973/commits/1569a909d3dc2301337e46441cc0cd969843c8d1. The gist is that we now instantiate those classes and pass VariantEvalEngine. Two of these classes had validation in their constructors, and could throw a CommandLineException if the tool was executed with bad arguments. This exception was getting caught and re-thrown as GATKException with the misleading message ""Problem making an instance of ...."". This proposal is to make a separate VariantStratifier.validateArgs() method, with a default no-op validation, and to call this only after instantiation. This was already exercised under the tests, such as testMultipleEvalTracksAlleleCountWithoutMerge(). VariantEval tests pass locally for me. With luck, tests will pass here.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827805993:697,message,message,697,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827805993,1,['message'],['message']
Integrability,"@cmnbroad yes, was literally just checking that in. I agree it's probably better to rethrow and preserve the stack than preserving the original class like my first commit did. Do you expect that so few of the travisci suites seem to actually run these integration tests? only three actually failed?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827938856:252,integrat,integration,252,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-827938856,1,['integrat'],['integration']
Integrability,"@cmnbroad, that's not wholly unreasonable, but i'd like to push back on a number of these points. . 1) First - would GATK consider simply letting us take over VariantEval and maintain as a GATK4-based tool in another repo? My understanding from GATK4 issues is that plan was to never migrate VariantEval (i think in favor of other picard/gatk QC tools). There is a bit of a conflict between keeping a lean core engine and having all these tools built off it. I would think there's an argument for keeping your core engine and the many tools built off it separated (GATK3 seemed to include some dead tools, for example). I appreciate we're the ones pushing this migration, but I hope on the other side you can appreciate the bar is pretty significant on our time. . 2) What new plugins are you talking about? VariantStratification and VariantEvaluator are part of GATK3's VariantEval? Yeah, I wrote a base PluginDescriptor class patterned on how ReadFilters work. It probably should exist in a more core position in code. While there's some good ideas in the argument-parsing/plugin code of GATK/Barlcay, frankly seems like much of it isnt fully developed yet, which is why I kept this separated at the moment. . 3) Be aware, the GATK3 tests depend on ~30GB of files. I dont know the limits of git lfs, but I did not currently have plans to check those in. I assumed I would convert these to use GATK4 chr20/21 data for a final commit, but felt there was a lot of value in using unaltered GATK3 data to confirm parity (and it was during the migration).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407123968:1241,depend,depend,1241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5043#issuecomment-407123968,2,['depend'],['depend']
Integrability,"@cwhelan & @ldgauthier sorry for the delay on getting back this issue. Firstly, I just grabbed the new release (4.0.12.0) and re-ran with that to generate both gVCF and VCF. The VCF output still generates the 1/1 genotype unfortunately. What's interesting though is that the gVCF is capturing the spanning allele! So it looks like `GenotypeGVCFs` is causing the problem. Here are the rows from the gVCF and VCF respectively (with INFO elided for compactness):. ```; # gVCF; chr6 42932200 . GGC TGT,<NON_REF> 1623.73 . GT:AD:DP:GQ:PL:SB 0/1:39,44,0:83:99:1661,0,1458,1778,1591,3369:10,29,14,30; chr6 42932202 . C T,*,<NON_REF> 3439.77 . GT:AD:DP:GQ:PL:SB 1/2:1,37,44,0:82:99:3468,1802,1661,1518,0,1449,3406,1802,1577,3436:0,1,24,57. # VCF; chr6 42932200 . GGC TGT 1632.77 . GT:AD:DP:GQ:PL 0/1:39,44:83:99:1661,0,1458; chr6 42932202 . C T 3439.77 . GT:AD:DP:GQ:PL 1/1:1,37:82:99:1807,141,0; ```. For completeness I also ran HaplotypeCaller going direct to VCF without making a gVCF first. The results are fairly similar to the VCF above, except for some AD/DP differences:. ```; # Direct to VCF; chr6 42932200 . GGC TGT 1623.73 . GT:AD:DP:GQ:PL 0/1:39,44:83:99:1661,0,1458; chr6 42932202 . C T 3439.77 . GT:AD:DP:GQ:PL 1/1:1,50:51:99:1807,141,0; ```. Going back to what's the right representation - I think I largely agree with @nh13 and @ldgauthier that long term it would be nice, when running with MNP support, to integrate the two haplotypes into a single variant output. But that sounds like it might be a big project and not happening any time soon? In the meantime if there's an easier fix to have the `*`/spanning allele called in the VCF propagated into the genotyped VCF that would really help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5523#issuecomment-449758576:1415,integrat,integrate,1415,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5523#issuecomment-449758576,1,['integrat'],['integrate']
Integrability,"@cwhelan , addressed comments in 4 commits, with the first 3 addressing requested changes in main and the last dealing with integration test.; Please review again. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2621#issuecomment-298986792:124,integrat,integration,124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2621#issuecomment-298986792,1,['integrat'],['integration']
Integrability,@cwhelan I've addressed the comments in the separate commits. The commit messages decribes what was done in each push.. Please take another look. Thanks!. The tests are failing because of travis. They run successfully when manually rebooted but the status here don't get updated...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2567#issuecomment-292063168:73,message,messages,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2567#issuecomment-292063168,1,['message'],['messages']
Integrability,"@cwhelan I've been thinking about this a lot more since we were looking at your integration test results. The PGT calls are inconsistent between HaplotypeCaller/CombineGVCFs and GenotypeGVCFs since we correct hom vars with 0|1 PGT in GGVCFs: https://github.com/broadinstitute/gatk/blob/851c8408d11042a402debf183d4fb69048a16c0e/src/main/java/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFsEngine.java#L436; but I like the idea that the PGT is still showing that there are two different haplotypes at that site. I'm leaning towards removing that ""cleanup"", which will mean a lot of hom var sites will have PGTs that are ""inconsistent"" as the user was complaining about, but I will add some documentation. What do you think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6432#issuecomment-705613003:80,integrat,integration,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6432#issuecomment-705613003,1,['integrat'],['integration']
Integrability,"@danxmoran This is the bug you're seeing too. I haven't gotten a chance to try any of the suggestions above yet, but I'm hoping to start this afternoon. Also, just for completeness I saw a new error message today that I think Dan saw too (this time from PrintReads):. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -Xms2g -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar PrintReads -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/a4b1f3b8-9530-491e-8d87-749495f526c8/call-GatherBamFiles/CHMI_CHMI3_WGS2.bam --interval_padding 500 -L /cromwell_root/broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/a4b1f3b8-9530-491e-8d87-749495f526c8/call-ScatterIntervalList/glob-cb4648beeaff920acb03de7603c06f98/1scattered.interval_list -O local.sharded.bam; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.l7eTB5; [July 21, 2017 6:20:54 PM UTC] PrintReads --output local.sharded.bam --intervals /cromwell_root/broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/a4b1f3b8-9530-491e-8d87-749495f526c8/call-ScatterIntervalList/glob-cb4648beeaff920acb03de7603c06f98/1scattered.interval_list --interval_padding 500 --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/a4b1f3b8-9530-491e-8d87-749495f526c8/call-GatherBamFiles/CHMI_CHMI3_WGS2.bam --interval_set_rule UNION --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564:199,message,message,199,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564,1,['message'],['message']
Integrability,"@david-wb @popboy126 I'm having trouble reproducing the shutdown issue on our own cluster, I sometimes get the message `Shutdown hook called before final status was reported.` but the job status is SUCCEEDED. This happens if I run with the System.exit(0) or not. Could one of you test with this branch and let me know if it solves your issue? I think my cluster configuration must be different then yours in some way.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3400#issuecomment-319778125:111,message,message,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3400#issuecomment-319778125,1,['message'],['message']
Integrability,"@david-wb Interesting... what version of spark / spark submit are you using? I was pretty sure that at the point where setMaster() was called by gatk the spark context was already created by yarn and setup with the appropriate master. I wonder if it changed from a previous version of spark... Alternatively, I may be misremembering and relying on the fact that our wrapper script supplies `--sparkMaster yarn` as a gatk argument which would probably override what's being set. Could you try:; ```; spark-submit \; --deploy-mode client \; --class org.broadinstitute.hellbender.Main \; --master yarn \; /home/hadoop/gatk-package-4.alpha.2-269-gdce8abc-SNAPSHOT-spark.jar BwaSpark \; --bwamemIndexImage /var/tmp/hs38DH-V.fasta.img \; -I hdfs:///unaligned.bam \; -O hdfs:///aligned.bam \; -R hdfs:///hg38/hs38DH-V.fasta \; --disableSequenceDictionaryValidation true \; --sparkMaster yarn; ```. or with the wrapper: ; ```; GATK_SPARK_JAR_ENV_VARIABLE=/home/hadoop/gatk-package-4.alpha.2-269-gdce8abc-SNAPSHOT-spark.jar. ./gatk-launch \; --bwamemIndexImage /var/tmp/hs38DH-V.fasta.img \; -I hdfs:///unaligned.bam \; -O hdfs:///aligned.bam \; -R hdfs:///hg38/hs38DH-V.fasta \; --disableSequenceDictionaryValidation true \; -- \; --sparkRunner SPARK \; --sparkMaster yarn; ```. Our wrapper script sets a number of properties which we think are important for running our spark tools. If running directly on spark you might want to set them explicitly. Things like `-Dsamjdk.compression_level=1` have MAJOR performance implications. . Also, be aware the BwaSpark is not in the best health at the moment may have issues. If you're running it you may want to run the version that's in this branch which is currently under review https://github.com/broadinstitute/gatk/pull/2494.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2718#issuecomment-301925138:366,wrap,wrapper,366,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2718#issuecomment-301925138,3,['wrap'],['wrapper']
Integrability,"@davidbenjamin Can you implement a simple integration test for this arg, to ensure it doesn't break again?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4128#issuecomment-357045030:42,integrat,integration,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4128#issuecomment-357045030,2,['integrat'],['integration']
Integrability,"@davidbenjamin Can you tell me whether this is a straight-up port of the GATK3 version of this code, or whether you've made any changes in the process of porting?. I will test out this change, in combination with a change from @samuelklee / @ronlevine, in a branch in protected, and craft passing integration tests there before merging this here in public.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2710#issuecomment-301086407:297,integrat,integration,297,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2710#issuecomment-301086407,1,['integrat'],['integration']
Integrability,"@davidbenjamin I added the AF thresholding and limited it to just the NON_REF allele. There's a mildly awkward check in the integration test for it. If you can formulate an elegant unit test that makes for nice round numbers I'm happy to add it, but that's beyond me. I lost the new Twist exome, but once I can get ahold of it I'll make a GVCF and see what happens.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5312#issuecomment-449127402:124,integrat,integration,124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5312#issuecomment-449127402,1,['integrat'],['integration']
Integrability,"@davidbenjamin I checked with our diagnostic lab director about which data can be put on the public repo (anonymized of course). The only file that cannot be used is the one labeled ""Exome_NBPF16_SNP.bam"", the other bam files I shared with you are from control samples and can be used in the integration test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-453800471:292,integrat,integration,292,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-453800471,1,['integrat'],['integration']
Integrability,"@davidbenjamin I figured out that particular case we talked about earlier. The case (`depth = 0` but `PileupElement` is not empty) happens when all the reads have deletion at the locus. Instead of logging a message, now I simply skip such a locus.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3721#issuecomment-348321755:207,message,message,207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3721#issuecomment-348321755,2,['message'],['message']
Integrability,"@davidbenjamin I think that is a bit of a cop out. I would have been happy to use a provided resource but there was none to be found for hg38. I had to do a liftover for the gnomAD data and that introduced subtle changes to the VCF that invoked this bug in <20% of my samples after hours of processing without any sensible error message to lead me onto what was the cause of the problem. I have wasted many days on debugging this issue and creating a bug report and I was considering switching to GATK3 or some other variant caller because of it. I think someone else reported a very similar issue on the forum and went back to using GATK3. . Maybe Mutect2 should, by default, run a filter on the pop resource VCF to get rid of unnecessary or erroneous lines. When users get more familiar with the algorithm, they could disable this filtering to save time and provide a pre-filtered VCF (--germline-resource or --germline-filtered-resource).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5391#issuecomment-435840613:329,message,message,329,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5391#issuecomment-435840613,1,['message'],['message']
Integrability,"@davidbenjamin I've spun this off into a separate ticket. I think this might be serious/widespread enough that we'll want a 4.1.6.1 release once we have a working fix. I recommend that we manually do full-scale test runs of both HaplotypeCaller and Mutect2 to confirm that the issue is resolved rather than relying on the integration tests, which are not large-scale enough to catch edge cases like this, unfortunately.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6533#issuecomment-606748607:322,integrat,integration,322,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6533#issuecomment-606748607,1,['integrat'],['integration']
Integrability,"@davidbenjamin Just added an additional automated test thanks to @sooheelee , but please ignore commit message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3538#issuecomment-326306087:103,message,message,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3538#issuecomment-326306087,1,['message'],['message']
Integrability,"@davidbenjamin LODs are fixed, but I'm not super happy with them. They fluctuate a lot, making for a big GVCF. How easy would it be to modify the likelihood calculation to integrate over all AFs greater than some threshold of interest? I'm hoping that would produce more stability. Just to give you an idea of the fluctuation, below are some lines from my integration test VCF where I block anything less than -2 and between -2 and 0. I tried a few other thresholds, but it's just a lot of variability. I have a hunch it has to do with the minimum base quality in the pileup. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT NA12878; chrM 1 . G <NON_REF> . . END=4 GT:DP:MIN_DP:TLOD 0/0:67:48:-1.958e+00; chrM 5 . A <NON_REF> . . END=5 GT:DP:MIN_DP:TLOD 0/0:107:107:-2.033e+00; chrM 6 . C <NON_REF> . . END=6 GT:DP:MIN_DP:TLOD 0/0:123:123:-1.603e+00; chrM 7 . A <NON_REF> . . END=8 GT:DP:MIN_DP:TLOD 0/0:135:135:-2.138e+00; chrM 9 . G <NON_REF> . . END=9 GT:DP:MIN_DP:TLOD 0/0:138:138:-1.975e+00; chrM 10 . T <NON_REF> . . END=13 GT:DP:MIN_DP:TLOD 0/0:178:154:-2.226e+00; chrM 14 . T <NON_REF> . . END=15 GT:DP:MIN_DP:TLOD 0/0:208:205:-1.974e+00; chrM 16 . A <NON_REF> . . END=23 GT:DP:MIN_DP:TLOD 0/0:259:218:-2.424e+00; chrM 24 . A <NON_REF> . . END=25 GT:DP:MIN_DP:TLOD 0/0:312:310:-8.945e-01; chrM 26 . C <NON_REF> . . END=26 GT:DP:MIN_DP:TLOD 0/0:317:317:-2.509e+00; chrM 27 . C <NON_REF> . . END=27 GT:DP:MIN_DP:TLOD 0/0:335:335:-1.962e+00; chrM 28 . A <NON_REF> . . END=50 GT:DP:MIN_DP:TLOD 0/0:492:343:-2.821e+00; chrM 51 . T <NON_REF> . . END=51 GT:DP:MIN_DP:TLOD 0/0:700:700:-3.808e-01; chrM 52 . T <NON_REF> . . END=63 GT:DP:MIN_DP:TLOD 0/0:822:722:-2.943e+00; chrM 64 . C <NON_REF> . . END=64 GT:DP:MIN_DP:TLOD 0/0:909:909:-1.492e+00; chrM 65 . T <NON_REF> . . END=86 GT:DP:MIN_DP:TLOD 0/0:1064:938:-3.065e+00; chrM 87 . A C,<NON_REF> . . DP=942;ECNT=8;POP_AF=5.000e-08,5.000e-08;TLOD=-2.463e+00,-2.668e+00 GT:AD:AF:DP:F1R2:F2R1:MBQ:MFRL:MMQ:MPOS:ORIGINAL_CONTIG_MISMATCH:SA_MAP_AF:SA_PO",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5312#issuecomment-437501517:172,integrat,integrate,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5312#issuecomment-437501517,2,['integrat'],"['integrate', 'integration']"
Integrability,"@davidbenjamin OK, we have a utility method in `AbstractLocatableCollection` that essentially enables this for our particular use case (sorting and concatenating sharded tables, which are themselves non-overlapping and sorted, and returning the sort order; no reason why we couldn't just return the resulting concatenated table, either). These sorts of methods can be easily made generic if we have good base classes for individual locatable records that implement the appropriate interfaces.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-480968991:481,interface,interfaces,481,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-480968991,1,['interface'],['interfaces']
Integrability,"@davidbenjamin Sorry I've been out and just got around to looking at this. Given that this test appears to run just fine in the Java 11 job (which is not run on our docker), I suspect the failure may have something to do with the jar file we use to test on the docker (which is not the same jar we use on the non-docker tests). . I pulled your branch and all of the generation tasks (gatk doc, wdl gen, javadoc) seem to work fine, so given how much time it looks like this has taken up, I think it would make sense to either disable this test (on the docker only - see below - since we want it to still run in the other CI integration test job), or else remove the variantcalling package from the test package list (if thats the one thats causing the failure ?). And then create a ticket for me with whatever data you have, which I'll follow up on. If you restore everything to its natural state, you should be able to add this to the `DocumentationGenerationIntegrationTest.documentationSmokeTest` method and then it will be skipped only when running on the docker:. ```; final DocumentationGenerationIntegrationTest dt = new DocumentationGenerationIntegrationTest();; if (dt.isGATKDockerContainer()) {; throw new SkipException(""See gatk issue #..."");; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1216668361:623,integrat,integration,623,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1216668361,1,['integrat'],['integration']
Integrability,"@davidbenjamin The bug here is that we misinterpreted what a TreeSet in java does. The actual behavior for this method was that it only took the FRIST variant at each start position that it saw from the ordering of the haplotypes it saw. This meant if a SNP and INDEL started at the same position then there was a chance that site only looks like a SNP to the subsequent trimming code and we trim incorrectly. . See the TreeSet docs:; ```; <p>Note that the ordering maintained by a set (whether or not an explicit; * comparator is provided) must be <i>consistent with equals</i> if it is to; * correctly implement the {@code Set} interface. (See {@code Comparable}; * or {@code Comparator} for a precise definition of <i>consistent with; * equals</i>.) This is so because the {@code Set} interface is defined in; * terms of the {@code equals} operation, but a {@code TreeSet} instance; * performs all element comparisons using its {@code compareTo} (or; * {@code compare}) method, so two elements that are deemed equal by this method; * are, from the standpoint of the set, equal. The behavior of a set; * <i>is</i> well-defined even if its ordering is inconsistent with equals; it; * just fails to obey the general contract of the {@code Set} interface.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-645528965:630,interface,interface,630,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-645528965,4,"['contract', 'interface']","['contract', 'interface']"
Integrability,"@davidbenjamin The message ""Flush-to-zero (FTZ) is enabled when running PairHMM"" is completely normal and not a sign of any problem. The ticket does not have enough detail for us to determine why the output file was empty.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4788#issuecomment-590928031:19,message,message,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4788#issuecomment-590928031,1,['message'],['message']
Integrability,@davidbenjamin We should chat about this in person -- have some questions for you. Some of the functionality you removed from the downsampler interface is needed by code that is not yet ported.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314200383:142,interface,interface,142,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314200383,1,['interface'],['interface']
Integrability,"@davidbenjamin as we just discussed, back from vacation now and modulo other circumstances (which we also just discussed) should be able to get this back to you in a week. If you could squash the commits after the last review, that might actually be a little cleaner for me to review---perhaps comment a copy of the squashed commit messages here if you'd like to keep them for posterity. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1112295304:332,message,messages,332,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1112295304,1,['message'],['messages']
Integrability,"@davidbenjamin mutect2_pon.wdl and mutect2.wdl worked great without docker installed. Thanks!. @samuelklee @sooheelee As a user, I found a json template useful for two reasons, though it may be up to how a wdl is written.; 1) womtool generates inputs from all the dependent wdls including unnecessary ones for the workflow. (e.g. mutect2_pon.wdl); 2) womtool didn't provide default values. Looking at mutect_resources.wdl, I wondered what the good value for minimum_allele_frequency is (or what GATK team used for creating the resource bundle). In addition, I thought a test to validate every wdl would be helpful. (womtool validate [a wdl])",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360544256:264,depend,dependent,264,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360544256,1,['depend'],['dependent']
Integrability,"@davidbenjamin thank you for your work and thank you for the clarification. Is this going to be code shared by the HaplotypeCaller as well? A lot of the analyses I do are dependent on the variance of the AD counts to be properly modeled, so I look forward to this improvement being implemented.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6096#issuecomment-524372694:171,depend,dependent,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6096#issuecomment-524372694,1,['depend'],['dependent']
Integrability,"@davidbenjamin, @fleharty agree with the implementation of PR #7003. ; I'm running that version comparing to samples previously reported 0 contamination and 0 std error.; will update here. One concern on the math Eq37 - Eq.42 calculate std (chi).; the math not taking into account the sample size (n) i.e number of homs.; note that we are starting with GetPileupSummaries output ~5k loci , ; filterSitesByCoverage keep ~300 loci ; filter segments + MAF keep variable number of loci depend on panel size etc. this number can vary and the question should the implementation will take it into account? i.e. reject the sample if n<NUM_LOCI (5,10,50???). **Thinking on the end user observing the Pair( contamination,stdError) and his interpretation on that...** . Probably adding the number of homs sites + strategy to final output as well as listing the pileups for the homsites will let the end user better understand the sample contamination output or even to find contaminant of a batch. **suggesting the following update to output file:**; sample	contamination	error; TUMOR	0.019245855721094312	0.0036809520099731763. sample, **strategy, n_loci,** contamination, error; TUMOR,HOM_ALT,M. list of homosites used; **contig	position	ref_count	alt_count	other_alt_count	allele_frequency**; PileupSummary1; PileupSummary2; ...; PileupSummaryM",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7177#issuecomment-833821730:482,depend,depend,482,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7177#issuecomment-833821730,1,['depend'],['depend']
Integrability,"@ddrichel @jhl667 @schelhorn @xiucz I have a theory that, depending on the answers to the following questions, I may pursue further. 1. What are you using for a panel of normals in both WES and WGS?; 2. What reference assembly are you using?; 3. Were the new false positives present in the unfiltered Mutect2 VCF before version 4.1.9.0 (and then flagged by FilterMutectCalls) or absent entirely?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1202001839:58,depend,depending,58,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7921#issuecomment-1202001839,1,['depend'],['depending']
Integrability,@drifty914 Do you encounter the ulimit message when you run a *single* shard (covering say 5000 intervals) of GermlineCNVCaller?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-468308508:39,message,message,39,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-468308508,1,['message'],['message']
Integrability,"@droazen , We made fixes for the vulnerabilities after java17 which was release last week. . Can you help to integrate this into GATK so that we can have new release. We have the files with patch ready. Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-2222021256:109,integrat,integrate,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-2222021256,1,['integrat'],['integrate']
Integrability,"@droazen - Still some questions about integration tests (on the comment with your suggestion, but here too):. * I am not sure if the test that you are proposing will work with all the implementations of `createTempFile`: depends on how it is handle, as a `File` or as a `Path`; * I think that this depends a lot on the parts of the codebase that we are looking at, so maybe before accepting this a pass should be done for the usages and how the `java.io.tmpdir` is used. Waiting for your feedback before doing something that does not make sense...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-385942269:38,integrat,integration,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-385942269,6,"['depend', 'integrat']","['depends', 'integration']"
Integrability,"@droazen - That won't be solved by the current #3447, because there is no way of fine-tune the codecs: I require to being able to add/remove concrete classes, and exclude codecs from a concrete package. An example is a custom codec implementation for some feature, to provide extra-validation for the downstream toolkit. This would be even more useful if HTSJDK is moving to an interface-based library...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2139#issuecomment-337622596:378,interface,interface-based,378,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2139#issuecomment-337622596,1,['interface'],['interface-based']
Integrability,"@droazen - a proposal for that, which will be great for my toolkit too, is to make `GATKTool` params an argument collection which defaults to the ones in the tool now, but can be change in a tool-basis. For example, if I have a `VariantWalker` which does not use any read-source, disabling all params for reads will be nice for re-use the `VariantWalker` interface without allowing the user to pass something that it is not used at all. It is not enough to provide a way to require or not a source, but to completely remove from the command line the ability to get that argument. I guess that's what it is required also for the CNV tools (correct me if I am wrong, @samuelkle), to be able to change that behaviour and to being able to provide custom documentation/arguments (re-factor the reads input `-I` to be other kind of input). I did something similar for the `ReadFilter` plugin to change the documentation and hide some arguments in my tools using it. Let me know if I can help with something in this direction, because it will be useful for me too...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2471#issuecomment-358254662:355,interface,interface,355,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2471#issuecomment-358254662,1,['interface'],['interface']
Integrability,"@droazen - please, clarify how the tests should be done. I'm going to be on vacation next week, so feel free to add them to this branch if you would like to speed up the process (taking into account that #3998 depends on this now). Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-377577797:210,depend,depends,210,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-377577797,1,['depend'],['depends']
Integrability,"@droazen - this is prepared from the next pass. Maybe you can answer the following questions before doing a full second pass:. * Your comment about ""Assert that you get the correct number of shards back"" is tested implicitly, by iterating over the expected shards. Should I really make it explicit?; * Does realistic size reads adds something to the unit test itself? The integration test for the real data (and probably a future PR with other sliding-window implementations) might be enough for the purpose of real data...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4682#issuecomment-389185267:372,integrat,integration,372,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4682#issuecomment-389185267,1,['integrat'],['integration']
Integrability,@droazen :man_facepalming: I wish we had thought of this ahead of time so we could have done the appropriate commit message rewrites...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2814#issuecomment-306012234:116,message,message,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2814#issuecomment-306012234,1,['message'],['message']
Integrability,"@droazen ; * A field is imported into TileDB/GenomicsDB from the input VCF/gVCF files irrespective of whether the combine operation exists or doesn't exist.; * During the query phase, when GenomicsDBFeatureReader is executed, if the combine operation isn't specified (either in the source or in the vid JSON) for an INFO field, it will not be available in the combined VariantContext objects (warning message showed up front).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-293997495:401,message,message,401,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-293997495,1,['message'],['message']
Integrability,@droazen @KevinCLydon If one of you wants to take a look at this that would be great. It updates a bunch of build and housekeeping stuff. It doesn't resolve all the dependency vulnerabilities yet.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8998#issuecomment-2414941314:165,depend,dependency,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8998#issuecomment-2414941314,1,['depend'],['dependency']
Integrability,"@droazen @cmnbroad @mbabadi I generally agree with the sentiments expressed in #4127, except that I think it's OK to require a conda environment (or even use of the Docker) for these particular tools. How we should validate this requirement is another question. We can discuss more with @vdauwera. @stefandiederich Hopefully once you get the conda environment set up you will be able to run the tools. We would definitely appreciate any feedback you might be able to provide. Note that the gCNV model is relatively sophisticated, so there may be some parameters (which control the priors for the model as well as how inference is performed) that you will need to adjust for your data. Depending on the number of intervals/bins you are using and your memory constraints, you may also need to scatter across multiple GermlineCNVCaller runs; see how things are done in the WDLs here: https://github.com/broadinstitute/gatk/tree/master/scripts/cnv_wdl/germline. As you noted, this pipeline is still in beta. We are currently running several evaluations and hope to soon release some Best Practices recommendations for the aforementioned parameter values that should work well for various data types generated at the Broad. We will also have some blog or forum posts that explain the new CNV pipelines in more detail coming soon---stay tuned!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357034364:685,Depend,Depending,685,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357034364,1,['Depend'],['Depending']
Integrability,"@droazen @davidbenjamin any thoughts regarding the last bullet above in https://github.com/broadinstitute/gatk/pull/6885#issuecomment-891907471 on possible integration tests? Started looking at this today and was wondering if you might have any suggestions. Ideally, we'd want to test that the exposure was done correctly through the 3 affected tools: HaplotypeCaller, Mutect2, and FilterAlignmentArtifacts. I can certainly take the approach outlined above and 1) on master, pick one or more integration tests for each tool, then generate results by changing the original unexposed constants and running on the relevant test data, 2) on this branch, commit those new results, then add corresponding versions of the integration tests that change the exposed inputs and check against the results. However, not sure if we'll want to clutter the repo with more test files just for this sort of exposing of constants, and such tests don't really feel complete anyway. So alternatively, I could probably write a script to do essentially the same thing and just check consistency between the branches for a bunch of randomly generated SW parameter values, perhaps also running on more substantial test files for each tool. I can document this process and then we can move on without committing any new tests or test files once we're satisfied that the exposure was done correctly. Or if you guys have additional suggestions, would be glad to hear them!. Finally, it looks like FilterAlignmentArtifacts doesn't have any integration tests for correctness---let me know if there are auxiliary tests we'd want to run there. Anyway, probably overthinking things, but the exposure was enough of a headache that I want to make sure I did it right. But would also rather fully hash out what to do beforehand, so I don't end up having to redo things after review.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-896314077:156,integrat,integration,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-896314077,4,['integrat'],['integration']
Integrability,"@droazen @lbergelson, in the new changes, I throw an illegal arugment exception if FeatureReader is null in the sampleToReaderMap. Also, if the sample name in the sampleToReaderMap does not match with the one in the header, I print a warning message. Let me know if these two changes will fix this issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2715#issuecomment-302257170:242,message,message,242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2715#issuecomment-302257170,1,['message'],['message']
Integrability,"@droazen @samuelklee this is a duplicate PR, I close the previous one. Travis was behaving strangely on the previous PR (oddly not picking up the correct commit for `continuous-integration/travis-ci/pr` test).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3183#issuecomment-311481750:177,integrat,integration,177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3183#issuecomment-311481750,1,['integrat'],['integration']
Integrability,@droazen After wrangling with this for a few hours I couldn't quite even get rid of the chr20-21 b37 mini references. There are too many integration tests of deep parts of the engine that I don't feel comfortable messing with. I'm throwing in the towel.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5313#issuecomment-451712041:137,integrat,integration,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5313#issuecomment-451712041,1,['integrat'],['integration']
Integrability,@droazen An existing integration test already tested the full pipeline including merging VCFs with GenomicsDB and creating the panel. I modified the input VCFs to contain multiallelic sites that previously failed.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6871#issuecomment-705910895:21,integrat,integration,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6871#issuecomment-705910895,1,['integrat'],['integration']
Integrability,"@droazen I didn't get a chance to do this yet. Once I do (most likely during next week), I will post here about any progress. However, as per @mlathara's message (https://github.com/broadinstitute/gatk/issues/6667#issuecomment-646167430), I do expect this to fix the issue. This potential fix has already been implemented by the bcbio_nextgen guys, so I'm going to be testing that precisely (https://github.com/bcbio/bcbio-nextgen/commit/336920a630d7f50b341eeeb4bad4ea6ab213f995). For what it's worth, I do think that setting up the VCF codec as default (instead of BCF) makes sense, at least until this bug is fixed. https://github.com/broadinstitute/gatk/issues/6667#issuecomment-646232210",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6548#issuecomment-646706502:154,message,message,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6548#issuecomment-646706502,1,['message'],['message']
Integrability,"@droazen I don't really have much of an opinion about the loggers. I think we chose log4j2 pretty arbitrarily and because it seemed popular. We don't have very complex logging needs so any logger pretty much satisfied our needs. . If there's a good reason to switch to SLF4J with a log4j backend that seems fine to me. It makes sense to use the more general solution so that people can use whatever backend they want. . I do know that we've encountered a lot of issues with having multiple copies of different logging frameworks included as transitive dependencies on spark. So there may be some hassle switching over, we'd have to run tests on google cloud to make sure we don't start crashing all of a sudden for logger related classpath issues. . @magicDGS I don't think anyone here cares that much about which logger we're using as long as it doesn't get in our way. If you want to do the switchover I think we'd be happy to accept a pull request as long as it didn't cause problems with our spark tools. Are you able to run our spark tools on gcloud dataproc?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-259003257:552,depend,dependencies,552,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-259003257,1,['depend'],['dependencies']
Integrability,"@droazen I investigated working in the other direction: i.e. refining the shading in google-cloud-java to remove the conflict. Unfortunately, I can't get it to work either. What I did was to shade less in google-cloud-java (see [this branch](https://github.com/tomwhite/google-cloud-java/tree/nio-bigquery)). With this change I could successfully run `ExampleBigQueryReader` from [this GATK branch](https://github.com/broadinstitute/gatk/tree/tw_jts_bigquery_spark_example): . ```; $ ./gradlew clean localJar; $ export GOOGLE_APPLICATION_CREDENTIALS=...; $ ./gatk ExampleBigQueryReader; ...; 14:16:43.468 INFO BigQueryUtils - Query returned 10 results.; ...; ```. However, the mini cluster for testing doesn't work any more:. ```; $ ./gradlew test -Dtest.single=ReadsSparkSinkUnitTest; org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSinkUnitTest.setupMiniCluster FAILED; java.lang.NoSuchMethodError: com.google.common.base.Objects.toStringHelper(Ljava/lang/Object;)Lcom/google/common/base/Objects$ToStringHelper;; ```. It seems that the Guava conflict can't be resolved either way, since the fundamental problem is that the internals of Hadoop (used for the mini cluster) depend on an older, incompatible version of Guava than BigQuery does.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-494393817:1190,depend,depend,1190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-494393817,1,['depend'],['depend']
Integrability,@droazen I profiled a lot and did some unit test experiments and basically there's no difference. Depending on average depths one or the other can be faster by up to 15 seconds per billion sites. I really just wanted to cull the list of open issues and had nothing against the old downsampler code. How about we close this PR *and* close Adam's GATK issue?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5074#issuecomment-433994089:98,Depend,Depending,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5074#issuecomment-433994089,1,['Depend'],['Depending']
Integrability,"@droazen I ran the latest version but the message about google is still there!. 14:08:05.607 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cm/shared/unil/software/8.3/GATK/4.1; .9.0-GCCcore-8.3.0-Java-8/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 14, 2020 2:08:06 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-708360241:42,message,message,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-708360241,1,['message'],['message']
Integrability,"@droazen I'm not sure this is an improvement. We want the fundamental unit of spark tool to be the transform, not the cli wrapper around it. If we do this then we're pushing more of the contract of the transform outside of itself, i.e. see the newly duplicated bqsr code. I think that it was a deliberate decision to lift all reads into the initial rdd and then filter them in the transforms to what was needed by that transform. This is paying some performance cost in multi-stage pipelines which will potentially apply the same filters over and over again, but it simplifies the code because the filters can be baked into the transform and the pipeline writer doesn't have to think about them. It would be nice if we had a mechanism for adding metadata to an RDD so we can say ""this is a sorted RDD filtered with X,Y,and Z filters"", so we could intelligently avoid re-filtering.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1159#issuecomment-158168856:122,wrap,wrapper,122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1159#issuecomment-158168856,2,"['contract', 'wrap']","['contract', 'wrapper']"
Integrability,@droazen Integration tests went from ~58 minutes to ~50 minutes as a result of this branch.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4992#issuecomment-403528803:9,Integrat,Integration,9,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4992#issuecomment-403528803,1,['Integrat'],['Integration']
Integrability,@droazen OK - the tests in `DataSourceUtilsUnitTest` pass for me locally. I had to substantially refactor the tests and I added some log messages and some `final` modifiers to clean up some other Intellij warnings.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6807#issuecomment-694956600:137,message,messages,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6807#issuecomment-694956600,1,['message'],['messages']
Integrability,"@droazen Thank you for the confirmation that HaplotypeCaller performs separate filtering passes on the read mapping qualities, and that the code on line 729 of HaplotypeCallerEngine.java (method ```filterNonPassingReads()``` ) is indeed executing subsequent to the ```MappingQualityReadFilter```. May I suggest, however, that MAPQ values less than 20 might not necessarily lead to an increase in FP variant calls? My understanding is that HaplotypeCaller uses MAPQ values only in a nonparametric rank sum test, in which case MAPQ is treated as an ordinal. This seems appropriate since the magnitude of a MAPQ value depends both on the data and on the computational model the read aligner uses to calculate it. With this in mind, a set of mappings with MAPQ in a lower range (e.g., ```--minimum-mapping-quality 10``` and a correspondingly lower ```--maximum-mapping-quality``` as well) might very well be appropriate for variant calling. So changing the semantics of ```MappingQualityReadFilter``` or parameterizing the currently-hardwired MAPQ range would enable additional control without affecting performance. @jamesemery I will watch for the HaplotypeCaller update that implements that functionality. And if you have a moment, could you please point me to the code that might be adversely affected by decreasing the low-end MAPQ threshold? I might have some ideas about that (or not!)... Thanks again!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6854#issuecomment-701512278:615,depend,depends,615,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6854#issuecomment-701512278,1,['depend'],['depends']
Integrability,@droazen This improves the error message we talked about in the meeting.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6779#issuecomment-683955730:33,message,message,33,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6779#issuecomment-683955730,1,['message'],['message']
Integrability,"@droazen This is a straight-up port -- it was copy and paste except I had to update some method names, like `alleleCount()` -> `numberOfAlleles()` and `sampleIndex` -> `indexOfSample`. And of course I couldn't port the changes to integration tests md5s.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2710#issuecomment-301089484:230,integrat,integration,230,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2710#issuecomment-301089484,1,['integrat'],['integration']
Integrability,@droazen We are still on hold for update the Funcotator datasources. Especially getting new versions of gencode would be desirable and does not work with the current scripts. We already started looking for alternatives for our routine diagnostics workflow.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-1231327112:227,rout,routine,227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7427#issuecomment-1231327112,1,['rout'],['routine']
Integrability,"@droazen When we finally remove CNNScoreVariants, don't forget that you can put an entry in the [DeprecatedToolsRegistry](https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/cmdline/DeprecatedToolsRegistry.java#L22-L24) with a helpful message about the replacement.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2121083870:278,message,message,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2121083870,1,['message'],['message']
Integrability,"@droazen Yeah, what @ronlevine mentioned could possibly do it, depending on where the data flows to next, i.e., if the header lines are then put back into a header, the contig line list in the new header should be correct if retrieved via getMetadataInSortedOrder() though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2753#issuecomment-304047071:63,depend,depending,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2753#issuecomment-304047071,1,['depend'],['depending']
Integrability,"@droazen Yes, the user has confirmed there are contigs in their eval VCF that are not in the truth VCF. This bug report is to improve the error message for this case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7562#issuecomment-969320338:144,message,message,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7562#issuecomment-969320338,1,['message'],['message']
Integrability,"@droazen any thoughts how we should proceed here, if at all? @ldgauthier reminded me that this story was unfinished and is getting a little stale. @fleharty take note if we want to report progress on this front to our MalariaGEN collaborators. On my end, there are a couple of things to do:; - [x] rebase and resolve conflicts; - [x] change TSV input as discussed above; - [x] add doc strings for new arguments; - [x] add integration tests to make absolutely sure exposure was done correctly, perhaps? I'm open to discussion about how this should be done. Complete coverage here will be difficult and perhaps not worth the effort, but I can probably put in a few tests that make sure changing the hard-coded values in master and doing the same via the exposed parameters in this branch have the same effect on a few existing test cases. However, while I'm doing the last three, I wonder if we could run whatever canonical evaluations/optimizations we have to see whether it's worth consolidating some of the parameter sets at this stage? I think there's an argument for having at least two sets (haplotype-to-reference + read-to-haplotype), but I'm not sure how to justify having a separate set for dangling heads/tails. But also not sure which set the latter should be consolidated with---@jamesemery thoughts? Again, let me reiterate that it seems that many of these parameter values were chosen arbitrarily (or, if not, that the procedure for choosing them has been lost). As a start, you can see the results of some optimizations I did on the CHM mix on slide 15 at https://docs.google.com/presentation/d/1zGuquAZWSUQ-wNxp8D6HhGNjIaFcV0_X9WAS4LODbEo/edit?usp=sharing Here, I optimized over haplotype-to-reference + read-to-haplotype SW parameters on various metrics after variant normalization using vcfeval. These optimizations were done using the Bayesian optimization framework I prototyped long ago (see https://github.com/broadinstitute/gatk-evaluation/tree/master/pipeline-optimizer and http",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-891907471:422,integrat,integration,422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-891907471,1,['integrat'],['integration']
Integrability,"@droazen exactly, the artifact will depend on `BigQueryUtils` which would be in a `gvs` package to hopefully make clear that the contents are currently fairly specific to GVS and probably not ideal for more general use in their present form.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8375#issuecomment-1604900043:36,depend,depend,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8375#issuecomment-1604900043,2,['depend'],['depend']
Integrability,"@droazen here are the error messages with gatk4.1.8.1 and gatk4.1.4.1:. 15:01:44.424 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cm/shared/unil/software/8.3/GATK/4.1.4.1-GCCcore-8.3.0-Java-8/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 09, 2020 3:01:45 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine. 14:28:22.786 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cm/shared/unil/software/8.3/GATK/4.1.8.1-GCCcore-8.3.0-Java-8/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 09, 2020 2:28:23 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-707085229:28,message,messages,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-707085229,1,['message'],['messages']
Integrability,"@droazen just for context, I punted on this in the linked PR (I'm not too familiar with the annotation interfaces, and it wasn't immediately obvious to me how to implement the required methods for ExcessHet). So @ldgauthier asked me to file this on the off chance that someone else wants to look at it in the future, but I think it's probably low priority. Seems like someone might have taken a previous unsuccessful stab at it; there were a few vestigial, commented-out `//@Override` lines.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7564#issuecomment-969270587:103,interface,interfaces,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7564#issuecomment-969270587,1,['interface'],['interfaces']
Integrability,"@droazen or anyone else from GATK: are you able to comment on the status of this bug, and any conversations that might be happening outside github? I posted earlier that #7962 (which is admittedly just a workaround), seems to side-step this exception. Do you foresee some other route to fix this?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7966#issuecomment-1208692561:278,rout,route,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7966#issuecomment-1208692561,1,['rout'],['route']
Integrability,@droazen sorry for a late response. I agree moving to java 17 would help. I do see that GATK itself is using the newer version of log4j but then its the transitive dependencies for the libraries used that bring in the older version of log4j. . this creates situations that the final compiled jar has both version of the log4j and this could create problems. . Gatk being a very useful tool gets integrated in multiple other tools and pipelines so in a way affecting the security posture of where its being used. The risk might be low being a standalone cli tool but its a very hard conversation with info security :) . May I ask for a ballpark ETA for the new version? Appreciate the work thats gone into this tool.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1448897264:164,depend,dependencies,164,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1448897264,2,"['depend', 'integrat']","['dependencies', 'integrated']"
Integrability,"@droazen sure. This PR updates both `BucketUtils.getPathOnGcs` and `IOUtils.getPath` (the latter indirectly) to create a Google Cloud Storage filesystem with a default reopen set to 3. Anyone opening the given `Path` (or even a `Path` derived from it, e.g. via `subpath`) will have the retries enabled. `addPrefetcher` wraps an existing `Path`, so it inherits the underlying `Path`'s retry behavior. Classes within htsjdk that create a `Path` from a String, without using our utility code, would indeed not set retries and errors on those files would not get the benefit of our extra retry. The exception to that is the Spark code path with `NioBam`: this goes via `ReadsIterable`, which also sets the retries. My understanding is that the normal way to open BAMs for tools always creates the `Path` object when parsing the command line, as in e.g. `ReadInputArgumentCollection::GetReadIndexPaths()`. That code path that calls `IOUtils.getPath` (and thus sets the retries). I would expect that the added support for VCF follows the same style, though it looks like it doesn't. If there's a code path that I missed where you think we need retries then please let me know so I can add it!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2506#issuecomment-289585791:319,wrap,wraps,319,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2506#issuecomment-289585791,1,['wrap'],['wraps']
Integrability,"@droazen thanks for the quick response! Just to be clear, my concerns were about testing that I didn't somehow screw up the original behavior through the exposure, not just testing that *some* behavior was exposed. But message received---will keep things on the simple side!. Also, please see the plots in #5564 to get an idea of the effect on outputs, if you haven't already. Would appreciate any thoughts you might have on that thread!. Will try to get this done in the next day or two, thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-896328697:219,message,message,219,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-896328697,2,['message'],['message']
Integrability,"@droazen the bam that I added was aligned with minimap2. However, it is a really small BAM, so I could not run it through the integration tests. It sounds useful to add minimap2-aligned bam to HaplotypeCallerIntegrationTest. Can you or @jamesemery point me to a suitable BAM for that?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8337#issuecomment-1558588144:126,integrat,integration,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8337#issuecomment-1558588144,1,['integrat'],['integration']
Integrability,"@droazen there are 3 minor changes here that were left over after the other branch got merged. The only controversial one might be unforcing the protobuff version, but I think it makes sense to just let it float at whatever the other dependencies require since that's what everything else does.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6736#issuecomment-840053329:234,depend,dependencies,234,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6736#issuecomment-840053329,1,['depend'],['dependencies']
Integrability,"@droazen this branch wasn't STRICTLY dependent on #5607, so I removed it from this branch to make reviewing easier. Its worth noting that the performance numbers and observed speedup were seen when this branch did hang off of #5607.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5616#issuecomment-460423597:37,depend,dependent,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5616#issuecomment-460423597,1,['depend'],['dependent']
Integrability,"@droazen, I updated the PR message to describe the changes, because I tried to get all the code referring to test resources packaged in src/test. Now it should pass the tests too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324295384:27,message,message,27,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324295384,1,['message'],['message']
Integrability,"@droazen, just to make sure I understand...you are suggesting that we keep doing the wrong things in GATK4 just so the integration tests match their results in GATK3?. Wouldn't it be better to have a GATK3_EQUIVALENCE_MODE flag and create new tests that do the right thing?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3680#issuecomment-342985499:119,integrat,integration,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3680#issuecomment-342985499,1,['integrat'],['integration']
Integrability,"@droazen, we have fixed all issues in genomicsdb code. the test now fails giving this message:. java.lang.AssertionError: Attribute MIN_DP expected [27.0] but found [27]; Expected :27.0; Actual :27. As I told you before I am using VariantContextTestUtils.assertVariantContextsAreEqual() to compare two feature reader iterators. is this the correct method to use?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-292376903:86,message,message,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-292376903,1,['message'],['message']
Integrability,"@droazen, yes despite the message about Google gatk4 runs well and I got an output file. Thanks for your support! I will run the latest version and see if it does not provide the Google message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-708305495:26,message,message,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-708305495,2,['message'],['message']
Integrability,"@droazen, yes, I built the dylib with all dependencies statically linked. That's why I am a little confused why these transitive dependencies are coming up. I am regenerating the dylib in my local environment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294233601:42,depend,dependencies,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294233601,2,['depend'],['dependencies']
Integrability,"@dwuab which issue/error are you specifically referring to? As indicated in the last message before you posted, the previous user was able to use GenomicsDBImport and GenotypeGVCFs after following our suggestions to break up large chromosomes into smaller intervals.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-900456302:85,message,message,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-900456302,1,['message'],['message']
Integrability,@erniebrau I don't think we can exclude log4j 1.x. A lot of our dependencies use it. This branch is failing with various ClassNotFound errors. ex: https://storage.googleapis.com/hellbender/test/build_reports/11489.3/tests/test/classes/org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSourceUnitTest.html#testReadFromFileAndHDFS,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320696279:64,depend,dependencies,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320696279,1,['depend'],['dependencies']
Integrability,"@erniebrau, the mesage and log file corresponds to the latest master (GKL 0.5.8); for the GKL 0.5.3 the error message is the following:. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x000000011dc557f4, pid=20586, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression1417468606951982528.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid20586.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. And the log file: [hs_err_pid20586.log.txt](https://github.com/broadinstitute/gatk/files/1264191/hs_err_pid20586.log.txt). Let me know if you need more information.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152:110,message,message,110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152,1,['message'],['message']
Integrability,"@felixm3 The bioconda environment doesn't actually configure the gatk conda environment (it installs gatk, but not the python dependencies required for CNNScoreVariants). You need to set up the gatk conda environment, as described in the Python Dependencies section in the README.md file: https://github.com/broadinstitute/gatk#readme.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7811#issuecomment-1275000632:126,depend,dependencies,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7811#issuecomment-1275000632,2,"['Depend', 'depend']","['Dependencies', 'dependencies']"
Integrability,"@fi1d18 It looks to me like the error message is correct. The input file you specified (`--INPUT NG-27280_CLTSS_LTS_001A_lib506241_7636_2_MarkedDup.bam`) is in fact not in the folder from which you're running, which you can see from the results of the `ls` command you provided:. ```; (gatk) root@34684eaa046e:/gatk/data/Continuum/WES/vcf# ls; GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz; ```. You can see that `NG-27280_CLTSS_LTS_001A_lib506241_7636_2_MarkedDup.bam` is not included in the `ls` output. If the input file is in another location, you'll need to specify it using either an absolute or relative pathname. If the problem persists after that, feel free to reopen this ticket.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8462#issuecomment-1677320234:38,message,message,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8462#issuecomment-1677320234,1,['message'],['message']
Integrability,"@fleharty @avalind ; Sorry, something happened with my previous message.; But what I wrote previously was that I couldn't reproduce the same error message using Picard ValidateSamFile. I tried validating my bam file and I don't see any errors. Even the samtools flagstat option works fine on my bam file.; Please find the attached screenshots,. <img width=""704"" alt=""picard"" src=""https://user-images.githubusercontent.com/6302819/88064375-8023f200-cb6b-11ea-960e-bab93f79ff22.png"">. <img width=""289"" alt=""flagstst"" src=""https://user-images.githubusercontent.com/6302819/88064447-9631b280-cb6b-11ea-86ee-6c49f9111507.png"">. Do you still think my bam file is malformatted?. PS: @fleharty used Picard version (2.20.4-SNAPSHOT), whereas I used v.2.23.2; for running Picard ValidateSamFile.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-661884614:64,message,message,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695#issuecomment-661884614,2,['message'],['message']
Integrability,"@fnothaft Thanks for the cleanup. I've seen that annotations take on different types depending on whether they were added during the current traversal or read in from a file, but I haven't run into any issues with the strand bias annotations so far. Do you have a specific use case for the int[] version?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4432#issuecomment-367345646:85,depend,depending,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4432#issuecomment-367345646,1,['depend'],['depending']
Integrability,"@gaze-abyss Can you check your `.table` input files to see whether they have a header that looks like this:. ```; #<METADATA>SAMPLE=sample; contig position ref_count alt_count other_alt_count allele_frequency; ```. The error message indicates that the tool is not finding the ""contig"" column for some reason, and a malformed header line is one possiblity.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7707#issuecomment-1061039784:225,message,message,225,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7707#issuecomment-1061039784,1,['message'],['message']
Integrability,"@gbrandt6 So now the protocol is that you wait for tests to pass (although it's unlikely this could break them...) and then you can merge with ""squash and merge"". You can edit the commit message in the browser to make sure it is clear. `Fix typo in --tmp-dir argument in GenomicsDB docs` is a pretty good description for this one though :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6785#issuecomment-684939263:21,protocol,protocol,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6785#issuecomment-684939263,4,"['message', 'protocol']","['message', 'protocol']"
Integrability,"@gevro The `HaplotypeCaller` adds padding to the intervals on its own. This is controlled by the `--assembly-region-padding` argument, which defaults to 100 bases on either side. Note that this controls both padding around user-provided intervals, as well as padding around each individual assembly region that the `HaplotypeCaller` discovers. Typically a single user interval will get divided into many assembly regions, depending on where variant activity is located.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6071#issuecomment-517371918:422,depend,depending,422,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6071#issuecomment-517371918,1,['depend'],['depending']
Integrability,"@gokalpcelik This isn't an insane request, but it's probably not going to happen very quickly. . I don't think it's a trivial change to just exclude log4j, we'd need a compatible replacement or you'd end up with crashes in weird places when a transitive dependency tries to log with it. We can (and might) do it, but it's not super high priority at the moment. I think there's internal interest in changing out the logger but at the moment our strategy is to patch to the newest version as they become available. . That said, if you find a way to build a log4j free version without weird issues please let us know :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7626#issuecomment-1005810220:254,depend,dependency,254,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7626#issuecomment-1005810220,1,['depend'],['dependency']
Integrability,"@gspowley Can you take a look? This problem started happening with https://github.com/broadinstitute/gatk/commit/dfa9cf1a420490285b7be7917082222a07e2b042. I can pretty reliably move back to the previous commit and it goes away. It always surfaces in the VariantSparkSinkUnitTests, but it seems to be the result of a cumulative effect since AFAICT it only happens when running the full test suite via ""./gradlew clean test"". I tried changing the default values of useJdkInflater and useJdkDeflater to true, and I still get the same problem. Interestingly, disabling all of the tests in IntelInflaterDeflaterIntegrationTest seems to reliably fix it (even with useJdkInflater/Deflater set to false), so I'd start there. If thats the culprit, it might explain why we don't see this in travis since we run the unit tests and integration tests separately there.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2490#issuecomment-288098956:820,integrat,integration,820,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2490#issuecomment-288098956,1,['integrat'],['integration']
Integrability,@gspowley Could you route this bug report to whoever is able to deal with this nowadays?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-465238238:20,rout,route,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-465238238,1,['rout'],['route']
Integrability,@gspowley Looks like integration tests are failing?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-282054550:21,integrat,integration,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-282054550,1,['integrat'],['integration']
Integrability,"@heuermh Thanks for your input, we'll look into those options. I think the use case most of us are imagining is for narrow tables with ~1M-1B records or fewer (sometimes far fewer). For the CNV pipeline, Tribble support is a much higher priority than Hadoop integration, efficient compression, etc., and it's very unlikely we'll need to do out-of-core computations that won't be enabled by Tribble. However, that might not be true of more general use cases, so it's certainly worth investigating more robust formats. @SHuang-Broad For all current CNV use cases, we use separate columns for each annotation. Not sure how much VCF code actually needs to be shared if all we care about is extracting parsing and Tribble indexing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-481408414:258,integrat,integration,258,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-481408414,1,['integrat'],['integration']
Integrability,@iAMSe What's the error? `Shutting down engine` is a normal message that shows up in normal runs. Is it producing output that seems correct?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8204#issuecomment-1432199784:60,message,message,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8204#issuecomment-1432199784,1,['message'],['message']
Integrability,"@ilyasoifer I don't know why it's using so much more memory now than it used to. I did notice you're not running with all of the options we usually specify for spark though. There are a few options we set via the `gatk` wrapper script. I'm not 100% sure if they're all still important but we set them for a reason in the distant past. I would try adding them as --conf options. I think it's possible that they have significant impact on the memory usage.; ```; ""spark.kryoserializer.buffer.max"" : ""512m"",; ""spark.driver.maxResultSize"" : ""0"",; ""spark.driver.userClassPathFirst"" : ""false"",; ""spark.io.compression.codec"" : ""lzf"",; ""spark.executor.memoryOverhead"" : ""600"",; ""spark.driver.extraJavaOptions"" : EXTRA_JAVA_OPTIONS_SPARK,; ""spark.executor.extraJavaOptions"" : EXTRA_JAVA_OPTIONS_SPARK; ```. EXTRA_JAVA_OPTIONS_SPARK is; ```; ""-DGATK_STACKTRACE_ON_USER_EXCEPTION=true "" \; ""-Dsamjdk.use_async_io_read_samtools=false "" \; ""-Dsamjdk.use_async_io_write_samtools=false "" \; ""-Dsamjdk.use_async_io_write_tribble=false "" \; ""-Dsamjdk.compression_level=2 ""; ```. Now, David was suggesting that you try running using spark-submit and specify explicit memory commands for the driver/executors. I'm not convinced this will help, but it's worth trying. that this will help, but it's worth trying. ; If you have spark-submit on your path you can either call it directly with `--master local[24]` or use `gatk --spark-runner SPARK --spark-master local[24] ... [the rest of the arguments]` which will construct the appropriate call. . ```; gatk \; MarkDuplicatesSpark \; --spark-runner SPARK \; --spark-master ""local[24]"" \; --input in.bam \; --output out.bam \; --create-output-bam-index true \; --spark-verbosity WARN \; --verbosity WARNING; --driver-memory 8G \; --executor-memory 4G ; ```. Something like that. I'm honestly not sure how it will handle those memory requests in local mode though since it all runs in the same process. I suspect it will just add them up and set xmx using the sum. . The oth",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8307#issuecomment-1564851825:220,wrap,wrapper,220,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8307#issuecomment-1564851825,1,['wrap'],['wrapper']
Integrability,"@imneuro The easiest thing to do is to use the GATK docker image, however, if you like you can install R and then run the R script found [here](https://github.com/broadinstitute/gatk/blob/master/scripts/docker/gatkbase/install_R_packages.R) to get the required R dependencies. Also, these kinds of questions can be best handled by posting on the GATK forum - github issues are for bugs/feature requests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2199#issuecomment-484250130:263,depend,dependencies,263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2199#issuecomment-484250130,1,['depend'],['dependencies']
Integrability,"@jamesemery @cmnbroad This fixes a personal pet peeve of mine, which is that we're packaging a bunch of test classes as a runtime dependency. It splits out a new test artifact which contains just the classes in utils.test and allows it to be published and consumed separately from the rest of the gatk. This allows us to make testng and minicluster no longer compile dependencies",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5112#issuecomment-413011677:130,depend,dependency,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5112#issuecomment-413011677,2,['depend'],"['dependencies', 'dependency']"
Integrability,"@jamesemery @droazen I've updated this branch to ensure all read and write paths to shared state in `GenotypeLikelihoodCalculators` is synchronized. I then wrote a little [test](https://github.com/broadinstitute/gatk/commit/3bb178746b1dd286f55ba77e6939e2104ced98d0) using `AlleleSubsettingUtils` to access `GenotypeLikelihoodCalculators` 10^6 times to see the effect of adding synchronization. R session (times are in millis):; ```; > without_sync = c(10166, 10049, 10306, 10059, 10165); > with_sync = c(10700, 10384, 9923, 10097, 10190); > t.test(without_sync, with_sync, paired=TRUE). 	Paired t-test. data: without_sync and with_sync; t = -0.70447, df = 4, p-value = 0.52; alternative hypothesis: true difference in means is not equal to 0; 95 percent confidence interval:; -542.5421 322.9421; sample estimates:; mean of the differences ; -109.8 ; ```. The p-value is not less than 0.05, so we can't reject the null hypothesis (that the mean times are the same). So adding synchronization doesn't seem to make any difference in this test. BTW, I noticed that `GenotypeLikelihoods` has synchronization, so there is some precedent for thread-safety using this means.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5071#issuecomment-426338479:135,synchroniz,synchronized,135,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5071#issuecomment-426338479,4,['synchroniz'],"['synchronization', 'synchronized']"
Integrability,@jamesemery Could you also add an integration test with the pipeline above? You'll need to run bash using `ProcessController` or similar,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4167#issuecomment-358108007:34,integrat,integration,34,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4167#issuecomment-358108007,1,['integrat'],['integration']
Integrability,"@jamesemery Hey James. Is it possible to add an error message stating that the user needs to set --TMP_DIR to a bigger disk? Another user posted ""It would be nice some warning about low disk space instead of crashing after running for so many hours.""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4487#issuecomment-398159225:54,message,message,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4487#issuecomment-398159225,1,['message'],['message']
Integrability,"@jamesemery I agree - all access (read and write) to `GenotypeLikelihoodCalculators` instance variables needs to be synchronized to make it safe. I think it would be sufficient to make `getInstance()` and `calculateGenotypeCountUsingTables()` synchronized. @droazen, are you concerned about performance for the Spark case? For the walker version, presumably the access is single-threaded, and hence [uncontended, which is very cheap](https://books.google.co.uk/books?id=mzgFCAAAQBAJ&pg=PA230&lpg=PA230&dq=java+uncontended+synchronization+goetz&source=bl&ots=7W4J807faW&sig=YALE1qdWoAUELPqLRhIedz-bZ20&hl=en&sa=X&ved=2ahUKEwj4jJeko8zdAhXVFsAKHazkBrcQ6AEwB3oECAIQAQ#v=onepage&q=java%20uncontended%20synchronization%20goetz&f=false). Another option would be to maintain a separate instance of `GenotypeLikelihoodCalculators` per genotyping engine. The size of the table is ploidy * alleles, so not too large?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5071#issuecomment-423546586:116,synchroniz,synchronized,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5071#issuecomment-423546586,3,['synchroniz'],"['synchronization', 'synchronized']"
Integrability,"@jamesemery I think this is because the annotation plugin, which has the pedigree arg, hasn't been integrated with the tools yet (second part of https://github.com/broadinstitute/gatk/issues/3287) ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4604#issuecomment-376905093:99,integrat,integrated,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4604#issuecomment-376905093,1,['integrat'],['integrated']
Integrability,"@jamesemery This depended on #5416, which has since been merged. What's the status of this PR now?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5451#issuecomment-582715942:17,depend,depended,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5451#issuecomment-582715942,1,['depend'],['depended']
Integrability,"@jamesemery This was the first pass where I reviewed the tests, so there are a bunch of new comments, and also some issues with the founder id integration.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3851#issuecomment-361723540:143,integrat,integration,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3851#issuecomment-361723540,1,['integrat'],['integration']
Integrability,"@jamesemery What about supporting an initialize() method on VariantAnnotation? This is GATK3-like, and would be non-disruptive to existing code, since the interfaces could have a default no-op implementation? . /**; * Provides an opportunity to set up context; */; public void initialize(VariantAnnotatorEngine engine) {. }. Then we could address whether any context is appropriate to expose via methods on VariantAnnotatorEngine?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-754274008:155,interface,interfaces,155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-754274008,1,['interface'],['interfaces']
Integrability,"@jamesemery You should include a `Resolves #issuenumber` line in your commit message, so that the linked issue will be auto-closed on merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3350#issuecomment-317537842:77,message,message,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3350#issuecomment-317537842,1,['message'],['message']
Integrability,"@jamesemery in order to get the tests to pass I had to regenerate one of the expected output vcf's for a GenotypGvcfs integration test, which makes sense because I'm changing the way we annotate variant id's. Can I just get a quick thumbs up if you are comfortable with this additional change before I merge, assuming tests now pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6626#issuecomment-639121904:118,integrat,integration,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6626#issuecomment-639121904,1,['integrat'],['integration']
Integrability,"@jamesemery sorry to bug on this topic, but I'm hoping to make a push early this year to fully migrate my lab off GATK3 . I looked more closely at the specific annotations we need to migrate. I decided that I will implement our walker, 'DiscvrVariantAnnotator', which is basically a light wrapper around VariantAnnotation. This will make it easier to spike in custom annotations. In that walker, I will override makeVariantAnnotations(). I will make a new marker interface for EngineAwareAnnotation, and test that on all the Annotation classes, and use this to inject FeatureManager. So no core GATK changes needed. I did find one thing I'd like to propose. You probably know PedigreeAnnotation is special-cased in GATK. Annotations that use it have automatic argument validation and have the SampleDB injected. Currently, PedigreeAnnotation is a subclass of InfoFieldAnnotation, so isnt available to GenotypeAnnotations. There doesnt appear to be a solid reason why. I tried to fix that and my best idea is the proposal here: #7041 . The core idea is to convert InfoFieldAnnotation and GenotypeAnnotation to interfaces. This is generally a trivial switch in existing code. With that, it becomes possible for classes that currently extend PedigreeAnnotation (which I switched to no longer extend InfoFieldAnnotation) to simply PedigreeAnnotation and implement InfoFieldAnnotation. This makes it possible for future classes to extend PedigreeAnnotation and implement GenotypeAnnotation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-760424063:289,wrap,wrapper,289,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930#issuecomment-760424063,10,"['inject', 'interface', 'wrap']","['inject', 'injected', 'interface', 'interfaces', 'wrapper']"
Integrability,"@jamesemery, yes, I've opened #5248 with the isolated fix (and unit test). I'll leave this open for the `CollectAllelicCountsSpark` changes, which I'll update when the other changes it depends on are merged.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5222#issuecomment-426317398:185,depend,depends,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5222#issuecomment-426317398,1,['depend'],['depends']
Integrability,"@jason-weirather Interesting. I have no trouble accessing the FTP site from outside the Broad. What kind of error message are you getting?. There is a new version from 3/29 that has several fixes in it, in addition you'll need to make sure you have the latest GATK code (you may need to pull the source code rather than a release - I'm not sure when the last release was and some fixes required both data source changes and code changes). If you can wait a few days we're planning on doing another minor / bugfix release this week. In general it's probably not worth trying to fix errors in the data sources - you may find yourself going down a rabbit hole. That said, one of the things that was fixed was that data source line in the gencode file. There shouldn't be very many __UNKNOWN__ fields (if any at all) - at least there aren't when running with the latest version of everything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383404016:114,message,message,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383404016,1,['message'],['message']
Integrability,@jberghout If you post your actual output we might be able to track down your variant of the problem (the error message in the original post looks to me somewhat like a corrupt gradle cache: error reading /vsc-hard-mounts/leuven-user/304/vsc30484/.gradle/caches/modules-2/files-2.1/org.spire-math/spire_2.11/0.11.0/998b1c1d841baf4fc5d1b119ea55f165f6684ef5/spire_2.11-0.11.0.jar; error in opening zip file). Is it the `gatkTabComplete` task that is failing for you as well ?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566793345:112,message,message,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566793345,1,['message'],['message']
Integrability,"@jean-philippe-martin Agree that we probably shouldn't refactor `IntegrationTest` as part of this PR, but it looks like some other tests are failing now. The PR build failures are [here](https://travis-ci.com/broadinstitute/gatk/builds/97887212). There are some CRAN mirror problems that are affecting all builds at the moment, but there are also some failures that are fallout from the `IntegrationTest` changes. See [this](https://travis-ci.com/broadinstitute/gatk/jobs/171535202). The previous (`XReadLines`) code was gzip aware, but the new code is not, which is causing the test failures.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-456645889:65,Integrat,IntegrationTest,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-456645889,2,['Integrat'],['IntegrationTest']
Integrability,"@jean-philippe-martin Can you comment on this one? It looks like `google-cloud-java` recently bumped their `google-auth-library-credentials` and `google-auth-library-oauth2-http` dependencies to `0.8.0` -- was there some change that would require us to modify our authentication-related code in GATK, and/or the permissions setup in our Google Cloud project, that could explain the error:. ```; Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330936001:179,depend,dependencies,179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330936001,1,['depend'],['dependencies']
Integrability,"@jean-philippe-martin Could you request a dot release? If they say no, we'll go the custom jar route.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2220#issuecomment-257688566:95,rout,route,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2220#issuecomment-257688566,1,['rout'],['route']
Integrability,"@jean-philippe-martin I can wrap the `CloudStorageFileSystemProvider.checkAccess()` method in a retry, but can you think of any other methods *outside* of `CloudStorageReadChannel` that might also require a retry?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314891599:28,wrap,wrap,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314891599,1,['wrap'],['wrap']
Integrability,"@jean-philippe-martin I had assumed that there were already CRAM tests in ReadUtilsUnitTest for the old createSAMWriter method, but there aren't (there are integration tests that exercise the cram code path through PrintReadsIntegrationTest.) In general you have to just know which reference goes with which cram. The canonical file we use is print_reads.cram/print_reads.fasta (in the tools test folder). You should probably copy them into the ReadUtils test folder to use it in those tests. If you do,you'll have to also copy print_reads.fasta.fai, or you'll get misleading CRAM errors. Also note that you won't be able to use iterator comparison when comparing an Iterator<CRAMRecord> with Iterator<BAMRecord>.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332212832:156,integrat,integration,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332212832,1,['integrat'],['integration']
Integrability,"@jean-philippe-martin I like your counter proposal in general for testing path integration. I think writing to GCS over NIO is an important enough feature that we should have at least 1 test in gatk that actually writes to a real GCS bucket in case there's ever an issue specifically with GCS (authentication issues are one potential problem I can imagine). . It seems like we should be able to design in a way that avoids collisions. What does `Files.createTempFile()` do with gcs? My guess is that it probably doesn't do the right thing, but maybe we could fix it so it would? Or use some sort of scheme with random UUID's like the methods in BucketUtils that we have already.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332235140:79,integrat,integration,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332235140,1,['integrat'],['integration']
Integrability,"@jean-philippe-martin Possibly we were using the GCS<->HDFS adapter previously, and something changed in the code to make us use NIO here instead? (possibly https://github.com/HadoopGenomics/Hadoop-BAM/pull/111?)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-265002735:60,adapter,adapter,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-265002735,1,['adapter'],['adapter']
Integrability,"@jean-philippe-martin Sorry, the baby was not very asleep last night so I may be slightly less coherent than usual... . I see how you heard that, but it wasn't what I meant. What I mean was that we should eventually move the information about how to set -DSTACK_TRACE_ON_USEREXCEPTION into the top level UserException message to make it discoverable, and remove it from the comment it's in now. Lets do that in a different PR though since it's sort of orthogonal and the best thing to do might be to integrate it as a regular commandline option instead of an environment variable. Separately from that, I was wondering if we should catch StorageExceptions at the top level and handle them specially. If we're going to do that I think we could just add them to the UserException catch block and have them be treated the same way, no need for special handling.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2417#issuecomment-285152468:318,message,message,318,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2417#issuecomment-285152468,2,"['integrat', 'message']","['integrate', 'message']"
Integrability,"@jean-philippe-martin Thanks for adding the additional test, but by ""integration test"", I meant something that exercises an actual tool (which is why I mentioned SelectVariants) with a non-default provider, not another unit test that uses GCS. I suggested SelectVariants since I thought it would be easy:. > all the previous comments have been addressed with the exception of adding a SelectVariants integration test. It should be pretty easy to clone an existing case and change it use a non-default nio provider. I think this last test is redundant with the one you already added. My apologies if that was confusing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-455668135:69,integrat,integration,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-455668135,2,['integrat'],['integration']
Integrability,@jean-philippe-martin That's great news. Unfortunately we can't easily update the NIO dependency until we have some solution to https://github.com/googleapis/google-cloud-java/issues/5884,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-516442831:86,depend,dependency,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-516442831,1,['depend'],['dependency']
Integrability,"@jean-philippe-martin Will there be a gcloud release with this change within the next ~week? We're rather urgently in need of a short-term fix, unfortunately. If a gcloud release isn't imminent, would it be an option to move GATK to depend on a gcloud snapshot?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-304124941:233,depend,depend,233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-304124941,1,['depend'],['depend']
Integrability,"@jean-philippe-martin has added support for requester pays to gcloud. ; See https://github.com/GoogleCloudPlatform/google-cloud-java/pull/3406 . I've set up a new fork of the project at https://github.com/broadinstitute/google-cloud-java. I have a branch https://github.com/broadinstitute/google-cloud-java/tree/lb_update_pom_to_publish_to_orgbroad which I believe should make the changes necessary to run on dataproc and avoid https://github.com/GoogleCloudPlatform/google-cloud-java/issues/2453. However, if you rollback the dependencies the project no longer compiles. You can compile the nio-subproject, but the parent project can no longer build against the old dependencies. That makes me very nervous because it seems likely that we will encounter runtime errors if we substitute them. . JP created a small test case to reproduce the error and it seems like the dataproc team is looking at it. Hopefully they can resolve the issue and we can switch to the base library instead of needing to publish an additional sketchy version of it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4828#issuecomment-404322757:527,depend,dependencies,527,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4828#issuecomment-404322757,2,['depend'],['dependencies']
Integrability,"@jean-philippe-martin, when you have a chance could you please take a look at the stack trace above and give your thoughts? Our NIO library dependency was not upgraded between 4.0.11.0 and 4.0.12.0 (it was last upgraded in 4.0.9.0), so it's not clear what it is about 4.0.12.0 that is leading to this higher failure rate. . We've already tried a custom build of 4.0.12.0 that included the version of htsjdk from 4.0.11.0, but that didn't help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459838085:140,depend,dependency,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459838085,2,['depend'],['dependency']
Integrability,"@jfarrell Do you recognize ""scc"" as a local host name ? ""hdfs:///project/casa/gcad/adsp.cc/sv"" looks reasonable enough as a file URI, except that the hadoop file system provider requires an authority component (the part of the uri between the second and third slash: ""hdfs://authority-component/..."") be provided in such URIs. Since you didn't include one as part of the hdfs path on the command line, it looks like transform along the way resulted in one being added (the authority component looks like ""host:port""), resulting in the port number -1. So I'm not clear if its a configuration issue, or a bad code code path, or both. But I would suggest trying an hdfs path with a valid authority component (one that works with the hadoop shell). @SHuang-Broad I do see some code paths in `StructuralVariationDiscoveryPipelineSpark` that call `Paths.get directly`, rather than `IOUtils.getPath()`. I would also suggest replacing the direct calls to `makeSAMOrBAMWriter` in `SVFileUtils` with the GATK wrapper code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-493980166:999,wrap,wrapper,999,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5942#issuecomment-493980166,2,['wrap'],['wrapper']
Integrability,"@jingydz The error message; `Feature inputs must be unique: /data/users/zhanglei/species/Medicago/result/SRR340103.HC.g.vcf.gz` says exactly what the problem is, which is that you have a duplicate input:. /data/users/zhanglei/species/Medicago/result/SRR340102.HC.g.vcf.gz --variant /data/users/zhanglei/species/Medicago/result/**SRR340103.HC.g.vcf.gz** --variant /data/users/zhanglei/species/Medicago/result/**SRR340103.HC.g.vcf.gz** --variant /data/users/zhanglei/species/Medicago/result/SRR340104.HC.g.vcf.gz --variant",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5947#issuecomment-493674150:19,message,message,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5947#issuecomment-493674150,1,['message'],['message']
Integrability,@jjfarrell Thanks for the update. This error message indicates an invalid index file - older versions of GATK/HTSJDK didn't report these. Reindexing is the correct remedy.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7076#issuecomment-779851653:45,message,message,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7076#issuecomment-779851653,1,['message'],['message']
Integrability,"@jjfarrell That error message usually indicates that the reference supplied isn't the same (exact) same one that was used to create the cram. Can you try using `samtools view` on the same file/ref pair, and see if that works.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449485244:22,message,message,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449485244,1,['message'],['message']
Integrability,"@jjfarrell You don't need splitting index for cram. The index works around a bam specific problem which makes it hard to find good split points in the file. Cram is designed in a way that makes it easier to find the split points so the index is unnecessary. . I don't have good numbers for how long it takes to find the split points for bam. It depends on your filesystem. If you have a low latency file system like a local disk or hdfs setup than finding split points takes very little time (~seconds), but if you have a high latency file system like something backed by google object store then finding split points may take a long time (on the order of minutes to tens of minutes depending on latency and file size).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371224015:345,depend,depends,345,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371224015,2,['depend'],"['depending', 'depends']"
Integrability,@jmthibault79 This fails with a compiler error: . ```; :compileTestJava/home/travis/build/broadinstitute/gatk/src/test/java/org/broadinstitute/hellbender/engine/spark/datasources/VariantsSparkSinkUnitTest.java:240: error: cannot find symbol; return inferFromUncompressedData(IOUtil.isGZIPInputStream(bis) ? new GZIPInputStream(bis) : bis);; ^; symbol: method isGZIPInputStream(BufferedInputStream); location: class IOUtil; 1 error; FAILED; ```. I think you perhaps need to update the htsjdk dependency to a release that includes this change?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5583#issuecomment-454957265:491,depend,dependency,491,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5583#issuecomment-454957265,1,['depend'],['dependency']
Integrability,"@jonn-smith - I think that it is a good idea to have a codec interface for non-locatables, but `Tribble` is designed for working with indexed data sources __by coordinate__ (the same as `Tabix`). I think that the proposal that you are making here for HTSJDK should be a different implementation, without messing up with the tribble code. Otherwise, tribble will lose the sense of working with coordinate-sorted data...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3760#issuecomment-340693533:61,interface,interface,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3760#issuecomment-340693533,1,['interface'],['interface']
Integrability,"@jonn-smith @LeeTL1220 @droazen Thanks for sharing the information above, and I looked at it. It seems to me that once we have a chain file for one reference and another reference, the remaining steps are straightforward. I also noticed the following Picard utility [Picard LiftoverVcf]( https://broadinstitute.github.io/picard/command-line-overview.html#LiftoverVcf ) that can Lift over a VCF file from one reference to another. ; Therefore, creating the chain file between a pair of references (and limiting ourselves to cases where both references are from the same species, mouse/human) is the key. To that end, according to the following post [List of chain file creators](https://www.biostars.org/p/65558/) most of the chain file creation tools are available as a web interface. However, the UCSC one seems to be more popular, and fortunately, they have the utilities as open source and to some degree explain their steps in the [LiverOver_Howto](http://genomewiki.ucsc.edu/index.php/LiftOver_Howto) link you sent. With this approach, they first BLAT the pairwise contigs in the reference files and then use the utility DoSameSpeciesLiftOver.pl. . Based on this, it appears to me I should think about the following steps:; a) First, try out their code (UCSC) and make sure it works to produce chain files for two references successfully.; b) Design/propose a solution putting the logic in DoSameSpeciesLiftOver.pl into GATK, which also might need a BLAT run . Let me know what you think of this or have any suggestions about how I should proceed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6837#issuecomment-804188470:774,interface,interface,774,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6837#issuecomment-804188470,1,['interface'],['interface']
Integrability,@jonn-smith I'll add that it would be good to include an end-to-end integration test here as well to prove that the tool can successfully run to completion when the bounds-checking gets triggered.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7513#issuecomment-948797839:68,integrat,integration,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7513#issuecomment-948797839,1,['integrat'],['integration']
Integrability,@jonn-smith This should be good to go now. I added a non-regenerated integration test for the specific problem.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6178#issuecomment-538132773:69,integrat,integration,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6178#issuecomment-538132773,1,['integrat'],['integration']
Integrability,"@jsotobroad The version I pushed up should be good for you to test with. There are some more bells and whistles that need to be added around user interface, but the fundamental of fixing the sample assignment should be good.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3675#issuecomment-334882135:146,interface,interface,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3675#issuecomment-334882135,1,['interface'],['interface']
Integrability,"@kcibul Can you try re-running with a build of https://github.com/broadinstitute/gatk/pull/2417, and paste the (hopefully) more detailed error message here?. Can you also try with a few different files in different buckets, and see whether you get the same error in every case?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2415#issuecomment-281521368:143,message,message,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2415#issuecomment-281521368,1,['message'],['message']
Integrability,"@kcibul My reasoning for doing it in WDL is to better integrate with the process that creates the VAT table, and therefore make sure that the person running it has access (and knows the location of) not only to the VAT table but also the intermediary steps (e.g. the annotation JSON files that are output from NIRVANA). Not all of the validation steps need to be all bash; the first one was because it's literally just a call to make sure a table exists and has rows with `vid` values in it. Other rules (e.g. [rule #2](https://github.com/broadinstitute/dsp-spec-ops/issues/365)) will most likely need either python or jq to run.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7352#issuecomment-883457790:54,integrat,integrate,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7352#issuecomment-883457790,1,['integrat'],['integrate']
Integrability,@kdatta Can you build GenomicsDB with static linkage of dependencies to guard against this sort of thing? That is what we do for the GKL.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294233248:56,depend,dependencies,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294233248,1,['depend'],['dependencies']
Integrability,@kdatta How's the integration test coming? Any issues writing it? Will it be pushed soon? Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-290445381:18,integrat,integration,18,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-290445381,1,['integrat'],['integration']
Integrability,"@kdatta I think the reason its failing is because the dylib has an unresolved transitive dependency on openssl (and possibly other things). When I debug locally, I can see that it has streamed the dylib out to a local folder and its trying to load it, but then I get this (see the highlighted text):. /private/var/folders/cr/16ghvyfj5lvfwxx01rt1k4tdl04sy3/T/libtiledbgenomicsdb2535884808429708562.dylib: dlopen(/private/var/folders/cr/16ghvyfj5lvfwxx01rt1k4tdl04sy3/T/libtiledbgenomicsdb2535884808429708562.dylib, 1): Library not loaded: **/usr/local/opt/openssl/lib/libssl.1.0.0.dylib**; Referenced from: /private/var/folders/cr/16ghvyfj5lvfwxx01rt1k4tdl04sy3/T/libtiledbgenomicsdb2535884808429708562.dylib; Reason: image not found. It looks TileDB does have such a dependency ([here](https://github.com/Intel-HLS/TileDB/blob/master/CMakeLists.txt#L79)). Do you know if thats new ? I think we need to figure out how many of these there are and resolve them somehow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294230131:89,depend,dependency,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294230131,2,['depend'],['dependency']
Integrability,@kdatta Is the version of protobuffs that gatk depends on compatible with the version that genomicsDB needs?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2588#issuecomment-292757482:47,depend,depends,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2588#issuecomment-292757482,1,['depend'],['depends']
Integrability,"@kdatta Looks like the integration tests passed on travis after clearing the cache! Once you address comments, squash, and rebase onto the latest gatk master the unit tests should pass as well, since you just need the TestNG fix that got merged into master. This means we can merge this today in all likelihood!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-296301829:23,integrat,integration,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-296301829,2,['integrat'],['integration']
Integrability,"@kdatta Thanks for the update -- we do need to get these tests passing with our `assertVariantContextsAreEqual()` comparison routine, rather than your diffing tool, but we can relax this routine to be agnostic to allele ordering. About the `MIN_DP` issue: can you explain what was causing it? Why was it working with a `VCFCodec` and not a `BCF2Codec`? I still don't understand. Does it work now with our comparison routine and using a `BCF2Codec` internally, or does it still require a `VCFCodec` to pass? . And what was the ""ExcessHet problem"" (don't see a description of it above)? Was it just the ""no combination operation"" warning? What did the output look like before and after the fix for this annotation?. @cmnbroad has volunteered to have a look at the tests in this branch this afternoon, so we should be able to give you some more feedback soon!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-293978277:125,rout,routine,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-293978277,6,['rout'],['routine']
Integrability,"@kdatta The Spark build broke last time because of a jar signature file from the `gnu.getopt` dependency that made it into our final GATK jar, not because of `protobuf-java-format`. We've now excluded these signature files from our jar. When will `genomicsdb-0.6.0` be released?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2634#issuecomment-297980594:94,depend,dependency,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2634#issuecomment-297980594,1,['depend'],['dependency']
Integrability,"@kdatta We'd prefer it if the tool could accept intervals and vcfs, and create whatever internal objects it needs to talk to GenomicsDB. This way, when you do the overhaul you're talking about, the command-line interface to this tool (and therefore pipeline scripts that invoke it) won't have to change. This would also enable it to be a more-standard `GATKTool` rather than a raw `CommandLineProgram`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-277331110:211,interface,interface,211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-277331110,1,['interface'],['interface']
Integrability,"@kew24 Thanks for the bug report! Would you be satisfied if we just changed the text of the error message to read ""The last overlapping interval is ....""?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8103#issuecomment-1329723947:98,message,message,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8103#issuecomment-1329723947,1,['message'],['message']
Integrability,"@kguraj It looks like there are existing integration tests that use intervals that cover a pretty wide genomic range. It should be easy to write a test that programmatically generates a large set of (10000) or so very small intervals (1bp) with small (1bp) gaps between them (the gaps are necessary since otherwise the intervals will be merged together by the engine) that fails without this change and passes with it. It doesn't necessarily have to verify the results, just successfully complete.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407056469:41,integrat,integration,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407056469,1,['integrat'],['integration']
Integrability,"@kguraj Thanks for the response(s). The test in the PR was super useful as a temporary test, but as you mentioned it runs pretty slowly, and as it stands the test passes on current master anyway. It seems to require on the order of 9000-1000 intervals instead rather than 1000 to actually hit stack overflow. Since that would be a very slow running test, I'm inclined to back it out. Also, the user who originally reported the issue was using 11k intervals, and it seems that the stack overflow fix is unlikely to help in that case. Is there any guidance for users on what is a reasonable number of intervals per process ? It sounds like the intention was that it be used with pretty small intervals. Should we issue a warning message in GenomicsDBImport at some threshold number of intervals ?. Are you planning to produce a jar with the error messages suppressed for this PR?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407867902:727,message,message,727,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407867902,4,['message'],"['message', 'messages']"
Integrability,"@kgururaj @ldgauthier I'd propose that we add defensive code to detect this, as @kgururaj proposed above. Maybe throw with a message identifying the name of the field and the issue ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5045#issuecomment-408081250:125,message,message,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5045#issuecomment-408081250,1,['message'],['message']
Integrability,@kgururaj Can you please add a good integration test for this branch?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3982#issuecomment-357057167:36,integrat,integration,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3982#issuecomment-357057167,1,['integrat'],['integration']
Integrability,@kgururaj Can you take a look and see if we can issue a more informative error message.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5064#issuecomment-408492983:79,message,message,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5064#issuecomment-408492983,1,['message'],['message']
Integrability,"@kgururaj Do those first messages originate [here](https://github.com/Intel-HLS/TileDB/blob/33ad0355db215cb528162a74c16b706a059b0346/core/src/storage_manager/storage_manager.cc#L1168) ? I'm not sure what GenomicsDB code path leads there, but it looks like TileDB considers them to be an error that results in a short-circuit return. I'd be concerned that masking them would hide some underlying error. Are there any tests that verify that data round-trips though GDB when an interval list large enough to trigger these messages is encountered ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407394879:25,message,messages,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407394879,2,['message'],['messages']
Integrability,"@kgururaj I ran the commands you suggested. . > [user@cedar5 bin]$ bash -x TestGenomicsDBJar/run_checks.sh; > + [[ hB != hxB ]]; > + XTRACE_STATE=-x; > + [[ hxB != hxB ]]; > + VERBOSE_STATE=+v; > + set +xv; > + unset XTRACE_STATE VERBOSE_STATE; > ++ uname -s; > + osname=Linux; > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.so; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.dylib; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + '[' Linux == Darwin ']'; > + LIBRARY_SUFFIX=so; > + ldd libtiledbgenomicsdb.so; > ldd: ./libtiledbgenomicsdb.so: No such file or directory; > + md5sum libtiledbgenomicsdb.so; > md5sum: libtiledbgenomicsdb.so: No such file or directory. I'm using a compute canada server, so I don't have root access. The version of gatk4 I'm using was installed by their support team, and I load it using 'module load gatk'. I had that module loaded when I ran this test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071:310,depend,dependencies,310,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071,4,['depend'],['dependencies']
Integrability,"@kgururaj I think we just need to check the catch blocks in `GenomicsDBImport.getFeatureReadersInParallel()`, and get them to propagate the underlying exceptions properly (instead of just the top-level exception), so that we don't lose useful error messages like this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4592#issuecomment-376597795:249,message,messages,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4592#issuecomment-376597795,1,['message'],['messages']
Integrability,@kgururaj Is it possible to include information about the lock disabling in the lock error messages?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4753#issuecomment-439982616:91,message,messages,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4753#issuecomment-439982616,1,['message'],['messages']
Integrability,"@kgururaj Thanks for adding the test. Running it locally on my laptop (without your fix) succeeds though - I have to bump it up from 1000 intervals to 9000 to reproduce the stack overflow. But if I do that, it takes a long time to run, since it appears to be creating lots of small partitions. Is there any way to get it to use fewer partitions in a case like this where there are lots of intervals ?. Somewhat more concerning is that when with 8000 intervals, I see a different failure mode. First I see lots (thousands) of these messages:. `[GenomicsDB::VariantStorageManager] INFO: ignore message ""[TileDB::StorageManager] Error: Cannot list TileDB directory; Directory buffer overflow."" in the previous line`. followed by a failure that ends like this:. `[TileDB::StorageManager] Error: Cannot store schema; Too many open files in system.; libc++abi.dylib: terminating with uncaught exception of type LoadOperatorException: LoadOperatorException : Could not define TileDB array; TileDB error message : [TileDB::StorageManager] Error: Cannot store schema; Too many open files in system`. Can you reproduce that ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407214031:531,message,messages,531,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-407214031,3,['message'],"['message', 'messages']"
Integrability,@kgururaj We should definitely add a defensive check to emit an error message when there's a mismatch.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5113#issuecomment-413289512:70,message,message,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5113#issuecomment-413289512,1,['message'],['message']
Integrability,@knight2015 There's no specific schedule. The hope is to switch to spark 3.0.0 soon after it's officially released but it depends on some other factors like google cloud dataproc supporting 3.0 images. We're still essentially using the spark 1.x RDD API so as far as I can tell there isn't a ton of stuff coming that is going to be a big benefit to gatk in spark 3 (other than the official java 11+ support which is a very good thing.),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6644#issuecomment-641325396:122,depend,depends,122,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6644#issuecomment-641325396,1,['depend'],['depends']
Integrability,"@laserson the `SAMRecord` vs. Google `Read` is a loooooong story.; The super-short version:; We had a bunch of utilities written for `SAMRecord` that @droazen refactored over months to take the GATKRead interface. As it happens, the SAM spec and the GA4GH spec are not 100% compatible. So, it's not possible to losslessly convert from A -> B -> A (where A is `SAMRecord` or Google `Read`). The cases where it doesn't work are edge cases, but they exist. Second, @jean-philippe-martin found that converting to Google `Read` was fairly expensive. Between those two points, I think we're probably better off with SAM-backed reads. (Also, right now the Google `Read` is serialized via JSON, so it's not that small anyway.). @tomwhite and @jean-philippe-martin, I think adding the header back will be fine for us engineers working on the engine, but it will make for a poorer user experience for newcomers and Comp Bios to burden them with having to care about what happens with shuffles (when they just want to prototype something). . That said, I think this is probably the best approach we have at our disposal. If we do, we need to do an excellent job of throwing errors if users try to perform actions that would require the header. The error message should explain what really happened and ideally point to some documentation we write explaining the stripping of the header and how to fix it. If this error occurs, it needs to be simple for anyone to fix it. @droazen @lbergelson, what do you two think? (also @laserson, do you have any ideas or thoughts on the header since we're probably stuck with `SAMRecord`?)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141086025:203,interface,interface,203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-141086025,2,"['interface', 'message']","['interface', 'message']"
Integrability,"@lbergelson , 1 is not impossible, but it could turn out to be a bigger-than-expected project, because the bwa code, as I understand it, is accumulated through the years. For this specify error message we saw, the abort call is actually made by some low level code in bwa that once modified could throw away many other parts as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2123#issuecomment-243288136:194,message,message,194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2123#issuecomment-243288136,1,['message'],['message']
Integrability,"@lbergelson - regarding the single implementation of `GATKRead`, I would like to maintain the interface because I have some custom implementations. Although if it is true that HTSJDK will move to a version 3 based on interfaces, I can change my code to use the HTSJDK interfaces instead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358264778:94,interface,interface,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358264778,3,['interface'],"['interface', 'interfaces']"
Integrability,"@lbergelson @KevinCLydon This branch now passes all tests, is rebased onto the latest master, and is (finally) using the official GATK Python environment rather than the custom NVIDIA-provided one. I had to add two additional Python dependencies to our environment, and make some small modifications to the Python code to account for a newer version of pytorch-lightning that was required. The final outstanding issue in this PR is that I had to temporarily comment out the Jacoco coverage report code in our build.gradle and dockertest.gradle files, due to a bizarre problem where Jacoco was attempting to read/parse the new Pytorch model files added in this branch. This will have to be resolved before we can merge (or we might have to permanently disable Jacoco if it can't be...). After this is merged, there will have to be a second PR that adds the CNN tools to the `DeprecatedToolsRegistry`, and actually removes the legacy tools. When we do this, we need to be careful not to remove the expected CNN output files used by the new NVScoreVariants integration tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-2402661408:233,depend,dependencies,233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-2402661408,2,"['depend', 'integrat']","['dependencies', 'integration']"
Integrability,"@lbergelson @droazen @kgururaj ; 1. I was playing around with the test codes in GATK and did not push GenomicsDB tests in this PR. Will push it in the next commit.; 2. This is at the top of our discussion list for next week. GenomicsDB interfaces use these JSON files today which contain input configuration, list of samples, mapping between sample IDs and TileDB row indexes and stream ids for the input VCFs. If this tool takes the list of VCFs and intervals as input, we'd have to recreate JSON files internally and pass it to GenomicsDB. I wanted to avoid this for now as we are thinking about overhauling the input methodology completely in GenomicsDB with protocol buffers, but this is going to take a while. Also, we need to decide what's the best way to maintain the callset mappings.; 3. Will let you know asap. -Kushal.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-277320579:236,interface,interfaces,236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-277320579,2,"['interface', 'protocol']","['interfaces', 'protocol']"
Integrability,@lbergelson Do we actually have any tests that depend on R besides the RScriptExecutor tests (which don't do much). Also wondering if there would be inconsistencies with Picard R requirements.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359096527:47,depend,depend,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359096527,1,['depend'],['depend']
Integrability,"@lbergelson Do you have an opinion on the best way to pip install the gcnvkernel python package and dependencies for Travis testing? I've verified that the pip install works within a basic conda environment with python=3.6. We'll need to load this environment both for unit/integration tests as well as WDL tests. As long as this is the only python environment we need, I think we can simply use the base environment in the Docker. If more environments are required (e.g., for @lucidtronix), then maybe we'll need to be more clever for unit/integration tests, but we can still load them manually in the scripts that kick off the WDL tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-348073948:100,depend,dependencies,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-348073948,6,"['depend', 'integrat']","['dependencies', 'integration']"
Integrability,"@lbergelson I added an integration test that writes to GCS... it doesn't work for me (""com.google.cloud.storage.StorageException (...) does not have storage.objects.get access to (...)""). This may be due to a misconfiguration on my end. I wonder if it'll work with Travis.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-334877523:23,integrat,integration,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-334877523,1,['integrat'],['integration']
Integrability,"@lbergelson I added the ClassLoader fallback code in to `GATKPathSpecifier`. In doing so, I expected some of the `PathSpecifier` negative unit tests to produce different exceptions, but they didn't. This was because the tests were all using the `PathSpecifier` base class (because I took them from htsjdk-next which has only the base implementation). So I updated the tests to use `GATKPathSpecifier` (they all passed), then integrated the fallback code and changed 3 negative tests that went from FileSystemNotFoundException to ProviderNotFoundException. Finally I renamed the test class file to correctly reflect the class being tested. Sorry this was such a pain.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5526#issuecomment-457751714:425,integrat,integrated,425,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5526#issuecomment-457751714,1,['integrat'],['integrated']
Integrability,"@lbergelson I moved the ""disable"" toggle to the `ProgressMeter` constructors, and made it `final` so that it won't change over the lifetime of the object. I agree that extracting an interface, etc., would be nicer, but I think such a larger refactor can wait for a future PR. For now, this fixes the currently-broken `disableProgressMeter()` method in a way that involves the least-invasive changes to the tools / traversals.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7354#issuecomment-881711125:182,interface,interface,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7354#issuecomment-881711125,1,['interface'],['interface']
Integrability,"@lbergelson I think most use cases for this would be for post-arg-parsing problems, so it would make sense to add an Advanced, common command line argument for it. Much easier to use, and as you say we could include instructions in the exception message itself for how to enable it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2443#issuecomment-285197345:246,message,message,246,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2443#issuecomment-285197345,1,['message'],['message']
Integrability,"@lbergelson I think the idea of the BlockCompressedIntervalStream is a sound one, and will be quite useful. The code around it -- trying to integrate it with the Feature system -- is a stinky mess, and I'm trying to clean it up.; I'm close to having a major update. Let's think about it more at that point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-840054226:140,integrat,integrate,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7142#issuecomment-840054226,1,['integrat'],['integrate']
Integrability,"@lbergelson I used Maven because it's what they taught me at the university to download Spark dependencies, so I'm a novice too; I'm sorry to bothering you with new errors (I promise that tomorrow I see how to do it with Gradle and stop bothering you), but adding even the repository to the pom.xml generated this error: ; ```; [ERROR] Failed to execute goal on project GATKpipe: ; Could not resolve dependencies for project uk.ac.ncl:GATKpipe:jar:0.0.1-SNAPSHOT: ; Failed to collect dependencies at org.broadinstitute:gatk:jar:4.beta.6-18-g2ee7724-20171025.162137-1 ; -> com.google.cloud.genomics:google-genomics-dataflow:jar:v1beta2-0.15 ; -> com.google.cloud.genomics:google-genomics-utils:jar:v1beta2-0.30 ; -> io.grpc:grpc-all:jar:0.7.1 -> io.grpc:grpc-auth:jar:0.7.1 ; -> com.google.auth:google-auth-library-oauth2-http:jar:0.1.0: ; Failed to read artifact descriptor for com.google.auth:google-auth-library-oauth2-http:jar:0.1.0: ; Could not find artifact com.google.auth:google-auth-library:pom:0.1.0 in snapshots (https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot) -> [Help 1]; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339755211:94,depend,dependencies,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339755211,3,['depend'],['dependencies']
Integrability,"@lbergelson I was a little surprised too, but the unit test that's failing is a dumb test. The header description had been copied into the test itself, so I extracted it as a static constant. The integration test for GVCFs checks headers, which, after some internal debate, I think is fair. And there's David's handy exact match update, so fixing it is super easy.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6431#issuecomment-581435478:196,integrat,integration,196,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6431#issuecomment-581435478,1,['integrat'],['integration']
Integrability,"@lbergelson I was able to get the auth set up right for the integration test (locally). It fails in a few places because some combinations are not supported.; *edit* I spoke too soon, that was a bug in the test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-336530831:60,integrat,integration,60,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-336530831,1,['integrat'],['integration']
Integrability,"@lbergelson I was referring more to the middle part of the StackOverflow by Daniel Chapman - specifically the [4.1 The ObjectStreamClass Class](http://docs.oracle.com/javase/8/docs/platform/serialization/spec/class.html#a5082) and [4.6 Stream Unique Identifiers](http://docs.oracle.com/javase/8/docs/platform/serialization/spec/class.html#a4100):. _If not specified by the class, the value returned is a hash computed from the class's name, interfaces, methods, and fields using the Secure Hash Algorithm (SHA) as defined by the National Institute of Standards._. Now when I look at the `java.io.ObjectStreamClass.java` file for 64-bit JDK7 and JDK8 - from src.zip - both have the same code for the following parts after performing a `diff` - I didn't list all of the lines of code since they are quite long:. ```; public long getSerialVersionUID() {; // REMIND: synchronize instead of relying on volatile?; if (suid == null) {; suid = AccessController.doPrivileged(; new PrivilegedAction<Long>() {; public Long run() {; return computeDefaultSUID(cl);; }; }; );; }; return suid.longValue();; }; ... private static long computeDefaultSUID(Class<?> cl) {; ...very long code which can be inspected via the src.zip file...; }; ```. So looking at the code portions of `computeDefaultSUID()` and I notice in our instance `ReadFilter` is a interface, which gets defined later via [ReadFilterLibrary.java](https://github.com/broadinstitute/hellbender/blob/62ef76ba60951c562a0d4c39189aa3f01f27f8d3/src/main/java/org/broadinstitute/hellbender/engine/filters/ReadFilterLibrary.java) or via `new ReadsFilter(readFilter, header)`, in either of these instances the fields would be different, based on this portion of `computeDefaultSUID` when looking at declared fields:. ```; Field[] fields = cl.getDeclaredFields();; MemberSignature[] fieldSigs = new MemberSignature[fields.length];; for (int i = 0; i < fields.length; i++) {; fieldSigs[i] = new MemberSignature(fields[i]);; }; ```. Therefore the `SUID` would be ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107730499:441,interface,interfaces,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/535#issuecomment-107730499,2,"['interface', 'synchroniz']","['interfaces', 'synchronize']"
Integrability,@lbergelson I'm looking into this some more; I wonder if the ADAM bump is bringing in some dependency conflict. I'll report back.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356133180:91,depend,dependency,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356133180,1,['depend'],['dependency']
Integrability,"@lbergelson If you query for output after you've terminated the process, the query will fail immediately because the Futures will have been completed with a CancellationException when the pipes were broken by the termination. But I think even that might be subject to a race condition. Previously we were dependent on stdout/stderr for synchronization and error detection, but with the ack fifo and the python exception handler installed, we really aren't anymore. We do need to fix https://github.com/broadinstitute/gatk/issues/5100, and have a better logging integration strategy, but in general I think we should seek to eliminate all use of stdout/stderr except for advisory purposes. On a separate tangent, what I'd really like to do is unify the two PythonExecutors into a single one. All of these features I'm adding like profiling, version checking, logging integration etc., will have to be done in both of them otherwise.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5097#issuecomment-413575698:305,depend,dependent,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5097#issuecomment-413575698,4,"['depend', 'integrat', 'synchroniz']","['dependent', 'integration', 'synchronization']"
Integrability,"@lbergelson In your opinion, how likely is this feature to cause problems? We do still call `QueryInterval.optimizeIntervals()` to merge intervals in `ReadsDataSource` before starting an iteration, and I think that's the main example of an HTSJDK query interface that can't handle overlapping intervals.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567634113:253,interface,interface,253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567634113,1,['interface'],['interface']
Integrability,"@lbergelson It looks like it did indeed still work to only download the gradle dependencies once, i'm going to squash and merge this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5155#issuecomment-418753777:79,depend,dependencies,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5155#issuecomment-418753777,1,['depend'],['dependencies']
Integrability,@lbergelson Looks like we have a failure in `BigQueryUtilsUnitTest`:. ```; testQueryWithStorageAPI; java.lang.IllegalStateException: getTransportChannel() called when needsExecutor() is true; 	at com.google.api.gax.grpc.InstantiatingGrpcChannelProvider.getTransportChannel(InstantiatingGrpcChannelProvider.java:194); 	at com.google.api.gax.rpc.ClientContext.create(ClientContext.java:241); 	at com.google.cloud.bigquery.storage.v1beta1.stub.EnhancedBigQueryStorageStub.create(EnhancedBigQueryStorageStub.java:108); 	at com.google.cloud.bigquery.storage.v1beta1.BigQueryStorageClient.<init>(BigQueryStorageClient.java:144); 	at com.google.cloud.bigquery.storage.v1beta1.BigQueryStorageClient.create(BigQueryStorageClient.java:125); 	at com.google.cloud.bigquery.storage.v1beta1.BigQueryStorageClient.create(BigQueryStorageClient.java:116); 	at org.broadinstitute.hellbender.utils.bigquery.StorageAPIAvroReader.<init>(StorageAPIAvroReader.java:51); 	at org.broadinstitute.hellbender.utils.bigquery.StorageAPIAvroReader.<init>(StorageAPIAvroReader.java:45); 	at org.broadinstitute.hellbender.utils.bigquery.BigQueryUtils.executeQueryWithStorageAPI(BigQueryUtils.java:394); 	at org.broadinstitute.hellbender.utils.bigquery.BigQueryUtils.executeQueryWithStorageAPI(BigQueryUtils.java:370); 	at org.broadinstitute.hellbender.utils.bigquery.BigQueryUtilsUnitTest.testQueryWithStorageAPI(BigQueryUtilsUnitTest.java:74); ```. I suspect we need to bump our BigQuery dependency in this PR as well -- I'll attempt it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1051025679:1456,depend,dependency,1456,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1051025679,1,['depend'],['dependency']
Integrability,"@lbergelson Now that https://github.com/broadinstitute/gatk/pull/6759 is merged, can you rebase this branch onto master to reconcile it with the extensive dependency changes in that PR?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6736#issuecomment-702906315:155,depend,dependency,155,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6736#issuecomment-702906315,1,['depend'],['dependency']
Integrability,"@lbergelson Our stuff runs fine using Dataproc image 1.3 and the current GATK dependencies, so I guess it's not crucial, but it's probably something we should investigate doing?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5125#issuecomment-417720868:78,depend,dependencies,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5125#issuecomment-417720868,1,['depend'],['dependencies']
Integrability,"@lbergelson Right, that what I was thinking. It's a very commonly occurring issue for gCNV, so it would be a very useful message for users.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6362#issuecomment-572682056:121,message,message,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6362#issuecomment-572682056,1,['message'],['message']
Integrability,"@lbergelson So, the test failures are in `ScoreVariantAnnotationsIntegrationTest` and `TrainVariantAnnotationsModelIntegrationTest`, when run within the conda environment in the new docker image. I've confirmed that they happen with both Ubuntu 22.04 and 20.04. They are assertion failures from `h5diff` indicating that the actual outputs did not match the expected outputs, so there are likely actual numerical differences here. Most likely the newer Ubuntu releases are shipping with newer versions of native libraries that HDF5 (or some other GATK dependency) depends on, and there was some breaking change somewhere along the line. . I think our only option is to capture the outputs of these tests, and ask @samuelklee to confirm that the differences do not indicate an actual regression.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8610#issuecomment-1848740833:551,depend,dependency,551,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8610#issuecomment-1848740833,2,['depend'],"['dependency', 'depends']"
Integrability,"@lbergelson Sorry to be unclear---this isn't a GATK issue. For Cromwell, you can configure various options for each backend. For example, if you are running on a local backend with Docker, you can set a `submit-docker` attribute to specify the string that runs the Docker container; so to solve the above problem, you'd set this to include `--shm-size` and set it accordingly. However, according to @jsotobroad, you're not allowed such an attribute when submitting to Google cloud. If that's the case, then this is more of an issue with the Cromwell/Google Pipelines interface than the data.table package (although, as the discussion in the GitHub issue above shows, it'd be a simple fix on the data.table end, so I'm not sure why it's not addressed yet...) Changing the R script to get around the issue in this particular case is not unacceptably ugly, but you could imagine we might run into a similar problem in the future if anything else exceeds the 64MB /dev/shm limit and also cannot specify tmpfs. So perhaps we should take a look at the underlying issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357375691:567,interface,interface,567,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357375691,2,['interface'],['interface']
Integrability,"@lbergelson Thank you for reviewing. `FeatureDataSource.getGenomicsDBFeatureReader()` passes the default vcf header name to `GenomicsDBFeatureReader()` - and I've updated the GenomicsDB integration tests for clarity. If I've misunderstood your previous comment and other changes to `FeatureDataSource.getGenomicsDBFeatureReader()` are required, I can make these updates.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3994#issuecomment-354856711:186,integrat,integration,186,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3994#issuecomment-354856711,1,['integrat'],['integration']
Integrability,@lbergelson Thank you for your response. I tried this version of Spark and it did not change the error message. Please tell me what information you may need to reproduce the error.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3050#issuecomment-306963267:103,message,message,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050#issuecomment-306963267,1,['message'],['message']
Integrability,"@lbergelson The stats file is not optional, but the *argument* is optional because by default `FilterMutectCalls` looks for the stats file produced automatically by `Mutect2` in the same directory as the output vcf. @andrewrech The official best practices pipeline -- that is, mutect2.wdl in this repo and hosted on Terra (formerly Firecloud) -- handles this automatically. We generally discourage users from writing their own pipelines because it takes very long and can easily yield inferior results. Is the official pipeline missing a feature that you need?. As for backwards compatibility, while we can guarantee that `Mutect2` and `FilterMutectCalls` from the same GATK release will always work together we do not make any promises about the interoperability of different releases.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6124#issuecomment-527621821:747,interoperab,interoperability,747,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6124#issuecomment-527621821,1,['interoperab'],['interoperability']
Integrability,@lbergelson The trouble with the large tests is that they can be automatically generated and have lots of output so it's hard to check the details. Do you have an example of where this was causing an error before? If so we can build a unit or integration test out of that variant to ensure this doesn't regress. If you can provide that kind of a locus I could go in and add in a test for it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6178#issuecomment-534637031:243,integrat,integration,243,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6178#issuecomment-534637031,1,['integrat'],['integration']
Integrability,"@lbergelson There aren't too many incompatible changes between Spark 1.x and Spark 2.x, but there are some, and that required us to further parameterize our build and release. Feel free to borrow from our scripts if you go down that route. I'll keep an eye out for your new patch to review.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2264#issuecomment-261284201:233,rout,route,233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2264#issuecomment-261284201,1,['rout'],['route']
Integrability,"@lbergelson These changes are dependent on a Barclay [PR](https://github.com/broadinstitute/barclay/pull/17) that is not merged yet, so we should at least wait for that snapshot. Ideally, the other two (tiny) Barclay PRs in the queue should also be reviewed/merged, then we could do a release and upgrade to that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-271991891:30,depend,dependent,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2327#issuecomment-271991891,1,['depend'],['dependent']
Integrability,@lbergelson We were just talking about this. Thanks to @skwalker's HaplotypeCaller tie out I think it's close. Question for the engine team: this is going to break several integration tests. What would you suggest doing?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-377359265:172,integrat,integration,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4614#issuecomment-377359265,1,['integrat'],['integration']
Integrability,"@lbergelson Yes - this test is a leftover artifact of the original implementation, but we're no longer dependent on the features tested it so its fine to remove.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5537#issuecomment-451021915:103,depend,dependent,103,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5537#issuecomment-451021915,1,['depend'],['dependent']
Integrability,"@lbergelson You are correct. Let us do a bit more research to see if we can get GKL to log properly to both GATK 3 and 4. If not, we might have to go the route of having a GKL specific to GATK 3. Can we leave this PR open for now?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320745313:154,rout,route,154,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320745313,1,['rout'],['route']
Integrability,"@lbergelson counter-proposal: since writing to a temp location in GCS would risk collisions if multiple people run the test, how about writing to JimFS instead? It's a RAM filesystem so each test machine gets its own, and it still requires the code to use the Path objects correctly since any conversion to File would fail. As a bonus, we do not incur Cloud charges and the test is much faster, so we can keep it as a unit test instead of an integration test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332078512:442,integrat,integration,442,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332078512,1,['integrat'],['integration']
Integrability,"@lbergelson please review. I chose to add a master ""disable"" toggle to the `ProgressMeter` class itself rather than requiring all traversals / tools to wrap ProgressMeter calls in if statements.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7354#issuecomment-881695208:152,wrap,wrap,152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7354#issuecomment-881695208,1,['wrap'],['wrap']
Integrability,@lbergelson thank you for the comment and sorry for my bit late response. I excluded the dependency to the jsr203-s3a and tested that both local- and spark-gatk can access s3a files by dynamically loading it. I also added a new directory `scripts/s3a` for documentation and simple tests for s3a demonstration.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6698#issuecomment-665484597:89,depend,dependency,89,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6698#issuecomment-665484597,2,['depend'],['dependency']
Integrability,"@lbergelson you beat me because I was stuck trying to actually run a Picard tool in the integration test. (For future reference, that needs a workaround because the test running adds the ERROR level logging to all command lines and Barclay can't parse that for Picard tools for some reason.). The big reason I was using this instead of IntervalListTools is because the Picard version creates a terrible output file structure that I was having trouble capturing with a simple glob in WDL. I agree that the functionality here is largely redundant, but it was helping me get my workflow working faster at the moment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5392#issuecomment-435894196:88,integrat,integration,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5392#issuecomment-435894196,2,['integrat'],['integration']
Integrability,"@lbergelson, @droazen are you OK with adding a SNAPSHOT dependency for Hadoop-BAM so we can commit this (and also the GVCF PR)?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3369#issuecomment-325704254:56,depend,dependency,56,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3369#issuecomment-325704254,1,['depend'],['dependency']
Integrability,"@lbergelson, I don't think that this solution will help in this case, because another error when trying to use `CommandLineProgramTest`is that it extends `BaseTest`, which loads directly a `GenomeLocParser` for a reference that is not present and it blows up in every test. Regarding the `Main` class, because you point it out here, I would like to have some control over `Main` and how it manages things like errors or logging header. Basically all the things that I'm facing at the moment are, apart of this error using the testing framework, is that the framework have tons of mentions to the GATK itself (error messages pointing to the GATK manual page or bundle tools), and little control over which of them should be expose to the final user. Only as an example, I would like to output a line with the name and version of my software and a short notice about the usage of the GATK framework and which version I'm using (for easier maintenance, and contribution if a bug is found).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-242802278:615,message,messages,615,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-242802278,1,['message'],['messages']
Integrability,"@lbergson's instructions above are good, but somehow they did not work for me. I was able to follow the [application default credentials](https://developers.google.com/identity/protocols/application-default-credentials) instructions, though. Here are the steps I took:. 1. create a new service account on the Google Cloud web page and download the JSON key file.; 2. gcloud auth activate-service-account --key-file ""$PATH_TO_THE_KEY_FILE""; 3. export GOOGLE_APPLICATION_CREDENTIALS=""$PATH_TO_THE_KEY_FILE"". I cleared my credentials first to make sure that the access worked because of the above steps, not because of other credentials. After those steps, gatk was able to run from my desktop and access files using the service account credentials. `gsutil ls` worked as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2425#issuecomment-282900470:177,protocol,protocols,177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2425#issuecomment-282900470,2,['protocol'],['protocols']
Integrability,"@ldgauthier & @droazen I've done as you've suggested. There is now a check in `GenomicsDBImport`, by wrapping the FeatureReader. It's a little ugly but it gets the job done. I've also added a simple test for GenotypeGVCFs to genotype a GVCF that has an MNP in it. I _think_ this is probably now ready for review. Let me know if you think further tests are needed!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5182#issuecomment-422989371:101,wrap,wrapping,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5182#issuecomment-422989371,2,['wrap'],['wrapping']
Integrability,@ldgauthier @davidbenjamin please take a look. . Don't allow the number of lines changed intimidate you... (most are in test resource files). The first commit contains the actual main code changes. . The second and third commits update the test resources (where most of the changed lines come from) and test code. . The very last commit changes the default radius to 2... I was planning to set it to 0 since it is more parsimonious (less complex configuration) but it may well affect sensitivity and certainly changes the PL/QUAL values so I guess set the value two the current 2 (for PLs) is a safer and more conservative approach until we evaluate what is the optimal value for this parameter. . Perhaps @davidbenjamin would like to have a different default for Mutec. This is last minute change and may break some of the integration test so bear with me if that is the case. However I think you can start reviewing the code at this point.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-516992042:824,integrat,integration,824,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6055#issuecomment-516992042,1,['integrat'],['integration']
Integrability,"@ldgauthier @lucidtronix I'm updating this with a proposed list of CNNScoreVariants issues I think need to be resolved before we can remove the `@Beta` tag (actually is currently marked `@Experimental`). Let me know what you think:. - https://github.com/broadinstitute/gatk/issues/4538 (Python factoring/PEP-8/code review); - factor python args handling (minimally factor out the inference args); - there is only one 2D test, which I think has no reads overlapping any of the variants; - we should add a test that specifies one or more intervals; - the tool currently adds standard VQSR header lines via addVQSRStandardHeaderLines, which is unnecssary; - integrate read downsampling; - determine/handle the failure mode when the user supplies a mix (of mismatched) 1D/2D arch and weights inputs. Other (not necessarily blockers):; - establish all defaults (weights/arch/etc) in Java code; - default arch is 1D - should this change to 2D ?; - see if we can remove the artificially small inference/batch sizes (1) used in the tests. I think we added these due to timeouts which should no longer be an issue.; - remove the `newExpectations` code paths in integration tests",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231:655,integrat,integrate,655,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231,2,['integrat'],"['integrate', 'integration']"
Integrability,"@ldgauthier @yfarjoun We have an update on this! We've identified the bug:. * When `AbstractFeatureReader.getFeatureReader()` tries to open a `.vcf.gz` that doesn't have an index, it returns a `TribbleIndexedFeatureReader` instead of a `TabixFeatureReader`, because `methods.isTabix()` returns false when an index is not present.; * `TribbleIndexedFeatureReader`, in turn, opens a Java vanilla `GZIPInputStream`, instead of the `BlockCompressedInputStream` that gets opened when you create a `TabixFeatureReader`.; * `GZIPInputStream`, in turn, has a *confirmed bug* filed against it in Oracle's bug tracker (see https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that it inappropriately relies on the `available()` method to detect end-of-file, which is never safe to do given the contract of `available()`; * As the final piece in the ghastly puzzle, implementations of `SeekableStream` in htsjdk do not implement `available()` at all, instead using the default implementation which always returns 0. As a result of this combination of bugs in Java's `GZIPInputStream` itself and bugs in htsjdk's `SeekableStream` classes, end-of-file can be detected prematurely when within 26 bytes of the end of a block, due to the following code in `GZIPInputStream.readTrailer()`:. ```; if (this.in.available() > 0 || n > 26) {; ....; }; return true; // EOF; ```. Where `n` is the number of bytes left to inflate in the current block. The solution is to replace all usages of the bugged `GZIPInputStream` with `BlockCompressedInputStream` in tribble in htsjdk (at least, for points in the code where the input is known to be block-gzipped rather than regular gzipped). For due diligence we should also implement `available()` correctly for all implementations of `SeekableStream` in htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461:795,contract,contract,795,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461,1,['contract'],['contract']
Integrability,"@ldgauthier At the test locus used in `HaplotypeCallerIntegrationTest.testHaploidNoCall()`, <NON_REF> allele/haploid genotype is no longer the most likely genotype after the changes in this PR. So I removed the integration test and added a unit test that checks that when the <NON_REF> allele is present in the genotype, the no_call genotype (e.g. ""."" or ""./."") has the correct ploidy, which was the problem #6563 fixed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6696#issuecomment-679416696:211,integrat,integration,211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6696#issuecomment-679416696,1,['integrat'],['integration']
Integrability,@ldgauthier Can you take a look at this? This fixed a pretty rare (but not rare enough that it wasn't causing mismatches in my other work) error in GATK where we would be mis-sizing assembly windows where indels that overlapped snps were involved. It made some moderate differences in PL scores in HC tests which suggests its actually happening somewhat more frequently than couple of dropped indels I observed would suggest. I see however that it affected one of the CombineGVCFs integration tests (specifically all the values seem to be off by very small margins). Is that a problem at all?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-671564473:481,integrat,integration,481,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-671564473,1,['integrat'],['integration']
Integrability,"@ldgauthier Certainly, if that's what's really in the VCFs. As mentioned in my earlier comment, the changes in 4.1.5.0 may just be revealing pre-existing problems in the data. It's unfortunate that the error message doesn't include the locus... @GATKSupportTeam @bhanugandham I think the next step here is to tell the user that the error message is an additional check added in recent versions of GATK, and suggests that a reference allele in one of their `--resource` VCFs mismatches a reference allele in the `-V` VCF. . Given that several of their VCFs are missing sequence dictionaries according to the warning messages at the beginning, it's likely that at least one VCF is using a different reference from the `-V` VCF.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6701#issuecomment-663065592:208,message,message,208,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701#issuecomment-663065592,3,['message'],"['message', 'messages']"
Integrability,@ldgauthier I added an integration test for GVCF mode and it works fine: the alleles are as expected with the addition of `<NON REF>`. I'm now going to investigate how the MNPs interact with CombineGVCFs and GenotypeGVCFs.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4650#issuecomment-384473840:23,integrat,integration,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4650#issuecomment-384473840,1,['integrat'],['integration']
Integrability,@ldgauthier I wrote a detailed error message. Anything else?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6263#issuecomment-560982515:37,message,message,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6263#issuecomment-560982515,1,['message'],['message']
Integrability,"@ldgauthier I'm about to submit a bug fix PR. In the line you found the `.intersect(region)` should be `.intersect(region.getPaddedSpan())`. The intersection is to avoid a bug where the requested trimmed padded region is bigger than the original padded region, but `intersect(region)` causes it to lie within the original unpadded region, which is unnecessary and probably harmful to sensitivity (the trimming cigar didn't hurt sensitivity, but I wonder if this mistake may have offset a net benefit that it should have created). I replicated @jemunro's error in the branch, fixed it (of course), and wrote an equivalent regression test that fails before and passes after the PR. The rest is just the usual annoying updating of integration test files, which as of right now I'm in the middle of.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6495#issuecomment-599885755:728,integrat,integration,728,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6495#issuecomment-599885755,1,['integrat'],['integration']
Integrability,"@ldgauthier I've fixed the NPE by deleting an incorrect implementation of `getRawKeyNames()`. Actually, I deleted them all, and just put a correct implementation as a default method in the `ReducibleAnnotation` interface, as we discussed. I also removed a bunch of unnecessary qualifiers from the interface. If tests pass this time around, we should finally be able to release :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6079#issuecomment-539412047:211,interface,interface,211,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6079#issuecomment-539412047,2,['interface'],['interface']
Integrability,"@ldgauthier If you feel that you need some validation, but less strict/expensive than the default, then I'd suggest turning off the default validation, writing your own scaled-down dictionary validation routine, and calling it from `onTraversalStart()` in your tool. Then if it seems like the scaled-down validation might be generally useful, we could hook it up to the `SequenceDictionaryValidationArgumentCollection` as a third engine-level option.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6589#issuecomment-625438251:203,rout,routine,203,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6589#issuecomment-625438251,1,['rout'],['routine']
Integrability,"@ldgauthier In GATK4 we require that all PRs be squashed into a single commit at the end of review (ie., ""Squash and merge"" is the only option enabled for this repo). But I'll add that github will do the final squash for you -- all you have to do is click ""Squash and merge"", then edit the commit message in the text box that pops up to cleanly describe the final feature (you can enlarge the text box while editing).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3255#issuecomment-316868380:297,message,message,297,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3255#issuecomment-316868380,1,['message'],['message']
Integrability,"@ldgauthier It looks like when you added GVCF mode to Mutect2, you may have marked this arg as beta even though it's shared with the HaplotypeCaller. Perhaps it would be easiest for M2 and HC to just have separate `-ERC` arg declarations? Or you could remove the beta label from the argument itself, and have M2 emit a logger message saying that GVCF mode is beta when running with `-ERC GVCF`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5988#issuecomment-499609768:326,message,message,326,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5988#issuecomment-499609768,1,['message'],['message']
Integrability,@ldgauthier Should we patch `GenotypeGVCFs` to detect reblocked input and throw a `UserException` with an explanatory message?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7437#issuecomment-906617099:118,message,message,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7437#issuecomment-906617099,1,['message'],['message']
Integrability,"@ldgauthier The new test files you added were indeed correctly checked in as git-lfs files! You can tell this because in the diff for the PR these files are marked with the message ""Git LFS file not shown"". (I'll add that any new files added under `src/test/resources/large` get automatically tracked by lfs provided that you've completed the lfs setup instructions in https://github.com/broadinstitute/gatk#lfs -- we generally put files that are more than about 1 MB in there)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3255#issuecomment-316188293:173,message,message,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3255#issuecomment-316188293,1,['message'],['message']
Integrability,"@ldgauthier This looks good, its a pretty simple change and there are unit tests and integration tests that enforce the new behavior. I would squash the two commits and give them an informative commit message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320707124:85,integrat,integration,85,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320707124,4,"['integrat', 'message']","['integration', 'message']"
Integrability,"@ldgauthier Unfortunately there are still two integration test failures left after fixing that NPE:. ```; Gradle suite > Gradle test > org.broadinstitute.hellbender.tools.walkers.GnarlyGenotyperIntegrationTest > testUsingGenomicsDB[2]([Ljava.io.File;@2b20e8a, src/test/resources/org/broadinstitute/hellbender/tools/walkers/GnarlyGenotyper/twoSampleAS.vcf, src/test/resources/org/broadinstitute/hellbender/tools/walkers/GnarlyGenotyper/twoSampleASDB.vcf, [20:1-2147483647], [], /gatkCloneMountPoint/src/test/resources/large/human_g1k_v37.20.21.fasta) [31mFAILED[39m[0K. java.lang.IllegalStateException: Something went wrong: [0K. at org.broadinstitute.hellbender.tools.walkers.gnarlyGenotyper.GnarlyGenotyperEngine.finalizeGenotype(GnarlyGenotyperEngine.java:131). at org.broadinstitute.hellbender.tools.walkers.gnarlyGenotyper.GnarlyGenotyper.apply(GnarlyGenotyper.java:287). at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104). at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193). at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193). at java.util.Iterator.forEachRemaining(Iterator.java:116). at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801). at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482). at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472). at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151). at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174). at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234). at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418). at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102). at or",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6079#issuecomment-539518973:46,integrat,integration,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6079#issuecomment-539518973,1,['integrat'],['integration']
Integrability,"@lessdata In many cases we need to rely on the file extensions to check the file format, because actually opening the files and reading the first few bytes to determine the format gets expensive when the files are hosted in the cloud and there are many VCFs. I do agree that this error message could be improved, however -- it should mention the file extensions that are allowed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7691#issuecomment-1049130908:286,message,message,286,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7691#issuecomment-1049130908,1,['message'],['message']
Integrability,"@louisb I did wind up making the docgen and wdlgen and tab completion integration tests non-docker only, since they're failing when run on the docker. The tasks themselves seem to be working fine - these tests are really just here to do a quick smoke test, and to make it easy to debug issues in case of a failure. I suspect the failures are related to the way we run the tests on the docker using the 3 separate jars. So for now I made them non-docker only.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1448991698:70,integrat,integration,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1448991698,1,['integrat'],['integration']
Integrability,"@lucidtronix @mbabadi @samuelklee I think the best solution would be to establish a single, common Python environment, with a single set of dependencies, that all GATK Python tools depend on. We would establish a single docker image that has all of these dependencies pip installed, and could also include a conda env for the GATK environment for users who don't want to use the docker image. If we could do that, it would eliminate the need load per-tool conda environments. From what I've seen so far based on existing branches, the two environments we need (gCNV and CNN-VQSR) don't look that far apart in terms of dependencies. gCNV is using Theano, and CNN Tensorflow, but the rest looks [pretty close](https://docs.google.com/a/broadinstitute.org/spreadsheets/d/1RV7--uBQ0ctlXzMH09cmr0VimpZYIU68DdxJzE60y-c/edit?usp=sharing). So a strawman proposal for the main components for a common environment would be:. Python 3.6; Numpy >= 1.13.1; Scipy 1.0.0; Theano .0.9.0; Tensorflow 1.4.0; Pymc3 3.1; Keras 2.1.1. Can you all chime on on whether you think we can converge in a single environment ? If so, it would greatly simplify things, and we can start with getting a docker image built for running travis tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3692#issuecomment-348188451:140,depend,dependencies,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3692#issuecomment-348188451,8,['depend'],"['depend', 'dependencies']"
Integrability,"@lucidtronix @mbabadi Update on this: There is a branch [here](https://github.com/broadinstitute/gatk/commits/cn_python_environment) that updates the docker image that we build on travis to include a full anaconda installation. That may be overkill in the long run but for now gives us a base environment for running integration tests on Travis. The environment managers I've looked at (conda and virtualenv) both appear to work by activating a shell environment. Ideally, we wouldn't need an intermediate shell between the Java code and the Python code, but thats still TBD. In parallel, I'm working on a streaming I/O solution for using input/output streams over standard I/O as the next incarnation of the PythonScriptExecutor for https://github.com/broadinstitute/gatk/issues/3698.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3692#issuecomment-340804405:317,integrat,integration,317,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3692#issuecomment-340804405,1,['integrat'],['integration']
Integrability,"@lucidtronix Agreed -- provided that there's a fallback conda environment that users without AVX can use, and provided that the tool produces an easy-to-understand error message when AVX is not present, pointing the user to that fallback environment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-428273650:170,message,message,170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-428273650,1,['message'],['message']
Integrability,"@lucidtronix Based on the response we got from Intel, I tried upgrading to TF 1.15, but there are a cascade of downstream issues. The version of openssl we use conflicts (not sure what thats used for, but for now I removed the explicit dependency from the conda env); next was numpy, which I upgraded to 1.16; followed by what appear to be keras import issues. The branch with the 3 commits is [here](https://github.com/broadinstitute/gatk/tree/cn_update_tensorflow), and the most recent Travis results (with the keras issue) [here](https://travis-ci.com/broadinstitute/gatk/builds/144056822). Can you take a look ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6307#issuecomment-573878340:236,depend,dependency,236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6307#issuecomment-573878340,1,['depend'],['dependency']
Integrability,"@lucidtronix Does the above outlined proposal for establishing a common environment work for you ? I think there are a bunch of other dependencies we need to include for one or the other of the tools, but I think this lists the common ones (plus Theano/Tensorflow).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3692#issuecomment-348528188:134,depend,dependencies,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3692#issuecomment-348528188,1,['depend'],['dependencies']
Integrability,"@lucidtronix Have you looked at the conda env defined in this branch ? The .yml file here is based in part on dependencies I took from your conda env (minus the actual VQSR-CNN package, since we want our travis tests to run on the code and env defined in the GATK source repo - see comment above), but I haven't actually tried running your code with it yet. I want to make sure we're converging on a unified conda env.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350307336:110,depend,dependencies,110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350307336,1,['depend'],['dependencies']
Integrability,"@lucidtronix Hi Sam, wonder if you could take a look at this? Adding the ""AVX required"" message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-427873520:88,message,message,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-427873520,1,['message'],['message']
Integrability,@lucidtronix Probably something's up with my configuration...; `; $ gcc -v; Using built-in specs.; COLLECT_GCC=gcc; COLLECT_LTO_WRAPPER=/Users/markw/anaconda/envs/py27/bin/../libexec/gcc/x86_64-apple-darwin11.4.2/4.8.5/lto-wrapper; Target: x86_64-apple-darwin11.4.2; Configured with: ./configure --prefix=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_1477649012852/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --with-gxx-include-dir=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_1477649012852/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac/gcc/include/c++ --bindir=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_1477649012852/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac/bin --datarootdir=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_1477649012852/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac/share --libdir=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_1477649012852/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac/lib --with-gmp=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_1477649012852/_b_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --with-mpfr=/Users/ray/mc-x64-3.5/conda-bld/gcc-4.8_147764901285,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4742#issuecomment-391065177:223,wrap,wrapper,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4742#issuecomment-391065177,1,['wrap'],['wrapper']
Integrability,"@magicDGS . I am afraid this is not easy. I didn't write the binding (@tedsharpe did), but I would asseme the limitation comes from bwa mem itself, not the binding, as the binding is a thin wrapper that delegates the loading of the index files (or the image that combines all 5 index files in this case) to bwa. . The SV team here have a script (`scripts/sv/default_init.sh`) that when the Spark cluster is created and initialized, the image file is distributed to all walker nodes. Spark clusters other than Google's Dataproc would probably allow you to provide scripts as initialization actions as well. On the other hand, there seem to be a `--files` argument that you can append to your cmd line arguments which yarn will parse and distribute the provided local file to all nodes, though in this case it will be very inefficient considering the image file's size.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312362074:190,wrap,wrapper,190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312362074,1,['wrap'],['wrapper']
Integrability,"@magicDGS A method like this should probably go into the base CommandLinePluginDescriptor class in Barclay first. . Having said that, I'm going to close this issue here, since I've recently added a new method in Barclay called [getDefaultInstances](https://github.com/broadinstitute/barclay/blob/976fafea23216cf0577b8e3fe635b115c7975a76/src/main/java/org/broadinstitute/barclay/argparser/CommandLinePluginDescriptor.java#L170) (not available until GATK upgrades, which I think will be soon). That, in combination with getAllInstances, might be sufficient for what you need. If not, please propose the new method in Barclay (or reopen this one here if I'm missing something). Either way, I think your original point about getAllInstances is valid, since the name doesn't reflect the contract, but for that I think we should just change the name of it in Barclay to something like ""getUserInstances"" to reflects what it actually does.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2362#issuecomment-275688356:782,contract,contract,782,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2362#issuecomment-275688356,1,['contract'],['contract']
Integrability,"@magicDGS After much thought I believe that the code we discussed belongs in your code, not in the GATK. Here's an outline of some static methods that should meet your needs:. ``` java; public class DGSUtils {; @FunctionalInterface; private interface LikelihoodFunction {; double apply(final Allele allele, final GATKRead read);; }. private static Allele createAllele(final PileupElement e, final byte refBase, final Allele refAllele) {; return e.isDeletion() ? Allele.SPAN_DEL : (e.getBase() == refBase ? refAllele : Allele.create(e.getBase()));; }. public static ReadLikelihoods<Allele> likelihoodsFromPileup(final ReadPileup pileup,; final Allele refAllele,; final SAMFileHeader header) {; final Map<String, List<GATKRead>> readsBySample = pileup.getReads().stream(); .collect(Collectors.groupingBy(read -> ReadUtils.getSampleName(read, header)));. final byte refBase = refAllele.getBases()[0];; final Set<Allele> alleleSet = new TreeSet<>();; pileup.forEach(e -> alleleSet.add(createAllele(e, refBase, refAllele)));. return new ReadLikelihoods<>(new IndexedSampleList(readsBySample.keySet()), new IndexedAlleleList<>(alleleSet), readsBySample);. }. public static void setLikelihoods(final ReadLikelihoods<Allele> likelihoods, final LikelihoodFunction likelihoodFunction) {; final int numAlleles = likelihoods.numberOfAlleles();; for (int sample = 0; sample < likelihoods.numberOfSamples(); sample++) {; final LikelihoodMatrix<Allele> matrix = likelihoods.sampleMatrix(sample);; final int numReads = matrix.numberOfReads();; for (int alleleIndex = 0; alleleIndex < numAlleles; alleleIndex++) {; final Allele allele = likelihoods.getAllele(alleleIndex);; for (int readIndex = 0; readIndex < numReads; readIndex++) {; final GATKRead read = matrix.getRead(readIndex);; matrix.set(alleleIndex, readIndex, likelihoodFunction.apply(allele, read));; }; }; }; }; }; ```. This lets you compute likelihoods with an arbitrary function of the read and the allele. In your toy example you would call it as:. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-253623925:241,interface,interface,241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2185#issuecomment-253623925,1,['interface'],['interface']
Integrability,"@magicDGS Can you move the make*Transformer methods up to GATKTool (at some point we'll have a plugin at that level), and then also integrate these with AssemblyRegionWalker ? We'll want to do the Spark tools as well, but we leave that for a separate PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-289924338:132,integrat,integrate,132,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2085#issuecomment-289924338,1,['integrat'],['integrate']
Integrability,"@magicDGS I could certainly do that (split out an OptionalReadFilterArgumentCollection), though we'd then need to add a ""requiresReadFilters"" method to determine which to use. I guess it depends on how common that case would be. An simple alternative would be to just override makeReadFilter and reject any command line filter requests or do any custom filter handling.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1900#issuecomment-225997121:187,depend,depends,187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1900#issuecomment-225997121,1,['depend'],['depends']
Integrability,"@magicDGS I don't expect we'll get to this for a while, at a minimum it will not be until after the beta milestone. The dependent changes referenced above are still under development.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-300189558:120,depend,dependent,120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-300189558,1,['depend'],['dependent']
Integrability,"@magicDGS I think the context for this issue is the Pathogen sequence detection tools, which are Spark tools. `CountingReadFilter` isn't inherently reducible, and shouldn't be used in a Spark tool. Also, I can't say love the idea of using a filter as a control flow mechanism; but I don't have a better idea (maybe a separate tool as @mwalker174 mentioned above ?). One other note. As things currently stand, wrapping a WellFormedReadFilter in a counting filter (which we currently do for walkers) wouldn't give summary counts at the granular level, because WellFormedReadFilter is composed from non-CountingRead filters. Wrapping it yields a single, outer level summary/count. It would be easy enough to create one though that provided detailed summary/counts though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3454#issuecomment-323738847:409,wrap,wrapping,409,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3454#issuecomment-323738847,2,"['Wrap', 'wrap']","['Wrapping', 'wrapping']"
Integrability,"@magicDGS I think the suggestion of using a common interface is a reasonable proposal, but we can't hold up this PR for that. We'll have to do that in a separate PR once the interface is propagated through the various projects.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3620#issuecomment-332958835:51,interface,interface,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3620#issuecomment-332958835,2,['interface'],['interface']
Integrability,@magicDGS I was thinking that we could reproduce essentially the same output using the void method having any of the methods that could return multiple error message wrap those multiple error messages into a single exception. . If you'd rather just merge your initial solution we can revisit changing the method signature in a later pr.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2226#issuecomment-255879124:158,message,message,158,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2226#issuecomment-255879124,3,"['message', 'wrap']","['message', 'messages', 'wrap']"
Integrability,@magicDGS I would say close and integrate into the single new PR.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2360#issuecomment-278331081:32,integrat,integrate,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2360#issuecomment-278331081,1,['integrat'],['integrate']
Integrability,"@magicDGS I'd strongly prefer not to introduce a read filter descriptor hierarchy if we can avoid it, as it will be tricky to get right, and add complexity. We definitely need to be able to extend the package list used by the descriptor to find plugins, but as you point out we'll be able to use the configuration mechanism for that. For before/after-analysis filters, I expect that we'll just add that directly to the existing plugin once we resolve https://github.com/broadinstitute/gatk/pull/2085 (which I hope to get to this week). I think the rest of the cases can be addressed by overriding makeReadFilter and providing custom behavior of filter merging. If this turns out to be something truly common, we could consider allowing the tool to inject an argument collection into the plugin.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2353#issuecomment-274970451:748,inject,inject,748,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2353#issuecomment-274970451,1,['inject'],['inject']
Integrability,"@magicDGS In the interest of moving this PR along, perhaps it would be easier to just write an integration test for `ExampleSlidingWindowReadWalker` that uses a large interval from a more realistic bam (such as `CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam` from `large`). This would address most of my concerns, and we could create a ticket to eventually add exhaustive tests with synthetic reads in a future PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4682#issuecomment-418453819:95,integrat,integration,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4682#issuecomment-418453819,1,['integrat'],['integration']
Integrability,"@magicDGS My apologies for the long delay on this. It looks like there are still quite a few standard porting issues that need to be addressed in this PR (brackets, finals, multiple top-level public classes, outdated GATK3 usage example, remove references to RODs, kebabify, etc., etc.). There is also the bigger issue of testing and validation - ideally at a minimum we'd reproduce the existing GATK3 tests, but since these are dependent on large, private files, those tests will have to be replaced with new tests, and validated/compared against GATK3. These same issues will come up with IndelRealigner. @vdauwera @sooheelee Even with @magicDGS graciously volunteering to do the work of porting the code, retaining the indel realignment tools will require internal review, helping with test development and validation, and support. Before we commit to that, I guess I want to make sure that this is indeed a high priority, and that you think porting this to GATK4 is a better option than relying on GATK3, or letting @magicDGS port it to ReadTools ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363451643:429,depend,dependent,429,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363451643,1,['depend'],['dependent']
Integrability,"@magicDGS My take on these: I think the read filter plugin descriptor shouldn't be removed, since it also does filter merging, header propagation, etc. which need to be done even if you want to disable user command line control. (Also, if you remove it I would expect you'd get an NPE). So I would say that we should update the doc to say that you shouldn't remove it from the list, and should override `makeReadFilter` in the case where you want finer control. I know we talked a lot about the transformer issue a while back; I think the intention was that we would do the integration with the rest of the tool types as part of https://github.com/broadinstitute/gatk/issues/2160, but @droazen may recall differently.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4651#issuecomment-381279453:574,integrat,integration,574,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4651#issuecomment-381279453,1,['integrat'],['integration']
Integrability,"@magicDGS Review complete for now. Looks good but I have some nitpicks. I think they're almost all due to it being ancient gatk3 code that no one has updated in a long time. I'd recommend dropping the deprecated formats and only supporting mpilup single sample format which should allow for massive simplification of both the Codec and the Feature. . We need some unit tests for the codec itself since it has a bunch of different potential error cases, and we should have some integration tests for the tool that show it correctly failing on cases with errors.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1862#issuecomment-224417179:477,integrat,integration,477,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1862#issuecomment-224417179,1,['integrat'],['integration']
Integrability,"@magicDGS Sorry for the delay on this one -- I'll try to talk it over with the other GATK devs soon. One question: would a generic ""hide/disable this list of arguments"" feature in barclay be a workable solution for you? That seems like a viable alternate approach that could spare GATK from having to wrap all of our arguments in interfaces.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-365649680:301,wrap,wrap,301,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-365649680,2,"['interface', 'wrap']","['interfaces', 'wrap']"
Integrability,"@magicDGS The plan is to eventually push this codec down into htsjdk for wider use by the community, but we want to develop it here first for the sake of fast iteration. Since the GATK project that depends on this branch has a looming deadline, we're unable to generalize this code further at this time, but we can revisit this when the codec is moved into htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3410#issuecomment-321247532:198,depend,depends,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3410#issuecomment-321247532,1,['depend'],['depends']
Integrability,"@magicDGS Was discussing this today with @lbergelson, and Louis thinks that we should temporarily depend on a snapshot of ADAM to work around the problem, rather than disabling ADAM support. The one disadvantage of that approach is that we'd be prevented from releasing GATK to maven central until we move off of the snapshot. I recommend that we reach out to the ADAM project to try to find out when their next release might be, so that we have a sense of the time scale involved.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2247#issuecomment-258534258:98,depend,depend,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2247#issuecomment-258534258,1,['depend'],['depend']
Integrability,"@magicDGS We already plan to add the common CommandLineProgram interface as described in (broadinstitute/barclay#127). I think that makes a lot more sense than adding more new methods for this. The existing PR for it is out of date though, since there is more and more common functionality that could be pushed up into the common base (beta/experimental decoration, tool registry, etc.).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4660#issuecomment-382000269:63,interface,interface,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4660#issuecomment-382000269,1,['interface'],['interface']
Integrability,"@magicDGS We recently hit this ourselves (https://github.com/broadinstitute/gatk-protected/issues/1048). The fix is easy, but I'd like to find a way to repro it as a standalone test in Barclay, with no dependencies, i.e., no gatk dependencies. Also, to use docgen for your toolkit, you'll need to provide the source for common classes like read filters, argument collections, etc. You may have noticed that gatk-protected does this. I expect that list will grow as we add @DocumentedFeature to more tools and encounter more dependencies.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2739#issuecomment-303124944:202,depend,dependencies,202,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2739#issuecomment-303124944,3,['depend'],['dependencies']
Integrability,"@magicDGS We talked about this a bit today. I think we should get https://github.com/broadinstitute/gatk/pull/4469 finished and merged, and then rebase this on top of that. Then we should put the remaining arguments, including the ""doc-only"" config file arg, as well as the special arguments collection, into the interface and default implementation class that you've defined here. Then we can do a detailed review.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-377344569:313,interface,interface,313,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-377344569,1,['interface'],['interface']
Integrability,"@magicDGS We will definitely be keeping the `GATKRead` interface around for the foreseeable future. When the HTSJDK 3.0 interfaces materialize we'll re-evaluate, but it's possible that we would continue to code against `GATKRead` even then, as our `SAMRecord` -> `GATKRead` adapter layer does some useful caching, and having our own interface has certain advantages (as well as disadvantages).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358325854:55,interface,interface,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358325854,4,"['adapter', 'interface']","['adapter', 'interface', 'interfaces']"
Integrability,"@magicDGS We'd like to, but are currently prevented from migrating to Java 11 by our Spark dependency (see https://issues.igniterealtime.org/browse/SPARK-2017). This ticket is specifically for the task of benchmarking alternate Java 8 JDKs, rather than upgrading to newer versions of Java.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5279#issuecomment-429064810:91,depend,dependency,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5279#issuecomment-429064810,1,['depend'],['dependency']
Integrability,"@magicDGS We've inherited customCommandLineValidation() from picard, but it never really caught on as a way to do things in GATK. The fact that it's output is inconsistent with the rest of the command line parsing is an accident and should be fixed. . I think the right thing to do here would be to make `customCommandLineValidation()` into a `void` method that either throws a `CommandLineException` or doesn't. It will take some changes to a few tools but it will make things less confusing in the long run. Then you can move the call to customCommandLineValidation to just after the call to `parseArgs` like you've done, but we can remove the custom code to print error messages since it will just be handled by the regular exception handling.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2226#issuecomment-255845846:673,message,messages,673,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2226#issuecomment-255845846,1,['message'],['messages']
Integrability,"@magicDGS You could always rename the arguments within your tool, rather than changing the interface to our tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2384#issuecomment-278452455:91,interface,interface,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2384#issuecomment-278452455,1,['interface'],['interface']
Integrability,"@magicdgs Do you get all your dependencies from there, or only gatk? I assumed you had multiple repos configured so that it first resolves from central and then from artifactory. I'm not sure how to configure that sanely in maven, although I'm sure it's doable to someone who is less ignorant of maven then me.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-340474332:30,depend,dependencies,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-340474332,1,['depend'],['dependencies']
Integrability,"@magigDGS There are 4 separate issues in here, and I have slightly different feelings about each of them. Some comments:. - Removing the RNA string seems fine.; - I deliberately left the GATK test program group in because even though there is a Picard one, its harmless, and easier for people to find.; - I have reservations about exposing and sharing the super category maps. The Picard docgen process is pretty much unused and unmaintained at this point. The `getSuperCategoryMap` mthod really shouldn't be public, and it may even be removed in the near future. The GATK supercategory map ""truth"" should be defined by GATK.; - I'm reluctant to make the GATK `getSuperCategoryMap` public, because I don't think it can have any kind of useful contract. Its tied to the GATK doc templates and doc process, which we need to be able to change freely. It seems much safer for ReadTools to define it's own set categories (the overlap would probably pretty minimal I think - maybe just ReadFilters, right ?).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4247#issuecomment-360832234:743,contract,contract,743,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4247#issuecomment-360832234,1,['contract'],['contract']
Integrability,"@marionamujal I just noticed that this email was sent directly to me, rather than being; posted to the github ticket. Anyway, this looks like a completely different issue than what was reported; in the original ticket - in this case, the parser thinks that; 'UGTB015-pe.sorted.marked_duplicates.bam' is a positional argument, which; indicates that the command line being executed is not properly formed. I; suspect the shell code isn't working as you expect.; -Chris. On Thu, Jun 11, 2020 at 10:19 AM marionamujal <notifications@github.com>; wrote:. > I have a similar issue with BaseRecalibator; i get the error message; > below; when I run the script below.; > A USER ERROR has occurred: Invalid argument; > 'UGTB015-pe.sorted.marked_duplicates.bam'.; > ------------------------------; >; > org.broadinstitute.barclay.argparser.CommandLineException: Invalid; > argument 'UGTB015-pe.sorted.marked_duplicates.bam'.; > at; > org.broadinstitute.barclay.argparser.CommandLineArgumentParser.setPositionalArgument(CommandLineArgumentParser.java:600); > at; > org.broadinstitute.barclay.argparser.CommandLineArgumentParser.parseArguments(CommandLineArgumentParser.java:432); > at; > org.broadinstitute.hellbender.cmdline.CommandLineProgram.parseArgs(CommandLineProgram.java:232); > at; > org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:206); > at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); > at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); > at org.broadinstitute.hellbender.Main.main(Main.java:292); >; > for sample in $(ls *-pe.sorted.marked_duplicates.bam | sed; > 's/-pe.sorted.marked_duplicates.bam//g' | sort | uniq); do echo $sample; > gatk --java-options ""-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Xmx4g; > -Djava.io.tmpdir=pwd`/tmpdir"" BaseRecalibrator; > -R $REF; > -I ${sample}-pe.sorted.marked_duplicates.bam; > --known-sites ${ref_dbsnp}; > --known-sites ${ref_Mills_and_1000G}; > --known-sites ${ref_1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2199#issuecomment-651127284:613,message,message,613,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2199#issuecomment-651127284,1,['message'],['message']
Integrability,@marissa97 A given version of the GATK conda environment is built for a specific Python version -- attempting to update it to use a newer version without also updating the rest of the dependencies is likely to fail.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8127#issuecomment-1376270558:184,depend,dependencies,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8127#issuecomment-1376270558,1,['depend'],['dependencies']
Integrability,"@markw The error message above looks like the one I'd expect you'd get if you haven't built the python archive (`./gradlew createPythonPackageAchive`), as discussed in the Slack thread. I assume you get a different error message once you've done that (which was in turn resolved by your moving the .yml file). If thats right, can you update this ticket with that message/output, and the conda version you're using.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4741#issuecomment-387155861:17,message,message,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4741#issuecomment-387155861,3,['message'],['message']
Integrability,"@mbabadi Can you update this when you get a chance? We should reevaluate how much of the ICG, FourierLinearOperator, etc. stuff we want to leave in. For example, is it worth requiring the dependency on nd4j?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2929#issuecomment-356695544:188,depend,dependency,188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2929#issuecomment-356695544,1,['depend'],['dependency']
Integrability,"@mbabadi I think the somatic tests are fixed: https://travis-ci.org/broadinstitute/gatk/builds/313333659?utm_source=email&utm_medium=notification Did you pull my commit?. Feel free to cut out some of the test cases if the WDL tests are too slow. Especially now that there is no real distinction between WGS/WES besides -L (except for in PreprocessIntervals, which integration tests should cover).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-350248239:364,integrat,integration,364,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-350248239,1,['integrat'],['integration']
Integrability,"@mbabadi I've updated my PR to use miniconda3. @mbabadi @lucidtronix @samuelklee I think we should aim for tools that at least run out-of-box, without depending on any out-of-band configuration other than the conda env. On top of that we can provide guidance/configs for users on how to enable further optimizations, like g++. Does that sound like an achievable goal ?. As for the docker, we're going to have strike the right balance between image bloat and performance(including test performance). I think we're around 4+ gig now, and counting. Before the Python integration we were at 1.9G, and trying to find ways to reduce it. So lets see where we wind up but keep that in mind. Finally, we need to find a way to install the (GATK) python package(s) without depending on access to the GATK repo. Right now I think the gCNV branch has a ""pip install from source"" added to the conda env .yml. That will work on the docker at the moment (and thus on travis), but that won't work for non-docker users how don't have source/repo access. Also, one of the proposals to reduce the size of the docker is to remove the repo clone that is currently there. My proposal is that we change the gradle build to create an archive/zip of the python source (this would include the VQSR-CNN package code as well as gCNV kernel). We can then copy that on to the docker image, and pip-install it from the copy. That would retain the ability to always run travis tests based on the code in the repo, and also keep the nightly docker image in sync. We'll also have deliver the archive as an artifact somehow (perhaps including PyPi) for non-docker users.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350303277:151,depend,depending,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-350303277,6,"['depend', 'integrat']","['depending', 'integration']"
Integrability,"@mbabadi Looks like an integration test is now failing, which was not the case with the previous (Travis-related?) failures:. Gradle suite > Gradle test > org.broadinstitute.hellbender.tools.exome.germlinehmm.xhmm.XHMMSegmentGenotyperIntegrationTest.testRun[0](org.broadinstitute.hellbender.tools.exome.germlinehmm.xhmm.XHMMSegmentCallerBaseIntegrationTest$XHMMData@335a85cb) FAILED; org.broadinstitute.hellbender.exceptions.UserException$BadInput: Bad input: The sample names in the provided segments file does not match those on which HMM output is given; at org.broadinstitute.hellbender.utils.hmm.segmentation.HMMPostProcessor.composeGenotypingSegmentsFromSegmentsFile(HMMPostProcessor.java:552); at org.broadinstitute.hellbender.utils.hmm.segmentation.HMMPostProcessor.writeVariantsToVCFWriterOnGivenSegments(HMMPostProcessor.java:282); at org.broadinstitute.hellbender.tools.exome.germlinehmm.xhmm.XHMMSegmentGenotyper.makeCalls(XHMMSegmentGenotyper.java:79); at org.broadinstitute.hellbender.tools.exome.germlinehmm.xhmm.XHMMSegmentCallerBase.doWork(XHMMSegmentCallerBase.java:100); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:122); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:109); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:129); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:28); at org.broadinstitute.hellbender.tools.exome.germlinehmm.xhmm.XHMMSegmentGenotyperIntegrationTest.testRun(XHMMSegmentGenotyperIntegrationTest.java:60)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2813#issuecomment-307206903:23,integrat,integration,23,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2813#issuecomment-307206903,1,['integrat'],['integration']
Integrability,"@mbabadi Not sure - we'll need to discuss how to do handle that. It looks like the docker image already has g++ installed, which is a start. Having said that, the docker image is getting pretty huge rapidly... BTW, do you know if there is way to programmatically query theano to determine whether it will compile the graph, vs running python/numpy ? I know it prints out a message, but it would be nice if we could detect that from theano directly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-349733375:373,message,message,373,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-349733375,1,['message'],['message']
Integrability,"@mbabadi On testing, I think what you suggest is workable. I thought you guys would want unit tests for your own purposes - but for travis we're going to have to depend on java-driven tests anyway, so as long as we have good tests that should work.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-345794012:162,depend,depend,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-345794012,1,['depend'],['depend']
Integrability,"@mcovarr Does the GVS traversal artifact destined to remain in GATK depend on the `BigQueryUtils`? I'm guessing that it does? Is the intention that `BigQueryUtils` would remain in gatk/master, then, just in a different package?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8375#issuecomment-1604769158:68,depend,depend,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8375#issuecomment-1604769158,1,['depend'],['depend']
Integrability,"@meganshand Do you have a public mitochondrial bam that I could use for a test? If not, what if I took just the reads at the beginning of the contig, excluding any variants, and anonymized the header? That would be enough. Actually, if you do have an entire mitochondrial bam that's public, I wouldn't mind adding a mitochondrial integration test to the repo. . .",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5038#issuecomment-406461195:330,integrat,integration,330,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5038#issuecomment-406461195,1,['integrat'],['integration']
Integrability,@meganshand I will include testing for this bug as part of an overall mitochondria integration test using your NA12878 bam in a separate PR.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5038#issuecomment-406838107:83,integrat,integration,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5038#issuecomment-406838107,1,['integrat'],['integration']
Integrability,"@meganshand There is a warning in the docs for `ReadCoordinateComparator` that it should not be used for bam file output that needs to match the ordering of `SAMRecordCoordinateComparator` exactly, since it sorts all unmapped reads after all mapped reads. `ReadCoordinateComparator` is a comparator for `GATKRead`, and that interface does not allow unmapped reads to have a position. Ie., even if an unmapped `SAMRecord` is assigned the position of its mapped mate, calling `getContig()`/`getStart()` on the unmapped read via the `GATKRead` interface will return null/0. This was done mainly for consistency reasons and to simplify client code. Whenever we need bam file order for reads in GATK4, we operate on SAMRecords directly and use either the `SAMRecordCoordinateComparator` from htsjdk or the `HeaderlessSAMRecordCoordinateComparator` (for headerless Spark reads) that produces the same ordering. I recommend addressing this for this tool via `presorted = false` for now, since the GATK3 version has it set to false as well with the comment: ""**we don't want to assume that reads will be written in order by the manager because in deep, deep pileups it won't work**"". This suggests that even if you were to change the comparator used by this tool to behave like `SAMRecordCoordinateComparator`, you'd still have ordering issues in deep coverage areas. It's worthwhile, though, to open a separate ticket to explore whether `ReadCoordinateComparator` could be changed to exactly match bam file order. Eg., perhaps we could add `getAssignedContig()`, `getAssignedStart()`, etc. methods to `GATKRead` to expose the positions that unmapped reads with mapped mates get assigned for sorting purposes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1853#issuecomment-224668518:324,interface,interface,324,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1853#issuecomment-224668518,2,['interface'],['interface']
Integrability,"@mlathara The workaround of using multiple intervals does work (it took me more than one week to confirm, implying how annoying this bug could be), but several versions later, GATK still has this issue and could not even produce an informative error message. I could not find any mention of this issue in GATK's documentation. Is this bug going to be fixed?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-907716852:250,message,message,250,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-907716852,1,['message'],['message']
Integrability,"@mmokrejs That message is harmless -- the build system is just trying to delete some symlinks that may exist if `mvn clean` was not run before the build, but it's not finding anything to delete. It's not an actual error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4686#issuecomment-383196456:15,message,message,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4686#issuecomment-383196456,1,['message'],['message']
Integrability,"@mohitmathew Thanks for the report! We are currently in the process of updating GATK to Java 17, which necessarily involves updating many of our dependencies. We are also updating our docker image to be based off of the latest Ubuntu LTS release. This should greatly reduce the number of critical vulnerabilities in our release image. After the Java 17 switchover we can revisit this and see what security issues remain.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1442245408:145,depend,dependencies,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1442245408,1,['depend'],['dependencies']
Integrability,"@mohitmathew With the GATK 4.5 release, we've again made significant progress on the known vulnerabilities in our dependencies, as well as in our docker image. There are still a few left, in ""dependencies of our dependencies"" that will be difficult to update, but we're getting there. Note that the known vulnerabilities in log4j 1.x reported above are **not** the same as the infamous (and extremely serious) log4j 2.x vulnerabilities that were discovered a few years back. log4j 1.x completely lacks the feature that was exploited in the log4j 2.x vulnerability, and we patched our version of log4j 2.x in GATK almost as soon as that vulnerability was reported.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1854898099:114,depend,dependencies,114,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-1854898099,3,['depend'],['dependencies']
Integrability,"@munrosa Is there any chance we could use part of the data you shared as an integration test within the gatk repository? The repo is public, but we would only need a few hundred bases of your data and could anonymize the sample name and anything else in the header. We fully understand if this is not possible, and are very grateful for the help you have given already.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-451712253:76,integrat,integration,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-451712253,1,['integrat'],['integration']
Integrability,"@mwalker174 Is encountering the same problem in the wild. He's reporting that it goes away if you specify the environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY. he's seeing the warning message:; ```; 16:55:09.480 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; ```; which *should* only appear during tests, so something is strange.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330650894:221,message,message,221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330650894,1,['message'],['message']
Integrability,"@mwalker174 It sounds like this is still a work in progress, so I""m not sure what kind of ffedback you're looking for at this point but I made a couple of suggestions relating to how these tools and the read filters integrate with the framework. FWIW.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2237#issuecomment-257380584:216,integrat,integrate,216,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2237#issuecomment-257380584,1,['integrat'],['integrate']
Integrability,"@mwalker174 Many gatk tools require our bams to have readgroups. We should probably update our bwa tools to add readgroups, although fixing hadoop-bam to give a more useful error message would be good as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3488#issuecomment-324388148:179,message,message,179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3488#issuecomment-324388148,1,['message'],['message']
Integrability,"@mwalker174 the region you found above is included in the 10X SV blacklist. What list is the SV team currently using?. If the read-depth data is not reliable in these regions, I would not expect the model fit to be very good, even if we made the model more robust against nans. So I wouldn't think the results would be very useful for SV integration. Is there a way to make CNV-SV integration ""Bayesian"" in the sense that we could fall back on a prior in the case of missing CNV data?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4824#issuecomment-393202676:338,integrat,integration,338,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4824#issuecomment-393202676,2,['integrat'],['integration']
Integrability,"@nalinigans ,I have put the command for chromosome 9 and chromosome 10 is similar, thanks.; ```; gatk --java-options ""-Xmx40g"" GenotypeGVCFs -R /home/xuql/copyNAM/B73/Zm-B73-REFERENCE-NAM-5.0.fa -stand-call-conf 0 -ploidy 1 -V gendb:///home/xuql/copyNAM/NAM_out_gatk9_1 -O /home/xuql/copyNAM/gatk93.vcf.gz --cloud-prefetch-buffer 10000 --cloud-index-prefetch-buffer 10000 --genomicsdb-max-alternate-alleles 110 --max-alternate-alleles 100 --gcs-max-retries 1000; ```; `GenotypeGVCFs` error. ```; 20:16:05.938 INFO ProgressMeter - 9:3448230 8.8 3294000 373171.8; 20:16:15.978 INFO ProgressMeter - 9:3553392 9.0 3386000 376457.9; 20:16:26.015 INFO ProgressMeter - 9:3646052 9.2 3471000 378861.9; [TileDB::ArrayIterator] Error: Cannot advance iterator; Buffer overflow.; terminate called after throwing an instance of 'VariantStorageManagerException'; what(): VariantStorageManagerException exception : VariantArrayCellIterator increment failed; TileDB error message : [TileDB::ArrayIterator] Error: Cannot advance iterator; Buffer overflow. ```; ```; gatk --java-options ""-Xmx50g -Xms5g"" GenomicsDBImport \; -V /home/xuql/copyNAM/B97/B97ToB73.gvcf.gz \; -V /home/xuql/copyNAM/CML247/CML247ToB73.gvcf.gz \; -V /home/xuql/copyNAM/CML333/CML333ToB73.gvcf.gz \; -V /home/xuql/copyNAM/HP301/HP301ToB73.gvcf.gz \; -V /home/xuql/copyNAM/Ki3/Ki3ToB73.gvcf.gz \; -V /home/xuql/copyNAM/M37W/M37WToB73.gvcf.gz \; -V /home/xuql/copyNAM/NC350/NC350ToB73.gvcf.gz \; -V /home/xuql/copyNAM/Oh7B/Oh7BToB73.gvcf.gz \; -V /home/xuql/copyNAM/Tzi8/Tzi8ToB73.gvcf.gz \; -V /home/xuql/copyNAM/CML103/CML103ToB73.gvcf.gz \; -V /home/xuql/copyNAM/CML277/CML277ToB73.gvcf.gz \; -V /home/xuql/copyNAM/CML52/CML52ToB73.gvcf.gz \; -V /home/xuql/copyNAM/Il14H/Il14HToB73.gvcf.gz \; -V /home/xuql/copyNAM/Ky21/Ky21ToB73.gvcf.gz \; -V /home/xuql/copyNAM/Mo18W/Mo18WToB73.gvcf.gz \; -V /home/xuql/copyNAM/NC358/NC358ToB73.gvcf.gz \; -V /home/xuql/copyNAM/P39/P39ToB73.gvcf.gz \; -V /home/xuql/copyNAM/CML228/CML228ToB73.gvcf.gz \; -V /h",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7976#issuecomment-1367332059:956,message,message,956,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7976#issuecomment-1367332059,1,['message'],['message']
Integrability,"@neuro2019 Well, the gatkDoc task relies on running the javadoc process with a custom doclet. I'm not sure why its not working for you, but a few suggestions to try. You can try running `javadoc` from the command line to make sure you have the executable. Also, it looks like you're trying to run from within`/usr/bin`. Not sure if thats deliberate, but do other gradle tasks succeed there, i.e., does `./gradlew shadowJar` work ? I would expect that `./gradlew javadoc` would also fail ? Also, normally the gatkDoc task is only run by us when we do a new release and publish the doc. Its not something most users would need to do. Depending on what you're trying to do, you might be able to skip that. But if you need to, let us know the results of the suggestions above.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6466#issuecomment-592725915:632,Depend,Depending,632,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6466#issuecomment-592725915,1,['Depend'],['Depending']
Integrability,"@nh13 - @Kmannth and I met today and discussed this ticket. As @droazen mentioned above, we're currently working on a new release, primarily bringing dependencies up to date and addressing a couple reported bugs related to processing SNPs and indels. The current release of GKL was primarily tested on SNPs and indels, and not long reads. We have a few open tickets surrounding long reads. We plan on addressing these in a future release. We will pull your ticket into that body of work. . In the meantime please let us know if you run into GKL issues with short reads, and we will be sure to prioritize for our pending release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6733#issuecomment-674241524:150,depend,dependencies,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6733#issuecomment-674241524,1,['depend'],['dependencies']
Integrability,"@nh3 care to take a look? In the GGVCFs integration test, the with OxoGReadCounts.g.vcf file has ; ```; 20 10101674 . TTGTGTG T,TTG,TTGTGTGTGTGTG,TTGTGTGTGTGTGTG,<NON_REF> 1464.10 . DP=64;ExcessHet=3.0103;MLEAC=0,1,1,0,0;MLEAF=0.00,0.500,0.500,0.00,0.00;RAW_MQandDP=196622,64 GT:AD:DP:F1R2:F2R1:GQ:PL:SB 2/3:0,3,22,6,4,0:35:0,1,13,3,3,0:0,2,9,3,1,0:47:1481,1115,1205,557,577,581,932,574,0,925,973,621,47,860,972,1495,1189,615,968,1015,1570:0,0,20,15; ```; with read counts. | TTGTGTG* | T | TTG | TTGTGTGTGTGTG | TTGTGTGTGTGTGTG | <NON_REF> |; | --- | -- | -- | -- | -- | -- |; | 0 | 1 | 13 | 3 | 3 | 0 |; | 0 | 2 | 9 | 3 | 1 | 0 |. after genotyping alleles get dropped and trimmed and we have. | TTGTG* | T | TTGTGTGTGTG |; | -- | -- | -- |; | 0 | 13 | 3 |; | 0 | 9 | 3 |. Do you agree that's as expected? (I couldn't reproduce your exact example without the exact bam.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5833#issuecomment-476221850:40,integrat,integration,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5833#issuecomment-476221850,1,['integrat'],['integration']
Integrability,"@ning-y The GATK conda environment distributed with GATK in the `gatkcondaenv.yml` file contains the necessary R dependencies to run our tools:. ```; - r-base=3.6.2; - r-data.table=1.12.8; - r-dplyr=0.8.5; - r-getopt=1.20.3; - r-ggplot2=3.3.0; - r-gplots=3.0.3; - r-gsalib=2.1; - r-optparse=1.6.4; - r-backports=1.1.10; ```. The bioconda GATK package is not maintained by us -- if it's missing these R dependencies, you might want to open a ticket with the bioconda maintainer!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7697#issuecomment-1061048229:113,depend,dependencies,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7697#issuecomment-1061048229,2,['depend'],['dependencies']
Integrability,@nyl2002 What's your command line that's hitting problems? Are you trying to run BWA-MEM spark on a SAM file or on a BAM file? . I agree that we should change documentation and produce a better error message if it's failing on SAM files.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4131#issuecomment-358365390:200,message,message,200,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4131#issuecomment-358365390,1,['message'],['message']
Integrability,"@olavurmortensen, looks like TILEDB_DISABLE_FILE_LOCKING=1 did not get passed to the tool. Did you use `export TILEDB_DISABLE_FILE_LOCKING=1` as the command to set the environment variable?; If you have and see the issue, please try the attached zip that contains a shared library with some debug/tracing messages, so we can pinpoint the issue a little more.; [libgenomicsdb.zip](https://github.com/broadinstitute/gatk/files/2922767/libgenomicsdb.zip); To use the zip, from a bash shell:. ```; %: tar zxf libgenomicsdb.zip; %: export LD_LIBRARY_PATH=`pwd`:$LD_LIBRARY_PATH; %: export TILEDB_DISABLE_FILE_LOCKING=1; %: gatk --java-options ""-Xmx4g -Xms4g"" GenomicsDBImport ...; ```; Please attach the log if you still see the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5740#issuecomment-468989614:305,message,messages,305,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5740#issuecomment-468989614,1,['message'],['messages']
Integrability,@oldmikeyang Thank you for reporting and then following up. I'm going to reopen this because we should not be crashing with an NPE. We should provide a useful error message in this common error case.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5169#issuecomment-419923524:165,message,message,165,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5169#issuecomment-419923524,1,['message'],['message']
Integrability,"@pd410668 This is just an informational message, and nothing to worry about. It's not an error. It looks like the `HaplotypeCaller` otherwise completed normally.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7229#issuecomment-831442213:40,message,message,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7229#issuecomment-831442213,1,['message'],['message']
Integrability,"@pnvaidya Actually, one more request, could go into the haplotype caller integration tests and specify to use `AVX_ENABLED` smith waterman?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3701#issuecomment-337346662:73,integrat,integration,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3701#issuecomment-337346662,1,['integrat'],['integration']
Integrability,@psfoley The branch is failing tests after your latest commit with the error:. ```; > Could not resolve all dependencies for configuration ':runtime'.; > Could not find com.intel:genomicsdb:0.9.2-proto-3.0.0-beta-1+uuid-static.; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360870965:108,depend,dependencies,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360870965,1,['depend'],['dependencies']
Integrability,"@pupgen I can't see anything obvious from the log, but some of the log messages seem to not be in the order I would expect. ; The GATK version you're running is almost 2 years old, and there have been quite a few releases since then. Can you reproduce this behavior with GATK 4.1.9.0 ? If so, can you include a log from that ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6990#issuecomment-744559303:71,message,messages,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6990#issuecomment-744559303,1,['message'],['messages']
Integrability,"@rdbremel This got missed in the churn of issues. Does this happen repeatedly or is it a 1 time occurrence? We've seen similar issues in the past and tried to wrap them all in layers of retries, but sometimes things slip through.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-547962085:159,wrap,wrap,159,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-547962085,1,['wrap'],['wrap']
Integrability,"@riasc I got the same issue on 4.4.0.0 and found that it was due to running via slurm. . Not sure why, but when running from the headnode it works, but running via sbatch only the .vcf and .vcf.idx are created. In the error message it reads:. > A USER ERROR has occurred: Mutect stats table calls.vcf.stats not found. When Mutect2 outputs a file calls.vcf it also creates a calls.vcf.stats file. Perhaps this file was not moved along with the vcf, or perhaps it was not delocalized from a virtual machine while running in the cloud. which sounds related.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6271#issuecomment-1599684447:224,message,message,224,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6271#issuecomment-1599684447,1,['message'],['message']
Integrability,"@ronlevine I don't see a test covering that argument in GATK4. If you have such a test in GATK3, could you port it to GATK4 (or write a new test if the old one depends on large files in the Broad filesystem)?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2301#issuecomment-265793638:160,depend,depends,160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2301#issuecomment-265793638,1,['depend'],['depends']
Integrability,"@ronlevine I haven't started, but start to PR would be a few days to a week. However, if you're doing the same thing my efforts might be totally extraneous. It depends what exactly you're doing but Pair-HMM is the same for HC and M2.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3338#issuecomment-318448675:160,depend,depends,160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3338#issuecomment-318448675,1,['depend'],['depends']
Integrability,"@samuelklee . In the non-docker integration test build we do run the R installation script, but a failure doesn't kill the build unless the tests fail because of it. . Would it be less painful if we had a readme explaining how to update the r-dependencies? That way it wouldn't be a surprise that you have to build a new docker image. Typically the workflow when updating the R installation script should probably be to update the base image and update the Dockerfile in the same PR that updates the R dependencies. That way we don't get out of sync. . I do like the idea of hosting the cran dependencies somewhere ourselves. Those cause us a lot of pain.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3712#issuecomment-337638980:32,integrat,integration,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3712#issuecomment-337638980,4,"['depend', 'integrat']","['dependencies', 'integration']"
Integrability,"@samuelklee @cmnbroad I wonder whether we could get rid of libgcc-ng altogether? it automatically appeared after I installed the main dependencies. For what it's worth, I have a fully working mkl-enabled gcnv python env on my mac!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4074#issuecomment-356015168:134,depend,dependencies,134,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4074#issuecomment-356015168,1,['depend'],['dependencies']
Integrability,"@samuelklee @lucidtronix @mbabadi I still need to update the readme, but please review/try this out. I wound up just creating the conda environment right in the docker, so we use the same environment we'll give to non-docker users. The environment includes the common dependencies from https://github.com/broadinstitute/gatk/issues/3692, but not the actual GATK (CNN-vqsr or gCNV) packages.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-349144593:268,depend,dependencies,268,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3912#issuecomment-349144593,1,['depend'],['dependencies']
Integrability,"@samuelklee David Roazen wants to hold off on merging for a few weeks while James wraps up something. After that, I will need to merge this PR before implementing some DRAGEN features.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1438960730:82,wrap,wraps,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1438960730,1,['wrap'],['wraps']
Integrability,"@samuelklee For each of the 3 tools, I would pick an existing, straightforward integration test, make a copy, shrink the interval way down, modify the command line to set all of the SW parameters to custom values, and check in new expected outputs. The goal is just to prove that the new arguments don't explode and have some actual effect on the output, so we don't need anything fancy.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-896317184:79,integrat,integration,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885#issuecomment-896317184,1,['integrat'],['integration']
Integrability,@samuelklee From ~10 minutes of reading code it looks like the functionality is the same. It's been a while but I suspect we created the GATK tool to get rid of a Picard jar dependency.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5392#issuecomment-435634712:174,depend,dependency,174,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5392#issuecomment-435634712,1,['depend'],['dependency']
Integrability,@samuelklee Hold on - just saw the last message. Let me try using your .yml.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4061#issuecomment-355649022:40,message,message,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4061#issuecomment-355649022,1,['message'],['message']
Integrability,"@samuelklee I bet you were right about Jonathan's latest fix, but the error message did still need a little polish.; Good to go?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6076#issuecomment-518660214:76,message,message,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6076#issuecomment-518660214,1,['message'],['message']
Integrability,"@samuelklee I think the issue may be that we currently run integration tests on both Java 8 on the docker and on Java 11 on CI (though I'm not 100% sure that these specific tests run on both). I was able to update the expected results on the Java 17 branch, but that branch only runs on one version of Java. So updating the expected results may just move the problem to Java 8. Not sure.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8107#issuecomment-1330948150:59,integrat,integration,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8107#issuecomment-1330948150,1,['integrat'],['integration']
Integrability,"@samuelklee I will build the docker and run the warp tests, but if we do this again I'm going to teach you to fish. Wasn't there a VariantRecalibrator integration test that had some sort of random seed hijinx? Hopefully your fix should mean we don't need any shenanigans anymore -- can you see if there are any other tests we can clean up?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7709#issuecomment-1061820382:151,integrat,integration,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7709#issuecomment-1061820382,1,['integrat'],['integration']
Integrability,@samuelklee I'd like to keep `RobustBrentSolver` and `SynchronizedUnivariateSolver` + their dependencies. Everything else (ICG and linear operator) can go.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4181#issuecomment-358451918:54,Synchroniz,SynchronizedUnivariateSolver,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4181#issuecomment-358451918,2,"['Synchroniz', 'depend']","['SynchronizedUnivariateSolver', 'dependencies']"
Integrability,@samuelklee I'm not sure we need to hold up #4061 for the osx issue - those dependencies were introduced in #3925 and are already in master. I don't think #4061 makes them any worse.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4064#issuecomment-355670255:76,depend,dependencies,76,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4064#issuecomment-355670255,1,['depend'],['dependencies']
Integrability,@samuelklee I've reworded the hack message,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3408#issuecomment-322550439:35,message,message,35,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3408#issuecomment-322550439,1,['message'],['message']
Integrability,"@samuelklee I've worked through all of the issues with the other repos (Barclay, picard, etc.), so we're ready to move forward with Java 17 reviews, but the `ModelSegments` tests are still inconsistent. This branch has updated `ModelSegments` expected result files that were produced locally with Java 17 (based on our discussion from some months ago), but now the same tests still fail on the docker. They succeed when run locally or in the CI non-docker job. At one point when I looked into these, the values produced when the tests fail look similar(/identical ?) to the values that the tests USED to produce (i.e., I suspect if we reverted expected results files, the tests might succeed on the docker and fail on the non-docker). I'm not sure what is causing the instability, but this is going to become a blocking issue for this in the next couple of weeks. We also have the option of disabling them only on the docker (or non-docker), but I hate to do that. Can you take a look at this in the next week or so ?. There is also one WDL test (`CNVSomaticPanelWorkflow.CreateReadCountPanelOfNormals`) that fails pretty consistently - I suspect this is a resource/memory issue since it sometimes returns exit code 134. The default CI machines are pitiful things, 7GB IIRC. The other test failures (doc and wdl gen) can be ignored for now - they require code that is on another branch that is dependent on a new Barclay version.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1402764136:1394,depend,dependent,1394,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1402764136,1,['depend'],['dependent']
Integrability,"@samuelklee Is it possible to expand the error message a bit so that users get something actionable. For example, ""Does the interval list match what was covered in the bam file? Does this bam have coverage in all intervals?""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-365706839:47,message,message,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-365706839,1,['message'],['message']
Integrability,@samuelklee Is it something in our code or in the hdf5 java or native code that we wrap? What's the error?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3763#issuecomment-340795352:83,wrap,wrap,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3763#issuecomment-340795352,1,['wrap'],['wrap']
Integrability,"@samuelklee OK it is not a cromwell issue -- after your commit, the somatic denoising integration tests are failing locally too:; ```java.lang.IllegalArgumentException: Sample intervals must be identical to the original intervals used to build the panel of normals.```. I wouldn't worry about it now. It is most likely related to test resource files.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-350195448:86,integrat,integration,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-350195448,1,['integrat'],['integration']
Integrability,@samuelklee Should we make some tickets to update the wrapper?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-318184455:54,wrap,wrapper,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-318184455,1,['wrap'],['wrapper']
Integrability,"@samuelklee The module can now save and load everything, including the state of the optimizer. This allows to making interesting inference pipelines. Here's a decent strategy for obtaining the global optimum (it works flawlessly on simulated data every time):. - In the first pass, one disables annealing and obtains the variational parameters in a thermal state. The temperature needs to be _high enough_ to allow most/all local minima to merge, though, not too high to allow copy numbers to travel too far away from baseline copy numbers. If this occurs, one must anneal very slowly in the next stage (see below). The results are checkpointed once converged. - In the second pass, one makes another call to the CLI tool, this time w/ annealing enabled (starting from the same temperature) and starting from the checkpointed thermal results (model params, posteriors, adam(ax) state). The annealing rate must be slow enough to prevent thermal fluctuations from getting quenched (i.e. the evolution must be quasi-isothermal). One must look for a steady and linear rise of ELBO, such that when the annealing protocol ends, SNR quickly drops to values below 1. In both runs, the learning rate must be very small (in the rate 0.01-0.05) such that we wouldn't have to worry about controlling stochastic noise. Adam(ax) quickly adjusts its moment estimates and compensates for the small learning rate, so this doesn't increase the training time significantly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-347369020:1107,protocol,protocol,1107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-347369020,2,['protocol'],['protocol']
Integrability,@samuelklee Why can't we right integer matrices? Is that a missing feature in the hdf5 wrapper we built or is it fundamental to hdf5?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-317545909:87,wrap,wrapper,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-317545909,1,['wrap'],['wrapper']
Integrability,"@samuelklee gCNV integration tests and WDL tests pass locally. There are a number of issues:; - Somatic WDL tests fail on travis, and haven't tried them locally. Those tests were failing before I made changes -- it's unlikely to be related to my changes. Could you please take a look?; - Germline WDL tests are extremely slow on travis, perhaps there is no g++ and it is using python fallback? I don't know how to see the cromwell log files on travis. @lbergelson any pro tips?; - Python-related integration tests all fail on travis (though not locally w/ a properly setup python environment).; - I noticed that the python env in `Dockerfile` is based on `Miniconda2`. We strictly require Python 3 for gCNV.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-350158363:17,integrat,integration,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-350158363,2,['integrat'],['integration']
Integrability,"@samuelklee this is fantastic!. 1. @cmnbroad any ideas about the absence of log messages from python? by default, the logger writes to `sys.stderr`. Perhaps I should set it to `sys.stdout`?. 2. I think it makes sense to move python packages and scripts (or at least, the scripts) to src/main/resources.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-345774324:80,message,messages,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-345774324,1,['message'],['messages']
Integrability,"@samuelklee, that is very hackish indeed, and very reference version/species dependent. Tools should not discard hard-wired contig names or intervals like that but rather the user must provide the appropriate -L or -XL list. A half-way possibility here is to provide a default set of excluded chromosomes depending on what reference is being used which must be verified on run-time as supposed to make the assumption is the one/ones the developer cared about at the time of writing the code. . Lack of a reference version/species match, lack of explicity -L or -XL lists and lack of non-autosome exclusing flag in the argument list should result in a warning message or perhaps even an error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317819766:77,depend,dependent,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317819766,3,"['depend', 'message']","['dependent', 'depending', 'message']"
Integrability,"@samuelklee: @LeeTL1220 and I just had a discussion about the writer aspect of this branch, and we agreed on the following:. 1. Lee will introduce a new header type to encapsulate the information that's currently passed in individually to the `writeHeader()` method in `AnnotatedIntervalWriter`. This makes the interface cleaner and more future-proof, since the signature will just become `writeHeader(AnnotatedIntervalHeader)`. 2. Lee will start writing out 3 additional structured header lines (as comment lines) to every header, declaring the names of the chrom, start, and stop columns. These will not be respected on input yet (he will still be relying on a config file to get the names of these 3 columns), but it's the first step in the direction of storing all necessary schema information in the header of each file, rather than separately from each file. 3. Lee will file a github issue to eventually use these 3 header lines on input, when they are present, to get the names of the chrom/start/stop columns (possibly still with a fallback to a separate config file if they aren't, but that is a point we can debate in a future PR).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4276#issuecomment-369709447:311,interface,interface,311,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4276#issuecomment-369709447,1,['interface'],['interface']
Integrability,"@shuaiwang2 Hi, we don't currently support indexes that long. We use a bai index for bams and tabix for vcf which only support up to 512 M. You need to use a CSI index for references that large but we don't support writing those. (Reading them is weird, I think we can read BAM csi indexes but not VCF ones). . It might be possible to work around this issue by setting `--create-output-variant-index false`, although downstream gatk tools would need an index if you're sharding them. Otherwise I recommend splitting your chromosomes into two separate parts and calling on the split chromosomes. Splitting along a long region of N's should be a safe way to avoid missing any useful calls. (The telemere might be a good spot unless you have a T2T reference.). . We should probably improve that error message to make it clear what the problem is.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8192#issuecomment-1422828609:798,message,message,798,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8192#issuecomment-1422828609,2,['message'],['message']
Integrability,"@sooheelee . Here is my command:. ```; singularity exec gatk.simg test.pbs; ```; Here is test.pbs:. ```; gatk DetermineGermlineContigPloidy \; -L filtered.interval_list \; --input A1.count.hdf5 --input A2.count.hdf5 \; --contig-ploidy-priors contig_ploidy_priors_homo_sapiens.tsv \; --interval-merging-rule OVERLAPPING_ONLY \; --output out \; --output-prefix exomeseq \; --verbosity DEBUG \; --mean-bias-standard-deviation 0.01 \; --mapping-error-rate 0.01 \; --global-psi-scale 0.001 \; --sample-psi-scale 0.0001; ```. Here is the error message and I think the python environment has been activated by Singularity. The task failed when it tried to create directory of '/root/.theano'. ```; 17:03:28.891 INFO DetermineGermlineContigPloidy - Initializing engine; 17:03:28.896 DEBUG ScriptExecutor - Executing:; 17:03:28.896 DEBUG ScriptExecutor - python; 17:03:28.896 DEBUG ScriptExecutor - -c; 17:03:28.896 DEBUG ScriptExecutor - import gcnvkernel. Traceback (most recent call last):; File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/theano/configdefaults.py"", line 1738, in filter_compiledir; os.makedirs(path, 0o770) # read-write-execute for user and group; File ""/opt/miniconda/envs/gatk/lib/python3.6/os.py"", line 210, in makedirs; makedirs(head, mode, exist_ok); File ""/opt/miniconda/envs/gatk/lib/python3.6/os.py"", line 220, in makedirs; mkdir(name, mode); PermissionError: [Errno 13] Permission denied: '/root/.theano'; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-433477833:538,message,message,538,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4782#issuecomment-433477833,1,['message'],['message']
Integrability,"@sooheelee I am not sure that modifying the Dockerfile is the way to go. Especially since our list is a lot shorter than GotC. For most users, the GATK version is all that is important. Everything else is derived from that. We've removed our WDL usage of `samtools` and soon GATK will wrap `picard` and again the version of picard being wrapped will be 1:1 to the version of GATK. . If we do modify it, we would just be putting a label in the dockerfile that has the GATK version. But it would be no more informative than the tag in the `docker images` command.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3645#issuecomment-333544918:285,wrap,wrap,285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3645#issuecomment-333544918,2,['wrap'],"['wrap', 'wrapped']"
Integrability,@sooheelee I do agree. USers cannot be expected to do this. @lbergelson @droazen Any ideas how best to address this? Tell me if you need more details. This ties into Picard integration.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306528306:173,integrat,integration,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306528306,1,['integrat'],['integration']
Integrability,"@sooheelee I think we should be able to hit Jan 9 for what I've been calling the ""ModelSegments"" pipeline, in terms of getting the new code merged into master. It will be ready to go for WGS. However, it's hard to say whether or not we'll have completed internal evaluations of this pipeline by then. These will be necessary to identify good default values for parameters that will affect sensitivity. @LeeTL1220 and @katevoss are helping out here. @MartonKN is also beginning work on an improved caller, which could potentially replace the current one before release. As for gCNV, @asmirnov239 and I will be helping @mbabadi get the python version wrapped in Java. We should be able to get at least cohort-calling mode in by release. Case calling can come shortly after if we don't manage to get it in as well. Here, we are relying a bit more on external groups to run evaluations and provide feedback, but we will do what internal evaluations we can before release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3769#issuecomment-341271339:649,wrap,wrapped,649,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3769#issuecomment-341271339,2,['wrap'],['wrapped']
Integrability,"@sooheelee Is the input ""8_mutect2.vcf.gz"" file that you used above the same one that David sent me today ? If so, the second error above (the ""Features added out of order..."") that happens when the output is a .gz, is a legitimate error. That input file was not sorted (even though it had a companion .tbi index file, which I suspect is not it's actual companion), so the output tabix index can't be created. You can try adding `--createOutputVariantIndex false` to the command line and see if that eliminates the error message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306668026:521,message,message,521,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306668026,1,['message'],['message']
Integrability,"@sooheelee It's a mix of single and double, depending on the algorithm. This will determine the number of significant digits. A good explanation of single and double precision is [here](https://en.wikipedia.org/wiki/Floating-point_arithmetic#IEEE_754:_floating_point_in_modern_computers).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2756#issuecomment-304045430:44,depend,depending,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2756#issuecomment-304045430,1,['depend'],['depending']
Integrability,"@sooheelee Not everything listed above should get a DocumentedFeature tag. For example, Annotation is a base interface; AnnotationUtils are utilities; RankSumTest is a base class for other rank sum-based annotations (none of these should be tagged). There may be others. In general, things that are interfaces, abstract classes, or utility classes should probably be skipped. If in doubt, feel free to ask...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-344417769:109,interface,interface,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3809#issuecomment-344417769,2,['interface'],"['interface', 'interfaces']"
Integrability,"@sooheelee Note that for many users, `./gatk` will work, while just `gatk` will not. It depends on the PATH setup in their shell.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3911#issuecomment-350384348:88,depend,depends,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3911#issuecomment-350384348,1,['depend'],['depends']
Integrability,@sooheelee That error message occurs after the tool has done all the hard work and ju isst has to emit the `VariantContext`s to a file. It seems like the inputs are out of order. Could you check two things: 1) is the input vcf ordered? and 2) are you outputting a vcf or a vcf.gz? I'm curious if the error occurs for both.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306381135:22,message,message,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306381135,1,['message'],['message']
Integrability,"@sooheelee Was not my call to implement the parser that way. Hence, to support both would require a big hack that we would throw away later, anyway. . Possible that FBOB is using the dependency wrong for writing out bgz VCF. But it seems to be doing it in a pretty standard way. I'm just going to have to ask @droazen and @lbergelson on that one.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306535543:183,depend,dependency,183,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306535543,1,['depend'],['dependency']
Integrability,@sooheelee can you share that input file with Katie so she can add the het-non-ref case to the integration tests?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5129#issuecomment-417312492:95,integrat,integration,95,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5129#issuecomment-417312492,1,['integrat'],['integration']
Integrability,"@sooheelee, the computation engine `gcnvkernel` produces a lot of informative messages, however, they are not shown unless you run GATK with `--verbosity DEBUG`. I have filed an issue about it: #4629. @cmnbroad could you please take a look at the issue?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4826#issuecomment-393224962:78,message,messages,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4826#issuecomment-393224962,1,['message'],['messages']
Integrability,@stefandiederich There is a conda environment .yml file called gatkcondaenv.yml that is included with the distribution. It will establish the correct version of Python and other dependencies that are required for the CNV tools. You can find more detail about how to set this up [here](https://github.com/broadinstitute/gatk#requirements) (see the 3rd bullet point under Optional).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357012782:178,depend,dependencies,178,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357012782,1,['depend'],['dependencies']
Integrability,"@stefandiederich, I think this is a problem with how your BED file is being interpreted. In general, with GATK, it's best to use 1-based coordinates intervals, e.g. that of a [Picard-style interval_list](https://gatkforums.broadinstitute.org/gatk/discussion/1319/collected-faqs-about-interval-lists). BED is 0-based. See https://www.biostars.org/p/84686/ for a clear illustration of the differences. . If provided a BED file, i.e. an intervals list with `.bed` extension, GATK will convert it to the expected 1-based format. So, if `chr2 29430911 29430911` is 0-based BED, then conversion to 1-based would yield `chr2 29430912 29430911`, making the stop less than the start as the error message says. . It seems though that your intervals are actually already 1-based, not 0-based (which the BED format implies). Make sure your coordinates are expected and try changing the file extension.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4504#issuecomment-371144113:687,message,message,687,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4504#issuecomment-371144113,2,['message'],['message']
Integrability,"@t-ogasawara @frank-y-liu @gspowley @paolonarvaez @droazen @lbergelson please comment on the following proposal. The proposal is that we would spin off native PairHMM as a separate project/repo on github and host AVX code there and have alternative implementations extend that project/repo (by creating repos that depend on the AVX one). . In other words, now we have 1 repo, broadinstitute/gatk. After the proposed change we'll have 3 repos (all BSD licensed):; 1) broadinstitute/gatk; 2) broadinstitute/nativePairHMM-AVX; 2) broadinstitute/nativePairHMM-PPC. We will duplicate the native code (AVX and PPC will be separate copies of C++ files etc) to simplify the testing burden. The parties interested in working on a specific architecture will contribute code directly to the respective architecture-specific repo and gatk will take occasional updates of those repos. The gatk repo will depend on the other two. The PPC repo will depend on the AVX repo (and any other native repos will depend on the AVX one). The avx and ppc repos will have their own build systems and unit tests against the new interface. The AVX repo will expose something like the following Java API (to be worked out in detail). ```; //Used to copy references to byteArrays to JNI from reads; public final class JNIReadDataHolderClass {; public byte[] readBases = null;; public byte[] readQuals = null;; public byte[] insertionGOP = null;; public byte[] deletionGOP = null;; public byte[] overallGCP = null;; }. //Used to copy references to byteArrays to JNI from haplotypes; public final class JNIHaplotypeDataHolderClass {; public byte[] haplotypeBases = null;; }. public interface NativePairHMMKernel extends AutoCloseable { . /**; * Function to initialize the fields of JNIReadDataHolderClass and JNIHaplotypeDataHolderClass from JVM.; * C++ code gets FieldIDs for these classes once and re-uses these IDs for the remainder of the program. Field IDs do not; * change per JVM session; *; * @param readDataHolderClass class",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-214914864:314,depend,depend,314,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1748#issuecomment-214914864,4,['depend'],['depend']
Integrability,@tfenne @gubrins @pkaleta @aushev We've opened a PR to improve these log messages here: https://github.com/broadinstitute/gatk/pull/6891,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5912#issuecomment-709475596:73,message,messages,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5912#issuecomment-709475596,1,['message'],['messages']
Integrability,"@tfenne Well, `GenomicsDBImport` is starting to replace `CombineGVCFs` for some of our userbase as well, so I'm not sure we can assume users of that tool are necessarily more advanced than average... It should be possible to patch `GenomicsDBImport` to throw a `UserException` whenever it encounters a MNP, if @ldgauthier agrees that that's the right thing to do here. That tool creates a map of `FeatureReaders` up front for its inputs and passes them to GenomicsDB. We could pretty easily wrap the existing FeatureReaders within a custom FeatureReader implementation that throws whenever it sees a MNP (or returns an iterator of VariantContexts that throws).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5182#issuecomment-421410100:491,wrap,wrap,491,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5182#issuecomment-421410100,1,['wrap'],['wrap']
Integrability,@tomwhite @cwhelan Should we update our spark dependencies to 2.3.0 then?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5125#issuecomment-417706567:46,depend,dependencies,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5125#issuecomment-417706567,1,['depend'],['dependencies']
Integrability,"@tomwhite @jean-philippe-martin is going to look into the possibility of a gcloud release this week to unblock this PR. If we can't get a release this week, we can look at depending on a custom snapshot temporarily.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2220#issuecomment-255816154:172,depend,depending,172,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2220#issuecomment-255816154,1,['depend'],['depending']
Integrability,"@tomwhite After spending some time searching for this feature for my testing purposes, it would be helpful to expose the NIO adapter toggle directly from the command line in this branch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5138#issuecomment-418494235:125,adapter,adapter,125,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5138#issuecomment-418494235,1,['adapter'],['adapter']
Integrability,"@tomwhite Ignore my previous message, sorry -- I see that you commented above that you tested https://github.com/broadinstitute/gatk/pull/4314 and it had no effect. I've opened https://github.com/broadinstitute/gatk/pull/4428 to revert the ADAM upgrade for now until we understand the underlying cause of the performance regression. @fnothaft It seems to me that the serializer registrations in ADAM could in theory affect the GATK, since we both register serializers for core classes in htsjdk. It seems worth investigating as a possibility, at least, as it's the only candidate mentioned so far that seems to have the potential to cause such a massive performance difference.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367069808:29,message,message,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367069808,1,['message'],['message']
Integrability,"@tomwhite To clarify, I think that the caller of `ensureCapacity()`, namely `GenotypeLikelihoodCalculators.calculateGenotypeCountUsingTables()`, also needs to be synchronized in order to avoid some unlikely but still-possible races. Given this, I think that we should consider whether `ThreadLocal` might be a better option here. It's not 100% clear to me whether a `ThreadLocal` `get()` call is cheaper than a synchronized method call, but some casual googling suggests that it might be. If we're going to end up entering a synchronized method on every single call to `GenotypeLikelihoodCalculators.getInstance()`, we might want to do some research into whether `ThreadLocal` + no synchronization would be faster, since I believe that this is a performance-sensitive section of code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5071#issuecomment-422171244:162,synchroniz,synchronized,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5071#issuecomment-422171244,8,['synchroniz'],"['synchronization', 'synchronized']"
Integrability,"@tomwhite We just sat down and had a look at this class. @droazen was suggesting that this might still be unsafe, and that the outer layer where we compute the genotype likelihood should either be synchronized as well or the whole thing should be wrapped in a thread local object",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5071#issuecomment-422154723:197,synchroniz,synchronized,197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5071#issuecomment-422154723,2,"['synchroniz', 'wrap']","['synchronized', 'wrapped']"
Integrability,"@tomwhite What if we created a special, shaded version of Hadoop just for the MiniCluster, and used it as a test dependency in GATK? Or perhaps we could start the MiniCluster using the command line client instead of directly from GATK? Could either of those approaches work? . Tagging @lbergelson as well for an opinion.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-494410699:113,depend,dependency,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-494410699,1,['depend'],['dependency']
Integrability,"@tovanadler Review complete. Looks good, just a few comments. I have a few comments about the organization of duplicate marking. I think you've inherited some very old style code that could maybe use some refactoring. I think we do need to also include the histogram and the metrics headers. Those could be done in a separate ticket though. I'm a bit worried that the test is indeterministic. Unless I overlooked something which is likely, it seems like it might depend on the ordering of a PCollection which is undefined. This isn't problematic for the actual metric file, but might be for the tests. What do you think about reorganizing to output an annotation on only 1 of the ""best"" reads with the count of all optical duplicates in it's group. That would simplify the code, and since we only care about the global count it wouldn't change the information content.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/749#issuecomment-126762958:463,depend,depend,463,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/749#issuecomment-126762958,1,['depend'],['depend']
Integrability,@tushu1232 Could you include your command line that you used to launch gatk? Are you using the `gatk-launch` wrapper?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-265467552:109,wrap,wrapper,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-265467552,1,['wrap'],['wrapper']
Integrability,"@uros-sipetic The comparator depends on the ordering of the chromosomes imposed by the sequence dictionary in the header, so unfortunately this is not a check that can be relaxed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6855#issuecomment-716740690:29,depend,depends,29,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6855#issuecomment-716740690,1,['depend'],['depends']
Integrability,"@vdauwera @sooheelee I just noticed a [PR](https://github.com/broadinstitute/gatk/pull/3917/files) that has a command line usage example embedded in the ""usageExample"" field of the CommandLineProgramProperties annotation. I'm not sure if this was part of the SOP (I didn't see it mentioned), but that field is [not integrated](https://github.com/broadinstitute/barclay/issues/10) into either doc or command line help output, and should probably not be used. I didn't want to blast anything out without first mentioning it to you though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349427729:315,integrat,integrated,315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349427729,1,['integrat'],['integrated']
Integrability,@vdauwera Added the informative message for an empty recal file.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2431#issuecomment-283433902:32,message,message,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2431#issuecomment-283433902,1,['message'],['message']
Integrability,"@vdauwera Have to disagree -- the wiki on github is not versioned, and we definitely want this README to be versioned, since we distribute it with the binary release (there's VERY little that is not version-dependent). We also care a lot about being able to search through the README efficiently. I think having a table of contents makes the README a bit less intimidating :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3158#issuecomment-310760238:207,depend,dependent,207,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3158#issuecomment-310760238,1,['depend'],['dependent']
Integrability,"@vdauwera The tools are categorized and listed in the Google Spreadsheet above. It is waiting for you to assign tech leads to tools for documentation. One thing that @chandrans brought to my attention is that for BaseRecalibrator one of the parameters (`-bqsr`) actually causes an error. One can no longer generate the 2nd recalibration table with correction on the fly and instead must use the recalibrated BAM through BaseRecalibrator to generate the 2nd recal table for plotting. **This type of information is missing from the tool docs.** Furthermore, updates I made to the BQSR slidedeck (that showcase this `-bqsr` parameter) are based on information from a developer and this information turns out to be incorrect now (perhaps correct at some point in development?). Soooo, I think it may be prudent that those responsible for tool docs test the commands on data. - [4] Make sure the doc content enables Best Practices, e.g. plotting BQSR recalibration, and ; - [5] Test example commands to ensure they work. If they do not, make corrections and notate the change in application in the documentation.; - [6] Remember @vdauwera's plan to change the representation of parameters from camel to KEBAB case. Issue is <https://github.com/broadinstitute/gatk/issues/2596>. Geraldine would like your help to do this for the tools you are responsible for. Remember to change the integration tests too. . ### What the gatkDocs look like as of commit of `Mon Nov 20 17:30:46 2017 -0500` where we upgraded htsjdk to 2.13.1: . # [gatkdoc.zip](https://github.com/broadinstitute/gatk/files/1492593/gatkdoc.zip). Download and load the `index.html` into a web browser to click through the docs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346060583:1377,integrat,integration,1377,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346060583,1,['integrat'],['integration']
Integrability,"@vdauwera There are some tools that have very specific requirements with regards to `-Xmx`, however. For example, `GenomicsDBImport` requires that you size your `-Xmx` value significantly **smaller** than the total amount of free memory on the machine, in order to leave enough room for the native heap. If you don't do this, you will get truly horrific and cryptic messages when the native code crashes with out-of-memory. This is really something that needs to be documented prominently!. I'd advocate for selective inclusion of recommended `-Xmx` values in the docs, for cases like the above where it really matters.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3137#issuecomment-319384386:366,message,messages,366,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3137#issuecomment-319384386,1,['message'],['messages']
Integrability,"@vilay-nference Thank you for doing this work. It's nitpicky annoying stuff to figure out.; ; I have one additional request. Instead of addding additional direct implementation dependencies, could we specify the transtive version requirements in a [gradle constraints block](https://docs.gradle.org/current/userguide/dependency_constraints.html)? . That will: ; 1. make it clear that we don't rely on these directly; 2. prevent us from keeping them around if we do something like remove hadoop in the future; 3. lets us rewrite those force blocks to instead define minimum versions so if the libraries move forward in the future we're not accidentally holding on a to an old version",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8950#issuecomment-2297074810:177,depend,dependencies,177,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8950#issuecomment-2297074810,2,['depend'],['dependencies']
Integrability,@vilay-nference Thank you for your pull request. I've incorporated your suggestions and closed out many vulnerabilities from our transitive dependencies. Hadoop/spark have finally stopped incorporating log4j1 so that one is closed out for good. . I've also rebuilt our base docker to incorporate recent patches from ubuntu. We've implemented some additional security scanning into our build process which will help keep us more up to date going forward.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-2432287402:140,depend,dependencies,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-2432287402,1,['depend'],['dependencies']
Integrability,"@vilay-nference Were you able to get this configuration to pass tests on your end? I've attempted to incorporate your changes into https://github.com/broadinstitute/gatk/pull/8998, but I'm running into issues with hadoop and protobuf incompatibilities. I see the same problem with your branch when I try to run tests on it. (I also can't run tests without disabling -Werror on your branch since there are still some unresolved deprecation and other minor issues). Errors look like this:. ```; Caused by: java.lang.ExceptionInInitializerError: Exception java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.security.proto.SecurityProtos [in thread ""IPC Server handler 1 on default port 64812""]; 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos.<clinit>(ClientNamenodeProtocolProtos.java); ```. and you can easily trigger one by running `ParallelCopyGCSDirectoryIntoHDFSSparkIntegrationTest`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8950#issuecomment-2412827680:745,protocol,protocol,745,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8950#issuecomment-2412827680,1,['protocol'],['protocol']
Integrability,"@vilay-nference You are always very welcome to submit a pull request on github with any proposed changes to GATK!. Most of the remaining vulnerabilities are in dependencies-of-dependencies which can be difficult to update, but we are slowly chipping away at them. For example, log4j 1.x is a dependency of the latest release of Apache Spark 3.x, and 4.x is still in preview (and note again that the log4j 1.x vulnerabilities are not the same as the infamous and very serious vulnerability that affected log4j 2.x some years ago). We don't believe that any of the remaining library vulnerabilities pose a real-world threat to GATK in practice, but it would still be good to eliminate them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-2223132298:160,depend,dependencies-of-dependencies,160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8215#issuecomment-2223132298,2,['depend'],"['dependencies-of-dependencies', 'dependency']"
Integrability,"@vruano @mwalker174 Any estimates on cost that could help determine the priority of issue 1? Specifically, is the disk cost required to localize the entire count file for all samples a determining factor? If we can drastically reduce this cost, then we can dedicate more to increasing resolution, etc. Here is a minimal set of fixes that could enable the querying of intervals for GermlineCNVCaller (and also for DetermineGermlineContigPloidy without too much extra work, since we also subset intervals there) *only in the gCNV WGS pipeline*, without disrupting other interfaces:. 1) Write a Tribble SimpleCountCodec for the `counts.tsv` extension. I've already done this in a branch.; 2) Change GermlineCNVCaller and DetermineGermlineContigPloidy tools to accept paths.; 3) If an index is present for each count path, create a FeatureDataSource, merge the requested -L/-XL intervals, and query to perform the subset. We will also need to stream the SAM header metadata. It should not require much code to extract all this to a temporary IndexedSimpleCountCollection class. (Caveat: for now, this will work with the current gCNV convention of providing bins via -L/-XL. Technically, it will also work with the more conventional use of -L/-XL to denote contiguous regions, but we may have to perform checks that bins are not duplicated in adjacent shards if they overlap both, since querying a FeatureDataSource will return any bins that overlap the interval---rather than only those that are completely contained within it.); 4) Index read-count TSVs in the gCNV WGS pipeline after collection and modify the DetermineGermlineContigPloidy and GermlineCNVCaller tasks to take read-count paths and indices, if necessary. These changes could be confined in the gCNV WGS WDL for now. I think that should do the trick. If this is high priority, I can implement now. In the future, we might be able to promote all Locatable CNV Records to Features and write code to automatically pass the columns/encoders/de",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082:568,interface,interfaces,568,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082,1,['interface'],['interfaces']
Integrability,"@vruano Sorry for the delay on this branch! I am away this week, but had time this morning to do a quick initial pass over your engine-related changes here. I have some concerns about your additions to the `GATKRead` interface in particular -- we should discuss how best to accomplish your goals there without making the interface confusing or incoherent.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2607#issuecomment-302106816:217,interface,interface,217,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2607#issuecomment-302106816,2,['interface'],['interface']
Integrability,"@wujh2017 Did you set up the appropriate conda environment as described in the README?. > Python 3.6.2, along with a set of additional Python packages, are required to run some tools and workflows. GATK uses the Conda package manager to establish and manage the environment and dependencies required by these tools. The GATK Docker image comes with this environment pre-configured. In order to establish an environment suitable to run these tools outside of the Docker image, the conda gatkcondaenv.yml file is provided. To establish the conda environment locally, Conda must first be installed. Then, create the gatk environment by running the command conda env create -n gatk -f gatkcondaenv.yml (developers should run ./gradlew createPythonPackageArchive, followed by conda env create -n gatk -f scripts/gatkcondaenv.yml from within the root of the repository clone). To activate the environment once it has been created, run the command source activate gatk. See the Conda documentation for additional information about using and managing Conda environments.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4389#issuecomment-364748538:278,depend,dependencies,278,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4389#issuecomment-364748538,1,['depend'],['dependencies']
Integrability,"@yfarjoun I pushed a commit to this branch that fixes the truncation issue flagged above, adds unit tests for the new argument collection, and adds integration tests to cover the new -O argument for all affected tools. This can be merged once tests pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7072#issuecomment-777074618:148,integrat,integration,148,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7072#issuecomment-777074618,1,['integrat'],['integration']
Integrability,"@yfarjoun Right, the intention of this ticket was to implement the codec in htsjdk, then add a GATK integration test proving that we can now access interval_list files as tribble features.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5788#issuecomment-472566997:100,integrat,integration,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5788#issuecomment-472566997,1,['integrat'],['integration']
Integrability,"@yurivict Unfortunately we only support the version of gradle bundled with the GATK repo, which is currently version `7.3.2`. We're happy to consider a PR to update us to a newer gradle, however (just need to modify the version in `gradle-wrapper.properties`). We also don't currently support Java 17, though we have an open work-in-progress PR to update us to it, which we expect to get merged within the next month or so: https://github.com/broadinstitute/gatk/pull/8013",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7984#issuecomment-1251454881:239,wrap,wrapper,239,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7984#issuecomment-1251454881,1,['wrap'],['wrapper']
Integrability,A bit of further information. The conda forge maintainers actually noticed that this was problematic and pushed a patched version of the recipe with corrected version bounds. I'm not sure why we're still resolving the old incorrect version. . I'm in favor of pinning the exact dependencies to prevent this problem. We can always unpin and test periodically.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7800#issuecomment-1105425883:277,depend,dependencies,277,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7800#issuecomment-1105425883,1,['depend'],['dependencies']
Integrability,A check:; Can you clone https://github.com/kgururaj/TestGenomicsDBJar ?; ```; export GENOMICSDB_VERSION=0.8.1-proto-3.0.0-beta-1+uuid-static; curl -O http://repo1.maven.org/maven2/com/intel/genomicsdb/${GENOMICSDB_VERSION}/genomicsdb-${GENOMICSDB_VERSION}-jar-with-dependencies.jar; bash -x TestGenomicsDBJar/run_checks.sh; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356988842:265,depend,dependencies,265,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356988842,1,['depend'],['dependencies']
Integrability,"A couple of high-level things to start:. - I think the main short-term issue is getting some tests with inout/output files, and a test strategy, both for Python unit testing and for GATK integration testing. @mbabadi Do you have any tests for exercise this functionality ?; - We're probably going to want to standardize on a way to integrate tool logging (both the level and the stream) with Python logging. Since the stdout/stderr streams of the Python process will be redirected back to GATK via anonymous pipes, we need to ensure that verbose logging doesn’t block Python, which will happen when the buffering capability of the pipe is exceeded.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-344927793:187,integrat,integration,187,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-344927793,2,['integrat'],"['integrate', 'integration']"
Integrability,"A couple of thoughts after doing a little more reading on this. Depending on the source it would appear that each arena will allocate either 64MB or 128MB of virtual memory (i.e. address space). So it would probably also be fine to set this limit a bit higher. Secondly, while there's lots of discussion online that setting this doesn't negatively impact Java code running on the JVM, it is possible that native code invoked using JNI could see a modest reduction in performance _if_ a) it's highly multithreaded and b) it's doing lots of heap allocations. I don't know enough about the native pair-HMM and other native code, but it would be helpful if someone who knows more about that could weigh in.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5849#issuecomment-478574401:64,Depend,Depending,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5849#issuecomment-478574401,1,['Depend'],['Depending']
Integrability,"A few minor issues:. - [x] Change `--resource <blah>` to `--resource:<blah>` in tool-level documentation. EDIT: Added to the sl_lite_overlap branch mentioned below.; - [x] The VCF writer in VariantRecalibrator has a few conditionals to allow for VCF headers without contig lines, we could do the same for the writer in LabeledVariantAnnotationsWalker. EDIT: Added to the sl_lite_overlap branch mentioned below.; - [ ] Double check whether we should worry about any differences in extraction on test data (provided via email) from https://gatk.broadinstitute.org/hc/en-us/community/posts/7974912707099-VariantRecalibrator-IndexOutOfBoundsException. Probably nothing to worry about, and at least the error messaging in the new tools is more informative.; - [x] We could change the strategy for checking for resource overlaps to require allele-level matching (rather than only matching on start position, as was inherited from VQSR). A quick test on malaria shows that this can reduce the number of overlaps by O(10%), but performance doesn't really change too much. Branch is already open at https://github.com/broadinstitute/gatk/tree/sl_lite_overlap; - [ ] Expand the exact-match tests to cover some of these strategies, which were added separately in #8049 and merged to make a release deadline.; - [x] Catch the exception in https://github.com/broadinstitute/gatk/blob/fd782504d18b56dbc266c2b3bb4eb32f21916776/src/main/java/org/broadinstitute/hellbender/tools/walkers/vqsr/scalable/LabeledVariantAnnotationsWalker.java#L389 and throw the same message that is thrown in AS mode. Added in #8074.; - [x] Add message to the score tool that the scores HDF5 file will not be out when the input VCF is empty (such a message is already emitted about the annotations HDF5 file). Added in #8074.; - [ ] Megan suggested in the review of #8074 that dynamic disk sizing could be added to the WDL.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1222787946:1545,message,message,1545,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1222787946,3,['message'],['message']
Integrability,"A few points:; 1. When we wrote the Java interface, the 'agreement' was that the sample names would be unique and consistent within the VCF headers. Hence, the assert statement in the Java code.; 1. Having said that, the sample name in the VCF header is ignored completely if checks are disabled (which are disabled by default). This includes the assert statement and a couple of other checks in the importer code. The sample name is taken from the name to reader map provided in the constructor call. This map is created from the tab delimited file.; 1. Would it be possible to provide a simple test case to replicate the bug? I couldn't replicate it. Here is what I did.; 1. Three VCF files - t0.vcf.gz, t1.vcf.gz, t0_dup.vcf.gz. t0 and t0_dup are identical except for the GT field in one location. So, these 2 files have the same header (same sample name in the header).; 1. Tab file (unique sample names). HG00141 test_inputs/vcf_test_inputs/t0.vcf.gz; HG0155 test_inputs/vcf_test_inputs/t0_dup.vcf.gz; HG00192 test_inputs/vcf_test_inputs/t1.vcf.gz. 1. Import. ./gatk-launch GenomicsDBImport --genomicsDBWorkspace /tmp/ws -L 1:1-1000000 --sampleNameMap test_inputs/gatk4_dup_test_list --batchSize 2; 1. Query prints the output correctly. ./bin/gt_mpi_gather -j test_inputs/query/gatk4-generated.json --produce-Broad-GVCF. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT HG00141 HG00192 HG0155; 1 12144 . G <NON_REF> . . . GT 0/0 . 0/0; 1 12191 . T <NON_REF> . . . GT 0/0 0/0 0/0; 1 17385 . G A,T,<NON_REF> . . . GT 0/1 2/2 1/1. ./gatk-launch SelectVariants -V gendb:///tmp/ws --output t.vcf.gz -R Homo_sapiens_assembly19.fasta; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT HG00141 HG0155 HG0192; 1 12141 . C <NON_REF> . . END=12144 GT:DP:GQ:MIN_DP:PL ./.:2:0:0:0,0,0 ./.:2:0:0:0,0,0 .; 1 12145 . C <NON_REF> . . END=12277 GT:DP:GQ:MIN_DP:PL ./.:2:0:0:0,0,0 ./.:2:0:0:0,0,0 ./.:3:0:0:0,0,0; 1 12278 . C <NON_REF> . . END=12295 GT:DP:GQ:MIN_DP:PL ./.:2:0:0:0,0,0 ./.:2:0:0:0,0,0 .; 1 17385 rs987;d345",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3814#issuecomment-343344853:41,interface,interface,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3814#issuecomment-343344853,2,['interface'],['interface']
Integrability,"A new Hadoop-BAM release is available with the dependent fix in it, so this is ready to go in. Could you have a look please @lbergelson?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4463#issuecomment-383618975:47,depend,dependent,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4463#issuecomment-383618975,1,['depend'],['dependent']
Integrability,"A quick high-level comment: what if the CNV interval is very large? Depending on the algorithm it could be 10s or 100s of kb. I'm worried that that could create a too-large assembly. One possible solution is that we might want to only create evidence intervals around the proposed breakpoints of the interval, based on adding some amount of slop around each breakpoint (since these inputs are from read-depth based CNV callers that won't be able to identify the breakpoint with single-nucleotide precision). It might take some analysis of the input parameters to figure out the right parameters for this type of approach, which we could do in a subsequent task if you want. Another option would be to offload that type of processing into a different tool depending on the CNV caller being used (ie a GenomeSTRipCNVCallPreprocessor or gCNVCallPreprocessor) if we think that the right approach might vary with the algorithm being used.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3542#issuecomment-327489556:68,Depend,Depending,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3542#issuecomment-327489556,2,"['Depend', 'depend']","['Depending', 'depending']"
Integrability,"A quick look at the code results in the following finding:. The error message : `""SA-BWT inconsistency: seq_len is not the same.""` is generated in function `bwt_restore_sa()` defined in `bwt.c`, and resulted in an `abort()` call.; `bwt_restore_sa()` itself was called in `bwa_idx_load_bwt()` defined in `bwa.c`, when trying to restore the suffix array from a file with extension "".sa"". This function call is issued when bwa mem (in its main) tries to load the reference information. This happens before input are read. Because of the `abort()` call, letting the `BwaMem` class handle the error is difficult, so I would propose two possible solutions:; 1. changing the behavior of `BwaIndex` class, so that it eagerly loads the reference, and throws an `Java.lang.IOException` when this error is encountered. Of course this must lead to code duplication, i.e. copying a large part of index loading code from bwa itself and walk around`abort()`ing.; 2. ask @lh3 to change the behavior so that it will not `abort()` any more, but return a null pointer. But the null pointer return error covers so many error cases that this might not be a good idea.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2123#issuecomment-243181189:70,message,message,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2123#issuecomment-243181189,1,['message'],['message']
Integrability,"A similar error message has been reported on the forum [here](https://gatk.broadinstitute.org/hc/en-us/community/posts/360073781912-Error-when-running-HaplotypeCallerSparkinfinite). . GATK Version: 4.1.9.0. The command is: ; ```; gatk# ./gatk HaplotypeCallerSpark -I HG03934.final.bam \; -O HG03934.final.g.vcf \; -R Ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --emit-ref-confidence GVCF \; -- \; --spark-runner LOCAL --spark-master 'local[20]'; ```. And a snippet of the error message: ; ```; 20/10/14 05:29:52 INFO BlockManager: BlockManager stopped; 20/10/14 05:29:52 INFO BlockManagerMaster: BlockManagerMaster stopped; 20/10/14 05:29:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 20/10/14 05:29:52 INFO SparkContext: Successfully stopped SparkContext; 05:29:52.033 INFO HaplotypeCallerSpark - Shutting down engine; [October 14, 2020 5:29:52 AM GMT] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.12 minutes.; Runtime.totalMemory()=2976382976; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.util.DefaultClassResolver.writeName(DefaultClassResolver.java:108); at com.esotericsoftware.kryo.util.DefaultClassResolver.writeClass(DefaultClassResolver.java:99); at com.esotericsoftware.kryo.Kryo.writeClass(Kryo.java:540); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:76); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esoterics",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-709409312:16,message,message,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-709409312,2,['message'],['message']
Integrability,"A user discovered it. I'm assuming they used the log messages. We could write a test that fails with a corrupt SBI index to prove that it breaks, but that seemed a bit convoluted.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6323#issuecomment-567094756:53,message,messages,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6323#issuecomment-567094756,1,['message'],['messages']
Integrability,"A user reported this same issue and the error message does not give any location information in GATK 4.1.9.0 with VariantRecalibrator. ; [Link to the forum post](https://gatk.broadinstitute.org/hc/en-us/community/posts/360074618292-New-version-of-GATK-leads-to-VariantRecalibrator-error-?page=1#community_comment_360013419291).; Here is the message:; ```; Using GATK jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms24g -jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar VariantRecalibrator -V temp/vatiant_germline/sites.only.vcf.gz -O temp/vatiant_germline/recaliberation.indel.vcf --tranches-file temp/vatiant_germline/tranches.indel.txt --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 -an DP -an FS -an MQRankSum -an QD -an ReadPosRankSum -an SOR -mode INDEL --max-gaussians 4 -resource:mills,known=false,training=true,truth=true,prior=12 ~/db/mutect2_support/b37/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.gz -resource:dbsnp,known=true,training=false,truth=false,prior=2 ~/db/mutect2_support/b37/hg19_v0_dbsnp_138.b37.vcf.gz --use-allele-specific-annotations -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ~/db/mutect2_support/b37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz. 14:58:10.389 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Nov 12, 2020 2:58:10 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 14:58:10.555 INFO VariantRecalibrator - --------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6701#issuecomment-726406532:46,message,message,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701#issuecomment-726406532,2,['message'],['message']
Integrability,"A warning message would be helpful, although I doubt most Terra users read their logs unless there's an error. What are the chances this can get addressed in htsjdk?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7732#issuecomment-1074323858:10,message,message,10,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7732#issuecomment-1074323858,1,['message'],['message']
Integrability,ACNV uses Spark MLlib's kernel density estimation to find the posterior mode from MCMC samples. I'm guessing the offending dependency comes from this import statement in `org.apache.spark.mllib.stat.KernelDensity`: `import com.github.fommil.netlib.BLAS.{getInstance => blas}` @lbergelson Any ideas?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3599#issuecomment-331165780:123,depend,dependency,123,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3599#issuecomment-331165780,1,['depend'],['dependency']
Integrability,"ADAM has no header. I realize I'm only coming into the game rather late, but would it be possible to ditch `SAMRecord`? Since you're already using Google `Read`-backed data as well, instead of writing against an interface (`GATKRead`), you could simply come up with your own, more-awesome concrete data structure. (Perhaps even an Avro `SpecificRecord` a la `AlignmentRecord`). In cases where ADAM wants a header back, at the moment it actually runs an aggregation across all the reads to rebuild it. (I'm trying to add a patch that allows you to specify a header, though, because it's breaking a hellbender test for reading/writing parquet.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/900#issuecomment-140990644:212,interface,interface,212,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/900#issuecomment-140990644,1,['interface'],['interface']
Integrability,AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:673); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264); 	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:162); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:143); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:79); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:996); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:541); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:474); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:591); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417:7651,protocol,protocol,7651,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8275#issuecomment-1817434417,1,['protocol'],['protocol']
Integrability,AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127); at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredent,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843:1775,protocol,protocol,1775,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843,4,['protocol'],['protocol']
Integrability,Ack... Does that kill the program or does it run alright after that message?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2618#issuecomment-296895576:68,message,message,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2618#issuecomment-296895576,1,['message'],['message']
Integrability,Actually ACT -> GCA would be useful because they could potentially be in the same codon depending on the reading frame. Is that an easy feature to add?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4650#issuecomment-381171433:88,depend,depending,88,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4650#issuecomment-381171433,1,['depend'],['depending']
Integrability,"Actually, I guess the global random generator is never reset in production code. This is probably fine and will result in overall deterministic behavior, but you can imagine instances in which changing the behavior or order of successive modules that use the generator could lead to debugging headaches. In CNV code (notably, the MCMC/sampling utilities and KernelSegmenter), classes either instantiate or reset private generators when appropriate or their methods take a generator as a parameter. Eliminating the dependence on global state has definitely saved me some headaches during development, but this may be less true when developing methods that don't depend as heavily on randomization. Will leave it up to whoever tackles this issue to decide what is appropriate.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6112#issuecomment-524422286:514,depend,dependence,514,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6112#issuecomment-524422286,2,['depend'],"['depend', 'dependence']"
Integrability,"Actually, I'm going to go ahead and add some exact match tests to guard against this sort of thing. Behavior for key somatic CNV tool modules (i.e., kernel segmentation and MCMC) is unit tested to within statistical noise (so, not exact match) on simulated data, but most integration tests just check for plumbing and not correctness. The idea was always that this sort of thing would be covered by what eventually became CARROT, since such tests would probably have to be long running and require more resources than are available in the repo to be useful. See the high priority but long dormant issues https://github.com/broadinstitute/gatk/issues/4122 and https://github.com/broadinstitute/gatk/issues/4123, as well as https://github.com/broadinstitute/gatk/issues/4630. In fact, I think the original idea was that Lee's validation would be the first to go into CARROT. Note also that I did some work to set up transition of all existing CNV tests (also including the somatic CNV validation against TCGA SNP calls that I put together on Terra) before going on leave and moving off CNVs, but during all that, we managed to 1) lose TCGA access, 2) delete the test files on which Lee based his validation after he left, and 3) reassign at least one of the people that was going to help with the transition. Again, the resulting differences here are minor and it's unlikely that future non-CNV code changes will have similar effects, since the CNV code is relatively well encapsulated, but the exact-match checks will hopefully give us some peace of mind until CARROT tests are ready. @jonn-smith @KevinCLydon looping you in just in case you're not aware of all of this history. Would love to chat about where CARROT is at and where you'd like it to go---feel free to ping me anytime!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7649#issuecomment-1023354175:272,integrat,integration,272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7649#issuecomment-1023354175,1,['integrat'],['integration']
Integrability,"Actually, as far as building with my local GATK, I remembered you can point to local JARs. Is the easiest solution to update my other project to point to the local GATK jar, like so:. dependencies {; implementation files('libs/something_local.jar'); }",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-759148835:184,depend,dependencies,184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-759148835,1,['depend'],['dependencies']
Integrability,"Actually, is the reshape dependency even required for AnalyzeCovariates? If not, we should just remove the import statement from BQSR.R. In any case, we should still add a test to cover plotting. @droazen can you delegate this?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5022#issuecomment-405647323:25,depend,dependency,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5022#issuecomment-405647323,1,['depend'],['dependency']
Integrability,"Added a `PrintReads` based test (`IntelInflaterIntegrationTest.testIntelInflaterDeflaterWithPrintReads`) to test integration of `IntelInflater` and `IntelDeflater`. Removed the previous `IntelInflater` and `IntelDeflater` integration tests, which were basically copies of GKL unit tests. . **Note:** ; The `PrintReads` test is using `CEUTrio.HiSeq.WGS.b37.NA12878.20.21.tiny.md.bam` for input. When using `CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam` for input, we see the exception below when comparing `PrintReads` input and output. **This is true when using `IntelInflater`/`IntelDeflater`, as well as JDK `Inflater`/`Deflater`.** Is this a problem?. ```; htsjdk.samtools.SAMFormatException: SAM validation error: ERROR: Record 9762, Read name 20GAVAAXX100126:7:2:8126:115177, bin field of BAM record does not equal value computed based on alignment start and end, and length of sequence to which read is aligned; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-284551832:113,integrat,integration,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2423#issuecomment-284551832,2,['integrat'],['integration']
Integrability,"Added a few comments of my own -- requested that you refactor to check the index modification time in the `FeatureDataSource` constructors, rather than in the sequence dictionary validation routines.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3063#issuecomment-320948324:190,rout,routines,190,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3063#issuecomment-320948324,1,['rout'],['routines']
Integrability,Added a regression test with two good variants that this PR rescues from being false negatives. Also made the sensitivity thresholds in the other integration tests higher because even without `--genotype-germline-sites` this PR saves a few calls.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8717#issuecomment-2008062964:146,integrat,integration,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8717#issuecomment-2008062964,1,['integrat'],['integration']
Integrability,"Added a unit test. To do so I had to make `BaseRecalibrationEngine.calculateKnownSites()` static. This wasn't a problem because I don't think it accesses any instance attributes but if there's some reason it shouldn't be static, I can do an integration test instead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6389#issuecomment-576898683:241,integrat,integration,241,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6389#issuecomment-576898683,1,['integrat'],['integration']
Integrability,"Added basic java wrappers for training and tranches. I'm working on integration tests and docs today, but the other files should be ready for 1st round review.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-363434657:17,wrap,wrappers,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-363434657,2,"['integrat', 'wrap']","['integration', 'wrappers']"
Integrability,Added unit and integration tests. Had to make a few things protected for testing and added a vcf with a single SNP (where @ldgauthier found this bug) for the integration test. Back to you @droazen.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3655#issuecomment-337705296:15,integrat,integration,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3655#issuecomment-337705296,2,['integrat'],['integration']
Integrability,"Additional feedback from the user for the mutect2 workflow. > ""Of note, it is really difficult and not really 'user-friendly' to have to predict disc space and runtime for Funcotator, which seem to depend (based on calculations you copied above from other Functotator workflows) on outputs of Mutect2 (eg vcf sizes), when here Mutect and Funcotator and bundled together. So I cannot see output of Mutect to predict values for Funcotator - especially not when I get to run this over hundreds of samples. It is also pricey to have jobs failing because of this. It would be much better to have these variables encoded, so that the algorithm uses Mutect outputs to predict memory etc. that it will need to run Funcotator downstream. If this is really how things work (and this is my current understanding), I really do not know how to estimate this for many samples without 'trial and error' that is both costly and it will take extremely long time....""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6680#issuecomment-651354230:198,depend,depend,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6680#issuecomment-651354230,2,['depend'],['depend']
Integrability,"Addressed feedback, updated so it can write reports and added test that checks the exact same reports as the BaseRecalibrator integration test (they pass).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/511#issuecomment-101783201:126,integrat,integration,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/511#issuecomment-101783201,1,['integrat'],['integration']
Integrability,"After discussing with @ldgauthier, I'm going to approve this PR as-is, and Laura will address the remaining TODOs in a separate PR. For the record, the three remaining issues that need addressing are:. * Get rid of the `instanceof VariantWalker` check in `FeatureManager` by making `GATKTool.getGenomicsDBOptions()` return null (or `new GenomicsDBOptions(referenceArguments.getReferencePath())`) instead of throwing an exception, and then having `GATKTool.initializeFeatures()` (and its overrides) pass the GenomicsDB options in to the `FeatureManager` constructor, which can then propagate them down here. * Add a simple direct integration test for the new `--floor-blocks` HaplotypeCaller arg. * Address my maintenance concerns about `AnnotationUtils.isAlleleSpecific()` by adding an empty marker interface for AS annotations (open to other ideas here if you don't like that one)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4947#issuecomment-517350314:629,integrat,integration,629,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4947#issuecomment-517350314,4,"['integrat', 'interface']","['integration', 'interface']"
Integrability,"After experimenting with this a bit, I think using failOnVersionConflict is too inflexible. Currently, we're silently picking up newer versions of dependencies because we're relying on Gradle's default resolution strategy. But if we switch to using failOnVersionConflict, we'll have to resolve each conflict manually, and then we'll have the opposite problem: we'll silently remain pinned to older versions. I think what we really want is to fix the ""silent"" part, so that we have a mechanism that notifies us when we've introduced a change that results in a change to transitive dependency resolution, and gives us a record of which commits caused the change, without necessarily requiring us to manually pin the dependency to a particular version. I propose that we add a file to the repo containing the output of the ""dependencies"" task, and also add a Gradle task that compares that file with the current ""dependencies"" output. Anytime dependencies change, the task/build will fail, and the file diff will tell us what transitive dependencies changed. We can then choose how to resolve the change; either by force resolution, or by just updating the file. The file would have to be updated every time our explicit dependencies change, but the file history would give us a record of which commits changed transitive dependencies.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2592#issuecomment-300280478:147,depend,dependencies,147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2592#issuecomment-300280478,9,['depend'],"['dependencies', 'dependency']"
Integrability,"Again, I'm sorry for being a pain, but the nf-core/raredisease release depends on these changes in which I'm responsible for adding gatk4 cnvcaller modules. Without this fix in a singularity container or conda-recipe, I cannot fully add it, and we cannot release our first pipeline collection:( Thus, @droazen, do you have an update on the release date?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8097#issuecomment-1439999744:71,depend,depends,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8097#issuecomment-1439999744,1,['depend'],['depends']
Integrability,"Again, it's difficult to hold these discussions over issues and understand exactly where the blockers are, but one argument in favor of the wrapper class (FeatureInputAwareVariantContext), instead of re-purposing the source field, is that we can a) retain a reference to the actual FeatureInput class, and b) this should not change existing tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-823598048:140,wrap,wrapper,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-823598048,1,['wrap'],['wrapper']
Integrability,"Ah, so the `ml.dmlc` dependency is the real xgboost library and the tool for predicting from trained models? Got it, thanks for the clarification.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7950#issuecomment-1189379178:21,depend,dependency,21,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7950#issuecomment-1189379178,1,['depend'],['dependency']
Integrability,"Ah, yes, that's kind of confusing actually... ; The **shadow** jar includes a copy of spark and all of it's dependencies, so if you want to run spark tools locally you can use the shadow jar. If you want to use an existing spark cluster, which may have slightly different versions of spark/spark's dependencies then you need to use the **spark** jar. The spark jar doesn't include it's own copy of spark and expects that the spark cluster will provide the necessary dependencies. This avoids conflicts between different dependency versions. . You don't need to use `gatk-launch` ever, but it can make it easier if you want to potentially run your code in different environments. It knows about 3 different potential ways to invoke spark, 1) running in local mode with --sparkMaster local, 2) running on a cluster using spark-submit and 3) running on a google dataproc cluster using gcloud. Gatk-launch knows which environment needs which jar and will prompt you to create one if you don't have it. . gatk-launch also applies some default arguments when running on spark, you may have to supply them yourself if you're not using it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2345#issuecomment-273307091:108,depend,dependencies,108,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2345#issuecomment-273307091,4,['depend'],"['dependencies', 'dependency']"
Integrability,Ah. I see. It's not clear to me what that problem is though. You can have many version of gradle coexisting. Gatk doesn't have to build with system gradle because it comes with the `./gradlew` wrapper which chooses the correct version to build it with.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444200479:193,wrap,wrapper,193,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444200479,2,['wrap'],['wrapper']
Integrability,"Alright, @droazen just showed me what actually got committed and it's all cleaned up. Yay! So now I approve this feature. As long as people do take advantage of the opportunity to clean up the squashed commit message!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2131#issuecomment-246815043:209,message,message,209,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2131#issuecomment-246815043,1,['message'],['message']
Integrability,"Alright, I've at least found (and fixed) a bug that was causing the error message to be so vague. . I may have found the error you're running into as well, if so it should be fixed pretty quickly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375437407:74,message,message,74,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375437407,1,['message'],['message']
Integrability,"Also @vruano , if you feel like it, please see if the integration test is at least resembling what you would like to see.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2595#issuecomment-293913493:54,integrat,integration,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2595#issuecomment-293913493,1,['integrat'],['integration']
Integrability,Also I'm slightly afraid of this branch on the grounds that it cases haplotype caller integration test failures due to subtle math rounding differences here and there in the expected outputs. The fact that this was distinct from `AssemblyBasedCallingUtils.getVariantContextsFromActiveHaplotypes()` in the first place is suspect. Perhaps these should be unified to prevent future confusion.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-644964777:86,integrat,integration,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6661#issuecomment-644964777,1,['integrat'],['integration']
Integrability,Also note a typo in the message output.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4499#issuecomment-370886468:24,message,message,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4499#issuecomment-370886468,1,['message'],['message']
Integrability,"Also pysam. Depends on https://github.com/broadinstitute/gatk/issues/4533, https://github.com/broadinstitute/gatk/issues/4534 and https://github.com/broadinstitute/gatk/issues/4535.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4465#issuecomment-387157958:12,Depend,Depends,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4465#issuecomment-387157958,1,['Depend'],['Depends']
Integrability,"Also, I think we're going to need to establish an environment for running all GATK Python tools, like a single Docker image that doesn't depend on a per-tool Conda environment already being activated (unless there is a programmatic activation mechanism that is independent of the shell environment - I'm not aware of any ?). Ideally, we would agree on a set of ""GATK Python"" dependencies across all Python-dependent tools, establish a Docker image to reflect that, and then all of the Python tools would run on it. If we can't do that, I think we have a much more complicated problem, since activating a per-tool Conda (or virtualenv) environment from Java adds to the complexity.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-345792985:137,depend,depend,137,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-345792985,3,['depend'],"['depend', 'dependencies', 'dependent']"
Integrability,"Also, can you tell us whether the tool runs to completion and produces an output file, despite the message about Google Compute Engine?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-707917240:99,message,message,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875#issuecomment-707917240,1,['message'],['message']
Integrability,"Also, it may be prudent for me to run the data through the commands the tests use, as the data I will make comes from an external source and may not validate in its current state, depending on the tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371500028:180,depend,depending,180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371500028,1,['depend'],['depending']
Integrability,"Also, this seems to misbehave when run on a GZIP file that is NOT a block gzipped file. I get the following result which appears to be flawed in a number of ways:; ```; Block at file offset 0; 	- compressed size: 25442; 	- uncompressed size: 2114545489. 15:24:38.967 INFO PrintBGZFBlockInformation - Shutting down engine; [January 25, 2018 3:24:38 PM EST] org.broadinstitute.hellbender.tools.diagnostics.PrintBGZFBlockInformation done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=190840832; ***********************************************************************. A USER ERROR has occurred: Error while parsing BGZF file. Error message was: testBrokenFile/gnomADaccuracyTest.SynDip.unBlocked.vcf.gz has invalid uncompressedLength: -758824605. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4239#issuecomment-360589954:635,message,message,635,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4239#issuecomment-360589954,1,['message'],['message']
Integrability,"Also, we should confirm that the tool itself emits a warning message to the logger when given coordinate-sorted input.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5672#issuecomment-463772659:61,message,message,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5672#issuecomment-463772659,1,['message'],['message']
Integrability,And on that note... integration run?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8550#issuecomment-1758070114:20,integrat,integration,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8550#issuecomment-1758070114,1,['integrat'],['integration']
Integrability,"Anders Peterson: apete@optimatika.se. I think I made a very small contribution. There is absolutely no need to list me among the contributors. > On 21 Jul 2017, at 23:14, Louis Bergelson <notifications@github.com> wrote:; > ; > Updating the AUTHORS file to include authors who contributed to gatk-protected who's work has been integrated into GATK by the merger.; > ; > I need to find out the preferred emails for the newly listed authors.; > ; > Anders Peterson; > Ayman Abdel Ghany aymana.ghany@devfactory.com; > Kenji Kaneda; > Nils Homer; > ; > @apete @AymanDF @kkaneda @nh13 Would you like to be included here and if so, what email address would you like listed? Have I spelled your name correctly?; > ; > Resolves #3048; > ; > You can view, comment on, or merge this pull request online at:; > ; > https://github.com/broadinstitute/gatk/pull/3330; > ; > Commit Summary; > ; > 	• updating authors to include gatk-protected authors; > File Changes; > ; > 	• M AUTHORS (4); > Patch Links:; > ; > 	• https://github.com/broadinstitute/gatk/pull/3330.patch; > 	• https://github.com/broadinstitute/gatk/pull/3330.diff; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3330#issuecomment-317188169:327,integrat,integrated,327,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3330#issuecomment-317188169,1,['integrat'],['integrated']
Integrability,Another argument against this: the map function of a tool should clearly articulate its inputs in its signature. A map() that takes no parameters and relies on reflection/injection into members for its inputs would be supremely bad design.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/242#issuecomment-76739266:171,inject,injection,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/242#issuecomment-76739266,1,['inject'],['injection']
Integrability,"Another library that just popped up on my radar---and this one is actually in Java!. http://www.amidsttoolbox.com/; https://arxiv.org/abs/1704.01427; https://arxiv.org/abs/1604.07990. The approach is quite different from the other libraries we have been considering; here, the focus seems to be on streaming/parallel data and inference via message passing. I think our models can be expressed in their framework (although, at a glance, the modeling language is not as nice as Stan---it looks like you have to build DAGs explicitly), but I have to admit that I am not familiar with message passing and how performance compares to MCMC, ADVI, etc. @mbabadi @davidbenjamin any thoughts?. I still think it's worth playing around with this library. We could investigate how quick it would be to implement a streaming/minibatch version of VQSR, for example, which might be useful for @eitanbanks @ldgauthier.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2746#issuecomment-318674946:340,message,message,340,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2746#issuecomment-318674946,2,['message'],['message']
Integrability,"Another permutation on this: i dont know if you'll like hooking into the codec, but one could wrap the codec and create a FeatureInputAwareVariantContext. This would go into FeatureDataSource, and would potentially allow Features to be 'aware' of their owning FeatureInput. The code below is not final and needs work, but this or the patch might give an idea:. [FeatureInputAwareVariantContext.patch.txt](https://github.com/broadinstitute/gatk/files/6346205/FeatureInputAwareVariantContext.patch.txt). ```; public static class CodecWrapper<FEATURE_TYPE extends Feature, SOURCE> implements FeatureCodec<FEATURE_TYPE, SOURCE>; {; private final FeatureCodec<FEATURE_TYPE, SOURCE> childCodec;; private final FeatureInput<FEATURE_TYPE> featureInput;. public CodecWrapper(FeatureCodec<FEATURE_TYPE, SOURCE> childCodec, FeatureInput<FEATURE_TYPE> featureInput); {; this.childCodec = childCodec;; this.featureInput = featureInput;; }. @Override; public Feature decodeLoc(SOURCE source) throws IOException {; return childCodec.decodeLoc(source);; }. @Override; public FEATURE_TYPE decode(SOURCE source) throws IOException {; FEATURE_TYPE feature = childCodec.decode(source);. //Either look for marker class or otherwise poke in FeatureInput here:; if (feature instanceof VariantContext); {; feature = new FeatureInputAwareVariantContext(feature, featureInput);; }. return feature;; }. @Override; public FeatureCodecHeader readHeader(SOURCE source) throws IOException {; return childCodec.readHeader(source);; }. @Override; public Class<FEATURE_TYPE> getFeatureType() {; return childCodec.getFeatureType();; }. @Override; public SOURCE makeSourceFromStream(InputStream bufferedInputStream) {; return childCodec.makeSourceFromStream(bufferedInputStream);; }. @Override; public LocationAware makeIndexableSourceFromStream(InputStream inputStream) {; return childCodec.makeIndexableSourceFromStream(inputStream);; }. @Override; public boolean isDone(SOURCE source) {; return childCodec.isDone(source);; }. @Overrid",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-823546766:94,wrap,wrap,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-823546766,1,['wrap'],['wrap']
Integrability,"Another user reported back with some information in the same thread. . ` When not using the '-new-qual' option the memory overrun does seem to depend on the inclusion of non-diploid samples in the cohort (haploid males in my case). I have now separately analyzed the 37 diploid females in the dataset. The script ran successfully with the following specs`. `...ncpus=1:mem=12g...; gatk CombineGVCFs...; gatk --java-options ""-Xmx8g"" GenotypeGVCFs...; Peak memory use of the job was 9.5gb. A previous job with 8gb total memory was terminated due to memory overrun at the CombineGVCFs stage.`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-379313294:143,depend,depend,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-379313294,1,['depend'],['depend']
Integrability,Any update? We have more users asking about the meaning of the WARN.; https://gatkforums.broadinstitute.org/gatk/discussion/13306/genotypegvcfs-warning-message/p1?new=1,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2689#issuecomment-431163980:152,message,message,152,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2689#issuecomment-431163980,1,['message'],['message']
Integrability,"Apart of the amount of work in both Barclay and GATK, I think that this shouldn't be implemented for 2 reasons:. * After #3486, some tools are hidden from the command line (and they will be most likely undocumented too). If the bash-completion works with undocumented tools that are hidden from the command line, there will appear anyway after pressing tab-tab. If that tools are treated in a different way, then it requires even more work - Barclay does not use the omitFromCommandLine at all, and that means that GATK should extend the bash-completion to take it into account.; * If a tool can bash-complete but it does not show in the online help pages (the main source for help, taking into account that in the CLI is a bit messy when the parameter space grows), then it will be really difficult to really understand how the tool work. Even if it shows the parameters with tab-tab, the only way of checking what the meaning of each of them is look at the CLI help. Because the bash-completion is a sub-type of help-doclet, it should require the `@DocumentedFeature` annotation: that is the marker interface in Barclay for mark classes as parsed/added to the ""help"" generated by doclets....",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3596#issuecomment-331112758:1101,interface,interface,1101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3596#issuecomment-331112758,2,['interface'],['interface']
Integrability,"Are gradle dependencies cached anywhere for the Travis build? Pretty sure they aren't, but I'm out of ideas why Travis is failing for this repo.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-296293145:11,depend,dependencies,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-296293145,1,['depend'],['dependencies']
Integrability,"Are we pulling in the fat jar? Very minor issue, but it seems it would be better to pull in a slim jar that only has GenomicsDB + native code, and get its java dependencies separately.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2578#issuecomment-292584597:160,depend,dependencies,160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2578#issuecomment-292584597,1,['depend'],['dependencies']
Integrability,"As determined by @davidadamsphd , the `Copyable` interface idea won't work:. The recommendation from the Dataflow team was to make a narrow API and do the copying part of the API. I started down this route, and I think it might be doable for things like the walker interface. The idea is to make a Copyable interface and have our interfaces extend that. . However, we have unsafe code already in the engine. I tried to make this SafeDoFn approach, however it became clear quickly that we'd have a combinatorial explosion of classes because we don't just have `DoFn<GATKRead,POut>`, but also `<Iterable<GATKRead>,POut>`, and many others. So, this approach will not work for the engine. I then tried to make a general purpose solution (using coders to write to bytes and then recreate a new class). This doesn't work for a few reasons, most critical is that the coder registry isn't Serializable, so that can't be passed down deep enough to get this to work. While working on this, I chatted with someone on the Dataflow team who is working on the verification on the direct runner. He has a PR out and likely going to get it approved soon. So, for the engine, we could always test using the direct runner and know for sure there are not issues (once we can use his code). However, there are two downsides:. 1) We will need to wait for a cut of the SDK (which looking at their previous clip is likely ~ two weeks away). . 2) I don't know if we want the direct runner test as our general purpose solution. Can we expect Comp Bios to always test with the direct runner first? Will they write anything more complex than functions that use the Walker interface?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/702#issuecomment-127403661:49,interface,interface,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/702#issuecomment-127403661,6,"['interface', 'rout']","['interface', 'interfaces', 'route']"
Integrability,"As discussed during GATK office hrs, we need to improve ValidateVariants message to say this is not a invalid vcf. ; **Solution**: separate validation argument that goes beyond vcf specs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6630#issuecomment-637245840:73,message,message,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6630#issuecomment-637245840,1,['message'],['message']
Integrability,"As discussed in person, extract a simple `Shard<T>` interface here to be more compatible with the work done in the `SlidingWindowWalker` branch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2016#issuecomment-234018888:52,interface,interface,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2016#issuecomment-234018888,1,['interface'],['interface']
Integrability,"As far as I can tell, even master passes when that line is removed. So the comments in the integration test are already misleading or out of date. Do you see differently?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7709#issuecomment-1064187912:91,integrat,integration,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7709#issuecomment-1064187912,1,['integrat'],['integration']
Integrability,"As far as I can tell, getting that error message means that BaseTest is being loaded at runtime, and running it's static initializer block which calls `SparkContextFactory.enableTestSparkContext();`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330658299:41,message,message,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330658299,1,['message'],['message']
Integrability,"As you suggested, I replace bed file with `-L chr1` and I am getting an error message shown below:. `A USER ERROR has occurred: Bad input: GenomicsDBImport does not support GVCFs with MNPs. MNP found at chr1:818499 in VCF /home/akansha/vivekruhela/PON/SRR1566827.vcf.gz`. Here is the screenshot:. ![Screenshot_2021-01-15_12-52-59](https://user-images.githubusercontent.com/13174913/104694058-a1d3ef80-5730-11eb-8e04-0842e92a9e6e.png)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7037#issuecomment-760705875:78,message,message,78,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7037#issuecomment-760705875,1,['message'],['message']
Integrability,"At the moment, ReadTools only documents and use `ReadFilters` but I am planning to probably add pack a couple of tools from the GATK/Picard tools at some point. In addition, I am working on another toolkit based on the GATK code, and it will include also annotations for variants (and probably some VCF tools). I just thought that it will be useful to been able to pull out the super-category map to re-use the GATK docgen code. If a downstream project with extra-categories wants to use the GATK templates and DocGen code might get into troubles without being able to access that. I am still working on how to document better my toolkits, but it is not a problem yet. Anyway, I don't really have any strong feeling about this; I just wanted to reduce a bit the complexity of the GATK code and do the same with my downstream projects. If it is something that you anticipate that it is going to change the contract often, feel free to close (the RNA Strings can be removed in other PR).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4247#issuecomment-360856661:905,contract,contract,905,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4247#issuecomment-360856661,1,['contract'],['contract']
Integrability,"BTW thanks @lbergelson for the diagnosis above! Not sure of the best way to prevent this sort of thing in the future without making the environment overly restrictive (this is not really my area of expertise), but perhaps a more thorough pinning of dependencies is worthwhile.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7800#issuecomment-1104492179:249,depend,dependencies,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7800#issuecomment-1104492179,1,['depend'],['dependencies']
Integrability,Back to @jamesemery -- needs an integration test.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2042#issuecomment-237275723:32,integrat,integration,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2042#issuecomment-237275723,1,['integrat'],['integration']
Integrability,"Back to @meganshand. I put in a simple mitochondrial integration test. Given that our MC3 validation already covers this particular bug I actually don't think it needs a new test for mitochondria. Also, for later, are any of your spike-in bams public (or rather, public + public)? I noticed that the NA12878 truth doesn't have very low AFs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5057#issuecomment-408649991:53,integrat,integration,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5057#issuecomment-408649991,2,['integrat'],['integration']
Integrability,"Based off of the integration test differences, this seems to only affect reference block bases following deletions (which is expected).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5665#issuecomment-462883021:17,integrat,integration,17,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5665#issuecomment-462883021,1,['integrat'],['integration']
Integrability,Based on my understanding of the changes in broadinstitute/picard#569 this might actually be easier than I first expected. Unfortunately the metrics collection code is one of the parts of MarkDuplicatesSpark that cannot depend on Picard classes so we are going to have to reimplement this histogram ourselves. It looks like it would require we serialize one additional integer for every duplicate set (that is the count of the total number of elements in the set as opposed to the count of the number of optical duplicates in the set). Since it involves changing the Spark driving code for the tool it is somewhat non-trivial.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6155#issuecomment-530973567:220,depend,depend,220,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6155#issuecomment-530973567,1,['depend'],['depend']
Integrability,Based on the messages you have provided. looks like you have built and run the GATK master branch. You should switch to the genomicsdb_120_1 branch (git checkout genomicsdb_120_1) and retry. You don't need to delete the imported workspace. You should see the version string 4.1.4.1-7-gdb054ab-SNAPSHOT in the GATK stdout.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-574181034:13,message,messages,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-574181034,1,['message'],['messages']
Integrability,"Bayesian GMM:. This is essentially an exact port of the sklearn implementation, but only allowing for full covariance matrices. I think it might be good for those in the Bishop reading group to take a look during review. I decided to split this off into its own branch (just updated the existing branch https://github.com/broadinstitute/gatk/tree/sl_sklearn_bgmm_port) and only include stubs for the BGMM backend in the above tools. This is so we can prioritize merging the IsolationForest implementation for @meganshand. We can easily add this module back when it's been reviewed separately. TODOs:. - [x] Class-level docs.; - [x] Method-level docs. I think pointers back to the original sklearn code will suffice for most methods, but I've also included some parameter descriptions. Also note that I've retained original sklearn comments throughout the implementation and have also commented on mathematical expressions where it might be helpful.; - [x] Unit tests. There's already test data (generated using Pyro) checked in and the results match the sklearn implementation to high precision, I just need to write numerical checks. There are also already unit tests for static utility methods. Future work:; - [ ] Expanding unit tests to cover more of the interface. These initial unit tests will almost certainly not completely cover the possibilities allowed by the interface, e.g. warm starts. Could be a good exercise for other developers. EDIT: At least one test of warm starts has been added.; - [ ] As mentioned in the prototyping discussion, expanding this implementation to properly include marginalization might be of future interest. However, I think a very strong case would have to made before proceeding, as I think closely matching the sklearn implementation has obvious benefits for maintainability.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948712:1259,interface,interface,1259,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948712,2,['interface'],['interface']
Integrability,"Bcftools setGT plugin is probably the best way of fixing this issue currently. ; ```; bcftools plugin setGT -h ; About: Sets genotypes. The target genotypes can be specified as:; ./. .. completely missing (""."" or ""./."", depending on ploidy); ./x .. partially missing (e.g., ""./0"" or "".|1"" but not ""./.""); . .. partially or completely missing; a .. all genotypes; b .. heterozygous genotypes failing two-tailed binomial test (example below); q .. select genotypes using -i/-e options; and the new genotype can be one of:; . .. missing (""."" or ""./."", keeps ploidy); 0 .. reference allele (e.g. 0/0 or 0, keeps ploidy); c:GT .. custom genotype (e.g. 0/0, 0, 0/1, m/M, overrides ploidy); m .. minor (the second most common) allele (e.g. 1/1 or 1, keeps ploidy); M .. major allele (e.g. 1/1 or 1, keeps ploidy); p .. phase genotype (0/1 becomes 0|1); u .. unphase genotype and sort by allele (1|0 becomes 0/1); Usage: bcftools +setGT [General Options] -- [Plugin Options]; Options:; run ""bcftools plugin"" for a list of common options. Plugin options:; -e, --exclude <expr> Exclude a genotype if true (requires -t q); -i, --include <expr> include a genotype if true (requires -t q); -n, --new-gt <type> Genotypes to set, see above; -t, --target-gt <type> Genotypes to change, see above. Example:; # set missing genotypes (""./."") to phased ref genotypes (""0|0""); bcftools +setGT in.vcf -- -t . -n 0p. # set missing genotypes with DP>0 and GQ>20 to ref genotypes (""0/0""); bcftools +setGT in.vcf -- -t q -n 0 -i 'GT=""."" && FMT/DP>0 && GQ>20'. # set partially missing genotypes to completely missing; bcftools +setGT in.vcf -- -t ./x -n . # set heterozygous genotypes to 0/0 if binom.test(nAlt,nRef+nAlt,0.5)<1e-3; bcftools +setGT in.vcf -- -t ""b:AD<1e-3"" -n 0. # force unphased heterozygous genotype if binom.test(nAlt,nRef+nAlt,0.5)>0.1; bcftools +setGT in.vcf -- -t ./x -n c:'m/M'; ```; I was always wondering if GATK will have a plugin interface where people can code their own using groovy, kotlin, javascr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-1556119501:220,depend,depending,220,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-1556119501,1,['depend'],['depending']
Integrability,Because I am stupid and don't know how to read numbers (I saw 4.3 instead of 4.6): actually the list that I did was based on the 4.6 changelog. I edited title and message.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4659#issuecomment-382305931:163,message,message,163,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4659#issuecomment-382305931,1,['message'],['message']
Integrability,"Blocked by #4609; (github ""Add dependency"" option disappeared)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5932#issuecomment-491111534:31,depend,dependency,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5932#issuecomment-491111534,1,['depend'],['dependency']
Integrability,"By default we aim for correctness over efficiency... for what you're saying about the target being useless it sounds that perhaps you should consider to generalize the ReadCountCollection so that in some sub implementations targets are implicit based on their index in the collection and so for those tools that don't care about target-names this operation would go much faster. . So RCC could be an interface rather than a concrete class and some child class would implement the current RCC s behavior, whereas some new child class would implement a more efficient solution for WG- fix size interval collections.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-316486183:400,interface,interface,400,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2858#issuecomment-316486183,1,['interface'],['interface']
Integrability,"By default we only support OSX and modernish linux on amd64. We don't have a plan to test or officially support aarch64. However, it's mostly java so it might mostly work? The things I can think of off the bat that won't work are the optimizations for intel hardware, i.e. the fast pairhmm and deflate/inflate optimizations will definitely not work. They **should** degrade to java implementations automatically though. . IBM has a fork that works on power8 which reimplements some of the optimizations for PairHMM, so it's definitely possible to implement the various native optimizations for other architectures although not a small project. . GenomicsDB won't work since we only bundle libs for amd64/osx. You could in theory compile it yourself and pass the library on the library path. Other things that will need special attention would any of the library wrappers, for bwa-mem, fermlite, and hdf5. Those will similarly need custom builds supplied to the gatk. . I suspect that you could get the reads pipeline working, but newer tools with weirder native dependencies will be tricky.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6118#issuecomment-524959548:862,wrap,wrappers,862,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6118#issuecomment-524959548,2,"['depend', 'wrap']","['dependencies', 'wrappers']"
Integrability,"By doing the following, I was able to get a JointGenotyping result for my 343 samples:; - increased the amount of memory allocated to the Java heap in ImportGvcfs to 50000m; - modified the runtime attributes for all the joint genotyping tasks to match the format that Cromwell accepts for HPC environments (https://cromwell.readthedocs.io/en/stable/tutorials/HPCIntro/#specifying-the-runtime-attributes-for-your-hpc-tasks); - increasing the runtime memory attribute for ImportGvcfs and GenotypeGvcfs from 26000 MiB to 60 G; - executing the workflow with the following sbatch parameters:; nodes=4; ntasks=32; mem=248g; tmp=429G; - manually tar'ing up all the genomicsdb directories from the execution directories of all 10 shards of ImportGvcfs after they successfully completed GenomicsDBImport and failed with the error message: ; pure virtual method called ; terminate called without active exception; - running an abbreviated version of JointGenotyping which started at GenotypeGvcfs and executed the remainder of the JointGenotyping workflow unchanged.; ; I think this pretty clearly demonstrates that, whatever is going on, it occurs between GenomicsDBImport's successful creation of genomicsdb and the tar -cf of same. The failure is 100% reproducible with a number of different runtime configurations. The error messages are from C++ and seem to be occurring at the point where native C++ code is handing execution back to Java.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1314069533:821,message,message,821,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8076#issuecomment-1314069533,4,['message'],"['message', 'messages']"
Integrability,"By modifying the test I was able to isolate the error in the `org.broadinstitute.hellbender.tools.walkers.variantutils` package, which is strange because the PR did not modify the javadoc for any class in that package. The integration test runs `com.sun.tools.javadoc.Main.execute` and asserts that the output code is zero, which does not yield a useful error message. In order to produce something more meaningful I hacked the test to output the entire `stdout` and `stderr` as follows:. ```; final StringWriter out = new StringWriter();; final PrintWriter err = new PrintWriter(out);. final int result = com.sun.tools.javadoc.Main.execute(""program"", err, err, err, ""doclet"",docArgList.toArray(new String[] {}));; err.flush(); // probably not needed; String message = out.toString(); // message contains the entire stdout and stderr of the call to execute; Assert.assertEquals(result, 0, message);; ```. The output is about 2000 lines, but a lot of it is clearly innocuous. Removing lines such as; * `2022-08-16T00:09:07.2336106Z [parsing completed 1ms]`; * `2022-08-16T00:09:07.4456202Z [loading ZipFileIndexFileObject[/jars/gatk-package-4.2.6.1-56-gad9a538-SNAPSHOT-test.jar(org/broadinstitute/hellbender/tools/walkers/variantutils/ReblockGVCFIntegrationTest.class)]]`; * `2022-08-16T00:09:07.4459732Z [loading RegularFileObject[src/main/java/org/broadinstitute/hellbender/cmdline/argumentcollections/OptionalIntervalArgumentCollection.java]]`; * `2022-08-16T00:09:07.4462012Z [parsing started RegularFileObject[src/main/java/org/broadinstitute/hellbender/cmdline/argumentcollections/OptionalReferenceInputArgumentCollection.java]]`; * 2022-08-16T00:09:07.2322755Z [loading ZipFileObject[/gatk/gatk-package-unspecified-SNAPSHOT-local.jar(htsjdk/samtools/SAMSequenceDictionary.class)]]. brings it down to 353 lines, the majority of which look like . ```2022-08-16T00:09:07.4435974Z src/main/java/org/broadinstitute/hellbender/cmdline/CommandLineProgram.java:479: error: cannot find symbol; 2022-08-1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217231488:223,integrat,integration,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7991#issuecomment-1217231488,10,"['integrat', 'message']","['integration', 'message']"
Integrability,"Calling intervals should be based on targets. The targets are the goal and the probes are the implementation. Depending on the bait design and the size of the exons, there can be regions of the targets that are not covered by baits, but still have coverage and still should be called.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6080#issuecomment-518249465:110,Depend,Depending,110,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6080#issuecomment-518249465,1,['Depend'],['Depending']
Integrability,Can has integration run?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8529#issuecomment-1758063142:8,integrat,integration,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8529#issuecomment-1758063142,1,['integrat'],['integration']
Integrability,"Can you give a bit more information here? If I'm understanding correctly, it's not clear that the same issue is at play here. The original issue was that duplicate/incomplete fragments were causing queries to the workspace to fail. . In this latest instance, it seems you are appending additional samples to the existing workspace. Is that right? If so,; - are you seeing the same/similar error? That is, it's a core dump? Can you share the error messages, any logs, core dump files etc?; - did you clean up the workspace before importing? That is, remove the incomplete fragment @nalinigans identified and the duplicated ones?. My first instinct is that even if the incomplete/duplicated fragments weren't cleaned up, the incremental import shouldn't have an issue -- at least not till it gets to the consolidate phase, which only happens after all batches are imported. Sounds like you were seeing an issue at batch 3 of 4, so might have something to do with the samples in that batch...or some other import issue. You mentioned that previous imports to this particular contig failed -- were those just transient failures that worked when rerun, or was there some configuration that you changed to get that to work?. For completeness, the way I identified duplicate fragments was to do an md5sum check on some of the internal files. If any pair of fragments have the same md5sum they are likely duplicates. So, from the workspace directory, something like:. ```; find . -name ""ALT.tdb"" -exec md5sum {} \;|sort; ```; That will highlight the fragments that are potentially duplicate. To confirm that the fragments are indeed duplicates, you'll then want to take that list of potentially duplicate fragments and check that all corresponding files within each pair of potentially duplicate fragments actually have the same md5sum. I have a crude bash script that I can share if you want.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-722541707:447,message,messages,447,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910#issuecomment-722541707,2,['message'],['messages']
Integrability,"Can you have a look to this one, @cmnbroad? It is just a simple change for let me upgrade my dependencies and do not include the NPE in not bounded arguments...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2455#issuecomment-285858467:93,depend,dependencies,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2455#issuecomment-285858467,2,['depend'],['dependencies']
Integrability,"Can you have a look to this proposal, @droazen? I really need to have this in before the release of GATK4 to be able to update my dependency for the release one. Otherwise, I will need a version bump or a hacked CLP class (which I prefer to avoid). Thank you very much in advance!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-353034378:130,depend,dependency,130,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-353034378,1,['depend'],['dependency']
Integrability,"Can you provide me some test data for include in the tools integration test, @vdauwera and/or @sooheelee? If not, I will try to use some BAM files already in the repository...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308060263:59,integrat,integration,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308060263,1,['integrat'],['integration']
Integrability,Can you provide more details on what operating system you are using and other related information such as java version etc?. Even if the process gets interrupted by the system there must be a java segfault message at some point thrown by the process. Did you observe any files with names ERR around the output file?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2238814358:206,message,message,206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2238814358,1,['message'],['message']
Integrability,Can you provide your logs that shows the error message?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2236819113:47,message,message,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2236819113,1,['message'],['message']
Integrability,"Can you try running GenotypeGVCFs with -L ""contig_name"" parameter?. EDIT: ; This may also produce another error about the -L parameter so the only solution I could find was to have a bed file that covers the whole contig that you are interested in for that import and pass it to GenotypeGVCFs as -L parameter. We need to change the behavior and provide a better error message to warn users about this issue. ; EDIT2: this only occurs if your GenomicsDB folder name is the same as your contig name. If that's the case you may need to use the bed file otherwise you can use the contig name directly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8415#issuecomment-2191335515:368,message,message,368,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8415#issuecomment-2191335515,1,['message'],['message']
Integrability,Change commit message to `Replace --allowMissingData with --errorIfMissingData (gives opposite default behavior as previously) and print NA for null object in VariantsToTable`.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3190#issuecomment-318691479:14,message,message,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3190#issuecomment-318691479,1,['message'],['message']
Integrability,Chaning the holding collection to a Vector which is synchronized. There is no performance impact as this add and single collection iteractiion should happen just a finite number of times.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7403#issuecomment-899839756:52,synchroniz,synchronized,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7403#issuecomment-899839756,1,['synchroniz'],['synchronized']
Integrability,Closed. Will be integrated with tws_bafFixes PR.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7882#issuecomment-1146270034:16,integrat,integrated,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7882#issuecomment-1146270034,1,['integrat'],['integrated']
Integrability,"Closing as a part of my issue clearing rampage, but let it be known Pyro is on the roadmap for future CNV models, and we are currently looking into updating PyMC3 to resolve some dependency issues with gCNV.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5766#issuecomment-926143041:179,depend,dependency,179,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766#issuecomment-926143041,2,['depend'],['dependency']
Integrability,"Closing in favor of https://github.com/broadinstitute/gatk/pull/6011, where the dependency conflict from this branch has been resolved.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-557190804:80,depend,dependency,80,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5928#issuecomment-557190804,1,['depend'],['dependency']
Integrability,Closing this because it turns out it requires adding an additional dependency on devtools which adds more complication. It lets us specify versions of our existing dependencies but we end up with an unversioned dependency on devtools instead. Doesn't really seem worth it since devtools is a fairly heavy thing with lots of it's own dependencies.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3352#issuecomment-319185047:67,depend,dependency,67,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3352#issuecomment-319185047,4,['depend'],"['dependencies', 'dependency']"
Integrability,"Closing this one -- I think scraping the exception messages for keywords to infer what's gone wrong is too brittle an approach. If we want better error reporting, we should submit a patch to `google-cloud-java`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5477#issuecomment-567219186:51,message,messages,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5477#issuecomment-567219186,1,['message'],['messages']
Integrability,Closing until I find a different strategy for docker integration.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5866#issuecomment-481260984:53,integrat,integration,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5866#issuecomment-481260984,1,['integrat'],['integration']
Integrability,CompareReferences FullAlignment integration tests & ExecuteMummer unit test failing currently due to MUMmer build,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7987#issuecomment-1213576637:32,integrat,integration,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7987#issuecomment-1213576637,1,['integrat'],['integration']
Integrability,"Completed VDS Creation run [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/9e438044-9317-4df7-9a0b-46eee26b6875), Integration run [in progress](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/694df4e3-b903-4d7b-86ec-4344c7f3007b).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8534#issuecomment-1759783490:145,Integrat,Integration,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8534#issuecomment-1759783490,1,['Integrat'],['Integration']
Integrability,"Completing https://github.com/broadinstitute/hellbender/issues/673 will take care of the case of ""missing reference for CRAM"", but we also need to make sure we're handling the case of ""wrong reference"" elegantly (where elegantly means ""throw a `UserException` with a descriptive error message). We want a test case with a reference that is the wrong reference for a CRAM, but has a compatible sequence dictionary (so that it won't be caught by the sequence dictionary validation). Both the wrong and missing reference cases should have a simple integration test that runs, eg., `PrintReads` with `expectedExceptions = UserException.class`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/677#issuecomment-126031374:285,message,message,285,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/677#issuecomment-126031374,2,"['integrat', 'message']","['integration', 'message']"
Integrability,"Copying in some discussion about my initial, incorrect, effort in PR #2547:. David Roazen:; As discussed in person, we fully support the mission of making this class less stateful (and particularly making it so that `isVcCoveredByDeletion()` does not modify state, which was the original ticket), but we're concerned that this method `calculateOutputAlleleSubset()` was intended to be stateful, and to accumulate deletions across calls. It's also not well covered by tests, so this change could easily break the method. Can you think about this issue and reply here once you've looked into it, davidbenjamin ? Also at-mentioning ronlevine to solicit his comments, since he appears to have added `upstreamDeletionsLoc` to this class in the first place. Ron Levine; droazen Is correct. It was intended to maintain state for upstream deletions. Make sure the upstream spanning deletion does not span shard barriers, then there will be problems with the book keeping. AFAIK, shards overlap genome locations but for a large spanning deletion, the size might not be sufficient. davidbenjamin Here is the motivation for the change: https://github.com/broadinstitute/gsa-unstable/issues/1188 and accompanying pull request, [Removed spanning deletions if the deletion was removed](https://github.com/broadinstitute/gsa-unstable/pull/1417). I am not convinced the [integration test](https://github.com/broadinstitute/gsa-unstable/pull/1417/files#diff-b60a90bdf249d0dbb8636427be0a5dd7) from the pull request will give the desired results with this implementation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2537#issuecomment-303470744:1355,integrat,integration,1355,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2537#issuecomment-303470744,1,['integrat'],['integration']
Integrability,"Correct - though it also depends on the Gencode data source which is tied to the reference. It really pulls the protein change info from the gencode transcript sequence, which is at the core of the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-754168308:25,depend,depends,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651#issuecomment-754168308,1,['depend'],['depends']
Integrability,"Correct, `MaxChannelReopens` defaults to 0. So this path used the underlying retry mechanism only (which doesn't give a special message when it's done, hence we didn't see ""All retries failed""). . You're asking about the default: my understanding is that [the default retry count is 6](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-core/src/main/java/com/google/cloud/ServiceOptions.java#L588). Global settings would be useful, yes I agree.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2749#issuecomment-308578621:128,message,message,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2749#issuecomment-308578621,1,['message'],['message']
Integrability,"Could you nominate someone for this one, @droazen?. In addition, I would like to use the `GATKRead` interface instead of `SAMRecord`, but I do not look into the logic enough to do the change yet...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3107#issuecomment-308122779:100,interface,interface,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3107#issuecomment-308122779,1,['interface'],['interface']
Integrability,"Current status of this: The tool can physically run on 11k samples, but with a 1-5% failure rate, depending on the combination of arguments used. The failures are almost all due to https://github.com/broadinstitute/gatk/issues/2685 (see the stack trace in https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308541727 for a representative example error). . One possibility is that we are being throttled in a way that GATK itself can't recover from. GATK is retrying in the face of these SSL errors 20 times, with increasing wait times between each attempt, and still running out of retries. See @jean-philippe-martin 's latest hypothesis in https://github.com/broadinstitute/gatk/issues/2685#issuecomment-308586876. @kcibul @Horneth take note.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2633#issuecomment-308755736:98,depend,depending,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2633#issuecomment-308755736,1,['depend'],['depending']
Integrability,"Dear @shulik7, according to the error message, gcnvkernel is expecting ploidy calls at the following path: `/scratch/users/shulik7/test_GATK_CNV/Postprocess/../DetermineGermlineContigPloidy/model/test_run-calls/`. Could you please assert that the above path is indeed the ploidy *calls* paths, and if so, whether it contains `test_sample_0` under one of `SAMPLE_x` subdirs? if the path is valid, please try running `PostprocessGermlineCNVCalls` with an absolute path and report back.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4724#issuecomment-385782919:38,message,message,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4724#issuecomment-385782919,1,['message'],['message']
Integrability,"Dear Geraldine and David,. Sorry for my delayed reply. I am busy with graduation in recent days, and will work on visa application for the further postdoc position at Harvard Medical School. Thank you for the interests in our tool, MosaicHunter. The option you suggest looks great. Do you mean that I should establish the GATK 4 developing environment and develop the MosaicHunterFilter tool? I may do that when I have some time. I found the document of GATK 4 at https://github.com/broadinstitute/gatk. Do you have any further advices?. Best regards,; Adam Yongxin Ye; Center for Bioinformatics; Peking University. At 2018-07-07 01:43:05, ""Geraldine Van der Auwera"" <notifications@github.com> wrote:. Hi @Yyx2626, I'm Geraldine, you may remember me from the Beijing training. It was great visiting your team! I'm sorry it took me so long to follow up on this discussion, and I want to thank you again for reaching out to us about integrating the tool that you developed into GATK. We are certainly very interested in providing this enhancement to the research community, and we are now ready to talk about the next steps. After examining your paper and the source code in Github, we think that the most efficient way to integrate the functionality you developed would be to adapt the filtering parts of your tool to run on the output of Mutect2. So this would be a standalone tool that you would run after Mutect2, much like the current FilterMutectCalls tool. If the results are comparable to your current tool, then we would take that into the official distribution of GATK. If somehow that integration does not yield satisfactory results, then we would look at integrating the entire tool, though we're hoping it won't be necessary, so we can avoid maintaining duplicate functionality for some of the boilerplate data transformations. David @davidbenjamin can provide some advice on how to implement this in GATK4; in brief you would need to write some code that applies the filters you developed ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4632#issuecomment-404104349:931,integrat,integrating,931,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4632#issuecomment-404104349,1,['integrat'],['integrating']
Integrability,"Deleted AllelicCNV in #3935. I don't think `org.apache.spark.mllib.stat.KernelDensity` is used any longer, but we may still run into similar dependency issues in the future. Going to close this for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3599#issuecomment-356744585:141,depend,dependency,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3599#issuecomment-356744585,1,['depend'],['dependency']
Integrability,"Depending on what the allele frequencies are in that supporting VCF, the prior on there being a variant could be very strong against homozygous reference calls. We've found that the support resource doesn't have to be well population matched, but that was for overall accuracy. There can be a small decrease in sensitivity. Another option is to decrease the de novo mutation prior with `--de-novo-prior` to increase sensitivity as seen in slide 15 from the GATK workshop presentation here: https://drive.google.com/drive/u/0/folders/1FzkoFoIVI41JBp_E8S6WfwhJH7xt8T2Y The default is 1e-6, which is not in agreement with the literature, but provided good results in our evaluations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6424#issuecomment-580271959:0,Depend,Depending,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6424#issuecomment-580271959,1,['Depend'],['Depending']
Integrability,Depends on #4571.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5439#issuecomment-443750050:0,Depend,Depends,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5439#issuecomment-443750050,1,['Depend'],['Depends']
Integrability,Depends on https://github.com/broadinstitute/barclay/issues/128.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3947#issuecomment-359538226:0,Depend,Depends,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3947#issuecomment-359538226,1,['Depend'],['Depends']
Integrability,Depends on https://github.com/broadinstitute/gatk/issues/2599,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2638#issuecomment-298106226:0,Depend,Depends,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2638#issuecomment-298106226,1,['Depend'],['Depends']
Integrability,Depends on https://github.com/broadinstitute/gatk/issues/2613,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2633#issuecomment-297818474:0,Depend,Depends,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2633#issuecomment-297818474,2,['Depend'],['Depends']
Integrability,"Depends on https://github.com/broadinstitute/gatk/issues/2639, https://github.com/broadinstitute/gatk/issues/2641, and https://github.com/broadinstitute/gatk/issues/2640",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2633#issuecomment-298341590:0,Depend,Depends,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2633#issuecomment-298341590,1,['Depend'],['Depends']
Integrability,Depends on https://github.com/broadinstitute/gatk/issues/3705,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3706#issuecomment-337335613:0,Depend,Depends,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3706#issuecomment-337335613,1,['Depend'],['Depends']
Integrability,"Depends on what you mean by ""wrong"". They accurately report their truth sensitivity, it just may not do the best job achieving what was requested on the low end.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4313#issuecomment-362406085:0,Depend,Depends,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4313#issuecomment-362406085,1,['Depend'],['Depends']
Integrability,Did that fix the problem? Depending on your shell you may have to escape the local bit. ```; --spark-master `local[20]`; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4230#issuecomment-360197001:26,Depend,Depending,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4230#issuecomment-360197001,1,['Depend'],['Depending']
Integrability,"Did you figure out why Travis is failing? Also, I think this PR needs at least one test---you can just add to the gCNV integration tests for now, but we should extract out the HMM code and its tests at some point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4335#issuecomment-363108424:119,integrat,integration,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4335#issuecomment-363108424,1,['integrat'],['integration']
Integrability,"Dijkstra origina algorithm is about finding the single shortest route (or one of the in case of a tie), here we need the one that finds the K-shortest routes which is described [here](https://en.wikipedia.org/wiki/K_shortest_path_routing). Is this one implanted in Jgraph? In that case, yes we could.... . Otherwise if we have to implement the it from scratch... then there is no guaranteed the code is going to be simpler.... it could simpler just because I didn't bother to make the current one as simple as it could be.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3561#issuecomment-328169271:64,rout,route,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3561#issuecomment-328169271,4,['rout'],"['route', 'routes']"
Integrability,"Do you think that this is really necessary for a normal user? I mean, usually `UserException` should have a well-defined message String for point to the user what happened. If the stack traces are necessary, are for debugging and I think that the final user won't benefit for having an extra argument. In addition, it is in the repository README, which made it discoverable for developers and it is what it is really meant for (I guess). Other option may be to print the stack trace for `UserException`only if the verbosity is set to DEBUG, and that will get rid of the environmental variable....",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2443#issuecomment-285282288:121,message,message,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2443#issuecomment-285282288,1,['message'],['message']
Integrability,Doesn't seem to be a problem with the Maven central jar - I created a blank Github repo which requests the same environment as GATK-4 on Travis and builds and runs a Java test program for GenomicsDB by downloading the jar from Maven central. I added the ldd commands as well to show that there are no spurious dependencies.; https://travis-ci.org/kgururaj/TestGenomicsDBJar/builds/224466325,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-296280376:310,depend,dependencies,310,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-296280376,1,['depend'],['dependencies']
Integrability,Doing some digging it seems the message was added in the `IntelInflater.inflate()` update as of our upgrade to `gkl:0.8.8`. This is a very minor logging bug but we should probably ask for that warning to be removed as its confusing to users.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8126#issuecomment-1371207984:32,message,message,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8126#issuecomment-1371207984,1,['message'],['message']
Integrability,"EachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); ```. Then another run I happened to click on had a similar error to what we've seen before, but I'm now wondering if this message means something different from the other inflator style error messages:. ```; Using GATK jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.v",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963:7094,message,message,7094,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963,2,['message'],"['message', 'messages']"
Integrability,Excellent! I will update my GATK dockers soon and then _I_ won't have to look at that message any more either.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-458267899:86,message,message,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-458267899,1,['message'],['message']
Integrability,"ExtractVariantAnnotations:. This tool extracts annotations, labels, and other relevant metadata from variants (or alleles, in allele-specific mode) that do or do not overlap with specified resources. The former are considered labeled and each variant/allele can have multiple labels. The latter are considered unlabeled and can be randomly downsampled using reservoir sampling; extraction of these is optional. The outputs of the tool are HDF5 files containing the extracted data for labeled and (optional) unlabeled variant sets, as well as a sites-only VCF containing the labeled variants. This VCF can be used in ScoreVariantAnnotations to in turn specify an additional ""extracted"" label, which can be useful for indicating those sites that were actually extracted from the provided resources (since we may only extract over a subset of the genome). TODOs:; - [x] Integration tests. Putting together tests using chr1:1-10M snippets of 1) the 1kgp-50-exomes sites-only VCF for the input (since this has both non-AS and AS annotations; EDIT: Scratch that, it only has AS_InbreedingCoeff and AS_QD), 2) the Omni SNP training/truth VCF (yielding ~3.5k training), and 3) the Mills training/truth VCF (yielding ~500 training). Incidentally, VariantRecalibrator SNP and INDEL runs both fail to converge on these small training sets without the #7709 fix, but do converge with it. I still need to check if enough multiallelics are included here; if not, I'll choose a different snippet. EDITEDIT: Now using gs://broad-gotc-test-storage/joint_genotyping/exome/scientific/truth/master/gather_vcfs_high_memory/small_callset_low_threshold.vcf.gz provided by @ldgauthier, which does have AS annotations.; ; We'll use expected outputs here as inputs to downstream steps, but rather than provide the expected outputs directly, we'll create copies of them and provide those as inputs. This will make the tests better encapsulated. However, it should be relatively easy to update the whole chain of test files, shou",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948059:867,Integrat,Integration,867,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7724#issuecomment-1067948059,1,['Integrat'],['Integration']
Integrability,"FO BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on scc-q01.scc.bu.edu:41129 (size: 25.4 KB, free: 365.9 MB); 2019-01-09 13:35:46 INFO BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on scc-q01.scc.bu.edu:41129 (size: 113.9 KB, free: 365.8 MB); 2019-01-09 13:35:48 INFO TaskSetManager:54 - Starting task 4.0 in stage 0.0 (TID 2, scc-q20.scc.bu.edu, executor 2, partition 4, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:48 WARN TaskSetManager:66 - Lost task 1.0 in stage 0.0 (TID 0, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:23471,Wrap,Wrappers,23471,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616,1,['Wrap'],['Wrappers']
Integrability,"FO BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on scc-q12.scc.bu.edu:38418 (size: 25.4 KB, free: 365.9 MB); 2019-01-07 11:34:05 INFO BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on scc-q12.scc.bu.edu:38418 (size: 113.9 KB, free: 365.8 MB); 2019-01-07 11:34:06 INFO TaskSetManager:54 - Starting task 3.0 in stage 0.0 (TID 2, scc-q21.scc.bu.edu, executor 1, partition 3, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:06 WARN TaskSetManager:66 - Lost task 1.0 in stage 0.0 (TID 1, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:24184,Wrap,Wrappers,24184,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969,1,['Wrap'],['Wrappers']
Integrability,"FO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 609.8425236940001; 08:42:02.710 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 142.16 sec; 08:42:02.711 INFO Mutect2 - Shutting down engine; [December 4, 2019 8:42:02 AM CST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 24.59 minutes.; Runtime.totalMemory()=2076049408; java.lang.IndexOutOfBoundsException: Index: 0, Size: 0; at java.util.ArrayList.rangeCheck(ArrayList.java:653); at java.util.ArrayList.get(ArrayList.java:429); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.lambda$getGermlineAltAlleleFrequencies$31(SomaticGenotypingEngine.java:350); at java.util.stream.ReferencePipeline$6$1.accept(ReferencePipeline.java:244); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); at java.util.stream.DoublePipeline.toArray(DoublePipeline.java:506); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.getGermlineAltAlleleFrequencies(SomaticGenotypingEngine.java:352); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.getNegativeLogPopulationAFAnnotation(SomaticGenotypingEngine.java:335); at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:141); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:250); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:324); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:308); at org.broadinstitute.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4578#issuecomment-561699783:1791,wrap,wrapAndCopyInto,1791,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4578#issuecomment-561699783,1,['wrap'],['wrapAndCopyInto']
Integrability,FWIW I'm having the exact same issue with HaplotypeCaller. It's not quite limited to just requests for help (`-h`). Any completely valid command line works. Any incorrect command line that also triggers display of the help text also fails with the same error message.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4875#issuecomment-396286813:259,message,message,259,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4875#issuecomment-396286813,1,['message'],['message']
Integrability,Factory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:907); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:861); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at j,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-783746069:3992,wrap,wrapAndCopyInto,3992,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6289#issuecomment-783746069,1,['wrap'],['wrapAndCopyInto']
Integrability,FeatureDataSource.java:326); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.initializeDrivingVariants(VariantLocusWalker.java:76); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFeatures(VariantWalkerBase.java:67); 	at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:709); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.onStartup(VariantLocusWalker.java:63); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: java.io.IOException: GenomicsDB JNI Error: VariantQueryProcessorException : Could not open array 3$1$121351753 at workspace: /data1/EquCab/GenomicsDB/ECA3_GenomicsDB_260/3; TileDB error message : [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading MBR failed; 	at org.genomicsdb.reader.GenomicsDBQueryStream.jniGenomicsDBInit(Native Method); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:209); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:182); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:91); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.generateHeadersForQuery(GenomicsDBFeatureReader.java:200); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.<init>(GenomicsDBFeatureReader.java:85); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:407); 	... 12 more,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-755760402:8400,message,message,8400,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012#issuecomment-755760402,2,['message'],['message']
Integrability,"FilterFactory; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/FindBreakpointEvidenceSpark.java; - input coverage-scaled thresholds, convert to absolute internally. Allow thresholds to be double instead of int; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointDensityFilter.java; - getter functions added to calculate properties for XGBoostEvidenceFilter. Also fromStringRep() and helper constructors added for testing; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointEvidence.java; - updates to tests reflecting changes to these interfaces; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointDensityFilterTest.java; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/FindBreakpointEvidenceSparkUnitTest.java; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/integration/FindBreakpointEvidenceSparkIntegrationTest.java; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/integration/SVIntegrationTestDataProvider.java. 4. Added code; - factory to call appropriate BreakpointEvidence filter; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/BreakpointFilterFactory.java; - simple helper class to hold feature vectors for classifier; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/EvidenceFeatures.java; - implement classifier-based BreakpointEvidence filter; src/main/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/XGBoostEvidenceFilter.java; - unit test for classifier filter; src/test/java/org/broadinstitute/hellbender/tools/spark/sv/evidence/XGBoostEvidenceFilterUnitTest.java. 5. Added resources; - Genome tracts; src/main/resources/large/hg38_centromeres.txt.gz; src/main/resources/large/hg38_gaps.txt.gz; src/main/resources/large/hg38_umap_s100.txt.gz; - Classifier binary file; src/main/resources/large/sv_evidence_classifier.bin; - Data used for validation of performance in unit tests; src/test/reso",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-389218477:2144,integrat,integration,2144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-389218477,2,['integrat'],['integration']
Integrability,"First and second lines in are printed by the wrapper script, no? In that case, it shouldn't be a problem to downstream projects unless the use the same wrapper script. Regarding the last one, I think that it is already customizable by overriding the method that you pointed out (I'm using it in my toolkit, and I guess that it works.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3312#issuecomment-316637378:45,wrap,wrapper,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3312#issuecomment-316637378,2,['wrap'],['wrapper']
Integrability,Fix pushed -- there was a problem with the version of the `google-cloud-contrib` dependency in the pom for the snapshot. Tests should pass now.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3766#issuecomment-340885747:81,depend,dependency,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3766#issuecomment-340885747,1,['depend'],['dependency']
Integrability,Fixing a typo that gives rise to confusing error messages over in gatk-protected. @davidbenjamin can you review?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2378#issuecomment-276701522:49,message,messages,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2378#issuecomment-276701522,1,['message'],['messages']
Integrability,"For one example, gatk-protected is currently pulling in a newer version of protobuf than GATK uses, since GATK uses an older one but gatk-protected pulls in a newer version via other dependencies. Using failOnVersionConflict would at least alert us when this is happening and allow us to choose how it gets resolved.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2592#issuecomment-293032989:183,depend,dependencies,183,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2592#issuecomment-293032989,1,['depend'],['dependencies']
Integrability,"For reporting the number of reads that fails each of the filters, the composed filter could be changed by a `CountingReadFilter`; using the `getSummaryLine()` method will provide the number of reads failing each of the components. Developers could have in their tools a field with the `WellFormedReadFilter` and call a new method for reporting the summary, to log a warning/debug line. For exploding depending on the tool, maybe an advance/hidden argument can be added to the filter (something like `--failOnMalformed`) to throw an exception if true; developers might add a default filter with this value equals to true if they want to enforce by default this behaviour. I think that this a simpler idea for allow the developer to choose, and give some flexibility to the user to change the behaviour as its own risk (they can disable all filters anyway, which is also risky).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3454#issuecomment-323698699:400,depend,depending,400,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3454#issuecomment-323698699,2,['depend'],['depending']
Integrability,For some reason the java 11 integration test seem to fail with 137 at a higher rate than other tests. Maybe it used more memory some how? (This is unrelated to the change in this PR),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6210#issuecomment-541212785:28,integrat,integration,28,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6210#issuecomment-541212785,1,['integrat'],['integration']
Integrability,"For testing #3069, creating a Java test that shows that the GKL messages are controlled by the [log4j logLevel](https://www.tutorialspoint.com/log4j/log4j_logging_levels.htm).; Also, this branch should be rebased. A fix for the test failures, due to an issue with 2 factor authentication for [GIt Large File Storage](https://git-lfs.github.com/) of test data was recently merged.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312404141:64,message,messages,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312404141,1,['message'],['messages']
Integrability,"For the FASTQ input in Hadoop (and thus, Spark), there is a small library called [FastDoop](https://www.ncbi.nlm.nih.gov/pubmed/28093410) that I found time ago. Today it looks like the page is not working, but this could be (maybe) integrated into Hadoop-BAM/disq and it can help reading FASTQ from Spark",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4612#issuecomment-405072736:232,integrat,integrated,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4612#issuecomment-405072736,1,['integrat'],['integrated']
Integrability,"For the record, I'm not thrilled with what the dynamic pruning has done to the MT integration test output compared to the old --min-pruning 5 argument, but for some reason the coverage in that bam ramps up pretty slowly, so it's not representative of our WGS data. But I'd like to see some more analysis of the dynamic pruning for exomes before this goes into our exome pipeline in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5312#issuecomment-448737667:82,integrat,integration,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5312#issuecomment-448737667,1,['integrat'],['integration']
Integrability,"For the second option I get the following error message (cloud prefetch buffer = 0):. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr1:1+ --cloudPrefetchBuffer 0 --cloudIndexPrefetchBuffer 0; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.AtXpRI; [July 24, 2017 5:46:26 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.recal_data.csv --intervals chr1:1+ --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --reference /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta --cloudPrefetchBuffer 0 --cloudInd",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:48,message,message,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138,1,['message'],['message']
Integrability,"For this first-pass documentation, the goal was to add a `@DocumentedFeature` tag _only_. I also added in example use commands from the repo's WDL scripts, if available, or scoured the integration test for an example command. Testing of the commands was extremely limited. Some tools required discussion to decide how to archive. Finally, I completely overhauled the Mutect2 documentation, which reflected GATK3's M2.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3055#issuecomment-306854889:185,integrat,integration,185,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3055#issuecomment-306854889,1,['integrat'],['integration']
Integrability,"For what it's worth, this works but I should improve the error message. If you don't have the right permissions, currently you get an error that's something like this:. ```; htsjdk.samtools.util.RuntimeIOException: Error opening file: file:///home/jpmartin//gatk/gs:/bobs-bucket-you-cant-write-to/test-output/printtogcs.bam; ```. This is both; - confusing: it makes it look like the path is wrong even though the code actually tried the correct path; - improvable: it'd be nice if we gave the reason there was an error (403 Forbidden: user jpmartin doesn't have write access)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2422#issuecomment-342255531:63,message,message,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2422#issuecomment-342255531,1,['message'],['message']
Integrability,"Friendly reminder here: even if the interface is going to change, this method only needs to be renamed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2360#issuecomment-278243924:36,interface,interface,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2360#issuecomment-278243924,1,['interface'],['interface']
Integrability,"From the new message you are getting (Sample ""$1"" already has coverage metadata annotations), I’m guessing that both of your samples have the same name (“$1”). I would fix this upstream in the BAMs. Again, the forum is a better place for this kind of discussion, as other users can participate (as well as search previous posts)—GitHub issues lose a lot of visibility once they are closed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6217#issuecomment-543127386:13,message,message,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6217#issuecomment-543127386,1,['message'],['message']
Integrability,"GATK version of collect sequencing artifact metrics has bugs. You have to use Picard version as workaround, but the output of Picard must be changed. @sooheelee your input file is also busted. The errors you are getting are in dependencies of FilterByOrientationBias. Also, I don't think you can just cut and paste the sed command from the WDL (Don't ask.... Subtleties of WDL parsing). . Vcf vs tar.gz is in the engine. Maybe the VCF writer does not look at the extension when doing a VCF write? Therefore, maybe FilterByOrientationBias will write VCF no matter what the extension? does not automatically write the proper output? @lbergelson might know",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306456760:227,depend,dependencies,227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306456760,1,['depend'],['dependencies']
Integrability,"Gatk builds with whatever version of gradle it claims to build against, currently 5.4.1. We don't generally support other versions. However, I just tested locally using gradle 5.6 and it worked fine. . I suspect there is probably some other issue with the way you are building it. Are you trying to build it in an offline mode somehow? It looks like maybe you're trying to use a tarball to provide the dependencies instead of letting gradle resolve them for you? I would look into that as a possible cause of problems.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6097#issuecomment-523209763:402,depend,dependencies,402,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6097#issuecomment-523209763,1,['depend'],['dependencies']
Integrability,"GenomicsDB integration tests pass on my local system, but fails in Travis. Looking at this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294224976:11,integrat,integration,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294224976,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [10306895203](https://github.com/broadinstitute/gatk/actions/runs/10306895203); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [10306895203.10](https://github.com/broadinstitute/gatk/actions/runs/10306895203/job/28530966170) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8712/merge_10306895203.10/tests/test/index.html) |; | unit | 17.0.6+10 | [10306895203.12](https://github.com/broadinstitute/gatk/actions/runs/10306895203/job/28530966710) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8712/merge_10306895203.12/tests/test/index.html) |; | integration | 17.0.6+10 | [10306895203.11](https://github.com/broadinstitute/gatk/actions/runs/10306895203/job/28530966455) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8712/merge_10306895203.11/tests/test/index.html) |; | unit | 17.0.6+10 | [10306895203.1](https://github.com/broadinstitute/gatk/actions/runs/10306895203/job/28531633980) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8712/merge_10306895203.1/tests/test/index.html) |; | variantcalling | 17.0.6+10 | [10306895203.2](https://github.com/broadinstitute/gatk/actions/runs/10306895203/job/28531634204) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8712/merge_10306895203.2/tests/test/index.html) |; | integration | 17.0.6+10 | [10306895203.0](https://github.com/broadinstitute/gatk/actions/runs/10306895203/job/28531633667) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8712/merge_10306895203.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8712#issuecomment-2276373624:744,integrat,integration,744,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8712#issuecomment-2276373624,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [10373907397](https://github.com/broadinstitute/gatk/actions/runs/10373907397); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [10373907397.11](https://github.com/broadinstitute/gatk/actions/runs/10373907397/job/28720136543) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8951/merge_10373907397.11/tests/test/index.html) |; | integration | 17.0.6+10 | [10373907397.0](https://github.com/broadinstitute/gatk/actions/runs/10373907397/job/28720895477) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8951/merge_10373907397.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8951#issuecomment-2286758498:251,integrat,integration,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8951#issuecomment-2286758498,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [10457568370](https://github.com/broadinstitute/gatk/actions/runs/10457568370); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [10457568370.11](https://github.com/broadinstitute/gatk/actions/runs/10457568370/job/28957496196) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6388/merge_10457568370.11/tests/test/index.html) |; | integration | 17.0.6+10 | [10457568370.0](https://github.com/broadinstitute/gatk/actions/runs/10457568370/job/28958237124) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6388/merge_10457568370.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6388#issuecomment-2297071361:251,integrat,integration,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6388#issuecomment-2297071361,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [10457619605](https://github.com/broadinstitute/gatk/actions/runs/10457619605); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [10457619605.11](https://github.com/broadinstitute/gatk/actions/runs/10457619605/job/28957665866) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6388/merge_10457619605.11/tests/test/index.html) |; | integration | 17.0.6+10 | [10457619605.0](https://github.com/broadinstitute/gatk/actions/runs/10457619605/job/28958407269) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6388/merge_10457619605.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6388#issuecomment-2297080911:251,integrat,integration,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6388#issuecomment-2297080911,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [10458689373](https://github.com/broadinstitute/gatk/actions/runs/10458689373); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [10458689373.11](https://github.com/broadinstitute/gatk/actions/runs/10458689373/job/28961069838) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6388/merge_10458689373.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6388#issuecomment-2297214567:251,integrat,integration,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6388#issuecomment-2297214567,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [10908982699](https://github.com/broadinstitute/gatk/actions/runs/10908982699); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [10908982699.11](https://github.com/broadinstitute/gatk/actions/runs/10908982699/job/30276194553) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6388/merge_10908982699.11/tests/test/index.html) |; | variantcalling | 17.0.6+10 | [10908982699.2](https://github.com/broadinstitute/gatk/actions/runs/10908982699/job/30276956567) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6388/merge_10908982699.2/tests/test/index.html) |; | integration | 17.0.6+10 | [10908982699.0](https://github.com/broadinstitute/gatk/actions/runs/10908982699/job/30276955816) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6388/merge_10908982699.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6388#issuecomment-2356697440:251,integrat,integration,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6388#issuecomment-2356697440,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [11076165405](https://github.com/broadinstitute/gatk/actions/runs/11076165405); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [11076165405.10](https://github.com/broadinstitute/gatk/actions/runs/11076165405/job/30778671475) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_11076165405.10/tests/test/index.html) |; | unit | 17.0.6+10 | [11076165405.12](https://github.com/broadinstitute/gatk/actions/runs/11076165405/job/30778672067) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_11076165405.12/tests/test/index.html) |; | integration | 17.0.6+10 | [11076165405.11](https://github.com/broadinstitute/gatk/actions/runs/11076165405/job/30778671856) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_11076165405.11/tests/test/index.html) |; | unit | 17.0.6+10 | [11076165405.1](https://github.com/broadinstitute/gatk/actions/runs/11076165405/job/30779373801) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_11076165405.1/tests/test/index.html) |; | conda | 17.0.6+10 | [11076165405.3](https://github.com/broadinstitute/gatk/actions/runs/11076165405/job/30779374453) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_11076165405.3/tests/test/index.html) |; | variantcalling | 17.0.6+10 | [11076165405.2](https://github.com/broadinstitute/gatk/actions/runs/11076165405/job/30779374174) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_11076165405.2/tests/test/index.html) |; | integration | 17.0.6+10 | [11076165405.0](https://github.com/broadinstitute/gatk/actions/runs/11076165405/job/30779373426) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_11076165405.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-2379901645:744,integrat,integration,744,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-2379901645,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [11077108461](https://github.com/broadinstitute/gatk/actions/runs/11077108461); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [11077108461.1](https://github.com/broadinstitute/gatk/actions/runs/11077108461/job/30782274824) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_11077108461.1/tests/test/index.html) |; | conda | 17.0.6+10 | [11077108461.3](https://github.com/broadinstitute/gatk/actions/runs/11077108461/job/30782275326) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_11077108461.3/tests/test/index.html) |; | variantcalling | 17.0.6+10 | [11077108461.2](https://github.com/broadinstitute/gatk/actions/runs/11077108461/job/30782275089) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_11077108461.2/tests/test/index.html) |; | integration | 17.0.6+10 | [11077108461.0](https://github.com/broadinstitute/gatk/actions/runs/11077108461/job/30782274559) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_11077108461.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-2380045868:994,integrat,integration,994,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-2380045868,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [11256533054](https://github.com/broadinstitute/gatk/actions/runs/11256533054); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [11256533054.11](https://github.com/broadinstitute/gatk/actions/runs/11256533054/job/31298663063) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8994/merge_11256533054.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [11256533054.0](https://github.com/broadinstitute/gatk/actions/runs/11256533054/job/31301133748) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8994/merge_11256533054.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8994#issuecomment-2402515117:251,integrat,integration,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8994#issuecomment-2402515117,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [11334895424](https://github.com/broadinstitute/gatk/actions/runs/11334895424); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [11334895424.10](https://github.com/broadinstitute/gatk/actions/runs/11334895424/job/31522009464) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8998/merge_11334895424.10/tests/test/index.html) |; | unit | 17.0.6+10 | [11334895424.12](https://github.com/broadinstitute/gatk/actions/runs/11334895424/job/31522009991) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8998/merge_11334895424.12/tests/test/index.html) |; | integration | 17.0.6+10 | [11334895424.11](https://github.com/broadinstitute/gatk/actions/runs/11334895424/job/31522009737) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8998/merge_11334895424.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8998#issuecomment-2412354402:744,integrat,integration,744,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8998#issuecomment-2412354402,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [11408724818](https://github.com/broadinstitute/gatk/actions/runs/11408724818); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [11408724818.10](https://github.com/broadinstitute/gatk/actions/runs/11408724818/job/31747528004) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/9006/merge_11408724818.10/tests/test/index.html) |; | integration | 17.0.6+10 | [11408724818.11](https://github.com/broadinstitute/gatk/actions/runs/11408724818/job/31747528375) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/9006/merge_11408724818.11/tests/test/index.html) |; | integration | 17.0.6+10 | [11408724818.0](https://github.com/broadinstitute/gatk/actions/runs/11408724818/job/31748238573) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/9006/merge_11408724818.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9006#issuecomment-2423006517:498,integrat,integration,498,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9006#issuecomment-2423006517,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [11409067427](https://github.com/broadinstitute/gatk/actions/runs/11409067427); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [11409067427.11](https://github.com/broadinstitute/gatk/actions/runs/11409067427/job/31748540734) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/9006/merge_11409067427.11/tests/test/index.html) |; | integration | 17.0.6+10 | [11409067427.0](https://github.com/broadinstitute/gatk/actions/runs/11409067427/job/31749260669) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/9006/merge_11409067427.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/9006#issuecomment-2423070770:251,integrat,integration,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/9006#issuecomment-2423070770,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [11502878660](https://github.com/broadinstitute/gatk/actions/runs/11502878660); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [11502878660.11](https://github.com/broadinstitute/gatk/actions/runs/11502878660/job/32018868714) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8994/merge_11502878660.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [11502878660.0](https://github.com/broadinstitute/gatk/actions/runs/11502878660/job/32021017757) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8994/merge_11502878660.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8994#issuecomment-2435729871:251,integrat,integration,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8994#issuecomment-2435729871,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [11506462963](https://github.com/broadinstitute/gatk/actions/runs/11506462963); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [11506462963.11](https://github.com/broadinstitute/gatk/actions/runs/11506462963/job/32030464680) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8994/merge_11506462963.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [11506462963.0](https://github.com/broadinstitute/gatk/actions/runs/11506462963/job/32032491397) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8994/merge_11506462963.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8994#issuecomment-2436278958:251,integrat,integration,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8994#issuecomment-2436278958,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [11506500757](https://github.com/broadinstitute/gatk/actions/runs/11506500757); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [11506500757.11](https://github.com/broadinstitute/gatk/actions/runs/11506500757/job/32030592345) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8994/merge_11506500757.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [11506500757.0](https://github.com/broadinstitute/gatk/actions/runs/11506500757/job/32032999607) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8994/merge_11506500757.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8994#issuecomment-2436283747:251,integrat,integration,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8994#issuecomment-2436283747,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [11519677920](https://github.com/broadinstitute/gatk/actions/runs/11519677920); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [11519677920.11](https://github.com/broadinstitute/gatk/actions/runs/11519677920/job/32069264945) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8994/merge_11519677920.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [11519677920.0](https://github.com/broadinstitute/gatk/actions/runs/11519677920/job/32072231495) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8994/merge_11519677920.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8994#issuecomment-2437992448:251,integrat,integration,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8994#issuecomment-2437992448,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [11580320242](https://github.com/broadinstitute/gatk/actions/runs/11580320242); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [11580320242.11](https://github.com/broadinstitute/gatk/actions/runs/11580320242/job/32238576982) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8994/merge_11580320242.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [11580320242.0](https://github.com/broadinstitute/gatk/actions/runs/11580320242/job/32242153407) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8994/merge_11580320242.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8994#issuecomment-2445116719:251,integrat,integration,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8994#issuecomment-2445116719,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [11619790404](https://github.com/broadinstitute/gatk/actions/runs/11619790404); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [11619790404.11](https://github.com/broadinstitute/gatk/actions/runs/11619790404/job/32360209107) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8994/merge_11619790404.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [11619790404.0](https://github.com/broadinstitute/gatk/actions/runs/11619790404/job/32364881248) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8994/merge_11619790404.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8994#issuecomment-2450850909:251,integrat,integration,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8994#issuecomment-2450850909,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2197878351](https://github.com/broadinstitute/gatk/actions/runs/2197878351); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 8 | [2197878351.10](https://github.com/broadinstitute/gatk/runs/6101272574?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7754/merge_2197878351.10/tests/test/index.html) |; | conda | 8 | [2197878351.3](https://github.com/broadinstitute/gatk/runs/6101486125?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7754/merge_2197878351.3/tests/test/index.html) |; | cloud | 11 | [2197878351.11](https://github.com/broadinstitute/gatk/runs/6101272683?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7754/merge_2197878351.11/tests/test/index.html) |; | unit | 11 | [2197878351.13](https://github.com/broadinstitute/gatk/runs/6101272825?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7754/merge_2197878351.13/tests/test/index.html) |; | integration | 11 | [2197878351.12](https://github.com/broadinstitute/gatk/runs/6101272758?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7754/merge_2197878351.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7754#issuecomment-1104403935:1188,integrat,integration,1188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7754#issuecomment-1104403935,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2202312023](https://github.com/broadinstitute/gatk/actions/runs/2202312023); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [2202312023.11](https://github.com/broadinstitute/gatk/runs/6113475598?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7754/merge_2202312023.11/tests/test/index.html) |; | cloud | 8 | [2202312023.10](https://github.com/broadinstitute/gatk/runs/6113475477?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7754/merge_2202312023.10/tests/test/index.html) |; | unit | 11 | [2202312023.13](https://github.com/broadinstitute/gatk/runs/6113475809?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7754/merge_2202312023.13/tests/test/index.html) |; | integration | 11 | [2202312023.12](https://github.com/broadinstitute/gatk/runs/6113475700?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7754/merge_2202312023.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7754#issuecomment-1105283632:955,integrat,integration,955,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7754#issuecomment-1105283632,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2202472504](https://github.com/broadinstitute/gatk/actions/runs/2202472504); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [2202472504.11](https://github.com/broadinstitute/gatk/runs/6113948244?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7754/merge_2202472504.11/tests/test/index.html) |; | cloud | 8 | [2202472504.10](https://github.com/broadinstitute/gatk/runs/6113948127?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7754/merge_2202472504.10/tests/test/index.html) |; | unit | 11 | [2202472504.13](https://github.com/broadinstitute/gatk/runs/6113948503?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7754/merge_2202472504.13/tests/test/index.html) |; | integration | 11 | [2202472504.12](https://github.com/broadinstitute/gatk/runs/6113948351?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7754/merge_2202472504.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7754#issuecomment-1105327695:955,integrat,integration,955,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7754#issuecomment-1105327695,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2202635208](https://github.com/broadinstitute/gatk/actions/runs/2202635208); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 8 | [2202635208.10](https://github.com/broadinstitute/gatk/runs/6114436585?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7754/merge_2202635208.10/tests/test/index.html) |; | cloud | 11 | [2202635208.11](https://github.com/broadinstitute/gatk/runs/6114436718?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7754/merge_2202635208.11/tests/test/index.html) |; | unit | 11 | [2202635208.13](https://github.com/broadinstitute/gatk/runs/6114436924?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7754/merge_2202635208.13/tests/test/index.html) |; | integration | 11 | [2202635208.12](https://github.com/broadinstitute/gatk/runs/6114436838?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7754/merge_2202635208.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7754#issuecomment-1105369370:955,integrat,integration,955,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7754#issuecomment-1105369370,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2203889963](https://github.com/broadinstitute/gatk/actions/runs/2203889963); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 8 | [2203889963.10](https://github.com/broadinstitute/gatk/runs/6118153873?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7725/merge_2203889963.10/tests/test/index.html) |; | cloud | 11 | [2203889963.11](https://github.com/broadinstitute/gatk/runs/6118154019?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7725/merge_2203889963.11/tests/test/index.html) |; | unit | 11 | [2203889963.13](https://github.com/broadinstitute/gatk/runs/6118154185?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7725/merge_2203889963.13/tests/test/index.html) |; | integration | 11 | [2203889963.12](https://github.com/broadinstitute/gatk/runs/6118154089?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7725/merge_2203889963.12/tests/test/index.html) |; | variantcalling | 8 | [2203889963.2](https://github.com/broadinstitute/gatk/runs/6118412844?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7725/merge_2203889963.2/tests/test/index.html) |; | unit | 8 | [2203889963.1](https://github.com/broadinstitute/gatk/runs/6118412791?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7725/merge_2203889963.1/tests/test/index.html) |; | integration | 8 | [2203889963.0](https://github.com/broadinstitute/gatk/runs/6118412714?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7725/merge_2203889963.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7725#issuecomment-1105687674:955,integrat,integration,955,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7725#issuecomment-1105687674,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2276753690](https://github.com/broadinstitute/gatk/actions/runs/2276753690); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [2276753690.12](https://github.com/broadinstitute/gatk/runs/6309340781?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7831/merge_2276753690.12/tests/test/index.html) |; | integration | 8 | [2276753690.0](https://github.com/broadinstitute/gatk/runs/6309618140?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7831/merge_2276753690.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7831#issuecomment-1118775058:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7831#issuecomment-1118775058,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2277372920](https://github.com/broadinstitute/gatk/actions/runs/2277372920); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [2277372920.12](https://github.com/broadinstitute/gatk/runs/6311175341?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7831/merge_2277372920.12/tests/test/index.html) |; | integration | 8 | [2277372920.0](https://github.com/broadinstitute/gatk/runs/6311448509?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7831/merge_2277372920.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7831#issuecomment-1118923778:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7831#issuecomment-1118923778,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2340788459](https://github.com/broadinstitute/gatk/actions/runs/2340788459); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 11 | [2340788459.13](https://github.com/broadinstitute/gatk/runs/6476976122?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7725/merge_2340788459.13/tests/test/index.html) |; | integration | 11 | [2340788459.12](https://github.com/broadinstitute/gatk/runs/6476975989?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7725/merge_2340788459.12/tests/test/index.html) |; | unit | 8 | [2340788459.1](https://github.com/broadinstitute/gatk/runs/6477229747?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7725/merge_2340788459.1/tests/test/index.html) |; | variantcalling | 8 | [2340788459.2](https://github.com/broadinstitute/gatk/runs/6477229827?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7725/merge_2340788459.2/tests/test/index.html) |; | integration | 8 | [2340788459.0](https://github.com/broadinstitute/gatk/runs/6477229638?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7725/merge_2340788459.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7725#issuecomment-1129240530:484,integrat,integration,484,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7725#issuecomment-1129240530,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2378038203](https://github.com/broadinstitute/gatk/actions/runs/2378038203); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 11 | [2378038203.13](https://github.com/broadinstitute/gatk/runs/6574035878?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7867/merge_2378038203.13/tests/test/index.html) |; | integration | 11 | [2378038203.12](https://github.com/broadinstitute/gatk/runs/6574035759?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7867/merge_2378038203.12/tests/test/index.html) |; | unit | 8 | [2378038203.1](https://github.com/broadinstitute/gatk/runs/6574403967?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7867/merge_2378038203.1/tests/test/index.html) |; | integration | 8 | [2378038203.0](https://github.com/broadinstitute/gatk/runs/6574403822?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7867/merge_2378038203.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7867#issuecomment-1135941657:484,integrat,integration,484,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7867#issuecomment-1135941657,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2417438811](https://github.com/broadinstitute/gatk/actions/runs/2417438811); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [2417438811.12](https://github.com/broadinstitute/gatk/runs/6677816873?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7877/merge_2417438811.12/tests/test/index.html) |; | variantcalling | 8 | [2417438811.2](https://github.com/broadinstitute/gatk/runs/6678051995?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7877/merge_2417438811.2/tests/test/index.html) |; | integration | 8 | [2417438811.0](https://github.com/broadinstitute/gatk/runs/6678051821?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7877/merge_2417438811.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7877#issuecomment-1142634454:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7877#issuecomment-1142634454,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2417458185](https://github.com/broadinstitute/gatk/actions/runs/2417458185); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [2417458185.12](https://github.com/broadinstitute/gatk/runs/6677872877?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7877/merge_2417458185.12/tests/test/index.html) |; | variantcalling | 8 | [2417458185.2](https://github.com/broadinstitute/gatk/runs/6678114978?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7877/merge_2417458185.2/tests/test/index.html) |; | integration | 8 | [2417458185.0](https://github.com/broadinstitute/gatk/runs/6678114844?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7877/merge_2417458185.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7877#issuecomment-1142635673:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7877#issuecomment-1142635673,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2423439288](https://github.com/broadinstitute/gatk/actions/runs/2423439288); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [2423439288.12](https://github.com/broadinstitute/gatk/runs/6695008456?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7876/merge_2423439288.12/tests/test/index.html) |; | variantcalling | 8 | [2423439288.2](https://github.com/broadinstitute/gatk/runs/6695362379?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7876/merge_2423439288.2/tests/test/index.html) |; | integration | 8 | [2423439288.0](https://github.com/broadinstitute/gatk/runs/6695362163?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7876/merge_2423439288.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1144004622:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1144004622,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2436334810](https://github.com/broadinstitute/gatk/actions/runs/2436334810); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [2436334810.12](https://github.com/broadinstitute/gatk/runs/6730565500?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7882/merge_2436334810.12/tests/test/index.html) |; | integration | 8 | [2436334810.0](https://github.com/broadinstitute/gatk/runs/6730848251?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7882/merge_2436334810.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7882#issuecomment-1146269102:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7882#issuecomment-1146269102,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2448670766](https://github.com/broadinstitute/gatk/actions/runs/2448670766); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [2448670766.12](https://github.com/broadinstitute/gatk/runs/6758056690?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7861/merge_2448670766.12/tests/test/index.html) |; | integration | 8 | [2448670766.0](https://github.com/broadinstitute/gatk/runs/6758409978?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7861/merge_2448670766.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7861#issuecomment-1147617711:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7861#issuecomment-1147617711,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2491072258](https://github.com/broadinstitute/gatk/actions/runs/2491072258); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [2491072258.12](https://github.com/broadinstitute/gatk/runs/6869349297?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7895/merge_2491072258.12/tests/test/index.html) |; | variantcalling | 8 | [2491072258.2](https://github.com/broadinstitute/gatk/runs/6869619555?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7895/merge_2491072258.2/tests/test/index.html) |; | integration | 8 | [2491072258.0](https://github.com/broadinstitute/gatk/runs/6869619367?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7895/merge_2491072258.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7895#issuecomment-1154454876:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7895#issuecomment-1154454876,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2497440564](https://github.com/broadinstitute/gatk/actions/runs/2497440564); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 8 | [2497440564.0](https://github.com/broadinstitute/gatk/runs/6887203664?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7900/merge_2497440564.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7900#issuecomment-1155678615:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7900#issuecomment-1155678615,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2503081068](https://github.com/broadinstitute/gatk/actions/runs/2503081068); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [2503081068.12](https://github.com/broadinstitute/gatk/runs/6902238052?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7900/merge_2503081068.12/tests/test/index.html) |; | integration | 8 | [2503081068.0](https://github.com/broadinstitute/gatk/runs/6902701791?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7900/merge_2503081068.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7900#issuecomment-1156619484:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7900#issuecomment-1156619484,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2531442755](https://github.com/broadinstitute/gatk/actions/runs/2531442755); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17 | [2531442755.11](https://github.com/broadinstitute/gatk/runs/6973910574?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7909/merge_2531442755.11/tests/test/index.html) |; | unit | 17 | [2531442755.13](https://github.com/broadinstitute/gatk/runs/6973910740?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7909/merge_2531442755.13/tests/test/index.html) |; | integration | 17 | [2531442755.12](https://github.com/broadinstitute/gatk/runs/6973910650?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7909/merge_2531442755.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7909#issuecomment-1160842433:720,integrat,integration,720,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7909#issuecomment-1160842433,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2570768583](https://github.com/broadinstitute/gatk/actions/runs/2570768583); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [2570768583.12](https://github.com/broadinstitute/gatk/runs/7077627519?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7911/merge_2570768583.12/tests/test/index.html) |; | integration | 8 | [2570768583.0](https://github.com/broadinstitute/gatk/runs/7077924735?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7911/merge_2570768583.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7911#issuecomment-1167674721:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7911#issuecomment-1167674721,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2576941157](https://github.com/broadinstitute/gatk/actions/runs/2576941157); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2576941157.13](https://github.com/broadinstitute/gatk/runs/7094712446?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7909/merge_2576941157.13/tests/test/index.html) |; | cloud | 17 | [2576941157.11](https://github.com/broadinstitute/gatk/runs/7094712153?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7909/merge_2576941157.11/tests/test/index.html) |; | integration | 17 | [2576941157.12](https://github.com/broadinstitute/gatk/runs/7094712288?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7909/merge_2576941157.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7909#issuecomment-1168815792:720,integrat,integration,720,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7909#issuecomment-1168815792,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2578792940](https://github.com/broadinstitute/gatk/actions/runs/2578792940); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17 | [2578792940.11](https://github.com/broadinstitute/gatk/runs/7100187282?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2578792940.11/tests/test/index.html) |; | unit | 17 | [2578792940.13](https://github.com/broadinstitute/gatk/runs/7100187475?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2578792940.13/tests/test/index.html) |; | integration | 17 | [2578792940.12](https://github.com/broadinstitute/gatk/runs/7100187372?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2578792940.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1169184718:720,integrat,integration,720,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1169184718,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2616727886](https://github.com/broadinstitute/gatk/actions/runs/2616727886); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 8 | [2616727886.10](https://github.com/broadinstitute/gatk/runs/7197942431?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7705/merge_2616727886.10/tests/test/index.html) |; | unit | 8 | [2616727886.1](https://github.com/broadinstitute/gatk/runs/7198387000?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7705/merge_2616727886.1/tests/test/index.html) |; | conda | 8 | [2616727886.3](https://github.com/broadinstitute/gatk/runs/7198387284?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7705/merge_2616727886.3/tests/test/index.html) |; | variantcalling | 8 | [2616727886.2](https://github.com/broadinstitute/gatk/runs/7198387163?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7705/merge_2616727886.2/tests/test/index.html) |; | integration | 8 | [2616727886.0](https://github.com/broadinstitute/gatk/runs/7198386819?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7705/merge_2616727886.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7705#issuecomment-1175124331:1191,integrat,integration,1191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7705#issuecomment-1175124331,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2624287216](https://github.com/broadinstitute/gatk/actions/runs/2624287216); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2624287216.13](https://github.com/broadinstitute/gatk/runs/7219164039?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2624287216.13/tests/test/index.html) |; | cloud | 17 | [2624287216.11](https://github.com/broadinstitute/gatk/runs/7219163821?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2624287216.11/tests/test/index.html) |; | integration | 17 | [2624287216.12](https://github.com/broadinstitute/gatk/runs/7219163922?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2624287216.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1176458883:720,integrat,integration,720,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1176458883,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2624794723](https://github.com/broadinstitute/gatk/actions/runs/2624794723); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2624794723.13](https://github.com/broadinstitute/gatk/runs/7220614154?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2624794723.13/tests/test/index.html) |; | cloud | 17 | [2624794723.11](https://github.com/broadinstitute/gatk/runs/7220613835?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2624794723.11/tests/test/index.html) |; | integration | 17 | [2624794723.12](https://github.com/broadinstitute/gatk/runs/7220613994?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2624794723.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1176547195:720,integrat,integration,720,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1176547195,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2625894786](https://github.com/broadinstitute/gatk/actions/runs/2625894786); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17 | [2625894786.11](https://github.com/broadinstitute/gatk/runs/7223674027?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2625894786.11/tests/test/index.html) |; | unit | 17 | [2625894786.13](https://github.com/broadinstitute/gatk/runs/7223674313?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2625894786.13/tests/test/index.html) |; | integration | 17 | [2625894786.12](https://github.com/broadinstitute/gatk/runs/7223674212?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2625894786.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1176808999:720,integrat,integration,720,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1176808999,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2632297364](https://github.com/broadinstitute/gatk/actions/runs/2632297364); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17 | [2632297364.11](https://github.com/broadinstitute/gatk/runs/7241470507?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2632297364.11/tests/test/index.html) |; | unit | 17 | [2632297364.13](https://github.com/broadinstitute/gatk/runs/7241470725?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2632297364.13/tests/test/index.html) |; | integration | 17 | [2632297364.12](https://github.com/broadinstitute/gatk/runs/7241470617?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2632297364.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1178238737:720,integrat,integration,720,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1178238737,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2650555864](https://github.com/broadinstitute/gatk/actions/runs/2650555864); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2650555864.13](https://github.com/broadinstitute/gatk/runs/7285220098?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2650555864.13/tests/test/index.html) |; | cloud | 17 | [2650555864.11](https://github.com/broadinstitute/gatk/runs/7285219849?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2650555864.11/tests/test/index.html) |; | integration | 17 | [2650555864.12](https://github.com/broadinstitute/gatk/runs/7285219955?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2650555864.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1180568227:720,integrat,integration,720,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1180568227,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2651609966](https://github.com/broadinstitute/gatk/actions/runs/2651609966); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2651609966.13](https://github.com/broadinstitute/gatk/runs/7288391428?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2651609966.13/tests/test/index.html) |; | cloud | 17 | [2651609966.11](https://github.com/broadinstitute/gatk/runs/7288391211?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2651609966.11/tests/test/index.html) |; | integration | 17 | [2651609966.12](https://github.com/broadinstitute/gatk/runs/7288391325?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2651609966.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1180752038:720,integrat,integration,720,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1180752038,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2652121060](https://github.com/broadinstitute/gatk/actions/runs/2652121060); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2652121060.13](https://github.com/broadinstitute/gatk/runs/7289856755?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2652121060.13/tests/test/index.html) |; | integration | 17 | [2652121060.12](https://github.com/broadinstitute/gatk/runs/7289856648?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2652121060.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1180844351:484,integrat,integration,484,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1180844351,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2659419378](https://github.com/broadinstitute/gatk/actions/runs/2659419378); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [2659419378.11](https://github.com/broadinstitute/gatk/runs/7310286079?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2659419378.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1182531235:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1182531235,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2663895457](https://github.com/broadinstitute/gatk/actions/runs/2663895457); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [2663895457.11](https://github.com/broadinstitute/gatk/runs/7322342036?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2663895457.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1183298739:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1183298739,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2693262585](https://github.com/broadinstitute/gatk/actions/runs/2693262585); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [2693262585.12](https://github.com/broadinstitute/gatk/runs/7397399484?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7950/merge_2693262585.12/tests/test/index.html) |; | integration | 8 | [2693262585.0](https://github.com/broadinstitute/gatk/runs/7397679404?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7950/merge_2693262585.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7950#issuecomment-1188323351:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7950#issuecomment-1188323351,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2698481980](https://github.com/broadinstitute/gatk/actions/runs/2698481980); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2698481980.1](https://github.com/broadinstitute/gatk/runs/7412135258?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2698481980.1/tests/test/index.html) |; | conda | 17 | [2698481980.3](https://github.com/broadinstitute/gatk/runs/7412135713?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2698481980.3/tests/test/index.html) |; | variantcalling | 17 | [2698481980.2](https://github.com/broadinstitute/gatk/runs/7412135511?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2698481980.2/tests/test/index.html) |; | integration | 17 | [2698481980.0](https://github.com/broadinstitute/gatk/runs/7412135090?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2698481980.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1189193868:959,integrat,integration,959,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1189193868,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2699842700](https://github.com/broadinstitute/gatk/actions/runs/2699842700); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2699842700.1](https://github.com/broadinstitute/gatk/runs/7416144565?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2699842700.1/tests/test/index.html) |; | conda | 17 | [2699842700.3](https://github.com/broadinstitute/gatk/runs/7416144869?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2699842700.3/tests/test/index.html) |; | variantcalling | 17 | [2699842700.2](https://github.com/broadinstitute/gatk/runs/7416144715?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2699842700.2/tests/test/index.html) |; | integration | 17 | [2699842700.0](https://github.com/broadinstitute/gatk/runs/7416144450?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2699842700.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1189469773:959,integrat,integration,959,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1189469773,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2701474410](https://github.com/broadinstitute/gatk/actions/runs/2701474410); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2701474410.1](https://github.com/broadinstitute/gatk/runs/7420494215?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2701474410.1/tests/test/index.html) |; | conda | 17 | [2701474410.3](https://github.com/broadinstitute/gatk/runs/7420494363?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2701474410.3/tests/test/index.html) |; | integration | 17 | [2701474410.0](https://github.com/broadinstitute/gatk/runs/7420494157?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2701474410.0/tests/test/index.html) |; | variantcalling | 17 | [2701474410.2](https://github.com/broadinstitute/gatk/runs/7420494303?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2701474410.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1189698211:716,integrat,integration,716,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1189698211,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2720043735](https://github.com/broadinstitute/gatk/actions/runs/2720043735); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 8 | [2720043735.10](https://github.com/broadinstitute/gatk/runs/7472470894?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7876/merge_2720043735.10/tests/test/index.html) |; | cloud | 11 | [2720043735.11](https://github.com/broadinstitute/gatk/runs/7472470975?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7876/merge_2720043735.11/tests/test/index.html) |; | integration | 11 | [2720043735.12](https://github.com/broadinstitute/gatk/runs/7472471058?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7876/merge_2720043735.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1192787919:720,integrat,integration,720,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1192787919,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2720146764](https://github.com/broadinstitute/gatk/actions/runs/2720146764); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 8 | [2720146764.10](https://github.com/broadinstitute/gatk/runs/7472760142?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7876/merge_2720146764.10/tests/test/index.html) |; | cloud | 11 | [2720146764.11](https://github.com/broadinstitute/gatk/runs/7472760234?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7876/merge_2720146764.11/tests/test/index.html) |; | integration | 11 | [2720146764.12](https://github.com/broadinstitute/gatk/runs/7472760331?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7876/merge_2720146764.12/tests/test/index.html) |; | integration | 8 | [2720146764.0](https://github.com/broadinstitute/gatk/runs/7473063142?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7876/merge_2720146764.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1192797932:720,integrat,integration,720,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7876#issuecomment-1192797932,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2734621260](https://github.com/broadinstitute/gatk/actions/runs/2734621260); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [2734621260.12](https://github.com/broadinstitute/gatk/runs/7506880045?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7963/merge_2734621260.12/tests/test/index.html) |; | integration | 8 | [2734621260.0](https://github.com/broadinstitute/gatk/runs/7507245512?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7963/merge_2734621260.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7963#issuecomment-1194546155:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7963#issuecomment-1194546155,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2748430417](https://github.com/broadinstitute/gatk/actions/runs/2748430417); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [2748430417.12](https://github.com/broadinstitute/gatk/runs/7545518939?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7959/merge_2748430417.12/tests/test/index.html) |; | integration | 8 | [2748430417.0](https://github.com/broadinstitute/gatk/runs/7545820416?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7959/merge_2748430417.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7959#issuecomment-1197134313:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7959#issuecomment-1197134313,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2767073402](https://github.com/broadinstitute/gatk/actions/runs/2767073402); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2767073402.1](https://github.com/broadinstitute/gatk/runs/7594026688?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2767073402.1/tests/test/index.html) |; | conda | 17 | [2767073402.3](https://github.com/broadinstitute/gatk/runs/7594026717?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2767073402.3/tests/test/index.html) |; | integration | 17 | [2767073402.0](https://github.com/broadinstitute/gatk/runs/7594026670?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2767073402.0/tests/test/index.html) |; | variantcalling | 17 | [2767073402.2](https://github.com/broadinstitute/gatk/runs/7594026710?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2767073402.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1200293366:716,integrat,integration,716,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1200293366,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2767370544](https://github.com/broadinstitute/gatk/actions/runs/2767370544); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2767370544.1](https://github.com/broadinstitute/gatk/runs/7594556557?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2767370544.1/tests/test/index.html) |; | conda | 17 | [2767370544.3](https://github.com/broadinstitute/gatk/runs/7594556598?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2767370544.3/tests/test/index.html) |; | variantcalling | 17 | [2767370544.2](https://github.com/broadinstitute/gatk/runs/7594556574?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2767370544.2/tests/test/index.html) |; | integration | 17 | [2767370544.0](https://github.com/broadinstitute/gatk/runs/7594556527?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2767370544.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1200308780:959,integrat,integration,959,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1200308780,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2799863346](https://github.com/broadinstitute/gatk/actions/runs/2799863346); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [2799863346.11](https://github.com/broadinstitute/gatk/runs/7681558357?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_2799863346.11/tests/test/index.html) |; | cloud | 8 | [2799863346.10](https://github.com/broadinstitute/gatk/runs/7681558292?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_2799863346.10/tests/test/index.html) |; | unit | 11 | [2799863346.13](https://github.com/broadinstitute/gatk/runs/7681558481?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_2799863346.13/tests/test/index.html) |; | integration | 11 | [2799863346.12](https://github.com/broadinstitute/gatk/runs/7681558411?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_2799863346.12/tests/test/index.html) |; | unit | 8 | [2799863346.1](https://github.com/broadinstitute/gatk/runs/7681860568?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_2799863346.1/tests/test/index.html) |; | integration | 8 | [2799863346.0](https://github.com/broadinstitute/gatk/runs/7681860483?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_2799863346.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1205825557:955,integrat,integration,955,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1205825557,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2811164603](https://github.com/broadinstitute/gatk/actions/runs/2811164603); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 11 | [2811164603.13](https://github.com/broadinstitute/gatk/runs/7709351619?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_2811164603.13/tests/test/index.html) |; | integration | 11 | [2811164603.12](https://github.com/broadinstitute/gatk/runs/7709351600?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_2811164603.12/tests/test/index.html) |; | unit | 8 | [2811164603.1](https://github.com/broadinstitute/gatk/runs/7709458914?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_2811164603.1/tests/test/index.html) |; | integration | 8 | [2811164603.0](https://github.com/broadinstitute/gatk/runs/7709458893?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_2811164603.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1207325010:484,integrat,integration,484,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1207325010,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2812723684](https://github.com/broadinstitute/gatk/actions/runs/2812723684); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [2812723684.12](https://github.com/broadinstitute/gatk/runs/7712955954?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_2812723684.12/tests/test/index.html) |; | integration | 8 | [2812723684.0](https://github.com/broadinstitute/gatk/runs/7713083486?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_2812723684.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1207412121:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1207412121,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2814070537](https://github.com/broadinstitute/gatk/actions/runs/2814070537); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 8 | [2814070537.0](https://github.com/broadinstitute/gatk/runs/7715915559?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_2814070537.0/tests/test/index.html) |; | integration | 8 | [2814070537.0](https://github.com/broadinstitute/gatk/runs/7717382208?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_2814070537.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1207497041:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1207497041,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2822355346](https://github.com/broadinstitute/gatk/actions/runs/2822355346); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 8 | [2822355346.0](https://github.com/broadinstitute/gatk/runs/7738412464?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_2822355346.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1208885303:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1208885303,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2837191529](https://github.com/broadinstitute/gatk/actions/runs/2837191529); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 8 | [2837191529.0](https://github.com/broadinstitute/gatk/runs/7780073761?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_2837191529.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1211550529:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1211550529,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2837453255](https://github.com/broadinstitute/gatk/actions/runs/2837453255); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 8 | [2837453255.0](https://github.com/broadinstitute/gatk/runs/7780706803?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_2837453255.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1211581646:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1211581646,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2841114156](https://github.com/broadinstitute/gatk/actions/runs/2841114156); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 11 | [2841114156.13](https://github.com/broadinstitute/gatk/runs/7790831538?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7987/merge_2841114156.13/tests/test/index.html) |; | integration | 11 | [2841114156.12](https://github.com/broadinstitute/gatk/runs/7790831392?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7987/merge_2841114156.12/tests/test/index.html) |; | unit | 8 | [2841114156.1](https://github.com/broadinstitute/gatk/runs/7791226570?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7987/merge_2841114156.1/tests/test/index.html) |; | integration | 8 | [2841114156.0](https://github.com/broadinstitute/gatk/runs/7791226407?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7987/merge_2841114156.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7987#issuecomment-1212211996:484,integrat,integration,484,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7987#issuecomment-1212211996,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2841313433](https://github.com/broadinstitute/gatk/actions/runs/2841313433); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 11 | [2841313433.13](https://github.com/broadinstitute/gatk/runs/7791447878?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7987/merge_2841313433.13/tests/test/index.html) |; | integration | 11 | [2841313433.12](https://github.com/broadinstitute/gatk/runs/7791447755?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7987/merge_2841313433.12/tests/test/index.html) |; | unit | 8 | [2841313433.1](https://github.com/broadinstitute/gatk/runs/7791753937?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7987/merge_2841313433.1/tests/test/index.html) |; | integration | 8 | [2841313433.0](https://github.com/broadinstitute/gatk/runs/7791753842?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7987/merge_2841313433.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7987#issuecomment-1212251246:484,integrat,integration,484,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7987#issuecomment-1212251246,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2842334324](https://github.com/broadinstitute/gatk/actions/runs/2842334324); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [2842334324.12](https://github.com/broadinstitute/gatk/runs/7794432889?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7987/merge_2842334324.12/tests/test/index.html) |; | integration | 8 | [2842334324.0](https://github.com/broadinstitute/gatk/runs/7794730422?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7987/merge_2842334324.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7987#issuecomment-1212462982:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7987#issuecomment-1212462982,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2842345810](https://github.com/broadinstitute/gatk/actions/runs/2842345810); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [2842345810.12](https://github.com/broadinstitute/gatk/runs/7794465491?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7987/merge_2842345810.12/tests/test/index.html) |; | integration | 8 | [2842345810.0](https://github.com/broadinstitute/gatk/runs/7794746770?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7987/merge_2842345810.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7987#issuecomment-1212460311:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7987#issuecomment-1212460311,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2842681984](https://github.com/broadinstitute/gatk/actions/runs/2842681984); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 8 | [2842681984.0](https://github.com/broadinstitute/gatk/runs/7795756893?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_2842681984.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1212545204:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1212545204,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2849712241](https://github.com/broadinstitute/gatk/actions/runs/2849712241); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 11 | [2849712241.13](https://github.com/broadinstitute/gatk/runs/7814604084?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7987/merge_2849712241.13/tests/test/index.html) |; | integration | 11 | [2849712241.12](https://github.com/broadinstitute/gatk/runs/7814604036?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7987/merge_2849712241.12/tests/test/index.html) |; | unit | 8 | [2849712241.1](https://github.com/broadinstitute/gatk/runs/7814789386?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7987/merge_2849712241.1/tests/test/index.html) |; | integration | 8 | [2849712241.0](https://github.com/broadinstitute/gatk/runs/7814789301?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7987/merge_2849712241.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7987#issuecomment-1213575789:484,integrat,integration,484,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7987#issuecomment-1213575789,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2856248753](https://github.com/broadinstitute/gatk/actions/runs/2856248753); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 8 | [2856248753.0](https://github.com/broadinstitute/gatk/runs/7827530131?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_2856248753.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1214412608:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1214412608,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2863005179](https://github.com/broadinstitute/gatk/actions/runs/2863005179); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 8 | [2863005179.0](https://github.com/broadinstitute/gatk/runs/7845114986?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_2863005179.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1215810989:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1215810989,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2863935609](https://github.com/broadinstitute/gatk/actions/runs/2863935609); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 8 | [2863935609.0](https://github.com/broadinstitute/gatk/runs/7847589930?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_2863935609.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1215989186:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1215989186,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2864043518](https://github.com/broadinstitute/gatk/actions/runs/2864043518); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 8 | [2864043518.0](https://github.com/broadinstitute/gatk/runs/7847893392?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_2864043518.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1216004358:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1216004358,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2870397534](https://github.com/broadinstitute/gatk/actions/runs/2870397534); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2870397534.1](https://github.com/broadinstitute/gatk/runs/7865544601?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2870397534.1/tests/test/index.html) |; | conda | 17 | [2870397534.3](https://github.com/broadinstitute/gatk/runs/7865544860?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2870397534.3/tests/test/index.html) |; | variantcalling | 17 | [2870397534.2](https://github.com/broadinstitute/gatk/runs/7865544721?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2870397534.2/tests/test/index.html) |; | integration | 17 | [2870397534.0](https://github.com/broadinstitute/gatk/runs/7865544456?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2870397534.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1217085196:959,integrat,integration,959,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1217085196,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2871220130](https://github.com/broadinstitute/gatk/actions/runs/2871220130); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [2871220130.12](https://github.com/broadinstitute/gatk/runs/7867510074?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7990/merge_2871220130.12/tests/test/index.html) |; | integration | 8 | [2871220130.0](https://github.com/broadinstitute/gatk/runs/7867787009?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7990/merge_2871220130.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7990#issuecomment-1217234050:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7990#issuecomment-1217234050,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2906922660](https://github.com/broadinstitute/gatk/actions/runs/2906922660); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [2906922660.11](https://github.com/broadinstitute/gatk/runs/7960689440?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2906922660.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1223063146:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1223063146,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2921600692](https://github.com/broadinstitute/gatk/actions/runs/2921600692); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [2921600692.12](https://github.com/broadinstitute/gatk/runs/8002247654?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7996/merge_2921600692.12/tests/test/index.html) |; | integration | 8 | [2921600692.0](https://github.com/broadinstitute/gatk/runs/8002589137?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7996/merge_2921600692.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7996#issuecomment-1226191978:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7996#issuecomment-1226191978,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2935907552](https://github.com/broadinstitute/gatk/actions/runs/2935907552); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [2935907552.11](https://github.com/broadinstitute/gatk/runs/8042744893?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.11/tests/test/index.html) |; | cloud | 8 | [2935907552.10](https://github.com/broadinstitute/gatk/runs/8042744743?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.10/tests/test/index.html) |; | unit | 11 | [2935907552.13](https://github.com/broadinstitute/gatk/runs/8042745129?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.13/tests/test/index.html) |; | integration | 11 | [2935907552.12](https://github.com/broadinstitute/gatk/runs/8042744999?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.12/tests/test/index.html) |; | conda | 8 | [2935907552.3](https://github.com/broadinstitute/gatk/runs/8043019512?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.3/tests/test/index.html) |; | unit | 8 | [2935907552.1](https://github.com/broadinstitute/gatk/runs/8043019322?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.1/tests/test/index.html) |; | variantcalling | 8 | [2935907552.2](https://github.com/broadinstitute/gatk/runs/8043019429?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_2935907552.2/tests/test/index.html) |; | integration | 8 | [2935907552.0](https://github.com/broadinstitute/gatk/runs/8043019196?check_sui,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1228829876:955,integrat,integration,955,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1228829876,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2950774906](https://github.com/broadinstitute/gatk/actions/runs/2950774906); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [2950774906.11](https://github.com/broadinstitute/gatk/runs/8077134348?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2950774906.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1230731679:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1230731679,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2959446389](https://github.com/broadinstitute/gatk/actions/runs/2959446389); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2959446389.1](https://github.com/broadinstitute/gatk/runs/8101806193?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2959446389.1/tests/test/index.html) |; | conda | 17 | [2959446389.3](https://github.com/broadinstitute/gatk/runs/8101806461?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2959446389.3/tests/test/index.html) |; | integration | 17 | [2959446389.0](https://github.com/broadinstitute/gatk/runs/8101806060?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2959446389.0/tests/test/index.html) |; | variantcalling | 17 | [2959446389.2](https://github.com/broadinstitute/gatk/runs/8101806317?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2959446389.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1232192115:716,integrat,integration,716,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1232192115,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2959822805](https://github.com/broadinstitute/gatk/actions/runs/2959822805); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2959822805.1](https://github.com/broadinstitute/gatk/runs/8102691660?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2959822805.1/tests/test/index.html) |; | conda | 17 | [2959822805.3](https://github.com/broadinstitute/gatk/runs/8102691853?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2959822805.3/tests/test/index.html) |; | integration | 17 | [2959822805.0](https://github.com/broadinstitute/gatk/runs/8102691580?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2959822805.0/tests/test/index.html) |; | variantcalling | 17 | [2959822805.2](https://github.com/broadinstitute/gatk/runs/8102691764?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2959822805.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1232236621:716,integrat,integration,716,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1232236621,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2964124733](https://github.com/broadinstitute/gatk/actions/runs/2964124733); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2964124733.1](https://github.com/broadinstitute/gatk/runs/8114655234?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2964124733.1/tests/test/index.html) |; | conda | 17 | [2964124733.3](https://github.com/broadinstitute/gatk/runs/8114655590?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2964124733.3/tests/test/index.html) |; | variantcalling | 17 | [2964124733.2](https://github.com/broadinstitute/gatk/runs/8114655395?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2964124733.2/tests/test/index.html) |; | integration | 17 | [2964124733.0](https://github.com/broadinstitute/gatk/runs/8114655035?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2964124733.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1232967615:959,integrat,integration,959,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1232967615,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2965310204](https://github.com/broadinstitute/gatk/actions/runs/2965310204); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2965310204.1](https://github.com/broadinstitute/gatk/runs/8118264930?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2965310204.1/tests/test/index.html) |; | conda | 17 | [2965310204.3](https://github.com/broadinstitute/gatk/runs/8118265254?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2965310204.3/tests/test/index.html) |; | integration | 17 | [2965310204.0](https://github.com/broadinstitute/gatk/runs/8118264729?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2965310204.0/tests/test/index.html) |; | variantcalling | 17 | [2965310204.2](https://github.com/broadinstitute/gatk/runs/8118265112?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2965310204.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1233173516:716,integrat,integration,716,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1233173516,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2965573763](https://github.com/broadinstitute/gatk/actions/runs/2965573763); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2965573763.1](https://github.com/broadinstitute/gatk/runs/8119138622?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2965573763.1/tests/test/index.html) |; | conda | 17 | [2965573763.3](https://github.com/broadinstitute/gatk/runs/8119138854?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2965573763.3/tests/test/index.html) |; | variantcalling | 17 | [2965573763.2](https://github.com/broadinstitute/gatk/runs/8119138713?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2965573763.2/tests/test/index.html) |; | integration | 17 | [2965573763.0](https://github.com/broadinstitute/gatk/runs/8119138496?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2965573763.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1233226669:959,integrat,integration,959,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1233226669,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2966654286](https://github.com/broadinstitute/gatk/actions/runs/2966654286); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2966654286.1](https://github.com/broadinstitute/gatk/runs/8122155906?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2966654286.1/tests/test/index.html) |; | conda | 17 | [2966654286.3](https://github.com/broadinstitute/gatk/runs/8122156215?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2966654286.3/tests/test/index.html) |; | integration | 17 | [2966654286.0](https://github.com/broadinstitute/gatk/runs/8122155735?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2966654286.0/tests/test/index.html) |; | variantcalling | 17 | [2966654286.2](https://github.com/broadinstitute/gatk/runs/8122156064?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2966654286.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1233395928:716,integrat,integration,716,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1233395928,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2968128596](https://github.com/broadinstitute/gatk/actions/runs/2968128596); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2968128596.1](https://github.com/broadinstitute/gatk/runs/8126000306?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2968128596.1/tests/test/index.html) |; | conda | 17 | [2968128596.3](https://github.com/broadinstitute/gatk/runs/8126000421?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2968128596.3/tests/test/index.html) |; | integration | 17 | [2968128596.0](https://github.com/broadinstitute/gatk/runs/8126000247?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2968128596.0/tests/test/index.html) |; | variantcalling | 17 | [2968128596.2](https://github.com/broadinstitute/gatk/runs/8126000360?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2968128596.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1233631990:716,integrat,integration,716,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1233631990,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2972474666](https://github.com/broadinstitute/gatk/actions/runs/2972474666); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2972474666.1](https://github.com/broadinstitute/gatk/runs/8138273675?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2972474666.1/tests/test/index.html) |; | variantcalling | 17 | [2972474666.2](https://github.com/broadinstitute/gatk/runs/8138273951?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2972474666.2/tests/test/index.html) |; | conda | 17 | [2972474666.3](https://github.com/broadinstitute/gatk/runs/8138274242?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2972474666.3/tests/test/index.html) |; | integration | 17 | [2972474666.0](https://github.com/broadinstitute/gatk/runs/8138273321?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2972474666.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1234422616:959,integrat,integration,959,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1234422616,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2973021281](https://github.com/broadinstitute/gatk/actions/runs/2973021281); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2973021281.1](https://github.com/broadinstitute/gatk/runs/8139821503?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2973021281.1/tests/test/index.html) |; | integration | 17 | [2973021281.0](https://github.com/broadinstitute/gatk/runs/8139821227?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2973021281.0/tests/test/index.html) |; | variantcalling | 17 | [2973021281.2](https://github.com/broadinstitute/gatk/runs/8139821753?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2973021281.2/tests/test/index.html) |; | conda | 17 | [2973021281.3](https://github.com/broadinstitute/gatk/runs/8139821972?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2973021281.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1234507046:482,integrat,integration,482,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1234507046,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2973346685](https://github.com/broadinstitute/gatk/actions/runs/2973346685); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2973346685.1](https://github.com/broadinstitute/gatk/runs/8140815478?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2973346685.1/tests/test/index.html) |; | conda | 17 | [2973346685.3](https://github.com/broadinstitute/gatk/runs/8140815759?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2973346685.3/tests/test/index.html) |; | integration | 17 | [2973346685.0](https://github.com/broadinstitute/gatk/runs/8140815339?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2973346685.0/tests/test/index.html) |; | variantcalling | 17 | [2973346685.2](https://github.com/broadinstitute/gatk/runs/8140815606?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2973346685.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1234563620:716,integrat,integration,716,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1234563620,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2974297830](https://github.com/broadinstitute/gatk/actions/runs/2974297830); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2974297830.1](https://github.com/broadinstitute/gatk/runs/8143510087?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2974297830.1/tests/test/index.html) |; | integration | 17 | [2974297830.0](https://github.com/broadinstitute/gatk/runs/8143509953?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2974297830.0/tests/test/index.html) |; | variantcalling | 17 | [2974297830.2](https://github.com/broadinstitute/gatk/runs/8143510198?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2974297830.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1234730732:482,integrat,integration,482,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1234730732,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2974887773](https://github.com/broadinstitute/gatk/actions/runs/2974887773); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2974887773.1](https://github.com/broadinstitute/gatk/runs/8145265747?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2974887773.1/tests/test/index.html) |; | variantcalling | 17 | [2974887773.2](https://github.com/broadinstitute/gatk/runs/8145265874?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2974887773.2/tests/test/index.html) |; | integration | 17 | [2974887773.0](https://github.com/broadinstitute/gatk/runs/8145265599?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2974887773.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1234820824:725,integrat,integration,725,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1234820824,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2979443533](https://github.com/broadinstitute/gatk/actions/runs/2979443533); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2979443533.1](https://github.com/broadinstitute/gatk/runs/8157564952?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2979443533.1/tests/test/index.html) |; | variantcalling | 17 | [2979443533.2](https://github.com/broadinstitute/gatk/runs/8157565098?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2979443533.2/tests/test/index.html) |; | integration | 17 | [2979443533.0](https://github.com/broadinstitute/gatk/runs/8157564771?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2979443533.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1235578469:725,integrat,integration,725,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1235578469,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [2980069635](https://github.com/broadinstitute/gatk/actions/runs/2980069635); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [2980069635.1](https://github.com/broadinstitute/gatk/runs/8159526146?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2980069635.1/tests/test/index.html) |; | variantcalling | 17 | [2980069635.2](https://github.com/broadinstitute/gatk/runs/8159526265?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2980069635.2/tests/test/index.html) |; | integration | 17 | [2980069635.0](https://github.com/broadinstitute/gatk/runs/8159526001?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7920/merge_2980069635.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1235676964:725,integrat,integration,725,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7920#issuecomment-1235676964,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3002176541](https://github.com/broadinstitute/gatk/actions/runs/3002176541); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [3002176541.11](https://github.com/broadinstitute/gatk/runs/8212856906?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.11/tests/test/index.html) |; | cloud | 8 | [3002176541.10](https://github.com/broadinstitute/gatk/runs/8212856796?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.10/tests/test/index.html) |; | unit | 11 | [3002176541.13](https://github.com/broadinstitute/gatk/runs/8212857102?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.13/tests/test/index.html) |; | integration | 11 | [3002176541.12](https://github.com/broadinstitute/gatk/runs/8212857016?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.12/tests/test/index.html) |; | unit | 8 | [3002176541.1](https://github.com/broadinstitute/gatk/runs/8213287905?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.1/tests/test/index.html) |; | integration | 8 | [3002176541.0](https://github.com/broadinstitute/gatk/runs/8213287794?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.0/tests/test/index.html) |; | variantcalling | 8 | [3002176541.2](https://github.com/broadinstitute/gatk/runs/8213288012?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3002176541.2/tests/test/index.html) |; | conda | 8 | [3002176541.3](https://github.com/broadinstitute/gatk/runs/8213288138?check_sui,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1238473387:955,integrat,integration,955,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1238473387,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3007621976](https://github.com/broadinstitute/gatk/actions/runs/3007621976); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17 | [3007621976.10](https://github.com/broadinstitute/gatk/runs/8227986354?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3007621976.10/tests/test/index.html) |; | unit | 17 | [3007621976.12](https://github.com/broadinstitute/gatk/runs/8227986607?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3007621976.12/tests/test/index.html) |; | integration | 17 | [3007621976.11](https://github.com/broadinstitute/gatk/runs/8227986474?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3007621976.11/tests/test/index.html) |; | unit | 17 | [3007621976.1](https://github.com/broadinstitute/gatk/runs/8228402523?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3007621976.1/tests/test/index.html) |; | integration | 17 | [3007621976.0](https://github.com/broadinstitute/gatk/runs/8228402396?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3007621976.0/tests/test/index.html) |; | variantcalling | 17 | [3007621976.2](https://github.com/broadinstitute/gatk/runs/8228402648?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3007621976.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1239359136:720,integrat,integration,720,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1239359136,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3010561778](https://github.com/broadinstitute/gatk/actions/runs/3010561778); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [3010561778.1](https://github.com/broadinstitute/gatk/runs/8237217523?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3010561778.1/tests/test/index.html) |; | integration | 17 | [3010561778.0](https://github.com/broadinstitute/gatk/runs/8237217381?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3010561778.0/tests/test/index.html) |; | variantcalling | 17 | [3010561778.2](https://github.com/broadinstitute/gatk/runs/8237217650?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3010561778.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1239912124:482,integrat,integration,482,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1239912124,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3011127108](https://github.com/broadinstitute/gatk/actions/runs/3011127108); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [3011127108.1](https://github.com/broadinstitute/gatk/runs/8238668704?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3011127108.1/tests/test/index.html) |; | variantcalling | 17 | [3011127108.2](https://github.com/broadinstitute/gatk/runs/8238668795?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3011127108.2/tests/test/index.html) |; | integration | 17 | [3011127108.0](https://github.com/broadinstitute/gatk/runs/8238668610?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3011127108.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1240010544:725,integrat,integration,725,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1240010544,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3024497902](https://github.com/broadinstitute/gatk/actions/runs/3024497902); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 8 | [3024497902.10](https://github.com/broadinstitute/gatk/runs/8276264935?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7705/merge_3024497902.10/tests/test/index.html) |; | unit | 8 | [3024497902.1](https://github.com/broadinstitute/gatk/runs/8276594766?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7705/merge_3024497902.1/tests/test/index.html) |; | conda | 8 | [3024497902.3](https://github.com/broadinstitute/gatk/runs/8276594992?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7705/merge_3024497902.3/tests/test/index.html) |; | integration | 8 | [3024497902.0](https://github.com/broadinstitute/gatk/runs/8276594669?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7705/merge_3024497902.0/tests/test/index.html) |; | variantcalling | 8 | [3024497902.2](https://github.com/broadinstitute/gatk/runs/8276594865?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7705/merge_3024497902.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7705#issuecomment-1242341221:949,integrat,integration,949,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7705#issuecomment-1242341221,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3024517679](https://github.com/broadinstitute/gatk/actions/runs/3024517679); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 8 | [3024517679.10](https://github.com/broadinstitute/gatk/runs/8276320214?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7705/merge_3024517679.10/tests/test/index.html) |; | unit | 8 | [3024517679.1](https://github.com/broadinstitute/gatk/runs/8276689991?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7705/merge_3024517679.1/tests/test/index.html) |; | conda | 8 | [3024517679.3](https://github.com/broadinstitute/gatk/runs/8276690175?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7705/merge_3024517679.3/tests/test/index.html) |; | variantcalling | 8 | [3024517679.2](https://github.com/broadinstitute/gatk/runs/8276690087?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7705/merge_3024517679.2/tests/test/index.html) |; | integration | 8 | [3024517679.0](https://github.com/broadinstitute/gatk/runs/8276689872?check_suite_focus=true) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7705/merge_3024517679.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7705#issuecomment-1242341845:1191,integrat,integration,1191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7705#issuecomment-1242341845,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3038992031](https://github.com/broadinstitute/gatk/actions/runs/3038992031); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3038992031.0](https://github.com/broadinstitute/gatk/actions/runs/3038992031/jobs/4893712003) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3038992031.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1244088726:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1244088726,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3045422563](https://github.com/broadinstitute/gatk/actions/runs/3045422563); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [3045422563.12](https://github.com/broadinstitute/gatk/actions/runs/3045422563/jobs/4906964457) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3045422563.12/tests/test/index.html) |; | integration | 17 | [3045422563.11](https://github.com/broadinstitute/gatk/actions/runs/3045422563/jobs/4906964341) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3045422563.11/tests/test/index.html) |; | unit | 17 | [3045422563.1](https://github.com/broadinstitute/gatk/actions/runs/3045422563/jobs/4907383659) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3045422563.1/tests/test/index.html) |; | conda | 17 | [3045422563.3](https://github.com/broadinstitute/gatk/actions/runs/3045422563/jobs/4907383882) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3045422563.3/tests/test/index.html) |; | variantcalling | 17 | [3045422563.2](https://github.com/broadinstitute/gatk/actions/runs/3045422563/jobs/4907383780) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3045422563.2/tests/test/index.html) |; | integration | 17 | [3045422563.0](https://github.com/broadinstitute/gatk/actions/runs/3045422563/jobs/4907383526) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3045422563.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1245443412:485,integrat,integration,485,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1245443412,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3046768438](https://github.com/broadinstitute/gatk/actions/runs/3046768438); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | conda | 17 | [3046768438.3](https://github.com/broadinstitute/gatk/actions/runs/3046768438/jobs/4910279512) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3046768438.3/tests/test/index.html) |; | unit | 17 | [3046768438.1](https://github.com/broadinstitute/gatk/actions/runs/3046768438/jobs/4910279289) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3046768438.1/tests/test/index.html) |; | integration | 17 | [3046768438.0](https://github.com/broadinstitute/gatk/actions/runs/3046768438/jobs/4910279126) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3046768438.0/tests/test/index.html) |; | variantcalling | 17 | [3046768438.2](https://github.com/broadinstitute/gatk/actions/runs/3046768438/jobs/4910279416) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3046768438.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1245723446:718,integrat,integration,718,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1245723446,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3047288660](https://github.com/broadinstitute/gatk/actions/runs/3047288660); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | conda | 17 | [3047288660.3](https://github.com/broadinstitute/gatk/actions/runs/3047288660/jobs/4911368598) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3047288660.3/tests/test/index.html) |; | unit | 17 | [3047288660.1](https://github.com/broadinstitute/gatk/actions/runs/3047288660/jobs/4911368369) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3047288660.1/tests/test/index.html) |; | variantcalling | 17 | [3047288660.2](https://github.com/broadinstitute/gatk/actions/runs/3047288660/jobs/4911368475) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3047288660.2/tests/test/index.html) |; | integration | 17 | [3047288660.0](https://github.com/broadinstitute/gatk/actions/runs/3047288660/jobs/4911368236) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3047288660.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1245832564:962,integrat,integration,962,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1245832564,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3047406737](https://github.com/broadinstitute/gatk/actions/runs/3047406737); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [3047406737.1](https://github.com/broadinstitute/gatk/actions/runs/3047406737/jobs/4911614795) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3047406737.1/tests/test/index.html) |; | conda | 17 | [3047406737.3](https://github.com/broadinstitute/gatk/actions/runs/3047406737/jobs/4911614986) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3047406737.3/tests/test/index.html) |; | variantcalling | 17 | [3047406737.2](https://github.com/broadinstitute/gatk/actions/runs/3047406737/jobs/4911614901) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3047406737.2/tests/test/index.html) |; | integration | 17 | [3047406737.0](https://github.com/broadinstitute/gatk/actions/runs/3047406737/jobs/4911614683) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3047406737.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1245845583:962,integrat,integration,962,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1245845583,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3053420783](https://github.com/broadinstitute/gatk/actions/runs/3053420783); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [3053420783.1](https://github.com/broadinstitute/gatk/actions/runs/3053420783/jobs/4924461648) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3053420783.1/tests/test/index.html) |; | conda | 17 | [3053420783.3](https://github.com/broadinstitute/gatk/actions/runs/3053420783/jobs/4924462042) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3053420783.3/tests/test/index.html) |; | variantcalling | 17 | [3053420783.2](https://github.com/broadinstitute/gatk/actions/runs/3053420783/jobs/4924461865) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3053420783.2/tests/test/index.html) |; | integration | 17 | [3053420783.0](https://github.com/broadinstitute/gatk/actions/runs/3053420783/jobs/4924461444) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3053420783.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1246904756:962,integrat,integration,962,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1246904756,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3053953098](https://github.com/broadinstitute/gatk/actions/runs/3053953098); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | conda | 17 | [3053953098.3](https://github.com/broadinstitute/gatk/actions/runs/3053953098/jobs/4925633723) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3053953098.3/tests/test/index.html) |; | unit | 17 | [3053953098.1](https://github.com/broadinstitute/gatk/actions/runs/3053953098/jobs/4925633450) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3053953098.1/tests/test/index.html) |; | variantcalling | 17 | [3053953098.2](https://github.com/broadinstitute/gatk/actions/runs/3053953098/jobs/4925633580) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3053953098.2/tests/test/index.html) |; | integration | 17 | [3053953098.0](https://github.com/broadinstitute/gatk/actions/runs/3053953098/jobs/4925633298) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3053953098.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1246998934:962,integrat,integration,962,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1246998934,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3054258770](https://github.com/broadinstitute/gatk/actions/runs/3054258770); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [3054258770.1](https://github.com/broadinstitute/gatk/actions/runs/3054258770/jobs/4926255413) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3054258770.1/tests/test/index.html) |; | conda | 17 | [3054258770.3](https://github.com/broadinstitute/gatk/actions/runs/3054258770/jobs/4926255605) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3054258770.3/tests/test/index.html) |; | variantcalling | 17 | [3054258770.2](https://github.com/broadinstitute/gatk/actions/runs/3054258770/jobs/4926255516) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3054258770.2/tests/test/index.html) |; | integration | 17 | [3054258770.0](https://github.com/broadinstitute/gatk/actions/runs/3054258770/jobs/4926255302) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3054258770.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1247043189:962,integrat,integration,962,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1247043189,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3054511752](https://github.com/broadinstitute/gatk/actions/runs/3054511752); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [3054511752.1](https://github.com/broadinstitute/gatk/actions/runs/3054511752/jobs/4926772450) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3054511752.1/tests/test/index.html) |; | conda | 17 | [3054511752.3](https://github.com/broadinstitute/gatk/actions/runs/3054511752/jobs/4926772646) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3054511752.3/tests/test/index.html) |; | variantcalling | 17 | [3054511752.2](https://github.com/broadinstitute/gatk/actions/runs/3054511752/jobs/4926772542) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3054511752.2/tests/test/index.html) |; | integration | 17 | [3054511752.0](https://github.com/broadinstitute/gatk/actions/runs/3054511752/jobs/4926772351) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3054511752.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1247089567:962,integrat,integration,962,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1247089567,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3054929408](https://github.com/broadinstitute/gatk/actions/runs/3054929408); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [3054929408.1](https://github.com/broadinstitute/gatk/actions/runs/3054929408/jobs/4927695468) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3054929408.1/tests/test/index.html) |; | conda | 17 | [3054929408.3](https://github.com/broadinstitute/gatk/actions/runs/3054929408/jobs/4927695744) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3054929408.3/tests/test/index.html) |; | integration | 17 | [3054929408.0](https://github.com/broadinstitute/gatk/actions/runs/3054929408/jobs/4927695281) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3054929408.0/tests/test/index.html) |; | variantcalling | 17 | [3054929408.2](https://github.com/broadinstitute/gatk/actions/runs/3054929408/jobs/4927695615) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3054929408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1247169079:718,integrat,integration,718,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1247169079,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3055474275](https://github.com/broadinstitute/gatk/actions/runs/3055474275); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [3055474275.1](https://github.com/broadinstitute/gatk/actions/runs/3055474275/jobs/4928900457) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3055474275.1/tests/test/index.html) |; | conda | 17 | [3055474275.3](https://github.com/broadinstitute/gatk/actions/runs/3055474275/jobs/4928900636) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3055474275.3/tests/test/index.html) |; | variantcalling | 17 | [3055474275.2](https://github.com/broadinstitute/gatk/actions/runs/3055474275/jobs/4928900525) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3055474275.2/tests/test/index.html) |; | integration | 17 | [3055474275.0](https://github.com/broadinstitute/gatk/actions/runs/3055474275/jobs/4928900359) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3055474275.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1247258818:962,integrat,integration,962,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1247258818,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3055560396](https://github.com/broadinstitute/gatk/actions/runs/3055560396); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3055560396.0](https://github.com/broadinstitute/gatk/actions/runs/3055560396/jobs/4929006211) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3055560396.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1247283324:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1247283324,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3056941027](https://github.com/broadinstitute/gatk/actions/runs/3056941027); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3056941027.0](https://github.com/broadinstitute/gatk/actions/runs/3056941027/jobs/4931784084) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3056941027.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1247466306:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1247466306,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3060958649](https://github.com/broadinstitute/gatk/actions/runs/3060958649); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3060958649.0](https://github.com/broadinstitute/gatk/actions/runs/3060958649/jobs/4940525959) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3060958649.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1248232272:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1248232272,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3061340088](https://github.com/broadinstitute/gatk/actions/runs/3061340088); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3061340088.0](https://github.com/broadinstitute/gatk/actions/runs/3061340088/jobs/4941411487) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3061340088.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1248289732:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1248289732,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3061391635](https://github.com/broadinstitute/gatk/actions/runs/3061391635); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3061391635.0](https://github.com/broadinstitute/gatk/actions/runs/3061391635/jobs/4941564282) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3061391635.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1248312709:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1248312709,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3062119651](https://github.com/broadinstitute/gatk/actions/runs/3062119651); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3062119651.11](https://github.com/broadinstitute/gatk/actions/runs/3062119651/jobs/4942731721) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3062119651.11/tests/test/index.html) |; | integration | 17 | [3062119651.0](https://github.com/broadinstitute/gatk/actions/runs/3062119651/jobs/4942968022) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3062119651.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1248388960:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1248388960,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3062964783](https://github.com/broadinstitute/gatk/actions/runs/3062964783); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3062964783.0](https://github.com/broadinstitute/gatk/actions/runs/3062964783/jobs/4944804747) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3062964783.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1248556689:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1248556689,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3083014822](https://github.com/broadinstitute/gatk/actions/runs/3083014822); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17 | [3083014822.12](https://github.com/broadinstitute/gatk/actions/runs/3083014822/jobs/4983426332) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3083014822.12/tests/test/index.html) |; | unit | 17 | [3083014822.1](https://github.com/broadinstitute/gatk/actions/runs/3083014822/jobs/4983844294) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3083014822.1/tests/test/index.html) |; | integration | 17 | [3083014822.0](https://github.com/broadinstitute/gatk/actions/runs/3083014822/jobs/4983844159) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3083014822.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1251148362:719,integrat,integration,719,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1251148362,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3083956781](https://github.com/broadinstitute/gatk/actions/runs/3083956781); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3083956781.0](https://github.com/broadinstitute/gatk/actions/runs/3083956781/jobs/4985806540) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3083956781.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1251335271:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1251335271,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3084876395](https://github.com/broadinstitute/gatk/actions/runs/3084876395); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3084876395.0](https://github.com/broadinstitute/gatk/actions/runs/3084876395/jobs/4987811157) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3084876395.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1251502962:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1251502962,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3086099831](https://github.com/broadinstitute/gatk/actions/runs/3086099831); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3086099831.0](https://github.com/broadinstitute/gatk/actions/runs/3086099831/jobs/4990316799) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3086099831.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1251683568:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1251683568,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3090275384](https://github.com/broadinstitute/gatk/actions/runs/3090275384); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3090275384.0](https://github.com/broadinstitute/gatk/actions/runs/3090275384/jobs/4999186810) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3090275384.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1252417906:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1252417906,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3091522410](https://github.com/broadinstitute/gatk/actions/runs/3091522410); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3091522410.0](https://github.com/broadinstitute/gatk/actions/runs/3091522410/jobs/5002073301) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3091522410.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1252638802:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1252638802,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3092731818](https://github.com/broadinstitute/gatk/actions/runs/3092731818); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 8 | [3092731818.10](https://github.com/broadinstitute/gatk/actions/runs/3092731818/jobs/5004333411) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092731818.10/tests/test/index.html) |; | cloud | 11 | [3092731818.11](https://github.com/broadinstitute/gatk/actions/runs/3092731818/jobs/5004333541) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092731818.11/tests/test/index.html) |; | unit | 11 | [3092731818.13](https://github.com/broadinstitute/gatk/actions/runs/3092731818/jobs/5004333748) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092731818.13/tests/test/index.html) |; | integration | 11 | [3092731818.12](https://github.com/broadinstitute/gatk/actions/runs/3092731818/jobs/5004333644) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092731818.12/tests/test/index.html) |; | conda | 8 | [3092731818.3](https://github.com/broadinstitute/gatk/actions/runs/3092731818/jobs/5004627834) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092731818.3/tests/test/index.html) |; | unit | 8 | [3092731818.1](https://github.com/broadinstitute/gatk/actions/runs/3092731818/jobs/5004627636) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092731818.1/tests/test/index.html) |; | integration | 8 | [3092731818.0](https://github.com/broadinstitute/gatk/actions/runs/3092731818/jobs/5004627523) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092731818.0/tests/test/index.html) |; | variantcalling | 8 | [3092731818.2](https://github.com/broadinstitute/gatk/actions/runs/30927,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1252803679:958,integrat,integration,958,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1252803679,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3092772192](https://github.com/broadinstitute/gatk/actions/runs/3092772192); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3092772192.0](https://github.com/broadinstitute/gatk/actions/runs/3092772192/jobs/5004663204) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3092772192.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1252865820:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1252865820,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3092905417](https://github.com/broadinstitute/gatk/actions/runs/3092905417); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 8 | [3092905417.10](https://github.com/broadinstitute/gatk/actions/runs/3092905417/jobs/5004691605) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092905417.10/tests/test/index.html) |; | cloud | 11 | [3092905417.11](https://github.com/broadinstitute/gatk/actions/runs/3092905417/jobs/5004691712) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092905417.11/tests/test/index.html) |; | unit | 11 | [3092905417.13](https://github.com/broadinstitute/gatk/actions/runs/3092905417/jobs/5004691976) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092905417.13/tests/test/index.html) |; | integration | 11 | [3092905417.12](https://github.com/broadinstitute/gatk/actions/runs/3092905417/jobs/5004691810) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092905417.12/tests/test/index.html) |; | unit | 8 | [3092905417.1](https://github.com/broadinstitute/gatk/actions/runs/3092905417/jobs/5004926160) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092905417.1/tests/test/index.html) |; | conda | 8 | [3092905417.3](https://github.com/broadinstitute/gatk/actions/runs/3092905417/jobs/5004926443) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092905417.3/tests/test/index.html) |; | variantcalling | 8 | [3092905417.2](https://github.com/broadinstitute/gatk/actions/runs/3092905417/jobs/5004926310) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3092905417.2/tests/test/index.html) |; | integration | 8 | [3092905417.0](https://github.com/broadinstitute/gatk/actions/runs/30929,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1252832367:958,integrat,integration,958,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1252832367,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3093286177](https://github.com/broadinstitute/gatk/actions/runs/3093286177); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3093286177.0](https://github.com/broadinstitute/gatk/actions/runs/3093286177/jobs/5005785965) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3093286177.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1252948957:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1252948957,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3128179115](https://github.com/broadinstitute/gatk/actions/runs/3128179115); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3128179115.0](https://github.com/broadinstitute/gatk/actions/runs/3128179115/jobs/5076048173) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8013/merge_3128179115.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1258151344:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8013#issuecomment-1258151344,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3128674181](https://github.com/broadinstitute/gatk/actions/runs/3128674181); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3128674181.0](https://github.com/broadinstitute/gatk/actions/runs/3128674181/jobs/5077172442) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8035/merge_3128674181.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1258254849:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1258254849,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3129008425](https://github.com/broadinstitute/gatk/actions/runs/3129008425); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [3129008425.12](https://github.com/broadinstitute/gatk/actions/runs/3129008425/jobs/5077559800) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7996/merge_3129008425.12/tests/test/index.html) |; | integration | 8 | [3129008425.0](https://github.com/broadinstitute/gatk/actions/runs/3129008425/jobs/5077899371) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7996/merge_3129008425.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7996#issuecomment-1258282095:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7996#issuecomment-1258282095,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3130948787](https://github.com/broadinstitute/gatk/actions/runs/3130948787); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3130948787.0](https://github.com/broadinstitute/gatk/actions/runs/3130948787/jobs/5082041065) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8035/merge_3130948787.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1258678608:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1258678608,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3132106780](https://github.com/broadinstitute/gatk/actions/runs/3132106780); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3132106780.0](https://github.com/broadinstitute/gatk/actions/runs/3132106780/jobs/5084279021) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8035/merge_3132106780.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1258858794:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1258858794,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3136014671](https://github.com/broadinstitute/gatk/actions/runs/3136014671); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3136014671.0](https://github.com/broadinstitute/gatk/actions/runs/3136014671/jobs/5092799076) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8035/merge_3136014671.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1259613815:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1259613815,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3160429275](https://github.com/broadinstitute/gatk/actions/runs/3160429275); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [3160429275.12](https://github.com/broadinstitute/gatk/actions/runs/3160429275/jobs/5144877638) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7996/merge_3160429275.12/tests/test/index.html) |; | integration | 8 | [3160429275.0](https://github.com/broadinstitute/gatk/actions/runs/3160429275/jobs/5145085214) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7996/merge_3160429275.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7996#issuecomment-1263851972:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7996#issuecomment-1263851972,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3236342061](https://github.com/broadinstitute/gatk/actions/runs/3236342061); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3236342061.0](https://github.com/broadinstitute/gatk/actions/runs/3236342061/jobs/5302299817) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8035/merge_3236342061.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1276523129:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1276523129,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3237120012](https://github.com/broadinstitute/gatk/actions/runs/3237120012); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3237120012.0](https://github.com/broadinstitute/gatk/actions/runs/3237120012/jobs/5304090787) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8035/merge_3237120012.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1276669589:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1276669589,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3255713647](https://github.com/broadinstitute/gatk/actions/runs/3255713647); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 8 | [3255713647.10](https://github.com/broadinstitute/gatk/actions/runs/3255713647/jobs/5345313263) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8031/merge_3255713647.10/tests/test/index.html) |; | cloud | 11 | [3255713647.11](https://github.com/broadinstitute/gatk/actions/runs/3255713647/jobs/5345313299) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8031/merge_3255713647.11/tests/test/index.html) |; | unit | 11 | [3255713647.13](https://github.com/broadinstitute/gatk/actions/runs/3255713647/jobs/5345313375) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8031/merge_3255713647.13/tests/test/index.html) |; | integration | 11 | [3255713647.12](https://github.com/broadinstitute/gatk/actions/runs/3255713647/jobs/5345313336) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8031/merge_3255713647.12/tests/test/index.html) |; | unit | 8 | [3255713647.1](https://github.com/broadinstitute/gatk/actions/runs/3255713647/jobs/5345411719) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8031/merge_3255713647.1/tests/test/index.html) |; | integration | 8 | [3255713647.0](https://github.com/broadinstitute/gatk/actions/runs/3255713647/jobs/5345411665) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8031/merge_3255713647.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8031#issuecomment-1279740580:958,integrat,integration,958,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8031#issuecomment-1279740580,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3255830437](https://github.com/broadinstitute/gatk/actions/runs/3255830437); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 11 | [3255830437.13](https://github.com/broadinstitute/gatk/actions/runs/3255830437/jobs/5345561079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8031/merge_3255830437.13/tests/test/index.html) |; | integration | 11 | [3255830437.12](https://github.com/broadinstitute/gatk/actions/runs/3255830437/jobs/5345561038) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8031/merge_3255830437.12/tests/test/index.html) |; | unit | 8 | [3255830437.1](https://github.com/broadinstitute/gatk/actions/runs/3255830437/jobs/5345658062) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8031/merge_3255830437.1/tests/test/index.html) |; | integration | 8 | [3255830437.0](https://github.com/broadinstitute/gatk/actions/runs/3255830437/jobs/5345658041) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8031/merge_3255830437.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8031#issuecomment-1279749841:485,integrat,integration,485,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8031#issuecomment-1279749841,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3257265858](https://github.com/broadinstitute/gatk/actions/runs/3257265858); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 11 | [3257265858.13](https://github.com/broadinstitute/gatk/actions/runs/3257265858/jobs/5348425153) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8031/merge_3257265858.13/tests/test/index.html) |; | integration | 11 | [3257265858.12](https://github.com/broadinstitute/gatk/actions/runs/3257265858/jobs/5348425128) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8031/merge_3257265858.12/tests/test/index.html) |; | unit | 8 | [3257265858.1](https://github.com/broadinstitute/gatk/actions/runs/3257265858/jobs/5348526142) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8031/merge_3257265858.1/tests/test/index.html) |; | integration | 8 | [3257265858.0](https://github.com/broadinstitute/gatk/actions/runs/3257265858/jobs/5348526035) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8031/merge_3257265858.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8031#issuecomment-1279843041:485,integrat,integration,485,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8031#issuecomment-1279843041,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3259842595](https://github.com/broadinstitute/gatk/actions/runs/3259842595); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [3259842595.12](https://github.com/broadinstitute/gatk/actions/runs/3259842595/jobs/5352969945) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8031/merge_3259842595.12/tests/test/index.html) |; | integration | 8 | [3259842595.0](https://github.com/broadinstitute/gatk/actions/runs/3259842595/jobs/5353055477) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8031/merge_3259842595.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8031#issuecomment-1279991519:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8031#issuecomment-1279991519,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3284842037](https://github.com/broadinstitute/gatk/actions/runs/3284842037); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 8 | [3284842037.0](https://github.com/broadinstitute/gatk/actions/runs/3284842037/jobs/5411512260) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8064/merge_3284842037.0/tests/test/index.html) |; | integration | 8 | [3284842037.0](https://github.com/broadinstitute/gatk/actions/runs/3284842037/jobs/5432877133) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8064/merge_3284842037.0/tests/test/index.html) |; | integration | 8 | [3284842037.0](https://github.com/broadinstitute/gatk/actions/runs/3284842037/jobs/5645278312) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8064/merge_3284842037.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8064#issuecomment-1284623406:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8064#issuecomment-1284623406,3,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3291375153](https://github.com/broadinstitute/gatk/actions/runs/3291375153); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 8 | [3291375153.10](https://github.com/broadinstitute/gatk/actions/runs/3291375153/jobs/5425447220) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3291375153.10/tests/test/index.html) |; | cloud | 11 | [3291375153.11](https://github.com/broadinstitute/gatk/actions/runs/3291375153/jobs/5425447314) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3291375153.11/tests/test/index.html) |; | unit | 11 | [3291375153.13](https://github.com/broadinstitute/gatk/actions/runs/3291375153/jobs/5425447526) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3291375153.13/tests/test/index.html) |; | integration | 11 | [3291375153.12](https://github.com/broadinstitute/gatk/actions/runs/3291375153/jobs/5425447422) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3291375153.12/tests/test/index.html) |; | unit | 8 | [3291375153.1](https://github.com/broadinstitute/gatk/actions/runs/3291375153/jobs/5425749385) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3291375153.1/tests/test/index.html) |; | conda | 8 | [3291375153.3](https://github.com/broadinstitute/gatk/actions/runs/3291375153/jobs/5425749598) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3291375153.3/tests/test/index.html) |; | variantcalling | 8 | [3291375153.2](https://github.com/broadinstitute/gatk/actions/runs/3291375153/jobs/5425749495) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3291375153.2/tests/test/index.html) |; | integration | 8 | [3291375153.0](https://github.com/broadinstitute/gatk/actions/runs/32913,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1285871268:958,integrat,integration,958,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1285871268,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3300316784](https://github.com/broadinstitute/gatk/actions/runs/3300316784); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 8 | [3300316784.10](https://github.com/broadinstitute/gatk/actions/runs/3300316784/jobs/5444679663) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300316784.10/tests/test/index.html) |; | cloud | 11 | [3300316784.11](https://github.com/broadinstitute/gatk/actions/runs/3300316784/jobs/5444679780) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300316784.11/tests/test/index.html) |; | unit | 11 | [3300316784.13](https://github.com/broadinstitute/gatk/actions/runs/3300316784/jobs/5444679952) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300316784.13/tests/test/index.html) |; | integration | 11 | [3300316784.12](https://github.com/broadinstitute/gatk/actions/runs/3300316784/jobs/5444679868) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300316784.12/tests/test/index.html) |; | conda | 8 | [3300316784.3](https://github.com/broadinstitute/gatk/actions/runs/3300316784/jobs/5444871971) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300316784.3/tests/test/index.html) |; | unit | 8 | [3300316784.1](https://github.com/broadinstitute/gatk/actions/runs/3300316784/jobs/5444871800) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300316784.1/tests/test/index.html) |; | variantcalling | 8 | [3300316784.2](https://github.com/broadinstitute/gatk/actions/runs/3300316784/jobs/5444871887) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8004/merge_3300316784.2/tests/test/index.html) |; | integration | 8 | [3300316784.0](https://github.com/broadinstitute/gatk/actions/runs/33003,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1287429116:958,integrat,integration,958,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8004#issuecomment-1287429116,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3413577203](https://github.com/broadinstitute/gatk/actions/runs/3413577203); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3413577203.0](https://github.com/broadinstitute/gatk/actions/runs/3413577203/jobs/5680829507) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8035/merge_3413577203.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1306200873:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1306200873,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3441109117](https://github.com/broadinstitute/gatk/actions/runs/3441109117); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 8 | [3441109117.0](https://github.com/broadinstitute/gatk/actions/runs/3441109117/jobs/5740502374) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8064/merge_3441109117.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8064#issuecomment-1311079122:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8064#issuecomment-1311079122,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3463372954](https://github.com/broadinstitute/gatk/actions/runs/3463372954); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 8 | [3463372954.10](https://github.com/broadinstitute/gatk/actions/runs/3463372954/jobs/5783514970) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8092/merge_3463372954.10/tests/testOnPackagedReleaseJar/index.html) |; | cloud | 11 | [3463372954.11](https://github.com/broadinstitute/gatk/actions/runs/3463372954/jobs/5783515412) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8092/merge_3463372954.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 11 | [3463372954.12](https://github.com/broadinstitute/gatk/actions/runs/3463372954/jobs/5783515545) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8092/merge_3463372954.12/tests/testOnPackagedReleaseJar/index.html) |; | integration | 8 | [3463372954.0](https://github.com/broadinstitute/gatk/actions/runs/3463372954/jobs/5783843866) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8092/merge_3463372954.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8092#issuecomment-1314075494:762,integrat,integration,762,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8092#issuecomment-1314075494,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3499912997](https://github.com/broadinstitute/gatk/actions/runs/3499912997); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [3499912997.11](https://github.com/broadinstitute/gatk/actions/runs/3499912997/jobs/5862011952) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8098/merge_3499912997.11/tests/testOnPackagedReleaseJar/index.html) |; | unit | 11 | [3499912997.13](https://github.com/broadinstitute/gatk/actions/runs/3499912997/jobs/5862012197) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8098/merge_3499912997.13/tests/testOnPackagedReleaseJar/index.html) |; | integration | 11 | [3499912997.12](https://github.com/broadinstitute/gatk/actions/runs/3499912997/jobs/5862012078) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8098/merge_3499912997.12/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8098#issuecomment-1320492607:762,integrat,integration,762,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8098#issuecomment-1320492607,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3505269846](https://github.com/broadinstitute/gatk/actions/runs/3505269846); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [3505269846.11](https://github.com/broadinstitute/gatk/actions/runs/3505269846/jobs/5871471411) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8092/merge_3505269846.11/tests/testOnPackagedReleaseJar/index.html) |; | unit | 11 | [3505269846.13](https://github.com/broadinstitute/gatk/actions/runs/3505269846/jobs/5871471473) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8092/merge_3505269846.13/tests/testOnPackagedReleaseJar/index.html) |; | integration | 11 | [3505269846.12](https://github.com/broadinstitute/gatk/actions/runs/3505269846/jobs/5871471446) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8092/merge_3505269846.12/tests/testOnPackagedReleaseJar/index.html) |; | integration | 8 | [3505269846.0](https://github.com/broadinstitute/gatk/actions/runs/3505269846/jobs/5871574693) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8092/merge_3505269846.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8092#issuecomment-1320979732:762,integrat,integration,762,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8092#issuecomment-1320979732,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3515578568](https://github.com/broadinstitute/gatk/actions/runs/3515578568); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 11 | [3515578568.13](https://github.com/broadinstitute/gatk/actions/runs/3515578568/jobs/5891031712) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8099/merge_3515578568.13/tests/test/index.html) |; | cloud | 11 | [3515578568.11](https://github.com/broadinstitute/gatk/actions/runs/3515578568/jobs/5891031383) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8099/merge_3515578568.11/tests/test/index.html) |; | integration | 11 | [3515578568.12](https://github.com/broadinstitute/gatk/actions/runs/3515578568/jobs/5891031580) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8099/merge_3515578568.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8099#issuecomment-1322245188:722,integrat,integration,722,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8099#issuecomment-1322245188,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3516053178](https://github.com/broadinstitute/gatk/actions/runs/3516053178); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 11 | [3516053178.13](https://github.com/broadinstitute/gatk/actions/runs/3516053178/jobs/5892107837) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8093/merge_3516053178.13/tests/test/index.html) |; | cloud | 11 | [3516053178.11](https://github.com/broadinstitute/gatk/actions/runs/3516053178/jobs/5892107412) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8093/merge_3516053178.11/tests/test/index.html) |; | integration | 11 | [3516053178.12](https://github.com/broadinstitute/gatk/actions/runs/3516053178/jobs/5892107607) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8093/merge_3516053178.12/tests/test/index.html) |; | cloud | 11 | [3516053178.11](https://github.com/broadinstitute/gatk/actions/runs/3516053178/jobs/5893650279) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8093/merge_3516053178.11/tests/test/index.html) |; | cloud | 11 | [3516053178.11](https://github.com/broadinstitute/gatk/actions/runs/3516053178/jobs/5893979481) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8093/merge_3516053178.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8093#issuecomment-1322336708:722,integrat,integration,722,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8093#issuecomment-1322336708,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3518330277](https://github.com/broadinstitute/gatk/actions/runs/3518330277); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [3518330277.11](https://github.com/broadinstitute/gatk/actions/runs/3518330277/jobs/5897125265) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8074/merge_3518330277.11/tests/testOnPackagedReleaseJar/index.html) |; | unit | 11 | [3518330277.13](https://github.com/broadinstitute/gatk/actions/runs/3518330277/jobs/5897125458) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8074/merge_3518330277.13/tests/testOnPackagedReleaseJar/index.html) |; | integration | 11 | [3518330277.12](https://github.com/broadinstitute/gatk/actions/runs/3518330277/jobs/5897125359) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8074/merge_3518330277.12/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8074#issuecomment-1322708616:762,integrat,integration,762,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8074#issuecomment-1322708616,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3518606408](https://github.com/broadinstitute/gatk/actions/runs/3518606408); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [3518606408.11](https://github.com/broadinstitute/gatk/actions/runs/3518606408/jobs/5897707248) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8074/merge_3518606408.11/tests/testOnPackagedReleaseJar/index.html) |; | unit | 11 | [3518606408.13](https://github.com/broadinstitute/gatk/actions/runs/3518606408/jobs/5897707377) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8074/merge_3518606408.13/tests/testOnPackagedReleaseJar/index.html) |; | integration | 11 | [3518606408.12](https://github.com/broadinstitute/gatk/actions/runs/3518606408/jobs/5897707308) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8074/merge_3518606408.12/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8074#issuecomment-1322752951:762,integrat,integration,762,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8074#issuecomment-1322752951,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3518689409](https://github.com/broadinstitute/gatk/actions/runs/3518689409); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [3518689409.11](https://github.com/broadinstitute/gatk/actions/runs/3518689409/jobs/5897871892) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8074/merge_3518689409.11/tests/testOnPackagedReleaseJar/index.html) |; | unit | 11 | [3518689409.13](https://github.com/broadinstitute/gatk/actions/runs/3518689409/jobs/5897872048) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8074/merge_3518689409.13/tests/testOnPackagedReleaseJar/index.html) |; | integration | 11 | [3518689409.12](https://github.com/broadinstitute/gatk/actions/runs/3518689409/jobs/5897871968) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8074/merge_3518689409.12/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8074#issuecomment-1322767204:762,integrat,integration,762,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8074#issuecomment-1322767204,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3518744551](https://github.com/broadinstitute/gatk/actions/runs/3518744551); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [3518744551.11](https://github.com/broadinstitute/gatk/actions/runs/3518744551/jobs/5897977920) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8101/merge_3518744551.11/tests/test/index.html) |; | integration | 11 | [3518744551.12](https://github.com/broadinstitute/gatk/actions/runs/3518744551/jobs/5897978006) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8101/merge_3518744551.12/tests/test/index.html) |; | unit | 11 | [3518744551.13](https://github.com/broadinstitute/gatk/actions/runs/3518744551/jobs/5897978071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8101/merge_3518744551.13/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8101#issuecomment-1322777545:486,integrat,integration,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8101#issuecomment-1322777545,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3518769461](https://github.com/broadinstitute/gatk/actions/runs/3518769461); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [3518769461.11](https://github.com/broadinstitute/gatk/actions/runs/3518769461/jobs/5898028765) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8074/merge_3518769461.11/tests/testOnPackagedReleaseJar/index.html) |; | unit | 11 | [3518769461.13](https://github.com/broadinstitute/gatk/actions/runs/3518769461/jobs/5898028910) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8074/merge_3518769461.13/tests/testOnPackagedReleaseJar/index.html) |; | integration | 11 | [3518769461.12](https://github.com/broadinstitute/gatk/actions/runs/3518769461/jobs/5898028849) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8074/merge_3518769461.12/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8074#issuecomment-1322779428:762,integrat,integration,762,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8074#issuecomment-1322779428,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3527272492](https://github.com/broadinstitute/gatk/actions/runs/3527272492); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [3527272492.12](https://github.com/broadinstitute/gatk/actions/runs/3527272492/jobs/5916143702) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8100/merge_3527272492.12/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8100#issuecomment-1324310773:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8100#issuecomment-1324310773,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3533317748](https://github.com/broadinstitute/gatk/actions/runs/3533317748); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 11 | [3533317748.13](https://github.com/broadinstitute/gatk/actions/runs/3533317748/jobs/5928792369) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8104/merge_3533317748.13/tests/test/index.html) |; | integration | 11 | [3533317748.12](https://github.com/broadinstitute/gatk/actions/runs/3533317748/jobs/5928792214) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8104/merge_3533317748.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8104#issuecomment-1325279517:485,integrat,integration,485,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8104#issuecomment-1325279517,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3533672613](https://github.com/broadinstitute/gatk/actions/runs/3533672613); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [3533672613.12](https://github.com/broadinstitute/gatk/actions/runs/3533672613/jobs/5929604840) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8102/merge_3533672613.12/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8102#issuecomment-1325363886:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8102#issuecomment-1325363886,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3535155196](https://github.com/broadinstitute/gatk/actions/runs/3535155196); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [3535155196.11](https://github.com/broadinstitute/gatk/actions/runs/3535155196/jobs/5932850301) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8104/merge_3535155196.11/tests/test/index.html) |; | integration | 11 | [3535155196.12](https://github.com/broadinstitute/gatk/actions/runs/3535155196/jobs/5932850383) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8104/merge_3535155196.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8104#issuecomment-1325602734:486,integrat,integration,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8104#issuecomment-1325602734,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3535257980](https://github.com/broadinstitute/gatk/actions/runs/3535257980); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 11 | [3535257980.13](https://github.com/broadinstitute/gatk/actions/runs/3535257980/jobs/5933074644) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8104/merge_3535257980.13/tests/test/index.html) |; | integration | 11 | [3535257980.12](https://github.com/broadinstitute/gatk/actions/runs/3535257980/jobs/5933074567) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8104/merge_3535257980.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8104#issuecomment-1325616385:485,integrat,integration,485,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8104#issuecomment-1325616385,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3567484153](https://github.com/broadinstitute/gatk/actions/runs/3567484153); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 11 | [3567484153.13](https://github.com/broadinstitute/gatk/actions/runs/3567484153/jobs/5995241620) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8092/merge_3567484153.13/tests/testOnPackagedReleaseJar/index.html) |; | integration | 11 | [3567484153.12](https://github.com/broadinstitute/gatk/actions/runs/3567484153/jobs/5995241485) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8092/merge_3567484153.12/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8092#issuecomment-1329575212:505,integrat,integration,505,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8092#issuecomment-1329575212,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3567534442](https://github.com/broadinstitute/gatk/actions/runs/3567534442); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 11 | [3567534442.13](https://github.com/broadinstitute/gatk/actions/runs/3567534442/jobs/5995349540) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8092/merge_3567534442.13/tests/testOnPackagedReleaseJar/index.html) |; | integration | 11 | [3567534442.12](https://github.com/broadinstitute/gatk/actions/runs/3567534442/jobs/5995349354) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8092/merge_3567534442.12/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8092#issuecomment-1329590862:505,integrat,integration,505,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8092#issuecomment-1329590862,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3576877848](https://github.com/broadinstitute/gatk/actions/runs/3576877848); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [3576877848.12](https://github.com/broadinstitute/gatk/actions/runs/3576877848/jobs/6015212631) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8108/merge_3576877848.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8108#issuecomment-1331148538:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8108#issuecomment-1331148538,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3577067919](https://github.com/broadinstitute/gatk/actions/runs/3577067919); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 11 | [3577067919.13](https://github.com/broadinstitute/gatk/actions/runs/3577067919/jobs/6015631779) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8109/merge_3577067919.13/tests/test/index.html) |; | cloud | 11 | [3577067919.11](https://github.com/broadinstitute/gatk/actions/runs/3577067919/jobs/6015631549) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8109/merge_3577067919.11/tests/test/index.html) |; | integration | 11 | [3577067919.12](https://github.com/broadinstitute/gatk/actions/runs/3577067919/jobs/6015631662) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8109/merge_3577067919.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8109#issuecomment-1331171583:722,integrat,integration,722,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8109#issuecomment-1331171583,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3577583009](https://github.com/broadinstitute/gatk/actions/runs/3577583009); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11.0.11+9 | [3577583009.12](https://github.com/broadinstitute/gatk/actions/runs/3577583009/jobs/6016753335) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8111/merge_3577583009.12/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8111#issuecomment-1331281131:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8111#issuecomment-1331281131,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3577955591](https://github.com/broadinstitute/gatk/actions/runs/3577955591); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 11 | [3577955591.13](https://github.com/broadinstitute/gatk/actions/runs/3577955591/jobs/6017558771) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8113/merge_3577955591.13/tests/test/index.html) |; | cloud | 11 | [3577955591.11](https://github.com/broadinstitute/gatk/actions/runs/3577955591/jobs/6017558551) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8113/merge_3577955591.11/tests/test/index.html) |; | integration | 11 | [3577955591.12](https://github.com/broadinstitute/gatk/actions/runs/3577955591/jobs/6017558663) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8113/merge_3577955591.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8113#issuecomment-1331335209:722,integrat,integration,722,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8113#issuecomment-1331335209,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3577966142](https://github.com/broadinstitute/gatk/actions/runs/3577966142); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [3577966142.12](https://github.com/broadinstitute/gatk/actions/runs/3577966142/jobs/6017582191) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8113/merge_3577966142.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8113#issuecomment-1331352251:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8113#issuecomment-1331352251,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3578374711](https://github.com/broadinstitute/gatk/actions/runs/3578374711); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [3578374711.11](https://github.com/broadinstitute/gatk/actions/runs/3578374711/jobs/6018468343) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8113/merge_3578374711.11/tests/test/index.html) |; | integration | 11 | [3578374711.12](https://github.com/broadinstitute/gatk/actions/runs/3578374711/jobs/6018468484) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8113/merge_3578374711.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8113#issuecomment-1331402516:486,integrat,integration,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8113#issuecomment-1331402516,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3584250201](https://github.com/broadinstitute/gatk/actions/runs/3584250201); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 11 | [3584250201.13](https://github.com/broadinstitute/gatk/actions/runs/3584250201/jobs/6030684823) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8113/merge_3584250201.13/tests/test/index.html) |; | integration | 11 | [3584250201.12](https://github.com/broadinstitute/gatk/actions/runs/3584250201/jobs/6030684583) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8113/merge_3584250201.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8113#issuecomment-1332315343:485,integrat,integration,485,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8113#issuecomment-1332315343,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3587120976](https://github.com/broadinstitute/gatk/actions/runs/3587120976); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [3587120976.11](https://github.com/broadinstitute/gatk/actions/runs/3587120976/jobs/6037109523) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8116/merge_3587120976.11/tests/test/index.html) |; | unit | 11 | [3587120976.13](https://github.com/broadinstitute/gatk/actions/runs/3587120976/jobs/6037109732) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8116/merge_3587120976.13/tests/test/index.html) |; | integration | 11 | [3587120976.12](https://github.com/broadinstitute/gatk/actions/runs/3587120976/jobs/6037109635) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8116/merge_3587120976.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8116#issuecomment-1332758794:722,integrat,integration,722,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8116#issuecomment-1332758794,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3587567328](https://github.com/broadinstitute/gatk/actions/runs/3587567328); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [3587567328.12](https://github.com/broadinstitute/gatk/actions/runs/3587567328/jobs/6038060397) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8104/merge_3587567328.12/tests/test/index.html) |; | unit | 11 | [3587567328.13](https://github.com/broadinstitute/gatk/actions/runs/3587567328/jobs/6038060517) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8104/merge_3587567328.13/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8104#issuecomment-1332840771:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8104#issuecomment-1332840771,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3596247632](https://github.com/broadinstitute/gatk/actions/runs/3596247632); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11 | [3596247632.12](https://github.com/broadinstitute/gatk/actions/runs/3596247632/jobs/6056701079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8117/merge_3596247632.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8117#issuecomment-1334436521:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8117#issuecomment-1334436521,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3623308160](https://github.com/broadinstitute/gatk/actions/runs/3623308160); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [3623308160.11](https://github.com/broadinstitute/gatk/actions/runs/3623308160/jobs/6109026630) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8117/merge_3623308160.11/tests/test/index.html) |; | integration | 11 | [3623308160.12](https://github.com/broadinstitute/gatk/actions/runs/3623308160/jobs/6109026729) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8117/merge_3623308160.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8117#issuecomment-1338062367:486,integrat,integration,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8117#issuecomment-1338062367,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3624257957](https://github.com/broadinstitute/gatk/actions/runs/3624257957); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [3624257957.11](https://github.com/broadinstitute/gatk/actions/runs/3624257957/jobs/6111033110) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8090/merge_3624257957.11/tests/test/index.html) |; | integration | 11 | [3624257957.12](https://github.com/broadinstitute/gatk/actions/runs/3624257957/jobs/6111033198) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8090/merge_3624257957.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8090#issuecomment-1338262933:486,integrat,integration,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8090#issuecomment-1338262933,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3624346186](https://github.com/broadinstitute/gatk/actions/runs/3624346186); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 11 | [3624346186.13](https://github.com/broadinstitute/gatk/actions/runs/3624346186/jobs/6111228538) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8077/merge_3624346186.13/tests/test/index.html) |; | integration | 11 | [3624346186.12](https://github.com/broadinstitute/gatk/actions/runs/3624346186/jobs/6111228387) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8077/merge_3624346186.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8077#issuecomment-1338268763:485,integrat,integration,485,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8077#issuecomment-1338268763,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3624458247](https://github.com/broadinstitute/gatk/actions/runs/3624458247); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [3624458247.11](https://github.com/broadinstitute/gatk/actions/runs/3624458247/jobs/6111462117) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8077/merge_3624458247.11/tests/test/index.html) |; | integration | 11 | [3624458247.12](https://github.com/broadinstitute/gatk/actions/runs/3624458247/jobs/6111462227) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8077/merge_3624458247.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8077#issuecomment-1338276491:486,integrat,integration,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8077#issuecomment-1338276491,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3633623135](https://github.com/broadinstitute/gatk/actions/runs/3633623135); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [3633623135.11](https://github.com/broadinstitute/gatk/actions/runs/3633623135/jobs/6130848688) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8122/merge_3633623135.11/tests/test/index.html) |; | integration | 11 | [3633623135.12](https://github.com/broadinstitute/gatk/actions/runs/3633623135/jobs/6130848795) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8122/merge_3633623135.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8122#issuecomment-1340063603:486,integrat,integration,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8122#issuecomment-1340063603,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3650386129](https://github.com/broadinstitute/gatk/actions/runs/3650386129); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [3650386129.11](https://github.com/broadinstitute/gatk/actions/runs/3650386129/jobs/6166310404) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8077/merge_3650386129.11/tests/test/index.html) |; | integration | 11 | [3650386129.12](https://github.com/broadinstitute/gatk/actions/runs/3650386129/jobs/6166310524) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8077/merge_3650386129.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8077#issuecomment-1343060632:486,integrat,integration,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8077#issuecomment-1343060632,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3877173679](https://github.com/broadinstitute/gatk/actions/runs/3877173679); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3877173679.0](https://github.com/broadinstitute/gatk/actions/runs/3877173679/jobs/6612215423) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8035/merge_3877173679.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1376320453:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1376320453,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3949939482](https://github.com/broadinstitute/gatk/actions/runs/3949939482); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11.0.11+9 | [3949939482.12](https://github.com/broadinstitute/gatk/actions/runs/3949939482/jobs/6761805229) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8163/merge_3949939482.12/tests/testOnPackagedReleaseJar/index.html) |; | integration | 8 | [3949939482.0](https://github.com/broadinstitute/gatk/actions/runs/3949939482/jobs/6762208192) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8163/merge_3949939482.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8163#issuecomment-1387248353:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8163#issuecomment-1387248353,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [3987916695](https://github.com/broadinstitute/gatk/actions/runs/3987916695); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17 | [3987916695.0](https://github.com/broadinstitute/gatk/actions/runs/3987916695/jobs/6838942860) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8035/merge_3987916695.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1400666954:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1400666954,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4001857759](https://github.com/broadinstitute/gatk/actions/runs/4001857759); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.1+12 | [4001857759.11](https://github.com/broadinstitute/gatk/actions/runs/4001857759/jobs/6868522588) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8174/merge_4001857759.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.1+12 | [4001857759.0](https://github.com/broadinstitute/gatk/actions/runs/4001857759/jobs/6868770706) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8174/merge_4001857759.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8174#issuecomment-1402974502:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8174#issuecomment-1402974502,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4079416605](https://github.com/broadinstitute/gatk/actions/runs/4079416605); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 8 | [4079416605.0](https://github.com/broadinstitute/gatk/actions/runs/4079416605/jobs/7031020797) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8064/merge_4079416605.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8064#issuecomment-1414553974:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8064#issuecomment-1414553974,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4195524107](https://github.com/broadinstitute/gatk/actions/runs/4195524107); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11.0.11+9 | [4195524107.12](https://github.com/broadinstitute/gatk/actions/runs/4195524107/jobs/7275198074) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8209/merge_4195524107.12/tests/testOnPackagedReleaseJar/index.html) |; | integration | 8 | [4195524107.0](https://github.com/broadinstitute/gatk/actions/runs/4195524107/jobs/7275623025) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8209/merge_4195524107.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8209#issuecomment-1433339736:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8209#issuecomment-1433339736,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4244812025](https://github.com/broadinstitute/gatk/actions/runs/4244812025); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11.0.11+9 | [4244812025.12](https://github.com/broadinstitute/gatk/actions/runs/4244812025/jobs/7379465028) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8218/merge_4244812025.12/tests/testOnPackagedReleaseJar/index.html) |; | integration | 8 | [4244812025.0](https://github.com/broadinstitute/gatk/actions/runs/4244812025/jobs/7379936632) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8218/merge_4244812025.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8218#issuecomment-1440448935:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8218#issuecomment-1440448935,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4244927791](https://github.com/broadinstitute/gatk/actions/runs/4244927791); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.1+12 | [4244927791.11](https://github.com/broadinstitute/gatk/actions/runs/4244927791/jobs/7379745917) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8035/merge_4244927791.11/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1440462847:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1440462847,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4245426925](https://github.com/broadinstitute/gatk/actions/runs/4245426925); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.1+12 | [4245426925.0](https://github.com/broadinstitute/gatk/actions/runs/4245426925/jobs/7381325475) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8035/merge_4245426925.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1440616975:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1440616975,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4245787268](https://github.com/broadinstitute/gatk/actions/runs/4245787268); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.1+12 | [4245787268.0](https://github.com/broadinstitute/gatk/actions/runs/4245787268/jobs/7382168934) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8035/merge_4245787268.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1440703590:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1440703590,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4246430995](https://github.com/broadinstitute/gatk/actions/runs/4246430995); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 11.0.11+9 | [4246430995.12](https://github.com/broadinstitute/gatk/actions/runs/4246430995/jobs/7383230736) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8219/merge_4246430995.12/tests/testOnPackagedReleaseJar/index.html) |; | integration | 8 | [4246430995.0](https://github.com/broadinstitute/gatk/actions/runs/4246430995/jobs/7383544532) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8219/merge_4246430995.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8219#issuecomment-1440766619:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8219#issuecomment-1440766619,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4246436160](https://github.com/broadinstitute/gatk/actions/runs/4246436160); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.1+12 | [4246436160.0](https://github.com/broadinstitute/gatk/actions/runs/4246436160/jobs/7383634211) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8035/merge_4246436160.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1440804930:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1440804930,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4246719849](https://github.com/broadinstitute/gatk/actions/runs/4246719849); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [4246719849.11](https://github.com/broadinstitute/gatk/actions/runs/4246719849/jobs/7383882576) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8035/merge_4246719849.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4246719849.0](https://github.com/broadinstitute/gatk/actions/runs/4246719849/jobs/7384354659) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8035/merge_4246719849.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1440803366:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1440803366,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4247139744](https://github.com/broadinstitute/gatk/actions/runs/4247139744); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [4247139744.0](https://github.com/broadinstitute/gatk/actions/runs/4247139744/jobs/7385161939) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8035/merge_4247139744.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1440963992:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1440963992,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4283354593](https://github.com/broadinstitute/gatk/actions/runs/4283354593); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [4283354593.0](https://github.com/broadinstitute/gatk/actions/runs/4283354593/jobs/7464525192) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8035/merge_4283354593.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1446947762:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1446947762,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4286541120](https://github.com/broadinstitute/gatk/actions/runs/4286541120); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [4286541120.0](https://github.com/broadinstitute/gatk/actions/runs/4286541120/jobs/7466650442) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8035/merge_4286541120.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1447150719:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1447150719,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4287290821](https://github.com/broadinstitute/gatk/actions/runs/4287290821); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [4287290821.0](https://github.com/broadinstitute/gatk/actions/runs/4287290821/jobs/7468313623) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8035/merge_4287290821.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1447267534:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1447267534,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4293546771](https://github.com/broadinstitute/gatk/actions/runs/4293546771); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [4293546771.1](https://github.com/broadinstitute/gatk/actions/runs/4293546771/jobs/7481817776) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8035/merge_4293546771.1/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4293546771.0](https://github.com/broadinstitute/gatk/actions/runs/4293546771/jobs/7481817464) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8035/merge_4293546771.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1448295597:510,integrat,integration,510,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1448295597,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4294252456](https://github.com/broadinstitute/gatk/actions/runs/4294252456); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [4294252456.0](https://github.com/broadinstitute/gatk/actions/runs/4294252456/jobs/7483708392) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8035/merge_4294252456.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1448475999:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1448475999,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4294588163](https://github.com/broadinstitute/gatk/actions/runs/4294588163); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | variantcalling | 17.0.6+10 | [4294588163.2](https://github.com/broadinstitute/gatk/actions/runs/4294588163/jobs/7484350167) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8035/merge_4294588163.2/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4294588163.0](https://github.com/broadinstitute/gatk/actions/runs/4294588163/jobs/7484349608) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8035/merge_4294588163.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1448488223:520,integrat,integration,520,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8035#issuecomment-1448488223,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4419433150](https://github.com/broadinstitute/gatk/actions/runs/4419433150); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | conda | 17.0.6+10 | [4419433150.3](https://github.com/broadinstitute/gatk/actions/runs/4419433150/jobs/7748302560) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8228/merge_4419433150.3/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4419433150.0](https://github.com/broadinstitute/gatk/actions/runs/4419433150/jobs/7748302120) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8228/merge_4419433150.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8228#issuecomment-1468790852:511,integrat,integration,511,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8228#issuecomment-1468790852,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4502197439](https://github.com/broadinstitute/gatk/actions/runs/4502197439); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [4502197439.11](https://github.com/broadinstitute/gatk/actions/runs/4502197439/jobs/7923681604) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_4502197439.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4502197439.0](https://github.com/broadinstitute/gatk/actions/runs/4502197439/jobs/7924514621) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_4502197439.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1481457141:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1481457141,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4537063838](https://github.com/broadinstitute/gatk/actions/runs/4537063838); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [4537063838.12](https://github.com/broadinstitute/gatk/actions/runs/4537063838/jobs/7994515697) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8263/merge_4537063838.12/tests/testOnPackagedReleaseJar/index.html) |; | unit | 17.0.6+10 | [4537063838.1](https://github.com/broadinstitute/gatk/actions/runs/4537063838/jobs/7994839744) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8263/merge_4537063838.1/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4537063838.11](https://github.com/broadinstitute/gatk/actions/runs/4537063838/jobs/7994515554) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8263/merge_4537063838.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4537063838.0](https://github.com/broadinstitute/gatk/actions/runs/4537063838/jobs/7994839595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8263/merge_4537063838.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8263#issuecomment-1485957902:773,integrat,integration,773,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8263#issuecomment-1485957902,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4537280596](https://github.com/broadinstitute/gatk/actions/runs/4537280596); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [4537280596.12](https://github.com/broadinstitute/gatk/actions/runs/4537280596/jobs/7994957209) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8263/merge_4537280596.12/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4537280596.11](https://github.com/broadinstitute/gatk/actions/runs/4537280596/jobs/7994957096) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8263/merge_4537280596.11/tests/testOnPackagedReleaseJar/index.html) |; | unit | 17.0.6+10 | [4537280596.1](https://github.com/broadinstitute/gatk/actions/runs/4537280596/jobs/7995297292) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8263/merge_4537280596.1/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4537280596.0](https://github.com/broadinstitute/gatk/actions/runs/4537280596/jobs/7995297152) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8263/merge_4537280596.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8263#issuecomment-1485983843:512,integrat,integration,512,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8263#issuecomment-1485983843,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4538115933](https://github.com/broadinstitute/gatk/actions/runs/4538115933); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [4538115933.12](https://github.com/broadinstitute/gatk/actions/runs/4538115933/jobs/7996704248) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8263/merge_4538115933.12/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4538115933.11](https://github.com/broadinstitute/gatk/actions/runs/4538115933/jobs/7996704166) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8263/merge_4538115933.11/tests/testOnPackagedReleaseJar/index.html) |; | unit | 17.0.6+10 | [4538115933.1](https://github.com/broadinstitute/gatk/actions/runs/4538115933/jobs/7996985606) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8263/merge_4538115933.1/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4538115933.0](https://github.com/broadinstitute/gatk/actions/runs/4538115933/jobs/7996985479) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8263/merge_4538115933.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8263#issuecomment-1486078794:512,integrat,integration,512,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8263#issuecomment-1486078794,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4542653569](https://github.com/broadinstitute/gatk/actions/runs/4542653569); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [4542653569.12](https://github.com/broadinstitute/gatk/actions/runs/4542653569/jobs/8006347482) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8263/merge_4542653569.12/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4542653569.11](https://github.com/broadinstitute/gatk/actions/runs/4542653569/jobs/8006347297) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8263/merge_4542653569.11/tests/testOnPackagedReleaseJar/index.html) |; | unit | 17.0.6+10 | [4542653569.1](https://github.com/broadinstitute/gatk/actions/runs/4542653569/jobs/8006778312) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8263/merge_4542653569.1/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4542653569.0](https://github.com/broadinstitute/gatk/actions/runs/4542653569/jobs/8006778006) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8263/merge_4542653569.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8263#issuecomment-1486769487:512,integrat,integration,512,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8263#issuecomment-1486769487,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4542992702](https://github.com/broadinstitute/gatk/actions/runs/4542992702); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [4542992702.12](https://github.com/broadinstitute/gatk/actions/runs/4542992702/jobs/8007115143) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8263/merge_4542992702.12/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4542992702.11](https://github.com/broadinstitute/gatk/actions/runs/4542992702/jobs/8007114965) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8263/merge_4542992702.11/tests/testOnPackagedReleaseJar/index.html) |; | unit | 17.0.6+10 | [4542992702.1](https://github.com/broadinstitute/gatk/actions/runs/4542992702/jobs/8007597143) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8263/merge_4542992702.1/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4542992702.0](https://github.com/broadinstitute/gatk/actions/runs/4542992702/jobs/8007596854) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8263/merge_4542992702.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8263#issuecomment-1486837614:512,integrat,integration,512,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8263#issuecomment-1486837614,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4669373498](https://github.com/broadinstitute/gatk/actions/runs/4669373498); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [4669373498.12](https://github.com/broadinstitute/gatk/actions/runs/4669373498/jobs/8267726867) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8283/merge_4669373498.12/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4669373498.11](https://github.com/broadinstitute/gatk/actions/runs/4669373498/jobs/8267726653) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8283/merge_4669373498.11/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8283#issuecomment-1503694982:512,integrat,integration,512,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8283#issuecomment-1503694982,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4692324203](https://github.com/broadinstitute/gatk/actions/runs/4692324203); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [4692324203.11](https://github.com/broadinstitute/gatk/actions/runs/4692324203/jobs/8317904694) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8283/merge_4692324203.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4692324203.0](https://github.com/broadinstitute/gatk/actions/runs/4692324203/jobs/8318583362) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8283/merge_4692324203.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8283#issuecomment-1507455580:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8283#issuecomment-1507455580,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4693611185](https://github.com/broadinstitute/gatk/actions/runs/4693611185); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [4693611185.11](https://github.com/broadinstitute/gatk/actions/runs/4693611185/jobs/8320803132) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8288/merge_4693611185.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4693611185.0](https://github.com/broadinstitute/gatk/actions/runs/4693611185/jobs/8321280292) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8288/merge_4693611185.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8288#issuecomment-1507622700:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8288#issuecomment-1507622700,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4693827836](https://github.com/broadinstitute/gatk/actions/runs/4693827836); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [4693827836.11](https://github.com/broadinstitute/gatk/actions/runs/4693827836/jobs/8321306601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8283/merge_4693827836.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4693827836.0](https://github.com/broadinstitute/gatk/actions/runs/4693827836/jobs/8321737238) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8283/merge_4693827836.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8283#issuecomment-1507650438:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8283#issuecomment-1507650438,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4701408293](https://github.com/broadinstitute/gatk/actions/runs/4701408293); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [4701408293.11](https://github.com/broadinstitute/gatk/actions/runs/4701408293/jobs/8337397234) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8283/merge_4701408293.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4701408293.0](https://github.com/broadinstitute/gatk/actions/runs/4701408293/jobs/8337913244) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8283/merge_4701408293.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8283#issuecomment-1508913451:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8283#issuecomment-1508913451,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4702712861](https://github.com/broadinstitute/gatk/actions/runs/4702712861); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [4702712861.11](https://github.com/broadinstitute/gatk/actions/runs/4702712861/jobs/8340314341) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8283/merge_4702712861.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4702712861.0](https://github.com/broadinstitute/gatk/actions/runs/4702712861/jobs/8340785857) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8283/merge_4702712861.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8283#issuecomment-1509090506:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8283#issuecomment-1509090506,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4845406997](https://github.com/broadinstitute/gatk/actions/runs/4845406997); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [4845406997.11](https://github.com/broadinstitute/gatk/actions/runs/4845406997/jobs/8634307333) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8257/merge_4845406997.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4845406997.0](https://github.com/broadinstitute/gatk/actions/runs/4845406997/jobs/8634529537) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8257/merge_4845406997.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8257#issuecomment-1529092876:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8257#issuecomment-1529092876,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4853456806](https://github.com/broadinstitute/gatk/actions/runs/4853456806); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [4853456806.11](https://github.com/broadinstitute/gatk/actions/runs/4853456806/jobs/8649649707) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8257/merge_4853456806.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4853456806.0](https://github.com/broadinstitute/gatk/actions/runs/4853456806/jobs/8650143375) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8257/merge_4853456806.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8257#issuecomment-1530053660:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8257#issuecomment-1530053660,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4853463316](https://github.com/broadinstitute/gatk/actions/runs/4853463316); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [4853463316.11](https://github.com/broadinstitute/gatk/actions/runs/4853463316/jobs/8649664843) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8257/merge_4853463316.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4853463316.0](https://github.com/broadinstitute/gatk/actions/runs/4853463316/jobs/8650161839) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8257/merge_4853463316.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8257#issuecomment-1530054035:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8257#issuecomment-1530054035,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4863023115](https://github.com/broadinstitute/gatk/actions/runs/4863023115); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [4863023115.10](https://github.com/broadinstitute/gatk/actions/runs/4863023115/jobs/8670137787) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8306/merge_4863023115.10/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4863023115.11](https://github.com/broadinstitute/gatk/actions/runs/4863023115/jobs/8670137952) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8306/merge_4863023115.11/tests/testOnPackagedReleaseJar/index.html) |; | conda | 17.0.6+10 | [4863023115.3](https://github.com/broadinstitute/gatk/actions/runs/4863023115/jobs/8670941490) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8306/merge_4863023115.3/tests/testOnPackagedReleaseJar/index.html) |; | variantcalling | 17.0.6+10 | [4863023115.2](https://github.com/broadinstitute/gatk/actions/runs/4863023115/jobs/8670941332) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8306/merge_4863023115.2/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4863023115.0](https://github.com/broadinstitute/gatk/actions/runs/4863023115/jobs/8670940969) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8306/merge_4863023115.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8306#issuecomment-1531711840:513,integrat,integration,513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8306#issuecomment-1531711840,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4863212990](https://github.com/broadinstitute/gatk/actions/runs/4863212990); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [4863212990.11](https://github.com/broadinstitute/gatk/actions/runs/4863212990/jobs/8670611153) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8283/merge_4863212990.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4863212990.0](https://github.com/broadinstitute/gatk/actions/runs/4863212990/jobs/8671264117) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8283/merge_4863212990.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8283#issuecomment-1531807029:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8283#issuecomment-1531807029,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4874413258](https://github.com/broadinstitute/gatk/actions/runs/4874413258); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [4874413258.11](https://github.com/broadinstitute/gatk/actions/runs/4874413258/jobs/8695304501) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8283/merge_4874413258.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4874413258.0](https://github.com/broadinstitute/gatk/actions/runs/4874413258/jobs/8696059220) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8283/merge_4874413258.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8283#issuecomment-1533430077:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8283#issuecomment-1533430077,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4875986159](https://github.com/broadinstitute/gatk/actions/runs/4875986159); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 11 | [4875986159.13](https://github.com/broadinstitute/gatk/actions/runs/4875986159/jobs/8698904875) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8295/merge_4875986159.13/tests/test/index.html) |; | integration | 11 | [4875986159.12](https://github.com/broadinstitute/gatk/actions/runs/4875986159/jobs/8698904740) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8295/merge_4875986159.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8295#issuecomment-1533686911:485,integrat,integration,485,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8295#issuecomment-1533686911,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4938974216](https://github.com/broadinstitute/gatk/actions/runs/4938974216); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [4938974216.11](https://github.com/broadinstitute/gatk/actions/runs/4938974216/jobs/8829297547) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8306/merge_4938974216.11/tests/testOnPackagedReleaseJar/index.html) |; | conda | 17.0.6+10 | [4938974216.3](https://github.com/broadinstitute/gatk/actions/runs/4938974216/jobs/8829731910) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8306/merge_4938974216.3/tests/testOnPackagedReleaseJar/index.html) |; | variantcalling | 17.0.6+10 | [4938974216.2](https://github.com/broadinstitute/gatk/actions/runs/4938974216/jobs/8829731825) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8306/merge_4938974216.2/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4938974216.0](https://github.com/broadinstitute/gatk/actions/runs/4938974216/jobs/8829731507) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8306/merge_4938974216.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8306#issuecomment-1542519590:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8306#issuecomment-1542519590,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4950124822](https://github.com/broadinstitute/gatk/actions/runs/4950124822); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [4950124822.11](https://github.com/broadinstitute/gatk/actions/runs/4950124822/jobs/8853310641) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8313/merge_4950124822.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4950124822.0](https://github.com/broadinstitute/gatk/actions/runs/4950124822/jobs/8853925376) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8313/merge_4950124822.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8313#issuecomment-1544374173:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8313#issuecomment-1544374173,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4950260120](https://github.com/broadinstitute/gatk/actions/runs/4950260120); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [4950260120.11](https://github.com/broadinstitute/gatk/actions/runs/4950260120/jobs/8853637397) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8313/merge_4950260120.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4950260120.0](https://github.com/broadinstitute/gatk/actions/runs/4950260120/jobs/8854214029) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8313/merge_4950260120.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8313#issuecomment-1544381962:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8313#issuecomment-1544381962,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4950260133](https://github.com/broadinstitute/gatk/actions/runs/4950260133); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [4950260133.11](https://github.com/broadinstitute/gatk/actions/runs/4950260133/jobs/8853635903) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8313/merge_4950260133.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4950260133.0](https://github.com/broadinstitute/gatk/actions/runs/4950260133/jobs/8854232054) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8313/merge_4950260133.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8313#issuecomment-1544397838:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8313#issuecomment-1544397838,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4952062427](https://github.com/broadinstitute/gatk/actions/runs/4952062427); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [4952062427.10](https://github.com/broadinstitute/gatk/actions/runs/4952062427/jobs/8857886780) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8314/merge_4952062427.10/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4952062427.11](https://github.com/broadinstitute/gatk/actions/runs/4952062427/jobs/8857886910) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8314/merge_4952062427.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4952062427.0](https://github.com/broadinstitute/gatk/actions/runs/4952062427/jobs/8858514928) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8314/merge_4952062427.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8314#issuecomment-1544635251:513,integrat,integration,513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8314#issuecomment-1544635251,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4953977643](https://github.com/broadinstitute/gatk/actions/runs/4953977643); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [4953977643.10](https://github.com/broadinstitute/gatk/actions/runs/4953977643/jobs/8862040836) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8314/merge_4953977643.10/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4953977643.11](https://github.com/broadinstitute/gatk/actions/runs/4953977643/jobs/8862040934) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8314/merge_4953977643.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4953977643.0](https://github.com/broadinstitute/gatk/actions/runs/4953977643/jobs/8862378455) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8314/merge_4953977643.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8314#issuecomment-1544963701:513,integrat,integration,513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8314#issuecomment-1544963701,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4954811217](https://github.com/broadinstitute/gatk/actions/runs/4954811217); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [4954811217.10](https://github.com/broadinstitute/gatk/actions/runs/4954811217/jobs/8863648172) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_4954811217.10/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4954811217.11](https://github.com/broadinstitute/gatk/actions/runs/4954811217/jobs/8863648244) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_4954811217.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4954811217.0](https://github.com/broadinstitute/gatk/actions/runs/4954811217/jobs/8863974369) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/6351/merge_4954811217.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1545061527:513,integrat,integration,513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6351#issuecomment-1545061527,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [4957343136](https://github.com/broadinstitute/gatk/actions/runs/4957343136); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [4957343136.10](https://github.com/broadinstitute/gatk/actions/runs/4957343136/jobs/8868904857) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8314/merge_4957343136.10/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4957343136.11](https://github.com/broadinstitute/gatk/actions/runs/4957343136/jobs/8868904972) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8314/merge_4957343136.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [4957343136.0](https://github.com/broadinstitute/gatk/actions/runs/4957343136/jobs/8869403263) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8314/merge_4957343136.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8314#issuecomment-1545482954:513,integrat,integration,513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8314#issuecomment-1545482954,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [5204025552](https://github.com/broadinstitute/gatk/actions/runs/5204025552); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [5204025552.12](https://github.com/broadinstitute/gatk/actions/runs/5204025552/jobs/9387682065) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8352/merge_5204025552.12/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5204025552.11](https://github.com/broadinstitute/gatk/actions/runs/5204025552/jobs/9387681955) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8352/merge_5204025552.11/tests/testOnPackagedReleaseJar/index.html) |; | unit | 17.0.6+10 | [5204025552.1](https://github.com/broadinstitute/gatk/actions/runs/5204025552/jobs/9388330559) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8352/merge_5204025552.1/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5204025552.0](https://github.com/broadinstitute/gatk/actions/runs/5204025552/jobs/9388330409) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8352/merge_5204025552.0/tests/testOnPackagedReleaseJar/index.html) |; | conda | 17.0.6+10 | [5204025552.3](https://github.com/broadinstitute/gatk/actions/runs/5204025552/jobs/9388330869) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8352/merge_5204025552.3/tests/testOnPackagedReleaseJar/index.html) |; | variantcalling | 17.0.6+10 | [5204025552.2](https://github.com/broadinstitute/gatk/actions/runs/5204025552/jobs/9388330704) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8352/merge_5204025552.2/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8352#issuecomment-1581418603:512,integrat,integration,512,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8352#issuecomment-1581418603,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [5533855739](https://github.com/broadinstitute/gatk/actions/runs/5533855739); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [5533855739.11](https://github.com/broadinstitute/gatk/actions/runs/5533855739/jobs/10098008584) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7750/merge_5533855739.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5533855739.0](https://github.com/broadinstitute/gatk/actions/runs/5533855739/jobs/10098707822) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/7750/merge_5533855739.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7750#issuecomment-1632878420:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7750#issuecomment-1632878420,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [5558172684](https://github.com/broadinstitute/gatk/actions/runs/5558172684); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [5558172684.10](https://github.com/broadinstitute/gatk/actions/runs/5558172684/jobs/10152931350) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8420/merge_5558172684.10/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5558172684.11](https://github.com/broadinstitute/gatk/actions/runs/5558172684/jobs/10152931493) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8420/merge_5558172684.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5558172684.0](https://github.com/broadinstitute/gatk/actions/runs/5558172684/jobs/10153480377) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8420/merge_5558172684.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8420#issuecomment-1636441750:514,integrat,integration,514,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8420#issuecomment-1636441750,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [5612203071](https://github.com/broadinstitute/gatk/actions/runs/5612203071); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [5612203071.11](https://github.com/broadinstitute/gatk/actions/runs/5612203071/job/15205416461) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8428/merge_5612203071.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5612203071.0](https://github.com/broadinstitute/gatk/actions/runs/5612203071/job/15206691930) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8428/merge_5612203071.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8428#issuecomment-1644092448:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8428#issuecomment-1644092448,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [5673591869](https://github.com/broadinstitute/gatk/actions/runs/5673591869); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [5673591869.10](https://github.com/broadinstitute/gatk/actions/runs/5673591869/job/15375410885) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8439/merge_5673591869.10/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5673591869.11](https://github.com/broadinstitute/gatk/actions/runs/5673591869/job/15375411042) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8439/merge_5673591869.11/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1652502916:513,integrat,integration,513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1652502916,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [5675230266](https://github.com/broadinstitute/gatk/actions/runs/5675230266); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [5675230266.10](https://github.com/broadinstitute/gatk/actions/runs/5675230266/job/15380158537) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8439/merge_5675230266.10/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5675230266.11](https://github.com/broadinstitute/gatk/actions/runs/5675230266/job/15380158667) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8439/merge_5675230266.11/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1652762977:513,integrat,integration,513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1652762977,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [5675309053](https://github.com/broadinstitute/gatk/actions/runs/5675309053); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [5675309053.10](https://github.com/broadinstitute/gatk/actions/runs/5675309053/job/15380352775) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8439/merge_5675309053.10/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5675309053.11](https://github.com/broadinstitute/gatk/actions/runs/5675309053/job/15380353004) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8439/merge_5675309053.11/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1652780532:513,integrat,integration,513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1652780532,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [5675450808](https://github.com/broadinstitute/gatk/actions/runs/5675450808); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [5675450808.10](https://github.com/broadinstitute/gatk/actions/runs/5675450808/job/15380699367) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8439/merge_5675450808.10/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5675450808.11](https://github.com/broadinstitute/gatk/actions/runs/5675450808/job/15380699456) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8439/merge_5675450808.11/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1652797118:513,integrat,integration,513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1652797118,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [5675759702](https://github.com/broadinstitute/gatk/actions/runs/5675759702); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [5675759702.10](https://github.com/broadinstitute/gatk/actions/runs/5675759702/job/15381453839) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8439/merge_5675759702.10/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5675759702.11](https://github.com/broadinstitute/gatk/actions/runs/5675759702/job/15381453989) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8439/merge_5675759702.11/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1652822383:513,integrat,integration,513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1652822383,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [5675841383](https://github.com/broadinstitute/gatk/actions/runs/5675841383); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [5675841383.10](https://github.com/broadinstitute/gatk/actions/runs/5675841383/job/15381665850) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8439/merge_5675841383.10/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5675841383.11](https://github.com/broadinstitute/gatk/actions/runs/5675841383/job/15381665950) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8439/merge_5675841383.11/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1652829890:513,integrat,integration,513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1652829890,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [5677288686](https://github.com/broadinstitute/gatk/actions/runs/5677288686); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [5677288686.10](https://github.com/broadinstitute/gatk/actions/runs/5677288686/job/15385355158) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8439/merge_5677288686.10/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5677288686.11](https://github.com/broadinstitute/gatk/actions/runs/5677288686/job/15385355285) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8439/merge_5677288686.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5677288686.0](https://github.com/broadinstitute/gatk/actions/runs/5677288686/job/15386108072) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8439/merge_5677288686.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1653006672:513,integrat,integration,513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1653006672,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [5677548223](https://github.com/broadinstitute/gatk/actions/runs/5677548223); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [5677548223.11](https://github.com/broadinstitute/gatk/actions/runs/5677548223/job/15386058858) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8439/merge_5677548223.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5677548223.0](https://github.com/broadinstitute/gatk/actions/runs/5677548223/job/15386778131) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8439/merge_5677548223.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1653075090:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1653075090,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [5677658199](https://github.com/broadinstitute/gatk/actions/runs/5677658199); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [5677658199.11](https://github.com/broadinstitute/gatk/actions/runs/5677658199/job/15386352276) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8439/merge_5677658199.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5677658199.0](https://github.com/broadinstitute/gatk/actions/runs/5677658199/job/15387051805) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8439/merge_5677658199.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1653091268:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8439#issuecomment-1653091268,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [5906500357](https://github.com/broadinstitute/gatk/actions/runs/5906500357); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [5906500357.10](https://github.com/broadinstitute/gatk/actions/runs/5906500357/job/16022649132) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906500357.10/tests/testOnPackagedReleaseJar/index.html) |; | unit | 17.0.6+10 | [5906500357.12](https://github.com/broadinstitute/gatk/actions/runs/5906500357/job/16022649351) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906500357.12/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5906500357.11](https://github.com/broadinstitute/gatk/actions/runs/5906500357/job/16022649238) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906500357.11/tests/testOnPackagedReleaseJar/index.html) |; | conda | 17.0.6+10 | [5906500357.3](https://github.com/broadinstitute/gatk/actions/runs/5906500357/job/16023343655) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906500357.3/tests/testOnPackagedReleaseJar/index.html) |; | unit | 17.0.6+10 | [5906500357.1](https://github.com/broadinstitute/gatk/actions/runs/5906500357/job/16023343343) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906500357.1/tests/testOnPackagedReleaseJar/index.html) |; | variantcalling | 17.0.6+10 | [5906500357.2](https://github.com/broadinstitute/gatk/actions/runs/5906500357/job/16023343497) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906500357.2/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5906500357.0](https://github.com/broadinstitute/gatk/actions/runs/5906500357/job/16023343147) | [logs](https://storage.googleapis.com/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8486#issuecomment-1684393146:776,integrat,integration,776,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8486#issuecomment-1684393146,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [5906807871](https://github.com/broadinstitute/gatk/actions/runs/5906807871); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [5906807871.10](https://github.com/broadinstitute/gatk/actions/runs/5906807871/job/16023558278) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906807871.10/tests/testOnPackagedReleaseJar/index.html) |; | unit | 17.0.6+10 | [5906807871.12](https://github.com/broadinstitute/gatk/actions/runs/5906807871/job/16023558558) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906807871.12/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5906807871.11](https://github.com/broadinstitute/gatk/actions/runs/5906807871/job/16023558444) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906807871.11/tests/testOnPackagedReleaseJar/index.html) |; | unit | 17.0.6+10 | [5906807871.1](https://github.com/broadinstitute/gatk/actions/runs/5906807871/job/16024178952) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906807871.1/tests/testOnPackagedReleaseJar/index.html) |; | conda | 17.0.6+10 | [5906807871.3](https://github.com/broadinstitute/gatk/actions/runs/5906807871/job/16024179175) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906807871.3/tests/testOnPackagedReleaseJar/index.html) |; | variantcalling | 17.0.6+10 | [5906807871.2](https://github.com/broadinstitute/gatk/actions/runs/5906807871/job/16024179060) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5906807871.2/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5906807871.0](https://github.com/broadinstitute/gatk/actions/runs/5906807871/job/16024178803) | [logs](https://storage.googleapis.com/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8486#issuecomment-1684420305:776,integrat,integration,776,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8486#issuecomment-1684420305,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [5930144661](https://github.com/broadinstitute/gatk/actions/runs/5930144661); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [5930144661.11](https://github.com/broadinstitute/gatk/actions/runs/5930144661/job/16079250057) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5930144661.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [5930144661.0](https://github.com/broadinstitute/gatk/actions/runs/5930144661/job/16080312223) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8486/merge_5930144661.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8486#issuecomment-1686885415:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8486#issuecomment-1686885415,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6015791113](https://github.com/broadinstitute/gatk/actions/runs/6015791113); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6015791113.11](https://github.com/broadinstitute/gatk/actions/runs/6015791113/job/16318413782) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6015791113.11/tests/test/index.html) |; | integration | 11 | [6015791113.12](https://github.com/broadinstitute/gatk/actions/runs/6015791113/job/16318413905) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6015791113.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8459#issuecomment-1697923110:486,integrat,integration,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8459#issuecomment-1697923110,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6016742374](https://github.com/broadinstitute/gatk/actions/runs/6016742374); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6016742374.11](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16321393716) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.11/tests/test/index.html) |; | integration | 11 | [6016742374.12](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16321393852) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.12/tests/test/index.html) |; | cloud | 11 | [6016742374.11](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16347530908) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.11/tests/test/index.html) |; | unit | 11 | [6016742374.13](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16347531468) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.13/tests/test/index.html) |; | integration | 11 | [6016742374.12](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16347531169) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.12/tests/test/index.html) |; | unit | 11 | [6016742374.13](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16362542517) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.13/tests/test/index.html) |; | cloud | 11 | [6016742374.11](https://github.com/broadinstitute/gatk/actions/runs/6016742374/job/16362542090) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8459/merge_6016742374.11/tests/test/index.html) |; | integration | 11 | [6016742374.12](https://github.com/broadinstitute/gatk/actions/r,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8459#issuecomment-1698045984:486,integrat,integration,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8459#issuecomment-1698045984,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6016766058](https://github.com/broadinstitute/gatk/actions/runs/6016766058); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6016766058.11](https://github.com/broadinstitute/gatk/actions/runs/6016766058/job/16321469898) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8487/merge_6016766058.11/tests/test/index.html) |; | integration | 11 | [6016766058.12](https://github.com/broadinstitute/gatk/actions/runs/6016766058/job/16321470038) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8487/merge_6016766058.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8487#issuecomment-1698065764:486,integrat,integration,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8487#issuecomment-1698065764,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6016796286](https://github.com/broadinstitute/gatk/actions/runs/6016796286); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 11 | [6016796286.13](https://github.com/broadinstitute/gatk/actions/runs/6016796286/job/16321574718) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8487/merge_6016796286.13/tests/test/index.html) |; | cloud | 11 | [6016796286.11](https://github.com/broadinstitute/gatk/actions/runs/6016796286/job/16321574364) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8487/merge_6016796286.11/tests/test/index.html) |; | integration | 11 | [6016796286.12](https://github.com/broadinstitute/gatk/actions/runs/6016796286/job/16321574527) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8487/merge_6016796286.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8487#issuecomment-1698061363:722,integrat,integration,722,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8487#issuecomment-1698061363,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6025723553](https://github.com/broadinstitute/gatk/actions/runs/6025723553); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6025723553.11](https://github.com/broadinstitute/gatk/actions/runs/6025723553/job/16347072443) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8507/merge_6025723553.11/tests/test/index.html) |; | integration | 11 | [6025723553.12](https://github.com/broadinstitute/gatk/actions/runs/6025723553/job/16347072702) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8507/merge_6025723553.12/tests/test/index.html) |; | integration | 8 | [6025723553.0](https://github.com/broadinstitute/gatk/actions/runs/6025723553/job/16348148161) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8507/merge_6025723553.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8507#issuecomment-1699255469:486,integrat,integration,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8507#issuecomment-1699255469,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6025741189](https://github.com/broadinstitute/gatk/actions/runs/6025741189); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6025741189.11](https://github.com/broadinstitute/gatk/actions/runs/6025741189/job/16347130272) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8507/merge_6025741189.11/tests/test/index.html) |; | integration | 11 | [6025741189.12](https://github.com/broadinstitute/gatk/actions/runs/6025741189/job/16347130517) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8507/merge_6025741189.12/tests/test/index.html) |; | integration | 8 | [6025741189.0](https://github.com/broadinstitute/gatk/actions/runs/6025741189/job/16347949455) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8507/merge_6025741189.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8507#issuecomment-1699269362:486,integrat,integration,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8507#issuecomment-1699269362,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6027328228](https://github.com/broadinstitute/gatk/actions/runs/6027328228); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6027328228.11](https://github.com/broadinstitute/gatk/actions/runs/6027328228/job/16352302636) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8487/merge_6027328228.11/tests/test/index.html) |; | integration | 11 | [6027328228.12](https://github.com/broadinstitute/gatk/actions/runs/6027328228/job/16352302843) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8487/merge_6027328228.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8487#issuecomment-1699493744:486,integrat,integration,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8487#issuecomment-1699493744,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6027458568](https://github.com/broadinstitute/gatk/actions/runs/6027458568); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6027458568.11](https://github.com/broadinstitute/gatk/actions/runs/6027458568/job/16352707779) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8487/merge_6027458568.11/tests/test/index.html) |; | integration | 11 | [6027458568.12](https://github.com/broadinstitute/gatk/actions/runs/6027458568/job/16352707984) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8487/merge_6027458568.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8487#issuecomment-1699510150:486,integrat,integration,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8487#issuecomment-1699510150,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6027505747](https://github.com/broadinstitute/gatk/actions/runs/6027505747); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6027505747.11](https://github.com/broadinstitute/gatk/actions/runs/6027505747/job/16352852068) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8487/merge_6027505747.11/tests/test/index.html) |; | integration | 11 | [6027505747.12](https://github.com/broadinstitute/gatk/actions/runs/6027505747/job/16352852261) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8487/merge_6027505747.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8487#issuecomment-1699527972:486,integrat,integration,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8487#issuecomment-1699527972,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6029204725](https://github.com/broadinstitute/gatk/actions/runs/6029204725); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6029204725.11](https://github.com/broadinstitute/gatk/actions/runs/6029204725/job/16358185601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6029204725.11/tests/test/index.html) |; | integration | 11 | [6029204725.12](https://github.com/broadinstitute/gatk/actions/runs/6029204725/job/16358185943) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6029204725.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8508#issuecomment-1699741786:486,integrat,integration,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8508#issuecomment-1699741786,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6038370097](https://github.com/broadinstitute/gatk/actions/runs/6038370097); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6038370097.11](https://github.com/broadinstitute/gatk/actions/runs/6038370097/job/16384642041) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8510/merge_6038370097.11/tests/test/index.html) |; | integration | 11 | [6038370097.12](https://github.com/broadinstitute/gatk/actions/runs/6038370097/job/16384642403) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8510/merge_6038370097.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8510#issuecomment-1701151755:486,integrat,integration,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8510#issuecomment-1701151755,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6038530241](https://github.com/broadinstitute/gatk/actions/runs/6038530241); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6038530241.11](https://github.com/broadinstitute/gatk/actions/runs/6038530241/job/16385137309) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8510/merge_6038530241.11/tests/test/index.html) |; | integration | 11 | [6038530241.12](https://github.com/broadinstitute/gatk/actions/runs/6038530241/job/16385137546) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8510/merge_6038530241.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8510#issuecomment-1701171146:486,integrat,integration,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8510#issuecomment-1701171146,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6039128959](https://github.com/broadinstitute/gatk/actions/runs/6039128959); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6039128959.11](https://github.com/broadinstitute/gatk/actions/runs/6039128959/job/16387080712) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6039128959.11/tests/test/index.html) |; | unit | 11 | [6039128959.13](https://github.com/broadinstitute/gatk/actions/runs/6039128959/job/16387081255) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6039128959.13/tests/test/index.html) |; | integration | 11 | [6039128959.12](https://github.com/broadinstitute/gatk/actions/runs/6039128959/job/16387080982) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6039128959.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8508#issuecomment-1701273955:722,integrat,integration,722,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8508#issuecomment-1701273955,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6039519552](https://github.com/broadinstitute/gatk/actions/runs/6039519552); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6039519552.11](https://github.com/broadinstitute/gatk/actions/runs/6039519552/job/16388346929) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6039519552.11/tests/test/index.html) |; | unit | 11 | [6039519552.13](https://github.com/broadinstitute/gatk/actions/runs/6039519552/job/16388347459) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6039519552.13/tests/test/index.html) |; | integration | 11 | [6039519552.12](https://github.com/broadinstitute/gatk/actions/runs/6039519552/job/16388347157) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6039519552.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8508#issuecomment-1701315967:722,integrat,integration,722,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8508#issuecomment-1701315967,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6039784886](https://github.com/broadinstitute/gatk/actions/runs/6039784886); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6039784886.11](https://github.com/broadinstitute/gatk/actions/runs/6039784886/job/16389215419) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6039784886.11/tests/test/index.html) |; | unit | 11 | [6039784886.13](https://github.com/broadinstitute/gatk/actions/runs/6039784886/job/16389216020) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6039784886.13/tests/test/index.html) |; | integration | 11 | [6039784886.12](https://github.com/broadinstitute/gatk/actions/runs/6039784886/job/16389215795) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6039784886.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8508#issuecomment-1701373139:722,integrat,integration,722,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8508#issuecomment-1701373139,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6040563225](https://github.com/broadinstitute/gatk/actions/runs/6040563225); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6040563225.11](https://github.com/broadinstitute/gatk/actions/runs/6040563225/job/16391644499) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6040563225.11/tests/test/index.html) |; | integration | 11 | [6040563225.12](https://github.com/broadinstitute/gatk/actions/runs/6040563225/job/16391644650) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6040563225.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8508#issuecomment-1701503582:486,integrat,integration,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8508#issuecomment-1701503582,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6041224075](https://github.com/broadinstitute/gatk/actions/runs/6041224075); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6041224075.11](https://github.com/broadinstitute/gatk/actions/runs/6041224075/job/16393710739) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6041224075.11/tests/test/index.html) |; | unit | 11 | [6041224075.13](https://github.com/broadinstitute/gatk/actions/runs/6041224075/job/16393711068) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6041224075.13/tests/test/index.html) |; | integration | 11 | [6041224075.12](https://github.com/broadinstitute/gatk/actions/runs/6041224075/job/16393710889) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6041224075.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8508#issuecomment-1701598279:722,integrat,integration,722,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8508#issuecomment-1701598279,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6041242949](https://github.com/broadinstitute/gatk/actions/runs/6041242949); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6041242949.11](https://github.com/broadinstitute/gatk/actions/runs/6041242949/job/16393773586) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6041242949.11/tests/test/index.html) |; | integration | 11 | [6041242949.12](https://github.com/broadinstitute/gatk/actions/runs/6041242949/job/16393773740) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6041242949.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8508#issuecomment-1701617540:486,integrat,integration,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8508#issuecomment-1701617540,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6041548152](https://github.com/broadinstitute/gatk/actions/runs/6041548152); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6041548152.11](https://github.com/broadinstitute/gatk/actions/runs/6041548152/job/16394743636) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6041548152.11/tests/test/index.html) |; | unit | 11 | [6041548152.13](https://github.com/broadinstitute/gatk/actions/runs/6041548152/job/16394744048) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6041548152.13/tests/test/index.html) |; | integration | 11 | [6041548152.12](https://github.com/broadinstitute/gatk/actions/runs/6041548152/job/16394743832) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6041548152.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8508#issuecomment-1701677371:722,integrat,integration,722,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8508#issuecomment-1701677371,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6041869902](https://github.com/broadinstitute/gatk/actions/runs/6041869902); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6041869902.11](https://github.com/broadinstitute/gatk/actions/runs/6041869902/job/16395792759) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6041869902.11/tests/test/index.html) |; | unit | 11 | [6041869902.13](https://github.com/broadinstitute/gatk/actions/runs/6041869902/job/16395793003) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6041869902.13/tests/test/index.html) |; | integration | 11 | [6041869902.12](https://github.com/broadinstitute/gatk/actions/runs/6041869902/job/16395792880) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8508/merge_6041869902.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8508#issuecomment-1701724937:722,integrat,integration,722,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8508#issuecomment-1701724937,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6042319707](https://github.com/broadinstitute/gatk/actions/runs/6042319707); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6042319707.11](https://github.com/broadinstitute/gatk/actions/runs/6042319707/job/16397171544) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8507/merge_6042319707.11/tests/test/index.html) |; | unit | 11 | [6042319707.13](https://github.com/broadinstitute/gatk/actions/runs/6042319707/job/16397171864) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8507/merge_6042319707.13/tests/test/index.html) |; | integration | 11 | [6042319707.12](https://github.com/broadinstitute/gatk/actions/runs/6042319707/job/16397171702) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8507/merge_6042319707.12/tests/test/index.html) |; | integration | 8 | [6042319707.0](https://github.com/broadinstitute/gatk/actions/runs/6042319707/job/16397698607) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8507/merge_6042319707.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8507#issuecomment-1701786870:722,integrat,integration,722,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8507#issuecomment-1701786870,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6042371878](https://github.com/broadinstitute/gatk/actions/runs/6042371878); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6042371878.11](https://github.com/broadinstitute/gatk/actions/runs/6042371878/job/16397346871) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8507/merge_6042371878.11/tests/test/index.html) |; | unit | 11 | [6042371878.13](https://github.com/broadinstitute/gatk/actions/runs/6042371878/job/16397347119) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8507/merge_6042371878.13/tests/test/index.html) |; | integration | 11 | [6042371878.12](https://github.com/broadinstitute/gatk/actions/runs/6042371878/job/16397346988) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8507/merge_6042371878.12/tests/test/index.html) |; | integration | 8 | [6042371878.0](https://github.com/broadinstitute/gatk/actions/runs/6042371878/job/16398082223) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8507/merge_6042371878.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8507#issuecomment-1701796781:722,integrat,integration,722,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8507#issuecomment-1701796781,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6042485207](https://github.com/broadinstitute/gatk/actions/runs/6042485207); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 11 | [6042485207.11](https://github.com/broadinstitute/gatk/actions/runs/6042485207/job/16397690832) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8510/merge_6042485207.11/tests/test/index.html) |; | integration | 11 | [6042485207.12](https://github.com/broadinstitute/gatk/actions/runs/6042485207/job/16397691068) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8510/merge_6042485207.12/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8510#issuecomment-1701820013:486,integrat,integration,486,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8510#issuecomment-1701820013,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6316280004](https://github.com/broadinstitute/gatk/actions/runs/6316280004); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [6316280004.11](https://github.com/broadinstitute/gatk/actions/runs/6316280004/job/17150554514) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8531/merge_6316280004.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [6316280004.0](https://github.com/broadinstitute/gatk/actions/runs/6316280004/job/17151473162) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8531/merge_6316280004.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8531#issuecomment-1736046844:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8531#issuecomment-1736046844,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6316614080](https://github.com/broadinstitute/gatk/actions/runs/6316614080); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [6316614080.11](https://github.com/broadinstitute/gatk/actions/runs/6316614080/job/17151618497) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8531/merge_6316614080.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [6316614080.0](https://github.com/broadinstitute/gatk/actions/runs/6316614080/job/17152824309) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8531/merge_6316614080.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8531#issuecomment-1736096032:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8531#issuecomment-1736096032,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6317259261](https://github.com/broadinstitute/gatk/actions/runs/6317259261); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [6317259261.11](https://github.com/broadinstitute/gatk/actions/runs/6317259261/job/17153654271) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8531/merge_6317259261.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [6317259261.0](https://github.com/broadinstitute/gatk/actions/runs/6317259261/job/17154755203) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8531/merge_6317259261.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8531#issuecomment-1736210346:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8531#issuecomment-1736210346,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6384614693](https://github.com/broadinstitute/gatk/actions/runs/6384614693); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [6384614693.11](https://github.com/broadinstitute/gatk/actions/runs/6384614693/job/17327645653) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8538/merge_6384614693.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [6384614693.0](https://github.com/broadinstitute/gatk/actions/runs/6384614693/job/17328498137) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8538/merge_6384614693.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8538#issuecomment-1743692264:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8538#issuecomment-1743692264,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6384923533](https://github.com/broadinstitute/gatk/actions/runs/6384923533); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [6384923533.11](https://github.com/broadinstitute/gatk/actions/runs/6384923533/job/17328588432) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8538/merge_6384923533.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [6384923533.0](https://github.com/broadinstitute/gatk/actions/runs/6384923533/job/17329501887) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8538/merge_6384923533.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8538#issuecomment-1743745525:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8538#issuecomment-1743745525,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6385319684](https://github.com/broadinstitute/gatk/actions/runs/6385319684); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [6385319684.11](https://github.com/broadinstitute/gatk/actions/runs/6385319684/job/17329812414) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8538/merge_6385319684.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [6385319684.0](https://github.com/broadinstitute/gatk/actions/runs/6385319684/job/17330706422) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8538/merge_6385319684.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8538#issuecomment-1743797305:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8538#issuecomment-1743797305,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6789554372](https://github.com/broadinstitute/gatk/actions/runs/6789554372); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [6789554372.11](https://github.com/broadinstitute/gatk/actions/runs/6789554372/job/18457022627) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8576/merge_6789554372.11/tests/testOnPackagedReleaseJar/index.html) |; | variantcalling | 17.0.6+10 | [6789554372.2](https://github.com/broadinstitute/gatk/actions/runs/6789554372/job/18457717644) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8576/merge_6789554372.2/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [6789554372.0](https://github.com/broadinstitute/gatk/actions/runs/6789554372/job/18457717112) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8576/merge_6789554372.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8576#issuecomment-1800034428:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8576#issuecomment-1800034428,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6791158196](https://github.com/broadinstitute/gatk/actions/runs/6791158196); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [6791158196.11](https://github.com/broadinstitute/gatk/actions/runs/6791158196/job/18462089758) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8577/merge_6791158196.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [6791158196.0](https://github.com/broadinstitute/gatk/actions/runs/6791158196/job/18462671872) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8577/merge_6791158196.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8577#issuecomment-1800418349:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8577#issuecomment-1800418349,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6895762275](https://github.com/broadinstitute/gatk/actions/runs/6895762275); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [6895762275.11](https://github.com/broadinstitute/gatk/actions/runs/6895762275/job/18760424597) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8438/merge_6895762275.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [6895762275.0](https://github.com/broadinstitute/gatk/actions/runs/6895762275/job/18761169421) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8438/merge_6895762275.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8438#issuecomment-1815257468:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8438#issuecomment-1815257468,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6896352136](https://github.com/broadinstitute/gatk/actions/runs/6896352136); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [6896352136.11](https://github.com/broadinstitute/gatk/actions/runs/6896352136/job/18762290246) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8438/merge_6896352136.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [6896352136.0](https://github.com/broadinstitute/gatk/actions/runs/6896352136/job/18763038038) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8438/merge_6896352136.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8438#issuecomment-1815337019:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8438#issuecomment-1815337019,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [6906804987](https://github.com/broadinstitute/gatk/actions/runs/6906804987); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 21 | [6906804987.12](https://github.com/broadinstitute/gatk/actions/runs/6906804987/job/18792647185) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8589/merge_6906804987.12/tests/testOnPackagedReleaseJar/index.html) |; | cloud | 21 | [6906804987.10](https://github.com/broadinstitute/gatk/actions/runs/6906804987/job/18792646673) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8589/merge_6906804987.10/tests/testOnPackagedReleaseJar/index.html) |; | integration | 21 | [6906804987.11](https://github.com/broadinstitute/gatk/actions/runs/6906804987/job/18792646928) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8589/merge_6906804987.11/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8589#issuecomment-1816781546:762,integrat,integration,762,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8589#issuecomment-1816781546,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [7120763686](https://github.com/broadinstitute/gatk/actions/runs/7120763686); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [7120763686.10](https://github.com/broadinstitute/gatk/actions/runs/7120763686/job/19388722321) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8598/merge_7120763686.10/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [7120763686.11](https://github.com/broadinstitute/gatk/actions/runs/7120763686/job/19388722680) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8598/merge_7120763686.11/tests/testOnPackagedReleaseJar/index.html) |; | variantcalling | 17.0.6+10 | [7120763686.2](https://github.com/broadinstitute/gatk/actions/runs/7120763686/job/19389414633) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8598/merge_7120763686.2/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [7120763686.0](https://github.com/broadinstitute/gatk/actions/runs/7120763686/job/19389414172) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8598/merge_7120763686.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8598#issuecomment-1843776739:513,integrat,integration,513,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8598#issuecomment-1843776739,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [7131188447](https://github.com/broadinstitute/gatk/actions/runs/7131188447); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [7131188447.10](https://github.com/broadinstitute/gatk/actions/runs/7131188447/job/19419221705) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8464/merge_7131188447.10/tests/testOnPackagedReleaseJar/index.html) |; | variantcalling | 17.0.6+10 | [7131188447.2](https://github.com/broadinstitute/gatk/actions/runs/7131188447/job/19420081818) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8464/merge_7131188447.2/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [7131188447.0](https://github.com/broadinstitute/gatk/actions/runs/7131188447/job/19420081036) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8464/merge_7131188447.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8464#issuecomment-1845719692:784,integrat,integration,784,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8464#issuecomment-1845719692,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [7184026360](https://github.com/broadinstitute/gatk/actions/runs/7184026360); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [7184026360.11](https://github.com/broadinstitute/gatk/actions/runs/7184026360/job/19564156491) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8561/merge_7184026360.11/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1852393379:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1852393379,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [7186584675](https://github.com/broadinstitute/gatk/actions/runs/7186584675); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [7186584675.11](https://github.com/broadinstitute/gatk/actions/runs/7186584675/job/19572299359) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8561/merge_7186584675.11/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1852751599:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1852751599,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [7186790110](https://github.com/broadinstitute/gatk/actions/runs/7186790110); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [7186790110.11](https://github.com/broadinstitute/gatk/actions/runs/7186790110/job/19572967047) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8561/merge_7186790110.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [7186790110.11](https://github.com/broadinstitute/gatk/actions/runs/7186790110/job/19576556694) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8561/merge_7186790110.11/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1852787065:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-1852787065,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [7405843720](https://github.com/broadinstitute/gatk/actions/runs/7405843720); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [7405843720.12](https://github.com/broadinstitute/gatk/actions/runs/7405843720/job/20149400857) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8639/merge_7405843720.12/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [7405843720.11](https://github.com/broadinstitute/gatk/actions/runs/7405843720/job/20149400666) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8639/merge_7405843720.11/tests/testOnPackagedReleaseJar/index.html) |; | unit | 17.0.6+10 | [7405843720.1](https://github.com/broadinstitute/gatk/actions/runs/7405843720/job/20149740095) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8639/merge_7405843720.1/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [7405843720.0](https://github.com/broadinstitute/gatk/actions/runs/7405843720/job/20149740046) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8639/merge_7405843720.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8639#issuecomment-1876373370:512,integrat,integration,512,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8639#issuecomment-1876373370,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [7891988613](https://github.com/broadinstitute/gatk/actions/runs/7891988613); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [7891988613.11](https://github.com/broadinstitute/gatk/actions/runs/7891988613/job/21537494791) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8689/merge_7891988613.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [7891988613.0](https://github.com/broadinstitute/gatk/actions/runs/7891988613/job/21538268383) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8689/merge_7891988613.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8689#issuecomment-1942405438:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8689#issuecomment-1942405438,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [7905273867](https://github.com/broadinstitute/gatk/actions/runs/7905273867); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [7905273867.11](https://github.com/broadinstitute/gatk/actions/runs/7905273867/job/21577524746) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8689/merge_7905273867.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [7905273867.0](https://github.com/broadinstitute/gatk/actions/runs/7905273867/job/21578446531) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8689/merge_7905273867.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8689#issuecomment-1944365526:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8689#issuecomment-1944365526,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [7920773846](https://github.com/broadinstitute/gatk/actions/runs/7920773846); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [7920773846.11](https://github.com/broadinstitute/gatk/actions/runs/7920773846/job/21624558365) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8674/merge_7920773846.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [7920773846.0](https://github.com/broadinstitute/gatk/actions/runs/7920773846/job/21625457399) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8674/merge_7920773846.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8674#issuecomment-1947033740:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8674#issuecomment-1947033740,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [7920955548](https://github.com/broadinstitute/gatk/actions/runs/7920955548); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [7920955548.11](https://github.com/broadinstitute/gatk/actions/runs/7920955548/job/21625179661) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8674/merge_7920955548.11/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8674#issuecomment-1947096700:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8674#issuecomment-1947096700,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [7921949505](https://github.com/broadinstitute/gatk/actions/runs/7921949505); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [7921949505.11](https://github.com/broadinstitute/gatk/actions/runs/7921949505/job/21628408055) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8674/merge_7921949505.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [7921949505.0](https://github.com/broadinstitute/gatk/actions/runs/7921949505/job/21629187149) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8674/merge_7921949505.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8674#issuecomment-1947340306:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8674#issuecomment-1947340306,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [7921992136](https://github.com/broadinstitute/gatk/actions/runs/7921992136); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [7921992136.11](https://github.com/broadinstitute/gatk/actions/runs/7921992136/job/21628545390) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8674/merge_7921992136.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [7921992136.0](https://github.com/broadinstitute/gatk/actions/runs/7921992136/job/21629407362) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8674/merge_7921992136.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8674#issuecomment-1947344522:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8674#issuecomment-1947344522,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [7922661849](https://github.com/broadinstitute/gatk/actions/runs/7922661849); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [7922661849.11](https://github.com/broadinstitute/gatk/actions/runs/7922661849/job/21630756683) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8674/merge_7922661849.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [7922661849.0](https://github.com/broadinstitute/gatk/actions/runs/7922661849/job/21631484142) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8674/merge_7922661849.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8674#issuecomment-1947428539:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8674#issuecomment-1947428539,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [8161782218](https://github.com/broadinstitute/gatk/actions/runs/8161782218); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8161782218.11](https://github.com/broadinstitute/gatk/actions/runs/8161782218/job/22311279082) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8715/merge_8161782218.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [8161782218.0](https://github.com/broadinstitute/gatk/actions/runs/8161782218/job/22312090528) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8715/merge_8161782218.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8715#issuecomment-1979517535:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8715#issuecomment-1979517535,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [8164035876](https://github.com/broadinstitute/gatk/actions/runs/8164035876); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8164035876.11](https://github.com/broadinstitute/gatk/actions/runs/8164035876/job/22318490548) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8715/merge_8164035876.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [8164035876.0](https://github.com/broadinstitute/gatk/actions/runs/8164035876/job/22319181115) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8715/merge_8164035876.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8715#issuecomment-1979799202:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8715#issuecomment-1979799202,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [8176966441](https://github.com/broadinstitute/gatk/actions/runs/8176966441); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8176966441.11](https://github.com/broadinstitute/gatk/actions/runs/8176966441/job/22357552500) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8718/merge_8176966441.11/tests/testOnPackagedReleaseJar/index.html) |; | integration | 17.0.6+10 | [8176966441.0](https://github.com/broadinstitute/gatk/actions/runs/8176966441/job/22358473526) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8718/merge_8176966441.0/tests/testOnPackagedReleaseJar/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8718#issuecomment-1981582998:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8718#issuecomment-1981582998,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [8177733856](https://github.com/broadinstitute/gatk/actions/runs/8177733856); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8177733856.11](https://github.com/broadinstitute/gatk/actions/runs/8177733856/job/22360049221) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8718/merge_8177733856.11/tests/test/index.html) |; | integration | 17.0.6+10 | [8177733856.0](https://github.com/broadinstitute/gatk/actions/runs/8177733856/job/22361011218) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8718/merge_8177733856.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8718#issuecomment-1981697888:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8718#issuecomment-1981697888,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [8509671598](https://github.com/broadinstitute/gatk/actions/runs/8509671598); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8509671598.11](https://github.com/broadinstitute/gatk/actions/runs/8509671598/job/23305710482) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8756/merge_8509671598.11/tests/test/index.html) |; | integration | 17.0.6+10 | [8509671598.0](https://github.com/broadinstitute/gatk/actions/runs/8509671598/job/23306610390) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8756/merge_8509671598.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8756#issuecomment-2029982633:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8756#issuecomment-2029982633,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [8524189026](https://github.com/broadinstitute/gatk/actions/runs/8524189026); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8524189026.11](https://github.com/broadinstitute/gatk/actions/runs/8524189026/job/23348239562) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8524189026.11/tests/test/index.html) |; | variantcalling | 17.0.6+10 | [8524189026.2](https://github.com/broadinstitute/gatk/actions/runs/8524189026/job/23349497146) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8524189026.2/tests/test/index.html) |; | integration | 17.0.6+10 | [8524189026.0](https://github.com/broadinstitute/gatk/actions/runs/8524189026/job/23349496223) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8524189026.0/tests/test/index.html) |; | unit | 17.0.6+10 | [8524189026.12](https://github.com/broadinstitute/gatk/actions/runs/8524189026/job/23348239909) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8524189026.12/tests/test/index.html) |; | unit | 17.0.6+10 | [8524189026.1](https://github.com/broadinstitute/gatk/actions/runs/8524189026/job/23349496656) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8524189026.1/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8741#issuecomment-2032228356:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8741#issuecomment-2032228356,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [8524495307](https://github.com/broadinstitute/gatk/actions/runs/8524495307); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [8524495307.12](https://github.com/broadinstitute/gatk/actions/runs/8524495307/job/23349224262) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8524495307.12/tests/test/index.html) |; | integration | 17.0.6+10 | [8524495307.11](https://github.com/broadinstitute/gatk/actions/runs/8524495307/job/23349223900) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8524495307.11/tests/test/index.html) |; | unit | 17.0.6+10 | [8524495307.1](https://github.com/broadinstitute/gatk/actions/runs/8524495307/job/23350493955) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8524495307.1/tests/test/index.html) |; | variantcalling | 17.0.6+10 | [8524495307.2](https://github.com/broadinstitute/gatk/actions/runs/8524495307/job/23350494281) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8524495307.2/tests/test/index.html) |; | integration | 17.0.6+10 | [8524495307.0](https://github.com/broadinstitute/gatk/actions/runs/8524495307/job/23350493586) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8524495307.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8741#issuecomment-2032255571:492,integrat,integration,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8741#issuecomment-2032255571,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [8541176894](https://github.com/broadinstitute/gatk/actions/runs/8541176894); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8541176894.11](https://github.com/broadinstitute/gatk/actions/runs/8541176894/job/23399915907) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8541176894.11/tests/test/index.html) |; | variantcalling | 17.0.6+10 | [8541176894.2](https://github.com/broadinstitute/gatk/actions/runs/8541176894/job/23401028686) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8541176894.2/tests/test/index.html) |; | integration | 17.0.6+10 | [8541176894.0](https://github.com/broadinstitute/gatk/actions/runs/8541176894/job/23401027987) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8541176894.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8741#issuecomment-2034980199:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8741#issuecomment-2034980199,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [8545290623](https://github.com/broadinstitute/gatk/actions/runs/8545290623); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8545290623.11](https://github.com/broadinstitute/gatk/actions/runs/8545290623/job/23413247429) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8545290623.11/tests/test/index.html) |; | variantcalling | 17.0.6+10 | [8545290623.2](https://github.com/broadinstitute/gatk/actions/runs/8545290623/job/23414070801) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8545290623.2/tests/test/index.html) |; | integration | 17.0.6+10 | [8545290623.0](https://github.com/broadinstitute/gatk/actions/runs/8545290623/job/23414070420) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8545290623.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8741#issuecomment-2035612373:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8741#issuecomment-2035612373,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [8570036475](https://github.com/broadinstitute/gatk/actions/runs/8570036475); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8570036475.11](https://github.com/broadinstitute/gatk/actions/runs/8570036475/job/23487147373) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8570036475.11/tests/test/index.html) |; | integration | 17.0.6+10 | [8570036475.0](https://github.com/broadinstitute/gatk/actions/runs/8570036475/job/23488077738) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8741/merge_8570036475.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8741#issuecomment-2039788908:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8741#issuecomment-2039788908,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [8648792151](https://github.com/broadinstitute/gatk/actions/runs/8648792151); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [8648792151.12](https://github.com/broadinstitute/gatk/actions/runs/8648792151/job/23713495402) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8771/merge_8648792151.12/tests/test/index.html) |; | integration | 17.0.6+10 | [8648792151.11](https://github.com/broadinstitute/gatk/actions/runs/8648792151/job/23713495044) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8771/merge_8648792151.11/tests/test/index.html) |; | unit | 17.0.6+10 | [8648792151.1](https://github.com/broadinstitute/gatk/actions/runs/8648792151/job/23714601757) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8771/merge_8648792151.1/tests/test/index.html) |; | integration | 17.0.6+10 | [8648792151.0](https://github.com/broadinstitute/gatk/actions/runs/8648792151/job/23714601308) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8771/merge_8648792151.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8771#issuecomment-2049933470:492,integrat,integration,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8771#issuecomment-2049933470,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [8854148674](https://github.com/broadinstitute/gatk/actions/runs/8854148674); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8854148674.11](https://github.com/broadinstitute/gatk/actions/runs/8854148674/job/24316579325) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8796/merge_8854148674.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8796#issuecomment-2080186235:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8796#issuecomment-2080186235,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [8882582500](https://github.com/broadinstitute/gatk/actions/runs/8882582500); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8882582500.11](https://github.com/broadinstitute/gatk/actions/runs/8882582500/job/24387605743) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8796/merge_8882582500.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8796#issuecomment-2083371351:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8796#issuecomment-2083371351,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [8883008459](https://github.com/broadinstitute/gatk/actions/runs/8883008459); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8883008459.11](https://github.com/broadinstitute/gatk/actions/runs/8883008459/job/24388921100) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8799/merge_8883008459.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8799#issuecomment-2083846921:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8799#issuecomment-2083846921,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [8992751464](https://github.com/broadinstitute/gatk/actions/runs/8992751464); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [8992751464.11](https://github.com/broadinstitute/gatk/actions/runs/8992751464/job/24703225763) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8819/merge_8992751464.11/tests/test/index.html) |; | integration | 17.0.6+10 | [8992751464.0](https://github.com/broadinstitute/gatk/actions/runs/8992751464/job/24703962607) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8819/merge_8992751464.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8819#issuecomment-2099410966:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8819#issuecomment-2099410966,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [9085418098](https://github.com/broadinstitute/gatk/actions/runs/9085418098); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [9085418098.11](https://github.com/broadinstitute/gatk/actions/runs/9085418098/job/24968705742) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8832/merge_9085418098.11/tests/test/index.html) |; | integration | 17.0.6+10 | [9085418098.0](https://github.com/broadinstitute/gatk/actions/runs/9085418098/job/24969675014) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8832/merge_9085418098.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8832#issuecomment-2111091907:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8832#issuecomment-2111091907,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [9085946968](https://github.com/broadinstitute/gatk/actions/runs/9085946968); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [9085946968.11](https://github.com/broadinstitute/gatk/actions/runs/9085946968/job/24970476460) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8832/merge_9085946968.11/tests/test/index.html) |; | integration | 17.0.6+10 | [9085946968.0](https://github.com/broadinstitute/gatk/actions/runs/9085946968/job/24971377026) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8832/merge_9085946968.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8832#issuecomment-2111156268:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8832#issuecomment-2111156268,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [9368869663](https://github.com/broadinstitute/gatk/actions/runs/9368869663); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [9368869663.11](https://github.com/broadinstitute/gatk/actions/runs/9368869663/job/25791969117) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8832/merge_9368869663.11/tests/test/index.html) |; | integration | 17.0.6+10 | [9368869663.0](https://github.com/broadinstitute/gatk/actions/runs/9368869663/job/25793353779) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8832/merge_9368869663.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8832#issuecomment-2147749326:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8832#issuecomment-2147749326,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [9386157234](https://github.com/broadinstitute/gatk/actions/runs/9386157234); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [9386157234.12](https://github.com/broadinstitute/gatk/actions/runs/9386157234/job/25846033405) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9386157234.12/tests/test/index.html) |; | integration | 17.0.6+10 | [9386157234.11](https://github.com/broadinstitute/gatk/actions/runs/9386157234/job/25846033042) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9386157234.11/tests/test/index.html) |; | unit | 17.0.6+10 | [9386157234.1](https://github.com/broadinstitute/gatk/actions/runs/9386157234/job/25847284448) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9386157234.1/tests/test/index.html) |; | integration | 17.0.6+10 | [9386157234.0](https://github.com/broadinstitute/gatk/actions/runs/9386157234/job/25847283864) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9386157234.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2150295571:492,integrat,integration,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2150295571,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [9454902078](https://github.com/broadinstitute/gatk/actions/runs/9454902078); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [9454902078.11](https://github.com/broadinstitute/gatk/actions/runs/9454902078/job/26043508758) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8862/merge_9454902078.11/tests/test/index.html) |; | integration | 17.0.6+10 | [9454902078.0](https://github.com/broadinstitute/gatk/actions/runs/9454902078/job/26044426261) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8862/merge_9454902078.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8862#issuecomment-2159253862:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8862#issuecomment-2159253862,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [9470383170](https://github.com/broadinstitute/gatk/actions/runs/9470383170); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [9470383170.12](https://github.com/broadinstitute/gatk/actions/runs/9470383170/job/26091160198) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9470383170.12/tests/test/index.html) |; | integration | 17.0.6+10 | [9470383170.11](https://github.com/broadinstitute/gatk/actions/runs/9470383170/job/26091159923) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9470383170.11/tests/test/index.html) |; | unit | 17.0.6+10 | [9470383170.1](https://github.com/broadinstitute/gatk/actions/runs/9470383170/job/26092096141) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9470383170.1/tests/test/index.html) |; | integration | 17.0.6+10 | [9470383170.0](https://github.com/broadinstitute/gatk/actions/runs/9470383170/job/26092095804) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9470383170.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2161344780:492,integrat,integration,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2161344780,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [9685898135](https://github.com/broadinstitute/gatk/actions/runs/9685898135); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [9685898135.12](https://github.com/broadinstitute/gatk/actions/runs/9685898135/job/26727088598) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9685898135.12/tests/test/index.html) |; | integration | 17.0.6+10 | [9685898135.11](https://github.com/broadinstitute/gatk/actions/runs/9685898135/job/26727088323) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9685898135.11/tests/test/index.html) |; | unit | 17.0.6+10 | [9685898135.1](https://github.com/broadinstitute/gatk/actions/runs/9685898135/job/26727998365) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9685898135.1/tests/test/index.html) |; | integration | 17.0.6+10 | [9685898135.0](https://github.com/broadinstitute/gatk/actions/runs/9685898135/job/26727998072) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9685898135.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2192548316:492,integrat,integration,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2192548316,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [9688050367](https://github.com/broadinstitute/gatk/actions/runs/9688050367); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [9688050367.12](https://github.com/broadinstitute/gatk/actions/runs/9688050367/job/26733866970) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9688050367.12/tests/test/index.html) |; | integration | 17.0.6+10 | [9688050367.11](https://github.com/broadinstitute/gatk/actions/runs/9688050367/job/26733866854) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9688050367.11/tests/test/index.html) |; | unit | 17.0.6+10 | [9688050367.1](https://github.com/broadinstitute/gatk/actions/runs/9688050367/job/26734370526) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9688050367.1/tests/test/index.html) |; | integration | 17.0.6+10 | [9688050367.0](https://github.com/broadinstitute/gatk/actions/runs/9688050367/job/26734370399) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9688050367.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2192792284:492,integrat,integration,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2192792284,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [9688780153](https://github.com/broadinstitute/gatk/actions/runs/9688780153); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [9688780153.12](https://github.com/broadinstitute/gatk/actions/runs/9688780153/job/26735949170) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9688780153.12/tests/test/index.html) |; | integration | 17.0.6+10 | [9688780153.11](https://github.com/broadinstitute/gatk/actions/runs/9688780153/job/26735949043) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9688780153.11/tests/test/index.html) |; | unit | 17.0.6+10 | [9688780153.1](https://github.com/broadinstitute/gatk/actions/runs/9688780153/job/26736488133) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9688780153.1/tests/test/index.html) |; | integration | 17.0.6+10 | [9688780153.0](https://github.com/broadinstitute/gatk/actions/runs/9688780153/job/26736487991) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9688780153.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2192866266:492,integrat,integration,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2192866266,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [9690704227](https://github.com/broadinstitute/gatk/actions/runs/9690704227); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | 17.0.6+10 | [9690704227.12](https://github.com/broadinstitute/gatk/actions/runs/9690704227/job/26740984048) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9690704227.12/tests/test/index.html) |; | integration | 17.0.6+10 | [9690704227.11](https://github.com/broadinstitute/gatk/actions/runs/9690704227/job/26740983925) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9690704227.11/tests/test/index.html) |; | unit | 17.0.6+10 | [9690704227.1](https://github.com/broadinstitute/gatk/actions/runs/9690704227/job/26741470210) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9690704227.1/tests/test/index.html) |; | integration | 17.0.6+10 | [9690704227.0](https://github.com/broadinstitute/gatk/actions/runs/9690704227/job/26741470114) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9690704227.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2193694066:492,integrat,integration,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2193694066,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [9690907019](https://github.com/broadinstitute/gatk/actions/runs/9690907019); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [9690907019.11](https://github.com/broadinstitute/gatk/actions/runs/9690907019/job/26741532368) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9690907019.11/tests/test/index.html) |; | integration | 17.0.6+10 | [9690907019.0](https://github.com/broadinstitute/gatk/actions/runs/9690907019/job/26742056381) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9690907019.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2193773007:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2193773007,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [9699861398](https://github.com/broadinstitute/gatk/actions/runs/9699861398); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [9699861398.11](https://github.com/broadinstitute/gatk/actions/runs/9699861398/job/26769897173) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9699861398.11/tests/test/index.html) |; | integration | 17.0.6+10 | [9699861398.0](https://github.com/broadinstitute/gatk/actions/runs/9699861398/job/26770925465) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8863/merge_9699861398.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2195179629:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8863#issuecomment-2195179629,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [9702596193](https://github.com/broadinstitute/gatk/actions/runs/9702596193); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | cloud | 17.0.6+10 | [9702596193.10](https://github.com/broadinstitute/gatk/actions/runs/9702596193/job/26778809125) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8888/merge_9702596193.10/tests/test/index.html) |; | integration | 17.0.6+10 | [9702596193.11](https://github.com/broadinstitute/gatk/actions/runs/9702596193/job/26778809399) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8888/merge_9702596193.11/tests/test/index.html) |; | unit | 17.0.6+10 | [9702596193.12](https://github.com/broadinstitute/gatk/actions/runs/9702596193/job/26778809607) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8888/merge_9702596193.12/tests/test/index.html) |; | variantcalling | 17.0.6+10 | [9702596193.2](https://github.com/broadinstitute/gatk/actions/runs/9702596193/job/26779620275) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8888/merge_9702596193.2/tests/test/index.html) |; | integration | 17.0.6+10 | [9702596193.0](https://github.com/broadinstitute/gatk/actions/runs/9702596193/job/26779619836) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8888/merge_9702596193.0/tests/test/index.html) |; | unit | 17.0.6+10 | [9702596193.1](https://github.com/broadinstitute/gatk/actions/runs/9702596193/job/26779620060) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8888/merge_9702596193.1/tests/test/index.html) |; | conda | 17.0.6+10 | [9702596193.3](https://github.com/broadinstitute/gatk/actions/runs/9702596193/job/26779620516) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8888/merge_9702596193.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8888#issuecomment-2195558811:493,integrat,integration,493,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8888#issuecomment-2195558811,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [9859920680](https://github.com/broadinstitute/gatk/actions/runs/9859920680); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [9859920680.11](https://github.com/broadinstitute/gatk/actions/runs/9859920680/job/27224817827) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8521/merge_9859920680.11/tests/test/index.html) |; | integration | 17.0.6+10 | [9859920680.0](https://github.com/broadinstitute/gatk/actions/runs/9859920680/job/27225663620) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8521/merge_9859920680.0/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8521#issuecomment-2218092798:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8521#issuecomment-2218092798,2,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [9860282479](https://github.com/broadinstitute/gatk/actions/runs/9860282479); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [9860282479.11](https://github.com/broadinstitute/gatk/actions/runs/9860282479/job/27226057661) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8561/merge_9860282479.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2218139213:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2218139213,1,['integrat'],['integration']
Integrability,Github actions tests reported job failures from actions build [9860496699](https://github.com/broadinstitute/gatk/actions/runs/9860496699); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | 17.0.6+10 | [9860496699.11](https://github.com/broadinstitute/gatk/actions/runs/9860496699/job/27226809021) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/8561/merge_9860496699.11/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2218189122:249,integrat,integration,249,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8561#issuecomment-2218189122,1,['integrat'],['integration']
Integrability,"Given that Sam's 1D model still depends on ReadPosRankSum and his 2D model takes annotations plus the trimmed bamout regions, the CNN isn't getting the best read position info either. I think this would definitely be useful on the germline side.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4856#issuecomment-395438288:32,depend,depends,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4856#issuecomment-395438288,1,['depend'],['depends']
Integrability,"Given that the tools in this PR are marked as experimental, I think it should be possible @lucidtronix. It would be good, though, if we could recruit someone (@samuelklee ? @mbabadi ?) to do a review pass on the Python side of this branch, as I don't think it's had a proper code review yet. We should also make sure that @cmnbroad is satisfied that the new tools are covered by good end-to-end integration tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367397138:395,integrat,integration,395,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367397138,1,['integrat'],['integration']
Integrability,"Given the above behavior, and looking at the error message produced, I wonder if it might not be an issue with the GenomicsDB, but rather just a bug in the code that doesn't properly no-call individuals at sites with too many alleles. I wonder that because the error message is emitted at the bottom of this block: . [https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/afcalc/AlleleFrequencyCalculator.java#L78-L90](https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/afcalc/AlleleFrequencyCalculator.java#L78-L90). and it only gets there for diploids if neither of `g.isHomRef()` or `g.isNoCall()` is true.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1014188838:51,message,message,51,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1014188838,2,['message'],['message']
Integrability,"Going to build and push a new 1.2.2 base image off of https://github.com/broadinstitute/gatk/tree/sl_getopt, which restores the dependency as it was previously.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359985913:128,depend,dependency,128,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359985913,1,['depend'],['dependency']
Integrability,"Good catch @EdwardDixon. From @cmnbroad 's Oct 12 post:; >We may need to provide a fallback environment for those (I'll try to get resolution on that). If it turns out we do, I'm actually not suggesting the fallback be automatic (3 in your list), just that we have a **graceful failure mode and an instructive error message.**. We have this now, right? Just want to be sure. If there's more work to be done, let's hash it out on another PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-438735712:316,message,message,316,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-438735712,1,['message'],['message']
Integrability,"Good clarification, but can you clean up the format a little? I'd like to see a colon instead of a comma after note and a hard return two wrap the long line (so that it lines up with the lines above).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4517#issuecomment-371871762:138,wrap,wrap,138,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4517#issuecomment-371871762,1,['wrap'],['wrap']
Integrability,Got a 503 that doesn't have the `All reopens failed` message:. ```; com.google.cloud.storage.StorageException: 503 Service Unavailable; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:335); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:550); 	at java.nio.file.Files.exists(Files.java:2385); 	at htsjdk.tribble.util.ParsingUtils.resourceExists(ParsingUtils.java:428); 	at htsjdk.tribble.AbstractFeatureReader.isTabix(AbstractFeatureReader.java:217); 	at htsjdk.tribble.AbstractFeatureReader$ComponentMethods.isTabix(AbstractFeatureReader.java:223); 	at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:103); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.getReaderFromVCFUri(GenomicsDBImport.java:454); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.getFeatureReaders(GenomicsDBImport.java:436); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse(GenomicsDBImport.java:358); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:779); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandL,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2749#issuecomment-308540929:53,message,message,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2749#issuecomment-308540929,1,['message'],['message']
Integrability,"Great to hear we figured out the discrepancy!. As for which set of parameters you should choose, the answer will be dependent on your data, so I cannot give strong recommendations without having much more information. Ideally, you would have some evaluation based on truth/concordance data that would inform your decision. But if you were happy with the old results, I might recommend sticking with them. It's very possible that the default parameters, which I believe were chosen for the UKBB analysis done in the gCNV publication, might not be suitable for your data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8628#issuecomment-1858041507:116,depend,dependent,116,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8628#issuecomment-1858041507,1,['depend'],['dependent']
Integrability,"HaplotypeCaller, GenotypeGVCFs, and GenomicsDBImport integration tests are all passing locally. I'll check Travis in the morning to see what tests are left to update.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5484#issuecomment-457893993:53,integrat,integration,53,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5484#issuecomment-457893993,1,['integrat'],['integration']
Integrability,"Happy to chat more @samuelklee, but for now in our use case this isn't super important to have this tuning step fully integrated into the tool. Of course I didn't respond to your first comment quickly enough and I completely agree with the approach you laid out in the second comment. . I can try adding this new workflow to the WDL and testing it out as well. I have some GIAB samples so the test you mention about comparing the LL to an orthogonal F1 should be doable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1066852670:118,integrat,integrated,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1066852670,1,['integrat'],['integrated']
Integrability,Have you run an integration test?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8847#issuecomment-2135781130:16,integrat,integration,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8847#issuecomment-2135781130,1,['integrat'],['integration']
Integrability,"Hello - I'm writing to check on these PRs again. I appreciate these are not GATK's priority, but they're blocking #6973 and we've been stuck for a long time here. If there is additional work, testing or anything needed on this I am happy to offer my time if there's anything that would help get this done. For example, while this PR creates the VC comparison code, it doesnt integrate it into existing tests. if doing this would help accelerate approving this I would be willing to take a stab at this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7021#issuecomment-814233123:375,integrat,integrate,375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7021#issuecomment-814233123,1,['integrat'],['integrate']
Integrability,"Hello @freeseek. It should be noted that you might be somewhat confused about what the -SO arguments do in the tools:; `-SORT_ORDER ""unsorted""` which has the help description `""The order in which the merged reads should be output. Default value: coordinate. Possible values: {unsorted, queryname, coordinate, duplicate, unknown}.""` For MergeBamAlignment that argument doesn't change how the input sort order is treated but rather is used to determine whether the tool will resort your reads before outputting them. Currently it looks like MergeBamAlignment requires queryname sorted inputs: `""Original SAM or BAM file of unmapped reads, which must be in queryname order. Reads MUST be unmapped.""` and will crash with the unhelpful message you encountered. It may be possible to loosen this restriction to queryname-grouped inputs (since it really primarily needs the mates adjacent to each other but not necessarily in readname order). The place to have this discussion would be here https://github.com/broadinstitute/picard since this tool is a picard tool that is called into by GATK and any changes would need to be approved by the maintainers of that repo.. Furthermore, I would recommend using the gatk forums here: https://gatk.broadinstitute.org/hc/en-us/community/topics There are users and moderators there who might be able to help you answer questions like this for you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7398#issuecomment-902946080:731,message,message,731,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7398#issuecomment-902946080,1,['message'],['message']
Integrability,Hello @lindenb. . I think I found what is going on here and its a bug on our part that we didn't provide a better error for this issue. In the bed file you uploaded this is the offending interval:; `GL000223.1 178912 180554`; Unfortunately this is the length of that interval in the hg37 decoy sequence dictionary is as follows:; `@SQ SN:GL000223.1 LN:180455`; So it seems the issue here is that something got mangled and you are requesting a bad interval. It turns out we were using a codepath that failed to check that the interval was valid when specified as a bed file and active region padding code was using the correct interval based on the dictionary. This should be an easy fix on your end. I am making a branch that should trigger a better check and error message.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7289#issuecomment-856162960:766,message,message,766,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7289#issuecomment-856162960,1,['message'],['message']
Integrability,"Hello Geraldine:. > On 1/Mar/2017, at 7:56 PM, Geraldine Van der Auwera <notifications@github.com> wrote:; > ; > @chlangley One thing we could potentially do to attract attention to this issue and solicit feedback from the community would be to feature it on the GATK blog. If you were to write a concise case study detailing the impact of the problem on your results, others may be motivated to look at their own results, and if it causes problems there, add their voices to yours. We're willing to bring this to public attention, we just don't have the bandwidth to do the legwork. I started to work on this a bit and found myself blocked. . At this point I have a simple question: The GATK blog is separate from the forum (?). When I am on the blog page I can’t seem to find a button to submit a new post. I must be missing something or the route to blog posting is only via the forum?. Sorry to bother you with such mundane question. Cheers,; Chuck",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/269#issuecomment-287541436:844,rout,route,844,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/269#issuecomment-287541436,1,['rout'],['route']
Integrability,"Hello everyone: I am realizing that the GATK framework is going to have a lot of dependencies from java and python even if the simpler framework is the one need it. Maybe it is a good idea to start thinking about sub-modules within the same repository for the engine (maybe even separate the Spark framework), CNV...and create an independent artifact for every of them, and one combined one. Does it sound reasonable?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-346051614:81,depend,dependencies,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-346051614,2,['depend'],['dependencies']
Integrability,"Hello,; yes simply because i was working under the base environment of conda, so; conda deactivate command solved the problem. Le dim. 9 avr. 2023 à 15:09, wangwenzheng-agis ***@***.***> a; écrit :. > Hi,i have the same problem, have you solve it ?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/8280#issuecomment-1501137724>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AWCQKJGPGKTPFL54TTIL5LLXAK7INANCNFSM6AAAAAAWV6IL2A>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8280#issuecomment-1501146041:576,Message,Message,576,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8280#issuecomment-1501146041,1,['Message'],['Message']
Integrability,"Hey @ccartermices. Looking at that error message it appears that the genotype given alleles has tried to insert a '\*' allele into an assembled haplotype. (""TTTTGAC\*TTCGC"" in the error message). I suspect this is because the code is missing a check to filter symbolic alleles out of GGA inputs. Can you check your input `db_raw_call_bbe_6largest.vcf` for `\*` alleles? It should be possible to filter those out of your input file.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6260#issuecomment-552999630:41,message,message,41,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6260#issuecomment-552999630,2,['message'],['message']
Integrability,"Hey @jean-philippe-martin, this looks good. I've made some very small changes to avoid the back-and-forth of a review, and rebased the branch onto latest master. . The main change I made was in `IOUtils.getPath()`. It now traps the `IOException` and throws a `UserException` instead. This has the benefit of not requiring client code to put `throws IOException` (or catch the `IOException`) everywhere, and is more consistent with the rest of the codebase, which typically traps checked exceptions as early as possible and wraps them in unchecked exceptions (either `UserException` or `GATKException`, depending on whether it's likely to be the user's fault or not). Also made a small change in `NioBam` to make it use a logger instead of `System.out.println()` for debug output.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2224#issuecomment-259798014:523,wrap,wraps,523,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2224#issuecomment-259798014,2,"['depend', 'wrap']","['depending', 'wraps']"
Integrability,"Hey @jemunro,. Thanks for sharing your fix. I tried it on my data but now I have this ERROR message:; ```; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A GATK RUNTIME ERROR has occurred (version 3.8-0-ge9d806836):; ##### ERROR; ##### ERROR This might be a bug. Please check the documentation guide to see if this is a known problem.; ##### ERROR If not, please post the error message, with stack trace, to the GATK forum.; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR MESSAGE: For input string: ""NaN\1SOR=0.693""; ##### ERROR ------------------------------------------------------------------------------------------; INFO 13:46:00,793 HelpFormatter - ---------------------------------------------------------------------------------- ; ```; Would not be enough to use this code instead?:; ```; bcftools view in.vcf.gz |; sed 's/=nan/=NaN/g' |; bgzip > fixed.vcf.gz; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734:92,message,message,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734,5,"['MESSAGE', 'message']","['MESSAGE', 'message']"
Integrability,"Hey @mwalker174 ,. Do you have any suggestions about how to perform step 1? I naively tried to use picard's `MergeBamAlignment` using the PathSeq output BAM as the aligned bam and the PathSeq input BAM as the unmapped BAM but I get the following error message. `IllegalArgumentException: Do not use this function to merge dictionaries with different sequences in them. Sequences must be in the same order as well. Found [NZ_DS990135.1, NZ_AJSY01000035.1, ... `. I tried sorting both BAM files by queryname and removing the alignment for the input BAM using `RevertSam` but neither of these worked. I suspect that it's because of the PathSeq output BAM given the references to the microbial sequences. Do you have any suggestions?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6655#issuecomment-644426370:252,message,message,252,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6655#issuecomment-644426370,1,['message'],['message']
Integrability,"Hey @rsasch -- Just thinking out loud here… but does WDL seem like the right ""language"" to implement these sort of checks? It just feels like there is a ton of boilerplate, the WDL/bash constructs are a bit hard to follow, and I'm sure the development cycles were pretty slow waiting for cromwell to spin up all those VMs, etc. An alternative would be to write all these validations as a python script, which could make better use of structure (ie authenticating once, etc) and I bet would be quite a bit more readable. You could also run it locally if needed for development, debugging and then ultimately wrap it into a single-task WDL so it could be run easily from Terra. Happy to chat more",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7352#issuecomment-883435010:607,wrap,wrap,607,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7352#issuecomment-883435010,1,['wrap'],['wrap']
Integrability,"Hey Chris. Tagging you for some triage help. User has reported ""Figured it out, this is what you get when you run out of disk space. Please could this error message be made more helpful please?"" Is there anything you can do? A better error message would help, but not sure who to assign this to.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5064#issuecomment-408466937:157,message,message,157,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5064#issuecomment-408466937,2,['message'],['message']
Integrability,"Hi @Jolleboll, that depends on number of intervals in your count matrix. In general we ask to submit these types of questions to our community forum: https://gatk.broadinstitute.org/hc/en-us/community/topics. Please post your question there with the corresponding details about the number of intervals, and tool's standard output. ; Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6166#issuecomment-1244205969:20,depend,depends,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6166#issuecomment-1244205969,1,['depend'],['depends']
Integrability,Hi @Nanderson246 ; This is a known issue that requires us to update the conda environment and its dependencies on our end which all rely on older versions of certain R and python tools. Direct intervention and changing this code breaks certain unit tests which result in failure to build our conda and docker environments. This is a works in progress for our newer conda and docker environment however for the time being you may manually edit your R scripts to solve it or use R from our conda or docker environments to generate images. I hope this helps. Regards.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8992#issuecomment-2391551502:98,depend,dependencies,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8992#issuecomment-2391551502,1,['depend'],['dependencies']
Integrability,"Hi @Neato-Nick @davidbenjamin . Apologies for posting this message here. I have posted this message few days before at the regular GATK forum and also using the direct inbox option but have got no response so maybe something wrong with my account. The issue is - I have done variant calling on 384 potato samples following, mostly, GATK best ##practices and have applied hard filters to select SNPs for further usage. However, I am noticing that '--max-nocall-fraction', '--max-nocall-number' and '--max-fraction-filtered-genotypes' arguments for 'SelectVariants' are not working properly. I have tried with various cutoff settings and every time I am observing SNPs with a much larger number of genotypes (~246 out of 384 with 0.10 setting) with 'no call' than the set thresholds. I have searched the forum first but couldn't find any relevant threads. I am using the latest GATK version (4.0.7.0). I am attaching three example sets of (1) log files (2) subset vcf files and (3) vcf index file for the three main vcfs. I would appreciate if you could provide any feedback on this issue and/or if this behaviour has been observed by some other users also. The link to the original post is here:; https://gatkforums.broadinstitute.org/gatk/discussion/12688/possible-bug-in-selectvariants-tool#latest; [SelectVariantBugReport.zip](https://github.com/broadinstitute/gatk/files/2291206/SelectVariantBugReport.zip). Regards,; Sanjeev",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-413285177:59,message,message,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-413285177,4,['message'],['message']
Integrability,"Hi @Nehir291, please refer to the SVAnnotate tool documentation for definitions of each annotation: https://gatk.broadinstitute.org/hc/en-us/articles/21905053774363-SVAnnotate. For translocations, PREDICTED_LOF is assigned if a breakpoint falls at any point in the transcript, so an intronic breakpoint would still be annotated as PREDICTED_LOF for any impacted genes. This is because only part of the gene exists on each chromosome after the translocation, which is likely to result in a truncated transcript subject to nonsense-mediated decay. . Perhaps in some cases this definition is overly permissive, such as if only the UTR or one shorter exon is removed by the translocation - those cases could be worth revisiting. . I hope this helps explain the behavior you are seeing. If this does not fully explain all the PREDICTED_LOF annotations you are observing, please share the CTX breakpoints, the annotations, the SVAnnotate version, and the GTF used so we can investigate further.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8852#issuecomment-2195034147:530,mediat,mediated,530,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8852#issuecomment-2195034147,1,['mediat'],['mediated']
Integrability,"Hi @Vzzarr ,. Thank you for reporting this. I've never heard of this happening before, but I suspect the difference is that you are using maven and we've only ever used gradle. @magicDGS @LeeTL1220 You both build downstream projects, have you ever seen this?. From what I can tell `com.github.fommil.netlib.all` is a POM only dependency, but it's not annotated as such in our generated POM. Gradle resolves it correctly, and then resolves it's transitive dependencies correctly, but maven seems to resolve it differently. . I've reproduced the issue locally, and it seems like it can be fixed by changing this line in our build file:. https://github.com/broadinstitute/gatk/blob/62e339fb9150db19f80d4b48aed8d47608461690/build.gradle#L220. to specify the exact dependencies we want instead of using the all artifact. I'll open a pull request with that. There's an additional catch though, you're using the latest release to maven central, which is actually a very old version. We haven't been able to release newer versions to central because they depend on a snapshot of a fork of a google library that isn't released to central. We publish these to our artifactory server which can be resolved like any other maven repository. Would you be able to work with an artifactory dependency? If you can you can A) use the newer and better gatk, B) I won't have to backport this change on top of beta.2 . We're going to fix the problem of not being in central eventually ( certainly before 4.0 release... ) but until then resolving from our artifactory is probably the best bet. If you can't / don't want to use the artifactory releases, let me know and I can release a patch version to maven that fixes this problem.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339056907:326,depend,dependency,326,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339056907,5,['depend'],"['depend', 'dependencies', 'dependency']"
Integrability,"Hi @Yyx2626, I'm Geraldine, you may remember me from the Beijing training. It was great visiting your team! I'm sorry it took me so long to follow up on this discussion, and I want to thank you again for reaching out to us about integrating the tool that you developed into GATK. We are certainly very interested in providing this enhancement to the research community, and we are now ready to talk about the next steps. . After examining your paper and the source code in Github, we think that the most efficient way to integrate the functionality you developed would be to adapt the filtering parts of your tool to run on the output of Mutect2. So this would be a standalone tool that you would run after Mutect2, much like the current FilterMutectCalls tool. . If the results are comparable to your current tool, then we would take that into the official distribution of GATK. If somehow that integration does not yield satisfactory results, then we would look at integrating the entire tool, though we're hoping it won't be necessary, so we can avoid maintaining duplicate functionality for some of the boilerplate data transformations. . David @davidbenjamin can provide some advice on how to implement this in GATK4; in brief you would need to write some code that applies the filters you developed to a variant context. Let us know if this is an option you'd like to explore; we'd be happy to help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4632#issuecomment-403101973:229,integrat,integrating,229,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4632#issuecomment-403101973,4,['integrat'],"['integrate', 'integrating', 'integration']"
Integrability,"Hi @bhanugandham . I wasn't able to reproduce your problem on my laptop. Based on the error message, it looks like a network config Spark issue. What environment are you running this in? If it's MacOS, can you post the contents of `/etc/hosts`? Also the error message looks like it's truncated. You might be able to get the full stack trace by adding `--verbosity DEBUG`, which would be helpful as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5802#issuecomment-473419380:92,message,message,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5802#issuecomment-473419380,2,['message'],['message']
Integrability,"Hi @chatchawit,. It's hard to tell what's going on from the information you provided. Could you include the exact commandline that you're trying to run. Also, the complete stack trace from both the original error and the new error message would be very helpful.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-384991868:231,message,message,231,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-384991868,1,['message'],['message']
Integrability,Hi @danieljrichard. I suspect the error message you're seeing is a not the underlying problem. Sometimes when the tool crashes there are errors during standard shutdown cleanup that hide the real problem. There's a [recent patch](https://github.com/broadinstitute/gatk/commit/f7dea3c08b126c56b851c4d381cfdb5513e0584f) which makes it so that should happen much less but it's not in any currently released version. Are you able to build the current master branch of gatk and repeat your test with that version? I suspect it will clarify what's going on.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452177739:40,message,message,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452177739,1,['message'],['message']
Integrability,"Hi @droazen , thanks for your quick response! Depending on what you mean for ""multiple tools,"" I'd say just Mutect2. I say this because we are running this as part of a cwl workflow, so Mutect2 is running on its own instance (virtual machine) with that specified docker image. All of the surrounding tools have produced the expected outputs when queried except for Mutect2. That's a good point about the release version, I think we happen to be considering upgrading, but have to be picky as to when given the size and scope of our operation :) Also, your suggestion of using the official GATK might help, as I am not sure I can rule out subtle `apt update` changes even within the same version of ubuntu over time.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7269#issuecomment-847248241:46,Depend,Depending,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7269#issuecomment-847248241,1,['Depend'],['Depending']
Integrability,"Hi @hh1985 . Memory tuning is pretty tricky and can depend on a lot of things. How is your cluster configured? ; Are you using YARN? Are you running in client or cluster mode? . I'm assuming you're running with YARN. Mesos should also work but I don't have any experience configuring it. . BQSR should run safely with 4g of memory per core. (It should really work with much less I think, but 4 should definitely be sufficient.) There are a few different parameters that can help you adjust the memory ratios.; A good tuning might be something like; ; ```; --num-executors 5 ; --executor-cores 8 ; --executor-memory 32g ; ```. if you're not running with gatk-launch you'll need to set; ```; --conf spark.yarn.executor.memoryOverhead=600; ```; Without setting a higher than default yarn memory overhead like this we see consistent crashes, it's included in the settings gatk-launch applies already. That should run 5 separate executors with 8 cores each and give each one 32g, so 4g / core. . If you're running in cluster mode you'll have to carve out some memory and cores for the driver. You can set the driver settings with ; ```; --driver-cores 2; --driver-memory 4g; ``` ; or something along those lines. The driver doesn't need much memory or computer for BQSR. In general we've had better luck using the entire cluster for one job and running jobs in sequence rather than trying to run two jobs simultaneously using a subset of the cluster.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3465#issuecomment-324064738:52,depend,depend,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3465#issuecomment-324064738,1,['depend'],['depend']
Integrability,"Hi @jean-philippe-martin ,. A `Feature` in our codebase has a specific meaning that is different from ""interval"": it is a record that 1. has a location on the genome plus (typically) some metadata information about that location and 2. is in one of the formats supported by our file-parsing framework tribble and is the product of a tribble codec. A VCF record is an example of a `Feature`. . The common interface between `Feature` and `SimpleInterval` is called `Locatable`. I recommend (for now) that you simply alter your uprooted version of BQSR to take a `List<? extends Locatable>` instead of a `List<? extends Feature>` in `apply()`. This should require no code changes beyond changing method parameter types, and it will allow you to feed BQSR `SimpleIntervals` for the known sites for now, and `Features` like VCF records later on when we're ready for that. Please do return `ArtificialTestFeature` to the `FeatureDataSourceUnitTest` from which it came -- this is a very incomplete class meant only for testing purposes and not for external use.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/511#issuecomment-100393247:404,interface,interface,404,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/511#issuecomment-100393247,1,['interface'],['interface']
Integrability,"Hi @jjfarrell . We took a look through our code and libraries we're depending on and the only place we could find any logging message that would produce those lines in any related repo we could find is in the `TestBAM` example tool from the Hadoop-BAM library. Is there any chance you ran that tool on one of your files (one with 76bp reads), perhaps after installing Hadoop-BAM and following the examples README, and that's what filled up the log?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373795692:68,depend,depending,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373795692,2,"['depend', 'message']","['depending', 'message']"
Integrability,"Hi @lbergelson ; Thanks for the response!; I tried building the current gatk from the master branch, and now the error message says something a little different. java.lang.ClassCastException: class htsjdk.samtools.BAMRecord cannot be cast to class java.lang.Comparable (htsjdk.samtools.BAMRecord is in unnamed module of loader 'app'; java.lang.Comparable is in module java.base of loader 'bootstrap'); 	at java.base/java.util.Arrays$NaturalOrder.compare(Arrays.java:105); 	at java.base/java.util.TimSort.countRunAndMakeAscending(TimSort.java:355); 	at java.base/java.util.TimSort.sort(TimSort.java:234); 	at java.base/java.util.ArraysParallelSortHelpers$FJObject$Sorter.compute(ArraysParallelSortHelpers.java:145); 	at java.base/java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:746); 	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290); 	at java.base/java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:408); 	at java.base/java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:736); 	at java.base/java.util.Arrays.parallelSort(Arrays.java:1183); 	at htsjdk.samtools.util.SortingCollection.spillToDisk(SortingCollection.java:247); 	at htsjdk.samtools.util.SortingCollection.add(SortingCollection.java:182); 	at htsjdk.samtools.SAMFileWriterImpl.addAlignment(SAMFileWriterImpl.java:202); 	at htsjdk.samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:36); 	at htsjdk.samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:16); 	at htsjdk.samtools.util.AbstractAsyncWriter$WriterRunnable.run(AbstractAsyncWriter.java:123); 	at java.base/java.lang.Thread.run(Thread.java:829); 	Suppressed: htsjdk.samtools.util.RuntimeIOException: Attempt to add record to closed writer.; 		at htsjdk.samtools.util.AbstractAsyncWriter.write(AbstractAsyncWriter.java:57); 		at htsjdk.samtools.AsyncSAMFileWriter.addAlignment(AsyncSAMFileWriter.java:58); 		at org.broadinstitute.hellbender.utils.read.SAMFileGATKReadWriter.addRead(SA",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452463087:119,message,message,119,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452463087,1,['message'],['message']
Integrability,"Hi @lbergelson I added **--disableAllReadFilters**, the log still says ""null"". Using GATK wrapper script /home/kh3/Softwares/gatk/build/install/gatk/bin/gatk; Running:; /home/kh3/Softwares/gatk/build/install/gatk/bin/gatk BwaSpark -I /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.bam -R /home/kh3/Resources/genome_b37/genome.fa --disableAllReadFilters --disableSequenceDictionaryValidation true -t 16 -O /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.aligned.bam; 12:08:44.856 INFO IntelGKLUtils - Trying to load Intel GKL library from:; jar:file:/home/kh3/Softwares/gatk/build/install/gatk/lib/gkl-0.1.2.jar!/com/intel/gkl/native/libIntelGKL.so; 12:08:44.905 INFO IntelGKLUtils - Intel GKL library loaded from classpath.; [September 17, 2016 12:08:44 PM EDT] org.broadinstitute.hellbender.tools.spark.bwa.BwaSpark --output /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.aligned.bam --threads 16 --reference /home/kh3/Resources/genome_b37/genome.fa --input /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.bam --disableSequenceDictionaryValidation true --disableAllReadFilters true --fixedChunkSize 100000 --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false --use_jdk_deflater false; [September 17, 2016 12:08:44 PM EDT] Executing as kh3@rgcaahauva08091.rgc.aws.com on Linux 3.13.0-91-generic amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_101-b13; Version: Version:4.alpha.2-45-ga30af5a-SNAPSHOT; 12:08:44.930 INFO BwaSpark - Defaults.BUFFER_SIZE : 131072; 12:08:44.930 INFO BwaSpark - Defaults.COMPRESSION_LEVEL : 1; 12:08:44.930 INFO BwaSpark - Defaults.CREATE_INDEX : false; 12:08:44.930 INFO BwaSpark - Defaults.CREATE_MD5 : false; 12:08:44.930 INFO BwaSpark - Defaults.CUSTOM_READER_FACTORY : ; 12:08:44.930 INFO BwaSpark - Defaults.EBI_REFERENCE_SERVICE_URL_MAS",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2171#issuecomment-247785408:90,wrap,wrapper,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2171#issuecomment-247785408,1,['wrap'],['wrapper']
Integrability,"Hi @lbergelson Thanks for the quick response! I just used the fasta as reference, and it still doesn't work. The log only says ""null"". Using GATK wrapper script /home/kh3/Softwares/gatk/build/install/gatk/bin/gatk; Running:; /home/kh3/Softwares/gatk/build/install/gatk/bin/gatk BwaSpark -I /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.bam -R /home/kh3/Resources/genome_b37/genome.fa --disableSequenceDictionaryValidation true -t 16 -O /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.aligned.bam; 16:55:32.261 INFO IntelGKLUtils - Trying to load Intel GKL library from:; jar:file:/home/kh3/Softwares/gatk/build/install/gatk/lib/gkl-0.1.2.jar!/com/intel/gkl/native/libIntelGKL.so; 16:55:32.310 INFO IntelGKLUtils - Intel GKL library loaded from classpath.; [September 16, 2016 4:55:32 PM EDT] org.broadinstitute.hellbender.tools.spark.bwa.BwaSpark --output /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.aligned.bam --threads 16 --reference /home/kh3/Resources/genome_b37/genome.fa --input /home/kh3/data/Illumina/GATK4/Platinum/TEST/test.spark.bam --disableSequenceDictionaryValidation true --fixedChunkSize 100000 --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --shardedOutput false --numReducers 0 --sparkMaster local[*] --help false --version false --verbosity INFO --QUIET false --use_jdk_deflater false --disableAllReadFilters false; [September 16, 2016 4:55:32 PM EDT] Executing as kh3@rgcaahauva08091.rgc.aws.com on Linux 3.13.0-91-generic amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_101-b13; Version: Version:4.alpha.2-45-ga30af5a-SNAPSHOT; 16:55:32.335 INFO BwaSpark - Defaults.BUFFER_SIZE : 131072; 16:55:32.335 INFO BwaSpark - Defaults.COMPRESSION_LEVEL : 1; 16:55:32.335 INFO BwaSpark - Defaults.CREATE_INDEX : false; 16:55:32.335 INFO BwaSpark - Defaults.CREATE_MD5 : false; 16:55:32.335 INFO BwaSpark - Defaults.CUSTOM_READER_FACTORY : ; 16:55:32.335 INFO BwaSpark - Default",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2171#issuecomment-247709200:146,wrap,wrapper,146,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2171#issuecomment-247709200,1,['wrap'],['wrapper']
Integrability,"Hi @lbergelson and thanks for considering my issue,. I'm sorry but I'm not familiar to artifactory dependency, if necessary I'll deepen about it; so I just inserted this dependency in the project's pom.xml; ```; <dependency>; <groupId>org.broadinstitute</groupId>; <artifactId>gatk</artifactId>; <version>4.beta.6-18-g2ee7724-20171025.162137-1</version>; </dependency>; ```; as reported in the [artifact repository](https://broadinstitute.jfrog.io/broadinstitute/webapp/#/artifacts/browse/tree/General/libs-snapshot-local/org/broadinstitute/gatk/4.beta.6-18-g2ee7724-SNAPSHOT/gatk-4.beta.6-18-g2ee7724-20171025.162137-1.jar), but when I execute `mvn clear install` in my folder project, I receive this error: ; ```; [ERROR] Failed to execute goal on project GATKpipe: ; Could not resolve dependencies for project uk.ac.ncl:GATKpipe:jar:0.0.1-SNAPSHOT: ; Could not find artifact org.broadinstitute:gatk:jar:4.beta.6-18-g2ee7724-20171025.162137-1 -> [Help 1]; ```. Am I making any mistake?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339624024:99,depend,dependency,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339624024,10,['depend'],"['dependencies', 'dependency']"
Integrability,Hi @lucifer9288. Thanks for pointing this out as its a very confusing message. Its an oversight in our logging that causes that error message and it should not mean that your execution of SplitNCigarReads was invalid. The inflater in this message is referring to the fact that one of the compressed blocks gets uncompressed with zero output bytes which happens with the very last block of a properly formatted BGZF file (as a your input bam should be). It looks like the issue is an errant message in the GKL intel inflater.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8126#issuecomment-1371196080:70,message,message,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8126#issuecomment-1371196080,4,['message'],['message']
Integrability,"Hi @marchoeppner - a few questions. It does sounds like a bad conda or python environment. Is the workflow running from within the GATK conda env when you see this (you would have had to have manually created it using the gatkcondaenv.yml file shipped with GATK4). It would be helpful to see the command line that led to this message, and the context in which it appears. Although GATK4 requires the GATK4 conda environment for a handful of tools to work, GenomicsDBImport isn't one of them. If there are other GATK tools that trigger this (or that you know work fine in the same environment) that would also be useful to know.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4459#issuecomment-368538022:326,message,message,326,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4459#issuecomment-368538022,1,['message'],['message']
Integrability,"Hi @qindan2008 - is this the full log file that is produced, or is there more to it? If there is more to the log file can you post it? Would you mind posting one or two of your variants as well? They can be simplified - I only the need position and alleles. Also, did you happen to make any modifications to the data sources? If you enabled gnomAD, Funcotator will try to read the gnomAD data sources via the Google Cloud API, which may be slow or fail depending on your internet connection and settings. You could experience similar issues if you added another web-facing data source.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7135#issuecomment-799646869:453,depend,depending,453,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7135#issuecomment-799646869,2,['depend'],['depending']
Integrability,"Hi @rhinorus,. This is surprising since we routinely run gCNV case on single samples without issue, albeit on Google Cloud. It looks like you are running on local. Can you please double-check that the `filtered_intervals` file is correct? This should be the output of the same name from when you ran Cohort mode.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7706#issuecomment-1061071289:43,rout,routinely,43,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7706#issuecomment-1061071289,1,['rout'],['routinely']
Integrability,"Hi @stefandiederich,. My guess is that you may have created your GATK conda environment with an older version of the GATK that did not include the changes to the `PloidyModelWriter`. Can you try creating a new conda environment with 4.0.3.0 and re-running?. @vdauwera @sooheelee @chandrans Any idea what the forum error message is about?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4679#issuecomment-382715149:320,message,message,320,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4679#issuecomment-382715149,1,['message'],['message']
Integrability,"Hi @sujianed ; Can you try running the tool without the /bin/bash entry at the beginning of the command? That entry disables the proper initiation of the conda environment with the proper python objects therefore you get this error message. You can run the tool directly from the commandline like . `docker run --rm -it broadinstitute/gatk-dev:NVSCOREVARIANTS-PREVIEW-SNAPSHOT gatk NVScoreVariants ....`. Here is what happens when you have the entry. ```; $ docker run --rm -it broadinstitute/gatk-dev:NVSCOREVARIANTS-PREVIEW-SNAPSHOT /bin/bash; root@5d30f9f10f97:/gatk# python -c ""import scorevariants""; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; ModuleNotFoundError: No module named 'scorevariants'; root@5d30f9f10f97:/gatk# . ```. Without the entry here is the result; ```; $ docker run --rm -it broadinstitute/gatk-dev:NVSCOREVARIANTS-PREVIEW-SNAPSHOT ; This docker image is specially built as a pre-release preview image for running the new GATK tool NVScoreVariants, and comes with a Python environment specific to that tool. Other Python-based GATK tools cannot be run using this image: use the official GATK release images instead.; (nvscorevariants) root@0a9dcd961783:/gatk# python -c ""import scorevariants""; (nvscorevariants) root@0a9dcd961783:/gatk#; ```. See that the bottom entry has the proper conda environment nvscorevariants initialized.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8501#issuecomment-1697386717:232,message,message,232,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8501#issuecomment-1697386717,1,['message'],['message']
Integrability,"Hi @tedsharpe, . A quick follow-up question on this – how does the function currently handle the Q-scores from overlapping portions of paired-end reads? @BenjaminWehnert1008 noticed that read pre-merging and dual Q-score integration can help improve our performance for 1nt variants. Best wishes,; Max",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8995#issuecomment-2416095456:221,integrat,integration,221,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8995#issuecomment-2416095456,1,['integrat'],['integration']
Integrability,"Hi @tomwhite; thanks for pinging this upstream on https://github.com/bigdatagenomics/adam/issues/1093. As per my comment there, I believe that it's only the various RDD transforms in ADAM that are impacted by the Spark 2.0.0 shift. I believe that the issue that was reported here is a Scala 2.10 vs. 2.11 issue. The GATK build points at [ADAM 0.18.0 built for Scala 2.10](https://github.com/broadinstitute/gatk/blob/master/build.gradle#L128). If you shifted said dependency to `compile('org.bdgenomics.adam:adam-core_2.11:0.18.0')`, I believe the error above would disappear. However, this is just conjecture; I haven't tested it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2073#issuecomment-241779355:463,depend,dependency,463,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2073#issuecomment-241779355,1,['depend'],['dependency']
Integrability,"Hi @wujh2017,. Note that the numbers in change30-model/mu_mean_bias_j_lowerbound__.tsv indicate the mean bias per *contig*, not per *sample*. It looks like you are providing only 4 samples to GermlineCNVCaller, even though you provided 30 samples to DetermineGermlineContigPloidy. Are these 4 samples included in those 30? Typically, you would just provide all 30 samples (along with their ploidy calls) to GermlineCNVCaller. Also, you mentioned that the read depth varies dramatically between samples. Remember that we are trying to model systematic sequencing bias using the samples in the cohort, so ideally they should have all been sequenced with a similar protocol.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4457#issuecomment-368230264:662,protocol,protocol,662,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4457#issuecomment-368230264,1,['protocol'],['protocol']
Integrability,Hi @yurivict I tested this on my machine and it works for me. Do you see a message saying the version was overridden?; ```; $ ./gradlew printVersion -Drelease=true -DversionOverride=myVersion1.2. > Configure project :; Version number overridden as myVersion1.2. > Task :printVersion; myVersion1.2; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7143#issuecomment-857796023:75,message,message,75,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7143#issuecomment-857796023,1,['message'],['message']
Integrability,"Hi @yurivict, gatk requires gradle 3.1. We include the wrapper script so you can always just run `./gradlew` instead of using the system gradle and it will automatically resolve the correct version.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444195902:55,wrap,wrapper,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444195902,1,['wrap'],['wrapper']
Integrability,"Hi Christina (@cristinaluengoagullo ),. The GenomicsDBImport in version 4.0.0.0 has a few bugs that you may or may not encounter, but I'd recommend you run GATK 4.0.1.0 or later. That's admittedly a very cryptic error message. We're working on doing a better job wrapping the GenomicsDB errors into readable GATK User Errors. In the meantime, I have a few ideas. Do you have any unusual annotations in that GVCF? The Vidmap takes information from the VCF header annotation descriptions to figure out how to store annotation values after they're parsed. It's complaining that something is wrong with the type of one of your annotations, so my guess is that there's an annotation that's not described correctly in the header. Can you send the gdbworkspace-gatk/vidmap.json file? A snippet of the input GVCF (ideally with the header) would be good too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4514#issuecomment-371831740:218,message,message,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514#issuecomment-371831740,2,"['message', 'wrap']","['message', 'wrapping']"
Integrability,"Hi David,. Thanks for your response and effort developing the best practices pipeline and GATK. I'm not certain, but I would suspect that a significant percentage of your users may also not use the best practices pipeline for one reason or another. In my particular case, I intersect calls from multiple variant callers and prefer to run this pipeline without the added abstraction of Terra (or WDL) for the sake of simplicity. This was easy to fix on my end, thanks again. Andrew. @davidbenjamin. > On Sep 3, 2019, at 4:16 PM, David Benjamin <notifications@github.com> wrote:; > ; > @lbergelson The stats file is not optional, but the argument is optional because by default FilterMutectCalls looks for the stats file produced automatically by Mutect2 in the same directory as the output vcf.; > ; > @andrewrech The official best practices pipeline -- that is, mutect2.wdl in this repo and hosted on Terra (formerly Firecloud) -- handles this automatically. We generally discourage users from writing their own pipelines because it takes very long and can easily yield inferior results. Is the official pipeline missing a feature that you need?; > ; > As for backwards compatibility, while we can guarantee that Mutect2 and FilterMutectCalls from the same GATK release will always work together we do not make any promises about the interoperability of different releases.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6124#issuecomment-527643415:1334,interoperab,interoperability,1334,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6124#issuecomment-527643415,2,['interoperab'],['interoperability']
Integrability,"Hi GATK team,. I tried running your PathSeq pipeline (broadinstitute/gatk:4.1.8.0) on my cohort and almost half of the samples failed the scoring step with this error message:. `20/07/17 09:38:35 INFO NewHadoopRDD: Input split: file:/cromwell_root/fc-6e61d4b2-bdc8-4abd-bb94-18d8fa11d9b6/7c1b0faa-e956-4289-9e2d-4fb8b9eff6ff/PathSeqPipeline/0ca5578f-70d3-498e-b7cc-23590f0ab31f/call-PathSeqAlign/MMRF_2072_2_BM.microbe_aligned.paired.bam:33554432+33554432; 20/07/17 09:38:46 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 5); java.util.NoSuchElementException: next on empty iterator; 	at scala.collection.Iterator$$anon$2.next(Iterator.scala:39); 	at scala.collection.Iterator$$anon$2.next(Iterator.scala:37); 	at scala.collection.Iterator$$anon$13.next(Iterator.scala:469); 	at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31); 	at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$PeekingImpl.next(Iterators.java:1155); 	at org.broadinstitute.hellbender.utils.spark.SparkUtils.lambda$putReadsWithTheSameNameInTheSamePartition$7bd206b0$1(SparkUtils.java:190); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); 	at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:123); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.execu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6319#issuecomment-660292360:167,message,message,167,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6319#issuecomment-660292360,3,"['Wrap', 'message']","['Wrappers', 'message']"
Integrability,"Hi Marissa - I think we're all in agreement that we'd like to find a way to make Intel-TF the default, but whether or not we can have CNNScoreVariants require AVX to run is less clear. Naturally, we'd prefer to not have to provide a custom TF distribution for a fallback, but there are 3 cases where we may not have a choice: user with old hardware, Travis/CI testing, and GCE. We may need to provide a fallback environment for those (I'll try to get resolution on that). If it turns out we do, I'm actually not suggesting the fallback be automatic (3 in your list), just that we have a graceful failure mode and an instructive error message. . In the meantime, there is still the issue that this PR fails to even build on Travis. It looks like it produces so much output building the Docker image that it exceeds the allowable Travis build log size. That will need to be resolved, and we'll also need to understand the impact of this change on the size of our Docker image, which is already large, and continues to be a challenge for us.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-429451059:634,message,message,634,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-429451059,2,['message'],['message']
Integrability,"Hi Sam,; Thanks for reply..; could you help me in creating apost in GATK forum.. I am searching it, couldnt find the link to post the issues. On Thu, 17 Oct 2019 at 16:48, samuelklee <notifications@github.com> wrote:. > From the new message you are getting (Sample ""$1"" already has coverage; > metadata annotations), I’m guessing that both of your samples have the same; > name (“$1”). I would fix this upstream in the BAM.; >; > Again, the forum is a better place for this kind of discussion, as other; > users can benefit from seeing discussion as well as previous posts—GitHub; > issues lose a lot of visibility once they are closed.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/6217?email_source=notifications&email_token=AKXA3TS5T4DLEAHKK6YF3HLQPBCYBA5CNFSM4JBWKHV2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEBPXOWQ#issuecomment-543127386>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AKXA3TVIUNONFO2NCNW4GMLQPBCYBANCNFSM4JBWKHVQ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6217#issuecomment-543177384:233,message,message,233,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6217#issuecomment-543177384,1,['message'],['message']
Integrability,"Hi all, thanks again for working to integrate this code!. Saw some confusion in the comments above and just wanted to clarify: if you take a look at the VQSR-lite PR https://github.com/broadinstitute/gatk/pull/7954/commits that the current branch is rebased upon, you'll see that it contains a version of the Joint Genotyping WDL (which was put together by Megan for Ultima) along with Java code for the tools (which was written by me). Both the WDL and the code have been updated in subsequent PRs. The WDL was rewritten by me in #8074; the main difference is that we no longer run SNPs and indels filtering in ""series"", but instead run them in a single step. However, this requires that you use the same annotations for both SNPs and indels; GVS might not be ready for that just yet, since the default WARP implementation uses different annotations. (But see also the comment here: https://github.com/broadinstitute/gatk/pull/8074#issue-1423991277. The gist is we can easily reimplement Megan's/WARP's ""serial"" SNP-then-indel workflow using the simpler single-step workflow.) (EDIT: I was originally confused here, Megan’s WDL simply runs SNPs and indels separately—thanks to George for correcting me here!). Note also that test infrastructure was moved from Travis to Github Actions between these PRs, so the Travis references above have already been cleaned up. There have also been a few additional minor PRs merged in the interim, with a couple more incoming. These PRs do not fundamentally change the interfaces of the tools/WDL, however, so I think you can update to them when you're ready. Punchline: this branch should suffice for a first cut of a VQSR/VQSR-lite bakeoff, and although it is already slightly out of date, it shouldn't be too much work to get things updated after the first cut is done.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8157#issuecomment-1412640649:36,integrat,integrate,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8157#issuecomment-1412640649,4,"['integrat', 'interface']","['integrate', 'interfaces']"
Integrability,"Hi everyone. I try to run gatk 4.2.5.0 VariantAnnotator using gnomAD data. However I get this error message java.lang.IllegalStateException: Allele in genotype C not in the variant context [C*, CT] can you maybe advise whats going on? . java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx30G -jar /run/media/riadh/One Touch1/Analysis/gatk-4.2.4.1/gatk-package-4.2.5.0-local.jar VariantAnnotator -V PE69_chr3.vcf -R /run/media/riadh/One Touch/Reference_data_b38/resources_broad_hg38_v0_Homo_sapiens_assembly38.fasta --resource:gnomad /run/media/riadh/One Touch/Reference_data_b38/gnomad.genomes.v3.1.2.sites.chr3.vcf.bgz -E gnomad.nhomalt -E gnomad.ALT -E gnomad.AF -O PE69_ch3_vep_cadd_gnomad.vcf --resource-allele-concordance; 10:58:19.715 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/run/media/riadh/One%20Touch1/Analysis/gatk-4.2.4.1/gatk-package-4.2.5.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Mar 17, 2022 10:58:19 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 10:58:19.796 INFO VariantAnnotator - ------------------------------------------------------------; 10:58:19.796 INFO VariantAnnotator - The Genome Analysis Toolkit (GATK) v4.2.5.0; 10:58:19.796 INFO VariantAnnotator - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:58:19.797 INFO VariantAnnotator - Executing as riadh@ikm-unix-1012.uio.no on Linux v5.16.12-200.fc35.x86_64 amd64; 10:58:19.797 INFO VariantAnnotator - Java runtime: OpenJDK 64-Bit Server VM v11.0.14.1+1; 10:58:19.797 INFO VariantAnnotator - Start Date/Time: March 17, 2022 at 10:58:19 AM CET; 10:58:19.797 INFO VariantAnnotator - ------------------------------------------------------------; 10:58:19.797 INFO VariantAnnotator - -------------------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6689#issuecomment-1070784053:100,message,message,100,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6689#issuecomment-1070784053,1,['message'],['message']
Integrability,"Hi! It would be great to see this issue addressed, as the error message that is generated is quite cryptic.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6548#issuecomment-643229485:64,message,message,64,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6548#issuecomment-643229485,1,['message'],['message']
Integrability,"Hi, . I am experiencing exactly the same issue. I also run gatk on a cluster using singularity. When using --include-non-variant-sites the same error message is reported for all but the first chromosome. When exluding non variant sites it works fine. . ```; 05:04:16.405 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.5.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 05:04:16.556 INFO GenotypeGVCFs - ------------------------------------------------------------; 05:04:16.559 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.5.0.0; 05:04:16.559 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 05:04:16.563 INFO GenotypeGVCFs - Initializing engine; 05:04:16.929 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.5.1-84e800e; 16:04:16.979 INFO NativeGenomicsDB - pid=680685 tid=680686 No valid combination operation found for INFO field InbreedingCoeff - the field will NOT be part of INFO fields in the generated VCF records; 16:04:16.979 INFO NativeGenomicsDB - pid=680685 tid=680686 No valid combination operation found for INFO field MLEAC - the field will NOT be part of INFO fields in the generated VCF records; 16:04:16.979 INFO NativeGenomicsDB - pid=680685 tid=680686 No valid combination operation found for INFO field MLEAF - the field will NOT be part of INFO fields in the generated VCF records; 05:04:17.059 INFO GenotypeGVCFs - Done initializing engine; 05:04:17.104 INFO ProgressMeter - Starting traversal; 05:04:17.105 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 05:04:17.124 INFO GenotypeGVCFs - Shutting down engine; [June 26, 2024 at 5:04:17 AM GMT] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=1126170624; java.lang.IllegalStateException: There are no sources based on those query parameters; at org.genomicsdb.reader.GenomicsDBFeature",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8415#issuecomment-2191214079:150,message,message,150,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8415#issuecomment-2191214079,1,['message'],['message']
Integrability,"Hi, I am getting similar errors but I can get output file. I wonder what this error message actually means? Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6292#issuecomment-682144031:84,message,message,84,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6292#issuecomment-682144031,1,['message'],['message']
Integrability,"Hi, thanks for the quick reply! The reason is indeed in the fasta file. I unzipped it when running another program but then re-zipped using gzip instead of bgzip. The error message disappears when I used bgzip to compress my fasta file again.; Thanks again!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6911#issuecomment-716831825:173,message,message,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911#issuecomment-716831825,1,['message'],['message']
Integrability,"Hi,. Thanks for the response. Running with -u isn’t ideal as we can’t control; how the user runs this (unless they do this on their own hardware or say a; cloud instance). However, I managed to convert the docker image into a singularity one and; that runs ‘out of the box’ in user space. Simon. On 3 Jun 2024, at 18:43, Gökalp Çelik ***@***.***> wrote:. Hi @potter-s <https://github.com/potter-s>; Our docker image is already built with root account only however PATH is; set to be usable by all users so if you wish to keep user priviledges after; execution you may add -u $UID:$GID parameter to docker command line; therefore the container will run using your user permissions. This has a catch of course. Temporary folders must be set where your user; has RWX permissions therefore we want users to pay attention to that. There; is a writing that we posted a while ago which you may refer to for setting; up your temporary files for GATK workflows. How to setup temporary folder for GATK local executtion; <https://gatk.broadinstitute.org/hc/en-us/articles/18965297287067-How-to-setup-and-use-temporary-folder-for-GATK-local-execution>. For some of the tools such as gCNV or CNN you may need to setup additional; environment variables to locate python compilation directory to a place; where you have read and write permissions. I hope this helps. —; Reply to this email directly, view it on GitHub; <https://github.com/broadinstitute/gatk/issues/8856#issuecomment-2145780965>,; or unsubscribe; <https://github.com/notifications/unsubscribe-auth/ABU3SAWISO2HSCUNHK3SGIDZFSTK5AVCNFSM6AAAAABIWRNXGKVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDCNBVG44DAOJWGU>; .; You are receiving this because you were mentioned.Message ID:; ***@***.***>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8856#issuecomment-2155884154:1712,Message,Message,1712,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8856#issuecomment-2155884154,1,['Message'],['Message']
Integrability,"Hi,; The operating system is ubuntu 20.04.; java version is openjdk ""17.0.11"".; If the process of GATK best practice has been interrupted, I could see the; error messages always.; But, in this time, the process was interrupted without giving any messages.; This is quite weird. I checked this several other chromosomes.; My callset has about 430 samples.; I could run GenotypeGVCFs in GATK 4.5.0.0 version without any problem.; But, in GATK 4.6.0.0, the process was successful in 3-4 chromosomes (which; is smaller one I think). The process has been interrupted; in incomplete stages.; I could not find any ERR files in the folder.; Thanks; Jinu Han. On Fri, Jul 19, 2024 at 7:01 PM Gökalp Çelik ***@***.***>; wrote:. > Can you provide more details on what operating system you are using and; > other related information such as java version etc?; >; > Even if the process gets interrupted by the system there must be a java; > segfault message at some point thrown by the process. Did you observe any; > files with names ERR around the output file?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2238814358>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AG7IXWSQYT56QW4Q4YCZUPTZNDPXPAVCNFSM6AAAAABLBRETECVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEMZYHAYTIMZVHA>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2238826908:162,message,messages,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8918#issuecomment-2238826908,4,"['Message', 'message']","['Message', 'message', 'messages']"
Integrability,"Hm, another issue related to the Experimental training tool (which I think it is the only place we still use a biopython dependency). Anyway, @EricDeveaud AFAICT this doesn't happen during our builds - we always wind up with numpy 1.13.3. Do you know if this is somehow specific to to singularity ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6396#issuecomment-576848664:121,depend,dependency,121,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6396#issuecomment-576848664,1,['depend'],['dependency']
Integrability,"Hm. Just yesterday we updated from TF 1.4 to 1.9. Although this makes it more compelling to switch the default to Intel-optimized, we may still have an issue for the reasons outlined in the previous PR (academic users, not all GCS zones guaranty AVX hardware, and its still unclear to me if Travis, which uses both GCS and EC2, makes such a guaranty). It [sounds like](https://github.com/tensorflow/tensorflow/issues/18689) the failure mode is to crash. For running inference at least (training may be a different story), we may need something better. Another option is that it sounds like its possible to build our own distribution without AVX dependencies to use as a fallback.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-429316465:645,depend,dependencies,645,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-429316465,1,['depend'],['dependencies']
Integrability,"Hmm, I also realize that I did not update the base Docker image at that time---although I commented in the PR that we should...and I don't think we updated it before release. So I *think* the latest base and the current 4.0.0.0 release Docker contain the getopt dependency, although it was removed from the installation script.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359984275:262,depend,dependency,262,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359984275,1,['depend'],['dependency']
Integrability,"Hmm, I am also getting intermittent build errors like the following much more often:. ```; Could not determine the dependencies of task ':sparkJar'.; > Could not resolve all files for configuration ':sparkConfiguration'.; > Could not download gson.jar (com.google.code.gson:gson:2.2.2); > Could not get resource 'https://repo.maven.apache.org/maven2/com/google/code/gson/gson/2.2.2/gson-2.2.2.jar'.; > Could not GET 'https://repo.maven.apache.org/maven2/com/google/code/gson/gson/2.2.2/gson-2.2.2.jar'. Received status code 403 from server: Forbidden; > Could not download core.jar (com.github.fommil.netlib:core:1.1); > Could not get resource 'https://repo.maven.apache.org/maven2/com/github/fommil/netlib/core/1.1/core-1.1.jar'.; > Could not GET 'https://repo.maven.apache.org/maven2/com/github/fommil/netlib/core/1.1/core-1.1.jar'. Received status code 403 from server: Forbidden; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601832142:115,depend,dependencies,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-601832142,1,['depend'],['dependencies']
Integrability,"Hmm, I started taking a stab at the LL score implementation, but I think it's going to complicate the code quite a bit and add some branching options to the tool interfaces. Compounding this with a change in the use of ""truth"" and ""validation"" terminology, I fear that the resulting differences from the legacy strategy might be a bit much for users to digest!. So I'd want to better understand the cost/benefit before we proceed. How critical is automatic tuning of the hard threshold? And what's the relative importance to method changes that increase AUC (i.e., as opposed to figuring out where on the curve to hard threshold)? Is there a clear path forward for evaluating such a tuning process? @meganshand would be glad to chat more!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1065524909:162,interface,interfaces,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1065524909,2,['interface'],['interfaces']
Integrability,"Hmm, actually, could this be a problem due to the way the native libraries are loaded in the test code? Note that we first cycle through all implementations in the DataProvider, loading the respective library for each implementation via the `synchronized boolean load` method in the `NativeLibraryLoader`. I'm not really that familiar with concurrency in Java (nor loading native libraries, for that matter), but it seems that the intermittent failure goes away when I refactor the test to remove the DataProvider (by just looping through the implementations in the test method). Perhaps related to https://github.com/broadinstitute/gatk/issues/5339?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-607596205:242,synchroniz,synchronized,242,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-607596205,1,['synchroniz'],['synchronized']
Integrability,"Hmm, looks like we lose events 1 and 3 with CollectReadCounts at 250bp using analogous ModelSegments parameters. However, I experimented with tweaking the segmentation to work on the copy ratios (rather than the log2 copy ratios), which seems to recover them. Although one of the goals of having evaluations backed by SV truth sets is to tune such parameters/methods, I'm beginning to think that SV integration might benefit from using the CNV tools in a more customized pipeline---especially if maximizing sensitivity at resolutions of ~100bp jointly with breakpoint evidence is the goal. For example, you might imagine a tool that directly uses CNV backend code to collect coverage over regions specified by `-L`, builds a PoN, denoises, and segments on the fly. Or we can put together a custom WDL optimized for sensitivity. Let's discuss in person?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372875222:399,integrat,integration,399,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372875222,1,['integrat'],['integration']
Integrability,"Hmn, those messages are supposed to only be produced once... something is wrong there. It's not a super high priority but we'll try to look into it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5912#issuecomment-492784881:11,message,messages,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5912#issuecomment-492784881,1,['message'],['messages']
Integrability,Hopefully one final integration run going here https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/99e98043-4606-4a6e-89e8-4a6eb2994bdb,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8505#issuecomment-1701586906:20,integrat,integration,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8505#issuecomment-1701586906,1,['integrat'],['integration']
Integrability,I added an integration test that tries the same thing with a bucket (it works fine). Merging as soon as green (do it for me if I miss it).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2643#issuecomment-299040179:11,integrat,integration,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2643#issuecomment-299040179,1,['integrat'],['integration']
Integrability,"I added commits that fix this now and more tests. I think that it will probably break the integrations tests...so we need to be sure that we like this change before we make the effort to update all of them... One thing I'm not sure about is continuing to use the STANDARD_CONFIDENCE_FOR_CALLING as the threshold...as I think it will have the opposite effect: as the threshold is lowered, you expect to get more variants, but fewer alleles will pass the `passesThreshold` test...so perhaps another argument is needed...I just hate adding arguments...I leave it to more experienced folks to decide.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6363#issuecomment-575130541:90,integrat,integrations,90,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6363#issuecomment-575130541,1,['integrat'],['integrations']
Integrability,I added integration tests for Gnarly and GGVCFs with data from #7483. Back to you @droazen,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7186#issuecomment-947863211:8,integrat,integration,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7186#issuecomment-947863211,1,['integrat'],['integration']
Integrability,"I added integration tests for simple output and including features or verbose. While doing it, I realized that GATK 3.5 included some filters that wasn't included here, and that indels weren't tracked, so I changed also the code to fit the previous implementation. Back to you @akiezun.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1836#issuecomment-221651158:8,integrat,integration,8,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1836#issuecomment-221651158,1,['integrat'],['integration']
Integrability,I addressed the ggplot2 dependency in #5040 and moved the commit to address #5022 to that PR.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406619450:24,depend,dependency,24,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406619450,1,['depend'],['dependency']
Integrability,"I addressed your comments, @cmnbroad. In addition, to make more consistent the errors for malformed `GATKRead`, I updated `ReadMissingReadGroup` and removed `MalformedRead` in two separated commits. Like that, every offending read is passing by `MalformedBAM` for consisten error messages. Back to you and many thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-268452263:280,message,messages,280,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-268452263,1,['message'],['messages']
Integrability,I agree that it is a good security measure to use fixed signed dependencies for repeatable builds. GATK depends on gradle 3.1.: [download](https://services.gradle.org/distributions/gradle-3.1-bin.zip) [shaw256](https://services.gradle.org/distributions/gradle-3.1-bin.zip.sha256),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444208372:63,depend,dependencies,63,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5483#issuecomment-444208372,2,['depend'],"['dependencies', 'depends']"
Integrability,"I agree with all Chris has said, and think that it's very likely that you're running out of memory on the executors. You might try cutting back on --num-executors, and bumping up --executor-memory.; If you can figure out your adapter sequence, you can specify that as --adaptor-sequence, and sometimes that helps with this stage.; We're laying down asphalt, and you're driving on the hot pavement just behind us. Thanks for trying out this tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4635#issuecomment-380144314:226,adapter,adapter,226,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4635#issuecomment-380144314,1,['adapter'],['adapter']
Integrability,"I also just got this ConcurrentModificationException in HaplotypeCallerSparkIntegrationTest locally when running tests on one of my branches (this time in `testNonStrictVCFModeIsConsistentWithPastResults`, but the rest of the stack looks the same). I also vaguely recall seeing once before on travis on a branch where all I did was try to update miniconda to a newer version. My local branch doesn't have any dependency changes, so I suspect this is an existing issue that is just showing up intermittently.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-602804665:409,depend,dependency,409,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6513#issuecomment-602804665,1,['depend'],['dependency']
Integrability,"I am also seeing this warning 3x with 4.0.11.0 on a cluster but outside of docker (centos 6). . ```; 18:05:08.861 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.11.0/install/bin/gatk-package-4.0.11.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Nov 24, 2018 6:05:09 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.NoRouteToHostException: No route to host (Host unreachable); at java.net.PlainSocketImpl.socketConnect(Native Method); at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredential",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441873417:524,rout,route,524,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-441873417,1,['rout'],['route']
Integrability,I am not sure what you’re asking for. Can you be more specific? I feel exhausted fighting the brittle unit and integration tests. I think this is ready for merge.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5318#issuecomment-445858864:111,integrat,integration,111,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5318#issuecomment-445858864,1,['integrat'],['integration']
Integrability,"I appreciate the desire for minimal changes, but I would point out that tying the VariantContext to the source FeatureInput is likely to be a somewhat common need for MultiVariantWalkers. I realize you have a lot of existing example that dont need this capability. While I started this using VariantEval/VariantQC, I more recently tried to port CombineVariants to GATK4 and hit a similar roadblock. I have one or two other lab-specific walkers that would benefit from using the iteration pattern of MultiVariantWalkerGroupedOnStart, but also need some ability to retain the FeatureInput->VariantContext link. I believe GATK3 retained this. It would be nice to at least make this a capability available to all MultiVariantWalkerGroupedOnStart walkers. My suggestion above about making a FeatureInputAwareVariantContext wasnt necessarily meant to be introduced into every class. Would something conceptually like this pass GATK if I could introduce it more surgically, perhaps injected into MultiVariantDataSource alone?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-823594870:975,inject,injected,975,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973#issuecomment-823594870,1,['inject'],['injected']
Integrability,"I believe `sites` and `variants` should be equivalent. I see that there is a warning emitted by GATK4 at sites that are not het, but it shouldn't be an error. If you're getting an error can you please post the full message in this thread? . ASEReadCounter will only process het sites in both GATK3 and GATK4, but it's possible that GATK3 silently skipped non-het sites rather than emitting a warning.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7712#issuecomment-1084552468:215,message,message,215,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7712#issuecomment-1084552468,1,['message'],['message']
Integrability,"I believe it's missing in the wrapper, although I'm not sure why?. If we revisit the wrapper code, there is some chunking functionality I've introduced in my branch for #2858 that we should perhaps also add. The writing of string matrices is also a bit awkward and could be improved.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-317617223:30,wrap,wrapper,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-317617223,2,['wrap'],['wrapper']
Integrability,"I brew installed openssl, and now there is a different unresolved dependency:. java.lang.UnsatisfiedLinkError: /private/var/folders/cr/16ghvyfj5lvfwxx01rt1k4tdl04sy3/T/libtiledbgenomicsdb6507285380909029818.dylib: dlopen(/private/var/folders/cr/16ghvyfj5lvfwxx01rt1k4tdl04sy3/T/libtiledbgenomicsdb6507285380909029818.dylib, 1): Library not loaded: **/usr/local/opt/libcsv/lib/libcsv.3.dylib**; Referenced from: /private/var/folders/cr/16ghvyfj5lvfwxx01rt1k4tdl04sy3/T/libtiledbgenomicsdb6507285380909029818.dylib; Reason: image not found",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294232254:66,depend,dependency,66,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2389#issuecomment-294232254,1,['depend'],['dependency']
Integrability,I can confirm that the fix works for me: I now see a user-friendly error message. Thank you!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/357#issuecomment-91289762:73,message,message,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/357#issuecomment-91289762,1,['message'],['message']
Integrability,"I checked, it looks like the cron job scheduling failed on the 2nd or 3rd of November last year. ""Next job scheduled 3 months ago"" being the message. I restarted the cron job and it is apparently working now. This is concerning since if this fails again we may not notice it for months again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6386#issuecomment-575736317:141,message,message,141,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6386#issuecomment-575736317,1,['message'],['message']
Integrability,I commented on the message itself. The problem seems to be that we output some log messages to STDOUT that break piping. Picard puts them on STDERR.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4133#issuecomment-357052981:19,message,message,19,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4133#issuecomment-357052981,2,['message'],"['message', 'messages']"
Integrability,"I concur, what it looks like we have here is code that switched (accidentally?) from the GCS adapter to GCS-NIO instead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-265014643:93,adapter,adapter,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-265014643,1,['adapter'],['adapter']
Integrability,I deleted my previous comment because I did recreate their issue and I was not able to find a contig in the DBSNP VCF that was not present in the fasta sequence dictionary. Would you be able to add a better error message for this case @lbergelson so that we can troubleshoot and find the culprit?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7383#issuecomment-896377645:213,message,message,213,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7383#issuecomment-896377645,1,['message'],['message']
Integrability,"I deleted ~/.m2/repository/ folder and his content, used this [pom.xml](https://pastebin.com/mV1qGTzv); ```; <project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""; xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">; <modelVersion>4.0.0</modelVersion>; <groupId>uk.ac.ncl</groupId>; <artifactId>GATKpipe</artifactId>; <version>0.0.1-SNAPSHOT</version>; <repositories>; <repository>; <id>central</id>; <name>Maven Repository Switchboard</name>; <layout>default</layout>; <url>http://repo1.maven.org/maven2</url>; <snapshots>; <enabled>false</enabled>; </snapshots>; </repository>; <repository>; <id>snapshots</id>; <snapshots>; <enabled>true</enabled>; </snapshots>; <name>libs-snapshot</name>; <url>https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot</url>; </repository>; </repositories>; <dependencies>; <dependency>; <groupId>org.broadinstitute</groupId>; <artifactId>gatk</artifactId>; <version>4.beta.6-18-g2ee7724-20171025.162137-1</version>; </dependency>; </dependencies>; </project>; ```; executed `mvn clean install -U` and finally obtained the `BUILD SUCCESS`; Thanks everybody for your support",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-340844337:899,depend,dependencies,899,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-340844337,4,['depend'],"['dependencies', 'dependency']"
Integrability,"I didn't realize before that there is no ""include"" (opt-in) validation type arg, only ""exclude"". So I'm not sure what the purpose of having ""ALL"" is in the first place, if the only thing you can usefully do with it is exclude it. I think the best longer term fix would be to add an ""--validation-type-to-include"" arg, and have it default to the everything except for IDs, and then construct the actual types based on merging include/exclude args. But thats a bigger change then just fixing the current (silent do-nothing) default behavior, and requires more error checking for conflicting args. Lets start with changing it so that in the default (no args) case, we log a warning message saying that IDs will be left out since no IDS were provided, and proceed with the remaining validations. Then if we want to get more ambitious we can talk about making the bigger change. Also, as part of the initial fix, it might be a good idea to change `calculateValidationTypesToApply` so that it doesn't modify the `excludeTypes` list directly, since this is the list provided by the user, and instead uses it's own temporary list.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5862#issuecomment-498685279:679,message,message,679,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5862#issuecomment-498685279,1,['message'],['message']
Integrability,"I don't think that hiding/disable arguments would work in every case: sometimes, an argument shouldn't be exposed but still available to set programmatically, or maybe just reduce visibility making it `@Hidden` and/or `@Advance`. What is the problem of making an interface for the top-level argument to the GATK? Changing the interface or the `CommadnLineProgram` has the same effect, but the API user can still behave the same as before. It is much more extensible and downstream-friendly. What's about making the `CLPConfigurationArgumentCollection` an interface always returning defaults to be able to change it in a proper way? The cycle of development of a new argument will be: 1) add a new method to the interface with a default returning what will be expected from the previous behaviour, 2) add and return by the argument in the GATK implementation, 3) use the getter in the CLP for perform the operation. This only adds the first point, and operating in 3 classes instead of 3. For API user it is really easy to maintain the previous behavior when upgrading the dependency by just using their own implementation of the class, or include the top-level new arguments by using the GATK implementation. It is much more flexible and extensible (I always think about GATK also as a library). In addition, I think that this approach is also important for evolving GATK. For example, if a new top-level argument is tagged as experimental (still not supported but requested in Barclay), removing it would allow to keep the interface (no version bump) the same and final users can still operate with the experimental argument. The same applies to the `GATKTool` base class (https://github.com/broadinstitute/gatk/issues/4341), and for downstream projects the aim should be to be able to extend safely the `CommandLineProgram` directly to implement their own toolkit using the powerful GATK framework.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-366185003:263,interface,interface,263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-366185003,6,"['depend', 'interface']","['dependency', 'interface']"
Integrability,"I don't think that will work as the key needs to be `GATKRead` to take advantage of the `SAMRecordToGATKReadAdapterSerializer`. How about writing a new `Comparator<GATKRead>` that wraps a `SAMRecordCoordinateComparator`? That should be pretty simple and won't require a new serializer. BTW minor correction: `ReadSparkSink` operates on `JavaPairRDD<GATKRead, Void>` (not `JavaPairRDD<GATKRead, SAMRecordWritable>`) at the moment - the values are null so as to not duplicate the amount of data going through the shuffle.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/1249#issuecomment-162024954:180,wrap,wraps,180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/1249#issuecomment-162024954,1,['wrap'],['wraps']
Integrability,"I don't think the warning message is coming from BaseTest, its coming directly from SparkContextFactory, which is executing static code that I think it shouldn't (see the stack I just added to #3591). Its unclear to me if that is actually CAUSING #3591, or just causing the message to display.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330894575:26,message,message,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330894575,2,['message'],['message']
Integrability,"I doubt much CRAM testing has been done with HaplotypeCaller, and I don't see any integration tests for it using CRAM. FWIW, since we have a CRAM version of the BAM we use for those tests, I did just try running them on the CRAM and they passed. As SooHee mentioned though, you'll have issues if the reference you use is in a GCS bucket, or if you specify intervals and the CRAM (and it's index) are in a bucket.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334831157:82,integrat,integration,82,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334831157,1,['integrat'],['integration']
Integrability,"I downloaded and built genomicsdb_120_1 from source. I deleted my previous GenomicsDB database, and built a new one with the following options:. ```; gatk --java-options ""-Xmx128g -Xms128g"" GenomicsDBImport -R genome.fasta -V input1.gvcf.gz -V input2.gvcf.gz -V input3.gvcf.gz -V input4.gvcf.gz -V input5.gvcf.gz --genomicsdb-workspace-path my_database --tmp-dir /tmp -L chrom1 -L chrom2 -L chrom3 -L chrom4 -L chrom5 -L chrom6 -L chrom7 -L chrom8 -L chrom9 --verbosity DEBUG --max-num-intervals-to-import-in-parallel 9; ```. I then ran GenotypeGVCFs with the following options for one of the chromosomes:. ```; gatk --java-options ""-Xmx16g"" GenotypeGVCFs -R genome.fasta -V gendb://my_database -O allpools.chrom2.vcf.gz --tmp-dir=/tmp --sample-ploidy 24 -L chrom2; ```. It failed at the same region it was failing before, with this error message:. ```; 01:15:27.623 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),8476.664214527651,Cpu time(s),8391.206707930733; [January 14, 2020 1:15:30 AM BRT] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 279.78 minutes.; Runtime.totalMemory()=16865820672; htsjdk.tribble.TribbleException: Invalid block size -122708061; at htsjdk.variant.bcf2.BCF2Decoder.readNextBlock(BCF2Decoder.java:66); at htsjdk.variant.bcf2.BCF2Codec.decode(BCF2Codec.java:134); at htsjdk.variant.bcf2.BCF2Codec.decode(BCF2Codec.java:58); at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:181); at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:49); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.loadNextFeature(FeatureIntervalIterator.java:98); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.loadNextNovelFeature(FeatureIntervalIterator.java:74); at org.broadinstitute.hellbender.engine.FeatureIntervalIterator.next(FeatureIntervalIterator.java:62); at org.broadinstitute.hellbender",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-574113941:839,message,message,839,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6275#issuecomment-574113941,1,['message'],['message']
Integrability,"I feel like this is going to be problematic in a different way than what @magicDGS is mentioning. We expect many versions of gatk to be compatible with the same python environment. Also for performance reasons we want to start avoid rebuilding the conda environment on every push and bake it into the base docker instead. This change means we definitely have to build it every time. . It feels like we need something more sophisticated. Instead of stamping the conda environment with the gatk version that matches it, maybe we should be stamping the gatk jar and the conda environment with some version based on the conda.env? Maybe we can do something like taking the md5 of the conda.yml and pushing that into both the jar manifest and the conda environment in some way? I'm guessing this scheme has an issue with the actual python code in the gatk since I think that's installed with conda as well? I'd really like to be able to preinstall the various dependencies though and then only update the code that's part of the gatk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5081#issuecomment-411214721:955,depend,dependencies,955,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5081#issuecomment-411214721,1,['depend'],['dependencies']
Integrability,"I finished the implementation for the draft `SlidingWindowWalker` (I should implement an example and an integration test, but I would like to wait till some issues are solved). made a ""TODO"" about the way in which the intervals are constructed, because I will need a that `ReadShard` have a way to construct a shard without `ReadSource` (either null or empty source), just in case that the implemented `SlidingWindowWalker` does not require reads. @droazen, could you review and give me some feedback about this, because this class is important for other parts of GATK?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-215710163:104,integrat,integration,104,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/1708#issuecomment-215710163,1,['integrat'],['integration']
Integrability,"I found a workaround for Terra. I just tried various cpuPlatform settings in the runtime parameters for the FilterAlignmentArtifacts task and for some reason this works:; cpuPlatform: ""Intel Sandy Bridge""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-782096053:197,Bridg,Bridge,197,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-782096053,1,['Bridg'],['Bridge']
Integrability,"I get tarballs from github, and then download dependencies and generate the intermediate tarball internally. We never clone git repositories as you might think due to security issues.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6395#issuecomment-584408522:46,depend,dependencies,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6395#issuecomment-584408522,1,['depend'],['dependencies']
Integrability,I got another report of something similar in the non-spark HaplotypeCaller; stack trace below. ````; java.lang.IllegalStateException: Duplicate key [B@42515a2f; at java.util.stream.Collectors.lambda$throwingMerger$0(Collectors.java:133); at java.util.HashMap.merge(HashMap.java:1253); at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1320); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.buildGapContinuationPenalties(PairHMMLikelihoodCalculationEngine.java:304); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngine.java:253); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngine.java:187); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:520); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller.apply(HaplotypeCaller.java:239); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:244); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:217); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:779); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(Com,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3018#issuecomment-310805959:621,wrap,wrapAndCopyInto,621,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3018#issuecomment-310805959,1,['wrap'],['wrapAndCopyInto']
Integrability,"I got it to work by using the runtime switch --disable-sequence-dictionary-validation . . If that is not used it crashes. . . Docker commandline. . /gatk Funcotator --disable-sequence-dictionary-validation \. -R mydata/refs/Homo_sapiens_assembly19.fasta \. -V mydata/P50513_mutect2_filtered.vcf \. -O mydata/P50513_mutect2_funcotator.maf \. --output-file-format MAF \. --data-sources-path mydata/dataSourcesFolder/funcotator_dataSources.v1.6.20190124s/ --ref-version hg19. . . . From: Louis Bergelson <notifications@github.com> ; Sent: Wednesday, October 30, 2019 10:26 AM; To: broadinstitute/gatk <gatk@noreply.github.com>; Cc: rdbremel <rdbremel017@gmail.com>; Mention <mention@noreply.github.com>; Subject: Re: [broadinstitute/gatk] Funcotator shuts down (#6182). . @rdbremel <https://github.com/rdbremel> This got missed in the churn of issues. Does this happen repeatedly or is it a 1 time occurrence? We've seen similar issues in the past and tried to wrap them all in layers of retries, but sometimes things slip through. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub <https://github.com/broadinstitute/gatk/issues/6182?email_source=notifications&email_token=ANCR2VB4ZCHMAJUHBKE2SP3QRGRQFA5CNFSM4I2MRFQKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOECUTZZI#issuecomment-547962085> , or unsubscribe <https://github.com/notifications/unsubscribe-auth/ANCR2VHRV5JESZYAYX55YHTQRGRQFANCNFSM4I2MRFQA> . <https://github.com/notifications/beacon/ANCR2VAS2WE5TDCUC6G5LETQRGRQFA5CNFSM4I2MRFQKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOECUTZZI.gif>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548102382:958,wrap,wrap,958,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6182#issuecomment-548102382,1,['wrap'],['wrap']
Integrability,"I got the same problem with GATK v 4.15.0, and for all my samples, I receive an error message like the following:. A USER ERROR has occurred: Read ST-E00318:149:HVLGNCCXX:7:1101:20791:63349 chr1:38902419-38902480 is malformed: read starts with deletion. Cigar: 3D59M91H. Although the SAM spec technically permits such reads, this is often indicative of malformed files. This is the bam file (aligned to hg38). Hope it help.; ST-E00318:149:HVLGNCCXX:7:1101:20791:63349 163 chr1 38902422 60 150M = 38902590 318 TTATTTTTTTTTTTTTGAGATAGAGTCTCGCTTTGTCACCCGGGCTGGAGTACAGTGGCGCAATCTCAGGTCACTGTAACCTCTGCTTCCCAGGTTTAAGCGATTCTCCTGCCTTGGTCTCCTGGGTAGCTTGGATTACAGGTTCACCCC AAAFFKKKKKKKKKKFF7FAK<F,F7<<,A,<FA<F7<AFA(<A,AFF,A,,7F<FFAAF7(,7AAKKK<F,7AAAF,77,FFKKA,<,,,,7<,7F,7A,A7AK,AA,A,77FK,A,,<<<FF,7,,<,<<FK,<<,,,,<A,,,,,,< MC:Z:150M MD:Z:21G19A73A1C6A18G3A2 PG:Z:bwamem RG:Z:A NM:i:7 MQ:i:60 UQ:i:89 AS:i:118; ST-E00318:149:HVLGNCCXX:7:1101:20791:63349 83 chr1 38902590 60 150M = 38902422 -318 TTTTGTATTTTTAATAGAGACGGGGTTTCACCATGTTGGTCGGGCTGGTCTCGAACTCCTGACCTGATGATCCGCCCACCTCGGCCTCCCCAAGTGCTGGGATTACAGGCATAAGCCACCACACCCAGCCTTTGTTATTTTTTTTTAAAG FF<7KKKKKFAKF<7KKF(<FKKKF<,KKFKKKKKKKKFFA<<KKK7FKKKKKFFFFKAAFKKKFFKKKFAKKFFFKKKKFFKKFAAKKKKKKFKKKKKKKKFKKKKKKKKKKKAKKKKKFFKKKKKKKKKKKKKKKKKK<KKKKFFFAA MC:Z:150M MD:Z:150 PG:Z:bwamem RG:Z:A NM:i:0 MQ:i:60 UQ:i:0 AS:i:150",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6490#issuecomment-597714610:86,message,message,86,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6490#issuecomment-597714610,1,['message'],['message']
Integrability,"I guess I could, but what is GATKTool contract... is it supposed to only perform reference driven analysis? I thought that is what a Walker is.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-577247790:38,contract,contract,38,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6390#issuecomment-577247790,1,['contract'],['contract']
Integrability,"I guess it depends on how general we want to keep this input path. I think most purely read-depth based callers won't really be able to discover events smaller than 800bp or so (maybe 500bp at the lower limit) with any accuracy. I also don't know of any tools that we're considering that will describe individual breakpoints. . What about this for a rule: create two intervals for the start and end of the CNV interval + or - 151 bases (allowing a read length of slop). If the two intervals overlap, merge them together into a single evidence interval. . We could also make the slop amount parameterizable per input file, since different tools might have different characteristics, although that would be a feature we could just make a ticket for until we need it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3542#issuecomment-327499474:11,depend,depends,11,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3542#issuecomment-327499474,1,['depend'],['depends']
Integrability,I guess that should be fixed as well. Do you have the command and data to reproduce... I can add the integration test for that.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5434#issuecomment-447125138:101,integrat,integration,101,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5434#issuecomment-447125138,1,['integrat'],['integration']
Integrability,"I guess we need to do some work on the doclet code, abstract out example code and use templates to transform it into the appropriate format/syntax depending what project is generating the documentation. Alternatively and only if documentation html is well formed (xhtml like) then in theory we could use XSLT transformation style sheets to convert embedded code example encoded with xml/xhtml into the concrete syntax. Most major browsers support XSLT. EDIT: The XSLT solution won't probably work since even if we try to change the output from html to xhtml, the fact that we are injecting the javadoc's html would probably break the xhtml.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349724551:147,depend,depending,147,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-349724551,2,"['depend', 'inject']","['depending', 'injecting']"
Integrability,I have a new build of the GKL that I need to test and then integrate into a new gatk. It's not available yet though.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-814269292:59,integrat,integrate,59,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-814269292,1,['integrat'],['integrate']
Integrability,"I have a version of this working in the branch `cw_phase_star_allele`, but am holding off on making a PR until https://github.com/broadinstitute/gatk/pull/6859 can be merged to avoid conflicting changes to integration test files.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5651#issuecomment-712158375:206,integrat,integration,206,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5651#issuecomment-712158375,1,['integrat'],['integration']
Integrability,"I have never used the GATK version CollectSequencingArtifactMetrics. So all of my errors stem from using the results of Picard's CollectSequencingArtifactMetrics, which we can expect our users to do for the foreseeable future, given the merging of the toolsets is not something in the works as far as I know. . @LeeTL1220 It seems peculiar to me that we should have to fix Picard's CollectSequencingArtifactMetrics for compatibility with this new tool FilterByOrientationBias. Rather, shouldn't you fix FilterByOrientationBias to accept either string?. Given other tools can read and write bgzipped VCFs, I would conjecture the way in which FilterByOrientationBias is utilizing dependencies is flawed, and not that dependencies require fixes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306531581:678,depend,dependencies,678,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306531581,2,['depend'],['dependencies']
Integrability,"I have pull requests in flight for both (1) and (2). They are 1469; <https://github.com/GoogleCloudPlatform/google-cloud-java/pull/1469> and; 1470 <https://github.com/GoogleCloudPlatform/google-cloud-java/pull/1470>. Cheers,; JP. On Tue, Dec 6, 2016 at 3:54 AM, Tom White <notifications@github.com> wrote:. > Yes, Hadoop-BAM uses the NIO API to do file merging, whereas in GATK we; > were using the Hadoop APIs (and therefore the GCS<->HDFS adapter) to do it.; >; > It looks like there are a couple of things needed in GCS-NIO to use the; > NIO API for this.; >; > 1. GoogleCloudPlatform/google-cloud-java#1450; > <https://github.com/GoogleCloudPlatform/google-cloud-java/issues/1450>; > so that we don't have to special-case gs URIs to remove everything; > except the scheme and host when looking up the filesystem (see; > https://github.com/HadoopGenomics/Hadoop-BAM/; > blob/master/src/main/java/org/seqdoop/hadoop_bam/util/; > NIOFileUtil.java#L40; > <https://github.com/HadoopGenomics/Hadoop-BAM/blob/master/src/main/java/org/seqdoop/hadoop_bam/util/NIOFileUtil.java#L40>; > ); > 2. GoogleCloudPlatform/google-cloud-java#813; > <https://github.com/GoogleCloudPlatform/google-cloud-java/issues/813>; > to support path matching (https://github.com/HadoopGenomics/Hadoop-BAM/; > blob/master/src/main/java/org/seqdoop/hadoop_bam/util/; > NIOFileUtil.java#L90; > <https://github.com/HadoopGenomics/Hadoop-BAM/blob/master/src/main/java/org/seqdoop/hadoop_bam/util/NIOFileUtil.java#L90>; > ); >; > There may be more, as I stopped there. The best way forward is probably to; > go back to the old code in GATK while the deficiencies in GCS-NIO are fixed; > and then released.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-266151447:441,adapter,adapter,441,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-266151447,1,['adapter'],['adapter']
Integrability,"I just created a Maven Project with Eclipse and modified the pom.xml as reported [here](https://pastebin.com/kwi7gSRk) and then I executed `mvn clean install -U` inside the folder of the project; ```; <project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""; xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">; <modelVersion>4.0.0</modelVersion>; <groupId>uk.ac.ncl</groupId>; <artifactId>GATKpipe</artifactId>; <version>0.0.1-SNAPSHOT</version>; <repositories>; <repository>; <snapshots />; <id>snapshots</id>; <name>libs-snapshot</name>; <url>https://broadinstitute.jfrog.io/broadinstitute/libs-snapshot</url>; </repository>; </repositories>; <dependencies>; <dependency>; <groupId>org.broadinstitute</groupId>; <artifactId>gatk</artifactId>; <version>4.beta.6-18-g2ee7724-20171025.162137-1</version>; </dependency>; </dependencies>; </project>; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339930421:743,depend,dependencies,743,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339930421,4,['depend'],"['dependencies', 'dependency']"
Integrability,"I just ran GATK 4.1.7.0 with GDB 1.2.1 and I'm seeing these logging messages again. Granted I've also built a few old jars lately, but after a clean build I'm still seeing it. @nalinigans can you run the latest and confirm or deny?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663151098:68,message,messages,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663151098,1,['message'],['messages']
Integrability,"I just remembered @ldgauthier we need a special note for GenomicsDBImport from #3137. To quote @droazen:. > For example, GenomicsDBImport requires that you size your -Xmx value significantly smaller than the total amount of free memory on the machine, in order to leave enough room for the native heap. If you don't do this, you will get truly horrific and cryptic messages when the native code crashes with out-of-memory. This is really something that needs to be documented prominently!. Also need to propogate the Xmx option to the 2nd example command. Shall I do this?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3891#issuecomment-350784422:365,message,messages,365,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3891#issuecomment-350784422,1,['message'],['messages']
Integrability,"I just tried with gatk 4.1.7.0 and 4.1.8.0 released zips and cannot reproduce the issue. I can only see buffer resize logging messages when I use a debug version of libtiledbgenomicsdb.so in my private builds. . That said, `gatk 4.1.7.0` picks up `libtiledbgenomicsdb.so` from the LD_LIBRARY_PATH, otherwise it extracts from the genomicsdb.jar. @ldgauthier, do you have an older version of the native `libtiledbgenomicsdb.so` in your LD_LIBRARY_PATH env? That could be one cause. Otherwise, if you move to using `gatk 4.1.8.1` as @droazen recommends, it will only pick up the native library packed with the genomicsdb 1.3.0 jar. To override the packed genomicsdb library, in versions 1.3.0+, one has to explicitly the path specify via java options -Dgenomicsdb.library.path=<path_to_libtiledbgenomicsdb.so>.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663238869:126,message,messages,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663238869,1,['message'],['messages']
Integrability,I kicked off an integration test run this morning. I don't expect the results to change (since the integration tests all set the `drop_state` themselves). But I've been burned before!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8550#issuecomment-1758135199:16,integrat,integration,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8550#issuecomment-1758135199,2,['integrat'],['integration']
Integrability,"I know that, and I kind of have an idea of how to do it with gradle without having a local copy (if you are interested, see https://stackoverflow.com/questions/28149123/is-there-a-way-to-tell-gradle-to-include-dependencies-javadocs-in-generated-java). I subscribed to broadinstitute/gatk-protected#1048, and I'm closing this as a duplicate of that one. Thanks for your help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2739#issuecomment-303325314:210,depend,dependencies-javadocs-in-generated-java,210,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2739#issuecomment-303325314,1,['depend'],['dependencies-javadocs-in-generated-java']
Integrability,I made a [PR](https://github.com/broadinstitute/gatk/pull/3169) for copying the CSS file that separate from the command line arg one since its dependent on this PR.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3165#issuecomment-311081582:143,depend,dependent,143,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3165#issuecomment-311081582,1,['depend'],['dependent']
Integrability,"I managed to 1) wrap the cohort_determine_ploidy_and_depth.py script in a CLI tool (see the sl_gcnv_ploidy_cli branch), and 2) build the gcnvkernel package within a conda environment on gsa6 and run the tool, both without too much trouble. A few things:. 1) I don't see any logging from the python script (but then again, I didn't try anything out of the ordinary to get it working---should I have had to?). 2) I had to copy the cohort_determine_ploidy_and_depth.py script to the appropriate place in src/main/resources. Perhaps that's a better place for python scripts/packages, rather than src/main/python?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-345745315:16,wrap,wrap,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3838#issuecomment-345745315,1,['wrap'],['wrap']
Integrability,I might be able to take a look on Friday. You can help me by confirming that there are integration tests where the output GT is `1|0` and that should jive with the existing PGT.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5318#issuecomment-436752851:87,integrat,integration,87,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5318#issuecomment-436752851,1,['integrat'],['integration']
Integrability,"I might have a working MacOS conda environment, but I haven't run all the python tools. Resolving packages got a lot harder (maybe impossible) after Sam integrated the R dependencies, so my environment branches off the old one.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6813#issuecomment-730426065:153,integrat,integrated,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6813#issuecomment-730426065,2,"['depend', 'integrat']","['dependencies', 'integrated']"
Integrability,"I prefer to keep out of this user exceptions the arguments from the wrapper script due to downstream projects including tools from GATK (and using the `UserException` classes). Thus, I vote for refere to the `--TMP_DIR`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4709#issuecomment-384568889:68,wrap,wrapper,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4709#issuecomment-384568889,1,['wrap'],['wrapper']
Integrability,"I propose to still hide from the command line and docs the example walkers. They are meant only for developers, to show how to use some kind of walkers and have a running tool for integration tests. Having then in the command line will generate software users to run them instead of use them for developmental purposes... In addition, I think that this is a good moment to also generate a sub-module structure (as I suggested in #3838) to separate artifact for different pipelines/framework bits (e.g., engine, Spark-engine, experimental, example-code, CNV pipeline, general-tools, etc.). For the aim of this issue, this will be useful for setting documentation guidelines in each of the sub-modules: e.g., example-code should be documented for developers, but not for the final user; experimental module should have the `@Experimental` barclay annotation in every `@DocumentedFeature`; etc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346291829:180,integrat,integration,180,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3853#issuecomment-346291829,2,['integrat'],['integration']
Integrability,"I randomly came across this ticket - this is happening because the GroupBy enum in CalculateTargetCoverage [overrides toString](https://github.com/broadinstitute/gatk/blob/b58baa5ff8d69e69ae4ac28c863a4126529cf094/src/main/java/org/broadinstitute/hellbender/tools/exome/CalculateTargetCoverage.java#L675) for some reason, and returns a lower cased string. Sending to @davidbenjamin for routing since he looks like the main contributor for that file.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2885#issuecomment-316486437:385,rout,routing,385,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2885#issuecomment-316486437,1,['rout'],['routing']
Integrability,"I rebased this, and responded to code review comments:. - updated comments; - reverted GenotypeGVCFs change; - reverted changing the default lookahead for VariantWalker side inputs. I think changing the default lookahead for VariantWalker side inputs to the new, smaller value will hurt performance for tools like VQSR. I did some crude timing tests using the FeatureDataSource default (1000 bases) proposed in this branch, and the current default (100,000 bases). The following are total times as reported by Gradle for serial runs of the VQSR integration tests:. With 1000 base lookahead:; 1m40s; 1m29s; 1m29s; 1m25s. With 100,000 base lookahead:; 1m29s; 1m17s; 1m16s; 1m18s. Back to 1000 base lookahead again:; 1m36s; 1m26s; 1m26s; 1m29s. It seems pretty consistently slower with the smaller lookahead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3480#issuecomment-417360848:545,integrat,integration,545,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3480#issuecomment-417360848,1,['integrat'],['integration']
Integrability,"I remember there being discussion about this when it was included. It was added by @jean-philippe-martin, I think there was a conflict between the version of protobuffers used by hadoop and the version used by the NIO dependency and this was the only one that worked for both. I could be misremembering though, and it's possible that since we're using the shaded NIO now that the proto buffer dependency in it is shaded and we no longer need to force any version.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2437#issuecomment-284492499:218,depend,dependency,218,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2437#issuecomment-284492499,2,['depend'],['dependency']
Integrability,"I reran option 2 with latest gatk4/master. I ran the BaseRecalibrator step (scattered about 20 ways) 10 times each. All 10 runs failed. I haven't checked all of the error messages yet, but I did see a couple with a new error message about the dbsnp vcf, which I was also streaming with NIO. I'm going to change that back to localizing the dbsnp vcf to see if those go away. Here's that message:. ```; Using GATK jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr8:1+ --cloudPrefetchBuffer 0 --cloudIndexPrefetchBuffer 0; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.DoXBYr; [July 24, 2017 9:31:25 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.re",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963:171,message,messages,171,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963,3,['message'],"['message', 'messages']"
Integrability,"I reran the BQSR step 5 times using the exact same input bam as before. One has succeeded, 3 are still running and I got a new yet similar error message on a different shard this time:. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr12:1+ -L chr13:1+; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.KnjoXJ; [July 21, 2017 2:50:20 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.recal_data.csv --intervals chr12:1+ --intervals chr13:1+ --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --reference /cromwell_root/broad-r",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317028955:145,message,message,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317028955,1,['message'],['message']
Integrability,"I reran this with retry enabled. It says it finished successfully. There was an error in the middle but it continued anyways (this isn't shown in the final output, but there was a second bar).; I'm not sure about the output, though. Where is this command supposed to leave `output.bam`? It's not on my desktop. ```; [Stage 1:=====================================> (375 + 2) / 553]17/03/30 18:18:46 WARN org.apache.hadoop.hdfs.DFSClient: DFSOutputStream ResponseProcessor exception for block BP-369249695-10.240.0.8-1490738675068:blk_1073745922_5098; java.io.EOFException: Premature EOF: no length prefix available; 	at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2282); 	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:244); 	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:733); 17/03/30 18:18:46 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block BP-369249695-10.240.0.8-1490738675068:blk_1073745922_5098 in pipeline DatanodeInfoWithStorage[10.240.0.4:50010,DS-5596b1b5-b89c-4c39-bbd8-7423614eae0e,DISK], DatanodeInfoWithStorage[10.240.0.3:50010,DS-a0c20806-0af3-4679-b8cd-9cae6ca25071,DISK]: bad datanode DatanodeInfoWithStorage[10.240.0.4:50010,DS-5596b1b5-b89c-4c39-bbd8-7423614eae0e,DISK]; 17/03/30 20:00:21 INFO org.spark_project.jetty.server.ServerConnector: Stopped ServerConnector@61cda923{HTTP/1.1}{0.0.0.0:4040}; 20:00:21.366 INFO MarkDuplicatesSpark - Shutting down engine; [March 30, 2017 8:00:21 PM UTC] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 165.11 minutes.; Runtime.totalMemory()=1222115328; Job [ac3f4131-f19f-47db-8cc3-82b243ad4b72] finished successfully.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2517#issuecomment-290541369:642,protocol,protocolPB,642,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2517#issuecomment-290541369,2,['protocol'],"['protocol', 'protocolPB']"
Integrability,"I resolved the conflicts, @cmnbroad. The only changes for Barclay were javadoc improvements related to the usage of `CommandLineException` after parsing, because I had some issues thinking that any `UserException` will be catch and exit with an error message, but now that it is decoupled into its own class I don't think that it is necessary.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-267000555:251,message,message,251,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2282#issuecomment-267000555,1,['message'],['message']
Integrability,"I run locally the gradle gatkDoc task and I fixed some HTML formatting (and a missing summary line in `MetricsReadFilter`. Can you have a look to the last commit to be sure, @vdauwera?. I will add fixes if I find problems in my own documentation code when I update the gatk dependency. Thanks for reviewing and accepting these changes!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3128#issuecomment-319623957:274,depend,dependency,274,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3128#issuecomment-319623957,1,['depend'],['dependency']
Integrability,I see something similar:. ![image](https://user-images.githubusercontent.com/13020550/176465545-00ab41ad-d1d2-4cbd-963c-f903ae025f60.png). ![image](https://user-images.githubusercontent.com/13020550/176465845-91b9e3e7-d111-4cd9-b723-7c8575693757.png). It's much better but still far more conservative than the F1. . This metric is somewhat counterintuitive to me because if you're dividing by M this is the number of total observations. It seems to me that that number is dependent not on the classifier at all but more on the results of HaploptypeCaller. In other words the class balance between true and unlabelled/false could have a large effect here.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1170078557:472,depend,dependent,472,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7711#issuecomment-1170078557,1,['depend'],['dependent']
Integrability,"I see whats going on now - I had been assuming that the extra lines were variant records, but they're just extra filter metadata lines resulting from the bogus tranches. So, the actual fix for this was https://github.com/broadinstitute/gatk/pull/2275. I'm closing this ticket out and will add a separate PR with an integration test that uses multiple tranches so we don't regress.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2276#issuecomment-263878175:315,integrat,integration,315,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2276#issuecomment-263878175,1,['integrat'],['integration']
Integrability,"I still feel strongly about not using outputs of SplitIntervals with any reassembly caller as these will expand active regions beyond the intervals given. It is thus possible to end up with calls that depend on identical reads. That is, read evidence is being counted twice for different calls and/or we end up with duplicate calls.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3061#issuecomment-349727030:201,depend,depend,201,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3061#issuecomment-349727030,1,['depend'],['depend']
Integrability,"I suspect it's a different issue than #4062, but probably some similar library incompatibility issue. Unfortunately the stack trace doesn't have enough information in it. We should consider rewriting the error message for this so that we are sure to have the first cause reported, not just the `Could not load genomicsdb native library` message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356984584:210,message,message,210,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356984584,2,['message'],['message']
Integrability,"I talked to comms and we agreed that a ""mitochondria-mode"" argument to Mutect2 was the right balance of clarity (you're really running Mutect2 not a wrapper) and simplicity (you don't need a laundry list of arguments to change which mode you're in if you just want to run with optimized defaults). . @ldgauthier @davidbenjamin @takutosato @rcmajovski Could you please take another look? Removing the wrapper tools has cleaned up the code so there are fewer changes now. I also changed TLOD to LOD in this version, but I'm happy to take that out and have that be future work if anyone is worried about it being a breaking change.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-428195077:149,wrap,wrapper,149,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5193#issuecomment-428195077,4,['wrap'],['wrapper']
Integrability,"I think changes in 4.2.4.1 are exposing an issue, but I think @eriqande is right that the issue isn't with GenomicsDB. The change was that previously GATK wasn't correctly passing the `--max-alternate-allele` argument to GenomicsDB, but now that it is doing so it makes it more likely that some sites don't contain fields like PL (dependent on number of possible genotypes). It looks like the AF calculation used to ignore sites if they didn't have likelihoods, but has now been updated slightly to also allow sites with GQ or sites where any alleles are called+nonref+not symbolic. https://github.com/broadinstitute/gatk/blob/caa48f98c8207b688db6ee35fead3eafb7219e38/src/main/java/org/broadinstitute/hellbender/utils/GenotypeUtils.java#L139-L141. Possibly that condition needs to be tweaked? @ldgauthier might be the best person to ask. As for this working with previous versions, that is only because the `--max-alternate-alleles` wasn't being passed to GenomicsDB correctly. if you want to revert to that behavior you can set `--max-alternate-alleles` to `50` (which is what GenomicsDB defaults to).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1015961941:331,depend,dependent,331,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7639#issuecomment-1015961941,1,['depend'],['dependent']
Integrability,"I think even more important is that they share the reference genome that they are using. Get Outlook for Android<https://aka.ms/AAb9ysg>; ________________________________; From: Gökalp Çelik ***@***.***>; Sent: Wednesday, April 24, 2024 12:28:39 AM; To: broadinstitute/gatk ***@***.***>; Cc: Ilya Soifer ***@***.***>; Assign ***@***.***>; Subject: Re: [broadinstitute/gatk] Prevent users enabling annotations with mismatching data type (flow etc) (Issue #8788). Assigned #8788<https://github.com/broadinstitute/gatk/issues/8788> to @ilyasoifer<https://github.com/ilyasoifer>. —; Reply to this email directly, view it on GitHub<https://github.com/broadinstitute/gatk/issues/8788#event-12581899218>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AGDPRCP66IKPOBF2GPENP6LY63HAPAVCNFSM6AAAAABGTGMBPWVHI2DSMVQWIX3LMV45UABCJFZXG5LFIV3GK3TUJZXXI2LGNFRWC5DJN5XDWMJSGU4DCOBZHEZDCOA>.; You are receiving this because you were assigned.Message ID: ***@***.***>. ________________________________. CONFIDENTIALITY NOTICE: This message (including any attachments) should be presumed to contain confidential, proprietary, privileged and/or private information. Information contained in this message is intended only for the recipient(s) named above. Any disclosure, reproduction, distribution or other use of this message or any attachments by any unauthorized individual or entity is strictly prohibited. If you have received this message in error, please notify the sender immediately, and delete the message and any attachments. Learn more about Ultima Genomics’ Privacy Policy<https://www.ultimagenomics.com/privacy-policy>.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8788#issuecomment-2074020625:943,Message,Message,943,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8788#issuecomment-2074020625,6,"['Message', 'message']","['Message', 'message']"
Integrability,"I think for SQ you could limit the lines you write out to the contigs that are covered in your intervals list, ignore the rest. So you can access that info as soon as you've parsed the command line. Or if you're running without an intervals list you could supply a seq dict file through a separate arg. But the former seems safer. . For other modes: EXTREME would hardcode what we consider required. Then you could potentially do ARBITRARY to allow passing strings for specific attributes that you want to drop. . None of these would have to depend on what's in the calls, I think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2233#issuecomment-266059687:542,depend,depend,542,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2233#issuecomment-266059687,1,['depend'],['depend']
Integrability,"I think it's best not to co-opt existing formats for storing *variant calls* and *mutations* if we want to store generic annotations. Furthermore, many of the drawbacks of VCF (e.g, wasted space from repeated tags/unused fields) are really not worth dealing with if our data is strictly tabular and well structured. I think if we can settle on a format internally that satisfies all of our needs, then it'd probably a *very small* amount of effort on the part of external developers to write adapters to consume it. After all, we are only talking about metadata (hopefully in a standardized but suitably flexible format, e.g. SAM/VCF-style header) + tabular data. It may also be that there is a format out there that already fits the bill, in which case we just need to do some more research and discussion. I think this would be better than causing confusion and setting a bad example by co-opting unsuitable formats, even if this would require no additional effort for external developers.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-386578762:492,adapter,adapters,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4717#issuecomment-386578762,1,['adapter'],['adapters']
Integrability,"I think removing pysam is dependent on writing Java front ends for the CNN tools that are currently just pass-through to python (https://github.com/broadinstitute/gatk/issues/4533, https://github.com/broadinstitute/gatk/issues/4534 and https://github.com/broadinstitute/gatk/issues/4535). @lucidtronix Do you have a timeframe for that work ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4742#issuecomment-387157643:26,depend,dependent,26,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4742#issuecomment-387157643,1,['depend'],['dependent']
Integrability,"I think that each tool should either emit proper error messages, or deal with the data it's given. currently BQSR emits a cryptic error message so I think that this PR is an improvement regardless of whether the pipeline is sanitized. . That said, I think that it might be a good idea to make ValidateSamFile break on non-ACGTN bases.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6625#issuecomment-642719900:55,message,messages,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6625#issuecomment-642719900,2,['message'],"['message', 'messages']"
Integrability,"I think that it is necessary to have a way for downstream projects to override some of the top-level arguments in the base CLP class. For example, the config file is for documentation purposes, but I don't want to expose users to that argument because I will set the defaults programmatically. Another example is the GCS retries, which might not be useful for a software that is not planning to support GCS even if it is already implemented (or does not want to expose). As a downstream developer, for me it is important to being able to configure arguments and expose/hide them to my final users; with the current implementation, my main issue is to have an argument that are irrelevant for the toolkit user and that I get questions about why and how to use them (the most clear example, the config file). If the main problem is to change an interface, a default value for new methods can be added to keep the same behavior.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-361876183:843,interface,interface,843,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-361876183,2,['interface'],['interface']
Integrability,"I think that this is because in Picard tools the version is populated from the manifest `Version` attribute, and thus it prints the GATK version. @droazen and @cmnbroad - this shows that https://github.com/broadinstitute/gatk/issues/4101 in combination with a common CLP barclay class is really needed to set versions properly to combine toolkits in one (GATK/Picard, integrate common tools into a downstream project, etc.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4733#issuecomment-386994409:368,integrat,integrate,368,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4733#issuecomment-386994409,1,['integrat'],['integrate']
Integrability,"I think the message isn't coming from BaseTest, its coming from a static block in SparkContextFactory:. 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getGcsHadoopAdapterTestProperties(SparkContextFactory.java:68); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.<clinit>(SparkContextFactory.java:59); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineArgumentCollection.<init>(SparkCommandLineArgumentCollection.java:20); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.<init>(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.<init>(GATKSparkTool.java:64); 	at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.<init>(PrintReadsSpark.java:19); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at java.lang.Class.newInstance(Class.java:442); 	at org.broadinstitute.hellbender.Main.extractCommandLineProgram(Main.java:285); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:150); 	at org.broadinstitute.hellbender.Main.main(Main.java:233)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330894140:12,message,message,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330894140,1,['message'],['message']
Integrability,"I think the root cause is the method ensureCapacity of GenotypesCache is not synchronized. So when multiple task threads run into this method, the new added cache is not fully initialized.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8961#issuecomment-2306051902:77,synchroniz,synchronized,77,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8961#issuecomment-2306051902,1,['synchroniz'],['synchronized']
Integrability,"I think we can generally enable this by pushing the option up to VariantWalker / GATKTool and integrating it with the createVCFWriter method. . It can optionally return a writer wrapped in a decorator that only outputs sites within the given intervals. We might want to rename the option in that case to something like ""only-output-variants-starting-in-intervals"" so it's clear that it only effects variant outputs. Or make it work with generated bamWriters too...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6339#issuecomment-568100260:94,integrat,integrating,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6339#issuecomment-568100260,4,"['integrat', 'wrap']","['integrating', 'wrapped']"
Integrability,"I think we just don't have any borderline cases in our integration tests. We have a lot of cases where VQSR passes and one with artificial data where it's obviously going to fail. I couldn't reproduce the particular failure they saw in production, so I didn't want to add that to Travis if it's persnickety.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6534#issuecomment-617341642:55,integrat,integration,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6534#issuecomment-617341642,1,['integrat'],['integration']
Integrability,I think we'll need to generalize the progress meter slightly to allow for different wording in the output message. (and the position column will make no sense for this tool).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2683#issuecomment-300227436:106,message,message,106,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2683#issuecomment-300227436,1,['message'],['message']
Integrability,"I thought I figured this out but I haven't. I'm looking at sample1.md.bam file header, but I can't figure it out. ```. for BAM in sample1.md.bam ; do samtools view -H $BAM; > header.sam; done; @HD	VN:1.5	SO:coordinate; @SQ	SN:1	LN:4918979; @SQ	SN:2	LN:4844472; @SQ	SN:3	LN:4079167; @SQ	SN:4	LN:3923705; @SQ	SN:5	LN:3948441; @SQ	SN:6	LN:3778736; @SQ	SN:7	LN:2058334; @SQ	SN:8	LN:1833124; @PG	ID:hisat2	PN:hisat2	VN:2.1.0	CL:""/usr/local/apps/eb/HISAT2/2.1.0-foss-2016b/bin/hisat2-align-s --wrapper basic-0 -p 8 --no-spliced-alignment -I 100 -x ./ref_tran.dir/ref_tran -S sample1.sam -1 e1_R1.fastq -2 e1_R2.fastq""; @PG	ID:MarkDuplicates	VN:2.16.0-SNAPSHOT	CL:MarkDuplicates INPUT=[sample1.bam] OUTPUT=sample1.md.bam METRICS_FILE=sample1.md.metrics.txt MAX_SEQUENCES_FOR_DISK_READ_ENDS_MAP=50000 MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=8000 SORTING_COLLECTION_SIZE_RATIO=0.25 TAG_DUPLICATE_SET_MEMBERS=false REMOVE_SEQUENCING_DUPLICATES=false TAGGING_POLICY=DontTag CLEAR_DT=true ADD_PG_TAG_TO_READS=true REMOVE_DUPLICATES=false ASSUME_SORTED=false DUPLICATE_SCORING_STRATEGY=SUM_OF_BASE_QUALITIES PROGRAM_RECORD_ID=MarkDuplicates PROGRAM_GROUP_NAME=MarkDuplicates READ_NAME_REGEX=<optimized capture of last three ':' separated fields as numeric values> OPTICAL_DUPLICATE_PIXEL_DISTANCE=100 MAX_OPTICAL_DUPLICATE_SET_SIZE=300000 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false	PN:MarkDuplicates. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5372#issuecomment-434156611:488,wrap,wrapper,488,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5372#issuecomment-434156611,1,['wrap'],['wrapper']
Integrability,"I thought we agreed to leave it unless Intel needed to wrap the current workflows as subworkflows? Remember that things like `CNVSomaticPanelWorkflow.PreprocessIntervals.bin_length` can still be set. Not sure how this looks on FireCloud at the moment, but unless it doesn't show up there even when the workflow is top level (in which case, I really don't understand the point of optional parameters), then let's leave it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3980#issuecomment-356001763:55,wrap,wrap,55,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3980#issuecomment-356001763,1,['wrap'],['wrap']
Integrability,I took the 2022-03-10-4.2.5.0-13-g1c749b37f-NIGHTLY-SNAPSHOT from 18hours ago and got what looks to be the same error message. [mutect2.log](https://github.com/broadinstitute/gatk/files/8226353/mutect2.log),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1064400690:118,message,message,118,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7700#issuecomment-1064400690,1,['message'],['message']
Integrability,"I tried a quick upgrade of our guava dependency from 18 -> 22, but it ends in test failures. It looks like at least one of our hadoop dependencies requires guava <= 18. I'm not totally clear if it's an issue for hadoop-core or only in hadoop-minicluster which is a library we use for running tests. If you're not using hdfs I think you won't have any problems including 22, but I'm afraid we can't upgrade our default version without some work. . Hopefully hadoop 3.x will solve the problem in general by shading their internal version of guava. ; https://issues.apache.org/jira/browse/HADOOP-14284, https://issues.apache.org/jira/browse/HADOOP-10101. It sounds like you have a reasonable workaround, let us know if you have further issues with it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308181516:37,depend,dependency,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308181516,4,['depend'],"['dependencies', 'dependency']"
Integrability,"I tried to do it, and I'm afraid that it won't be trivial as I expected: because it is a facade, there is not accesibility to `Logger.setLogLevel()` and this is required to set the verbosity level in the command line. After explore a bit the code, it seems that [`LoggingUtils`](https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/utils/LoggingUtils.java) is the only place where a concrete implementation should be used. My suggestion is to move this class to a package that could be excluded by the backend user (because it contains methods to change the logging of log4j, I suggest `org.apache.logging.log4j`), which implements a simple interface/abstract class `org.broadinstitute.hellbender.utils.LoggingUtils` to set the log level (LoggingUtils.setLoggingLevel(final Log.LogLevel verbosity)`. The default implementation (that could be used by final users callid`super.setLoggingLevel(final Log.LogLevel verbosity)`) could setup the htsjdk and the java.util.logger.Logger. This implementation requires to change the `CommandLineProgram` to have a setter for the `LoggingUtils` to use, that could be set in `Main` (as in my PR for improve the extensibility of this class). The only pronblem is that it requires to be initialize with a simple implementation class of `LoggingUtils`, which should use the default. I think that this design does not break the behaviour of GATK, but introduce more complexity in the code. If you think that this is worthy, I could implement it today. @lbergelson, I'm not able to run Spark tools in a cluster yet, neither in gcloud dataproc, sorry. I'll wait for your answers on this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-259073062:683,interface,interface,683,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2176#issuecomment-259073062,2,['interface'],['interface']
Integrability,"I typoed the commit message that closed this, it was done in #3052",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3049#issuecomment-306832820:20,message,message,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3049#issuecomment-306832820,1,['message'],['message']
Integrability,"I use the conda package [bioconda/gatk4 (version 4.2.5.0)](https://bioconda.github.io/recipes/gatk4/README.html), but from memory that conda package does not include the necessary R dependencies --- I could be wrong, though!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7697#issuecomment-1054919884:182,depend,dependencies,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7697#issuecomment-1054919884,1,['depend'],['dependencies']
Integrability,"I used to have maven projects depending on GATK4, but I ported them all to gradle. Nevertheless, I haven't seen this error before...maybe it came after all my code has being ported. Sorry for not being useful here...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339059469:30,depend,depending,30,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3724#issuecomment-339059469,1,['depend'],['depending']
Integrability,"I want to update my dependencies, but the last commits are not in the new artifactory. Which one is the latest?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3068#issuecomment-307822412:20,depend,dependencies,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3068#issuecomment-307822412,1,['depend'],['dependencies']
Integrability,"I was able to trigger the ArrayIndexOutOfBoundException (and subsequently fix it with your synchronization) with the following code, so perhaps a test similar to this would be useful to include:; ``` @Test(); public void testRaceCondition(){; final GenotypeLikelihoodCalculators calculator = new GenotypeLikelihoodCalculators();. List<int[]> counts = new ArrayList<>();; Random random = new Random(10);; for (int i = 1; i < 19; i++) {; counts.add(new int[]{random.nextInt(i), random.nextInt(i)});; }. Utils.stream(counts).parallel().forEach(params -> calculator.getInstance(params[0]+1, params[1]+1));; }```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5071#issuecomment-417006227:91,synchroniz,synchronization,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5071#issuecomment-417006227,1,['synchroniz'],['synchronization']
Integrability,"I was getting the same error with GATK version 4.2.0.0 for VCFs generated by GenotypeGVCFs, or by other tools. ```A USER ERROR has occurred: More then one variant context at position: chr1:969780```. It turns out it's caused either by the input VCF having 2 SNPs on separate rows but with the same position - for example:; ```; chr1	969780	.	C	T	... etc.; chr1	969780	.	C	A	... etc.; ```; or by an INDEL that overlaps a SNP - for example:; ```; chr1	969778	.	TGC	T	199.60	.	.	GT:AD:DP:GQ:PL	0/1:14,7:21:99:207,0,475; chr1	969780	.	C	T	467.64	.	.	GT:AD:DP:GQ:PL	0/1:7,14:21:99:475,0,207; ```; The solution was to filter out INDELs and multiallelic sites before running ASEReadCounter.; This is a reasonable thing to do regardless since INDELs and multiallelic sites are much more likely to yield biased ASE counts due to worse mapping and variant quality. . One way to do this filtering is with . ```; gatk SelectVariants -R hg38.fa. --variant dna_variants.vcf.bgz --restrict-alleles-to BIALLELIC -select 'vc.getHetCount()==1' --select-type-to-include SNP -O dna_variants.selected.vcf.bgz. bcftools norm --rm-dup all dna_variants.selected.vcf.bgz | bgzip > out.vcf.gz; ```. It would be nice if ASEReadCounter could do this automatically instead of exiting with an error, or print an error message that mentions the solution.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7249#issuecomment-1091075626:1288,message,message,1288,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7249#issuecomment-1091075626,1,['message'],['message']
Integrability,"I was looking into this myself as part of other argument renaming tasks. I don't see that you have changed any of the recalibration table arguments checked into the repo, namely in the test resources /tools/BQSR. (eg. `src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.lowMaxCycle.table`) You should probably take a look at this and other .table files and maybe update them to have more up to date summary statistics, as it could indicate that the gatk is writing its output with the old argument styles as these are used in integration tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4029#issuecomment-355064406:549,integrat,integration,549,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4029#issuecomment-355064406,1,['integrat'],['integration']
Integrability,"I was outputting to .vcf.gz. . I reran the command to output to just. vcf and it runs without error:; ```; /gatk-launch FilterByOrientationBias --artifactModes 'G/T' -V /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz -P ~/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics -O test_filterbyorientationbias.vcf; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk FilterByOrientationBias --artifactModes G/T -V /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz -P /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics -O test_filterbyorientationbias.vcf; 01:16:16.916 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.4.3.jar!/com/intel/gkl/native/libgkl_compression.dylib; [June 6, 2017 1:16:16 AM EDT] FilterByOrientationBias --output test_filterbyorientationbias.vcf --preAdapterDetailFile /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics --artifactModes G/T --variant /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891:421,wrap,wrapper,421,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891,2,['wrap'],['wrapper']
Integrability,I wasn't able to reproduce this exact issue. However at least I can make the error message a bit more user-friendly (submitting #2417 for review). Crucially this will now give the name of the file we're having issues with (thus removing the uncertainty about whether it's the data or the index file we cannot access).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2415#issuecomment-281515286:83,message,message,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2415#issuecomment-281515286,2,['message'],['message']
Integrability,I will approve after you take a look at the integration test I linked above.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7709#issuecomment-1062986841:44,integrat,integration,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7709#issuecomment-1062986841,1,['integrat'],['integration']
Integrability,"I will do a big PR with a commit for each of the issues that we found in the plugin, and including tests. Although the plugin interface is going to change in Barclay, I think that before that the PR should setup all the tests for the issues to ensura that the change does not broke anything. Any opinion on this, @cmnbroad, @droazen, @lbergelson?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2377#issuecomment-278248587:126,interface,interface,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2377#issuecomment-278248587,1,['interface'],['interface']
Integrability,"I will try that as well. I just finished building a PoN at 250bp bin size with 1k intervals per block. This produces ~10k models and the PostprocessGermlineCNVCalls WDL task gets us the following error from Cromwell:. > The task run request has exceeded the maximum PAPI request size.If you have a task with a very large number of inputs and / or outputs in your workflow you should try; > to reduce it. Depending on your case you could: 1) Zip your input files together and unzip them in the command. 2) Use a file of file names and localize the files yourself. Who knew? So, we are also going to have to modify PostprocessGermlineCNVCalls and the case mode calling task to accept a tar archive containing all the models. @samuelklee @mbabadi Let me know if you have any opinions on this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4397#issuecomment-392119427:404,Depend,Depending,404,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4397#issuecomment-392119427,1,['Depend'],['Depending']
Integrability,"I wonder if we could factor out a common base interface to cut down on code duplication, and ensure a more consistent API across `SimpleInterval` and `SVInterval`?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5154#issuecomment-418501188:46,interface,interface,46,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5154#issuecomment-418501188,1,['interface'],['interface']
Integrability,I would also really appreciate it if these log messages contained the locus/position that generated the warning.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5912#issuecomment-708684109:47,message,messages,47,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5912#issuecomment-708684109,1,['message'],['messages']
Integrability,"I would like to have this feature for a new project that will rely on the built-in walkers of GATK. The main problem that I am facing is while grabbing the info from the METAINF file. For fixing this, I have a proposal:. * Create a new interface with the single method to print the startup message; * Create a base-class with the current code in GATK, which can be extended to override some parts of the startup message, but not all.; * Make a non-final static field in `CommandLineProgram` , which is settable. This could be set in the `Main` for toolkits (similarly to how the config file is set). The default will be the GATK implementation. If you agree with the proposal, let me know to implement it and submit a PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-381504458:236,interface,interface,236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-381504458,3,"['interface', 'message']","['interface', 'message']"
Integrability,"I would suggest comparing the versions of the other dependencies that you have with the expected versions (which you can find [here](https://github.com/broadinstitute/gatk/blob/master/scripts/gatkcondaenv.yml.template)), especially keras, since I think the most likely issue is either a version mismatch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7250#issuecomment-951059146:52,depend,dependencies,52,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7250#issuecomment-951059146,1,['depend'],['dependencies']
Integrability,I would support pre-installing the R libraries into the base image. Installing R libraries is slow and tend to fail at random because CRAN isn't as reliable as our other dependencies. We just need keep the docker file for the base image around so we can rebuild it with new libraries if we need to.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2699#issuecomment-300576630:170,depend,dependencies,170,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2699#issuecomment-300576630,1,['depend'],['dependencies']
Integrability,"I'd rather keep the message more generic, and think of the check as simply defining what a valid `CopyRatio` object can be: an interval associated with a finite double value. One might imagine that someone would try to create such an object that does not originate from a BAM (perhaps for test data, or for imputing missing values in pre-existing data, etc.). This check says that they must create it with some finite value. A more appropriate place for the sort of message you suggest is in the relevant denoising method. In the edge case you encountered, you used a BAM that was almost completely uncovered in all bins at the specified resolution, resulting in a sample median of zero. Since one of the steps in standardization is dividing by the sample median, this results in a divide by zero. I've added the corresponding check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-365726746:20,message,message,20,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-365726746,4,['message'],['message']
Integrability,"I'd rather not change the default HC behavior, but this is pretty exciting because we can lay the argument about porting ReadBackedPhasing to rest. It would be good to do a comparison with RBP -- can you take a look at the RBP integration tests from GATK3 to see if there was a MNP test there?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4650#issuecomment-380816090:227,integrat,integration,227,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4650#issuecomment-380816090,1,['integrat'],['integration']
Integrability,"I'll try to see if I can create a test to verify index creation. It will probably involve manually integrating an hg38 header with a clone of one of the existing tests, though, since I need something that matches a real recal file.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2821#issuecomment-306814748:99,integrat,integrating,99,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2821#issuecomment-306814748,1,['integrat'],['integrating']
Integrability,I'm able to create a dummy test data that reproduces the same error messages.; On it to fix now.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4458#issuecomment-368541002:68,message,messages,68,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458#issuecomment-368541002,1,['message'],['messages']
Integrability,I'm actually a little surprised that it's not emitting a 1/* at the second location (despite that perhaps not being compatible with the spec; I agree with @bhandsaker 's view of what `*` should mean) given the changes I made in https://github.com/broadinstitute/gatk/pull/4963 to support spanning deletions. Those changes were not made with MNPs in mind but reading the code I'm surprised the `*` allele is not injected into the variant context. What version of HaplotypeCaller are you using @tfenne?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5523#issuecomment-447369490:411,inject,injected,411,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5523#issuecomment-447369490,1,['inject'],['injected']
Integrability,"I'm also seeing this more often during the Docker build, not sure if it is related:. ````; Step 5/27 : RUN /gatk/gradlew clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:942,protocol,protocol,942,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401,1,['protocol'],['protocol']
Integrability,I'm confused. Nowhere in the commit above did I disable physical phasing for non-ERC modes. The only line I touched was to change the error message to use the proper argument (GENOTYPE_GIVEN_ALLELES vs. Genotyping Giving Alleles). I have zero recollection of why physical phasing wouldn't be okay for standard HaplotypeCaller.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470950825:140,message,message,140,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470950825,1,['message'],['message']
Integrability,"I'm going to add to my previous comment, when I used -forceActive alone I picked up that het call I was missing BUT I lost another obvious het call that was getting called when I wasn't using -forceActive. If I use -forceActive and -dontTrimActiveRegions I can pick up both calls. It's still very troubling that these obvious calls are getting missed or not depending on these options...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-401453444:358,depend,depending,358,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-401453444,1,['depend'],['depending']
Integrability,I'm going to need the reads to debug this. @bhanugandham where's the latest article with the protocol for sharing data snippets?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6309#issuecomment-570218296:93,protocol,protocol,93,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6309#issuecomment-570218296,1,['protocol'],['protocol']
Integrability,"I'm not completely opposed to that way of dealing with this, but I'm not yet convinced either. . I'm not sure I see how having an extra argument is somehow shorter than having one special value that is included in the description of the original argument. As in:. --trimWhatever | -trimWvr -- bla bla bla; default w; min x max y; to disable trimming, use z. . As for the documentation auto-generator showing the two args together, that is dependent on setting up the arguments so that the code specifies they are related, and adding some logic to the auto-generation to pull related arguments together. (As a contributing developer to a documentation auto-generator --the GATKDocs-- I can tell you that is not necessarily trivial and adds even more moving parts.) This also generates additional complexity for third-party developers of wrappers (such as Galaxy). Finally, it can be a source of confusion for users who are trying to look up an argument called ""-dont-Trim-whatever"" since presumably it's only going to be listed under T (-Trim-whatever) and not under D in the alphabetical list. Or should it be listed twice? . A reference manual can be very ""nice"" and helpful, and it must be organized in the most intuitive way possible, especially since there is no way we can provide examples that cover every single use case under the sun (trust me, there's not).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/143#issuecomment-71122930:439,depend,dependent,439,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/143#issuecomment-71122930,2,"['depend', 'wrap']","['dependent', 'wrappers']"
Integrability,"I'm not crazy about the idea of specifying this in the example commands in general. It will depend a lot on what data and use case a user is going through at any given time. I would much prefer leaving specific recommendations to our pipeline scripts, where we can use whatever the prod pipeline uses, and say ""given this use case and example data, this is what works, ymmv"". So I would actually advocate for removing all -Xmx values in the tool docs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3137#issuecomment-319124674:92,depend,depend,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3137#issuecomment-319124674,1,['depend'],['depend']
Integrability,I'm not sure that we want to go down this path of having to actually change an interface every time we want to add a new top-level argument to the GATK. Let me discuss this PR with the other GATK devs to get their thoughts -- we'll get back to you on this soon.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-361625934:79,interface,interface,79,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3998#issuecomment-361625934,1,['interface'],['interface']
Integrability,"I'm not sure what proportion of users leverage the incremental import functionality...it wasn't available when GenomicsDBImport was first made available, but has been around for ~3 years now. As for workspaces with whole chromosomes -- there is no requirement or performance benefits to using whole chromosomes. As you say, subsetting a chromosome to smaller regions will work and make the import and query parallelizable. (if you remember where the advice about whole chromosomes came from, let us know. That might be something that needs to be updated/clarified). Many small contigs does add overhead to import though and, till recently, multiple contigs couldn't be imported together (i.e., each contig would have it's own folder under the GenomicsDB workspace - which gets inefficient with many small contigs). For WGS, probably the best way to create the GenomicsDBImport interval list is to split based on where there are consecutive N's in the reference genome (maybe using [Picard](https://broadinstitute.github.io/picard/command-line-overview.html#ScatterIntervalsByNs)) and/or regions that you are blacklisting. I think you suggested that some of the blacklisted regions were especially gnarly - maybe ploidy or high alternate allele count? - depending on the frequency of those, we may save a bit on space/memory requirements. That may address your concern about overlap between variants and import intervals. In general, any variant that starts in a specified import interval will show up in a query to that workspace. I'm not sure if the blacklist regions contain any variants that start within but extend beyond the blacklist -- those may not show up if the regions are split up in this way.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1212486548:1253,depend,depending,1253,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7968#issuecomment-1212486548,1,['depend'],['depending']
Integrability,"I'm not sure why the `gs` provider doesn't get installed (I think JP was seeing this before), but in any case there's a workaround in GATK for it: https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/utils/gcs/BucketUtils.java#L380-L390. However, since the Hadoop-BAM code is doing the path lookups, it can't call that code directly (the dependency is the wrong way round). It would be best if we could fix the underlying problem of course, so that it gets picked up properly - I wonder if this can be done by fixing the service provider so it survives relocation (see http://maven.apache.org/plugins/maven-shade-plugin/examples/resource-transformers.html#ServicesResourceTransformer). BTW I'm afraid I'm travelling this week, so I won't have time to look at it until next week either :(",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-263997131:380,depend,dependency,380,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2287#issuecomment-263997131,1,['depend'],['dependency']
Integrability,"I'm stepping into the 7 remaining test failures in the debugger, and I think they may just be fixed by overwriting the actual output of `GenotypeGVCFsIntegrationTest.testEntireVariant` onto the expected output for all the forced output test cases. However, this exercise has revealed some other changes:. `GenotypeGVCFsEngine.callRegion` contains the line `final VariantContext mergedVC = merger.merge(variantsToProcess, loc, ref.getBase(), !outputNonVariants, false)`. Since we want to remove the non-ref allele regardless, we should replace `!outputNonVariants` with `true`. It is important to do this here, because only then does `regenotypeVC` correctly restrict the `AD` to the emitted alleles. Also, doing this strips the variant QUAL from the output if it's monomorphic, which is desired (the `RGQ` field is in the output, so there remains a sense of the quality of the call). Once you do that, could you check whether `removeNonRefAndUnusedAltAlleles` is still necessary? In the integration tests, at least, I didn't see any alt alleles output except those called in a genotype.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-582242487:987,integrat,integration,987,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6406#issuecomment-582242487,1,['integrat'],['integration']
Integrability,"I'm surprised none of the variant calling integration tests change. @cmnbroad Would you expect this to change the behavior in any common use cases or is this more of a safety check?. It's admittedly also possible that the MT calling in the Mutect2 integration test does change slightly, but that's a very lenient concordance check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456900212:42,integrat,integration,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456900212,2,['integrat'],['integration']
Integrability,"I'm trying this, but it breaks the test, because the test relies on being; able to set a not-actually-buffering wrapper. As a compromise I'd adding; both methods, so the convenience method is available but the tests can also; do their thing. On Tue, Jan 24, 2017 at 8:48 AM, droazen <notifications@github.com> wrote:. > *@droazen* commented on this pull request.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/engine/GATKTool.java; > <https://github.com/broadinstitute/gatk/pull/2331>:; >; > > @@ -137,6 +157,16 @@ void initializeReference() {; > */; > void initializeReads() {; > if (! readArguments.getReadFiles().isEmpty()) {; > + // Prefetcher is useful for cloud files because of the latencies involved.; > + Function<SeekableByteChannel, SeekableByteChannel> wrapper = Function.identity();; > + Function<SeekableByteChannel, SeekableByteChannel> indexWrapper = Function.identity();; > +; > + if (cloudPrefetchBuffer > 0) {; > + wrapper = is -> GATKTool.addPrefetcher(cloudPrefetchBuffer, is);; > + }; > + if (cloudIndexPrefetchBuffer > 0) {; > + indexWrapper = is -> GATKTool.addPrefetcher(cloudIndexPrefetchBuffer, is);; > + }; >; > Yes, please move it all down into ReadsDataSource, and have the; > ReadsDataSource constructors take the buffer sizes as ints. There are; > clients in gatk-protected that use ReadsDataSource directly and would; > benefit, and in general we want to encapsulate these sort of low-level; > details in the data source classes as much as possible, and not bleed into; > the tool hierarchy.; >; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/2331>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AJ-XRcG2t6_144OndJhGaT5zdw9TSWRIks5rVit7gaJpZM4LdCht>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2331#issuecomment-274949252:112,wrap,wrapper,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2331#issuecomment-274949252,3,['wrap'],['wrapper']
Integrability,"I'm using GATK 4.1.8.1. And I found a similar error when trying to use GenotypeGVCFs to consolidate genotyping variants on chrX. It does not give any error message. It silently fails. BTW, I'm dealing with WES data. This is the code I used:; # For GenomicDBImport, I randomly select 50 samples from our history samples(using the same probe set) along with the current batch.; time ${gatk} --java-options ""-Xmx8g -Xms2g"" GenomicsDBImport \; --tmp-dir /paedyl01/disk1/yangyxt/test_tmp \; --genomicsdb-update-workspace-path ${vcf_dir}/genomicdbimport_chr${1} \; -R ${ref_gen}/ucsc.hg19.fasta \; --batch-size 0 \; --sample-name-map ${gvcf}/batch_cohort.sample_map \; --reader-threads 5; check_return_code. # For GenotypeGVCFs; time ${gatk} --java-options ""-Xmx8g -Xms2g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" GenotypeGVCFs \; -R ${ref_gen}/ucsc.hg19.fasta \; -V gendb://${vcf_dir}/genomicdbimport_chr${1} \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -L chr${1} \; -O ${bgvcf}/all_${seq_type}_samples_plus_${sample_batch}.chr${1}.HC.vcf. # These are log records:; 02:07:51.286 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 02:07:51.321 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl; Nov 06, 2020 2:07:56 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 02:07:56.529 INFO GenotypeGVCFs - ------------------------------------------------------------; 02:07:56.529 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 02:07:56.530 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 02:08:01.543 INFO GenotypeGVCFs - Executing as yangyxt@paedyl01 on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 02:08:01.543 INFO Ge",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059:156,message,message,156,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059,1,['message'],['message']
Integrability,"I've actually been lobbying to get rid of IntegrationTestSpec completely. Although it probably once added value, it has some [problems](https://github.com/broadinstitute/gatk/issues/1562) that limit its usefulness, and the remaining functionality (like expected exception checking) is available directly in the test framework. We have quite a few tests that don't use it at all, and it would be nice to only support one style, so I'd be inclined to discourage rather than encourage it, and focus on resolving the BaseTest issues.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-243120257:42,Integrat,IntegrationTestSpec,42,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2122#issuecomment-243120257,1,['Integrat'],['IntegrationTestSpec']
Integrability,"I've added a bunch of additional unit tests for the `StandardCallerArgumentCollection`, and beefed up the `HaplotypeCaller` integration tests as well (we now check for concordance against the GATK3 contamination-corrected calls, in addition to just asserting that the calls in GATK4 improve with contamination correction on).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4455#issuecomment-369983458:124,integrat,integration,124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4455#issuecomment-369983458,1,['integrat'],['integration']
Integrability,"I've added a new end-to-end test for SelectVariants that writes to GCS. Sadly, the IntegrationTestSpec class uses Files throughout, so it wasn't possible to do this simply without first completely refactoring IntegrationTestSpec (which should probably be its own pull request). . Doing this refactoring would have the advantage that changing existing end-to-end tests from local to GCS would be trivial. For now instead I went with an ad-hoc approach. It works, and the test passes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-455686612:83,Integrat,IntegrationTestSpec,83,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-455686612,2,['Integrat'],['IntegrationTestSpec']
Integrability,"I've added the CRAM tests. Remain to add an integration test that writes to GCS. @cmnbroad can you explain what you mean by ""Also note that you won't be able to use iterator comparison when comparing an Iterator with Iterator."" ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332368738:44,integrat,integration,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2558#issuecomment-332368738,1,['integrat'],['integration']
Integrability,"I've also changed the exception message to say ""Retry failed"" if it runs out of retries. If you see that you may have to increase the max reopen count - especially so if the program runs for a long time.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-303455493:32,message,message,32,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2685#issuecomment-303455493,1,['message'],['message']
Integrability,I've been taking a look this morning but am so far unable to reproduce the problem. I tried adding lines to the integration test file to mimic having a SNP at the last base of a spanning deletion as in the bug report:. ```; 20 10001300 . GGG G . . .; 20 10001302 . G C . . .; ```. But I'm not hitting this error. . @gmagoon any chance you could provide any more information that would help us reproduce this? The exact command line you're using might help. Do you still get the error if you run with an alleles file consisting _only_ of one of the pairs of given allele lines listed above?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5336#issuecomment-431865967:112,integrat,integration,112,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5336#issuecomment-431865967,1,['integrat'],['integration']
Integrability,I've created a new issue to make sure the error message for this is better in the future (#6712). This will be included in 4.1.9.0.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6708#issuecomment-661179629:48,message,message,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708#issuecomment-661179629,1,['message'],['message']
Integrability,"I've created a third party JAR that depends on GATK4 (4.beta.2). I believe I just hit a similar issue; however, what's odd is that it seems intermittent (though i have n=2 on this tool so far):. [October 2, 2017 6:10:01 AM PDT] com.github.discvrseq.walkers.BackportLiftedVcf done. Elapsed time: 6.27 minutes.; Runtime.totalMemory()=45813334016; Exception in thread ""main"" java.lang.NoClassDefFoundError: org/xerial/snappy/LoadSnappy; 	at htsjdk.samtools.util.SnappyLoader.<init>(SnappyLoader.java:86); 	at htsjdk.samtools.util.SnappyLoader.<init>(SnappyLoader.java:52); 	at htsjdk.samtools.util.TempStreamFactory.getSnappyLoader(TempStreamFactory.java:42); 	at htsjdk.samtools.util.TempStreamFactory.wrapTempOutputStream(TempStreamFactory.java:74); 	at htsjdk.samtools.util.SortingCollection.spillToDisk(SortingCollection.java:223); 	at htsjdk.samtools.util.SortingCollection.add(SortingCollection.java:166); 	at com.github.discvrseq.walkers.BackportLiftedVcf.apply(BackportLiftedVcf.java:156); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:110); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinsti",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-333579182:36,depend,depends,36,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-333579182,2,"['depend', 'wrap']","['depends', 'wrapTempOutputStream']"
Integrability,I've opened a ticket (https://github.com/samtools/htsjdk/issues/1651) to improve this error message and make it less confusing,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8192#issuecomment-1428469509:92,message,message,92,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8192#issuecomment-1428469509,1,['message'],['message']
Integrability,"I've pulled the problem VCF and a couple of successful ones locally and I can confirm that when running with 4 VCFs:. - VCFs that succeeded through JointGermlineCNVSegmentation in our pipeline succeeded for me locally; - The VCF that was flagged in the error message `Exception thrown at chrX:6383391 [VC SAMPLE_ID.segments.vcf.gz ...` completes just fine with other successful partners; - The VCF that was not identified in the error message, but was inferred to be a sex chromosome aneuploidy causes a failure with any combination of other VCFs; - If there are more than 2 VCFs run together, including the failing VCF/aneuploid sample, the error message indicates the problem originates in a non-aneuploid VCF, which misleading and makes this hard to treat. This behaviour was consistent in `4.5.0.0`. Command used in my toy dataset:. ```; gatk --java-options ""-Xms4000M -Xmx6000M"" JointGermlineCNVSegmentation -R /data/Homo_sapiens_assembly38_masked.fasta -O /data/out.vcf.gz -V /data/SAM1.segments.vcf.gz -V /data/SAM2.segments.vcf.gz -V /data/SAM3.segments.vcf.gz -V /data/SAM4.segments.vcf.gz --model-call-intervals /data/preprocessed.interval_list -ped /data/inferred_sex_pedigree.ped; ```. - In this configuration, `SAM4` is aneuploid, and `SAM1` is always the flagged VCF; - If I remove `SAM1` and re-run with 3 VCFs, `SAM3` is mentioned in the error message. It's not derived from alphabetical order, first argument specified with `-V`, or first in the PED file",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8834#issuecomment-2123897736:259,message,message,259,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8834#issuecomment-2123897736,4,['message'],['message']
Integrability,"I've rebased this branch and updated it to the latest `GnarlyGenotyper`. It looks like with the new version of google-cloud-java our dependency conflict with BigQuery has been resolved, so we can work towards getting this merged.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6011#issuecomment-531386196:133,depend,dependency,133,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6011#issuecomment-531386196,1,['depend'],['dependency']
Integrability,I've started to take a look at this. Thank you for running the Carrot Tests! I guess you might be right about the score jitter not mattering but man there are enough differences in the HC integration test that i'm a little worried....,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1581501197:188,integrat,integration,188,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8332#issuecomment-1581501197,1,['integrat'],['integration']
Integrability,"I've tried the latest GATK today. The error message changed. Please help. Thanks. Using GATK jar /omics/chatchawit/gatk2/gatk-package-4.0.4.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /omics/chatchawit/gatk2/gatk-package-4.0.4.0-local.jar Funcotator -R /omics/chatchawit/bundle/hsa38.fasta -V /omics/chatchawit/sm/out/sample21.vcf -O /omics/chatchawit/sm/anno/sample21.vcf --output-file-format VCF --data-sources-path /omics/chatchawit/bundle/dsrc/ --ref-version hg38; 10:24:13.971 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/omics/chatchawit/gatk2/gatk-package-4.0.4.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 10:24:14.182 INFO Funcotator - ------------------------------------------------------------; 10:24:14.183 INFO Funcotator - The Genome Analysis Toolkit (GATK) v4.0.4.0-0.0.2; 10:24:14.183 INFO Funcotator - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:24:14.183 INFO Funcotator - Executing as chatchawit@omics on Linux v3.13.0-133-generic amd64; 10:24:14.184 INFO Funcotator - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_161-b12; 10:24:14.184 INFO Funcotator - Start Date/Time: April 28, 2018 10:24:13 AM ICT; 10:24:14.184 INFO Funcotator - ------------------------------------------------------------; 10:24:14.184 INFO Funcotator - ------------------------------------------------------------; 10:24:14.185 INFO Funcotator - HTSJDK Version: 2.14.3; 10:24:14.185 INFO Funcotator - Picard Version: 2.18.2; 10:24:14.186 INFO Funcotator - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 10:24:14.186 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 10:24:14.186 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 10:24:14.186 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 10:24:14.186 INFO Fu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-385137363:44,message,message,44,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4712#issuecomment-385137363,1,['message'],['message']
Integrability,"If AVX is now required in the mainline tensorflow release as well, then I agree with @lucidtronix that we don't need to maintain a fallback environment -- provided that we're talking about **AVX1** here, and not AVX2/AVX512. We don't currently have the ability to request nodes on travis or Google cloud with AVX2/AVX512. I'd like to see this PR modified, however, to throw a `UserException` from the tool rather than in `customCommandLineValidation()`. The `UserException` should include a message with a pointer to versions of Tensorflow that work on non-AVX hardware.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-429956467:491,message,message,491,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-429956467,1,['message'],['message']
Integrability,"If I can suggest something here: . - instead of trying to move GATK from Java 8 to Java 11, probably better off to move to Java 17 or Java 18; - On Java 17/18, choose Amazon corretto - https://aws.amazon.com/corretto/ ; - Why Corretto - Corretto is a distribution of Open JDK with patches included by Amazon **_that are not yet integrated in the corresponding OpenJDK update projects_**. ; -- Quarterly updates/patches; - Github page: https://github.com/corretto; - easily ""dockerizable"": https://github.com/corretto/corretto-docker . **_Disclaimer_**: I am **_not_** from Amazon/AWS",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7842#issuecomment-1123002102:328,integrat,integrated,328,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7842#issuecomment-1123002102,1,['integrat'],['integrated']
Integrability,If IndexingVariantContextWriter is meant to create a index alongside /dev/null (... /dev/null.idx?) it isn't surprising that it does not work although the error message could be more informative. Is there a way to ask SelectVariants not to create an index and in that case you still have an exception?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3829#issuecomment-345038335:161,message,message,161,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3829#issuecomment-345038335,1,['message'],['message']
Integrability,"If a tool exists and is runnable, but is not documented, it should be accessible via tab-completion. Otherwise people can't depend on tab-completion to give a complete list of all tools that can be run.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3596#issuecomment-330936329:124,depend,depend,124,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3596#issuecomment-330936329,1,['depend'],['depend']
Integrability,"If the pattern is common, we could certainly explore adding some kind of ""argset"" support to Barclay. It would have the advantage of getting it integrated into the help and doc, though that could get complicated. Another possibility is a hybrid approach, where Barclay supports declarative argset definitions, but uses them for help interrogation only, with a command line argument that takes an argset name and generates output or an executable command line with recommended defaults for that argset:. `gatk GermlineCNVCaller --argsetfor WGS`. would generate:. `gatk GermlineCNVCaller --std-log-mean-bias 1.0 --interval-psi-scale 0.0001 ...`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385681493:144,integrat,integrated,144,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4719#issuecomment-385681493,1,['integrat'],['integrated']
Integrability,"If we let HTSJDK fail, we'll need to wrap the error in a `UserException`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6665#issuecomment-647690180:37,wrap,wrap,37,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6665#issuecomment-647690180,1,['wrap'],['wrap']
Integrability,"If we like this -- we also need to . - [x] build a jar; - [x] update the WDL to use this tool (and the Jar); - [ ] Put the BED files someplace public/widely accessible (likely just the 1kb version); - [x] Run an E2E on QuickStart, merge the VCFs and compare (and see no differences); - [x] If we want to validate evenness we need to run with a lot of shards and enough data that they are interesting. Maybe Stroke 10k; - [x] In parallel if we could turn some of the above script into integration tests that would be awesome",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7643#issuecomment-1017113500:484,integrat,integration,484,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7643#issuecomment-1017113500,1,['integrat'],['integration']
Integrability,"If you wrap the gatk python script with something like:. ```bash; #! /bin/bash -e; export LD_LIBRARY_PATH='<path to gcc-7.4.0-lib>/lib'${LD_LIBRARY_PATH:+':'}$LD_LIBRARY_PATH; exec ""gatk"" ""$@""; ```; It should work",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6012#issuecomment-541432820:7,wrap,wrap,7,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6012#issuecomment-541432820,1,['wrap'],['wrap']
Integrability,"If you're interested in BWASpark tool I might wait a bit. There are a lot of issues with it as it currently stands, it's one of the least tested tools we have. We have someone working on a different more efficient implementation of the bwa bindings that may eventually be integrated into mainline gatk, so we've sort of stopped most development on BWASparkEngine until we're clear on the direction that the new work is going to take.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-267119998:272,integrat,integrated,272,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2300#issuecomment-267119998,2,['integrat'],['integrated']
Integrability,"Improved error message sounds like a good solution, thank you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5064#issuecomment-439983479:15,message,message,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5064#issuecomment-439983479,1,['message'],['message']
Integrability,"In #2858 I give each `LocatableCollection` a method to create an `OverlapDetector` when necessary, which does the trick. The new pipeline has no dependence on either `ReadCountCollection` or `TargetCollection`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2859#issuecomment-335622099:145,depend,dependence,145,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2859#issuecomment-335622099,1,['depend'],['dependence']
Integrability,"In @meganshand's work on mitochondria we found that adjusting `-min-pruning` to be commensurate with the expected error rate per locus (eg minPruning = depth / 500 or something like that) rescued some false negatives and fixed the issue of interval- and padding-dependent calls. In her case, the sheer complexity of the assembly graph caused two undesirable things: 1) the true variant was missing from the best haplotypes and 2) the evidence for the true variant was diluted beyond recognition among many spurious haplotypes. This is not always the answer but for high depths or high error rates it is a strong possibility. I would be curious to see what turning on kmer error correction does, and in the long run I hope that #4868 will help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-399726606:262,depend,dependent,262,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3697#issuecomment-399726606,1,['depend'],['dependent']
Integrability,"In ADAM, we have well maintained Hadoop InputFormats for both normal and interleaved FASTQ. Additionally, we wrap these InputFormats in Spark-friendly APIs (exposed in Scala, Java, Python, and R) that add validation and standard transformations. GATK already has a dependency on ADAM, so...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4612#issuecomment-405114805:109,wrap,wrap,109,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4612#issuecomment-405114805,2,"['depend', 'wrap']","['dependency', 'wrap']"
Integrability,"In contrast, I think excluded chromosomes should be announced in INFO messages (perhaps WARN messages).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317820781:70,message,messages,70,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317820781,2,['message'],['messages']
Integrability,"In general our germline tools are designed for short variants. I don't think any of them will handle a millions long indel well or at all. The SV or CNV tools sound like a better fit although I'm not sure exactly if they cover your use case exactly. Typically we process short variants and long variants like this separately. . We should be detecting this variant up front on when loading into genomicsDB if it's going to be problematic to retrieve it, and we should be giving a better error message. I don't think we'll be able to handle it through GenotypeGVCFs in any helpful way though. (The best I can imagine it doing is passing it through ungenotyped.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7976#issuecomment-1376029770:492,message,message,492,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7976#issuecomment-1376029770,1,['message'],['message']
Integrability,"In preparing the VCF that generated the error, I had applied a hard filter on the excessHets variants before running the VQSR. If the excessHets are not filtered out, the VQSR runs fine. I traced the error to having AS_MQ in the model without the excessHet variants in the vcf. It would be nice to have a better error message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7380#issuecomment-905132194:318,message,message,318,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7380#issuecomment-905132194,1,['message'],['message']
Integrability,"In the WGS SV pipeline, for deletions and duplications that the pipeline believes to be biallelic we do the following:. - ALT: `<DEL>` or `<DUP>`; - SVTYPE: `DEL` or `DUP`; - GT: `0/0` or `0/1` or `1/1`. We currently report depth based copy number and quality for these variants in custom format fields `RD_CN` and `RD_GQ` if they are available; we could possibly move those values to the standard `CN` and `CNQ`, but there is some complexity in how to handle events detected by paired end and split reads without good read depth support; ie those under 1kb or so depending on our depth binning size and the coverage. Our depth genotyping module makes estimates of copy number for these sites but sometimes these can be very inaccurate so at the moment we prefer not to report total copy number in those fields. Probably what we _should_ do is fill in CN with 0, 1, or 2 based on the genotype we emitted and set CNQ to the value we computed for GQ. For multiallelic CNVs (i.e. sites where our model is not sure that the variant is bi-allelic) we write:. - ALT: `<CNV>`; - SVTYPE: `CNV`; - GT and GQ: `.`; - CN and CNQ: estimate of total (diploid/unphased) copy number and quality of the depth evidence. I think there are some tradeoffs in completely characterizing the evidence for and quality of each call and enabling easy searching across the whole VCF without having to parse and understand the entire record. Older versions of our pipeline used to put the diploid copy number of the event into the GT field, I think similarly to what's being described above. This is incorrect VCF -- GT values should be indices into the allele list for the variant, and should be a list of length equal to the ploidy. . My view is that if you can confidently infer the alleles present at the site in the sample set you should use a GT value of the form `0/1`, and if you don't know or aren't interested in trying to infer them you should use CN for total copy number and CNQ for the quality. CNF is also availabl",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6167#issuecomment-622053171:564,depend,depending,564,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6167#issuecomment-622053171,1,['depend'],['depending']
Integrability,"In this case, allele-specific annotations are outputted to GVCFs files by 'HaplotypeCaller -ERC GVCF -G AS_StandardAnnotation' command. Although some warning message of 'HaplotypeCaller -ERC GVCF -G AS_StandardAnnotation' command.; ```; WARN:StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; ```; This warning message does not happen in all of my cases, but the FORMAT/AD error happen in all of my cases.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4691#issuecomment-383763740:158,message,message,158,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4691#issuecomment-383763740,2,['message'],['message']
Integrability,Indeed adding ```--createOutputVariantIndex false``` there is no exception any longer.; Probrably the actual base cause is that the user does not have permission to create a file under /dev. Ideally instead of ``` Unable to close index for /dev/null``` the error message should be something like ``` Unable to create index file /dev/null.idx for the output; not enough permissions```. ... and make sure we fail early specially considering large VCF inputs.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3829#issuecomment-345040375:263,message,message,263,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3829#issuecomment-345040375,1,['message'],['message']
Integrability,"Indeed. The single gvcf also had the same problem. But I find the minimum depth across some positions was 1 or 2. I suppose that it can't be caused by the minimum depth.; your best!dengziguang; ; ; ; ; ***@***.***; ; ; . ; ---- Replied Message ----; ; ; ; ; ; From ; ; ; Laura ***@***.***>; ; ; ; ; ; Date ; ; ; 2/14/2023 03:54; ; ; ; ; To ; ; ; ; ; ***@***.***>; ; ; ; ; ; ; Cc ; ; ; ; ***@***.***>; ,; ; ; ***@***.***>; ; ; ; ; ; ; Subject ; ; ; Re: [broadinstitute/gatk] In the gvcf file, Does anyone know what this info means? (Issue #8081); ; ; ; ; ; This could be an artifact of the GVCF GQ bands, where we represent the DP for a reference block with the minimum depth across the positions included in the block. Do you see the same issue in the single-sample GVCFs?. —Reply to this email directly, view it on GitHub, or unsubscribe.You are receiving this because you were mentioned.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8081#issuecomment-1434148946:236,Message,Message,236,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8081#issuecomment-1434148946,2,['Message'],['Message']
Integrability,Integration run [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Integration/job_history/1b430f2b-4517-4d00-b8da-a8399da124b0),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8847#issuecomment-2140875298:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8847#issuecomment-2140875298,1,['Integrat'],['Integration']
Integrability,Integration run in progress with `GvsUnified` removed [here](https://job-manager.dsde-prod.broadinstitute.org/jobs/52748da4-46e6-4ae4-97a4-f91ca6517e34),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1636213505:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8404#issuecomment-1636213505,1,['Integrat'],['Integration']
Integrability,Integration test [here](https://app.terra.bio/#workspaces/gvs-dev/GVS%20Quickstart%20v3%20ggrant/job_history/80b6ed98-3b79-40f3-b55b-524b6f63f1e1). Failed one of the four (in Hail VDS tieout) - with a weird python3 error. 99.9994% sure not related to this PR.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8393#issuecomment-1613622838:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8393#issuecomment-1613622838,1,['Integrat'],['Integration']
Integrability,Integration tests look okay (there's a Python one that says to skip if it's in docker):; - org.broadinstitute.hellbender.utils.python.StreamingPythonExecutorIntegrationTest#testRequirePythonEnvironment; Unit tests:; - org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest#testLikelihoodsFromHaplotypes; - org.broadinstitute.hellbender.utils.io.IOUtilsUnitTest#testUnsuccessfulCanReadFileCheck (intended to be skipped); - fixed ; No variant calling tests ignored; No python tests ignored; No R tests ignored. The PairHMM one returns:; ```; 03:44:48.410 WARN NativeLibraryLoader - Unable to load libgkl_pairhmm_fpga.so from native/libgkl_pairhmm_fpga.so (/tmp/libgkl_pairhmm_fpga7585161099923450811.so: libgkl_pairhmm_shacc.so: cannot open shared object file: No such file or directory); ```; I don't know if that's expected or not -- maybe yes because it's looking for an FPGA?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5339#issuecomment-592086345:0,Integrat,Integration,0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5339#issuecomment-592086345,1,['Integrat'],['Integration']
Integrability,"Interesting, I guess that rules out a system dependent bug though which was what I was imagining.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6307#issuecomment-567145610:45,depend,dependent,45,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6307#issuecomment-567145610,1,['depend'],['dependent']
Integrability,"Interesting, it's definitely possible it's coming from one of the other buckets. I don't think we have fine grained control over WHICH bucket we attempt to read requester pays status from, so it's possible if it's enabled it's necessary to have that permission on every bucket. It's annoying that the error message doesn't say which reader is performing the access. Is there a longer stack trace available?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7492#issuecomment-934908586:307,message,message,307,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7492#issuecomment-934908586,1,['message'],['message']
Integrability,"Is it possible to add an integration test to this? Since the change did not fail any test, it seems that the integrationtest is missing",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8442#issuecomment-1803448694:25,integrat,integration,25,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8442#issuecomment-1803448694,2,['integrat'],"['integration', 'integrationtest']"
Integrability,Is there a successful integration run?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8915#issuecomment-2245307770:22,integrat,integration,22,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8915#issuecomment-2245307770,1,['integrat'],['integration']
Integrability,Is this actually fixed? Is there a version of GATK tools that incorporates this change so I can stop having the majority of my logs when run locally be filled up by this exact error message?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-472935667:182,message,message,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5447#issuecomment-472935667,1,['message'],['message']
Integrability,"Is this the only `CommandLineException` which should be an `UserException`? If not, how is going to work the development of new exceptions in Barclay. For instance, in https://github.com/broadinstitute/barclay/pull/11 there is a new exception that I made for values out of range, which extends `BadArgumentValue`. I agree that this errors should be decoupled from the ones that are not, but in this case I think that this is already implemented:. * `UserException` are handled in the `mainEntry()`, distinguishing errors that comes from the user's side regarding some specifications in the tools/framework.; * `CommandLineException` are handled in `parseArgs()`, distinguishing errors that comes from the command line from the user side while parsing. I expect that any command line error that is not `CommandLineParserInternalException ` or `ShouldNeverReachHereException` comes from the user's side. The contract in Barclay says that are `CommandLineException` are _""Exceptions thrown by CommandLineParser implementations.""_, and I think that if other parts of the code (outside arg parsing) is throwing this exception is a bug that does not come from the user. I guess that this is the problematic part.; * Any other `Exception` is thrown in `Main.handleNonUserException()`, which may be caused by non-user exceptions. I propose that `CommandLineException` is handled as currently to separate ""errors that are the user's fault regarding input and/or assumptions"" (`UserException`), ""errors that are the user's fault while providing parameters to the command line"" (`CommandLineException`) and ""errors that are not the user's fault"" (other `Exception`s). Actually, this is reasonable because the exit status is different for any kind of errors in the current `Main`. The only problem that I see with this approach is the silently failing of a ""bug"" in tools/engine code, which can be rethrow easily in `CommandLineProgram.instanceMain`` as following:. ```java; public Object instanceMain(final Strin",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268773161:906,contract,contract,906,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2324#issuecomment-268773161,1,['contract'],['contract']
Integrability,"It also fails in Mac OS X 10.11.6 x86_64. I'm trying to update my project to the latest version of GATK and this dependency throws the following error with some of my gradle tests and while running an uber-jar (using `--use_jdk_deflater false`):. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x000000011d925644, pid=7088, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression8215566221555962564.dylib+0x1644] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid7088.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. Find attached the log: [hs_err_pid7088.log.txt](https://github.com/broadinstitute/gatk/files/652421/hs_err_pid7088.log.txt). Should I open a different issue for this?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2302#issuecomment-267103689:113,depend,dependency,113,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2302#issuecomment-267103689,1,['depend'],['dependency']
Integrability,"It could be a synchronization issue. E.g. if thread A is asking for an alleleCount of 3 and and thread B an alleleCount of 4, then thread A could grow the array to 3 after thread B grows it to 4 (meaning the array is grown to size 4 but then set back to size 3), but before thread B reads position 4. This read will then fail. BTW I was seeing quite a lot of task failures, around 10%.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4661#issuecomment-408872373:14,synchroniz,synchronization,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4661#issuecomment-408872373,1,['synchroniz'],['synchronization']
Integrability,"It depends why it fails the filter. One reason is consecutive indel elements, but consider for example:. ref: ACGTTTA; read: AC TTTTA; cigar: 2M1D1I4M. Especially in long-read technologies with a lot of indel errors it seems draconian to throw out reads where this happens once. And okay, I understand that an aligner could represent this as a G->T subsitution, but what about the same thing but with 2D followed by 2I? That strikes me as a much better cigar than calling it a DNP. In general, a bad cigar should mean either that the aligner is bad (in which case why are we filtering isolated reads and not just rejecting the entire BAM?) or the read is malformed. But consecutive indels in a technology with many indel errors is neither of these!. Anyway, I don't think there's a problem with allowing these reads in the GATK, and if there is the refactoring in this #6403 should let us fix any problem easily enough.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6433#issuecomment-583415079:3,depend,depends,3,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6433#issuecomment-583415079,1,['depend'],['depends']
Integrability,"It is th esame computer, @gspowley. In the meanwhile I will change the dependency to 0.2.0 in my software, because it is mostly used in this kind of system. Also with `--use_jdk_deflater true` it will work. Thanks for the help!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2315#issuecomment-267134108:71,depend,dependency,71,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2315#issuecomment-267134108,1,['depend'],['dependency']
Integrability,"It is what I will do if this change is not accepted, @droazen. It was just a request to keep the arguments in my toolkit equals to Picard/GATK to easier integration of pipelines with my custom tools and yours. Anyway, thanks for taking in account my proposals. I added a new commit removing the change for the short arguments. Back to you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2384#issuecomment-278591310:153,integrat,integration,153,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2384#issuecomment-278591310,1,['integrat'],['integration']
Integrability,"It looks like the regression test failed due to some connectivity blip:. ```; pip._vendor.requests.packages.urllib3.exceptions.ProtocolError: (""Connection broken:; ConnectionResetError(104, 'Connection reset by peer')"", ; ConnectionResetError(104, 'Connection reset by peer')); ```; In the hope it's transient, could you please restart it?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5785#issuecomment-472529525:127,Protocol,ProtocolError,127,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5785#issuecomment-472529525,1,['Protocol'],['ProtocolError']
Integrability,"It looks like the tests are running very slowly because of a performance regression due to the changes in `IntegrationTestSpec.assertEqualTextFiles`. You can see this on tests that should be unaffected by the core changes in this PR, like the VQSR integration tests, which have no cloud/bucket dependency and usually take about [1 minute](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_24775.2/tests/test/classes/org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibratorIntegrationTest.html), but took [25 minutes](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_24563.2/tests/test/classes/org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibratorIntegrationTest.html) with this branch. The same thing happens when the VQSR tests are run locally with this branch; all the time is spent in `assertEqualTextFiles`. @jean-philippe-martin I don't want to push to this branch without your ok, but reverting the first few lines of `assertEqualTextFiles` seems to fix the problem locally. (Separately, I will do some profiling to figure out for posterity sake why that change had such a dramatic affect ).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-462772143:107,Integrat,IntegrationTestSpec,107,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5378#issuecomment-462772143,3,"['Integrat', 'depend', 'integrat']","['IntegrationTestSpec', 'dependency', 'integration']"
Integrability,"It looks like there have been some changes since I last looked at this, including one new tool, so I can make another pass on the java code. But I'd feel a lot better about taking this if there were at least one integration test for each of the tools (right now there are a couple of tests for the inference tool, and none for the other 3 tools). @lucidtronix is that possible to do that in the next day or so ? . As for type hinting,I'd love to see it in all of our Python code. I think it made the gcnv code much more readable (BTW, does anyone have mypy stubs for numpy, theano, tensorflow) ? We might want to run a type/checker linter as part of the build.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367435050:212,integrat,integration,212,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367435050,1,['integrat'],['integration']
Integrability,"It looks like they're using a strange hybrid of Picard and Barclay syntax. If they just use pure Barclay syntax with no ""="" (`--RUN_DATE 2011-04-30T01:00:00+0100`) when running the Picard tool from gatk, the error message should go away. The only part I don't understand is that they say the hybrid syntax works if they leave out `RUN_DATE`. I wouldn't expect that - I'll have to look into it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5189#issuecomment-421191038:214,message,message,214,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5189#issuecomment-421191038,1,['message'],['message']
Integrability,It looks like we need to update mockito. ; https://storage.googleapis.com/hellbender-test-logs/build_reports/master_27538.13/tests/test/index.html. ```. java.lang.IllegalArgumentException: Unknown Java version: 11; 	at net.bytebuddy.ClassFileVersion.ofJavaVersion(ClassFileVersion.java:135); 	at net.bytebuddy.ClassFileVersion$VersionLocator$ForJava9CapableVm.locate(ClassFileVersion.java:357); 	at net.bytebuddy.ClassFileVersion.ofThisVm(ClassFileVersion.java:147); 	at net.bytebuddy.dynamic.loading.ClassInjector$UsingReflection$Dispatcher$CreationAction.run(ClassInjector.java:301); 	at net.bytebuddy.dynamic.loading.ClassInjector$UsingReflection$Dispatcher$CreationAction.run(ClassInjector.java:290); 	at java.base/java.security.AccessController.doPrivileged(Native Method); 	at net.bytebuddy.dynamic.loading.ClassInjector$UsingReflection.<clinit>(ClassInjector.java:70); 	at net.bytebuddy.dynamic.loading.ClassLoadingStrategy$Default$InjectionDispatcher.load(ClassLoadingStrategy.java:184); 	at net.bytebuddy.dynamic.TypeResolutionStrategy$Passive.initialize(TypeResolutionStrategy.java:79); 	at net.bytebuddy.dynamic.DynamicType$Default$Unloaded.load(DynamicType.java:4456); 	at org.mockito.internal.creation.bytebuddy.SubclassBytecodeGenerator.mockClass(SubclassBytecodeGenerator.java:115); 	at org.mockito.internal.creation.bytebuddy.TypeCachingBytecodeGenerator$1.call(TypeCachingBytecodeGenerator.java:37); 	at org.mockito.internal.creation.bytebuddy.TypeCachingBytecodeGenerator$1.call(TypeCachingBytecodeGenerator.java:34); 	at net.bytebuddy.TypeCache.findOrInsert(TypeCache.java:138); 	at net.bytebuddy.TypeCache$WithInlineExpunction.findOrInsert(TypeCache.java:346); 	at net.bytebuddy.TypeCache.findOrInsert(TypeCache.java:161); 	at net.bytebuddy.TypeCache$WithInlineExpunction.findOrInsert(TypeCache.java:355); 	at org.mockito.internal.creation.bytebuddy.TypeCachingBytecodeGenerator.mockClass(TypeCachingBytecodeGenerator.java:32); 	at org.mockito.internal.creation.bytebuddy.SubclassB,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-532377836:939,Inject,InjectionDispatcher,939,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6119#issuecomment-532377836,1,['Inject'],['InjectionDispatcher']
Integrability,"It ought to be totally parallel to the current framework, but with an `AlleleLikelihoods<Fragment, Allele>` replacing `AlleleLikelihoods<GATKRead, Allelle>`. I don't see any other change to the interface. It would be nice to do this without duplicating the class hierarchy of `INFO` and `FORMAT` annotations, however.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6096#issuecomment-576826371:194,interface,interface,194,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6096#issuecomment-576826371,1,['interface'],['interface']
Integrability,"It seems that there are a lot of soft clips that aren't bacterial reads.; What's your mean insert size? I've seen lots of aberrant soft clips when; the insert size is small and Picard doesn't catch adapter sequences with; multiple mismatches. Does the Picard percent adapter in alignment summary; metrics seem high? I've also seen lots of soft clips when the chimera rate; is high, sometimes because of bad sample extraction. What's the percent; chimeras in your alignment summary metrics? 5% is bad and I've seen up to; 15%, but that was an FFPE tumor sample. On Mon, Mar 25, 2019 at 8:48 PM jjfarrell <notifications@github.com> wrote:. > When the --dontUseSoftCliiped flag is used, the GQ=0 is much lower- N=1355; > for '0/0' calls.; >; > zcat; > A-ADC-AD004288-BL-NCR-15AD82285.hg38.realign.bqsr.dontUseSoftclipped.g.vcf.gz; > |tr '\t' '\n'|grep '0/0'|tr ':' '\t'|cut -f2,3|awk '$2 == ""0"" {print; > $0}'|cut -f1|sort -n|uniq -c; > 1355 0; > 6 0,0,0; > 7 0,0,0,0; > 602 1; > 537 2; > 520 3; > 595 4; > 441 5; > 511 6; > 583 7; > 701 8; > 403 9; > 468 10; >; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5445#issuecomment-476431178>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdA_gZKYn3vuqNDvvDadvM9tgzQqGks5vaW5IgaJpZM4YxgEF>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5445#issuecomment-476654990:198,adapter,adapter,198,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5445#issuecomment-476654990,2,['adapter'],['adapter']
Integrability,"It turns out I was mistaken that setting the environment variables fixes the problem (stupid error on my part). It's possible the BaseTest message is unrelated. I haven't tested this branch out yet, but building from the commit immediately before the update works. I am going to try the next version to see if it helps. Edit: #3594 does not fix the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330896419:139,message,message,139,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330896419,1,['message'],['message']
Integrability,"It was a feature which we would have loved, but alas this isn't the case. We also relied on ```-ct``` to get percent of bases depending on their coverage (ex. 20x) which has now been dropped in GATK 4+ versions. We came across another tool called [mosdepth](https://github.com/brentp/mosdepth). When compared to DepthOfCoverage - ; - It uses multithreading (albeit only for deflation, so no performance gains when going beyond 4 threads).; - It gives coverage for exome within 5 minutes, and even faster when we don't need the per base coverage output.; - Per base coverage output can be skipped using ```-x``` the output of this matches closely to output from DepthOfCoverage. Do keep in mind, DepthOfCoverage also supports this skipping when using the parameter ```--omitDepthOutputAtEachBase``` which saves massively on I/O and cuts processing time from 50 minutes per sample to 40 minutes per sample. If you do decide to give it a try, we have some tips and suggestions - ; - The tool generates multiple output files. If looking for total coverage, check the last line of file ```output.mosdepth.summary.txt```; - If looking for percent of bases covered at target read depth, this information is present in file ```output.mosdepth.region.dist.txt```. If your target read depth is 20x, you can search this file with ```grep -P ""total\t20\t""``` and the third column should be the percentage (with only one decimal); - By using ```-d4``` switch, they claim the above percentage granularity increases to 4 decimal points.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7890#issuecomment-1153478071:126,depend,depending,126,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7890#issuecomment-1153478071,1,['depend'],['depending']
Integrability,"It's OK, I can still look at this. Sorry for the delay. I don't want @TedBrookings to be distracted from trying to wrap up his change set. If I understand correctly, you'd like to keep the lower threshold of 2 here and then apply the more strict threshold downstream, in `AssemblyContigAlignmentsConfigPicker`? In that case, why make it 2 and not 1, ie. not have a limit at all here?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4962#issuecomment-405610320:115,wrap,wrap,115,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4962#issuecomment-405610320,1,['wrap'],['wrap']
Integrability,"It's looking like we might have to fix the issues with NIO here after all @tomwhite @jean-philippe-martin, as @lbergelson has been unable to get this working reasonably with the GCS adapter (it runs, but veeeerrryyy slowly).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-271691417:182,adapter,adapter,182,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2306#issuecomment-271691417,1,['adapter'],['adapter']
Integrability,"It's not a technical problem but it's more than a question of style. It's a user experience problem. Happy to go into detail at some point (just not now). I hear you on the internal wiring rationale; but I think we should explore whether it's possible to fix that, potentially through changes to WDL itself. Clearly the language isn't allowing you to do what you need as an author and what I need as a user -- which I would characterize as ""conditional optionality"", ie things are made optional or not depending on a condition. Would be good to get redteam involved to see what they can suggest.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3657#issuecomment-334049665:502,depend,depending,502,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3657#issuecomment-334049665,2,['depend'],['depending']
Integrability,It's useful to put something like `fixes #5104` in the commit message. That way it automatically closes the issue and shows a link from the PR to the Issue.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4932#issuecomment-412920923:62,message,message,62,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4932#issuecomment-412920923,1,['message'],['message']
Integrability,"It's weird, usually java should output an error message if it runs out of memory. The exception would be when java is assigned so much memory that the SYSTEM kills it instead of java killing itself. ; You could try adding `dmesg | tail -100` to your wdl after m2 runs to see if there are any messages from the OOMkiller. . What's your total available memory on the machine and your -Xmx setting? You typically need to leave some memory room for the OS and other native sofware. (although by default our pipelines SHOULD have that configured correctly.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7494#issuecomment-939070414:48,message,message,48,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7494#issuecomment-939070414,2,['message'],"['message', 'messages']"
Integrability,"It's your call whether you want the test or not. Yeah, it would be good to put an advisory message if the number of intervals is more than 100. I uploaded a jar yesterday, but it's not showed up in Maven central",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-408165237:91,message,message,91,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-408165237,1,['message'],['message']
Integrability,"Its less of an issue than it was hen we had separate public/protected repos, but I'd still like to add the mechanism described above to notify us when dependency resolution changes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2592#issuecomment-308105454:151,depend,dependency,151,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2592#issuecomment-308105454,1,['depend'],['dependency']
Integrability,Its use in `ValidateBasicSomaticShortMutations` seems limited to the integration test. Can I rewrite the test to do without `AnnotatedInterval` and call it a day?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3884#issuecomment-526876913:69,integrat,integration,69,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3884#issuecomment-526876913,1,['integrat'],['integration']
Integrability,"I’d suggest starting with unpinning all of the “non-core” ML dependencies and seeing if that yields a workable environment. Then we can either try to resolve versions between the MacOS and Linux environments or accept differences in these dependencies. We might want to change tack if the core dependencies can’t be lined up, though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6813#issuecomment-730436926:61,depend,dependencies,61,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6813#issuecomment-730436926,3,['depend'],['dependencies']
Integrability,"I’ll take a look at the somatic tests. They should be OK, probably just something related to kebab case changes. EDIT: Or hmm, maybe they weren't passing before. Something to do with annotated-interval validation, I think. I think the WDL tests should be using the Docker, which has g++. Travis machines might be slower?. Integration tests will need to be in the python test group. Take a look at the python tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-350160424:322,Integrat,Integration,322,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3925#issuecomment-350160424,1,['Integrat'],['Integration']
Integrability,"Just a quick test of `--splitMultiallelics` looks good:; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; 17:52:19.004 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:52:19 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:52:19.130 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:52:19.131 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:52:19.131 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:52:19.131 INFO LeftAlignAndTrimVariants ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971:339,wrap,wrapper,339,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971,1,['wrap'],['wrapper']
Integrability,"Just another message reiterating that a VCF should follow the specs of a VCF. Default for missing data should be ./. . Having the default as 0/0, apart from being nonsensical, is likely to generate a lot of downstream errors in many papers.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-1932330312:13,message,message,13,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8328#issuecomment-1932330312,1,['message'],['message']
Integrability,"Just came across this again -- the gatk wrapper is in the path now and available from wherever, so I think this ticket is satisfied. Feel free to reopen if I'm wrong.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3899#issuecomment-449661421:40,wrap,wrapper,40,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3899#issuecomment-449661421,1,['wrap'],['wrapper']
Integrability,"Just got an update by email from the GP team indicating that their perspective is that these are valid index files. It seems that this issue lives in a liminal space where Mutect2 is crashing due to reasons that are not a GATK bug, but also not due to any formal problem in the GP pipeline either. Still, I'm running Broad-built software on recently sequenced Broad-provided genetic data, so it seems a little odd that these aren't playing well together. Trying to think of a solution so that other people in this situation aren't left confused by the error message, is this error specific enough that an additional statement could be added to the error message, e.g., ""This error may be triggered by CRAM indexes produced by older implementations of `htsjdk`, in which case reindexing with an updated `htsjdk` may resolve this problem.""? Or is this error more general, making such a suggestion inappropriate?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/7755#issuecomment-1099607060:558,message,message,558,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7755#issuecomment-1099607060,2,['message'],['message']
Integrability,"Just noting, as we discussed, this could allow us to condense coverage files, etc. We'd want to make sure that bins are always validated and that we don't introduce use cases that corrupt the bins (e.g., filtering bins). Also not really sure how hard indexing would be. Should be in conjunction with #4717. We are probably OK shuffling around relatively large interval and count files for the time being, but we can adjust priority when it makes sense (also depending on where htsjdk development is on these issues).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5702#issuecomment-466203330:458,depend,depending,458,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5702#issuecomment-466203330,1,['depend'],['depending']
Integrability,"Just saw one of these in the log that I'm going to go investigate. The new error message is very helpful, thanks @kgururaj !",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3745#issuecomment-364159215:81,message,message,81,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3745#issuecomment-364159215,1,['message'],['message']
Integrability,"Just wanted to add - I just tried installing the GATK docker as described here: https://gatk.broadinstitute.org/hc/en-us/articles/360035889991--How-to-Run-GATK-in-a-Docker-container. As I'd think that all software dependencies and whatnot should be fine. However, I still get the same error message:. /gatk/./gatk --java-options ""-Xmx25g"" SplitNCigarReads \; > -R Homo_sapiens.GRCh38.dna.primary_assembly.fa -I subset_TINY_rehead.bam \; > --tmp-dir /gatk/my_data/temp -O thing.bam; Using GATK jar /gatk/gatk-package-4.1.3.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx25g -jar /gatk/gatk-package-4.1.3.0-local.jar SplitNCigarReads -R Homo_sapiens.GRCh38.dna.primary_assembly.fa -I subset_TINY_rehead.bam --tmp-dir /gatk/my_data/temp -O thing.bam. 21:12:14.158 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.3.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Mar 02, 2023 9:12:16 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 21:12:16.383 INFO SplitNCigarReads - ------------------------------------------------------------; 21:12:16.384 INFO SplitNCigarReads - The Genome Analysis Toolkit (GATK) v4.1.3.0; 21:12:16.384 INFO SplitNCigarReads - For support and documentation go to https://software.broadinstitute.org/gatk/; 21:12:16.384 INFO SplitNCigarReads - Executing as root@9d399eec0e24 on Linux v5.19.0-32-generic amd64; 21:12:16.384 INFO SplitNCigarReads - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_191-8u191-b12-0ubuntu0.16.04.1-b12; 21:12:16.384 INFO SplitNCigarReads - Start Date/Time: March 2, 2023 9:12:14 PM UTC; 21:12:16.385 INFO SplitNCigarReads - ------------------------------------------------------------; 21:12:16.385 INFO SplitNCigarReads - ----------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452564826:214,depend,dependencies,214,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452564826,2,"['depend', 'message']","['dependencies', 'message']"
Integrability,L3NlZ21lbnRhdGlvbi9NdWx0aXNhbXBsZU11bHRpZGltZW5zaW9uYWxLZXJuZWxTZWdtZW50ZXIuamF2YQ==) | `89.375% <0.000%> (-4.375%)` | :arrow_down: |; | [...lkers/vqsr/VariantRecalibratorIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7918/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvVmFyaWFudFJlY2FsaWJyYXRvckludGVncmF0aW9uVGVzdC5qYXZh) | `98.315% <0.000%> (-0.481%)` | :arrow_down: |; | [...s/copynumber/models/AlleleFractionLikelihoods.java](https://codecov.io/gh/broadinstitute/gatk/pull/7918/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL21vZGVscy9BbGxlbGVGcmFjdGlvbkxpa2VsaWhvb2RzLmphdmE=) | `100.000% <0.000%> (ø)` | |; | [...s/solver/SynchronizedUnivariateSolverUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7918/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zb2x2ZXIvU3luY2hyb25pemVkVW5pdmFyaWF0ZVNvbHZlclVuaXRUZXN0LmphdmE=) | | |; | [...bender/utils/solver/RobustBrentSolverUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/7918/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zb2x2ZXIvUm9idXN0QnJlbnRTb2x2ZXJVbml0VGVzdC5qYXZh) | | |; | [...ute/hellbender/utils/solver/RobustBrentSolver.java](https://codecov.io/gh/broadinstitute/gatk/pull/7918/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=broadinstitute#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0a,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7918#issuecomment-1168977988:3051,Synchroniz,SynchronizedUnivariateSolverUnitTest,3051,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7918#issuecomment-1168977988,1,['Synchroniz'],['SynchronizedUnivariateSolverUnitTest']
Integrability,Latest greatest integration success https://job-manager.dsde-prod.broadinstitute.org/jobs/4ccc1f23-fcf4-4549-8046-a52364ec80c3,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/8533#issuecomment-1740967533:16,integrat,integration,16,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/8533#issuecomment-1740967533,1,['integrat'],['integration']
Integrability,Let's be honest -- this is never going to happen. The goal is to move towards non-exact-match integration tests anyway.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3407#issuecomment-580901710:94,integrat,integration,94,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3407#issuecomment-580901710,1,['integrat'],['integration']
Integrability,"Let's take the SB field as an example - the header says it's a fixed length field of 4 integers. What should happen if one of the data lines only contains 2 integers?. Similarly, let's say the AD field (length R) in a specific line contains fewer elements than the total number of alleles (alt+1). What should happen? . This is irrespective of the internals of TileDB/GenomicsDB - should I report an error (exception) and exit? Print warning message, (pad if needed) and continue? Both those options are possible, it's a question of what is preferable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5113#issuecomment-413299560:442,message,message,442,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5113#issuecomment-413299560,1,['message'],['message']
Integrability,"Like I said, I don't know enough to say if this approach is feasible, but sometimes it's possible to test an algorithm with a problem-generating function. This works well when it's easy to generate self-consistent solutions and test data consistent with a given solution. I was able to do this for some of the interval overlap functions on the python side of my code. Other methods were too complicated (for me to figure out anyway). Let's say you have an algorithm function f_algo that you want to test. You design a function test_data_factory that takes as input either a known solution, or a set of parameters from which it can easily generate a known solution (by a route that is logically distinct from the way f_algo works). Then f_tester generates and returns test_data. The flow looks like; ```; // get either random test solutions or some distinct set that tests particular edge cases; test_params = get_test_params();; test_solution = easy_solution_from_params(test_params);. test_data = test_data_factory(test_params, test_solution);; assert f_algo(test_data) == test_solution;; ```; In some sense you've already done that, but you've personally stepped in as test_data_factory(), and I'm wondering if it would be possible to automate that to get rid of all those numbers in the test code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4677#issuecomment-384785429:670,rout,route,670,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4677#issuecomment-384785429,1,['rout'],['route']
Integrability,"Likewise, some PyMC3 developments to be aware of:. http://twiecki.github.io/blog/2017/07/05/new-in-pymc3-31/. SVGD may be a good option for the TH model, which exhibits highly multimodal posteriors. It would be ideal if our Stan interface allows us to implement it. In general, it appears that PyMC3 is more feature rich than Stan at the moment. GPU support in particular is much farther along.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2984#issuecomment-313429834:229,interface,interface,229,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2984#issuecomment-313429834,1,['interface'],['interface']
Integrability,"Looking at the existing code in Hadoop_BAM it makes the assumption that coordinates are always of the form ```chr:start-stop``` never things like ```chr```, ```chr:pos```, ```char:star+```... I've just generalized a bit more so that it can handle ':' and '-' inside the ```chr``` in a PR. I guess is not ideal but In any case this addresses the current fire and dependants have a clear work around which is to provide their intervals in the expected ```chr:start-stop``` format.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3360#issuecomment-331202249:362,depend,dependants,362,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3360#issuecomment-331202249,2,['depend'],['dependants']
Integrability,"Looking at the htsjdk code responsible for the original throw (as far as I can see in the stack enclosed in the description) there is a few ""smells"" in the way synchronized is used or not use ReferenceSource.java. It is likely to be the reason behind the error considering that is failing in multi-thread. . Probably adding synchronized to getReferenceBasesByRegion would fix that. Is a htsjdk issue and not a GATK one. Do you want to add a workaround in GATK or press for a fix and update of the htsjdk dependency. @droazen?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8139#issuecomment-1376298392:160,synchroniz,synchronized,160,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8139#issuecomment-1376298392,3,"['depend', 'synchroniz']","['dependency', 'synchronized']"
Integrability,"Looking at the stack trace, the error takes place in a low-level BAM input reading component in a dependency library.... It seems that is trying to read as a number portions of the contig name for a read record in the input... which makes very little sense.... . My guess is that either it is a bug entirely contained in that library (is the name seqdoop?), say it does not tolerate those contig names, or that the user managed to input a bam file that isn't formatted correctly on those records.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317817540:98,depend,dependency,98,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317817540,1,['depend'],['dependency']
Integrability,"Looks like all packages *except* ggplot2 were successfully installed. The following lines in the R script are responsible for installing 3 of the packages:. ```; dependencies = c(""ggplot2"",""gplots"",""gsalib""); repos <- c(""http://cran.cnr.Berkeley.edu"",; ""https://cran.mtu.edu"",; ""http://lib.stat.cmu.edu/R/CRAN/""); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- 1; while(length(missing)!=0 & try <= length(repos)) {; install.packages(dependencies[missing], repos = repos[try], clean = TRUE); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- try + 1; }; ```. I guess this is supposed to ensure that the installs don't fail due to intermittent connection errors, etc., but each repo is only hit once and it's possible for the loop to exit with dependencies still missing. Could this have happened when the current base image was built and pushed? @jamesemery did you push this image?. Also, I learned that *reshape2* (as opposed to reshape) is actually a dependency of ggplot2 that is automatically installed along with ggplot2. So the original removal of reshape from the `install.packages` list was fine. However, the import statement that is removed in this PR fails whether or not ggplot2 successfully installs, and is extraneous in any case. This is all consistent with the fact that the users from the forum post only get an error message about reshape and not ggplot2. Note that they are using broadinstitute/gatk:4.0.4.0, in which ggplot2 is successfully installed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406028261:162,depend,dependencies,162,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5026#issuecomment-406028261,14,"['depend', 'message']","['dependencies', 'dependency', 'message']"
Integrability,Looks like the integration tests failed with an unrelated error -- I'll try re-running them.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7393#issuecomment-953190949:15,integrat,integration,15,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7393#issuecomment-953190949,1,['integrat'],['integration']
Integrability,"Looks like this failed on travis. I think given that given the lateness of the hour (release wise), we might want to take the original change that removes the libgcc-ng dependency, since that passed on travis, and rely on the simple workarounds for osx, which we'll have to convey out-of-band. Anything that requires changing the docker image seems risky at this point, not to mention that the image is already at 5.2 gig, which is way over our desired target. @samuelklee Any thoughts on this ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356131086:169,depend,dependency,169,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356131086,2,['depend'],['dependency']
Integrability,"Looks like this is my fault... I didn't realize BWA produces SAM output and the non-spark tool was correcting my mistake automatically (by checking for a magic number). Can we make the error message more informative like: ""BAM file must start with BGZF magic number""? . It would be great to detect whether it's SAM or BAM by checking the file contents, as in non-spark tools that use htsjdk, rather than the extension. Is this easily done?. @lbergelson To clarify I was using the regular BWA binaries not the GATK BWA tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/3488#issuecomment-324959378:191,message,message,191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3488#issuecomment-324959378,1,['message'],['message']
Integrability,"Louis is right. At the time I think I only had 3.0.0-beta-2 as the other option and that made Hadoop break, so I had to go with 3.0.0-beta-1. There may now be a more recent version of Hadoop we can switch to, perhaps, that depends on a more recent version of protobuf ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/2437#issuecomment-284513035:223,depend,depends,223,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/2437#issuecomment-284513035,1,['depend'],['depends']
Integrability,"M - Total compute time in PairHMM computeLogLikelihoods() : 2290.3264339380003; 12:16:16.286 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 4541.79 sec; 12:16:16.289 INFO Mutect2 - Shutting down engine; [April 20, 2020 12:16:16 PM UTC] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 285.86 minutes.; Runtime.totalMemory()=8561098752; java.lang.IndexOutOfBoundsException: Index: 0, Size: 0; 	at java.util.ArrayList.rangeCheck(ArrayList.java:657); 	at java.util.ArrayList.get(ArrayList.java:433); 	at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.lambda$getGermlineAltAlleleFrequencies$26(SomaticGenotypingEngine.java:339); 	at java.util.stream.ReferencePipeline$6$1.accept(ReferencePipeline.java:244); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:546); 	at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); 	at java.util.stream.DoublePipeline.toArray(DoublePipeline.java:508); 	at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.getGermlineAltAlleleFrequencies(SomaticGenotypingEngine.java:341); 	at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.getNegativeLogPopulationAFAnnotation(SomaticGenotypingEngine.java:324); 	at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:146); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:251); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:320); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:308); 	at org.broad",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4578#issuecomment-616557568:1375,wrap,wrapAndCopyInto,1375,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4578#issuecomment-616557568,1,['wrap'],['wrapAndCopyInto']
Integrability,"MFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:36); > at; > htsjdk.samtools.AsyncSAMFileWriter.synchronouslyWrite(AsyncSAMFileWriter.java:16); > at; > htsjdk.samtools.util.AbstractAsyncWriter$WriterRunnable.run(AbstractAsyncWriter.java:123); > at java.lang.Thread.run(Thread.java:750); > Suppressed: htsjdk.samtools.util.RuntimeIOException: Attempt to add record; > to closed writer.; > at; > htsjdk.samtools.util.AbstractAsyncWriter.write(AbstractAsyncWriter.java:57); > at; > htsjdk.samtools.AsyncSAMFileWriter.addAlignment(AsyncSAMFileWriter.java:58); > at; > org.broadinstitute.hellbender.utils.read.SAMFileGATKReadWriter.addRead(SAMFileGATKReadWriter.java:21); > at; > org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager.writeReads(OverhangFixingManager.java:358); > at; > org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager.flush(OverhangFixingManager.java:338); > at; > org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.closeTool(SplitNCigarReads.java:192); > at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1095); > at; > org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:149); > at; > org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:198); > at; > org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:217); > at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); > at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); > at org.broadinstitute.hellbender.Main.main(Main.java:289); >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452525485>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ABD3RLHBTGYTW4GAZPUHFUTW2EB4PANCNFSM6AAAAAAVNNK24I>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452528344:9120,Message,Message,9120,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8232#issuecomment-1452528344,1,['Message'],['Message']
Integrability,MHeaderFrom(SAMHeaderReader.java:51); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSource.getHeader(ReadsSparkSource.java:235); 	... 15 more; Caused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): File does not exist: /home/test/WGS_pipeline/TEST/output/spark_412.bowtie2.bam; 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:72); 	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62); 	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:152); 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1819); 	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:692); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381); 	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447); 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850); 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793); 	at java.security.AccessController.doPrivileged(Native Method); 	at javax.security.auth.Subject.doAs(Subject.java:422); 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840); 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489). 	at org.apache.hadoop.ipc.Client.call(Client.java:1475); 	at org.apache.hadoop.ipc.Client.call(Client.java:1412); 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229); 	at com.sun.proxy.$Proxy10.getBlockLocations(Unknown Source); 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProt,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294:9266,protocol,protocol,9266,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4675#issuecomment-427537294,1,['protocol'],['protocol']
Integrability,MM - Time spent in setup for JNI call : 0.010346494000000001; 15:48:19.342 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 6.453042841; 15:48:19.347 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 10.39 sec; 15:48:19.348 INFO Mutect2 - Shutting down engine; [28 novembre 2019 15:48:19 CET] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.72 minutes.; Runtime.totalMemory()=3822583808; java.lang.IllegalArgumentException: Cannot construct fragment from more than two reads; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:725); 	at org.broadinstitute.hellbender.utils.read.Fragment.create(Fragment.java:36); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.utils.genotyper.AlleleLikelihoods.groupEvidence(AlleleLikelihoods.java:595); 	at org.broadinstitute.hellbender.tools.walkers.mutect.SomaticGenotypingEngine.callMutations(SomaticGenotypingEngine.java:93); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:251); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:320); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:308); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:281); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstit,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6271#issuecomment-559553558:4216,wrap,wrapAndCopyInto,4216,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6271#issuecomment-559553558,1,['wrap'],['wrapAndCopyInto']
Integrability,Marking `AuthService` as `optional` in gcloud-nio's pom fixes it:. ```; <dependency>; <groupId>com.google.auto.service</groupId>; <artifactId>auto-service</artifactId>; <version>1.0-rc3</version>; <optional>true</optional>; <scope>provided</scope> <!-- to leave out of the all-deps jar -->; </dependency>; ```. $ ./gradlew sparkJar; BUILD SUCCESSFUL. $ ./gatk-launch ExampleNioCountReads (...); (starts without error),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/3241#issuecomment-314265654:73,depend,dependency,73,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3241#issuecomment-314265654,2,['depend'],['dependency']
Integrability,"MergeBamAlignment is run on each readgroup seperately, currently MarkDuplicates is used to aggregate all the readgroups. I tried finding a nice graph type thing showing the dependencies of the workflow but couldn't find anything :(. But here is where MBA is run on each readgroup (the output of BWA gets streamed into MBA) - https://github.com/gatk-workflows/five-dollar-genome-analysis-pipeline/blob/master/tasks_pipelines/unmapped_bam_to_aligned_bam.wdl#L113. and here is markduplicates taking in each aligned MBA'd readgroup bam as input ( this is outside the per readgroup scatter) - https://github.com/gatk-workflows/five-dollar-genome-analysis-pipeline/blob/master/tasks_pipelines/unmapped_bam_to_aligned_bam.wdl#L157",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5398#issuecomment-438050467:173,depend,dependencies,173,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5398#issuecomment-438050467,1,['depend'],['dependencies']
Integrability,Merging now. I added an issue to track adding in more integration tests: #7523,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/7513#issuecomment-951250845:54,integrat,integration,54,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7513#issuecomment-951250845,1,['integrat'],['integration']
Integrability,"Merging this now to have usable VCF NIO support in master -- continuous tests to prove that the wrapper is applied will be added in a separate PR, but my ad-hoc tests on the latest version of this branch suggest it's working fine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/2393#issuecomment-277697090:96,wrap,wrapper,96,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/2393#issuecomment-277697090,2,['wrap'],['wrapper']
Integrability,"Most of our integration tests use the non-UCSC convention. I would be shocked if that were the issue. If anyone reading this has the issue, feel free to re-open or post on the GATK forum.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4939#issuecomment-583804417:12,integrat,integration,12,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4939#issuecomment-583804417,1,['integrat'],['integration']
Integrability,"Most of these dependency changes are reflected in https://github.com/broadinstitute/gatk/pull/6759. We should let that PR go in first, then rebase this one.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/6736#issuecomment-686622834:14,depend,dependency,14,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6736#issuecomment-686622834,1,['depend'],['dependency']
Integrability,"Much appreciated! I had pulled from the broad master before your message came in & done as you suggest with our changes, which are now confined to CNNScoreVariants. I think I may have managed it... if not I'll go back to step 1 and give it one more try.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-437417489:65,message,message,65,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5291#issuecomment-437417489,1,['message'],['message']
Integrability,"Multiple causes can cause closed connections when reading from GCS, almost all of which are outside of our control. This will never be ""completely fixed"" in the sense that even if the code is perfect it's completely possible to send too many requests to GCS, and it'll respond by closing connections. The main factors that I know of are:. - number of concurrent accesses to the GCS bucket in question; - number of concurrent accesses to the GCP project in question; - storage class of the GCS bucket in question (the more expensive ones have more replicas, thus can handle a higher load). If you're running into those difficulties I would suggest trying to reduce the load (reduce the number of concurrent workers or threads) and making sure it's not a single-region storage bucket. If that fails, perhaps try using a different bucket that no one else is also using (to reduce other sources of load). If I understand correctly that you didn't change the version you're using but are suddenly seeing more issues than before, then perhaps the cause is a server-side change from GCS (outside of our control), a change in configuration (are you reading from a bucket of a different class from before), or perhaps just an increase of other activity on the same bucket/project. The current code is very persistent in its retries: as you can see from the messages it spent a whole half hour waiting. If it's an overload situation then you may get better performance by reducing the worker count (as they will have to retry less).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716:1348,message,messages,1348,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716,1,['message'],['messages']
Integrability,"My $0.02:. 1. In general it's ok with me to not provide a template for WDLs in the GATK repo as long as you guys help us (ie @bshifaw) produce appropriate templates to include in the gatk-workflows repo and in FireCloud. . 2. Re: Picard tools, going forward they should be invoked from the GATK jar by default. Among other benefits, that will reduce support entropy wrt possible combination of versions of tools people might be using. 3. I like the idea of focusing on the auto-generated wrappers for improvements like the string variable for adding arbitrary extra args.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358488159:488,wrap,wrappers,488,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358488159,1,['wrap'],['wrappers']
Integrability,"My knowledge about .so files, linkers and architectures is very limited but to me it sounds like the GKL library is part of the jar and GATK tries to load it from there. And reading [this](https://github.com/broadinstitute/gatk/issues/2302) thread it sounds like the GKL library of GATK should work on ppc. Because of the ""no such file or directory"" messages (in the first warnings) I have also tried to point the `--tmp-dir` parameter of HaplotypeCaller to my home directory to make sure that it's not just a permission problem.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/6794#issuecomment-687564287:350,message,messages,350,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794#issuecomment-687564287,1,['message'],['messages']
Integrability,"Need some guidance here. The CompareSAMs tool was not propagating the validation stringency. I have a fix for that, but that alone doesn't fix the compareBAMFiles test in BaseRecalibrationIntegrationTest.java, since that uses SamAssertionUtils.assertSamsEqual, which also doesn't propagate (or accept) a validation stringency. Changing SamAssertionUtils to use either SILENT or LENIENT does fix the integration test, and all the other tests pass, but it seems like a relaxing of the stringency, and I'm not sure it should be necessary to the BQSR test. If relaxing the stringency for BQSR test _IS_ the right path, one possibility is to add a new method to SamAssertionUtils that accepts a validation stringency argument.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/419#issuecomment-109796266:399,integrat,integration,399,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/419#issuecomment-109796266,1,['integrat'],['integration']
Integrability,"Needed two commits because I forgot to check the integration test the first go-round and I had changed parameter args. Sorry!; Github is complaining that there are conflicts, but since local git is fine, I'm assuming that just means I need to rebase before any merge and I should ignore that for now?. Back to you @cwhelan @davidbenjamin",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-396709375:49,integrat,integration,49,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4769#issuecomment-396709375,1,['integrat'],['integration']
Integrability,New jar without spurious debug messages,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-408189092:31,message,messages,31,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4997#issuecomment-408189092,1,['message'],['messages']
Integrability,"Nice that HTSJDK is moving forward to version 3. The points that I would like to address are similar to yours, with some inclussions. * Regarding NIO support, I would go to remove completely `File` support. If API users need to use the `File` abstraction, they should convert to a `java.nio.Path` using the `toPath` method.; * In addition, I would like that HTTP/S and FTP is handled also with NIO. For HTTP/S, I am working in a simple `FileSystemProvider` that should be good enough for using in combination with HTSJDK ([jsr203-http](https://github.com/magicDGS/jsr203-http)), and I can speed up the development there for needs in HTSJDK; for FTP, maybe [ftp-fs](https://github.com/robtimus/ftp-fs) can be used or a simple implementation can be derived from the HTTP/S implementation (without credentials). This will remove the special handling of HTTP/S and FTP paths in HTSJDK in favor of a consistent and pluggable manner.; * Interfaces for the data types are great, and maybe it will be good to have codec interfaces for both encoding and decoding. For example, I am missing encoders in tribble (an attempt in https://github.com/samtools/htsjdk/pull/822 for writing support).; * For VCF, I would like to have a less diploid-centric interface and design, or at least a way of configure the catching of genotype-related attributes. Currently there are methods for homozygotes/heterozygotes that aren't really useful for triploids or even VCFs without variation (for example, in Pool-Seq data).; * Modular design for artifacts: thus, a project with only SAM/BAM requirements will require only `htsjdk-sam`, and if they also want CRAM support, `htsjdk-cram`. See https://github.com/samtools/htsjdk/issues/896 for more info about it.; * Common license for all HTSJDK, or at least for each module. This will be good for taking into account legal concerns when including the library, because now there is a mixture depending on the files that are used. This is what is coming to my mind now. Maybe I ad",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940:1012,interface,interfaces,1012,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940,3,"['Interface', 'interface']","['Interfaces', 'interfaces']"
Integrability,"No did not. Fereshteh Izadi; ***@***.***?anonymous&ep=bwmEmailSignature> Book time to meet with ***@***.***?anonymous&ep=bwmEmailSignature>; ________________________________; From: mcollodetti ***@***.***>; Sent: Monday, 4 March 2024 19:51; To: broadinstitute/gatk ***@***.***>; Cc: Angel Izadi ***@***.***>; Author ***@***.***>; Subject: Re: [broadinstitute/gatk] I need a PON vcf (Issue #8477). CAUTION: This email originated from outside of Swansea University. Do not click links or open attachments unless you recognise the sender and know the content is safe. RHYBUDD: Daeth yr e-bost hwn o'r tu allan i Brifysgol Abertawe. Peidiwch â chlicio ar atodiadau neu agor atodiadau oni bai eich bod chi'n adnabod yr anfonwr a'ch bod yn gwybod bod y cynnwys yn ddiogel. Did it work? I had the same problem and that change didn't do it. —; Reply to this email directly, view it on GitHub<https://github.com/broadinstitute/gatk/issues/8477#issuecomment-1977332718>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AUS3HJIINO56ONF7EHSUANDYWTGFLAVCNFSM6AAAAAA3SP5AQKVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSNZXGMZTENZRHA>.; You are receiving this because you authored the thread.Message ID: ***@***.***>",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://github.com/broadinstitute/gatk/issues/8477#issuecomment-1993978579:1191,Message,Message,1191,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/8477#issuecomment-1993978579,1,['Message'],['Message']
