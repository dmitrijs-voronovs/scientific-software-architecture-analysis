quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Availability," ![tmpdm8256t1](https://user-images.githubusercontent.com/8238804/144899323-c439785d-5d57-4a18-b6e5-2b12412465f8.PNG); > ; > Instead of having an argument which changes the interpretation of the earlier arguments, I would prefer more orthogonal arguments.; > ; > I think you'd be able to get an output close to what you would currently like with:; > ; > ```python; > import scanpy as sc, pandas as pd, numpy as np; > ; > pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); > pbmc.obs[""sampleid""] = np.repeat([""s1"", ""s2""], pbmc.n_obs / 2); > df = sc.get.obs_df(pbmc, [""LDHB"", ""louvain"", ""sampleid""]); > ; > summarized = df.pivot_table(; > index=[""louvain"", ""sampleid""],; > values=""LDHB"",; > aggfunc=[np.mean, np.count_nonzero]; > ); > color_df = summarized[""mean""].unstack(); > size_df = summarized[""count_nonzero""].unstack(); > ; > # I don't think the var_names or groupby variables are actually important here; > sc.pl.DotPlot(; > pbmc,; > var_names=""LDHB"", groupby=[""louvain"", ""sampleid""], # Just here so it doesn't error; > dot_color_df=color_df, dot_size_df=size_df,; > ).style(cmap=""Reds"").show(); > ```; > ; > I think this functionality could be more generic, and inspired by the `pd.pivot_table` function. This could end up looking like:; > ; > ```python; > # Imaginary implementation:; > sc.pl.heatmap(; > pbmc,; > var_names=""LDHB"",; > row_groups=""louvain"",; > col_groups=""sampleid""; > ); > ```; > ; > ![image](https://user-images.githubusercontent.com/8238804/144901891-45c3a8aa-1b56-4521-abc1-66f968a59d23.png); > ; > ```python; > sc.pl.heatmap(; > pbmc,; > var_names=[""LDHB"", ""LYZ"", ""CD79A""],; > row_groups=""louvain"",; > col_groups=""sampleid""; > ); > ```; > ; > ![image](https://user-images.githubusercontent.com/8238804/144902398-e967c1db-53c1-4b44-bcbf-8dfedcf06e58.png); > ; > What do you think about that?. Thanks @ivirshup !. I like these lines you suggested- perhaps I can adopt to make it more elegant when creating color_df/size_df:; ```; import scanpy as sc, pandas as pd, numpy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1876#issuecomment-988045664:1756,error,error,1756,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1876#issuecomment-988045664,1,['error'],['error']
Availability, 'MANIFEST.in'; adding license file 'LICENSE'; writing manifest file 'fa2.egg-info/SOURCES.txt'; copying fa2/fa2util.c -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/fa2util.pxd -> build/lib.macosx-12.3-x86_64-3.10/fa2; running build_ext; skipping 'fa2/fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; creating build/temp.macosx-12.3-x86_64-3.10; creating build/temp.macosx-12.3-x86_64-3.10/fa2; clang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -I/Users/test/.pyenv/versions/3.10.3/include/python3.10 -c fa2/fa2util.c -o build/temp.macosx-12.3-x86_64-3.10/fa2/fa2util.o; fa2/fa2util.c:10939:33: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Node.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:10947:33: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Edge.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:10960:35: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Region.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:12133:22: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:261:7: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op) : \; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:5903,error,error,5903,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,2,['error'],['error']
Availability," 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ============== 252 failed, 650 passed, 59 skipped, 5 xfailed, 1038 warnings, 128 errors in 451.20s (0:07:31) ===============. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:75148,ERROR,ERROR,75148,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,6,"['ERROR', 'error']","['ERROR', 'errors']"
Availability," 1363 layer = None; -> 1364 return get_vector(self, k, ""obs"", ""var"", layer=layer); 1365 ; 1366 def var_vector(self, k, *, layer: Optional[str] = None) -> np.ndarray:. ~/miniconda3/envs/scanpy-1.6/lib/python3.8/site-packages/anndata/_core/index.py in get_vector(adata, k, coldim, idxdim, layer); 156 ; 157 if (in_col + in_idx) == 2:; --> 158 raise ValueError(; 159 f""Key {k} could be found in both .{idxdim}_names and .{coldim}.columns""; 160 ). ValueError: Key var_id could be found in both .var_names and .obs.columns; ```. ## Repeats in var_names. When there are repeats in `var_names` (pretty frequent occurence), getting a dataframe with keys that aren't repeated. I think it's fine for this to work. I do think it should error if the key is one values that is duplicated in the index. ```python; adata = sc.AnnData(; X=np.ones((2, 3)),; obs=pd.DataFrame(index=[""cell-0"", ""cell-1""]),; var=pd.DataFrame(index=[""gene-0"", ""gene-0"", ""gene-1""]),; ); sc.get.obs_df(adata, [""gene-1""]); ``````. ### This PR (errors). ```pytb; ---------------------------------------------------------------------------; InvalidIndexError Traceback (most recent call last); <ipython-input-62-405d671e2970> in <module>; ----> 1 sc.get.obs_df(adata, [""a"", ""gene-1""]). ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 213 var_idx = adata.raw.var_names.get_indexer(var_names); 214 else:; --> 215 var_idx = adata.var_names.get_indexer(var_names); 216 ; 217 # for backed AnnData is important that the indices are ordered. /usr/local/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_indexer(self, target, method, limit, tolerance); 3169 ; 3170 if not self.is_unique:; -> 3171 raise InvalidIndexError(; 3172 ""Reindexing only valid with uniquely valued Index objects""; 3173 ). InvalidIndexError: Reindexing only valid with uniquely valued Index objects; ```. ### 1.6 (suceeds). ```python; gene-1; cell-0 1.0; cell-1 1.0; ```. 1.6 does error if I use `""gene-0""` as a key, b",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421:4516,error,errors,4516,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421,1,['error'],['errors']
Availability, 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residual,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2104,ERROR,ERROR,2104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability, 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2983,ERROR,ERROR,2983,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability," @Aeget1000 , @iamsalil . I faced the same problem as well. TLDR: choose a higher `span` value in `sc.pp.highly_variable_genes`. The default is 0.3, which caused an error for me as well. 0.5 worked fine in my case. The information below might be interesting for developers or anyone who wants to understand this error more deeply. I got the error when using HLCA data. If scanpy developers are interested, I can point to the dataset to reproduce this problem. It is quite big, but I don't know any other example yet. The error is caused by [this line](https://github.com/scverse/scanpy/blob/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_highly_variable_genes.py#L84C20-L84C20). I got it when selecting HVGs by ""dataset"" batch key in HLCA. Batch ""Sims_2019"" caused the problem. Surprisingly, relationships between `mean` and `var` as well as between `x` and `y` seemed ok:. ![mean_var_relationship](https://github.com/scverse/scanpy/assets/35199218/c3462393-acb5-40fd-80eb-0a45172adce9). ![x_y_relationship](https://github.com/scverse/scanpy/assets/35199218/00e0f6e4-c7d9-4a3d-aeb3-655f185f4f0e). However, something was still causing the problem. I tried to locate the error in the[ loess calucation](https://github.com/has2k1/scikit-misc/blob/269f61e722f81c5bfea964b80b3c20871f2ffe22/skmisc/loess/src/_loess.pyx#L919) in the original package but did not succeed. Anyway, this is a bit out of the scope of scanpy. Setting `span` to a higher value (0.5) solved the problem for me. If there is no strong argument against it, I suggest changing the default value from 0.3 to 0.5. By the way, there is another potential bug in [this function](https://github.com/scverse/scanpy/blob/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_highly_variable_genes.py#L84C20-L84C20). If all the values are constant and `not_const` only consists of False, kernel dies when trying to run `model.fit()`. Maybe it is prevented previously, but in case it isn't, you might want to check that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2669#issuecomment-1768365664:1210,error,error,1210,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669#issuecomment-1768365664,1,['error'],['error']
Availability, AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image fi,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48199,Error,Error,48199,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability, ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74329,ERROR,ERROR,74329,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability, ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportErro,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68924,ERROR,ERROR,68924,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability, [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2542,ERROR,ERROR,2542,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability, [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3421,ERROR,ERROR,3421,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability," _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; return dispatch(args[0].__class__)(*args, **kw); scanpy/preprocessing/_simple.py:888: in scale_anndata; X, adata.var[""mean""], adata.var[""std""] = do_scale(; ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; error_rewrite(e, 'typing'); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); issue_type = 'typing'. def error_rewrite(e, issue_type):; """"""; Rewrite and raise Exception `e` with help supplied based on the; specified issue_type.; """"""; if config.SHOW_HELP:; help_msg = errors.error_extras[issue_type]; e.patch_message('\n'.join((str(e).rstrip(), help_msg))); if config.FULL_TRACEBACKS:; raise e; else:; > raise e.with_traceback(None); E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); E non-precise type pyobject; E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); E ; E File ""scanpy/preprocessing/_simple.py"", line 763:; E def do_scale(X, maxv, nthr):; E <source elided>; E # t0= time.time(); E s = np.zeros((nthr, X.shape[1])); E ^ ; E ; E This error may have been caused by the following argument(s):; E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>. ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; ```. When trying to use the new flavor with the existing test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183:1839,error,errors,1839,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183,3,['error'],"['error', 'errors']"
Availability," ```python; > sc.pl.heatmap(; > pbmc,; > var_names=[""LDHB"", ""LYZ"", ""CD79A""],; > row_groups=""louvain"",; > col_groups=""sampleid""; > ); > ```; > ; > ![image](https://user-images.githubusercontent.com/8238804/144902398-e967c1db-53c1-4b44-bcbf-8dfedcf06e58.png); > ; > What do you think about that?. Thanks @ivirshup !. I like these lines you suggested- perhaps I can adopt to make it more elegant when creating color_df/size_df:; ```; import scanpy as sc, pandas as pd, numpy as np. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); pbmc.obs[""sampleid""] = np.repeat([""s1"", ""s2""], pbmc.n_obs / 2); df = sc.get.obs_df(pbmc, [""LDHB"", ""louvain"", ""sampleid""]). summarized = df.pivot_table(; index=[""louvain"", ""sampleid""],; values=""LDHB"",; aggfunc=[np.mean, np.count_nonzero]; ); color_df = summarized[""mean""].unstack(); size_df = summarized[""count_nonzero""].unstack(). # I don't think the var_names or groupby variables are actually important here; sc.pl.DotPlot(; pbmc,; var_names=""LDHB"", groupby=[""louvain"", ""sampleid""], # Just here so it doesn't error; dot_color_df=color_df, dot_size_df=size_df,; ).style(cmap=""Reds"").show(); ```; this is the output:; ![image](https://user-images.githubusercontent.com/10910559/145053489-c550d5a7-a8fe-4a61-b672-9103ccf1d228.png); some work are needed to modify the grid/axis size, legend and scale. Actually this is the reason I work on top of the _dotplot and _baseplot function/ classes to implement the solution- to make the plots the same style with scanpy dotplot without doing too much work on the cosmetics. But I can certainly change grouby_expand from bool to an actual variable `group_cols` as you suggested in #2055 . Or should we call it `col_groups` as you did in your sc.pl.heatmap pseudo code? ; I'd be more than happy to make it more generalized, i.e., to sc.pl.heatmap, but I may need some time to understand sc.pl.heatmap first. The plotting functions are getting really complex- it took me some time to understand _dotplot and _baseplot :). Thanks",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1876#issuecomment-988045664:3309,error,error,3309,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1876#issuecomment-988045664,1,['error'],['error']
Availability," ```python; sc.pl.spatial(adata, color=""leiden"", groups=[""0""]); ```; <details>; <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. --------------------. > No behaviour changes in embedding if the basis is called ""spatial"" vs anything else, this should be triggered by calling the spatial function. this is addressed, embedding changes behaviour only if img is passed, but has nothing to do with spatial, there is a small trick, and has to do with `ax.invert_yaxis()`. See following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons; - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object; - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:; ```python; if img is _empty:; 	ax.invert_yaxis(); ```; This is the behviour; ```python; sc.pl",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1512#issuecomment-748455514:2755,avail,available,2755,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512#issuecomment-748455514,1,['avail'],['available']
Availability," `from skmisc.loess import loess`; ```python; from skmisc.loess import loess; ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_11028/3052125001.py in <module>; ----> 1 from skmisc.loess import loess. ~\AppData\Roaming\Python\Python38\site-packages\skmisc\loess\__init__.py in <module>; 49 pp. 829--836. 1979.; 50 """"""; ---> 51 from ._loess import (loess, loess_model, loess_inputs, loess_control,; 52 loess_outputs, loess_prediction,; 53 loess_confidence_intervals, loess_anova). ImportError: DLL load failed while importing _loess: The specified module could not be found.; ```; Step5: run `import skmisc; print(skmisc.__file__)`; ```python; import skmisc; print(skmisc.__file__); C:\Users\Park_Lab\AppData\Roaming\Python\Python38\site-packages\skmisc\__init__.py; ```; Step6: due to Step4, I follow the solution (https://github.com/has2k1/scikit-misc/issues/4) to install Numpy with mkl.; ```python; (base) C:\Users\Park_Lab>conda activate Python38; (Python38) C:\Users\Park_Lab>cd Downloads/; (Python38) C:\Users\Park_Lab\Downloads>pip install numpy-1.21.5+mkl-cp38-cp38-win_amd64.whl; Processing c:\users\park_lab\downloads\numpy-1.21.5+mkl-cp38-cp38-win_amd64.whl; Installing collected packages: numpy; Attempting uninstall: numpy; Found existing installation: numpy 1.21.5; Uninstalling numpy-1.21.5:; Successfully uninstalled numpy-1.21.5; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.21.5+mkl which is incompatible.; Successfully installed numpy-1.21.5+mkl; ```; Step7: check anaconda Python38 environment, numpy-1.21.5+mkl is successfully installed; ![image](https://user-images.githubusercontent.com/75048821/147306587-eb94c188-5c18-40f0-add0-3a899872d786.png). Step8: Scanpy import error. Numpy>v1.20 is conflicted with Scanpy; ```python; import numpy as np; import pa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342:4345,Down,Downloads,4345,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342,2,['Down'],['Downloads']
Availability," `scale[scale == 0] = 1e-12`.; Now I put instead `scale[scale == 0] = 1`. This yields the same result for `zero_center == True`: all values set to `0`, anyway (but with less arbitrary magic numbers and maybe less rounding errors). But if `zero_zenter == False`, unscalable values are untouched. This only affected the dense codepath where zero-centering was done afterwards anyway due to the original bug. Therefore this is no code breaking change.; But I also moved this statement before the sparse check to have consistent handling of sparse and dense data. Before that the sparse path wrote infs in the values (unchecked divison by zero) - this is a potentially code breaking change, but it only leads to the behaviour already stated in the documentation. I personally think that code relying on this undocumented behaviour should be rewritten, anyway...; In the new test I explicitly check for this behaviour to make it well defined.; Similar for integer datatypes (resulted in an error), they are now converted to floating point for scaling and return a copy. BTW: In order to make the tests run in my conda environment, I had to remove every reference to compare_images from matplotlib.testing.compare. There seems to be a version conflict in the version checking... It always gave errors like the following:; `________________ ERROR collecting scanpy/tests/test_plotting.py ________________; scanpy/tests/test_plotting.py:16: in <module>; from matplotlib.testing.compare import compare_images; ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/testing/compare.py:240: in <module>; _update_converter(); ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/testing/compare.py:222: in _update_converter; mpl._get_executable_info(""gs""); ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/__init__.py:364: in _get_executable_info; return impl([e, ""--version""], ""(.*)"", ""9""); ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/__init__.py:346: in impl; if min_ver i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1160#issuecomment-615407330:1212,error,error,1212,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1160#issuecomment-615407330,1,['error'],['error']
Availability," as before while confirming that the PYTHONHASHSEED variable was set to 0 before running the pipeline. ```; # First run on a machine on with 8 CPUs; %env PYTHONHASHSEED=0; import numpy as np; import pandas as pd; import scanpy as sc; adata = sc.read_10x_mtx(; './data/filtered_gene_bc_matrices/hg19/', ; var_names='gene_symbols',; cache=True) . sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); adata = adata.copy(); sc.pp.scale(adata, max_value=10); sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5); adata = adata[:, adata.var.highly_variable]; sc.tl.pca(adata, svd_solver='arpack', random_state=14); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14); sc.write('test8.h5ad', adata); sc.tl.pca(adata, svd_solver='randomized', random_state=14); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14); sc.write('test8_randomized.h5ad', adata); ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs; %env PYTHONHASHSEED=0; import numpy as np; import pandas as pd; import scanpy as sc; adata = sc.read_10x_mtx(; './data/filtered_gene_bc_matrices/hg19/', ; var_names='gene_symbols',; cache=True) . sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); adata = adata.copy(); sc.pp.scale(adata, max_value=10); sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5); adata = adata[:, adata.var.highly_variable]; sc.tl.pca(adata, svd_solver='arpack', random_state=14); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14); sc.write('test16.h5ad', adata); sc.tl.pca(adata, svd_solver='randomized', random_state=14); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14); sc.write('test16_randomized.h5ad', adata); ! echo $PYTHONHASHSEED. # Running on a machine with 16 CPUs, evaluate the differences betw",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1187#issuecomment-620841409:1160,echo,echo,1160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187#issuecomment-620841409,1,['echo'],['echo']
Availability," as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output. note: This is an issue with the package mentioned above, not pip.; hint: See above for details.; Exception information:; Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper; status = run_func(*args); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:4686,error,error,4686,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['error'],['error']
Availability, errors include:. * A lot of `AssertionError: Error: Image files did not match.`; * Some missing function from scipy; * Missing pynndescent; * 3 or 4 more unique ones. <details>; <summary> </summary>. ```python; FAILED scanpy/get/get.py::scanpy.get.get.obs_df; FAILED scanpy/plotting/_baseplot_class.py::scanpy.plotting._baseplot_class.BasePlot.add_totals; FAILED scanpy/tests/test_metrics.py::test_consistency[morans_i-allclose] - AssertionError: ; FAILED scanpy/tests/test_paga.py::test_paga_plots[-paga] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous-func1] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_obs-func2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_multiple-func3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_pie - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[umap] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image fil,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:1196,Error,Error,1196,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823:1639,down,downstream,1639,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823,1,['down'],['downstream']
Availability, files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:3678,Error,Error,3678,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability, import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Im,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:47815,Error,Error,47815,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability," improved!. 56 failed, 1236 passed, 96 skipped, 19 xfailed, 9 xpassed, 763 warnings in 595.02s (0:09:55). Remaining errors include:. * A lot of `AssertionError: Error: Image files did not match.`; * Some missing function from scipy; * Missing pynndescent; * 3 or 4 more unique ones. <details>; <summary> </summary>. ```python; FAILED scanpy/get/get.py::scanpy.get.get.obs_df; FAILED scanpy/plotting/_baseplot_class.py::scanpy.plotting._baseplot_class.BasePlot.add_totals; FAILED scanpy/tests/test_metrics.py::test_consistency[morans_i-allclose] - AssertionError: ; FAILED scanpy/tests/test_paga.py::test_paga_plots[-paga] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous-func1] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_obs-func2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_multiple-func3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_pie - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[umap] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED sc",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:1095,Error,Error,1095,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability," it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand.; I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```; $ conda create -yn flit-deps python=3.8 flit; $ conda activate flit-deps; $ flit install -s --dep=develop # Make development install of scanpy; $ pip install scvelo # Install project that depends on scanty; ...; Attempting uninstall: scanpy; Found existing installation: scanpy 1.8.0.dev49-ge715cd98; Uninstalling scanpy-1.8.0.dev49-ge715cd98:; Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98; ...; # Development version of scanpy has now been uninstalled; ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-787407852:1816,error,error,1816,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-787407852,1,['error'],['error']
Availability," mangled = func(compiler_state); 274 if mangled not in (True, False):; 275 msg = (""CompilerPass implementations should return True/False. "". C:\ProgramData\Anaconda3\lib\site-packages\numba\core\typed_passes.py in run_pass(self, state); 392 lower = lowering.Lower(targetctx, library, fndesc, interp,; 393 metadata=metadata); --> 394 lower.lower(); 395 if not flags.no_cpython_wrapper:; 396 lower.create_cpython_wrapper(flags.release_gil). C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower(self); 166 if self.generator_info is None:; 167 self.genlower = None; --> 168 self.lower_normal_function(self.fndesc); 169 else:; 170 self.genlower = self.GeneratorLower(self). C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower_normal_function(self, fndesc); 220 # Init argument values; 221 self.extract_function_arguments(); --> 222 entry_block_tail = self.lower_function_body(); 223 ; 224 # Close tail of entry block, do not emit debug metadata else the. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower_function_body(self); 249 bb = self.blkmap[offset]; 250 self.builder.position_at_end(bb); --> 251 self.lower_block(block); 252 self.post_lower(); 253 return entry_block_tail. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block); 263 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; 264 loc=self.loc, errcls_=defaulterrcls):; --> 265 self.lower_inst(inst); 266 self.post_block(block); 267 . C:\ProgramData\Anaconda3\lib\contextlib.py in __exit__(self, typ, value, traceback); 135 value = typ(); 136 try:; --> 137 self.gen.throw(typ, value, traceback); 138 except StopIteration as exc:; 139 # Suppress StopIteration *unless* it's the same exception that. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs); 835 else:; 836 tb = None; --> 837 raise newerr.with_traceback(tb); 838 elif use_new_style_errors():; 839 raise e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325:11687,error,errors,11687,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325,1,['error'],['errors']
Availability," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-801745797:1732,down,downstream,1732,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-801745797,1,['down'],['downstream']
Availability," setuptools’ `discover_packages` or so find it. > From your description above I had thought you didn't want to emulate [pandas use of conftest](https://github.com/pandas-dev/pandas/blob/main/pandas/conftest.py?rgh-link-date=2022-04-12T13%3A19%3A30Z). What do you mean specifically?. Pandas are defining special pytest functions/variables there and fixtures, which is what it’s for. I’d probably judge that we don’t need all those fixtures for our complete test suite and move some of them to a smaller scope (e.g. `tests/io/conftest.py` or so). > I'd lean towards it, but I fully expect issues like https://github.com/scverse/scanpy/pull/685 to come up. This is why I'd like to see a working example of what you want to work towards. Actually I think we can fix that: [the docs for `pytest_addoption`](https://doc.pytest.org/en/latest/reference/reference.html#pytest.hookspec.pytest_addoption) say it has to be defined at the *tests root directory* which can be configured using the [`rootpath`](https://doc.pytest.org/en/latest/reference/reference.html?highlight=root#pytest.Config.rootpath) config option. > Is it definitely the future default? It looks like they are walking that back. The question is if they remove the others or not, I think: https://github.com/pytest-dev/pytest/issues/7245. ---. My intention here is to make clear which code lives under which laws. Pytest world is very different from Python module world. The presence of `__init__.py` fools people into thinking that we’re dealing with python packages/modules here, but that’s not true. The way pytest works is pretty simple:. 1. it collects all test modules (`test_*.py` files, no directories) and determines which `conftest.py` files, plugins, … apply to which test module; 2. it collects all tests in those modules and checks which fixtures they need; 3. it sets up and tears down fixtures according to the needs of each test and executes the tests. accepting that makes it easier to reason about how our test suite works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986:2254,down,down,2254,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1096900986,1,['down'],['down']
Availability," this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default; * Consolidate implementation to a single well maintained library; * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points?. * `tsne` should allow weights to be passed through (whether perplexity based, or not); * There should be a warning to notify the user if the weights were computed in a non-standard way; * There should be a function for computing a perplexity weighted nearest neighbor gr",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-773051636:1183,error,erroring,1183,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-773051636,1,['error'],['erroring']
Availability, to fa2.egg-info/requires.txt; writing top-level names to fa2.egg-info/top_level.txt; reading manifest file 'fa2.egg-info/SOURCES.txt'; reading manifest template 'MANIFEST.in'; adding license file 'LICENSE'; writing manifest file 'fa2.egg-info/SOURCES.txt'; copying fa2/fa2util.c -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/fa2util.pxd -> build/lib.macosx-12.3-x86_64-3.10/fa2; running build_ext; skipping 'fa2/fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; creating build/temp.macosx-12.3-x86_64-3.10; creating build/temp.macosx-12.3-x86_64-3.10/fa2; clang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -I/Users/test/.pyenv/versions/3.10.3/include/python3.10 -c fa2/fa2util.c -o build/temp.macosx-12.3-x86_64-3.10/fa2/fa2util.o; fa2/fa2util.c:10939:33: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Node.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:10947:33: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Edge.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:10960:35: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Region.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:12133:22: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:261:7: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op) : \; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/ve,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:18942,error,error,18942,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,1,['error'],['error']
Availability," use_raw or k in adata.obs.columns:; --> 173 df[k] = adata.obs_vector(l, layer=layer); 174 else:; 175 df[k] = adata.raw.obs_vector(l). ~/miniconda3/envs/scanpy-1.6/lib/python3.8/site-packages/anndata/_core/anndata.py in obs_vector(self, k, layer); 1362 ); 1363 layer = None; -> 1364 return get_vector(self, k, ""obs"", ""var"", layer=layer); 1365 ; 1366 def var_vector(self, k, *, layer: Optional[str] = None) -> np.ndarray:. ~/miniconda3/envs/scanpy-1.6/lib/python3.8/site-packages/anndata/_core/index.py in get_vector(adata, k, coldim, idxdim, layer); 156 ; 157 if (in_col + in_idx) == 2:; --> 158 raise ValueError(; 159 f""Key {k} could be found in both .{idxdim}_names and .{coldim}.columns""; 160 ). ValueError: Key var_id could be found in both .var_names and .obs.columns; ```. ## Repeats in var_names. When there are repeats in `var_names` (pretty frequent occurence), getting a dataframe with keys that aren't repeated. I think it's fine for this to work. I do think it should error if the key is one values that is duplicated in the index. ```python; adata = sc.AnnData(; X=np.ones((2, 3)),; obs=pd.DataFrame(index=[""cell-0"", ""cell-1""]),; var=pd.DataFrame(index=[""gene-0"", ""gene-0"", ""gene-1""]),; ); sc.get.obs_df(adata, [""gene-1""]); ``````. ### This PR (errors). ```pytb; ---------------------------------------------------------------------------; InvalidIndexError Traceback (most recent call last); <ipython-input-62-405d671e2970> in <module>; ----> 1 sc.get.obs_df(adata, [""a"", ""gene-1""]). ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 213 var_idx = adata.raw.var_names.get_indexer(var_names); 214 else:; --> 215 var_idx = adata.var_names.get_indexer(var_names); 216 ; 217 # for backed AnnData is important that the indices are ordered. /usr/local/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_indexer(self, target, method, limit, tolerance); 3169 ; 3170 if not self.is_unique:; -> 3171 raise InvalidIndexError(; 3172 ""Reindexi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421:4238,error,error,4238,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421,1,['error'],['error']
Availability," was a single variable which would be used to fill cell in the plot. As an example:. ```python; pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); pbmc.obs[""sampleid""] = np.repeat([""s1"", ""s2""], pbmc.n_obs / 2). sc.pl.dotplot(pbmc, var_names='LDHB', groupby=['louvain', 'sampleid'], groupby_expand=True); ```. ![tmpdm8256t1](https://user-images.githubusercontent.com/8238804/144899323-c439785d-5d57-4a18-b6e5-2b12412465f8.PNG). Instead of having an argument which changes the interpretation of the earlier arguments, I would prefer more orthogonal arguments. I think you'd be able to get an output close to what you would currently like with:. ```python; import scanpy as sc, pandas as pd, numpy as np. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); pbmc.obs[""sampleid""] = np.repeat([""s1"", ""s2""], pbmc.n_obs / 2); df = sc.get.obs_df(pbmc, [""LDHB"", ""louvain"", ""sampleid""]). summarized = df.pivot_table(; index=[""louvain"", ""sampleid""],; values=""LDHB"",; aggfunc=[np.mean, np.count_nonzero]; ); color_df = summarized[""mean""].unstack(); size_df = summarized[""count_nonzero""].unstack(). # I don't think the var_names or groupby variables are actually important here; sc.pl.DotPlot(; pbmc,; var_names=""LDHB"", groupby=[""louvain"", ""sampleid""], # Just here so it doesn't error; dot_color_df=color_df, dot_size_df=size_df,; ).style(cmap=""Reds"").show(); ```. I think this functionality could be more generic, and inspired by the `pd.pivot_table` function. This could end up looking like:. ```python; # Imaginary implementation:; sc.pl.heatmap(; pbmc,; var_names=""LDHB"",; row_groups=""louvain"",; col_groups=""sampleid""; ); ```. ![image](https://user-images.githubusercontent.com/8238804/144901891-45c3a8aa-1b56-4521-abc1-66f968a59d23.png). ```python; sc.pl.heatmap(; pbmc,; var_names=[""LDHB"", ""LYZ"", ""CD79A""],; row_groups=""louvain"",; col_groups=""sampleid""; ); ```. ![image](https://user-images.githubusercontent.com/8238804/144902398-e967c1db-53c1-4b44-bcbf-8dfedcf06e58.png). What do you think about that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1876#issuecomment-987049315:1644,error,error,1644,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1876#issuecomment-987049315,1,['error'],['error']
Availability," we think it should ""update"" the original AnnData. I'm also confused by how this results in a performance decrease? If I do `adata = np.sqrt(adata)` then isn't this the same footprint as modifying inplace? If I do `adata_sq = np.sqrt(adata)` then my intention is to duplicate the adata object. In this case, it is my intention to create a duplicate object, and I would like AnnData to respect this intention. ; **2. Requirement to use .var_vector or .obs_vector for single columns**; ```python; # This works as expected; adata[:, adata.var_names[0:3]]. # I wish this did as well.; adata[:, adata.var_names[0]]; ```; **3. .var_vector doesn't return a Series**. ```python; pdata = pd.DataFrame(data); # Returns series; pdata[0]. # Returns ndarray; adata.var_vector[0]; ```. **4. Clusters as categories creates confusing scatterplots**; ```python; sc.pp.neighbors(adata); sc.tl.leiden(adata). plt.scatter(adata.obs['leiden'], adata.X[:,0]); ```; Produces the following plot. I would like it to have order 0-5 by default. <img width=""393"" alt=""image"" src=""https://user-images.githubusercontent.com/8322751/78272834-8bd8a380-74fd-11ea-9034-6c8d0aefebe8.png"">. **5. Cannot pass clusters to `c` parameter in plt.scatter**; I would like this to just work. Instead it throws a huge error.; ```python; plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['leiden']); ```. **6. Clusters as categories frustrate subclustering**; I understand this is a niche application, but like 4 and 5, this would be fixed by matching the output of sklearn.cluster operators.; ```python; sc.pp.neighbors(adata); sc.tl.leiden(adata). cluster_zero = adata[adata.obs['leiden'] == '0']; sub_clusters = cluster.KMeans(n_clusters=2).fit_predict(adata.X). # Here I'm trying to break up cluster '0' into subclusters with ; # new names that don't clash with the existing clusters; # However, np.max() and the + operators aren't well defined for ; # cateogricals of strings; sub_clusters = sub_clusters + np.max(adata.obs['leiden']); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-607952458:2303,error,error,2303,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-607952458,1,['error'],['error']
Availability, with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files di,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48084,Error,Error,48084,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability," y):; 40 """"""Reduced Euclidean distance.; 41 . ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/decorators.py in wrapper(func); 219 with typeinfer.register_dispatcher(disp):; 220 for sig in sigs:; --> 221 disp.compile(sig); 222 disp.disable_compile(); 223 return disp. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/dispatcher.py in compile(self, sig); 907 with ev.trigger_event(""numba:compile"", data=ev_details):; 908 try:; --> 909 cres = self._compiler.compile(args, return_type); 910 except errors.ForceLiteralArg as e:; 911 def folded(args, kws):. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 77 ; 78 def compile(self, args, return_type):; ---> 79 status, retval = self._compile_cached(args, return_type); 80 if status:; 81 return retval. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 91 ; 92 try:; ---> 93 retval = self._compile_core(args, return_type); 94 except errors.TypingError as e:; 95 self._failed_cache[key] = e. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 104 ; 105 impl = self._get_implementation(args, {}); --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,; 107 self.targetdescr.target_context,; 108 impl,. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 604 pipeline = pipeline_class(typingctx, targetctx, library,; 605 args, return_type, flags, locals); --> 606 return pipeline.compile_extra(func); 607 ; 608 . ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(self, func); 351 self.state.lifted = (); 352 self.state.lifted_from = None; --> 353 return self._compile_bytecode(); 354 ; 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~/.conda/envs/rpy/lib/python3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796:4482,error,errors,4482,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796,1,['error'],['errors']
Availability,"![image](https://user-images.githubusercontent.com/43333475/126772609-6fbdc819-46e1-4fac-8e8c-d73033192991.png). I have tried pynndescent, and I receive the same errors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1951#issuecomment-885560293:162,error,errors,162,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951#issuecomment-885560293,1,['error'],['errors']
Availability,""", ""repeated_col"", ""var_id""],; index=pd.Index([f""cell_{i}"" for i in range(M)], name=""obs_index""),; ),; var=pd.DataFrame(; index=pd.Index([""var_id""] + [f""gene_{i}"" for i in range(N-1)], name=""var_index""),; ),; ); ```. ## Repeated column in `adata.obs`. I think this should be an error. This is because downstream functions (like plotting) currently assume that for each key input here, there will be one output column. Turns out this isn't exactly pandas behaviour with repeated column values, but I do think it's reasonable. ```python; M, N = 5, 3; adata = sc.AnnData(; X=np.zeros((M, N)),; obs=pd.DataFrame(; np.arange(M * 2).reshape((M, 2)),; columns=[""repeated_col"", ""repeated_col""],; index=[f""cell_{i}"" for i in range(M)],; ),; var=pd.DataFrame(; index=[f""gene_{i}"" for i in range(N)],; ), ; ); sc.get.obs_df(adata, [""repeated_col""]); ```. ### This pr (gets both columns). ```; repeated_col repeated_col; obs_index ; cell_0 0 1; cell_1 3 4; cell_2 6 7; cell_3 9 10; cell_4 12 13; ```. ### 1.6 (errors). ```pytb; ~/miniconda3/envs/scanpy-1.6/lib/python3.8/site-packages/pandas/core/internals/blocks.py in __init__(self, values, placement, ndim); 140 ; 141 if self._validate_ndim and self.ndim and len(self.mgr_locs) != len(self.values):; --> 142 raise ValueError(; 143 f""Wrong number of items passed {len(self.values)}, ""; 144 f""placement implies {len(self.mgr_locs)}"". ValueError: Wrong number of items passed 2, placement implies 1; ```. Not a great error, could definitley be improved. ## Key in adata.obs.columns and adata.var_names. In this case, the key is ambiguous (should it get the gene values or the column from obs?). I think this means it should error. I feel like this point has been discussed a number of times, but doesn't seem to have been discussed when this behaviour was changed. ```python; M, N = 5, 3; adata = sc.AnnData(; X=np.zeros((M, N)),; obs=pd.DataFrame(; np.arange(M),; columns=[""var_id""],; index=[f""cell_{i}"" for i in range(M)],; ),; var=pd.DataFrame(; index=[""var_id",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421:1452,error,errors,1452,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421,1,['error'],['errors']
Availability,# Error Output. Output when using a list of marker genes in the `var_names` arg; ![Image](https://github.com/user-attachments/assets/570abb0c-a986-45f1-8d5c-3fceddf02273). Output when using a dict of marker genes in the `var_names` arg; ![Image](https://github.com/user-attachments/assets/9221dfe4-1638-4284-beb9-d8c02fa9d4eb),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3320#issuecomment-2436143352:2,Error,Error,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320#issuecomment-2436143352,1,['Error'],['Error']
Availability,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2201?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@2c55a14`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.9.x #2201 +/- ##; ========================================; Coverage ? 71.95% ; ========================================; Files ? 98 ; Lines ? 11538 ; Branches ? 0 ; ========================================; Hits ? 8302 ; Misses ? 3236 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2201#issuecomment-1086301791:326,error,error-reference,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2201#issuecomment-1086301791,1,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2202?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@2c55a14`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.9.x #2202 +/- ##; ========================================; Coverage ? 71.95% ; ========================================; Files ? 98 ; Lines ? 11538 ; Branches ? 0 ; ========================================; Hits ? 8302 ; Misses ? 3236 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2202#issuecomment-1086316533:326,error,error-reference,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2202#issuecomment-1086316533,1,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2213?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@3ac9169`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 9c0054f differs from pull request most recent head 02123f2. Consider uploading reports for the commit 02123f2 to get more accurate results. ```diff; @@ Coverage Diff @@; ## 1.9.x #2213 +/- ##; ========================================; Coverage ? 71.94% ; ========================================; Files ? 98 ; Lines ? 11539 ; Branches ? 0 ; ========================================; Hits ? 8302 ; Misses ? 3237 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2213#issuecomment-1088659791:326,error,error-reference,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2213#issuecomment-1088659791,1,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2221?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@6cc7541`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.9.x #2221 +/- ##; ========================================; Coverage ? 71.94% ; ========================================; Files ? 98 ; Lines ? 11539 ; Branches ? 0 ; ========================================; Hits ? 8302 ; Misses ? 3237 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2221#issuecomment-1088855272:326,error,error-reference,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2221#issuecomment-1088855272,1,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2226?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@a08c155`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.9.x #2226 +/- ##; ========================================; Coverage ? 71.82% ; ========================================; Files ? 98 ; Lines ? 11539 ; Branches ? 0 ; ========================================; Hits ? 8288 ; Misses ? 3251 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2226#issuecomment-1090215514:326,error,error-reference,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2226#issuecomment-1090215514,1,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2241?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`master@cab9f78`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #2241 +/- ##; =========================================; Coverage ? 71.74% ; =========================================; Files ? 99 ; Lines ? 11560 ; Branches ? 0 ; =========================================; Hits ? 8294 ; Misses ? 3266 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2241#issuecomment-1104534706:327,error,error-reference,327,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2241#issuecomment-1104534706,1,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2275?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@5bcb539`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.9.x #2275 +/- ##; ========================================; Coverage ? 71.82% ; ========================================; Files ? 98 ; Lines ? 11539 ; Branches ? 0 ; ========================================; Hits ? 8288 ; Misses ? 3251 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2275#issuecomment-1156972689:326,error,error-reference,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2275#issuecomment-1156972689,1,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2279?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@4d0d8be`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.9.x #2279 +/- ##; ========================================; Coverage ? 71.82% ; ========================================; Files ? 98 ; Lines ? 11539 ; Branches ? 0 ; ========================================; Hits ? 8288 ; Misses ? 3251 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2279#issuecomment-1157013971:326,error,error-reference,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2279#issuecomment-1157013971,1,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2348?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@6b5f786`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 6fb5f26 differs from pull request most recent head fb557a1. Consider uploading reports for the commit fb557a1 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2348 +/- ##; ========================================; Coverage ? 71.77% ; ========================================; Files ? 97 ; Lines ? 11519 ; Branches ? 0 ; ========================================; Hits ? 8268 ; Misses ? 3251 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2348#issuecomment-1273857794:326,error,error-reference,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2348#issuecomment-1273857794,1,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2350?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@cf6d820`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2350 +/- ##; ========================================; Coverage ? 71.77% ; ========================================; Files ? 97 ; Lines ? 11519 ; Branches ? 0 ; ========================================; Hits ? 8268 ; Misses ? 3251 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2350#issuecomment-1274792439:326,error,error-reference,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2350#issuecomment-1274792439,1,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2419?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@97c2617`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 72ea692 differs from pull request most recent head 8fb038a. Consider uploading reports for the commit 8fb038a to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2419 +/- ##; ========================================; Coverage ? 71.83% ; ========================================; Files ? 98 ; Lines ? 11543 ; Branches ? 0 ; ========================================; Hits ? 8292 ; Misses ? 3251 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2419#issuecomment-1433063184:326,error,error-reference,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2419#issuecomment-1433063184,1,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/scverse/scanpy/pull/2435?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@1fbbfcd`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2435 +/- ##; ========================================; Coverage ? 71.88% ; ========================================; Files ? 98 ; Lines ? 11546 ; Branches ? 0 ; ========================================; Hits ? 8300 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2435#issuecomment-1451099582:326,error,error-reference,326,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2435#issuecomment-1451099582,1,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1413?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > :exclamation: No coverage uploaded for pull request base (`master@62bb643`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#section-missing-base-commit).; > The diff coverage is `74.48%`. ```diff; @@ Coverage Diff @@; ## master #1413 +/- ##; =========================================; Coverage ? 71.34% ; =========================================; Files ? 92 ; Lines ? 11186 ; Branches ? 0 ; =========================================; Hits ? 7981 ; Misses ? 3205 ; Partials ? 0 ; ```. | [Impacted Files](https://codecov.io/gh/theislab/scanpy/pull/1413?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) | Coverage Δ | |; |---|---|---|; | [scanpy/\_\_main\_\_.py](https://codecov.io/gh/theislab/scanpy/pull/1413/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L19fbWFpbl9fLnB5) | `0.00% <0.00%> (ø)` | |; | [scanpy/plotting/\_tools/\_\_init\_\_.py](https://codecov.io/gh/theislab/scanpy/pull/1413/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9fX2luaXRfXy5weQ==) | `76.74% <ø> (ø)` | |; | [scanpy/plotting/\_tools/paga.py](https://codecov.io/gh/theislab/scanpy/pull/1413/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9wYWdhLnB5) | `70.62% <ø> (ø)` | |; | [scanpy/plotting/\_tools/scatterplots.py](https://codecov.io/gh/theislab/scanpy/pull/1413/diff?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_c,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1413#issuecomment-846966462:329,error,error-reference,329,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1413#issuecomment-846966462,1,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1693?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@c943b93`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `71.86%`. [![Impacted file tree graph](https://codecov.io/gh/theislab/scanpy/pull/1693/graphs/tree.svg?width=650&height=150&src=pr&token=UsIEoV0aqg)](https://codecov.io/gh/theislab/scanpy/pull/1693?src=pr&el=tree). ```diff; @@ Coverage Diff @@; ## master #1693 +/- ##; =========================================; Coverage ? 71.32% ; =========================================; Files ? 89 ; Lines ? 10969 ; Branches ? 0 ; =========================================; Hits ? 7824 ; Misses ? 3145 ; Partials ? 0 ; ```. | [Impacted Files](https://codecov.io/gh/theislab/scanpy/pull/1693?src=pr&el=tree) | Coverage Δ | |; |---|---|---|; | [scanpy/\_\_main\_\_.py](https://codecov.io/gh/theislab/scanpy/pull/1693/diff?src=pr&el=tree#diff-c2NhbnB5L19fbWFpbl9fLnB5) | `0.00% <0.00%> (ø)` | |; | [scanpy/plotting/\_dotplot.py](https://codecov.io/gh/theislab/scanpy/pull/1693/diff?src=pr&el=tree#diff-c2NhbnB5L3Bsb3R0aW5nL19kb3RwbG90LnB5) | `86.79% <ø> (ø)` | |; | [scanpy/plotting/\_matrixplot.py](https://codecov.io/gh/theislab/scanpy/pull/1693/diff?src=pr&el=tree#diff-c2NhbnB5L3Bsb3R0aW5nL19tYXRyaXhwbG90LnB5) | `97.87% <ø> (ø)` | |; | [scanpy/plotting/\_preprocessing.py](https://codecov.io/gh/theislab/scanpy/pull/1693/diff?src=pr&el=tree#diff-c2NhbnB5L3Bsb3R0aW5nL19wcmVwcm9jZXNzaW5nLnB5) | `87.75% <ø> (ø)` | |; | [scanpy/plotting/\_qc.py](https://codecov.io/gh/theislab/scanpy/pull/1693/diff?src=pr&el=tree#diff-c2NhbnB5L3Bsb3R0aW5nL19xYy5weQ==) | `88.23% <ø> (ø)` | |; | [scanpy/plotting/\_rcmod.py](https://codecov.io/gh/theislab/scanpy/pull/1693/diff?src=pr&el=tree#diff-c2NhbnB5L3Bsb3R0aW5nL19yY21vZC5weQ==) | `100.00% <ø> (ø)` | |; | [scanpy/plotting/\_stacked\_violin.py](https://codecov.io/gh/theislab,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1693#issuecomment-785678892:228,error,error-reference,228,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1693#issuecomment-785678892,1,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1920?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > :exclamation: No coverage uploaded for pull request base (`1.8.x@8750212`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.8.x #1920 +/- ##; ========================================; Coverage ? 71.60% ; ========================================; Files ? 92 ; Lines ? 11248 ; Branches ? 0 ; ========================================; Hits ? 8054 ; Misses ? 3194 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1920#issuecomment-873816651:328,error,error-reference,328,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1920#issuecomment-873816651,1,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1923?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > :exclamation: No coverage uploaded for pull request base (`1.8.x@d0f851f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.8.x #1923 +/- ##; ========================================; Coverage ? 71.60% ; ========================================; Files ? 92 ; Lines ? 11248 ; Branches ? 0 ; ========================================; Hits ? 8054 ; Misses ? 3194 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1923#issuecomment-873930176:328,error,error-reference,328,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1923#issuecomment-873930176,1,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1924?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > :exclamation: No coverage uploaded for pull request base (`1.8.x@1605f63`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.8.x #1924 +/- ##; ========================================; Coverage ? 71.60% ; ========================================; Files ? 92 ; Lines ? 11246 ; Branches ? 0 ; ========================================; Hits ? 8053 ; Misses ? 3193 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1924#issuecomment-873973489:328,error,error-reference,328,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1924#issuecomment-873973489,1,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1935?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > :exclamation: No coverage uploaded for pull request base (`1.8.x@8c51f19`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.8.x #1935 +/- ##; ========================================; Coverage ? 71.61% ; ========================================; Files ? 92 ; Lines ? 11246 ; Branches ? 0 ; ========================================; Hits ? 8054 ; Misses ? 3192 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1935#issuecomment-875351624:328,error,error-reference,328,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1935#issuecomment-875351624,1,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1938?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > :exclamation: No coverage uploaded for pull request base (`1.8.x@2883269`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.8.x #1938 +/- ##; ========================================; Coverage ? 71.61% ; ========================================; Files ? 92 ; Lines ? 11246 ; Branches ? 0 ; ========================================; Hits ? 8054 ; Misses ? 3192 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1938#issuecomment-875422302:328,error,error-reference,328,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1938#issuecomment-875422302,1,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1947?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > :exclamation: No coverage uploaded for pull request base (`1.8.x@9360422`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.8.x #1947 +/- ##; ========================================; Coverage ? 71.61% ; ========================================; Files ? 92 ; Lines ? 11246 ; Branches ? 0 ; ========================================; Hits ? 8054 ; Misses ? 3192 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1947#issuecomment-878124023:328,error,error-reference,328,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1947#issuecomment-878124023,1,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1952?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > :exclamation: No coverage uploaded for pull request base (`1.8.x@c9d319e`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.8.x #1952 +/- ##; ========================================; Coverage ? 71.61% ; ========================================; Files ? 92 ; Lines ? 11246 ; Branches ? 0 ; ========================================; Hits ? 8054 ; Misses ? 3192 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1952#issuecomment-882418271:328,error,error-reference,328,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1952#issuecomment-882418271,1,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1961?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > :exclamation: No coverage uploaded for pull request base (`1.8.x@aeaa07b`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.8.x #1961 +/- ##; ========================================; Coverage ? 71.61% ; ========================================; Files ? 92 ; Lines ? 11246 ; Branches ? 0 ; ========================================; Hits ? 8054 ; Misses ? 3192 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1961#issuecomment-887335708:328,error,error-reference,328,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1961#issuecomment-887335708,1,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1962?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > :exclamation: No coverage uploaded for pull request base (`1.8.x@370d1c6`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.8.x #1962 +/- ##; ========================================; Coverage ? 71.61% ; ========================================; Files ? 92 ; Lines ? 11246 ; Branches ? 0 ; ========================================; Hits ? 8054 ; Misses ? 3192 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1962#issuecomment-887353669:328,error,error-reference,328,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1962#issuecomment-887353669,1,['error'],['error-reference']
Availability,# [Codecov](https://codecov.io/gh/theislab/scanpy/pull/1966?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab) Report; > :exclamation: No coverage uploaded for pull request base (`1.8.x@b9cd8c8`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=theislab#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## 1.8.x #1966 +/- ##; ========================================; Coverage ? 71.61% ; ========================================; Files ? 92 ; Lines ? 11246 ; Branches ? 0 ; ========================================; Hits ? 8054 ; Misses ? 3192 ; Partials ? 0 ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1966#issuecomment-888502703:328,error,error-reference,328,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1966#issuecomment-888502703,1,['error'],['error-reference']
Availability,"## Test failures on 141eb6a315542317ddab2f7a413a24559c84492f. 252 failed, 650 passed, 59 skipped, 5 xfailed, 1038 warnings, 128 errors in 451.20s (0:07:31). Noting some of the big causes:. ### Expected warnings not thrown. A few times. ### Older versions of pandas do not support `na_action`. Likely caused during [Fix more pandas warnings by flying-sheep · Pull Request #2789 · scverse/scanpy](https://github.com/scverse/scanpy/pull/2789). Which did also bump up the required pandas version to 2.1.3. However, I think we'll want to revert that bump because:. * According to the scientific python versioning specification we're still meant to be on 1.4 ; * More than half of pandas users are still on 1.*; * Bumping pandas up to 2.1.3 actually requires bumping the versions on a number of other dependencies whose current minimums do not work with pandas 2.1.3. ### ufunc equal. Something is happening in a lot of plotting functions with the `equal` ufunc. ### Numba NotImplementedError. During `test_highly_variable_genes_pearson_residuals_general`. ### AnnData private methods used in tests. A lot of private anndata methods are used at test time. But these didn't exist at the time. Not totally sure what the best solution here is. * Vendoring anndata test helpers over here.; * Literally pulling in the file is probably not so bad; * I will investigate to see how many functions are really needed, possible it's just a few one liners (`as_dense_dask_array` is getting hit often); * Make a new package with just the test helpers? Probably too much of a pain. ### ImportError: cannot import name 'check_is_fitted' from 'sklearn.base'. <details>; <summary> Raw test output </summary>. ```python; FAILED scanpy/tests/test_datasets.py::test_krumsiek11 - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/tests/test_datasets.py::test_toggleswitch - Failed: DID NOT WARN. No warnings of type (<class 'UserWarning'>,) were emitted.; FAILED scanpy/get/get.py::",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:8,failure,failures,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,2,"['error', 'failure']","['errors', 'failures']"
Availability,"## Xarray and anndata. Theoretically, `AnnData` objects are kind of like a special case of `xarray.Dataset`s. While `AnnData` objects have an `obs` and a `var` dimension `xarray.Dataset` can have any number of dimensions. `AnnData` objects are just specializing to the the 2d case. I think it would make a lot of sense to eventually have `anndata` and `scanpy` be based on `xarray`, or something like it. In practice there are a number of difficulties here. The biggest one is support for sparse data, and I'll briefly point out a couple others. ### Sparse arrays. I could probably rant about this for a while, since it's always a problem. Efficient processing of scRNA-seq data needs sparse matrices. The only fully featured sparse array library in python right now is `scipy.sparse`. All of it's sparse arrays only follow the `np.matrix` interface, which is deprecated. This means that they only kind-of work like arrays, and need to be special cased pretty frequently. `xarray` seems to work pretty well with a number of different array types, as long as they act like `np.ndarray`s. They have explicit support for `pydata/sparse`, but that library isn't well supported by the rest of the ecosystem, probably because it doesn't have CSR or CSC matrices yet. This leaves `xarray` with a level of sparse array support that isn't usable for us. ### Pairwise arrays and other weird behaviour. * Having an array where multiple axes have the same name doesn't work well with `xarray`. This is a problem if you're frequently using adjacency matrices like we do.; * `xarray.DataArray`s do not necessarily have the same behaviour as numpy arrays. For example, they have specific behaviour for matrix multiplication. Any transition would be much easier if `DataArrays` could be used as drop-in replacements for numpy arrays (plus some errors for misaligned data). We need to map this out more before we could make any attempt at integrating the libraries.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-608238154:1828,error,errors,1828,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-608238154,1,['error'],['errors']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2516?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@2979f99`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2516 +/- ##; ========================================; Coverage ? 71.89% ; ========================================; Files ? 98 ; Lines ? 11488 ; Branches ? 0 ; ========================================; Hits ? 8259 ; Misses ? 3229 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2516#issuecomment-1596813650:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2516#issuecomment-1596813650,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2523?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@ec78ca9`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 249ef59 differs from pull request most recent head c69bc0f. Consider uploading reports for the commit c69bc0f to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2523 +/- ##; ========================================; Coverage ? 71.89% ; ========================================; Files ? 98 ; Lines ? 11488 ; Branches ? 0 ; ========================================; Hits ? 8259 ; Misses ? 3229 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2523#issuecomment-1599208625:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2523#issuecomment-1599208625,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2528?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@af11c8f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2528 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2528#issuecomment-1604254568:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2528#issuecomment-1604254568,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2538?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@120dcd0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2538 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2538#issuecomment-1609797792:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2538#issuecomment-1609797792,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2549?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@c40d2ee`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2549 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2549#issuecomment-1625396556:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2549#issuecomment-1625396556,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2567?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@759960d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2567 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2567#issuecomment-1645436066:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2567#issuecomment-1645436066,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2568?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@759960d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2568 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2568#issuecomment-1645437518:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2568#issuecomment-1645437518,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2574?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@053f47e`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2574 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2574#issuecomment-1649346773:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2574#issuecomment-1649346773,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2597?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@64fab42`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2597 +/- ##; ========================================; Coverage ? 72.13% ; ========================================; Files ? 104 ; Lines ? 11648 ; Branches ? 0 ; ========================================; Hits ? 8402 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2597#issuecomment-1665680324:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2597#issuecomment-1665680324,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2606?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@b5506e1`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2606 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11642 ; Branches ? 0 ; ========================================; Hits ? 8404 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2606#issuecomment-1670939429:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2606#issuecomment-1670939429,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2613?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@a8b931a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2613 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2613#issuecomment-1677226444:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2613#issuecomment-1677226444,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2616?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@a8b931a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2616 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11642 ; Branches ? 0 ; ========================================; Hits ? 8404 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2616#issuecomment-1677462171:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2616#issuecomment-1677462171,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2619?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@fbd73ac`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2619 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2619#issuecomment-1678888447:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2619#issuecomment-1678888447,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2620?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@a6f6c6d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2620 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2620#issuecomment-1681915003:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2620#issuecomment-1681915003,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2638?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@9ba0251`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2638 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2638#issuecomment-1691735842:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2638#issuecomment-1691735842,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2641?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@8aa93e2`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2641 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2641#issuecomment-1691930772:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2641#issuecomment-1691930772,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2643?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@6e8a8b4`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2643 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2643#issuecomment-1696930445:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2643#issuecomment-1696930445,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2652?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@16e7e9f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2652 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2652#issuecomment-1706132242:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2652#issuecomment-1706132242,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2659?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@efce8f8`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head eea03bb differs from pull request most recent head 256ce44. Consider uploading reports for the commit 256ce44 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2659 +/- ##; ========================================; Coverage ? 72.18% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8405 ; Misses ? 3238 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2659#issuecomment-1712163821:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2659#issuecomment-1712163821,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2676?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@fc498c3`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2676 +/- ##; ========================================; Coverage ? 72.00% ; ========================================; Files ? 104 ; Lines ? 11640 ; Branches ? 0 ; ========================================; Hits ? 8381 ; Misses ? 3259 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2676#issuecomment-1753090073:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2676#issuecomment-1753090073,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2677?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@46969b4`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2677 +/- ##; ========================================; Coverage ? 71.69% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8347 ; Misses ? 3296 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2677#issuecomment-1753261271:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2677#issuecomment-1753261271,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2686?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@418baff`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 503876d differs from pull request most recent head 5c315d4. Consider uploading reports for the commit 5c315d4 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2686 +/- ##; ========================================; Coverage ? 71.98% ; ========================================; Files ? 104 ; Lines ? 11642 ; Branches ? 0 ; ========================================; Hits ? 8381 ; Misses ? 3261 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2686#issuecomment-1764071999:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2686#issuecomment-1764071999,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2687?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`master@8353e45`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 601888e differs from pull request most recent head f257b7f. Consider uploading reports for the commit f257b7f to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## master #2687 +/- ##; =========================================; Coverage ? 71.97% ; =========================================; Files ? 108 ; Lines ? 11907 ; Branches ? 0 ; =========================================; Hits ? 8570 ; Misses ? 3337 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2687#issuecomment-1764131250:332,error,error-reference,332,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2687#issuecomment-1764131250,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2690?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@3c15b99`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2690 +/- ##; ========================================; Coverage ? 71.99% ; ========================================; Files ? 104 ; Lines ? 11643 ; Branches ? 0 ; ========================================; Hits ? 8382 ; Misses ? 3261 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2690#issuecomment-1764724800:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2690#issuecomment-1764724800,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2697?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@d71a4a9`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2697 +/- ##; ========================================; Coverage ? 72.01% ; ========================================; Files ? 104 ; Lines ? 11656 ; Branches ? 0 ; ========================================; Hits ? 8394 ; Misses ? 3262 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2697#issuecomment-1766637428:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2697#issuecomment-1766637428,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2721?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@05405f1`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2721 +/- ##; ========================================; Coverage ? 72.03% ; ========================================; Files ? 104 ; Lines ? 11659 ; Branches ? 0 ; ========================================; Hits ? 8398 ; Misses ? 3261 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2721#issuecomment-1785251436:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2721#issuecomment-1785251436,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2722?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@4936b7e`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2722 +/- ##; ========================================; Coverage ? 72.03% ; ========================================; Files ? 104 ; Lines ? 11659 ; Branches ? 0 ; ========================================; Hits ? 8398 ; Misses ? 3261 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2722#issuecomment-1787308099:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2722#issuecomment-1787308099,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2727?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@0b624b0`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2727 +/- ##; ========================================; Coverage ? 72.00% ; ========================================; Files ? 103 ; Lines ? 11641 ; Branches ? 0 ; ========================================; Hits ? 8382 ; Misses ? 3259 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2727#issuecomment-1787571772:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2727#issuecomment-1787571772,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2728?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@1083b36`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2728 +/- ##; ========================================; Coverage ? 72.00% ; ========================================; Files ? 103 ; Lines ? 11641 ; Branches ? 0 ; ========================================; Hits ? 8382 ; Misses ? 3259 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2728#issuecomment-1787613419:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2728#issuecomment-1787613419,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2738?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@d1fe8da`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2738 +/- ##; ========================================; Coverage ? 72.00% ; ========================================; Files ? 103 ; Lines ? 11642 ; Branches ? 0 ; ========================================; Hits ? 8383 ; Misses ? 3259 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2738#issuecomment-1801509928:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2738#issuecomment-1801509928,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2751?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@ec4d79f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2751 +/- ##; ========================================; Coverage ? 71.87% ; ========================================; Files ? 103 ; Lines ? 11635 ; Branches ? 0 ; ========================================; Hits ? 8363 ; Misses ? 3272 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2751#issuecomment-1808250177:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2751#issuecomment-1808250177,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2752?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@295d889`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2752 +/- ##; ========================================; Coverage ? 72.10% ; ========================================; Files ? 103 ; Lines ? 11635 ; Branches ? 0 ; ========================================; Hits ? 8389 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2752#issuecomment-1808445091:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2752#issuecomment-1808445091,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2774?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@70d55d5`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2774 +/- ##; ========================================; Coverage ? 72.11% ; ========================================; Files ? 103 ; Lines ? 11640 ; Branches ? 0 ; ========================================; Hits ? 8394 ; Misses ? 3246 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2774#issuecomment-1838034698:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2774#issuecomment-1838034698,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2783?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; > :exclamation: No coverage uploaded for pull request base (`1.9.x@4058e36`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit).; > The diff coverage is `n/a`. > :exclamation: Current head 09a432a differs from pull request most recent head 3b44d11. Consider uploading reports for the commit 3b44d11 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2783 +/- ##; ========================================; Coverage ? 17.51% ; ========================================; Files ? 103 ; Lines ? 11645 ; Branches ? 0 ; ========================================; Hits ? 2040 ; Misses ? 9605 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2783#issuecomment-1860972298:331,error,error-reference,331,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2783#issuecomment-1860972298,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2796?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > :exclamation: No coverage uploaded for pull request base (`1.9.x@1daae5b`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2796 +/- ##; ========================================; Coverage ? 71.35% ; ========================================; Files ? 103 ; Lines ? 11645 ; Branches ? 0 ; ========================================; Hits ? 8309 ; Misses ? 3336 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2796#issuecomment-1870329572:405,error,error-reference,405,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2796#issuecomment-1870329572,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2812?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > :exclamation: No coverage uploaded for pull request base (`1.9.x@518e76a`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.9.x #2812 +/- ##; ========================================; Coverage ? 71.34% ; ========================================; Files ? 103 ; Lines ? 11632 ; Branches ? 0 ; ========================================; Hits ? 8299 ; Misses ? 3333 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2812#issuecomment-1893321168:405,error,error-reference,405,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2812#issuecomment-1893321168,1,['error'],['error-reference']
Availability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2972?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; All modified and coverable lines are covered by tests :white_check_mark:; > :exclamation: No coverage uploaded for pull request base (`main@3ceb740`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#section-missing-base-commit). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2972 +/- ##; =======================================; Coverage ? 75.49% ; =======================================; Files ? 116 ; Lines ? 12911 ; Branches ? 0 ; =======================================; Hits ? 9747 ; Misses ? 3164 ; Partials ? 0 ; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2972#issuecomment-2029918769:422,error,error-reference,422,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2972#issuecomment-2029918769,1,['error'],['error-reference']
Availability,"### 1. Passing anndata objects to numpy and sklearn operators. I think this would be great! This would be easy to implement if python had generic functions. This is kinda something that's being worked on for numpy, but the assumptions a ufunc has about it's input data does not match with what an AnnData object is. I've worked on a side project of just wrapping the sklearn transformers so you can pass anndata objects, and could try and get that cleaned up for use if it'd be valuable. --------------------------------. I'm not really sure what you expect this line to do though:. ```python; adata[:, adata.var_names[0:3]] - adata[:, adata.var_names[3:6]]; ```. I would probably throw an error for that, since the var names wouldn't be the same. It's also not obvious to me which arrays would be subtracted (all of them? some of them?). If this is meant to do:. ```python; adata[:, adata.var_names[0:3]].X - adata[:, adata.var_names[3:6]].X; ```. I don't think that's so much more work. > I think it should return the whole AnnData object, like how DataFrames return themselves. I don't know if we think it should ""update"" the original AnnData. I'm also confused by how this results in a performance decrease?. If it should return the whole object, but not update the original, then all of the values from the original need to be copied to prevent unintentional modification. This is really expensive for large objects, which single cell datasets often are. For your example of `adata = np.sqrt(adata)` vs `adata_sq = np.sqrt(adata)`, there's no way for us to tell which of those statements was made while evaluating `np.sqrt`. That would require the ability to overload assignment, and for python to have different evaluation rules. ### 2. Requirement to use .var_vector or .obs_vector for single columns. Is what you're saying that you want: `adata[:, adata.var_names[0]].X` to be one dimensional?. This used to be the behaviour, but it got confusing quickly. Suddenly, `adata.X` could be a differ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-608231245:690,error,error,690,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-608231245,1,['error'],['error']
Availability,"### Test failures as of d36b977fa0c85d67b96799da4cb86b8582868048. Significantly improved!. 56 failed, 1236 passed, 96 skipped, 19 xfailed, 9 xpassed, 763 warnings in 595.02s (0:09:55). Remaining errors include:. * A lot of `AssertionError: Error: Image files did not match.`; * Some missing function from scipy; * Missing pynndescent; * 3 or 4 more unique ones. <details>; <summary> </summary>. ```python; FAILED scanpy/get/get.py::scanpy.get.get.obs_df; FAILED scanpy/plotting/_baseplot_class.py::scanpy.plotting._baseplot_class.BasePlot.add_totals; FAILED scanpy/tests/test_metrics.py::test_consistency[morans_i-allclose] - AssertionError: ; FAILED scanpy/tests/test_paga.py::test_paga_plots[-paga] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous-func1] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_obs-func2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_multiple-func3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_pie - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[umap] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:9,failure,failures,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,6,"['Error', 'error', 'failure']","['Error', 'errors', 'failures']"
Availability,"#2064 should do it. There seems to be some issues with recent builds of pytables. I've been having periodic trouble installing it, but had trouble reproducing the error when I tried. IIRC, the errors made me think it was some incompatibility between new versions of `pip`/ `setuptools` and old builds of `pytables` – but that wasn't on windows. @MxMstrmn has also mentioned seeing some issues with pytables installing on windows.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013006816:163,error,error,163,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013006816,2,['error'],"['error', 'errors']"
Availability,"#2733 bumps the minimum version **up** to 3.6 and adds two good reasons why that exact minimum version requirement is chosen:. 1. matplotlib’s maintenance schedule drops support for 3.5 in a little bit; 2. we use a feature from 3.5. If some piece of infrastructure doesn’t allow bumping versions of client libraries, that piece of infrastructure needs improvement. Jupyter allows distinct environments for kernels and the server for a reason. So while colab should be able to pin and use whatever they need on the server, there’s zero reason why colab should dictate any version of anything other than `ipykernel` for the user environment.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2413#issuecomment-1801466509:143,mainten,maintenance,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2413#issuecomment-1801466509,1,['mainten'],['maintenance']
Availability,"(Py_UNICODE *) PyUnicode_AsUnicode(; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:59: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; 12 warnings and 3 errors generated.; error: command '/usr/bin/clang' failed with exit code 1; [end of output]; ; note: This error originates from a subprocess, and is likely not a problem with pip.; WARNING: No metadata found in /Users/test/.local/lib/python3.10/site-packages; Rolling back uninstall of fa2; Moving to /Users/test/.local/lib/python3.10/site-packages/fa2-0.3.5.dist-info/; from /Users/test/.local/lib/python3.10/site-packages/~a2-0.3.5.dist-info; Moving to /Users/test/.local/lib/python3.10/site-packages/fa2/; from /Users/test/.local/lib/python3.10/site-packages/~a2; error: legacy-install-failure. × Encountered error while trying to install package.; ╰─> fa2. note: This is an issue with the package mentioned above, not pip.; hint: See above for output from the failure.; test@mac ~/PythonPackages/forceatlas2-0.3.5$; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:29933,error,errors,29933,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,7,"['error', 'failure']","['error', 'errors', 'failure']"
Availability,"* ; scanpy ; During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, varkwarg=None, target=None)"" at C:\ProgramData\Anaconda3\lib\site-packages\umap\layouts.py. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); computing neighbors; using 'X_pca' with n_pcs = 40; ; LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x000001FF1D57B970> (trying to write member #1). File ""C:\ProgramData\Anaconda3\lib\site-packages\umap\layouts.py"", line 53:; def rdist(x, y):; <source elided>; dim = x.shape[0]; for i in range(dim):; ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, varkwarg=None, target=None)"" at C:\ProgramData\Anaconda3\lib\site-packages\umap\layouts.py (53). TypeError Traceback (most recent call last); C:\ProgramData\Anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs); 822 try:; --> 823 yield; 824 except NumbaError as e:. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block); 264 loc=self.loc, errcls_=defaulterrcls):; --> 265 self.lower_inst(inst); 266 self.post_block(block). C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst); 438 ty = self.typeof(inst.target.name); --> 439 val = self.lower_assign(ty, inst); 440 argidx = None. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower_assign(self, ty, inst); 625 elif isinstance(value, ir.Expr):; --> 626 return self.lower_expr(ty, value); 627 . C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower_expr(self, resty, expr); 1161 elif expr.op == 'call':; -> 1162 res = self.lower_call(resty, expr); 1163 return res. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower_c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325:1067,error,errors,1067,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325,1,['error'],['errors']
Availability,"+1, I have the same error (on different data), which also only seems to appear when I don't filter to leave only the highly variable genes. In my case,. ```; np.any(adata.X.sum(axis=0) == 0); np.any(adata.X.sum(axis=1) == 0); ```; both return `False`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/667#issuecomment-519987040:20,error,error,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/667#issuecomment-519987040,1,['error'],['error']
Availability,", figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds); 215 # get the same order for rows and columns in the dot_color_df; 216 # using the order from the doc_size_df; --> 217 dot_color_df = dot_color_df.loc[dot_size_df.index][dot_size_df.columns]; 218 ; 219 self.dot_color_df = dot_color_df. /usr/local/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key); 929 ; 930 maybe_callable = com.apply_if_callable(key, self.obj); --> 931 return self._getitem_axis(maybe_callable, axis=axis); 932 ; 933 def _is_scalar_access(self, key: tuple):. /usr/local/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis); 1151 raise ValueError(""Cannot index with multidimensional key""); 1152 ; -> 1153 return self._getitem_iterable(key, axis=axis); 1154 ; 1155 # nested tuple slicing. /usr/local/lib/python3.9/site-packages/pandas/core/indexing.py in _getitem_iterable(self, key, axis); 1091 ; 1092 # A collection of keys; -> 1093 keyarr, indexer = self._get_listlike_indexer(key, axis); 1094 return self.obj._reindex_with_indexers(; 1095 {axis: [keyarr, indexer]}, copy=True, allow_dups=True. /usr/local/lib/python3.9/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis); 1312 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr); 1313 ; -> 1314 self._validate_read_indexer(keyarr, indexer, axis); 1315 ; 1316 if needs_i8_conversion(ax.dtype) or isinstance(. /usr/local/lib/python3.9/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis); 1375 ; 1376 not_found = list(ensure_index(key)[missing_mask.nonzero()[0]].unique()); -> 1377 raise KeyError(f""{not_found} not in index""); 1378 ; 1379 . KeyError: ""['B cells'] not in index""; ```. </details>. For `rankby_abs` it does error, but is that a valid argument to pass to this function?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911:4321,error,error,4321,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911,1,['error'],['error']
Availability,", tolerance, method, fill_value, copy; 4813 ).__finalize__(self, method=""reindex""); 4814 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4021 if index is not None:; 4022 frame = frame._reindex_index(; -> 4023 index, method, copy, level, fill_value, limit, tolerance; 4024 ); 4025 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance); 4043 copy=copy,; 4044 fill_value=fill_value,; -> 4045 allow_dups=False,; 4046 ); 4047 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups); 4881 fill_value=fill_value,; 4882 allow_dups=allow_dups,; -> 4883 copy=copy,; 4884 ); 4885 # If we've made a copy once, no need to make another one. ~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice); 1299 # some axes don't allow reindexing with dups; 1300 if not allow_dups:; -> 1301 self.axes[axis]._can_reindex(indexer); 1302 ; 1303 if axis >= self.ndim:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in _can_reindex(self, indexer); 3475 # trying to reindex on an axis with duplicates; 3476 if not self._index_as_unique and len(indexer):; -> 3477 raise ValueError(""cannot reindex from a duplicate axis""); 3478 ; 3479 def reindex(self, target, method=None, level=None, limit=None, tolerance=None):. ValueError: cannot reindex from a duplicate axis; ```; Loading a single h5 file works and produces expected output:; ```; a = sc.read_10x_h5('./a.h5', gex_only = True); a; AnnData object with n_obs × n_vars = 7474 × 31053; var: 'gene_ids', 'feature_types', 'genome'; ```. So the input files appear to be valid I just can't get them to concatenate to a single object. . Any ideas would be welcome.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683:4412,toler,tolerance,4412,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683,1,['toler'],['tolerance']
Availability,-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_nor,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3976,ERROR,ERROR,3976,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,"-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; Running command python setup.py egg_info; Traceback (most recent call last):; File ""<string>"", line 2, in <module>; File ""<pip-setuptools-caller>"", line 34, in <module>; File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; pr",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:2686,error,error,2686,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,2,['error'],['error']
Availability,-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambd,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4562,ERROR,ERROR,4562,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,"-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/; Complete output (15 lines):; running bdist_wheel; /home/mischko/test/python_virtual/bin/python /tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/ffi/build.py; LLVM version... 11.1.0; ; Traceback (most recent call last):; File ""/tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/ffi/build.py"", line 191, in <module>; main(); File ""/tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/ffi/build.py"", line 181, in main; main_posix('linux', '.so'); File ""/tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/ffi/build.py"", line 143, in main_posix; raise RuntimeError(msg); RuntimeError: Building llvmlite requires LLVM 10.0.x or 9.0.x, got '11.1.0'. Be sure to set LLVM_CONFIG to the right executable path.; Read the documentation at http://llvmlite.pydata.org/ for more information about building llvmlite.; ; error: command '/home/mischko/test/python_virtual/bin/python' failed with exit code 1; ; ERROR: Failed building wheel for llvmlite; ```. </details>. Any ideas about that?. When using **python 3.8** in a fresh new virtual environment, I get, installation of the development version works fine, but when importing scvelo. `Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/mischko/test/python_virtual/lib/python3.8/site-packages/scvelo/__init__.py"", line 5, in <module>; from scvelo import datasets, logging, pl, pp, settings, tl, utils; File ""/home/mischko/test/python_virtual/lib/python3.8/site-packages/scvelo/datasets.py"", line 10, in <module>; from scvelo.core import cleanup, SplicingDynamics; File ""/home/mischko/test/python_virtual/lib/python3.8/site-packages/scvelo/core/__init__.py"", line 1, in <module>; from ._anndata import (; File ""/home/mischko/test/python_virtual/lib/python3.8/site-packages/scvelo/core/_anndata.py"", line 4, in <module>; from typing_extensions import Literal; ModuleNotFoundError: No module named 't",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799#issuecomment-830137752:1909,error,error,1909,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799#issuecomment-830137752,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,". **random_state** : typing.Union[int, mtrand.RandomState, NoneType]. A numpy random seed. **method** : {'umap', 'gauss', `None`} (default: `'umap'`). Use 'umap' [McInnes18]_ or 'gauss' (Gauss kernel following [Coifman05]_; with adaptive width [Haghverdi16]_) for computing connectivities. **metric** : typing.Union[str, typing.Callable[[numpy.ndarray, numpy.ndarray], float]], optional (default: 'euclidean'). A known metric’s name or a callable that returns a distance. **metric_kwds** : Mapping. Options for the metric. **copy** : bool. Return a copy instead of writing to adata. :Returns:. Depending on `copy`, updates or returns `adata` with the following:. . **connectivities** : sparse matrix (`.uns['neighbors']`, dtype `float32`). Weighted adjacency matrix of the neighborhood graph of data; points. Weights should be interpreted as connectivities. **distances** : sparse matrix (`.uns['neighbors']`, dtype `float32`). Instead of decaying weights, this stores distances for each pair of; neighbors.; File: ~/_hholtz/01_projects/1512_scanpy/scanpy/scanpy/neighbors/__init__.py; Type: function; ```. PS: ; - Already the [docs](http://scanpy.readthedocs.io/en/latest/api/scanpy.api.Neighbors.compute_neighbors.html) show that `Neighbors.compute_neighbors` has invalid numpydoc... this was the case in several instances and I'm slowly fixing all of them... It's just a matter of adding `\` at the line breaks.; - I completely agree that the redundency between signature and docstring information lead to a a very small number of errors in the docstrings. However, in several instances, I'm setting the default value in the signature to `None`. But in the docstring, I'm giving the value to which this `None` evaluates in the default case (depending on what is passed)... There is quite a number of such cases. Clearly, one could replace all of them with `'auto'` parameters, which is probably the better way of doing this. As the whole thing is backwards compat, this is not an immediate problem",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/192#issuecomment-404108999:7690,error,errors,7690,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192#issuecomment-404108999,1,['error'],['errors']
Availability,". . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds); 367 ; 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); 370 scores[np.isnan(scores)] = 0; 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error; ```. P.S I just want to say thank you for all the work on Scanpy, loving it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611:1156,error,error,1156,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611,1,['error'],['error']
Availability,". ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func); 219 with typeinfer.register_dispatcher(disp):; 220 for sig in sigs:; --> 221 disp.compile(sig); 222 disp.disable_compile(); 223 return disp. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig); 907 with ev.trigger_event(""numba:compile"", data=ev_details):; 908 try:; --> 909 cres = self._compiler.compile(args, return_type); 910 except errors.ForceLiteralArg as e:; 911 def folded(args, kws):. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 77 ; 78 def compile(self, args, return_type):; ---> 79 status, retval = self._compile_cached(args, return_type); 80 if status:; 81 return retval. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 91 ; 92 try:; ---> 93 retval = self._compile_core(args, return_type); 94 except errors.TypingError as e:; 95 self._failed_cache[key] = e. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 104 ; 105 impl = self._get_implementation(args, {}); --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,; 107 self.targetdescr.target_context,; 108 impl,. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 602 compiler pipeline; 603 """"""; --> 604 pipeline = pipeline_class(typingctx, targetctx, library,; 605 args, return_type, flags, locals); 606 return pipeline.compile_extra(func). ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/compiler.py in __init__(self, typingctx, targetctx, library, args, return_type, flags, locals); 308 config.reload_config(); 309 typingctx.refresh(); --> 310 targetctx.refresh(); 311 ; 312 self.s",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-846931466:3324,error,errors,3324,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-846931466,1,['error'],['errors']
Availability,".); 768 **kwds,; 769 ):; 770 """"""\; 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`); 772 ; (...); 872 tl.rank_genes_groups; 873 """"""; --> 874 return _rank_genes_groups_plot(; 875 adata,; 876 plot_type='dotplot',; 877 groups=groups,; 878 n_genes=n_genes,; 879 groupby=groupby,; 880 values_to_plot=values_to_plot,; 881 var_names=var_names,; 882 gene_symbols=gene_symbols,; 883 key=key,; 884 min_logfoldchange=min_logfoldchange,; 885 show=show,; 886 save=save,; 887 return_fig=return_fig,; 888 **kwds,; 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 529 values_df = None; 530 if values_to_plot is not None:; --> 531 values_df = _get_values_to_plot(; 532 adata,; 533 values_to_plot,; 534 var_names_list,; 535 key=key,; 536 gene_symbols=gene_symbols,; 537 ); 538 title = values_to_plot; 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols); 1629 message = (; 1630 ""Please run `sc.tl.rank_genes_groups` with ""; 1631 ""'n_genes=adata.shape[1]' to save all gene ""; 1632 f""scores. Currently, only {df.shape[0]} ""; 1633 ""are found""; 1634 ); 1635 logg.error(message); -> 1636 raise ValueError(message); 1637 df['group'] = group; 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3049#issuecomment-2107618181:2683,error,error,2683,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049#issuecomment-2107618181,1,['error'],['error']
Availability,...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - Impo,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69739,ERROR,ERROR,69739,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - Im,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65650,ERROR,ERROR,65650,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,..; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:70872,ERROR,ERROR,70872,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,..; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normal,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63513,ERROR,ERROR,63513,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,..; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportErr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69405,ERROR,ERROR,69405,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,.; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61060,ERROR,ERROR,61060,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:4242,Error,Error,4242,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/tes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:73172,ERROR,ERROR,73172,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_me,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63016,ERROR,ERROR,63016,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - I,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:60404,ERROR,ERROR,60404,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERRO,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:70538,ERROR,ERROR,70538,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scan,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:70705,ERROR,ERROR,70705,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66292,ERROR,ERROR,66292,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"/scanpy/lib/python3.9/functools.py:888: in wrapper; > return dispatch(args[0].__class__)(*args, **kw); > scanpy/preprocessing/_simple.py:888: in scale_anndata; > X, adata.var[""mean""], adata.var[""std""] = do_scale(; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; > error_rewrite(e, 'typing'); > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ; > e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); > issue_type = 'typing'; > ; > def error_rewrite(e, issue_type):; > """"""; > Rewrite and raise Exception `e` with help supplied based on the; > specified issue_type.; > """"""; > if config.SHOW_HELP:; > help_msg = errors.error_extras[issue_type]; > e.patch_message('\n'.join((str(e).rstrip(), help_msg))); > if config.FULL_TRACEBACKS:; > raise e; > else:; > > raise e.with_traceback(None); > E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); > E non-precise type pyobject; > E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); > E ; > E File ""scanpy/preprocessing/_simple.py"", line 763:; > E def do_scale(X, maxv, nthr):; > E <source elided>; > E # t0= time.time(); > E s = np.zeros((nthr, X.shape[1])); > E ^ ; > E ; > E This error may have been caused by the following argument(s):; > E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>; > ; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; > ```; > ; > When trying to use the new flavor with the existing test. Hi @Zethson ,; We are not able to see this issue with the ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717:1925,error,errors,1925,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717,1,['error'],['errors']
Availability,/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/tes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:72514,ERROR,ERROR,72514,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74643,ERROR,ERROR,74643,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:67117,ERROR,ERROR,67117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] -,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:4134,Error,Error,4134,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,/tests/test_plotting.py::test_scatterplots[pca_markers_colors_with_dimensions-fn10] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[umap_with_edges-fn17] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_mask-fn19] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_groups_and_size - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/te,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:55068,ERROR,ERROR,55068,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65161,ERROR,ERROR,65161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - I,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74170,ERROR,ERROR,74170,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"0].__class__)(*args, **kw); > scanpy/preprocessing/_simple.py:888: in scale_anndata; > X, adata.var[""mean""], adata.var[""std""] = do_scale(; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; > error_rewrite(e, 'typing'); > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ; > e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); > issue_type = 'typing'; > ; > def error_rewrite(e, issue_type):; > """"""; > Rewrite and raise Exception `e` with help supplied based on the; > specified issue_type.; > """"""; > if config.SHOW_HELP:; > help_msg = errors.error_extras[issue_type]; > e.patch_message('\n'.join((str(e).rstrip(), help_msg))); > if config.FULL_TRACEBACKS:; > raise e; > else:; > > raise e.with_traceback(None); > E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); > E non-precise type pyobject; > E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); > E ; > E File ""scanpy/preprocessing/_simple.py"", line 763:; > E def do_scale(X, maxv, nthr):; > E <source elided>; > E # t0= time.time(); > E s = np.zeros((nthr, X.shape[1])); > E ^ ; > E ; > E This error may have been caused by the following argument(s):; > E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>; > ; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; > ```; > ; > When trying to use the new flavor with the existing test. Hi @Zethson ,; We are not able to see this issue with the latest commit. Can you please retry with the latest commit in scale branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717:2116,error,errors,2116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717,2,['error'],"['error', 'errors']"
Availability,"1. No, I have sampled cells with weights, out of those 1000 rows most; having weight=1, e.g. 1 row has weight 125, then in gene ranking the; expression all genes will multiplied with that specific weight of cell, so; I updated code by calculated weighted mean and variance. Before updating; this I was getting wrong marker genes. Same for plotting points in dotplot,; stacked_violin and heatmap. 2. I suggest that scanpy should support weighted data, I mean PCA should; also be computed for data with weighted observations (PCA in matlab support; weighted observations). Currently my input is weighted PCA data for; clustering, so I don't need to update PCA code, but in future it will be a; good thing to support scanpy for weighted sampled data as well. Thanks,; Khalid. On Tue, May 21, 2019 at 3:00 AM MalteDLuecken <notifications@github.com>; wrote:. > So you want to e.g., downweight the likelihood of sampling cells with a; > particular feature (like a common cell type), and upweight others. What do; > you want to use this weighting for now in the sc.tl.rank_genes_groups; > function? Or in the visualization functions you changed?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGOHR7Q62WL6MCWX7UWTPWLYOLA5CNFSM4HMZ5G72YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVZYS3I#issuecomment-494111085>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOHHMFZBUTLM4VIJCTLPWLYOLANCNFSM4HMZ5G7Q>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494119134:878,down,downweight,878,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494119134,1,['down'],['downweight']
Availability,2-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_violin_without_raw - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_path - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[pca] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_highly_variable_genes.py::test_high,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:44497,Error,Error,44497,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"20 formatter,. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in format_array(values, formatter, float_format, na_rep, digits, space, justify, decimal, leading_space, quoting); 1238 ); 1239 ; -> 1240 return fmt_obj.get_result(); 1241 ; 1242 . ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in get_result(self); 1269 ; 1270 def get_result(self) -> list[str]:; -> 1271 fmt_values = self._format_strings(); 1272 return _make_fixed_width(fmt_values, self.justify); 1273 . ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in _format_strings(self); 1516 ; 1517 def _format_strings(self) -> list[str]:; -> 1518 return list(self.get_result_as_array()); 1519 ; 1520 . ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in get_result_as_array(self); 1480 float_format = lambda value: self.float_format % value; 1481 ; -> 1482 formatted_values = format_values_with(float_format); 1483 ; 1484 if not self.fixed_width:. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in format_values_with(float_format); 1454 values = self.values; 1455 is_complex = is_complex_dtype(values); -> 1456 values = format_with_na_rep(values, formatter, na_rep); 1457 ; 1458 if self.fixed_width:. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in format_with_na_rep(values, formatter, na_rep); 1425 mask = isna(values); 1426 formatted = np.array(; -> 1427 [; 1428 formatter(val) if not m else na_rep; 1429 for val, m in zip(values.ravel(), mask.ravel()). ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in <listcomp>(.0); 1426 formatted = np.array(; 1427 [; -> 1428 formatter(val) if not m else na_rep; 1429 for val, m in zip(values.ravel(), mask.ravel()); 1430 ]. ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); ```; </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2008#issuecomment-947943666:10529,mask,mask,10529,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008#issuecomment-947943666,3,['mask'],['mask']
Availability,"4 impl,. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 714 pipeline = pipeline_class(typingctx, targetctx, library,; 715 args, return_type, flags, locals); --> 716 return pipeline.compile_extra(func); 717 ; 718 . C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func); 450 self.state.lifted = (); 451 self.state.lifted_from = None; --> 452 return self._compile_bytecode(); 453 ; 454 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self); 518 """"""; 519 assert self.state.func_ir is None; --> 520 return self._compile_core(); 521 ; 522 def _compile_ir(self):. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 497 self.state.status.fail_reason = e; 498 if is_final_pipeline:; --> 499 raise e; 500 else:; 501 raise CompilerError(""All available pipelines exhausted""). C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 484 res = None; 485 try:; --> 486 pm.run(self.state); 487 if self.state.cr is not None:; 488 break. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 366 (self.pipeline_name, pass_desc); 367 patched_exception = self._patch_error(msg, e); --> 368 raise patched_exception; 369 ; 370 def dependency_analysis(self):. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 354 pass_inst = _pass_registry.get(pss).pass_inst; 355 if isinstance(pass_inst, CompilerPass):; --> 356 self._runPass(idx, pass_inst, state); 357 else:; 358 raise BaseException(""Legacy pass in use""). C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 33 def _acquire_compile_lock(*args, **kwargs):; 34 with self:; ---> 35 r",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325:8284,avail,available,8284,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325,1,['avail'],['available']
Availability,"52 loess_outputs, loess_prediction,; 53 loess_confidence_intervals, loess_anova). ImportError: DLL load failed while importing _loess: The specified module could not be found.; ```; Step5: run `import skmisc; print(skmisc.__file__)`; ```python; import skmisc; print(skmisc.__file__); C:\Users\Park_Lab\AppData\Roaming\Python\Python38\site-packages\skmisc\__init__.py; ```; Step6: due to Step4, I follow the solution (https://github.com/has2k1/scikit-misc/issues/4) to install Numpy with mkl.; ```python; (base) C:\Users\Park_Lab>conda activate Python38; (Python38) C:\Users\Park_Lab>cd Downloads/; (Python38) C:\Users\Park_Lab\Downloads>pip install numpy-1.21.5+mkl-cp38-cp38-win_amd64.whl; Processing c:\users\park_lab\downloads\numpy-1.21.5+mkl-cp38-cp38-win_amd64.whl; Installing collected packages: numpy; Attempting uninstall: numpy; Found existing installation: numpy 1.21.5; Uninstalling numpy-1.21.5:; Successfully uninstalled numpy-1.21.5; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.21.5+mkl which is incompatible.; Successfully installed numpy-1.21.5+mkl; ```; Step7: check anaconda Python38 environment, numpy-1.21.5+mkl is successfully installed; ![image](https://user-images.githubusercontent.com/75048821/147306587-eb94c188-5c18-40f0-add0-3a899872d786.png). Step8: Scanpy import error. Numpy>v1.20 is conflicted with Scanpy; ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600); ; import scvelo as scv; scv.settings.verbosity = 3; scv.settings.presenter_view = True; scv.logging.print_versions(). import cellrank as cr; cr.settings.verbosity = 3; cr.logging.print_versions(). import matplotlib.pyplot as pl; from matplotlib impor",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342:4708,ERROR,ERROR,4708,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342,1,['ERROR'],['ERROR']
Availability,"6f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; Running command python setup.py egg_info; Traceback (most recent call last):; File ""<string>"", line 2, in <module>; File ""<pip-setuptools-caller>"", line 34, in <module>; File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:2835,error,error,2835,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['error'],['error']
Availability,: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - Assertion,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:3994,Error,Error,3994,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[r,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:2959,Error,Error,2959,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,:smile: Now this raises a proper error message: https://github.com/theislab/scanpy/commit/2490bec27c1c37e1388cb1da44369c81e176df6c,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/88#issuecomment-366287782:33,error,error,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88#issuecomment-366287782,1,['error'],['error']
Availability,"; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-39-2ee11f6b7699> in <module>; ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs); 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 725 """"""; --> 726 return embedding(adata, 'pca', **kwargs); 727 ; 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 226 itertools.product(color, idx_components); 227 ):; --> 228 color_vector, categorical = _get_color_values(; 229 adata,; 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer); 1031 ):; 1032 # We should probably just make an index for this, and share it over runs; -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][; 1034 0; 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key); 4095 if is_scalar(key):; 4096 key = com.cast_scalar_indexer(key, warn_float=True); -> 4097 return getitem(key); 4098 ; 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1277#issuecomment-703860357:1661,error,error,1661,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277#issuecomment-703860357,1,['error'],['error']
Availability,"; 314 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs); 4174 kwargs.pop(""axis"", None); 4175 kwargs.pop(""labels"", None); -> 4176 return super().reindex(**kwargs); 4177 ; 4178 def drop(. ~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4810 # perform the reindex on the axes; 4811 return self._reindex_axes(; -> 4812 axes, level, limit, tolerance, method, fill_value, copy; 4813 ).__finalize__(self, method=""reindex""); 4814 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4021 if index is not None:; 4022 frame = frame._reindex_index(; -> 4023 index, method, copy, level, fill_value, limit, tolerance; 4024 ); 4025 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance); 4043 copy=copy,; 4044 fill_value=fill_value,; -> 4045 allow_dups=False,; 4046 ); 4047 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups); 4881 fill_value=fill_value,; 4882 allow_dups=allow_dups,; -> 4883 copy=copy,; 4884 ); 4885 # If we've made a copy once, no need to make another one. ~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice); 1299 # some axes don't allow reindexing with dups; 1300 if not allow_dups:; -> 1301 self.axes[axis]._can_reindex(indexer); 1302 ; 1303 if axis >= self.ndim:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in _can_reindex(self, indexer); 3475 # trying to reindex on an axis with duplicates; 3476 if not self._index_as_unique and len(indexer):; -> 3477 raise ValueError(""cannot reindex from a duplicate axis""); 3478 ; 3479 de",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683:3340,toler,tolerance,3340,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683,1,['toler'],['tolerance']
Availability,; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - Impor,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61712,ERROR,ERROR,61712,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_ut,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66946,ERROR,ERROR,66946,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"> 'outline' could be good. We already have font outline that works similarly. Great!. > Can you take a look at the new type hints that I added. I am not sure if I did it right?. The typing is pretty good! There’s one rule I follow, which is to be specific:. - If your function has parameter `a`, does `for elem in a`, and expects `elem`s to be `str`s, you can say `Iterable[str]`. If you use `a[i]`, say `Sequence[str]`. You don’t want to artificially limit the user by saying you need a `List[str]` if a `Tuple[str]` can be passed or even any `Iterator[str]` is sufficient.; - If you say what you *return*, be concrete, e.g. `List[str]`. You know what exact type you return.; - If you accept a callable, specify its signature: `Callable[[ArgType1, ArgType2], RetType]`. There’s nothing more annoying than to dive into the code because the library doesn’t specify what kind of function you can supply. So you should change. - `callable`→`Callable[[???], ?]`; - `Sequence`→`Sequence[?]`; - `Optional[dict]`→`Optional[Mapping[?, ?]]`. Also stylewise: Once `(` and `)` aren on separate lines, never have anything after `(`, and before `)`:. ```py; def _get_vmin_vmax(; […]; color_vector: Sequence[float],; ):; '''; […]; ```. ```py; logg.error(; ""The parameter […]""; […]; ""of plots.""; ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/794#issuecomment-523541089:1234,error,error,1234,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794#issuecomment-523541089,1,['error'],['error']
Availability,"> (1) Any user doing data processing or interactive analysis could benefit from multithreading here. Consider the two big for-loops which through all of the genes between compared in the samples, and the for loop which automatically does this for each ""group"" in the ScanPy object. My concern is that there will be issues if you keep the current calculations, but parallelize over the groups. Within that loop, I believe large amounts of memory can be allocated. If it's ""group vs rest"", at least one `X` worth of memory is allocated per loop from matrix subsetting – since there's an `X_group = X[mask]; X_rest = X[~mask]`. If you parallelize over groups, now the max memory usage can be `~ min(n_procs, n_groups) * X` as opposed to `~2X`. For large `X` (probably where you want to see the speed up most), this can make you run out of memory. https://github.com/scverse/scanpy/blob/d26be443373549f26226de367f0213f153556915/scanpy/tools/_rank_genes_groups.py#L164-L178. Another memory related concern comes from `multiprocessing` (mentioned in your email). I think there's recently been some improvement here, but my impression was it's difficult/ impossible to share memory with `multiprocessing` – so everything that goes into or out of a subprocess has to be copied. So while I think we can absolutely make use of more processing power here, I think we need to consider the approach. * The link I mentioned above should reduce copies, and could potentially use a parallelized BLAS for compute; * Much of the loops over ""all of the genes between compared samples"" are already in compiled code, but could be parallelized. > In terms of our use case, an interactive way to run DE via the client is too slow. What is the interface here? Scanpy computes results for all groups at once, but in most interfaces I've used you can only really ""ask"" for one comparison at a time. This could also be much faster, if you can just reduce total computation. ---------. > What @ivirshup was referring to though, i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2390#issuecomment-1397484486:598,mask,mask,598,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390#issuecomment-1397484486,2,['mask'],['mask']
Availability,"> (a) a pair of completely correlated features, and (b) very strange count distributions. can you elaborate more on this? what does it mean ""completely correlated"", like an identical copy ?. > Once I used a proper variance stabilizing transform (arcsinh in this case) and remove redundant features. Interesting, never seen this used in scRNA-seq, is it common in IMC ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696#issuecomment-802666323:279,redundant,redundant,279,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696#issuecomment-802666323,1,['redundant'],['redundant']
Availability,"> * Make a case where a threshold can't be found (not sure how this would be done). Obviously I can test the plotting by directly unsetting the relevant things, but I'm not actually sure how to trigger a failure with the test data I'm afraid.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2023#issuecomment-963035287:204,failure,failure,204,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2023#issuecomment-963035287,1,['failure'],['failure']
Availability,"> . Hi, @jlause . There's a issue when using `normalize_pearson_residuals`, it seems that we can't calculated the `log2foldchange` in `rank_genes_groups` will be failed. That's because `np.expm1` can't restore the `adata.X` after `normalize_pearson_residuals`. Could you solve this issue that completed the downstream currently?. <img width=""770"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/46667721/a8e64ab1-360d-43a2-a07b-a766049bcbcd"">",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-1578401813:307,down,downstream,307,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-1578401813,1,['down'],['downstream']
Availability,"> ; > ; > #530 also related. Are you including the `log_transformed=True` kwarg in your call to `rank_genes_groups()`?. oh, I'm not. But when I included it, the ’ValueError: math domain‘ error still appeared.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/952#issuecomment-567379722:187,error,error,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/952#issuecomment-567379722,1,['error'],['error']
Availability,"> ; > ; > Seen this recently exactly on a windows laptop. Not sure but sound like something messed up with the environment, are you working on the base env? Try creating a fresh conda environment and installing scanpy there. Thanks for the suggestion, @giovp. Was doing it in the base env earlier. Made a new env and tried it again, but ran into the same exact error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147#issuecomment-609495323:361,error,error,361,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147#issuecomment-609495323,1,['error'],['error']
Availability,"> ; > ; > Thanks for your response. As of today that's correct: AWS, GCP and DO. Azure support is a work in progress at the moment. It should be available by the end of this month most likely. Do you have a hard deadline on this?. No we don't. But before using it Cirun I would have to look at more closely first.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1793#issuecomment-882740958:145,avail,available,145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793#issuecomment-882740958,1,['avail'],['available']
Availability,"> ; > ; > What's your version of `numba` in this environment?. It's version 0.48.0, @ivirshup. For what it's worth, the build is py38he350917_0 and the source is conda-forge. (In the base environment where I was getting the same error, the version is the same but the build is py37h47e9c7a_0.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147#issuecomment-610413337:229,error,error,229,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147#issuecomment-610413337,1,['error'],['error']
Availability,"> > > Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb.; > > > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters.; > > > Hope this helps 😊; > > ; > > ; > > Hi, the link seems to be invalid. Is there any alternative links?; > ; > Would you please try this link? https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb. Great help. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2973#issuecomment-2041349621:377,down,download,377,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973#issuecomment-2041349621,1,['down'],['download']
Availability,"> > Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb.; > > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters.; > > Hope this helps 😊; > ; > Hi, the link seems to be invalid. Is there any alternative links?. Would you please try this link? https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2973#issuecomment-2041346736:373,down,download,373,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973#issuecomment-2041346736,1,['down'],['download']
Availability,"> > I'm actually testing and tweaking someone else's code that was written a while ago. I assume they used; > > `import scanpy.api as sc` because it was appropriate then. I personally resolved my issue by downgrading versions, I just wanted to bring this up!; > ; > I encountered the same issue. Which version are you using to fix this?. nm, downgrading to 1.5.1 fixed my problem. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1397#issuecomment-684933191:205,down,downgrading,205,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1397#issuecomment-684933191,2,['down'],['downgrading']
Availability,"> > In the other word, the scvelo's 'scv.pl.velocity_embedding_stream' showing terminal differentiation cells develop to original cells. this was incorrected logically. why the scvelo showed the inverted result contrast with monocle result.; > ; > As @LuckyMD said, this is a question for `scvelo`.; > ; > > I guess what i make the cell order was wrong ?; > ; > The best way to check if ordering went wrong is to plot an embedding colored by some known grouping. If colors are all mixed up you know a mistake has done.; > ; > > i wonder whether the code just sorted the cell barcode on annData.obs but the annData.X's matrix? why was the order runing so quickly that the matrix of annData not be sorted at the same time?; > ; > Luckily `AnnData` is quite robust and it reorder any slot (`obs`, `obsp`, `obsm`…) according to the specified cell names.; > ; > d; Thanks i would check currently, and reported the result as soon as possible. ; Best,; hanhuihong",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1718#issuecomment-802436872:755,robust,robust,755,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1718#issuecomment-802436872,1,['robust'],['robust']
Availability,"> > Numba can’t correctly detect when a threading backend is available; >; > Is there a numba issue for this?. https://github.com/numba/numba/issues/6108, This issue may be specific to `tbb`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1931#issuecomment-874667150:61,avail,available,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931#issuecomment-874667150,1,['avail'],['available']
Availability,> > Why have separate package registries for biology vs everything else?; >; > probably because bioconda predates conda-forge?. That would make sense! I think things like bioconda and the bioconductor registry were good things to start and have been very important. I just think some of the initial design decisions are now outdated. > The only downside of this is that we need to update that file manually for every release of scanpy/ anndata. Seems github action-able?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160598574:345,down,downside,345,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160598574,1,['down'],['downside']
Availability,"> > ```python; > > scipy.io.mmwrite; > > ```; > ; > This code doesn't actually work - rows and columns are switched in the matrix, and it produces an error when you try to read in the output using either `Scanpy` or `Seurat` wrapper functions. Perhaps it's a package version thing though.. I was having the same issue as well. I ended up doing what was suggested above:. `adata.T.to_df().to_csv('matrix.csv')`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/262#issuecomment-1520696083:150,error,error,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/262#issuecomment-1520696083,1,['error'],['error']
Availability,"> @Sunyiqing2003 we certainly don’t want you crying!; > ; > people here had problem reading with older anndata versions, but you seem to have the newest one, so it’s not the same issue. could you file a new issue?. Thank you for your time and attention , I really appreciate it. I have filed a new issue : [https://github.com/scverse/scanpy/issues/2551](url). I might know the reason why updating anndata didn't work. the main reason for me seems to be big array and memory error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-1628515570:474,error,error,474,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-1628515570,1,['error'],['error']
Availability,"> @THZ34 can you create a reproducer where this happens, so I can add a test?. OK, I've upload the h5ad file to onedrive: https://bioplot-my.sharepoint.com/:u:/g/personal/tanghongzhen_bioplot_onmicrosoft_com/EUbNHPuin5pGuMPrmch6rsQBjHojfikr38EYgZEL4KAZ2A?e=T2YfkO.; The error will reapper in these code:; import anndata; import scanpy as sc; adata = ad.read_h5ad('debug.h5ad'); sc.tl.dendrogram(adata,groupby='leiden')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2804#issuecomment-2014432043:270,error,error,270,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2804#issuecomment-2014432043,1,['error'],['error']
Availability,"> @WeilerP, do you think this would be more appropriate in `scvelo`? (Side note, I have thought that tutorial; > of going from BAMs through `scvelo` would be quite useful). Hm, not sure if the functionality would match the expectation. In `scvelo`, we'd store only unspliced and spliced counts (spliced both in `adata.X` and `adata.layers`). Based on the proposed code snippet in [alexdobin/STAR#774 (comment)](https://github.com/alexdobin/STAR/issues/774#issuecomment-850477636), the expected output would be to read all of the available information?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1860#issuecomment-873990253:529,avail,available,529,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1860#issuecomment-873990253,1,['avail'],['available']
Availability,"> @Zethson I believe that's an upstream issue. Looks like the docs broke when `sphinx-autodoc-typehints` bumped versions from `1.12.0` to `1.13.0`.; > ; > I can build the docs locally from `master` and from this branch with `sphinx-autodoc-typehints` v1.12, but not v1.13. (You'll also see an identical error in #2099, despite that just being a dependency bump for pre-commit.); > ; > I'll submit a PR to pin `sphinx-autodoc-typehints` to version 1.12.0 shortly. Thank you for taking the time to dig into this! Much appreciated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1828#issuecomment-1005073549:303,error,error,303,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1828#issuecomment-1005073549,1,['error'],['error']
Availability,"> @awnimo , for me test_phenograph.py fails with `E TypeError: Expected list, got numpy.ndarray`.; > Could you check please?; > This is certainly related to scipy 1.5. With scipy 1.4 the test works fine. Indeed, this error is related to scipy, and we have fixed that in Phenograph new release [1.5.7](https://github.com/dpeerlab/PhenoGraph#version-157). The `test_phenograph.py` does not fail with the new Phenograph release (`pip install -U phenograph`)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1080#issuecomment-703773746:217,error,error,217,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080#issuecomment-703773746,1,['error'],['error']
Availability,"> @brainfo I'm afraid that we only speak English. Hi sorry and indeed that's an automatic reply from the email service I just changed the email address so this would not be a problem later. To add one more problem encountered when writing out anndata object: ; When the anndata has 'predicted_doublet' in obs annotation from sc.external.pp.scrublet, the boolean values could not be implicitly converted to strings so that gives errors: . ```{py}; TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'predicted_doublet' of <class 'h5py._hl.group.Group'> to /; ```. Users can map the values like this but would it be better to have the implicit conversion while read/write anndatas?; ```{py}; anndata.obs['predicted_doublet'] = anndata.obs['predicted_doublet'].map({True: 'True', False: 'False'}); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2383#issuecomment-1367301208:428,error,errors,428,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383#issuecomment-1367301208,2,['error'],"['error', 'errors']"
Availability,"> @brianpenghe, do you have a copy of your original file? Any idea what could have been different?; > ; > @dn-ra, would you be able to share the first couple lines of your file, and let me know how it was generated?. I think I found the cause: ; When the genes.tsv only has one column it doesn't work and throws this error. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2053#issuecomment-984799011:317,error,error,317,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2053#issuecomment-984799011,1,['error'],['error']
Availability,> @fidelram Thank you for your suggestions! The example data in Scanpy worked without flaw. I will go over my code again!. Actually I solved this problem by adding more markers in the marker gene list. ; Alternatively The error will be gone if I `swap_axes=True`; Interesting,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/405#issuecomment-470945339:222,error,error,222,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405#issuecomment-470945339,1,['error'],['error']
Availability,"> @hurleyLi, would you mind opening an issue over on umap that you're unable to get a `__version__` from it? It would be nice to have that fixed/ at least tracked down upstream. Figure it out. In my case it's because I have both `umap` and `umap-learn` installed, see here: https://github.com/theislab/scanpy/issues/2045#issuecomment-963533994",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1978#issuecomment-963537478:163,down,down,163,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978#issuecomment-963537478,1,['down'],['down']
Availability,"> @ivirshup @LuckyMD; > I fixed the problem - the issue was in the original h5ad file converted from a Seurat object using SeuratDisk::Convert(). It seems the var data wasn't ported over properly for the assay I was using. I rebuilt the h5ad file using reticulate instead and that solved the problem. I have encountered the same issue as @mosquitoCat .; Although adata.var_names still returns correct gene symbols, all my name IDs become numbers:; for example, sc.pl.umap(adata,color='GeneName') will return errors. but sc.pl.umap(adata,color='123') can be recognized.; SeuratDisk::Convert() seems to cause some trouble here. Is there a way to fix it? @ivirshup",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/914#issuecomment-852691627:508,error,errors,508,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/914#issuecomment-852691627,1,['error'],['errors']
Availability,"> @ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting. https://github.com/BGIResearch/stereopy/blob/6345d2732772a58d60351e790058bd5da1301fb5/requirements.txt#L26",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1452144253:167,error,error,167,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1452144253,1,['error'],['error']
Availability,"> A downside of this is it takes a really long time to compile on first run, which might be off-putting. Right, numba only compiles stuff when first run (because otherwise it can’t know the types) so this doesn’t slow down importing scanpy. > So... probably worth it?. We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary. If we do this in a generic way we could even defer importing numpy, saving on import duration (although there probably isn’t much functionality without running numpy-driven functions)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/844#issuecomment-534067279:4,down,downside,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844#issuecomment-534067279,2,['down'],"['down', 'downside']"
Availability,"> AFAICT, I think the parallelization you're seeing will be due to the underlying calls in statsmodels. If you turn down the number of threads blas can use, do you see the same utilization?. FYI more n_jobs seems to be slower for regress_out if I don't disable the BLAS multi threading:; ```; sc.pp.regress_out(adata, ['percent_mito'], n_jobs=1); ```; ```; regressing out ['percent_mito']; sparse input is densified and may lead to high memory use; finished (0:04:05); ```; ```; sc.pp.regress_out(adata, ['percent_mito'], n_jobs=24); ```; ```; regressing out ['percent_mito']; sparse input is densified and may lead to high memory use; finished (0:07:41); ```. I'm using scanpy 1.5.2.dev104+g8611dba1. Indeed after disabling BLAS multi threading sc.pp.regress_out will only use one core if setting n_jobs = 1. But it has to be disable by exporting these environmental variables before starting python ..., but I guess it is not a good thing because other scanpy functions may be affected?; ```; export MKL_NUM_THREADS=1; export NUMEXPR_NUM_THREADS=1; export OMP_NUM_THREADS=1; ```; More interesting is that regress_out becomes lightning fast when n_jobs = 24 and with BLAS multi threading disabled:; ```; sc.pp.regress_out(adata, ['percent_mito'], n_jobs=24); ```; ```; regressing out ['percent_mito']; sparse input is densified and may lead to high memory use; finished (0:00:23); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1396#issuecomment-684103610:116,down,down,116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1396#issuecomment-684103610,1,['down'],['down']
Availability,"> About the commit process: That's far far too much work to do it like you suggested. I don't have the time for this. As a general point about this PR: to me, the fair amount of the work of turning on flake8 deciding on the rules. Perhaps we should start with a subset of files then? I realize you did not come to the meeting where we talked about this, so perhaps there is a difference of expectations here, but we agreed to be conservative about the rules we turned on in `pre-commit`. Going through everything to make sure changes are correctly reverted is also takes a lot of time for me as the reviewer. I'd also like to limit that. ----------------. You said you used some automated tools to get faster compliance. What were these? In general, I would prefer to have a formatter that automatically ran than a tool that told me I formatted something wrong. -----------------. > `@ivirshup` I would keep the noqas. They are very easily searchable across the whole project and can be fixed later. I'm pretty strongly against this. `noqa`s just look like the formatter/ linter was wrong, and I'm not accepting that having no plan to address bugs. I think this should be a discussion with a broader set of the team. > ""Whats up with removing leading #s from comments?"" Not my choice either. What we have now is pep8 and flake8 compliant. If you're not happy with this we can ignore the rule. Yes, lets ignore this. >> ""I don't like replacing x == False with not x in all cases. Sometimes a variable could be a container, and an error should be thrown. I think cases have to be evaluated for this.""; >; > This should be covered by tests. In any case it is not good style and a violation. I will try and take a closer look at these changes. I'm particularly concerned that there will be cases where possible values are `None`, `True`, and `False`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1689#issuecomment-785871670:1529,error,error,1529,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689#issuecomment-785871670,1,['error'],['error']
Availability,"> Also isn’t it cool that it points exactly to the problematic line?. Currently, I think the line number reported is the number of lines past the `:` in the function definition. It'd be really nice if it could tell you which line number in the file it was (which might be difficult for manipulated doc-strings). Also, from what the error message says, isn't the `any(broken)` check testing the same thing as assert lines[0], `f""{name} needs a single-line summary""`? Isn't the first one sufficient?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1492#issuecomment-725996519:332,error,error,332,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492#issuecomment-725996519,1,['error'],['error']
Availability,"> Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?); > ; > A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading. I was not aware of `file`. I think it might be a good solution! `readwrite._download` should make sure that downloads are not incomplete, so just reading the header might be enough",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1506#issuecomment-733750462:407,down,downloading,407,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506#issuecomment-733750462,2,['down'],"['downloading', 'downloads']"
Availability,"> And scipy is also some 100 MB right?. Scipy is actually under `~/.cache` on my mac, ¯\\\_(ツ)_/¯. > Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. > miniconda is somewhere else for me by default, and it contains everything. I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. > You'd not notice it much, because datasets are just being re-downloaded on demand. So the compute nodes on this HPC have limited internet connectivity. One of the use cases I'd had for adding the expression atlas was to be able to easily try a method across a bunch of test datasets. If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. > My favorite command line interfaces have the ability to query options and set options globally by writing to a config file. I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-478212804:134,down,download,134,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478212804,4,['down'],"['download', 'downloaded']"
Availability,"> Could you try building the docs and checking if anything gets added? The `scanpy.plotting.rst` file has been weird in the past. I think it's at least started being consistent with newer versions of sphinx, but it'd be good to check. The pbmc data in the docs folder does indeed get downloaded when building the docs.; Do you want me to include this path into the `.gitignore`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1848#issuecomment-847710888:284,down,downloaded,284,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1848#issuecomment-847710888,1,['down'],['downloaded']
Availability,> Did you look at #454 ?. I tried to downgrade h5py but still did not work.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063709080:37,down,downgrade,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063709080,1,['down'],['downgrade']
Availability,"> Do you get an exception message or something else? If you can also copy paste the error message here, we can debug it more easily. Many thanks for your quick reply!; Unfortunately , no visible exception... My code is as follows:. ```py; import velocyto as vcy; import numpy as np; import scanpy as sc; import anndata. vlm = vcy.VelocytoLoom(""path of DentateGyrus.loom""); S = vlm.S; S=S.transpose(); adata = anndata.AnnData(S); print(adata.X); print(adata.obs); print(adata.var). sc.pp.neighbors(adata, n_neighbors=100); adata.uns['iroot'] = 0; print(adata.uns); sc.tl.dpt(adata, n_branchings=2); sc.pl.diffmap(adata, color='dpt_pseudotime', projection='2d'); ```. error message (a number of warnings as well, taking up lots of lines and I have no idea of how to include all of them here...) :. <details><summary>numba warnings</summary>. ```pytb; WARNING: You’re trying to run this on 27998 dimensions of `.X`, if you really want this, set `use_rep='X'`.; Falling back to preprocessing with `sc.pp.pca` and default params.; /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py:450: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""make_euclidean_tree"" failed type inference due to: Cannot unify RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none) and RandomProjectionTreeNode(none, bool, array(float32, 1d, C), float64, RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none), RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none)) for '$14.16', defined at /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py (457). File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 457:; def make_euclidean_tree(data, indices, rng_state, leaf_size=30):; <source elided>. left_node = make_euclidean_tree(data, left_indices, rng_state, leaf_size); ^. [1] During: resolving callee type: recursive(type(CPUDispatcher(<function make_euclidean_tree at 0x7f822dd05d08>))); [2] Du",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/749#issuecomment-515138442:84,error,error,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749#issuecomment-515138442,2,['error'],['error']
Availability,> Encountering the same error. Updating h5py did not seem to help. Any advice on this?. This might be useful to you:; https://github.com/scverse/scanpy/issues/1351#issuecomment-1198015945,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1435771153:24,error,error,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1435771153,1,['error'],['error']
Availability,"> FIXED: Updating adata.X to a scipy csr sparse matrix using `adata.X = scipy.sparse.csr_matrix(adata.X)` fixed this error.; > ; > I still get `RuntimeWarning: invalid value encountered in sqrt std = np.sqrt(var)` when running `sc.pp.scale(adata, max_value=10)` even after forcing to a csr matrix, but doesn't seem to affect downstream results... hi Rebecca, I have been trying to process scRNA (converted seurat to h5ad format) in python (processing like QC, normalisation, scaling, high variables, clustering etc) and have been getting stuck at the highly variable genes. Can you please help me out with it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-1149911935:117,error,error,117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-1149911935,2,"['down', 'error']","['downstream', 'error']"
Availability,> Failing test looks similar to what happens when I run out of memory locally. I’ve mostly seen these “illegal instruction” errors in a case where something is run on the wrong CPU architecture (e.g. compiled for a newer architecture than supported on that specific runner),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2815#issuecomment-1905756533:124,error,errors,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1905756533,1,['error'],['errors']
Availability,"> Figure out and fix this:. I think the `tbb` thing can be a `TODO` for this. Things work as is, and I don't know off the top of my head if we can reliably fix this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2870#issuecomment-1954623605:147,reliab,reliably,147,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2870#issuecomment-1954623605,1,['reliab'],['reliably']
Availability,"> First, thanks for adding more tests!. Sure thing. Thanks for all the great feedback!. > 1. Is the file `scanpy/tests/_images/scatter_filtered_genes_raw.png` meant to be here?. No, thanks for catching that. > 2. Could the tests be broken up by what they are asserting? I would prefer to break up what is being tested by test case ; rather than values of parameters. Yes, I've broken both of the tests down into multiple tests. > 3. Could we cut down on the number of reference images generated since those cause manual maintenance burden on some matplotlib updates. These reference based tests are not great for confirming the correct plot is output, only that their output is consistent across commits.; > I think some of these cases could instead be tested with `check_same_image`, e.g. where it doesn't matter whether raw is `True` or `None`. Also testing for checking cases where `use_raw=True` would be equivalent to passing `pbmc.raw.to_adata()`. I've cut the number of reference images down to two. I couldn't figure out a clever way to use `check_same_image()` instead of `save_and_compare_images()` for these as you did for the others. See below for comments about individual suggestions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2027#issuecomment-966240677:402,down,down,402,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027#issuecomment-966240677,4,"['down', 'mainten']","['down', 'maintenance']"
Availability,"> For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR. What’s the comparison to MulticoreTSNE?. ## Defaults. It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one. `use_fast_tsne` could be deprecated and made to default to `None`, with this logic (too bad we can’t use `match` yet). ```py; if use_fast_tsne is not None:; warnings.warn(""..."", FutureWarning); match (use_fast_tsne, flavor):; case (None, 'auto'): ... # try importing 'intelex', fall back to 'sklearn'; case (None, _): ... # use specified flavor; case (True, 'auto'): ... # use 'multicore'; case (True, 'sklearn'): ... # throw error; case (True, _): ... # use specified flavor; case (False, 'auto' | 'sklearn'): ... # Use 'sklearn'; case (False, _): ... # Throw error; case _: ... raise AssertionError(); ```. In the future, we can change `'auto'` to try both intelex and MulticoreTSNE. @ilan-gold what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3061#issuecomment-2114783668:50,down,down,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061#issuecomment-2114783668,3,"['down', 'error']","['down', 'error']"
Availability,"> From a first glance, with seurat_v3 requiring count data, it is important that your .X (becoming the layer you refer to as counts) indeed contains counts, otherwise loess quickly runs into stability issues. I would expect there would be a warning here if this were the case, since `check_values` defaults to `True`. But at least this person had the same error caused by passing in normalized values:. * https://www.biostars.org/p/9535944/. The [author of scikit-misc says](https://github.com/has2k1/scikit-misc/issues/6#issuecomment-615304167):. > pass `surface=""direct""`. to the loess solver based only off the error message. So maybe we can enable that. I don't know enough about loess to be able to say why that would fix this. It would be interesting to see the data that caused this error. I would definitely want to have a reproducible case before attempting a fix.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2853#issuecomment-1997957671:356,error,error,356,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2853#issuecomment-1997957671,3,['error'],['error']
Availability,"> From my error log it seems the only non-noarch dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py). That’s surprising! I think numba is our most complex dependency, and umap’s dependency PyNNDescent is also compiled. I think if this isn’t a mistake and it’s really just about h5py, we can think about it. Trying to install scanpy and following JupyterLite’s debug instructions gives:. ![image](https://github.com/scverse/scanpy/assets/291575/07a30013-e78d-46af-80fd-fb48af71d45b). ```pytb; ValueError: Can't find a pure Python 3 wheel for: 'umap-learn>=0.3.10', 'session-info', 'numba>=0.41.0'; See: https://pyodide.org/en/stable/usage/faq.html#why-can-t-micropip-find-a-pure-python-wheel-for-a-package; ```. (session-info isn’t a problem, it’s just an old package that doesn’t publish wheels)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731:10,error,error,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731,1,['error'],['error']
Availability,"> Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries?. Sorry yep tests added. And yep, the value_counts() will also catch empty categories (though added a test for that too).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1490#issuecomment-727864463:52,error,error,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490#issuecomment-727864463,1,['error'],['error']
Availability,"> Great!; > ; > I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do.; > ; > On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that?. Sure- there you go. I reverted the above and just raised an error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1490#issuecomment-726651017:213,error,error,213,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490#issuecomment-726651017,2,['error'],['error']
Availability,> Great. Please ping me here when you upload the file to... I uploaded the file.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/325#issuecomment-436040174:16,ping,ping,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325#issuecomment-436040174,1,['ping'],['ping']
Availability,"> Hello, I'd like to ask which version of scanpy you're using? The code you provided doesn't match the latest version, which is causing errors when I try to use it. Hi, I'm using 1.9.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2982#issuecomment-2044409149:136,error,errors,136,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2982#issuecomment-2044409149,1,['error'],['errors']
Availability,"> Hey! Just to chime in, I believe plotting functions also expect categoricals and I've had errors from other functions as well about obs columns not being categorical. I think that was `rank_genes_groups`, but I'm not sure. This is definitely true but easy enough for the user to address if the error is clear (or handle internally as needed).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1747#issuecomment-801719754:92,error,errors,92,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1747#issuecomment-801719754,2,['error'],"['error', 'errors']"
Availability,"> Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example using a random matrix. .; > ; > The problem is even more dramatic for method=""umap"".; > ; > ### Minimal code sample (that we can copy&paste without having any data); > ```python; > import scanpy; > import numpy; > ; > matrix = numpy.random.uniform(size=[10000,1000]); > ; > adata = scanpy.AnnData(matrix); > ; > scanpy.pp.pca(adata,n_comps=10); > scanpy.pp.neighbors(adata,method=""gauss"",n_pcs=10); > ```; > ; > The error I get:; > ---------------------------------------------------------------------------; > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context; yield; File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block; self.lower_inst(inst); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst; val = self.lower_assign(ty, inst); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign; return self.lower_expr(ty, value); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr; res = self.lower_call(resty, expr); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call; res = self._lower_call_normal(fnty, expr, signature); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal; res = impl(self.builder, argvals, self.loc); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__; res = self._imp(self._context, builder, self._sig, args, loc=loc); File ""C:\Users\RUTBO\AppData\L",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1652#issuecomment-1054106418:537,error,error,537,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652#issuecomment-1054106418,2,['error'],"['error', 'errors']"
Availability,"> Hi, It's not available in scanpy at the moment, but I wrote a wrapper for it via `rpy2` and `anndata2ri` which is available here:; > https://github.com/normjam/benchmark/blob/master/normbench/methods/ad2seurat.py. Hi,. I have been trying to use this wrapper, but seems like there's some error during the conversion process:. RRuntimeError: Error in validObject(.Object) : ; invalid class “dgCMatrix” object: 1: invalid object for slot ""i"" in class ""dgCMatrix"": got class ""array"", should be or extend class ""integer""; invalid class “dgCMatrix” object: 2: invalid object for slot ""p"" in class ""dgCMatrix"": got class ""array"", should be or extend class ""integer""; invalid class “dgCMatrix” object: 3: invalid object for slot ""Dim"" in class ""dgCMatrix"": got class ""array"", should be or extend class ""integer""; invalid class “dgCMatrix” object: 4: invalid object for slot ""x"" in class ""dgCMatrix"": got class ""array"", should be or extend class ""numeric"". Any pointers to get around this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-866121061:15,avail,available,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-866121061,4,"['Error', 'avail', 'error']","['Error', 'available', 'error']"
Availability,"> Hi, no worries! I tried that but by explicitly stating ‘use_raw=True’ but it did not change the outcome. From: Fidel Ramirez <notifications@github.com> Reply-To: theislab/scanpy <reply@reply.github.com> Date: Monday, January 7, 2019 at 11:16 AM To: theislab/scanpy <scanpy@noreply.github.com> Cc: ""Heymann, Jurgen (NIH/NIDDK) [E]"" <heymannj@niddk.nih.gov>, Author <author@noreply.github.com> Subject: Re: [theislab/scanpy] sc.pl.stacked_violin: IndexError, list index out of range (#405) Hi, sorry for the late reply. Given that the function works for some mg genes but not for other, this usually indicates that the gene may not be in the matrix. Can you try to set `use_raw=True` just to check if this is the issue (although use_raw should be True by default). Still, very suspicious that it works with with other functions like matrixplot.; > On Thu, Dec 27, 2018 at 9:07 PM Alex Wolf ***@***.***> wrote: @fidelram <https://github.com/fidelram> Could it be that stacked_violin doesn't fully account for .raw? — You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub <[#405 (comment)](https://github.com/theislab/scanpy/issues/405#issuecomment-450221575)>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AEu_1ftSP-OSKeDQYWV8Eu0-oRt6aXBAks5u9Sh_gaJpZM4ZiTv5> .; > — You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<[#405 (comment)](https://github.com/theislab/scanpy/issues/405#issuecomment-451988385)>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AioIiKYX4lsLgg91sMNygZWO1ALRDzsqks5vA3KmgaJpZM4ZiTv5>. Same error!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/405#issuecomment-470943686:1658,error,error,1658,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405#issuecomment-470943686,1,['error'],['error']
Availability,"> Hi, please provide the data you use, otherwise this is not reproducible:; > ; > ```; > FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '\external/CytAssist_FFPE_Human_Lung_Squamous_Cell_Carcinoma_filtered_feature_bc_matrix.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0); > ```. Hey, the data is publicly available under this link: https://www.10xgenomics.com/resources/datasets/human-lung-cancer-ffpe-2-standard. I simple copied the `curl` bash script to download all the files and then unzipped the file corresponding to the images to get the ""spatial"" folder",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2778#issuecomment-1845048906:271,error,error,271,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2778#issuecomment-1845048906,3,"['avail', 'down', 'error']","['available', 'download', 'error']"
Availability,"> Hi, thanks for the suggestion! Are you referring to [this function](https://rdrr.io/bioc/batchelor/man/multiBatchPCA.html) ?; > It sounds a bit like `ingest` but with multiple datasets, pinging @Koncopd to see what's his take on this. Yes that's the function.; I think it is doing something similar to `ingest`. I think this sort of batch-balanced PCA could be a useful addition addition where batches are very uneven in terms of number of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1289#issuecomment-660125494:188,ping,pinging,188,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289#issuecomment-660125494,1,['ping'],['pinging']
Availability,"> Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb.; > ; > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters.; > ; > Hope this helps 😊. Hi, the link seems to be invalid. Is there any alternative links?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2973#issuecomment-2041344958:373,down,download,373,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973#issuecomment-2041344958,1,['down'],['download']
Availability,"> Hi,; > ; > Can I ask if you are using the data from the tutorial? If not, then there are a a few potential sources of error here:; > ; > 1. You may have not aligned against the mitochondrial genome (Cell Ranger versions < 2.0 don't do this); > 2. You may have mouse data, in which case it should be lower case `mt-` instead of `MT-`.; > 3. Your data may have been pre-processed to take out mitochondrial genes.; > ; > I recall looking through quite a few datasets where there were really no mitochondrial genes. Scanpy doesn't automatically filter out mitochondrial genes. You could also check if you have any mitochondrial genes by just outputting this line: `adata.var_names.str.startswith('MT-')`. It really helps! Thanks very much!(by the way I am using zebrafish data and it still should be lower case, but I was just not aware of this)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/639#issuecomment-491473602:120,error,error,120,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/639#issuecomment-491473602,1,['error'],['error']
Availability,"> Hi,; > ; > Is your `mito_genes` vector all boolean? And does it have a non-zero sum? You seem to be getting NA values according to the error I guess. Thank you for your reply. I think the 'mito_genes' vector was all boolean. Maybe it has a zero-sum. So, how can I resolve this problem, Do you have any suggestions?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/647#issuecomment-493067273:137,error,error,137,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/647#issuecomment-493067273,1,['error'],['error']
Availability,"> Hm, even for my example it is 77.14 MiB vs 893.92 MiB, so 10 times difference. This seems large to me, no?. Yes, it's definitely large and it's awesome that you solved this problem! I just meant that it's not hitting people's computational resources limits: your example is 60K x 2K, so quite big already, if you densify you need 800MB, which is easily available even on a laptop. That's what I meant. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/403#issuecomment-450220968:355,avail,available,355,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/403#issuecomment-450220968,1,['avail'],['available']
Availability,> How are the download speeds/ hosting for figshare? Do they mirror to different regions? I recall some painful download times from Australia. It's also probably pretty stable. the datasets we have in figshar for squidpy are fast to access (europe at least) but also traffic is probably much less than pbmc3k() 😅,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2124#issuecomment-1026092545:14,down,download,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124#issuecomment-1026092545,2,['down'],['download']
Availability,"> Huh. This is really weird, since it looks like it's almost entirely due to scipy sparse indexing. Must have something to do with versions. Two things:; > ; > * If you upgrade scipy, do you still run into this error?; > * Could you get the version info from an environment where you've only imported scanpy and run this command?. I will try to update scipy. Here is the output from only import scanpy:; BTW, everything works fine until I updated scanpy to 1.7.0. ```; anndata 0.7.4; scanpy 1.7.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.4; backcall 0.2.0; cairo 1.19.1; cffi 1.14.4; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; future_fstrings NA; get_version 2.1; h5py 2.10.0; igraph 0.8.2; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.7.0; matplotlib 3.3.1; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.8; pandas 1.2.1; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.6; psutil 5.7.2; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 2.4.7; pytz 2020.1; scanpy 1.7.0; scipy 1.4.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; storemagic NA; tables 3.6.1; texttable 1.6.2; tornado 6.0.4; traitlets 4.3.3; wcwidth 0.2.5; zmq 19.0.2; zope NA; -----; IPython 7.17.0; jupyter_client 6.1.6; jupyter_core 4.6.3; notebook 6.1.3; -----; Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]; Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10; 64 logical CPU cores, x86_64; -----; Session information updated at 2021-02-21 23:42; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1670#issuecomment-783075376:211,error,error,211,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670#issuecomment-783075376,1,['error'],['error']
Availability,"> I am not sure what was causing this error, but it must be somewhat idiosyncratic as the issue is resolved in a fresh env. Thanks! Closing this.; Hi, I met same problem, how did you solve it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1275#issuecomment-996448667:38,error,error,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275#issuecomment-996448667,1,['error'],['error']
Availability,"> I created a new environment (see below for package details) and there everything works as it should. Can you use this new environment to do your analysis?. I expect that the previous environment managed to get into a messy state, which can lead to very strange errors. Because of this, I generally avoid trying to update old environments much and instead opt for creating fresh ones frequently.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-848441096:263,error,errors,263,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-848441096,1,['error'],['errors']
Availability,"> I didn't keep perfect track of the steps that I took to solve this or the exact versions of everything that I used but I'll try outlining what I did.; > ; > First I tried to upgrade numba and umap as suggested by the other individuals in the thread:; > ; > ```shell; > pip install --upgrade numba; > pip install --upgrade umap-learn; > ```; > ; > Then I essentially reinstalled scanpy using the steps in their installation docs.; > ; > ```shell; > conda install seaborn scikit-learn statsmodels numba pytables; > conda install -c conda-forge python-igraph leidenalg; > pip install scanpy; > ```; > ; > I think I then ended up with a version of numpy that was incompatible with numba so I ran; > ; > ```shell; > pip install numpy==1.20; > ```; > ; > After each step, you should be able to run the code from above to check if your installations worked, which I used to pinpoint what still needed work in my environment:; > ; > ```shell; > python3 -c ""import numpy as np; import umap; umap.UMAP().fit_transform(np.random.randn(10_000, 20))""; > ```; > ; > This seemed to fix my problems; I hope it's able to help others!. I followed your instruction but it still threw errors:. <frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject. Segmentation fault",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1567#issuecomment-1063184606:1167,error,errors,1167,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1567#issuecomment-1063184606,2,"['error', 'fault']","['errors', 'fault']"
Availability,"> I figured it'd be good to with everything being consistent. Plus documentation for the settings is now available through ?sc.settings.{setting}!. Of course, it's much better to be consistent. I was just suggesting a quick solution that wouldn't have been worse than the current one... ;). A complete automatic documentation is now also available from ; https://scanpy.readthedocs.io/en/latest/api/scanpy._settings.ScanpyConfig.html; under; https://scanpy.readthedocs.io/en/latest/api/index.html#settings. scanpy config: At some point almost 2 years ago, I removed a lot of stuff that I didn't think was essential to clean up the project. It was just an element of that. I'm very happy to introduce it again; these days, the project is much more major and indeed has many config options (there were only few at the time) and hence it would indeed merit having a config file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/573#issuecomment-479750272:105,avail,available,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479750272,2,['avail'],['available']
Availability,"> I find out the solution. Thank You. Although I think that this is not an issue with Scanpy, it is usually common courtesy to post the solution to the corresponding issue. If other people search for the same error they can find your solution :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1795#issuecomment-817788753:209,error,error,209,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795#issuecomment-817788753,1,['error'],['error']
Availability,"> I for now would not try to differentiate between noqas that we want to keep and noqas that we want to get rid of. We want to get rid of all of them in the follow up issue and only when examining all of them we will figure out which ones we want to keep. After this merges new ignore messages can be added for reasons like ""this rule is generally good, but not in this specific case"". Each of these will go through PR review, so will be vetted. The ones added here largely have not been vetted, and are just being added so we don't get a failure. I would like to be able to distinguish between these cases. Once more `noqa` cases are added, it gets more complicated to find cases that haven't been vetted if they don't have some associated label. --------------------------. > What do you mean? How to ignore a single line? How to fully ignore whole checks?. How to disable flake8 errors for a line or file. > I would always refer to the flake8 documentation, because it will certainly maintained better than the dev documentation. A link to the section of the flake8 docs on this would be great. -------------------------. > I wish it were that easy. autopep8 does not take its configuration from the flake8 config file . `autopep8` says it does this: https://github.com/hhatto/autopep8#configuration. > It formats consistently, but not necessarily compatible with other tools. I would like changes that are automatically applicable to be automatically applied. I'm thinking of things like white space in docstrings. Is there another way to automate these you can suggest?. ---------. BTW, I've added a few more points to the checklist above. I would recommend trying to build the package and build the docs in the directory you're working in to see what files get generated so they can be added to the `ignore`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1689#issuecomment-787426782:539,failure,failure,539,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689#issuecomment-787426782,2,"['error', 'failure']","['errors', 'failure']"
Availability,"> I found a workaround that does not require downloading the `.whl` file for `numpy=1.19.5`. By default, MKL is included when you install numpy with conda. It's good to do this in a new environment.; > ; > ```; > conda create -n scanpy_env; > conda activate scanpy_env; > conda install numpy=1.19; > conda install seaborn scikit-learn statsmodels numba pytables; > conda install -c conda-forge python-igraph leidenalg; > pip install scanpy; > ```; > ; > Now I can run `sc.pp.highly_variable_genes()` with no problem. Update: this workaround does not seem to work anymore, at least for scanpy 1.8.2 (you'll need to `pip install scanpy==1.8.1`). ; During `pip install scanpy`, a newer version of numpy is installed and version 1.19 is overwritten. This newer version does not have MKL, leading us back to square one. It's also not possible to `conda install numpy 1.19` as the very last step, because this leads to another error (it's related to the fact that scanpy needs to be compiled with the same version of numpy).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1058514241:45,down,downloading,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1058514241,2,"['down', 'error']","['downloading', 'error']"
Availability,"> I had also thought isort could be a good starting place, but it might actually be some work to turn on due to ""partially initialized module"" errors (imperative programming strikes again!). Yeah, I ran into this stuff when creating the flake8 PR (#1689). isort is dangerous with Scanpy and requires good testing and many exceptions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1563#issuecomment-785092164:143,error,errors,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563#issuecomment-785092164,1,['error'],['errors']
Availability,"> I had the exact same issue and error message at that step in the tutorial. I installed scanpy using pip, because installing with conda was not working. Same here. I assume there is some issue with the implementation of the setter of adata.X, which prevents `adata.X = adata.X.toarray()` from updating X to its densified version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1010#issuecomment-578596689:33,error,error,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010#issuecomment-578596689,1,['error'],['error']
Availability,> I just had another thought... it seems like this might have to do with the initial `sc.tl.paga()` call. There you get a runtime warning about overflow in long scalars. Maybe check if you get any meaningful output in `adata.uns['paga/connectivities']` or `adata.uns['paga/connectivities_tree']`. It might just be all `nan` in there due to the above errors. Could it be that you have a 32-bit windows version and the code is trying to use 64-bit floats? Maybe that's the overflow error?. my system type is 64 bit,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/852#issuecomment-535093343:350,error,errors,350,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/852#issuecomment-535093343,2,['error'],"['error', 'errors']"
Availability,"> I know exactly that in PCA I can interpret a component based on its rank (and/or variance contribution). Ah, I meant more specifically that it may be easier to biologically interpret an ICA. > That would say I should try as many decompositions as possible to see when I get a good result. I'm a little unsure of your meaning here. Do you mean decompositions like decomposition techniques? If so, I don't think this is the right conclusion. I think it means: probably PCA for clustering, probably NMF for finding gene modules. I would also suspect something which finds sparser variable loadings like ICA or NMF could be more robust for cross dataset classification. If you mean, if the results are unstable how do we know which to trust – I did ask that question. I think it's the usual: have a validation dataset, maybe some ensemble/ robustness method, or do some sort of enrichment. It's an open question, but a lot of our analysis pipeline is.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/941#issuecomment-560313033:627,robust,robust,627,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/941#issuecomment-560313033,2,['robust'],"['robust', 'robustness']"
Availability,"> I saw some of the github automated tests test are failing now, but I don't really understand the error messages tbh ;) Are they even related to the execution of the code provided by this PR?. yeah also don't understand them, it might be @cache in py 3.7 has issues? will investigate next week and report back!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-1050003610:99,error,error,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-1050003610,1,['error'],['error']
Availability,"> I see... but as it's always `adata.uns['paga']` what would happen if I have an old object and then run a new `sc.tl.paga()` with `key` set to something. Then you'll have it under both `adata.uns['paga']` and `adata.uns['paga'][key]`. That's not backwards compatibility though. BC is running the old code (so no key='key') with an old object (where paga is under `adata.uns['paga']`) with new scanpy and getting the old result, which is satisfied here. There are weird failure modes though, like using `key='groups'` or `key='connectivities'` might override some parts of an existing, old-style paga result. We can forbid keys like these. Actually this is related to the versioning of AnnData specification. We should keep some sort of version like `/attrs/LOOM_SPEC_VERSION` in loom. Then it would be easier to understand what to expect from an anndata object that is created at any point in time.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/957#issuecomment-567549770:470,failure,failure,470,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/957#issuecomment-567549770,1,['failure'],['failure']
Availability,"> I think it may be possible to use openTSNE's function to compute the affinities and then get the weights out of there?. I would definitely like this to be the case. I'm not sure I see . > Why? `sc.pp.neighbors` already has `method='gauss'`. To me, it’s largely of a maintenance and documentation issue. Most bugs I fix (here, and in upstream libraries) come from argument handling. The more features you lump into a function, the more complicated argument handling gets. There are questions of default values and fallbacks for different backends, and being sure users understand which arguments are valid for each backend. The use of the `Neighbors` class ends up making the `neighbors` function much more complicated than it needs to be. I think skipping out on that here can make this implementation much more simple. From an API stand point, I would like the ""blessed"" `tsne` workflow to be dead obvious. I'm thinking:. ```python; sc.pp.neighbors_tsne(adata); sc.tl.tsne(adata); ```. How many arguments is it going to take to make this work if this functionality is in `sc.pp.neighbors`? At a minimum, `k=30, method=tsne_affinity, nn_method=""annoy""`, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-759238450:268,mainten,maintenance,268,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-759238450,1,['mainten'],['maintenance']
Availability,"> I think the result in such a case could just contain nans and emit a warning. This sounds reasonable to me. With sparse values, it's consistently giving results, but it's the wrong results. The iteration is being chunked (probably related to number of available cores), and it looks like within each chunk all values after the constant one are filled with zeros. I should look into whether this is also numba, or a logic bug. If it's numba, it's strange that it's zeros and not `inf` or `nan`. If it's on our end, I'm not sure why the later iterations would be skipped. ----------. > p.s.: I really like how you document everything you do so nicely 😃. Thanks! Is mostly so I can remember my reasoning a month later 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1698#issuecomment-827271245:254,avail,available,254,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1698#issuecomment-827271245,1,['avail'],['available']
Availability,"> I thought at one point you guys were checking flake8 with CI. We were, sorta. The CI tool we were using had pretty stochastic reporting (which isn't really what we want in a CI tool). Hopefully it'll be back in a more reliable form soon: https://github.com/theislab/scanpy/issues/1563#issuecomment-784922713",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1679#issuecomment-784998888:220,reliab,reliable,220,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1679#issuecomment-784998888,1,['reliab'],['reliable']
Availability,"> I'd like the following sequence of commands ... to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. ; > I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications. I share the same worry, but am not qualified to answer when something becomes ""t-SNE"". I think it would be sufficient for `sc.tl.tsne` to warn users if the graph it was passed looks unexpected (or if it could tell it was generated by a different method). > What you suggest (t-SNE on normalized UMAP affinities) could maybe achieve that. From an API point of view, we don't control weights at the `sc.tl.umap` call, so I think it would be strange to control weights at the `sc.tl.tsne` call. I'm also not sure if binarizing the graph would be closer to ""t-SNE"". ----------------------. About `sc.pp.neighbors` vs `sc.pp.neighbors_tsne`. > This is just a question of API, and is less important for me personally. I agree that it could be better to have neighbors() compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR. I think for backwards compatibility I would like to keep neighbors pretty much as is. I think new functions like `distance_neighbors`, `umap_neighbors`, `tsne_neighbors` could be reasonable to add. It's also possible we could add a `""tsne""` method to `neighbors`, but I think the implementation can look very similar to having a `tsne_neighbors` function, so this can be kicked down the road a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-762595475:1477,down,down,1477,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-762595475,1,['down'],['down']
Availability,"> I'm actually testing and tweaking someone else's code that was written a while ago. I assume they used; > `import scanpy.api as sc` because it was appropriate then. I personally resolved my issue by downgrading versions, I just wanted to bring this up!. I encountered the same issue. Which version are you using to fix this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1397#issuecomment-684930174:201,down,downgrading,201,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1397#issuecomment-684930174,1,['down'],['downgrading']
Availability,"> I'm not sure we're looking at the same code. I was looking at this:. I was looking at the [TruncatedSVD](https://github.com/scikit-learn/scikit-learn/blob/b194674c4/sklearn/decomposition/_truncated_svd.py#L186) code. Either way, I'm not able to reproduce your assertion error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-593744652:272,error,error,272,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-593744652,1,['error'],['error']
Availability,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this?. > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function?. > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1233#issuecomment-631235395:169,avail,available,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233#issuecomment-631235395,2,"['avail', 'down']","['available', 'downstream']"
Availability,"> I'm not to sure what the assumptions are behind each method though. @falexwolf, any reason in particular you've chosen UMAP's method for the KNN calculation?. It's highly competitive in terms of speed and accuracy with other libraries (https://github.com/erikbern/ann-benchmarks, pynndescent is what umap uses, wasn't available at the time for Scanpy), it's a lot easier to install than everything else, and the result has been shown to harmonize well with UMAP, which I expected would become the canonical way of visualizing things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/277#issuecomment-427333649:320,avail,available,320,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/277#issuecomment-427333649,1,['avail'],['available']
Availability,"> I've figured out what was causing my error. The scanpy function to read in `features.tsv.gz` expects three columns: `['gene_symbols, 'gene_ids', 'feature_types']` Where 'feature types' is a text string like 'Gene Expression' and usually repeated along the whole length of the file. The file I was reading in was from HTO data and only had one column:; > ; > > Hashtag1-GTCAACTCTTTAGCG; > > Hashtag2-TTCCGCCTCTCTTTG; > > Hashtag3-AAGTATCGTTTCGCA; > > unmapped; > ; > So if others run into this same error, just add in some extra columns to the `features.tsv` file so it doesn't error out when looking for the extra columns. Something like this (different features file):; > ; > > RP11-34P13.7	RP11-34P13.7	Gene Expression; > > FO538757.3	FO538757.3	Gene Expression; > > FO538757.2	FO538757.2	Gene Expression; > > AP006222.2	AP006222.2	Gene Expression; > > RP4-669L17.10	RP4-669L17.10	Gene Expression; > ; > It would also be helpful if scanpy would validate the number of columns at the start. At the moment it looks like it reads in the whole `.mtx` file before trying to map the feature names and producing this error, so it takes a while to fail. when you do add those columns it makes the number of genes to 0 while reading it!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1916#issuecomment-1433364355:39,error,error,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916#issuecomment-1433364355,4,['error'],['error']
Availability,"> IIRC, it's discussed in more detail in Malte's paper:; > ; > > ; > ; > In the same way that cellular count data can be normalized to make them comparable between cells, gene counts can be scaled to improve comparisons between genes. Gene normalization constitutes scaling gene counts to have zero mean and unit variance (z scores). This scaling has the effect that all genes are weighted equally for downstream analysis. There is currently no consensus on whether or not to perform normalization over genes. While the popular Seurat tutorials (Butler et al, [2018](https://www.embopress.org/doi/full/10.15252/msb.20188746#core-msb188746-cit-0020)) generally apply gene scaling, the authors of the Slingshot method opt against scaling over genes in their tutorial (Street et al, [2018](https://www.embopress.org/doi/full/10.15252/msb.20188746#core-msb188746-cit-0125)). The preference between the two choices revolves around whether all genes should be weighted equally for downstream analysis, or whether the magnitude of expression of a gene is an informative proxy for the importance of the gene. In order to retain as much biological information as possible from the data, we opt to refrain from scaling over genes in this tutorial.; > ; > https://www.embopress.org/doi/full/10.15252/msb.20188746; > ; > Since there has been no new development on this topic, we cited Malte and also opted not to scale. This is also discussed by Malte himself in the issue that was cited above.; > ; > I cannot comment on spatial data itself and make confident statements here. Thanks a lot; so is there a conclusion or recommendation whether scale or not on spatial data? @ivirshup @Zethson",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2963#issuecomment-2034435734:402,down,downstream,402,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2963#issuecomment-2034435734,2,['down'],['downstream']
Availability,"> If I understand the .raw removal alternative correctly, then you would want to add masks to every operation in scanpy that is not DE and work with .layers?. Pretty much every function where you would want to use `highly_variable`. > It seems to me that adding masking like this would be quite a large endeavour, no?. I think a similarly sized endeavor to adding `highly_variable`, except we can use the `highly_variable` code where it's been implemented. I would expect this to be less effort than supporting `raw`, which is a constant maintenance burden, especially for `anndata`. I think this logic could be added to the `_get_obs_rep`, and `_set_obs_rep` functions. --------------. > If you assume anything filtered out was removed because it was predominantly 0. I'm not sure I like having this assumption. Especially when a collaborator asks ""what about gene X"", but it just wasn't in the table I received. Maybe it's an annotation issue, maybe it wasn't expressed, or maybe it wasn't expressed globally at a high enough level – but could have been expressed in the cells of interest. > you can assume it would not be in the HVG intersection for that dataset and if you add it,. Is intersection the way to go? If you have cell types which are only present in some datasets, wouldn't you want to take the union?. > Typically there is sufficient gene-gene covariance that you still keep this signal somehow. I would agree that it is unlikely that this would have a huge effect on analyses like PCA or UMAP. When it comes time to do differential expression or show expression on an embedding, then it starts to be an issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-822937305:85,mask,masks,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-822937305,3,"['mainten', 'mask']","['maintenance', 'masking', 'masks']"
Availability,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python; import vega_datasets; import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(; iris[""sepalLength""],; iris[""sepalWidth""],; c=iris[""petalLength""],; norm=norm,; vmin=3,; ); plt.colorbar(); ```. ```; MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax ; simultaneously is deprecated since 3.3 and will become an error two minor releases ; later. Please pass vmin/vmax directly to the norm when creating it.; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1551#issuecomment-748567569:47,error,error,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551#issuecomment-748567569,3,['error'],['error']
Availability,"> If the problem is windows, it's possible it will be solved by numpy 2.0. Not sure how easy the upgrade path to numpy 2.0 will be, however.; > ; > * https://numpy.org/devdocs/numpy_2_0_migration_guide.html#windows-default-integer. I can reproduce the error using Numpy 2.0.2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2326703284:252,error,error,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2326703284,1,['error'],['error']
Availability,"> If we need multiple tools in the same container the place to add it would be [BioContainers/multi-package-containers](https://github.com/BioContainers/multi-package-containers). We do make heavy use of optional dependencies, so this might be the way to go regardless. > Curious to know why and if it's something that can be overcome?. ### Practically. * The documentation for bioconda has been incomplete and out of date for years.; * conda-forge autoupdates recipes. When we make a pip release, a conda-forge release is automatically generated.; * bioconda packages can depend on conda-forge packages, but not the other way around (last I checked at least). If we go on bioconda all our dependents do too – *this could make it extremely painful to do a migration to bioconda*.; * All of our dependencies are on conda-forge; * Fewer channels to search means easier, faster environment solving. ### More philosophically. Why have separate package registries for biology vs everything else? Code for biology isn't particularly special, much of the tooling/ work here is duplicated effort. Why not just put all of bioconda onto conda-forge, but with a special tag saying they are bio packages? All the extra tooling/ maintenance consortiums can be developed orthogonally to the registry. I think there are very clear problems that come out of separate registries. It was a huge pain to install anything from BioJulia until they deprecated the BioJuliaRegistry. If bioconda didn't use it's own build system there wouldn't be out of date docs for that build system. It just seems like a lot of trouble to go through for unclear benefit. I will admit, I think there were more benefits to this model ~a decade ago. But I think these benefits have been mitigated by significantly improved tooling for developing, building, and distributing packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404:1216,mainten,maintenance,1216,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160555404,1,['mainten'],['maintenance']
Availability,"> If we return an array of integers we run into trouble downstream with functions that aren't tested with integer arrays. Issues from this have been opened a few times, so when I wrote this I thought it might be worth just maintaining the input type. I'm not sure I agree with that now. This is quite a compelling argument for me (as I was one of the people who reported an issue like this). If an integer matrix is generally returned, then one would have to ensure all other functions will work with this data type as intended (sc.pp.log1p for example). Otherwise this would be backward-breaking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/865#issuecomment-552814583:56,down,downstream,56,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/865#issuecomment-552814583,1,['down'],['downstream']
Availability,"> If you change `X_coords` to `coords`, where do errors occur? Could you also point me to where you're seeing this code? I've definitely been using embeddings in `obsm` whose keys don't start with `""X_""`. Right, my bad, switched to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1105#issuecomment-601303079:49,error,errors,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105#issuecomment-601303079,1,['error'],['errors']
Availability,"> If you want to try it out, I give instructions for how to reproduce the error with a Docker container for Windows in the cross-referenced issue. Yes please. I’m confused how Windows comes into play though since I thougt that Docker always runs on a Linux kernel – natively on Linux and in a VM on macOS and Windows.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2333436219:74,error,error,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2333436219,1,['error'],['error']
Availability,"> In case anyone has this error again, here is what worked for me:; > ; > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > * scanpy should work now; > ; > This worked on mine and also on a colleagues windows laptop.; > ; > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users. this helped me out as well",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-966445217:26,error,error,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-966445217,4,"['down', 'error']","['download', 'downloaded', 'error']"
Availability,"> In case anyone has this error again, here is what worked for me:; > ; > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > * scanpy should work now; > ; > This worked on mine and also on a colleagues windows laptop.; > ; > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users. this is the only way I solve my error. I tried every else except reinstall system.; thx!!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-871181214:26,error,error,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-871181214,5,"['down', 'error']","['download', 'downloaded', 'error']"
Availability,"> In general, are we agreed on these points? ; > tsne should allow weights to be passed through (whether perplexity based, or not) ; > There should be a warning to notify the user if the weights were computed in a non-standard way ; > There should be a function for computing a perplexity weighted nearest neighbor graph. . Yes. I agree. > Perhaps there needs to be a weights option on tsne which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. This sounds good. IMHO erroring is not necessary. There will be a warning anyway. > Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Actually UMAP weights *are* symmetric. So it would be enough to normalize the entire weight matrix to sum to 1. -----------------. I think there are two different choices that we have been disagreeing about:. * Choice 1: whether `preprocess_weights='normalize'` or `preprocess_weights='binarize'` is default for `tl.tsne()` if the passed weights do not sum to 1.; * Argument for `normalize` (Isaac): closer to originally calculated weights;; * Argument for `binarize` (Dmitry and Pavlin): will make it UMAP-independent if `tl.tsne()` is run after default `tt.neighbors()`.; * Choice 2: whether perplexity weights are given by `pp.neighbors_tsne()` or by `pp.neighbors(method='tsne')`; * Argument for `neighbors_tsne` (Isaac): the existing function is complicated enough, so let's not make it even more complicated;; * Argument for `neighbors(method='tsne')` (Dmitry and Pavlin): the other option would make the API for UMAP weights and for tSNE weights assymetric and even confusing, as `neighbors` is not called `neighbors_umap`. Does this summarize the arguments from both sides?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-773303341:441,error,erroring,441,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-773303341,2,['error'],['erroring']
Availability,"> In the other word, the scvelo's 'scv.pl.velocity_embedding_stream' showing terminal differentiation cells develop to original cells. this was incorrected logically. why the scvelo showed the inverted result contrast with monocle result. As @LuckyMD said, this is a question for `scvelo`. . > I guess what i make the cell order was wrong ? . The best way to check if ordering went wrong is to plot an embedding colored by some known grouping. If colors are all mixed up you know a mistake has done. > i wonder whether the code just sorted the cell barcode on annData.obs but the annData.X's matrix? why was the order runing so quickly that the matrix of annData not be sorted at the same time?. Luckily `AnnData` is quite robust and it reorder any slot (`obs`, `obsp`, `obsm`…) according to the specified cell names. d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1718#issuecomment-801970805:723,robust,robust,723,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1718#issuecomment-801970805,1,['robust'],['robust']
Availability,"> It seems you do not always end up with n-1 neighbors, because for n=3, you suddenly get differing number of neighbors:. I think the varying number of neighbors is because the connectivity graph is made symmetric. ```python; import scanpy as sc, numpy as np; pbmc = sc.datasets.pbmc68k_reduced(); sc.pp.neighbors(pbmc). np.unique((pbmc.obsp[""distances""] != 0).sum(axis=1).flat); # array([14]); ```. Yeah, n_neighbors=1 should definitely throw an error (I think it does for UMAP). We do document that reasonable values start at 2, but it could also be good to have more reasoning on that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1706#issuecomment-789305891:447,error,error,447,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706#issuecomment-789305891,1,['error'],['error']
Availability,"> I’m unsure if we can help you with this, as it’s your system creating his error and we don’t have access to the data. There’s multiple possible causes and solutions:; > ; > * a misunderstanding: The arrays should require `310385 * 8563 * 8B = 21.3 GB`, no idea why it says 10. But of course that’s still not close to 100GB unless other people/processes are using the machine, or other arrays are allocated. Can you track the memory usage and see if it spikes close to the maximum before the code crashes?; > * our implementation allocates memory it shouldn’t: this is the only one we can fix, but we’d have to figure out under which circumstances that happens, and where in our code.; > * some machine problem, [like many people on stackoverflow](https://www.google.com/search?q=site%3Astackoverflow.com+%22Unable+to+allocate%22+%22GiB+for+an+array+with+shape%22+%22and+data+type%22): maybe your sysadmin can help?. Thank you so much for all your assistance and detailed suggestion, I really appreciate it. I tracked the memory usage and found out that the free system memory is only about 5 GB, so apparently I have misunderstood the concept of ""memory usage"" before......Now I am going to turn to people who have encountered the same machine problem on stackoverflow and see if there is some advice. Thank you again for your time and attention!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2551#issuecomment-1640426447:76,error,error,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551#issuecomment-1640426447,1,['error'],['error']
Availability,"> Just to clarify, Jan started this PR because we were explicitly asked by some of the Scanpy core developers to prepare it for the core library. . I see, my comments weren't really directed at anyone in particular -- I know we are all trying to do good work and it's great that you all have thought a lot about this particular normalization -> dim. red. problem. > We view it basically as ""scTransform done right"". And scTransform is already published and is being used. Sure, but my point is that the analytic Pearson residuals method hasn't been peer-reviewed, and while the results in your preprint appear promising there are still questions that remain; e.g., how does it compare to deviance residuals? What is the effect on datasets that do not have so many cell types, i.e, ""continuous"" datasets? What happens when looking at metrics that aren't qualitative evaluation of t-SNE embeddings?. > One option would be to hold this PR until our paper is formally accepted... That makes sense to me, or just put it in external for now, or write generic methods for ""residuals"" that includes analytic, deviance, etc, with deviance as default (and as flavors?)? I'm not sure what is appropriate here, and some guidelines from the core scanpy team would be appreciated. For example, most people I know use the `""seurat_v3""` flavor of HVG selection, but it's not the default. It makes sense to me to change defaults as more information becomes available about performance/popularity.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-798687817:1440,avail,available,1440,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-798687817,1,['avail'],['available']
Availability,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering.; Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), ; but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering.; In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be ; missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) ; and mismatching color codes might also not be apparent initially. ; For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially.; This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1479#issuecomment-723071522:223,error,error,223,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479#issuecomment-723071522,3,['error'],['error']
Availability,"> Maybe a solution would be to set `highly_variable` equal to `highly_variable_intersection` when using the `batch_key`. I think `highly_variable` is a remnant of using `highly_variable_genes_single_batch()` (or whatever the function is called) to get the individual per-batch HVGs for intersection calculation. @gokceneraslan will be able to correct me here though. Encountered this exact issue today. In my example, `highly_variable_intersection` only contains 17 genes across 30 datasets, which I imagine might silently give unexpected results downstream. In addition to that option, another option might be to allow the user to define a minimum number of `highly_variable_nbatches` so `highly_variable` is derived from `highly_variable_nbatches > NUMBER`. This is an approach used here FWIW: https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1032#issuecomment-616240702:547,down,downstream,547,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032#issuecomment-616240702,1,['down'],['downstream']
Availability,"> No worries. I meant here: https://github.com/scverse/scanpy/blob/master/scanpy/tools/_leiden.py. Sorry I still don't really know what to do. After the RandomState object is passed to leiden, it passes it to igraph, which raises an error because igraph wants an int to initialize [it's own rng system](https://igraph.org/c/doc/igraph-Random.html). It seems to me like there's no easy way to fix this, no?. Maybe I should just give it an int instead? I'd just like my clustering to be reproducible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2431#issuecomment-1452342219:233,error,error,233,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431#issuecomment-1452342219,1,['error'],['error']
Availability,"> Not sure whether it is resolved, just put here another solution to read_mtx and add to anndata one by one; > ; > ```; > import pandas as pd; > import scanpy as sc; > ```; > ; > ```; > adata = sc.read_mtx('./matrix.mtx'); > adata_bc=pd.read_csv('./barcodes.tsv',header=None); > adata_features=pd.read_csv('./features.tsv',header=None); > adata= adata.T; > adata.obs['cell_id']= adata_bc; > adata.var['gene_name']= adata_features[0].tolist(); > adata.var.index= adata.var['gene_name']; > ```. set the delimiter for the features to tab, then use the second column which contains the gene names and not the gene ensembl id. Using the gene names is better for downstream qc since the scanpy recommended pipeline uses the gene name prefixes to identify mitochondrial genes. ```; adata_features = pd.read_csv('./barcodes.tsv', header = None, delimiter = '\t'); ... # technically don't need to use .values or tolist() since the mtx and features file should ; # have same number of rows resulting in same index in the adata.var and adata_features dataframes. adata.var['gene_name'] = adata_features[1].values; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1916#issuecomment-2241799568:657,down,downstream,657,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916#issuecomment-2241799568,1,['down'],['downstream']
Availability,> Numba can’t correctly detect when a threading backend is available. Is there a numba issue for this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1931#issuecomment-874655687:59,avail,available,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931#issuecomment-874655687,1,['avail'],['available']
Availability,"> Removed 3.6. We should keep 3.6 as long as we support it. It's easy to accidentally add features which only work with 3.7+ otherwise. I'd be happy to drop 3.6 once numpy does (and in general roughly follow [NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html) as soon as the ecosystem does). > is there any reason why we are currently not additionally using Github Actions?. Depends on the task. Also depends on the definition of github actions I think? We aren't using any of their runners for testing because we'd like the ability to integrate with hosted resources on azure. Also, azure seemed like much more of a standard for numeric python packages at the time we chose it. I'd be happy to have github actions for other things, like `precommit`. `twine check` could be another one, but I haven't looked in to how ""artifact"" type things are handled with github actions to know if we'd be able to recover the built objects. We'd talked about using codecov too, which I'd like to add a check for. I'm not totally clear on the distinction between checks and actions yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1602#issuecomment-763590019:914,recover,recover,914,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1602#issuecomment-763590019,1,['recover'],['recover']
Availability,"> Should the reference object where you learn the transformation always be a subset of the data you're going to apply the transformation to? If so, instead of passing a separate object, could there be a mask of which samples to train on?; > ; > If not, what do you think about making this a separate function? Maybe `combat_by_reference`?. Thank you for your great suggestions. I think it's easier to add a mask for train/evaluate instead of splitting into 2 objects. ; I don't think it should be a separate `combat_by_reference` function, though, because the chance in the function is small and I preserved the original functionality.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1501#issuecomment-730248703:203,mask,mask,203,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501#issuecomment-730248703,2,['mask'],['mask']
Availability,"> So I guess the real culprit is the float32 issue with AnnData. Is this something you all plan to address soon?. I think we can do that. I did a quick check and it's pretty benign in anndata. It causes test failures a few places in scanpy, but I think that's solvable with some conversion. It is a breaking change, so it will need to be in anndata 0.8. But there's a few more minor changes I'd like to make, so maybe we can be quick on that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1415#issuecomment-696580713:208,failure,failures,208,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1415#issuecomment-696580713,1,['failure'],['failures']
Availability,"> So I think the issue is the `foldchanges[global_indices]` that has values that you can't input into `np.log2`. That can be `NaN` or negative values. A fold change is something like `(average expression in condition 1)/(average expression in condition 2)` if expression values can be negative, then one of those values can be negative, giving a negative fold change. I would guess that these testing frameworks don't play well with negative values. I believe this is the reason why it happens. If one of those two averages are negative, then your fold change is negative, and you get an error when feeding that into `np.log2()`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/653#issuecomment-494541028:588,error,error,588,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494541028,1,['error'],['error']
Availability,"> Some pip wheel files are there for example. And scipy is also some 100 MB right?. > Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. That's exactly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My pe",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:325,down,download,325,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890,2,['down'],['download']
Availability,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted?. ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-777382118:7,failure,failures,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-777382118,2,['failure'],['failures']
Availability,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess?. I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows?. > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-759335128:1406,down,downstream,1406,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-759335128,1,['down'],['downstream']
Availability,> That doesn't seem to be a Scanpy or AnnData issue but an issue with a corrupted HDF5 file as such. Thanks! I struggled with this error for a long time yet it turns out the file is corrupted.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/626#issuecomment-488057644:131,error,error,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/626#issuecomment-488057644,1,['error'],['error']
Availability,"> That's fair. Might be worth asking the `conos` developers in this case?. Yes, could and should do this... but would slow down the process for now I guess. > Also, does using `install.packages` within a conda environment work for you? I recall that not working well for me in the past. It works if you install the R packages last and don't install anything else over the top via conda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-593311808:123,down,down,123,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-593311808,1,['down'],['down']
Availability,"> The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows. I have now done a speed comparison with adata object of 1.85 million cells. igraph on adata as implemented [above](https://github.com/theislab/scanpy/issues/1053#issuecomment-1039424473) ran in **33 minutes** vs `sc.tl.leiden()` which took **~14 hours**",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1053#issuecomment-1039999011:579,avail,available,579,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053#issuecomment-1039999011,1,['avail'],['available']
Availability,"> The just added changes should mimic the response from 1.6 except for duplicate names in var_names which I think should respond similarly like when doing a slicing on the AnnData object. Thinking about this more. Considering that no one has complained about this so far. I think I'm actually fine with this being an error. If there are complaints, I think we should change it back. I do think it's important that `gene_symbols` can have duplicates as long as those values aren't being accessed (as non-unique identifiers is the whole point of `gene_symbols`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770641710:317,error,error,317,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770641710,1,['error'],['error']
Availability,"> The tests have a tolerance parameter that is set high. The problem is that the stripplot shows different results each time. Also, different versions of matplotlib and seaborn have slight differences. Ah yes, I see. The stripplot result could be fixed by setting a seed with `np.random.seed`. I doubt it will fix the difference due to the used version, though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1422#issuecomment-696710488:19,toler,tolerance,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422#issuecomment-696710488,1,['toler'],['tolerance']
Availability,> The tolerances need to be tight enough that the tests do anything though …; > ; > I’ve seen and fixed quite some tests where the tolerances meant that completely broken output was accepted. This is exactly what I'm seeing in my PR.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1899355829:6,toler,tolerances,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1899355829,2,['toler'],['tolerances']
Availability,"> There are weird failure modes though, like using `key='groups'` or `key='connectivities'` might override some parts of an existing, old-style paga result. We can forbid keys like these. this is exactly what i was worried about. 'groups' is probably not such a rare case as a key. But good to take care of that. I guess in the old & new case, you just have a bit of a messy `adata.uns['paga']` dictionary, but it will still work (in most cases).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/957#issuecomment-567585303:18,failure,failure,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/957#issuecomment-567585303,1,['failure'],['failure']
Availability,"> This agrees with what I suspected: that randomized PCA itself should be pretty stable, . No, if you look into how higher PCs vary, you see that they vary drastically depending on the seed or computational platform. That also makes sense, it's a power-method that does the computation, that runs into some unstable stuff. > PCs were similar to within a couple of decimal points,. I'm very sure that you only observed this for the first couple of PCs, which you robustly estimate. Going higher, you end up in some local minima for a subsapce; I believe that it doesn't mean it doesn't capture important variation; it just means that it's a local minimum that the algorithm converges into... something we observe all the time when training models... in the context of Lanzcos and other algorithms powering SVD, PCA etc., it's usually a nuisance that you have that instability when you go higher in iterations; but also there, people just use the results even if they know they don't get the *exact* 50th eigen vector...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/325#issuecomment-436041937:462,robust,robustly,462,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325#issuecomment-436041937,1,['robust'],['robustly']
Availability,"> This is actually something I've been meaning to bug you about @WeilerP, why does scvelo pin umap below 0.5?. This was only a dirty hack to make our unit tests pass (see e.g. [here](https://github.com/WeilerP/scvelo/runs/2112241472?check_suite_focus=true)). It's no longer pinned on `scvelo@develop` which we plan on merging into master in the following days to tag a new version. > We can ban umap 0.5.0 specifically. It's generally important that scanpy has a broad-ish range of versions it's comparable with, since there's a lot downstream. I'd be happy bump umap to above 0.4 though, since it has been a while for that. I believe the problem is using `umap-learn<=0.5.0` with new `numba` versions (I think `numba>=0.53.0`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-846973729:533,down,downstream,533,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-846973729,1,['down'],['downstream']
Availability,"> This is mainly a fix for cases when multiple genes have zero variance. Could you add that as the test case? When some genes aren't expressed in a batch you won't get an error. > the best way forward would be to exclude those genes from the function. I think the approach of masking out the non-expressed genes sounds reasonable, since that's what you'd probably do if it were just one dataset. I'd definitely defer to @gokceneraslan on any more about the appropriateness of the approach.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/824#issuecomment-529851678:171,error,error,171,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824#issuecomment-529851678,2,"['error', 'mask']","['error', 'masking']"
Availability,"> This is not the case study code. I think this comes from the PAGA tutorial. So I can't really say whether this is normal. I typically don't have PAGA errors or warnings.; > ; > Most of the errors seem to be deprecation warnings, so that should be fine... but the ""finite values"" on posx and posy error I haven't come across. It looks like this is on Windows. Is there a matplotlib issue with windows?. matplotlib is working well with my windows and I tried to run ; pyplot.scatter([0,1], [0,1]) it works correctly. . Maybe, this issue is caused by the difference of versions?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/852#issuecomment-535106890:152,error,errors,152,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/852#issuecomment-535106890,3,['error'],"['error', 'errors']"
Availability,"> This is strange, i also tried to run the tests multiple times at the time of committing this and they failed every time. Maybe a dependency had a bugged release at the time?. > I am not sure what king of test. I don't want to add another save_and_compare_images test because plots seem to depend on the system at least sometimes. You could instead use `check_same_image`. Check that running `filter_rank_genes_group` then plotting is equivalent to manually passing those genes to `sc.pl.rank_genes_groups_*` plot on an object that hasn't had `filter_rank_genes_group` run on it. You can search the tests for examples of `check_same_image`. > (i have 3 failing plotting tests locally but they run fine here). Could you open an issue for this and note which tests they are? It would be good to make the tests as resilient as possible on other people's systems.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1942#issuecomment-878134649:812,resilien,resilient,812,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1942#issuecomment-878134649,1,['resilien'],['resilient']
Availability,"> This is the standard way of writing a numpydoc returns section. […] This solution is dropping support for them. It certainly shouldn’t, since the definition lists *are* rendered in other cases. IDK why not here, this should render as a definition list with one item. However, I don’t like indenting the whole section except for the first line, so in case it always works once there are multiple definition list items, I don’t worry too much here. > Also, do you by chance have another simple solution for having the styling of the return sections similar to the parameters section (what numpydoc did :slightly_smiling_face:)? Bold font and spacings around colons?. I’ll figure it out. > I would remove the `, optional` statement from the docstrings, as, what we mean with this is ""a parameter has a default value"". Hence, it's redundant. However, it's consistently used in all of numpy, scipy, sklearn, pandas, etc. We should definitely put the defaults inline, and I also think the “optional” is redundant. What would it even mean to have “a parameter that isn’t optional but has a default value”?. I’m pretty sure people will understand it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/610#issuecomment-484041417:829,redundant,redundant,829,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484041417,2,['redundant'],['redundant']
Availability,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here?. Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks; -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good!. > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes.; > ...; > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway?. > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here?. No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is un",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-781992443:152,down,downloaded,152,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-781992443,1,['down'],['downloaded']
Availability,"> Though if check_values is False, it shouldn't even run the check, correct?. Yes. > So the warning would be more like,; >; > ""'seurat_v3' flavor expects raw count data. Proceed with caution."". I was thinking the warning would only occur if `check_values=True` and non integer values were found. ""partial counts"" are common enough I'd agree it's not reasonable for this to error if the results are still meaningful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1642#issuecomment-777942673:373,error,error,373,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1642#issuecomment-777942673,1,['error'],['error']
Availability,"> Though maybe something simpler is to be able to access a global table of functions and citations, and it gives you the bibtex. @adamgayoso From my point of view, references are already available ([source](https://github.com/theislab/scanpy/blob/master/docs/references.rst), [rendered](https://scanpy.readthedocs.io/en/latest/references.html)) and linked to in the documentation. I'm not against the idea, I'm just not seeing how it makes this information more accessible/ prominent. A separate issue for the topic would be good for more discussion. ---------------------. > Would really welcome that. I can help where I can, although not so familiar with numba. @LuckyMD, meant to say, `numba` is super easy, it's really just python. Next best thing to Julia. Definitely worth some time to learn, but also it won't take that much time to learn.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/915#issuecomment-765107026:187,avail,available,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915#issuecomment-765107026,1,['avail'],['available']
Availability,> Throw an error if something other than an AnnData is passed in. I am in favor of this (so it seems like @Intron7 and I agree on this). And then using some sort of `key` arguments to specify where to fetch the aggregatable data from. > Maybe in future this could get a return_type: type[AnnData] | type[Dict] | type[xr.Dataset] = AnnData argument that controls what is returned?. I would also be in favor of this if we want to leave the option of getting a `dict` back.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2930#issuecomment-2007335971:11,error,error,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2930#issuecomment-2007335971,1,['error'],['error']
Availability,"> To be able to reproduce and help, it is a big aid for us if you can supply a code sample that we can run: that is, with some dummy data (the datasets scanpy readily supplies are great for that), and the error/unexpected behaviour you get. Can you show such an example, with data? It is not immediately clear to me what specific you are trying to add or construct; I'm not sure whether basically the dataframe gets destroyed by the operation you intend to perform, or whether it is the violin plot failing (if the dataframe is crooked, it would be this to be fixed)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3005#issuecomment-2066797546:205,error,error,205,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005#issuecomment-2066797546,1,['error'],['error']
Availability,"> When I run [`conda install python=3.11` and `conda install -c conda-forge scanpy`] I get an error . Yeah no idea how to debug conda conflicts. I’ve often seen things like this: completely unrelated packages “conflicting” containing cryptic symbols like `feature:|@/osx-64::__osx==10.16=0`. No clue what that means. Conda seems to be unable to figure out which user-specified versions are in conflict with each other. Pip seems to do a better job these days:. > Running this with `pip -vv install scanpy` as you suggested indeed gives an error with numba. Exactly, so this is a numba issue. Please follow https://github.com/numba/numba/issues/8304. Once numba supports Python 3.11, you’ll be able to install any dependent project there (including scanpy)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1333418043:94,error,error,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1333418043,2,['error'],['error']
Availability,"> While the single command works `adata = adata[adata[: , 'A'].X > 1, :]`; > ; > The compound command gives me the following error: TypeError: unsupported operand type(s) for &: 'SparseCSRView' and 'SparseCSRView'. Have you solved it? I have a similar problem. . My code:; adata = adata[(adata[: , 'A'].X > 0) & (adata[:, 'B'].X > 0), :]; # TypeError: unsupported operand type(s) for &: 'SparseCSRView' and 'SparseCSRView'. However, ; adata = adata[(adata[: , 'A'].X > 0), :]; It works greatly.; Hope to get help, thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1870#issuecomment-1192133374:125,error,error,125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1870#issuecomment-1192133374,1,['error'],['error']
Availability,"> Why is this PR getting a build if there is no `pr` trigger entry in the yaml?. See 3 paragraphs down:. > If no pr triggers appear in your YAML file, pull request validations are automatically enabled for all branches, as if you wrote the following pr trigger. This configuration triggers a build when any pull request is created, and when commits come into the source branch of any active pull request.; > ; > ```; > pr:; > branches:; > include:; > - '*' # must quote since ""*"" is a YAML reserved character; we want a string; > ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1516#issuecomment-737862275:98,down,down,98,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516#issuecomment-737862275,1,['down'],['down']
Availability,"> Yeah, I can't reproduce it with a canned dataset either --- I'm doing something a bit weird and transforming imaging mass cytometry data into AnnData objects (hence the imctools dependency). I have an object that looks like:. thank you for reporting, this is very interesting use case! and thanks for the detailed evaluation. I would also try with different number of PCs to see whether that has an impact. if you open an issue on `pynndescent`, would you mind referencing this issue or pinging me there, would be interested to see what's the proposed solution/bug. @TiongSun let us know about your use case, thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696#issuecomment-797652809:489,ping,pinging,489,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696#issuecomment-797652809,1,['ping'],['pinging']
Availability,"> ```; > MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax ; > simultaneously is deprecated since 3.3 and will become an error two minor releases ; > later. Please pass vmin/vmax directly to the norm when creating it.; > ```. Yeah, that actually re-ignited my idea of adding support for vcenter after upgrading mpl :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1551#issuecomment-748679208:139,error,error,139,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551#issuecomment-748679208,1,['error'],['error']
Availability,"> ```python; > scipy.io.mmwrite; > ```. This code doesn't actually work - rows and columns are switched in the matrix, and it produces an error when you try to read in the output using either `Scanpy` or `Seurat` wrapper functions. Perhaps it's a package version thing though..",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/262#issuecomment-1476035869:138,error,error,138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/262#issuecomment-1476035869,1,['error'],['error']
Availability,"> `batch1.X.mean(1)` should give you the desired result.; > Or maybe i don't get what you actually need. Thanks for the reply. Sometimes I got index error when I used the subset data view for further analysis, saying the dimension was not matched. ; It could be solved by assigning .copy() when subsetting the adata. So I was just wondering if any memory-efficient way to do this also?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1940#issuecomment-877836520:149,error,error,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1940#issuecomment-877836520,1,['error'],['error']
Availability,"> `paul15` is downloaded automatically, very practical. Yeah, it’s really cool for interactive use, but not for automated testing / continuous integration I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-364372580:14,down,downloaded,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-364372580,1,['down'],['downloaded']
Availability,"> adata.uns['log1p'][""base""] = None. Thank you. I also had this error when calculating highly variable genes `sc.pp.highly_variable_genes(Adult,batch_key='batch')`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2239#issuecomment-1184556213:64,error,error,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1184556213,1,['error'],['error']
Availability,"> and I'm fairly certain this has to do with the call to NNDescent in umap.umap_.py as if I import that directly, it raises the same errors. sorry just read this, this sounds it could be potentially data specific, have you tried playing around with other nndescent params?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696#issuecomment-797640822:133,error,errors,133,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696#issuecomment-797640822,1,['error'],['errors']
Availability,"> anndata.AnnData(). Thank you for you suggestion! I failed all other methods, including anndata2ri. God know why I encounter so much error. And I've posted issue in the specific place.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/808#issuecomment-527131466:134,error,error,134,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/808#issuecomment-527131466,1,['error'],['error']
Availability,"> any(broken) checks if there’s under-indented lines. Sure, but the error it throws is: ```""Header of function `{name}`’s docstring should start with one-line description:""```, which suggests that wasn't the intent of the check. If it's a check for white space, it should throw an error about white space.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1492#issuecomment-726019005:68,error,error,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492#issuecomment-726019005,2,['error'],['error']
Availability,"> hi @yotamcons ,; > ; > thanks a lot for the feedback, we'd really appreciate if you could submit a PR fixing these parts of the documentations that needs to be updated. Happy to support if you need any help,; > ; > Thank you!. Would love to starting November, ping me if thats still relevant",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2301#issuecomment-1233189531:262,ping,ping,262,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301#issuecomment-1233189531,1,['ping'],['ping']
Availability,"> how about making green just a bit brighter/less bright to make it discernible from red for color-blind people? should not break much. I guess that would be best done by switching the green with another green somewhere down the list to not mess with the color map entirely. Not sure this is a general purpose fix for all types of colorblindness though, no?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/387#issuecomment-444463868:220,down,down,220,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/387#issuecomment-444463868,1,['down'],['down']
Availability,"> it is trying to use linux formatting on a Windows machine. that’s not the issue, forward slashes and relative paths work perfectly on windows. The issue is that this code uses string manipulation to work with paths, which is error-prone. https://github.com/theislab/scanpy/blob/f33924011f7d0a7924fada933e1a20d7b5ceaac3/scanpy/readwrite.py#L440-L441. @falexwolf using `pathlib` for path manipulation as much as possible protects us from mistakes like this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/563#issuecomment-477527532:227,error,error-prone,227,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/563#issuecomment-477527532,1,['error'],['error-prone']
Availability,"> it would still be the older conda-forge version that gets installed. This could be overcome by pinning the channel but I agree it could be an issue if not explicitly specified. > Also there is [no mention of singularity in the bioconda docs](https://bioconda.github.io/search.html?q=singularity). This is the Github repo used for all of the automation and is hosted by the Galaxy project:; https://github.com/BioContainers/singularity-build-bot. As others have mentioned here, it would be awesome to have the latest versions of `scanpy` on Bioconda because it is the primary channel for most Bioinformatics tools. This also allows other communities like nf-core to piggy back off their automation to make our lives easier when writing reproducible, standardised workflows. @grst did come up with a couple of workarounds like adding a mulled container with scanpy but that adds a maintenance overhead to keep things up-to-date. How much work would it be to make this happen @ivirshup and would you be willing to help?. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160340283:881,mainten,maintenance,881,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160340283,1,['mainten'],['maintenance']
Availability,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review?. Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”?. Also: can we reenable squash/rebase merges soon?. > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-777397179:383,failure,failures,383,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-777397179,2,['failure'],"['failure', 'failures']"
Availability,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata.; 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized.; 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476#issuecomment-730939013:1025,down,down,1025,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476#issuecomment-730939013,1,['down'],['down']
Availability,"> pip install git+git://github.com/theislab/scanpy.git . should have worked, there seems to be a problem with your git installation or internet. > importlib_metadata.PackageNotFoundError: scanpy. That’s my mistake, seems like a broke installing from .zips (not that anyone tried so far, installing from git is more convenient). > pip install https://github.com/theislab/scanpy.git. This won’t work, `pip install http...` means “install me a `sdist` or `wheel` downloadable from that URL”, but there’s no sdist or wheel at that URL, but a git repository. > git clone --recursive git://github.com/theislab/scanpy.git. again, this should work, probably a problem with your internet or git installation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/838#issuecomment-533014138:460,down,downloadable,460,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838#issuecomment-533014138,1,['down'],['downloadable']
Availability,"> tests that check if combinations of input arguments lead to expected output (in terms of returned shapes/columns/...) and don't break the function; tests that check if warnings/errors are raised for ""common mistakes"" (inappropriate data, nonsense input argument combinations..). yes both makes sense, it would also be useful to come up with a dummy example for which the actual output could be tested against. This is done in seurat_v3 for instance, but in that case it's kind of straightforward because the ""expected"" is the output computed with original implementation (and as you catched in #1732 it's still might not be enough 😄 ).; another random thing that comes to mind re this specific case is to make sure that indexing etc. is consistent and robust, as you seem to have to sort and resort a fair bit in the hvg implementation. on another note, I was thinking if it makes sense to also release a short tutorial together with the PR (that would be on theislab/scanpy_tutorials) ? I think that for a lot of people the term ""pearson residuals"" could be alienating, and so they'd rather stick to `normalize_total` for comfort (but they shouldn't!). So maybe just something easy like pearson res norm + umap and hvg plots ? curious to hear what you and the others @ivirshup @LuckyMD think about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-797462245:179,error,errors,179,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-797462245,2,"['error', 'robust']","['errors', 'robust']"
Availability,"> thank you @jlause for the PR! This is really exciting and super useful!; > This is a first round of review, most comments are re types, args and function behviour. I think it looks really good overall and maybe it's time to start writing tests ?; > please let me know if anything unclear and also thanks in advance for code explanations!. Hey @giovp ,; thanks a lot for the review, this looks very helpful! I'll address the single points above one-by-one and make the required changes over the next few days! Will also add some first tests - are there formal guidelines what you expect to be tested? After looking at the tests for `highly_variable_genes`, from my naive perspective I'd test the following:. - tests that check if combinations of input arguments lead to expected output (in terms of returned shapes/columns/...) and don't break the function; - tests that check if warnings/errors are raised for ""common mistakes"" (inappropriate data, nonsense input argument combinations..). Any advice/ideas what else should be tested?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-797435681:890,error,errors,890,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-797435681,1,['error'],['errors']
Availability,"> thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. No worries!. I think communicating about the ideas we have for these tools can be fraught. > in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot). I don't think this is the case. . First, I believe there are non-visium grid based spatial methods (I remember seeing a product page for one, but can't find it atm). Second, I think you don't need segmentation info to use this function. You just need coordinates (probably derived from segmentation) and possibly an image. Like this:. > unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units. But I think a user already having done the segmentation, then coming to scanpy is a reasonable workflow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1512#issuecomment-742217703:686,mask,mask,686,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512#issuecomment-742217703,1,['mask'],['mask']
Availability,"> the main hpc I'm on 1gb of space where appdirs would put these files. That's a misconfigured server, not a normal case. We should use appdirs as default, catch a IOError on write, and send a nice message like. > Error: Cannot write to your cache directory. Please make sure there's space in {cache_dir!r} or override the cache directory by setting one of the $SCANPY_CACHE_DIR or $XDG_CACHE_DIR environment variables. All linux-based systems should set $XDG_CACHE_DIR if there's a better place than ~/.cache for such files.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-476675808:214,Error,Error,214,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476675808,1,['Error'],['Error']
Availability,"> then I'd say NearMiss and related are straightforward and scalable (just need to compute a kmeans whcih is really fast). For sampling from datasets, I would want to go with either extremely straightforward or something that has been shown to work. Maybe we could start with use provided labels to downsample by?. > reshuflling is performed. Reshuffling meaning that the order is changed?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/987#issuecomment-1054247364:299,down,downsample,299,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/987#issuecomment-1054247364,1,['down'],['downsample']
Availability,"> with some name like key=image_name and value=path ? or something like that. sure! What do you mean with image_name? As downloaded from the 10x website, the tiff image always has the same filename (""image.tif""). Or do you mean the string ""image_name"" as key?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1506#issuecomment-733618049:121,down,downloaded,121,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506#issuecomment-733618049,1,['down'],['downloaded']
Availability,">; ----> 1 sc.pl.dotplot(adata_2, adata_2.var_names[0:4], groupby='celltype', color_map = 'Reds'). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\plotting\_anndata.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, color_map, dot_max, dot_min, standard_scale, smallest_dot, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, show, save, **kwds); 1809 num_categories,; 1810 layer=layer,; -> 1811 gene_symbols=gene_symbols,; 1812 ); 1813 . ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\plotting\_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 2911 matrix = adata[:, var_names].layers[layer]; 2912 elif use_raw:; -> 2913 matrix = adata.raw[:, var_names].X; 2914 else:; 2915 matrix = adata[:, var_names].X. ~\Anaconda3\envs\UMCU\lib\site-packages\anndata\_core\raw.py in __getitem__(self, index); 94 ; 95 def __getitem__(self, index):; ---> 96 oidx, vidx = self._normalize_indices(index); 97 ; 98 # To preserve two dimensional shape. ~\Anaconda3\envs\UMCU\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index); 154 obs, var = unpack_index(packed_index); 155 obs = _normalize_index(obs, self._adata.obs_names); --> 156 var = _normalize_index(var, self.var_names); 157 return obs, var; 158 . ~\Anaconda3\envs\UMCU\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index); 91 not_found = indexer[positions < 0]; 92 raise KeyError(; ---> 93 f""Values {list(not_found)}, from {list(indexer)}, ""; 94 ""are not valid obs/ var names or indices.""; 95 ). KeyError: ""Values ['Rgs20', 'Oprk1', 'St18', 'Gm26901'], from ['Rgs20', 'Oprk1', 'St18', 'Gm26901'], are not valid obs/ var names or indices."". sc.pl.matrixplot(adata_2, adata_2.var_names[0:4], groupby='celltype') #same error; sc.pl.tsne(adata_2, color=adata_2.var_names[0:4]) #KeyError: 'Rgs20' . ```. Any help would be much appreciated!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1406#issuecomment-704271652:2757,error,error,2757,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1406#issuecomment-704271652,1,['error'],['error']
Availability,">Only strange thing is the getdoc function. It looks like instance methods can't have new attributes assigned (probably have slots). It's possible the `.getdoc` attribute could be added to the classes method (not sure if that's the right way to say that, here's an example):. ```python; class Foo(object):; def bar(self):; return 1. # Setting an attribute on the method of an instance raises an error; Foo().bar.x = 1; # AttributeError: 'method' object has no attribute 'x'. # Setting an attribute on the method of a class seems fine:; Foo.bar.x = 1 ; Foo().bar.x; # 1; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/573#issuecomment-479758866:395,error,error,395,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479758866,1,['error'],['error']
Availability,"@Chenyanjuan1993 thank you for reporting this. I think it's some typing problem with the var_names index, and so possibly regarding your anndata. Can you share the list of commands that you run before that error? Like do you concat/merge? Also, could you run that with this anndata `adata = scanpy.datasets.pbmc3k()`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1406#issuecomment-708958791:206,error,error,206,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1406#issuecomment-708958791,1,['error'],['error']
Availability,@HypoChloremic . Right now the error is gone but still got three weird PAGA pathay graphs shown below:. ![下載 (1)](https://user-images.githubusercontent.com/57272642/80285540-c1833d80-86f3-11ea-9a35-4fdf7385eaab.png); ![下載 (2)](https://user-images.githubusercontent.com/57272642/80285541-c47e2e00-86f3-11ea-9b10-1427ccfc978e.png); ![下載 (3)](https://user-images.githubusercontent.com/57272642/80285543-c7791e80-86f3-11ea-8c66-9ec7226de7c6.png),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1168#issuecomment-619409104:31,error,error,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168#issuecomment-619409104,1,['error'],['error']
Availability,"@HypoChloremic,; I did but it comes out with weird PAGA pathway analysis plot (shown blow) and new error:. ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-46-42a11a5bd10f> in <module>; 19 show=True,; 20 use_raw=False); ---> 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)); 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""); 23 pl.show(). ~\Miniconda3\envs\project\lib\site-packages\pandas\core\generic.py in to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal); 3226 decimal=decimal,; 3227 ); -> 3228 formatter.save(); 3229 ; 3230 if path_or_buf is None:. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\formats\csvs.py in save(self); 181 self.mode,; 182 encoding=self.encoding,; --> 183 compression=self.compression,; 184 ); 185 close = True. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\common.py in _get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text); 397 if encoding:; 398 # Encoding; --> 399 f = open(path_or_buf, mode, encoding=encoding, newline=""""); 400 elif is_text:; 401 # No explicit encoding. FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lin/write/paga_path_DC/LC.csv'. [下載](https://user-images.githubusercontent.com/57272642/80230003-47818480-861f-11ea-96ce-db1128b4a6eb.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1168#issuecomment-619083501:99,error,error,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168#issuecomment-619083501,1,['error'],['error']
Availability,@Koncopd @ivirshup can you have a look at this? CI fails for some weird docs error that we can't nail down.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476#issuecomment-723092789:77,error,error,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476#issuecomment-723092789,2,"['down', 'error']","['down', 'error']"
Availability,"@Koncopd Currently breaking test for me:. ```pytb; $ pytest -k test_ingest; ===================================================== test session starts =====================================================; platform darwin -- Python 3.7.6, pytest-5.3.5, py-1.8.0, pluggy-0.12.0; rootdir: /Users/isaac/github/scanpy, inifile: pytest.ini, testpaths: scanpy/tests/; plugins: pylama-7.7.1, parallel-0.0.10, cov-2.7.1, black-0.3.7, hypothesis-5.6.0; collected 393 items / 389 deselected / 4 skipped . scanpy/tests/test_ingest.py ...F [100%]. ========================================================== FAILURES ===========================================================; _______________________________________________ test_ingest_map_embedding_umap ________________________________________________. def test_ingest_map_embedding_umap():; adata_ref = sc.AnnData(X); adata_new = sc.AnnData(T); ; sc.pp.neighbors(; adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0; ); sc.tl.umap(adata_ref, random_state=0); ; ing = sc.tl.Ingest(adata_ref); ing.fit(adata_new); ing.map_embedding(method='umap'); ; reducer = UMAP(min_dist=0.5, random_state=0, n_neighbors=4); reducer.fit(X); umap_transformed_t = reducer.transform(T); ; > assert np.allclose(ing._obsm['X_umap'], umap_transformed_t); E assert False; E + where False = <function allclose at 0x119616b00>(array([[16.566338, 20.174282],\n [15.368203, 20.291983]], dtype=float32), array([[16.502459, 20.157679],\n [15.581459, 20.302881]], dtype=float32)); E + where <function allclose at 0x119616b00> = np.allclose. scanpy/tests/test_ingest.py:140: AssertionError; ---------------------------------------------------- Captured stderr call -----------------------------------------------------; computing neighbors; finished: added to `.uns['neighbors']`; 'distances', distances for each pair of neighbors; 'connectivities', weighted adjacency matrix (0:00:00); computing UMAP; finished: added; 'X_umap', UMAP coordinates (adata.obsm) (0:00:00); ``",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1036#issuecomment-599469073:594,FAILURE,FAILURES,594,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036#issuecomment-599469073,1,['FAILURE'],['FAILURES']
Availability,"@Koncopd here's an example of the current implementation breaking down at `n=3`. ```python; def walk_nsteps_current(adj, n=1):; adj = adj.copy(); if n > 1:; # get up to n_rings order connections; adj += adj ** n; adj.setdiag(0); adj.eliminate_zeros(); adj.data[:] = 1.0; return adj. fig, axes = plt.subplots(nrows=3); # Fixed circle layout; pos = {i: (np.cos(-np.pi + (np.pi * i) / 4), np.sin(-np.pi + (np.pi * i) / 4)) for i in range(5)}. for n, ax in enumerate(axes):; nx.draw(; nx.Graph(walk_nsteps_current(adj, n + 1)), # making sure we start at 1; pos=pos,; ax=ax,; ); ; plt.show(); ```. ![image](https://user-images.githubusercontent.com/8238804/94672185-3cfab200-0358-11eb-84d6-11abe07f7f1c.png). For `n=3` you're missing the neighbors at depth=2. Basically, you're just jumping to the 3rd step, instead of accumulating neighbors up to that step.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1383#issuecomment-701296035:66,down,down,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1383#issuecomment-701296035,1,['down'],['down']
Availability,"@Koncopd, this seems to work for me. But also it looks like `install_opener` modifies global state and we shouldn't do that. In theory it shouldn't be too difficult to both start a download with a header, and write the result to a file, but it's not obvious `urllib` has anything to help do that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1334#issuecomment-664837370:181,down,download,181,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334#issuecomment-664837370,1,['down'],['download']
Availability,@LouisFaure Great!; While I agree with your comments and suggestions I think that for now you can save yourself the time to implement them since they are likely to run into further merge conflicts down the road. ; The GPU CI is certainly off weeks if not months. As soon as it's ready I would ping you again and we can get this PR ready. Does this sound fine to you? Thanks again! Looking forward to GPU accelerated Scanpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-816784411:197,down,down,197,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533#issuecomment-816784411,2,"['down', 'ping']","['down', 'ping']"
Availability,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph; ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/807#issuecomment-638548074:111,error,error,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807#issuecomment-638548074,3,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"@LuckyMD @maximilianh Thanks guys for the reply. ; Sorry I'm just used to Seurat setup and kind of got lost. Long story short my issue is negative values, after data processing and scaling I have negative values in the expression matrix that throughs off my downstream analysis. But before scaling adata.X format looks completely different (as I mentioned in my previous post). I just want to have a matrix of gene/cell. . If I export using cell browser tool I get same values as processed adata.X ; If I do ; `adata.to_df().to_csv('./adata.csv', sep=',')`. or if I do . ```; import scanpy.external as sce; sce.exporting.cellbrowser(adata, './test', 'adata', embedding_keys=None, annot_keys=['louvain'], cluster_field='louvain'); ```. it generates exactly same expression matrix, I don't really see the raw value matrix",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/506#issuecomment-468460649:258,down,downstream,258,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506#issuecomment-468460649,1,['down'],['downstream']
Availability,"@LuckyMD Dear Malte, Thanks a lot for your hint and reply.; Regarding to the subset, well I got actually the cells that I needed with same number of the genes that I had before so I assume it is fine.; I did a rescale of my data to 10 again but unfortunately the same warning is happening! ; I don't know really if turning all negative values to zero would really make sense because first of all as I mentioned I had negative values before and it was not a problem and if I turn all those negative values to zero I guess I will lose quite a bit of genes during my downstream analysis. What I can imagine is those problematic values are anyway not considered during the marker analysis so in the case they are NaN turning them to zero wouldn't affect my result. my fear was mainly that those genes may be really something and due to a bug or a miscommand I am not getting them but I think it is a rare probability. I guess I should leave it as it is. I will though try to take the sc.tl.rank_genes_groups function code and run it step by step",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/653#issuecomment-494351528:564,down,downstream,564,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494351528,1,['down'],['downstream']
Availability,@LuckyMD Its up to you all where'd you like it. I thought it was a pretty core tool. What is the expectation for maintenance in core vs external?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1432#issuecomment-698884956:113,mainten,maintenance,113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432#issuecomment-698884956,1,['mainten'],['maintenance']
Availability,"@LuckyMD Thanks! Yes, the algorithm has been in development for quite some time. I presented it already in 2016 at a conference in Amsterdam, and after that in several other places. It kept changing in relatively minor ways, although that also affected the exact guarantees it could offer. Unfortunate that the section on disconnected communities got trimmed down! Would you have more extensive results described somewhere else?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/350#issuecomment-439188030:359,down,down,359,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350#issuecomment-439188030,1,['down'],['down']
Availability,"@LuckyMD Thanks. This agrees with what I suspected: that randomized PCA itself should be pretty stable, but downstream clustering procedures can be very unstable. I have little experience with clustering so I cannot really comment further, but this certainly should be a big red flag for taking a clustering result seriously. It's especially impressive that float32 vs float64 can cause such a difference. Did you observe this influencing t-SNE/UMAP/etc equally drastically, or did it only affect clustering so strongly?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/325#issuecomment-436013237:108,down,downstream,108,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325#issuecomment-436013237,1,['down'],['downstream']
Availability,"@LuckyMD is this the correct way of using pd.crosstab() ? I am getting an error as seen below:. adata_fibro.crosstab(""patient_id"",""louvain"", rownames=['louvain'], colnames=['patient_id']). ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-95-d09a5110597d> in <module>(); ----> 1 adata_fibro.crosstab(""patient_id"",""louvain"", rownames=['louvain'], colnames=['patient_id']). AttributeError: 'AnnData' object has no attribute 'crosstab'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/584#issuecomment-482815578:74,error,error,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/584#issuecomment-482815578,1,['error'],['error']
Availability,@LuckyMD yea after some further investigation I do agree with you! do you already know a method which can I use to scale my data to non-negative values? then I can scale my data only once and right after imputation and that should be fine for the rest of downstream analysis including the sub-clustering,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/653#issuecomment-494571722:255,down,downstream,255,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494571722,1,['down'],['downstream']
Availability,@MichaelPeibo Could you install the version 1.4.5.post1? It is not available in conda and with 1.4.4.post1 I'm getting the same error. Thanks!. ```; conda search -c bioconda scanpy; Loading channels: done; # Name Version Build Channel ; scanpy 1.3.1 py36_0 bioconda ; scanpy 1.3.2 py36_0 bioconda ; scanpy 1.3.3 py36_0 bioconda ; scanpy 1.3.4 py36_0 bioconda ; scanpy 1.3.5 py36_0 bioconda ; scanpy 1.3.6 py36_0 bioconda ; scanpy 1.3.7 py36_0 bioconda ; scanpy 1.4 py_0 bioconda ; scanpy 1.4.1 py_0 bioconda ; scanpy 1.4.2 py_0 bioconda ; scanpy 1.4.3 py_0 bioconda ; scanpy 1.4.4 py_0 bioconda ; scanpy 1.4.4 py_1 bioconda ; scanpy 1.4.4.post1 py_0 bioconda ; scanpy 1.4.4.post1 py_1 bioconda ; scanpy 1.4.4.post1 py_2 bioconda ; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/942#issuecomment-577681828:67,avail,available,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/942#issuecomment-577681828,2,"['avail', 'error']","['available', 'error']"
Availability,"@OnlyBelter I'm not getting an error from that, but I am getting a bunch of warnings, which makes it seem like something weird is going on. I'm going to split this into a new issue while we investigate, since it seems a bit different.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-863733680:31,error,error,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-863733680,1,['error'],['error']
Availability,"@PGmajev, I would recommend setting up pre-commit for the repo (as described in the contributing guide [here](https://scanpy.readthedocs.io/en/latest/dev/getting-set-up.html#pre-commit)). It should save you from dealing with these formatting errors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2179#issuecomment-1074431745:242,error,errors,242,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179#issuecomment-1074431745,1,['error'],['errors']
Availability,"@RubenVanEsch Can you provide a more minimally reproducible example?. For example, paring down a bit the above to just:. ```python; import scanpy as sc. em_adata = sc.datasets.pbmc3k(). sc.pp.pca(em_adata, n_comps=50); sc.pp.neighbors(em_adata); sc.tl.umap(em_adata); sc.tl.leiden(em_adata,flavor='igraph',n_iterations=2,random_state=1653,directed=False); ```; does not yield any error. ~~Could you share your system info i.e., widows or mac?~~",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2034402907:90,down,down,90,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2034402907,2,"['down', 'error']","['down', 'error']"
Availability,"@RubenVanEsch Yes, and the issue there is that we're not the ones calling `randint`. We may be able to hack it. I'll have a look at how the pipeline errors out on our CI to maybe see where the call is coming from.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2034529457:149,error,errors,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2034529457,1,['error'],['errors']
Availability,"@WeilerP would you be willing to write a tiny test and to add the release note, please?. Thanks! Happy to merge this then if you ping me. @ivirshup generally, I agree. Think that this tiny change doesn't harm though and deprecating the magic ""read"" is something bigger.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1969#issuecomment-1291807007:129,ping,ping,129,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1969#issuecomment-1291807007,1,['ping'],['ping']
Availability,"@Zethson I believe that's an upstream issue. Looks like the docs broke when `sphinx-autodoc-typehints` bumped versions from `1.12.0` to `1.13.0`. I can build the docs locally from `master` and from this branch with `sphinx-autodoc-typehints` v1.12, but not v1.13. (You'll also see an identical error in #2099, despite that just being a dependency bump for pre-commit.). I'll submit a PR to pin `sphinx-autodoc-typehints` to version 1.12.0 shortly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1828#issuecomment-1005072811:294,error,error,294,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1828#issuecomment-1005072811,1,['error'],['error']
Availability,"@Zifeng1995, @ivirshup . I received the same error caused by wrong shape of ""numer"" in line 268 in _combat.py. ; In my case, I could resolved this problem by generating unique cell names ( i.e. adata.obs_names) as following. . **Workaround** ; Before combat execution, in concatenate process of batch data, I specified index_unique='-' . ; e.g.) adata1.concatenate(adata2, adata3, ..., index_unique='-'). When index_unique=None, the error was occurred. However index_unique='-' was fine in my case.; I'm afraid that couldn't trace root cause of this problem due to busy day, but I hope this helps you. . Sincerely.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1170#issuecomment-628401842:45,error,error,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170#issuecomment-628401842,2,['error'],['error']
Availability,"@aditisk that depends on what you put in `adata.raw` ;). Initially `adata.raw` was used to store the full gene object when `adata.X` was filtered to only include HVGs or remove genes that aren't expressed in enough cells. Now, we just have a boolean mask in `adata.var['highly_variable']` for HVGs and so it's often not used anymore. I typically store my log-normalized expression data there if I do batch correction or regress anything out, as `adata.raw` is used as default to compute `rank_genes_groups` and to show expression values on an embedding plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1039#issuecomment-617882284:250,mask,mask,250,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039#issuecomment-617882284,1,['mask'],['mask']
Availability,"@akshayka thanks for contributing to the conversation! The package does indeed look interesting. A couple questions about the tool:. Can we get a weighted graph out of the fit embedding object? For context, we use the UMAP weighted connectivity graph for a number of downstream tasks. This seems related to distortions, but maybe not quite what they are. I'm also wondering about just how early the package is. I would like to be able to take advantage of any new features, and wouldn't want an early API decision to lock us out of those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2154#issuecomment-1057928027:267,down,downstream,267,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1057928027,1,['down'],['downstream']
Availability,@brianpenghe Did you find a solution for this? I am getting the same error in scanpy 1.7.0.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1487#issuecomment-848420774:69,error,error,69,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487#issuecomment-848420774,1,['error'],['error']
Availability,@brianpenghe Hi may I consult how you resolved the problem?. The comment says upgrade anndata to 0.8.0 but mine already is 0.8.0 and the error message remains.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1447928394:137,error,error,137,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1447928394,1,['error'],['error']
Availability,@brianpenghe What column did you add to the genes.tsv so that it worked? I currently have a genes.tsv file with one column for the gene names and am getting the same error as you did. Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2053#issuecomment-1180871625:166,error,error,166,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2053#issuecomment-1180871625,1,['error'],['error']
Availability,"@chris-rands, that section of the Seurat tutorial also ends in these points:. > * We encourage users to repeat downstream analyses with a different number of PCs (10, 15, or even 50!). As you will observe, the results often do not differ dramatically.; > * We advise users to err on the higher side when choosing this parameter. For example, performing downstream analyses with only 5 PCs does significantly and adversely affect results. > Can anyone explain/show literature on if/why the scanpy default of 50 PCs works well?. I think there is enough to show that PCA works well. I'm not sure if I can show you a paper that says either choosing a high cutoff, or using jackstraw/ elbow plots gives better downstream results. I'd note that the [cited paper](https://www.cell.com/fulltext/S0092-8674(15)00549-8) for the Seurat tutorial doesn't seem to evaluate this. ---------------. @wolf5996, I'm not sure I agree with your point that lower PCs are more likely to contain non biological variability. I don't think that a component which explains more variability in the dataset would necessarily represent biological variability. As an example, if we have a dataset with two evenly sized batches, and a rare cell type which makes up ~1% of the population, wouldn't a PC representing the batch explain much more variability than a PC corresponding to the rare cell type?. Anecdotally, I can say batch effects can show up in high principal components.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/872#issuecomment-822286073:111,down,downstream,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/872#issuecomment-822286073,3,['down'],['downstream']
Availability,"@dawe Could you also please provide a brief tutorial on how to install `scanpy` on M1? I am having troubles. I have followed [this tutorial ](https://medium.com/geekculture/the-best-way-to-setup-your-m1-mac-for-python-development-fb5dffd08fd) to set up python on my M1 Mac. Thus I have installed `miniforge` with `brew`. My versions are `Python 3.9.6` and `pip 21.2.4`. Also I have read that you succeed in install `scanpy` with `python 3.8` but I am not able to downgrade version. The error I face when I run `pip3 install scanpy` is:. ```; ERROR: Command errored out with exit status 1: /opt/homebrew/Caskroom/miniforge/base/bin/python3.9 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/y_/5kkrlhbj2v1bch8snxxws28c0000gn/T/pip-install-6blz73pw/h5py_c0efce6062af4b4d9f6564a97c24d1a7/setup.py'""'""'; __file__='""'""'/private/var/folders/y_/5kkrlhbj2v1bch8snxxws28c0000gn/T/pip-install-6blz73pw/h5py_c0efce6062af4b4d9f6564a97c24d1a7/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /private/var/folders/y_/5kkrlhbj2v1bch8snxxws28c0000gn/T/pip-record-lf5rwuj7/install-record.txt --single-version-externally-managed --compile --install-headers /opt/homebrew/Caskroom/miniforge/base/include/python3.9/h5py Check the logs for full command output.```. Thank you in advance!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1840#issuecomment-930949004:463,down,downgrade,463,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840#issuecomment-930949004,4,"['ERROR', 'down', 'error']","['ERROR', 'downgrade', 'error', 'errored']"
Availability,@falexwolf Do you think that these errors come from the code that I modified? I think I didn't touch the function that @bebatut is using.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/311#issuecomment-432212556:35,error,errors,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/311#issuecomment-432212556,1,['error'],['errors']
Availability,"@falexwolf I like the idea of downloading the data on the fly!. For an idea of a small dataset that is already filtered and normalized, do you know if the pbmc data from 10x Genomics has some restrictions? ... nevermind, they have a Creative Commons licence.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/207#issuecomment-405579971:30,down,downloading,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/207#issuecomment-405579971,1,['down'],['downloading']
Availability,@falexwolf Is there anyplace where we can read into `diffxpy`? I've been benchmarking available marker gene detection algorithms and am interested to see what is included in this new package.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/159#issuecomment-420362783:86,avail,available,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159#issuecomment-420362783,1,['avail'],['available']
Availability,"@falexwolf Thanks for the support. . I agree that this is not an urgent changes that can quietly be tested. Have you consider having a 'develop' branch were we can put all code like this? . As you point out some differences are seen with respect to the shape of the plot when multiple panels are plot. This is mostly due to some code to add space for the colorbar and legends that can overlap nearby figures. Nevertheless, I can further adjust this to get plots that are more similar to the actual ones. I think that the tests are failing because there is a clash between the module and a method called `scatter`. Once the code is cleaned this should go away. . If you don't mind I would slowly start removing redundant code and adding further tests. So, lets keep this PR open.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-416855357:710,redundant,redundant,710,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-416855357,1,['redundant'],['redundant']
Availability,@falexwolf This issue still persists in version 1.9.1. and the work around suggested by @Xparx results in the same error that @haskankaya has reported. Any advice on how to get around this or a potential fix?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/409#issuecomment-1431522729:115,error,error,115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/409#issuecomment-1431522729,1,['error'],['error']
Availability,"@falexwolf the problem is that there are functions that do now work without them and our down stream packages do not work ootb. Would it be possible to add a second file, e.g. `requirements-ect.txt` to keep track of this?. This file could also be used to create testing environments easily.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/305#issuecomment-433357089:89,down,down,89,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/305#issuecomment-433357089,1,['down'],['down']
Availability,"@falexwolf we just tried the solution you posted and it reveals a bug: when `ax` is not `None` you don't create the variable `axs` and thus throw an error here: https://github.com/theislab/scanpy/blob/master/scanpy/plotting/anndata.py#L634. Should be a simple fix (I think):. ```python; if ax is None:; axs, _, _, _ = setup_axes(ax=ax, panels=['x'] if groupby is None else keys, show_ticks=True, right_margin=0.3); else:; axs = [ax]; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/137#issuecomment-413354154:149,error,error,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/137#issuecomment-413354154,1,['error'],['error']
Availability,"@falexwolf:. It was a mistake to use optional positional parameters for our APIs. The core python team designs all its APIs using almost exclusively keyword-only parameters, because this way, parameters can be added without having to go to the end. (And they’re *much* more conservative and thoughtful in adding parameters in the first place). E.g. in this case there’s only one central important parameter apart from `adata`, so a `*` should be after `n_top`, and @grst could add his parameter before `ax`, leaving `ax` at the end of the pameter list without breaking anything:. ```py; def highest_expr_genes(; adata: AnnData,; n_top: int = 30,; *,; show: Optional[bool] = None,; ...; ax: Optional[Axes] = None,; **kwds,; ). highest_expr_genes(ad, 12, True) # Error: show is a keyword-only param; highest_expr_genes(ad, 12, show=True) # Works; ```. I have an idea how to fix this without breaking everything: I think I can build a decorator that allows people to use parameters positionally, but sends a DeprecationWarning when they do, while the docs only report the new signature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/376#issuecomment-441008995:761,Error,Error,761,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/376#issuecomment-441008995,1,['Error'],['Error']
Availability,"@fbrundu I just had the exact same error after installing from cloned master, so just wondering if it's working for you now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/585#issuecomment-480647524:35,error,error,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/585#issuecomment-480647524,1,['error'],['error']
Availability,"@fidelram Actually, a similar solution does exist for other plotting functions. @falexwolf added the `gene_symbols` parameter to `sc.pl.rank_genes_groups()` and `sc.pl.rank_genes_groups_violin()` as I was having the same issue of using Ensembl gene IDs. I'm not sure if he regrets doing that now though or not... it's not consistently applied. In either case, Ensembl gene IDs are more specific than HGNC/MGI gene symbols. For some users it may be important that this specificity is available (and you don't keep having to make copies of the data to plot). Also, if alternative splicing is investigated with single-cell data, then you cannot keep gene symbols as `var_names` throughout your dataset as a default. So this is a future-proof approach.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/376#issuecomment-441040160:483,avail,available,483,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/376#issuecomment-441040160,1,['avail'],['available']
Availability,"@fidelram again sorry for being late. I hope it doesn't matter that I've blackified one of the files (can revert this).; Not sure how relevant this PR will be, since @VolkerBergen has faster and more robust implementation, but as a triage version, it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1123#issuecomment-653803793:200,robust,robust,200,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123#issuecomment-653803793,1,['robust'],['robust']
Availability,"@fidelram knows more about the plotting code than me, but here's some recommendations:. * Many of the downstream plotting functions for `rank_genes_groups` take `gene_symbols` arguments. See the docs for functions like: `sc.pl.rank_genes_groups_*`; * The `gene_symbols` argument is recent, and is gradually being added to functions.; * You can always set `var_names` to be gene symbols. I prefer keeping `var_names` as unique, canonical identifiers, but sometimes do this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/455#issuecomment-473506355:102,down,downstream,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-473506355,1,['down'],['downstream']
Availability,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git; Collecting git+https://github.com/theislab/scanpy.git; Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp; xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun; Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/544#issuecomment-475325377:96,error,error,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544#issuecomment-475325377,3,['error'],['error']
Availability,"@fidelram that's a really great point and something I'd like to discuss at next meeting (already put it in the agenda). Another great example of such examples 😅 is the way @michalk8 set it up for [cellrank](https://cellrank.readthedocs.io/en/latest/auto_examples/index.html) and squidpy [not yet public].; The even nicer thing is that @michalk8 implemented a CI pipeline for the tutorials/examples part of the repo so that every time there is a change in master of the original repo, the examples are refreshed in the notebooks repo, so to have them always up to date. Would be really cool to concentrate efforts and try to get this logic also in scanpy (makes it both very user friendly and robust from a maintainer perspective)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1604#issuecomment-765363376:692,robust,robust,692,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1604#issuecomment-765363376,1,['robust'],['robust']
Availability,"@fidelram, from `seaborn==0.12` on, the only valid positional argument will be `data` which may cause failures or unexpected behaviour. This is relevant at least [here](https://github.com/theislab/scanpy/blob/f704f724529def21769ee6407f9b47b5c161564c/scanpy/plotting/_anndata.py#L774) and [here](https://github.com/theislab/scanpy/blob/f704f724529def21769ee6407f9b47b5c161564c/scanpy/plotting/_anndata.py#L785). Should we add / specify the keyword argument `x` in this PR or open a separate issue and PR?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1422#issuecomment-694389007:102,failure,failures,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422#issuecomment-694389007,1,['failure'],['failures']
Availability,"@fidelram, just wanted to add that I still cannot use the ```use_raw=False``` parameter, for example I keep getting an error when try to visualise my data with ```sc.pl.rank_genes_groups_heatmap``` or ```sc.pl.rank_genes_groups_matrixplot```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/377#issuecomment-441092773:119,error,error,119,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/377#issuecomment-441092773,1,['error'],['error']
Availability,@flying-sheep @gokceneraslan great! I agree it's hard to compare these algorithms as the performance of an imputation strategy often depends on the downstream use case. I'm looking forward to checking out the countae preprint. I find the [scVI](https://github.com/YosefLab/scVI) benchmark of imputation methods to be useful for now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/45#issuecomment-367680111:148,down,downstream,148,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45#issuecomment-367680111,1,['down'],['downstream']
Availability,"@flying-sheep Added this snippet to eval the coordinates as int and not str (plotting > _utils.py > circles, lines 1138 - 1145):. ```; if not np.issubdtype(x.dtype, np.integer) or not np.issubdtype(; y.dtype, np.integer; ):; try:; x = x.astype(int); y = y.astype(int); except ValueError as e:; print(""Error converting to int:"", e); ```. This has solved my issue and can now see the tissue images using `sc.pl.spatial`. Do feel free to change the code though, this would be my first contribution!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2778#issuecomment-1846833078:301,Error,Error,301,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2778#issuecomment-1846833078,1,['Error'],['Error']
Availability,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code ; ```; pip install git+https://github.com/theislab/scanpy.git ; ```; I got ouput as:; ```; Collecting git+https://github.com/theislab/scanpy.git; Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build; fatal: Unable to find remote helper for 'https'; Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None; ```. second, I tried; ```; pip install git+git://github.com/theislab/scanpy.git ; ```; I got ouput as:; ```; Collecting git+git://github.com/theislab/scanpy.git; Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build; ```; and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```; python setup.py build; ```. I got ouput as:. ```; importlib_metadata.PackageNotFoundError: scanpy; ```. after this, I tried . ```; pip install -e .; ```. I got ouput as:. ```; Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/; ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` ; pip install https://github.com/theislab/scanpy.git; ```. output:. ```; Collecting https://github.com/theislab/scanpy.git; Downloading https://github.com/theislab/scanpy.git; \ 143kB 442kB/s; Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format; Cannot determine archive format of /tmp/pip-xolhyav7-build; ```. and i also tried. ```; git clone --recursive git://github.com/theislab/scanpy.git; ```. output:. ```; Cloning into 'scanpy'...; remote: Enumerating objects: 122, done.; remote: Counting objects: 100% (122/122), done.; remote: Compressi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/838#issuecomment-532985027:80,error,errors,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838#issuecomment-532985027,3,"['down', 'error']","['download', 'error', 'errors']"
Availability,"@flying-sheep I got the similar result. ```python; >>> scanpy-master]$ ls; conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py; >>> scanpy-master]$ git init; Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/; >>> scanpy-master]$ git tag v1.4.5.dev0; fatal: Failed to resolve 'HEAD' as a valid ref.; >>> scanpy-master]$ pip install -e .; Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master; Complete output from command python setup.py egg_info:; Traceback (most recent call last):; File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>; from setuptools_scm import get_version; ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>; from scanpy import __author__, __email__; File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>; __version__ = version(__name__); File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version; return version(package); File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version; return distribution(package).version; File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution; return Distribution.from_name(package); File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name; raise PackageNotFoundError(name); importlib_metadata.PackageNotFoundError: scanpy. -----------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/838#issuecomment-533019090:305,Down,Download,305,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838#issuecomment-533019090,4,['Down'],['Download']
Availability,"@flying-sheep I think the [code added in that PR](https://github.com/scverse/scanpy/pull/2816/files#diff-5d0e683154209be7830f09b5389551bf9700a4184d08e97c46c23e2e4beb54a0) is minimally relevant to what happened here. > when user specifies an order, we use that. Right, so here the issue is that the category ordering is used for the labelling but we were not imposing it on the data itself when the violin plots render (separate from the axis labels, as the actual violin plots are added row-by-row). > if not, we rely on the DataFrame order for plotting, we don’t store this implicit order explicitly. In some sense the above also applies. If we want to add some sort of user-facing part of the API to allow for ordering, that is fine, but I think that should be separate as it would go into the next minor release and this is a fairly large bug. I'm fine not testing this because I genuinely don't know how and I spent a few hours yesterday trying different things to no avail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3196#issuecomment-2271132251:972,avail,avail,972,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196#issuecomment-2271132251,1,['avail'],['avail']
Availability,"@flying-sheep I think the output is clear once you know what is about. Since this error may happen to future contributions that are not aware of the efforts to reduce import times, I think is better to be explicit. Something like: ""Slow import detected (scipy.stats). Please check that slow-to-import packages are not in top level calls but inside the functions that require them"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/797#issuecomment-537510120:82,error,error,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797#issuecomment-537510120,1,['error'],['error']
Availability,"@flying-sheep I thought that by doing `adata[:, 'gene_name'].X` the AnnData object does all sorts of checks which are redundant if I only want to access a single column on the data matrix. But if you say this is fine I will not change it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-422361197:118,redundant,redundant,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-422361197,1,['redundant'],['redundant']
Availability,"@flying-sheep I tried running `pip install 'scanpy @ git+https://github.com/scverse/scanpy@modern-rng' ` in anaconda prompt and got ERROR: Invalid requirement: ""'scanpy"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3028#issuecomment-2085623955:132,ERROR,ERROR,132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028#issuecomment-2085623955,1,['ERROR'],['ERROR']
Availability,@flying-sheep Regarding your first thought... it may cause issues when interfacing with other functions that do not have type annotations on the arguments. And users may then find it difficult to interpret the errors.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-441219613:210,error,errors,210,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-441219613,1,['error'],['errors']
Availability,@flying-sheep Thanks for fielding all this! You never wrote what thought about having the CLI layer in the scanpy repo... my main reason is that I simply think that I cannot maintain a layer that I'm not actively using (at least right now) and that the library maintenance and development is already quite some work...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/281#issuecomment-437729436:261,mainten,maintenance,261,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281#issuecomment-437729436,1,['mainten'],['maintenance']
Availability,"@flying-sheep Thanks for the thorough response! This is a topic I have a lot of thoughts on, though I'm not so sure how coherently I can communicate all of them. On your first thought:. The worst case scenario I see here me typing something so poorly a newbie trying to follow the documentation gets horrible numba errors they can't figure out. This could happen if I hadn't thought about `Set` being a subtype of `Collection`. It can be difficult to know the `abc`s in `typing` are supposed to mean without spending a while using them. For example, this is not what I was expecting:. ```python; >>> issubclass(np.ndarray, typing.Collection); True; >>> issubclass(np.ndarray, typing.Sequence); False; ```. On defining `abc`s for this package, I think it would have to be done in a way where it was easy to discover exactly what is meant by the annotated types. Personally, I read most of my documentation through the ipython repl, where it can be difficult to figure out where a type referenced in a doc string is defined. Otherwise, I'd be interested in seeing how other people are doing it, but like @falexwolf, most of the packages I use don't have type annotations. Again, I think these would be less of an issue if quality writing on type annotation usage, particularly for scientific python, was available. As a Julia user, I found [this blog post](https://white.ucc.asn.au/2018/10/03/Dispatch,-Traits-and-Metaprogramming-Over-Reflection.html) very helpful not just for understanding how to implement trait types in Julia, but also when they're useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-441414363:315,error,errors,315,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-441414363,2,"['avail', 'error']","['available', 'errors']"
Availability,@flying-sheep Thanks! I will take care of the other errors.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1309#issuecomment-656556087:52,error,errors,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309#issuecomment-656556087,1,['error'],['errors']
Availability,@flying-sheep That is correct. There is both an error and the output of the figure without colors in the legend,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3102#issuecomment-2154816100:48,error,error,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102#issuecomment-2154816100,1,['error'],['error']
Availability,"@flying-sheep Yup, I think we need to at least print a better failure message than just returning -1 for the milestone check. It's not a good experience for people that are not familiar with this. @lazappi thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2657#issuecomment-1719024055:62,failure,failure,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2657#issuecomment-1719024055,1,['failure'],['failure']
Availability,"@flying-sheep and idea what's up with this build error? Docstrings are failing tests, but look fine to me. Seems related to https://github.com/theislab/scanpy/commit/3cacdc87ab47bae70b415e93f2fea74a018c39e2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/615#issuecomment-488208287:49,error,error,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/615#issuecomment-488208287,1,['error'],['error']
Availability,@flying-sheep just wait until tomorrow... when the next random error occurs ;).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-668225385:63,error,error,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-668225385,1,['error'],['error']
Availability,"@flying-sheep sorry, I didn't use Jupyter notebook. one is because i am a fresh man in python. second is that our engineer of the lab server told us that we don't have ""??? some image software"" due to the limited memory. (I think, he means we could use R, but we cannot see the figure like Rstudio. we have to save it, download it to our PC, and view the figure.) I would try Juputer tomorrow~",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/850#issuecomment-532654224:319,down,download,319,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/850#issuecomment-532654224,1,['down'],['download']
Availability,@flying-sheep thanks for taking a look. I've fixed the CI errors now and added the deps as suggested.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/830#issuecomment-534981775:58,error,errors,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830#issuecomment-534981775,1,['error'],['errors']
Availability,"@flying-sheep that user experience seems pretty reasonable. I'm wondering if we couldn't cut down on the need to explain by adopting a convention of referencing relevant settings in any function that access them? For example, the docs for `expression_atlas` would have a reference to `dataset_dir`?. Also on point 4, I've definitely had conda exit with helpful errors when I ran out of space.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-478225437:93,down,down,93,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478225437,2,"['down', 'error']","['down', 'errors']"
Availability,"@flying-sheep yes, it's exactly the same problem, with the exactly same error message that only happens when I (or the function) wanna subset an existing adata object",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/363#issuecomment-458658134:72,error,error,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363#issuecomment-458658134,1,['error'],['error']
Availability,"@flying-sheep, any idea what's up with the black error here? Am I at fault, are all the other listed files at fault, some combination of the two?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/989#issuecomment-577146797:49,error,error,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/989#issuecomment-577146797,3,"['error', 'fault']","['error', 'fault']"
Availability,"@flying-sheep, for this, were you thinking to update `adata.obs_vector` to throw errors with ambiguities , `sc.get.obsdf`, or both?. I'm wondering if there should be some period of deprecation warnings for that. I also think it's fair to consider it a bug.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1116#issuecomment-600108886:81,error,errors,81,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1116#issuecomment-600108886,1,['error'],['errors']
Availability,"@galamm, thanks for the report! Also thanks for the example, very useful!. I think I see what the issue is here, though your error is unexpected. Are you using the most recent version of scanpy (1.7.0)?. The `gene_symbols` argument is supposed to refer to column in `var` that has more human readable gene names. The idea here is that you might have some unique identifier as `var_names` (like ensembl ids), but would have something more interpretable sorted in `adata.var[gene_symbols]`. On my machine, I get a `KeyError` when I run your example since there is no column `""TEST""` in `adata.var`. This is expected. It's strange to me that you get a `NameError`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1636#issuecomment-776540580:125,error,error,125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1636#issuecomment-776540580,1,['error'],['error']
Availability,"@giovp I haven't been able to work around the issue. When I rebuild a container with different versions of scanorama, scanpy, numpy, scikit-learn I end up with errors. Most of the time it's this ValueError about the wrong shape. The only different error I noticed is when I tried scanorama 1.6 and there was an error about `concatenate()` not being an available function. . Whenever you find time to update the tutorial, that will be greatly appreciated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2143#issuecomment-1054575633:160,error,errors,160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143#issuecomment-1054575633,4,"['avail', 'error']","['available', 'error', 'errors']"
Availability,"@giovp Looking more into the crashing I was getting with my strange use case, it turns out that I had both (a) a pair of completely correlated features, and (b) very strange count distributions. Once I used a proper variance stabilizing transform (arcsinh in this case) and remove redundant features, I can't reliably reproduce this issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696#issuecomment-802328453:281,redundant,redundant,281,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696#issuecomment-802328453,2,"['redundant', 'reliab']","['redundant', 'reliably']"
Availability,"@gokceneraslan I like the idea, that would save quite some space. However, as a partial color blind person, I tend to avoid legends based on color because I can not map them reliably back to the figure. But otherwise, I think it is easy to adapt the current code to add such feature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/228#issuecomment-411039951:174,reliab,reliably,174,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/228#issuecomment-411039951,1,['reliab'],['reliably']
Availability,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1551#issuecomment-761117523:619,mask,masking,619,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551#issuecomment-761117523,1,['mask'],['masking']
Availability,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download?. @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`; * `seaborn` – `~/seaborn-data`; * `NLTK` – `~/nltk_data`; * `keras` and `tensorflow` – `~/.keras/datasets`; * `conda` – `~/miniconda3/`; * `intake` – `~/.intake/cache/` (specifically for caching feature); * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-476943448:218,down,download,218,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476943448,3,"['avail', 'down', 'error']","['available', 'download', 'error']"
Availability,"@gokceneraslan We had it switched to stable by default for some time already. I'm fine doing this again; I switched it back because I found some typos, etc., some missing explanation that I wanted to become immediately available...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/560#issuecomment-477453468:219,avail,available,219,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/560#issuecomment-477453468,1,['avail'],['available']
Availability,"@gokceneraslan Yes, I agree a transparent benchmark repo would be very valuable. . I'd also like to see a detailed breakdown of the limitations of each method or imputation in general. It seems problematic to me to use imputed data for all downstream analyses, for example sub-clustering or DGE analysis, but I can't find a discussion of those limitations anywhere. I'm a little wary of imputation methods being part of a standard toolkit without sufficient discussion of limitations in the documentation somewhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/189#issuecomment-404866769:240,down,downstream,240,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189#issuecomment-404866769,1,['down'],['downstream']
Availability,"@grst is also a good person to ping for tutorials. In general, we'll also want to link to more scverse tutorials eventually",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2502#issuecomment-1580570725:31,ping,ping,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2502#issuecomment-1580570725,1,['ping'],['ping']
Availability,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`; In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1422#issuecomment-734460539:353,avail,available,353,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422#issuecomment-734460539,1,['avail'],['available']
Availability,"@hurleyLi, would you mind opening an issue over on umap that you're unable to get a `__version__` from it? It would be nice to have that fixed/ at least tracked down upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1978#issuecomment-963432344:161,down,down,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978#issuecomment-963432344,1,['down'],['down']
Availability,"@ilan-gold If you want to try it out, I give instructions for how to reproduce the error with a Docker container for Windows in the cross-referenced issue. I also have tried it on WSL, and the problem is *not* present on WSL, so this is a workaround for Windows users. However, I am organizing a Python workshop in a few weeks, and I think it would add some additional administrative burden/overhead to the workshop to coordinate installing and setting up WSL (as we see in #3041, Ruben had trouble installing WSL and others might as well.) So, for me, using WSL is a suboptimal workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2332444655:83,error,error,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2332444655,1,['error'],['error']
Availability,@ilan-gold same thing without random state; I think there might be some windows error relating to numpy on linux defaulting to 64 bit integer vs windows sometimes defaulting to 32 bit (those were the first couple of google hits when i searched the error). though i dont know where the seed is generated in the source code though.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2034518751:80,error,error,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2034518751,2,['error'],['error']
Availability,"@ilan-gold your minimal example causes the exact same error:. Exception ignored in: <class 'ValueError'>; Traceback (most recent call last):; File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint; File ""numpy\\random\\_bounded_integers.pyx"", line 2881, in numpy.random._bounded_integers._rand_int32; ValueError: high is out of bounds for int32. if you are curious, it spits the error out 14.210 times (71050 lines of error message). EDIT: the random state does not seem to matter btw, also happens with different random states",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2034445010:54,error,error,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2034445010,3,['error'],['error']
Availability,"@ivirshup -- I still can't tell why Travis is failing. For some reason on Travis, loess is outputting a zero for the gene mentioned in the error message, but this doesn't happen locally for me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1204#issuecomment-624831279:139,error,error,139,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204#issuecomment-624831279,1,['error'],['error']
Availability,@ivirshup : Thanks for the background explanation. . @njbernstein Can you move the import statements inside the `_demultiplex_per_barcode` to remove the test errors? . I think the tool should go to `external` to point out that this is based on a method that we have not tested and thus the responsibility of its accuracy and implementation lies on the external contributor.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/797#issuecomment-537023624:158,error,errors,158,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797#issuecomment-537023624,1,['error'],['errors']
Availability,"@ivirshup ; Hello ivirshup, these error comes from the below environments. When I upgrade to py3.8 and use scanpy 1.8.2, everything works well. Thanks a lot!. <html xmlns:v=""urn:schemas-microsoft-com:vml""; xmlns:o=""urn:schemas-microsoft-com:office:office""; xmlns:x=""urn:schemas-microsoft-com:office:excel""; xmlns=""http://www.w3.org/TR/REC-html40"">. <head>. <meta name=ProgId content=Excel.Sheet>; <meta name=Generator content=""Microsoft Excel 15"">; <link id=Main-File rel=Main-File; href=""file:///C:/Users/Yuanjian/AppData/Local/Temp/msohtmlclip1/01/clip.htm"">; <link rel=File-List; href=""file:///C:/Users/Yuanjian/AppData/Local/Temp/msohtmlclip1/01/clip_filelist.xml"">; <style>; <!--table; 	{mso-displayed-decimal-separator:""\."";; 	mso-displayed-thousand-separator:""\,"";}; @page; 	{margin:.75in .7in .75in .7in;; 	mso-header-margin:.3in;; 	mso-footer-margin:.3in;}; tr; 	{mso-height-source:auto;; 	mso-ruby-visibility:none;}; col; 	{mso-width-source:auto;; 	mso-ruby-visibility:none;}; br; 	{mso-data-placement:same-cell;}; td; 	{padding-top:1px;; 	padding-right:1px;; 	padding-left:1px;; 	mso-ignore:padding;; 	color:black;; 	font-size:11.0pt;; 	font-weight:400;; 	font-style:normal;; 	text-decoration:none;; 	font-family:等线;; 	mso-generic-font-family:auto;; 	mso-font-charset:134;; 	mso-number-format:General;; 	text-align:general;; 	vertical-align:middle;; 	border:none;; 	mso-background-source:auto;; 	mso-pattern:auto;; 	mso-protection:locked visible;; 	white-space:nowrap;; 	mso-rotate:0;}; ruby; 	{ruby-align:left;}; rt; 	{color:windowtext;; 	font-size:9.0pt;; 	font-weight:400;; 	font-style:normal;; 	text-decoration:none;; 	font-family:等线;; 	mso-generic-font-family:auto;; 	mso-font-charset:134;; 	mso-char-type:none;; 	display:none;}; -->; </style>; </head>. <body link=""#0563C1"" vlink=""#954F72"">. Package | Version; -- | --; Anaconda | 2.1.0; Python | 3.6.13; anndata | 0.7.6; anyio | 2.2.0; argon2-cffi | 20.1.0; async-generator | 1.1; attrs | 21.2.0; Babel | 2.9.1; backcall | 0.2.0; ble",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2046#issuecomment-963453699:34,error,error,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2046#issuecomment-963453699,1,['error'],['error']
Availability,"@ivirshup ; Hi, thank for your help.; When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python; >>> import scanpy as sc; >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups; groups_order += [reference]; TypeError: must be str, not list. >>> import scanpy.api as sc; >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups; groups_order += [reference]; TypeError: must be str, not list. >>> import scanpy.external as sc; >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/838#issuecomment-532502522:199,error,error,199,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838#issuecomment-532502522,1,['error'],['error']
Availability,"@ivirshup ; Yeah, it was the same data as the privious plot. I tried calling sc.tl.umap(sp, init_pos=""paga"") but meet an error. I just use the get_init_pos_from_paga function to solve this error as mention in #769 .Thanks!; ```; TypingError: Failed in nopython mode pipeline (step: nopython frontend); Invalid use of type(CPUDispatcher(<function rdist at 0x7f90e19f58c8>)) with parameters (array(float64, 1d, C), array(float64, 1d, C)); Known signatures:; * (array(float32, 1d, A), array(float32, 1d, A)) -> float32; * parameterized; [1] During: resolving callee type: type(CPUDispatcher(<function rdist at 0x7f90e19f58c8>)); [2] During: typing of call at /datc/dh_data/.conda_env/scrna/lib/python3.6/site-packages/umap/umap_.py (797). File ""../../../../.conda_env/scrna/lib/python3.6/site-packages/umap/umap_.py"", line 797:; def optimize_layout(; <source elided>. dist_squared = rdist(current, other); ^. This is not usually a problem with Numba itself but instead often caused by; the use of unsupported features or an issue in resolving types. To see Python/NumPy features supported by the latest release of Numba visit:; http://numba.pydata.org/numba-doc/latest/reference/pysupported.html; and; http://numba.pydata.org/numba-doc/latest/reference/numpysupported.html. For more information about typing errors and how to debug them visit:; http://numba.pydata.org/numba-doc/latest/user/troubleshoot.html#my-code-doesn-t-compile. If you think your code should work with Numba, please report the error message; and traceback, along with a minimal reproducer at:; https://github.com/numba/numba/issues/new",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/918#issuecomment-555516223:121,error,error,121,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/918#issuecomment-555516223,4,['error'],"['error', 'errors']"
Availability,"@ivirshup @flying-sheep I would remove the `, optional` statement from the docstrings, as, what we mean with this is ""a parameter has a default value"". Hence, it's redundant. However, it's consistently used in all of numpy, scipy, sklearn, pandas, etc.; ![image](https://user-images.githubusercontent.com/16916678/56281364-b3780580-610c-11e9-8e40-2f44d3007a19.png). In the auto-generated type annotations, the default values miss completely, and I don't think we'll ever restore the `, optional` descriptor, there. ![image](https://user-images.githubusercontent.com/16916678/56281431-e15d4a00-610c-11e9-990c-6a2477540535.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/610#issuecomment-484029598:164,redundant,redundant,164,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/610#issuecomment-484029598,1,['redundant'],['redundant']
Availability,@ivirshup @gokceneraslan Do you have access to the error details for readthedocs? I get 'page does not exists' error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1204#issuecomment-654765480:51,error,error,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204#issuecomment-654765480,2,['error'],['error']
Availability,"@ivirshup @pavlin-policar I'd like to get back to this issue. I think maybe we should postpone discussing `ingest` until later (as well as ""recipes"" based on our Nat Comms paper, and other topics raised above) and focus on switching to openTSNE first. Scanpy's architecture is to compute kNN graph by calling `sc.pp.neighbors` and then run dimensionality reduction (UMAP) and clustering (Leiden) on this graph. I think this is very neat and makes everything consistent and other functions should follow this approach as much as possible. So IMHO if it's possible to run t-SNE on the kNN graph with k=15, then that's what we should do. And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is *very* similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. Admittedly, this is not the ""vanilla"" t-SNE. But it's very close. And I think advantages outweigh the disadvantages. Actually this is quite a bit faster than the standard t-SNE, because it only uses k=15 instead of k=90 (3 times perplexity=30). Moreover, we could make the standard t-SNE available by extending `sc.pp.neighors` with `method=""tsne""` (there are several `method`s there already). What I mean is that . ```; sc.pp.neighors(); sc.tl.tsne(); ```; would use let's say uniform kernel on k=15 kNN neighbor graph (and maybe print a warning about it, but I am not even sure it's needed), while. ```; sc.pp.neighbors(method=""tsne"", perplexity=30); sc.tl.tsne(); ```; would construct k=90 weighted kNN graph as standard t-SNE does and then use that. Either way, `sc.tl.tsne()` runs openTSNE with the pre-defined affinity matrix. Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1233#issuecomment-748543070:1348,avail,available,1348,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233#issuecomment-748543070,1,['avail'],['available']
Availability,@ivirshup I am getting same numba errors on windows 10 machine. I can test the workaround if you provide a fix. Currently to make the function working I set `percent_top=None`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/843#issuecomment-542784036:34,error,errors,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/843#issuecomment-542784036,1,['error'],['errors']
Availability,@ivirshup I fixed the build it should be available now. The issue can be closed.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/752#issuecomment-517984501:41,avail,available,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/752#issuecomment-517984501,1,['avail'],['available']
Availability,"@ivirshup I looked around and could not find any example in other packages that use input strings as in this case. I agree that the current solution is not ideal, but other solutions seem more complicated. For example, we can add a new parameter called `percentile` that then interprets `vmin` and `vmax` as percentiles/quantiles. However, this limits the option to mix different types of values. . In seaborn they use the parameter `robust` to set vmin and vmax as the .02 and .98 quantiles but the quantiles can not be changed. . Unless we have a strong opinion against this solution I suggest we keep it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/794#issuecomment-524280917:434,robust,robust,434,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794#issuecomment-524280917,1,['robust'],['robust']
Availability,"@ivirshup I simplified the conditionals a bit and there are only two sets now. One to check for various `{Value/Import}Error`s and another to do the `clustering_kwargs` building. I think this is cleaner and faster since no code will run that doesn't have to. I didn't really see a way to do it with only one set of conditionals without code duplication. There's some code that's just common to both, but that shouldn't be run in the case of one of the `{Value/Import}Error`s .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952548908:119,Error,Error,119,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2815#issuecomment-1952548908,2,['Error'],['Error']
Availability,"@ivirshup I think writing a file for uploading it to the web, for read caches, and for for checkpoints of a pipeline has different requirements. I think a `h5ad_compression` or even `hdf5_compression` setting could have its place, but separately from the `cache_compression`. We’ll have to think about naming though. Maybe we want to namespace our settings like matplotlib’s rcparams?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/847#issuecomment-532191481:91,checkpoint,checkpoints,91,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/847#issuecomment-532191481,1,['checkpoint'],['checkpoints']
Availability,"@ivirshup Indeed the problem is `use_raw=True` by default. In the test, I think what happens is that the raw data is being plotted and thus no error appears. The tolerance for the image difference may hide the problem if indeed the test image is correct. To avoid this confusion when plotting a layer I think it is better to override `use_raw`. This is how it was supposed to be working before the changes according to the documentation:. ```; layer : typing.Union[str, NoneType], optional (default: None); Name of the AnnData object layer that wants to be plotted. By default; adata.raw.X is plotted. If `use_raw=False` is set, then `adata.X` is plotted.; If `layer` is set to a valid layer name, then the layer is plotted. `layer`; takes precedence over `use_raw`.; ``` ; The current logic is around this lines https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L744. PS: the `use_raw` has been a source of many confusions for me. Now I know when raw is used by default but for new users this may not be obvious. One solution is to add a warning message everytime that `use_raw` is set to `True` by the code.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/730#issuecomment-510785080:143,error,error,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/730#issuecomment-510785080,2,"['error', 'toler']","['error', 'tolerance']"
Availability,@ivirshup Is the code for all the normalisations (including quantile rescaling) available somewhere?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1117#issuecomment-777280791:80,avail,available,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117#issuecomment-777280791,1,['avail'],['available']
Availability,@ivirshup Re: `AssertionError: Error: Image files did not match.` See https://github.com/scverse/scanpy/pull/2815/files#diff-79d72f67d7be639d5fcd7d63a006524d1317f16261044fdeeae6f6da4d14e88aR30-R34 - I suspect the tolerances need to be udpated and checked. I was getting the opposite (I assume) - images that should be different were not picked up as such for sparse plots (like gene rankings).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896481527:31,Error,Error,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896481527,2,"['Error', 'toler']","['Error', 'tolerances']"
Availability,"@ivirshup Sorry I need to correct my previous answer. `mnnpy.mnn_correct` is not giving errors, but is returning a tuple. Check my issue here https://github.com/chriscainx/mnnpy/issues/27",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/757#issuecomment-523455880:88,error,errors,88,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757#issuecomment-523455880,1,['error'],['errors']
Availability,"@ivirshup The idea is that if downloading with a browser or wget works but python requests fail, then the problem should be somewhere in the header. Changing user agent (to avoid blacklist \ whitelist on the server) is the most obvious thing to try.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1334#issuecomment-664924095:30,down,downloading,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334#issuecomment-664924095,1,['down'],['downloading']
Availability,@ivirshup The test failures are a bug exposed by the fixture refactoring. The tests were relying on `adata['uns']['pos']` being left over from a previous test run. Can you help me fix it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2235#issuecomment-1099069308:19,failure,failures,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235#issuecomment-1099069308,1,['failure'],['failures']
Availability,"@ivirshup any way to force Azure to clear its cache or use a different runner? The “invalid instruction” error here probably comes from using a binary wheel compiled for a newer CPU. /edit: wow, 9 attempts. Maybe just dropping Python 3.8 will get us there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2605#issuecomment-1761383417:105,error,error,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2605#issuecomment-1761383417,1,['error'],['error']
Availability,"@ivirshup is it possible that Travis has cached pbmc3k and that's what's causing the error? I really don't have it running pytest locally either. . Also as far as the code review -- I understand code is duplicated, but this code does not really fit in the existing implementation because it works a bit differently and requires raw data. Let me know how you'd like to address this. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1182#issuecomment-619321412:85,error,error,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182#issuecomment-619321412,1,['error'],['error']
Availability,@ivirshup ping,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2605#issuecomment-1776722388:10,ping,ping,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2605#issuecomment-1776722388,1,['ping'],['ping']
Availability,"@ivirshup regarding the three comments:; ; * `adata.obs.columns` non_unique: I also think this should be an error as this will cause trouble at some point or another. I added a check for this which will raise a ValueError if duplicates are found; * `adata.var.index` Here I wanted to raise an error only if a `key` matched a duplicated `var_name` as you suggested. However, the selection by index, instead of `var_name`, from the matrix causes an error whenever the `var_names` contains duplicates. Actually, doing an AnnData selection when the `var_names` are not unique also raises an error. Thus, I added a ValueError if the var_names are not unique; ```PYTHON; adata = sc.AnnData(; X=np.ones((2, 3)),; obs=pd.DataFrame(index=[""cell-0"", ""cell-1""]),; var=pd.DataFrame(index=[""gene-0"", ""gene-0"", ""gene-1""]),; ); adata[:, ['gene-1']]; ```. ```; --------------------------------------------------------------------------; InvalidIndexError Traceback (most recent call last); <ipython-input-58-8d1a96772653> in <module>; ----> 1 adata[:, ['gene-0']]. site-packages/anndata/_core/anndata.py in __getitem__(self, index); 1085 def __getitem__(self, index: Index) -> ""AnnData"":; 1086 """"""Returns a sliced view of the object.""""""; -> 1087 oidx, vidx = self._normalize_indices(index); 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1089 . site-packages/anndata/_core/anndata.py in _normalize_indices(self, index); 1066 ; 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1068 return _normalize_indices(index, self.obs_names, self.var_names); 1069 ; 1070 # TODO: this is not quite complete... site-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1); 33 ax0, ax1 = unpack_index(index); 34 ax0 = _normalize_index(ax0, names0); ---> 35 ax1 = _normalize_index(ax1, names1); 36 return ax0, ax1; 37 . site-packages/anndata/_core/index.py in _normalize_index(indexer, index); 95 return positions # np.ndarray[int]; 96 else: # indexer should b",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770217601:108,error,error,108,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770217601,4,['error'],['error']
Availability,"@ivirshup. > The worst case scenario I see here me typing something so poorly a newbie trying to follow the documentation gets horrible numba errors they can't figure out. Well, that’s an improvement over the current situation of “the freeform text type annotations make me guess what I can pass and I get horrible numba errors”, right?. > `issubclass(np.ndarray, typing.Sequence) == False`. That looks like a bug. The docs to `Sequence` say: “Concrete subclasses must override `__new__` or `__init__`, `__getitem__`, and `__len__`”, and. ```py; >>> np.ndarray.__new__ ; <function ndarray.__new__(*args, **kwargs)>; >>> np.ndarray.__getitem__ ; <slot wrapper '__getitem__' of 'numpy.ndarray' objects>; >>> np.ndarray.__len__ ; <slot wrapper '__len__' of 'numpy.ndarray' objects>; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-441583940:142,error,errors,142,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-441583940,2,['error'],['errors']
Availability,"@jarny I have the same error still, but when testing on travis it doesn't fail so I have no clue. Locally I create the `__init__.py` file though to make it work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/585#issuecomment-480651534:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/585#issuecomment-480651534,1,['error'],['error']
Availability,"@jefferyUstc I can't reproduce this with `scanpy 1.4.3` and `anndata v0.6.21 `. Here's what I ran on my machine:. ```python; from io import StringIO; import pandas as pd; import numpy as np; import scanpy as sc. csv = """"""; Group,Group1,Group1,Group3,Group6,Group5 ; Gene1,11,0,0,14,0 ; Gene2,12,17,9,34,11 ; Gene3,0,0,0,0,2; """""". df = pd.read_csv(StringIO(csv), index_col=0); genes = df.index.values; barcodes = df.columns; adata = sc.AnnData(np.transpose(df.values), var=pd.DataFrame(genes), obs=pd.DataFrame(barcodes)); adata.var_names_make_unique(); sc.pp.filter_genes(adata, min_cells=1); adata.raw = adata; sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4); ```. Could you try that? If the error still occurs, could you post the traceback?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/727#issuecomment-508640504:704,error,error,704,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/727#issuecomment-508640504,1,['error'],['error']
Availability,@k3yavi The right place to ask those questions is on the AnnData repository where all the read and write functions are located. [Here](https://icb-anndata.readthedocs-hosted.com/en/stable/api.html#reading) you can find the available read options. You are welcome to contribute! Would be great if AnnData can read EDS files.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/856#issuecomment-538301097:223,avail,available,223,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/856#issuecomment-538301097,1,['avail'],['available']
Availability,@kt6k were you using a conda environment when you hit this error?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/567#issuecomment-479352073:59,error,error,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/567#issuecomment-479352073,1,['error'],['error']
Availability,"@ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1451305928:165,error,error,165,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1451305928,1,['error'],['error']
Availability,"@ktpolanski I thought I had the newest anndata version, but turns out 0.8.0 is not in Ubuntu repositiories. I had to manually download and install Python 3.8, anndata 0.8.0 and h5py, now it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1451566540:126,down,download,126,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1451566540,1,['down'],['download']
Availability,@ktpolanski following from https://scanpy.readthedocs.io/en/stable/dev/code.html#code-style and building the docs locally gives me (among some errors that were not relevant):. ```; ...; /path/to/scanpy/scanpy/external/pp/_bbknn.py:docstring of scanpy.external.pp._bbknn.bbknn:28: WARNING: py:class reference target not found: function; /path/to/scanpy/scanpy/external/pp/_bbknn.py:docstring of scanpy.external.pp._bbknn.bbknn:28: WARNING: py:class reference target not found: function; ...; ```. Maybe that gives you some pointers?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1868#issuecomment-861412696:143,error,errors,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1868#issuecomment-861412696,1,['error'],['errors']
Availability,"@lazappi no worries! The scanpy CI has always been a little bit flaky and sometimes failures are not the faults of people submitting pull requests. If it fails again, we can dig deeper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2231#issuecomment-1139757936:84,failure,failures,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1139757936,2,"['failure', 'fault']","['failures', 'faults']"
Availability,"@liliblu `""louvain""` would work. @kleurless, sorry for such a late reponse to this! If you are still having this problem, does your `adata_2` have `.raw` set? `adata.raw.var_names` ca be different than `adata.var_names`, but is is used by default for plotting when available. Does your second call work with `sc.pl.dotplot(adata_2, adata_2.var_names[0:4], groupby='celltype', color_map = 'Reds', use_raw=False)`?. If this is the issue, we should at least have a more clear error in the next release (#1583).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1406#issuecomment-768012714:265,avail,available,265,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1406#issuecomment-768012714,2,"['avail', 'error']","['available', 'error']"
Availability,@maarten-hifibio in the mean time if you need it I have just made some GPU wrappers available on the following gist:; https://gist.github.com/LouisFaure/9302aa140d7989a25ed2a44b1ce741e8. It includes one for leiden that would exactly act like sc.tl.leiden (it is part of my PR referenced here),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1793#issuecomment-1106331321:84,avail,available,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793#issuecomment-1106331321,1,['avail'],['available']
Availability,@maarten-hifibio we are indeed actively working on this again. Feel free to join our zulip https://scverse.zulipchat.com/login/ and ping me. I can add you to the conversation.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1793#issuecomment-1102832260:132,ping,ping,132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793#issuecomment-1102832260,1,['ping'],['ping']
Availability,"@massonix Latest version is available on PyPI, so you can try installing via pip install.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/942#issuecomment-577689480:28,avail,available,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/942#issuecomment-577689480,1,['avail'],['available']
Availability,@maximilianh I think those messages are from your code? maybe you should improve the error message to include something like. > Try running sc.tl.rank_genes_groups(adata) to create the cluster annotation,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/262#issuecomment-478907896:85,error,error,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/262#issuecomment-478907896,1,['error'],['error']
Availability,"@maximilianh I was able to use the cell browser export function in the past but this time I am getting an error message:. INFO:root:Writing scanpy matrix to adata_cellbrowser_04_01_19_CD8_subclustered/exprMatrix.tsv.gz; INFO:root:Transposing matrix; INFO:root:Writing gene-by-gene, without using pandas; INFO:root:Writing 8068 genes in total; INFO:root:Wrote 0 genes; INFO:root:Wrote 2000 genes; INFO:root:Wrote 4000 genes; INFO:root:Wrote 6000 genes; INFO:root:Wrote 8000 genes; INFO:root:Writing UMAP coords to adata_cellbrowser_04_01_19_CD8_subclustered/umap_coords.tsv; ERROR:root:Couldnt find cluster markers list. I am using an h5ad file to import my ann data object. Is that why there is some issue with finding cluster markers ? I am able to plot the clusters in a UMAP plot so I know that the 'louvain' observation exists. Any thoughts on why this is happening ?. Thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/262#issuecomment-478685403:106,error,error,106,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/262#issuecomment-478685403,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```; python3 download_expression_atlas.py {accession}; ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-476613271:114,down,download,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476613271,5,"['down', 'redundant']","['download', 'downloads', 'redundant']"
Availability,"@maximillo Hi, sorry to bother you, I met the same error. But I don't konw how to change np.int8 to np.int32. Any help would be greatly appreciated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2547#issuecomment-1689304524:51,error,error,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2547#issuecomment-1689304524,1,['error'],['error']
Availability,"@mihem, thanks for pointing this out. I opened [this](https://github.com/theislab/scvelo/issues/443) issue on the `scvelo` repo to resolve the `typing_extensions` problem. You may want to open a new issue on `scanpy` for the `llvmlite` error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799#issuecomment-835257528:236,error,error,236,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799#issuecomment-835257528,1,['error'],['error']
Availability,@mmarwaosman what was the fix. I am getting the similar error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2402#issuecomment-2073491552:56,error,error,56,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402#issuecomment-2073491552,1,['error'],['error']
Availability,"@mumichae ; Thanks for letting us know about the error. For now if you need multiple scatter plots on a single figure you can do something like; `import matplotlib.pyplot as plt`; `f, axs = plt.subplots(2,2)`; `sc.pl.scatter(..., ax=axs[0,0])`; `sc.pl.scatter(..., ax=axs[1,0])`; ...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1986#issuecomment-916368363:49,error,error,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986#issuecomment-916368363,1,['error'],['error']
Availability,"@nahanoo ; Hi, there are 3 options for now:. 1. downgrading umap to 0.39; 2. installing scanpy from github; 3. waiting for a new release of scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1036#issuecomment-627837413:48,down,downgrading,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036#issuecomment-627837413,1,['down'],['downgrading']
Availability,"@ontsilla We can take a look at this, but I'm not sure if there will be a solution soon. Have you tried using [conda](https://conda.io/en/latest/miniconda.html) on this system? I think it might be your best bet here. @flying-sheep I can recreate with:. ```; conda create -yn testenv python=3.5.2; conda activate testenv; pip install scanpy; python -c ""import scanpy"" ; ```. It looks like there were a lot of bug fixes to python's `typing` module between v3.5.2 and v3.5.4 ([changelog](https://docs.python.org/3.5/whatsnew/changelog.html#python-3-5-4rc1)). I don't get this error with v3.5.4. Are pre-bugfix versions of python supported?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/561#issuecomment-476952168:573,error,error,573,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-476952168,1,['error'],['error']
Availability,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/525#issuecomment-471592072:42,error,error,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525#issuecomment-471592072,2,['error'],['error']
Availability,@outlace Did you try adding more marker genes? The error is gone if you have a large number of marker genes to plot in my case.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/405#issuecomment-471159340:51,error,error,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405#issuecomment-471159340,1,['error'],['error']
Availability,@pchiang5 @LuckyMD what does it mean when a gene is present in adata.raw.var_names but not in adata.var_names ? I'm running into a key not found error because of the gene being in one list and not the other. Thanks.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1039#issuecomment-617838606:145,error,error,145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039#issuecomment-617838606,1,['error'],['error']
Availability,"@rsggsr remove the `data.to_csv()` part, it seems to have worked otherwise, if the ``tl.paga_path` ran without errors",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1168#issuecomment-619398744:111,error,errors,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168#issuecomment-619398744,1,['error'],['errors']
Availability,"@rsggsr, that looks like a warning, not an error to me. Do the plots look wrong to you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1168#issuecomment-615069994:43,error,error,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168#issuecomment-615069994,1,['error'],['error']
Availability,"@sjfleming I am currently facing the same issue. I was able to load the h5 output with this input function you stated here https://lightrun.com/answers/broadinstitute-cellbender-read_10x_h5-error-in-scanpy-191. But after further analysis and I wanted to save the adata object with the write function to h5ad format, I am not able to read that saved h5ad object with scanpy again with error ; **test.h5ad contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp']**. For some reason, the genome ""GRCh38"" is not showing up in the available genomes options. And when I tried to use command test = sc.read_10x_h5 ('test.h5ad', genome = ""GRCh38), this error shows up again ; **Could not find genome 'GRCh38' in 'test.h5ad'. Available genomes are: ['X', 'layers', 'obs', 'obsm', 'obsp', 'raw', 'uns', 'var', 'varm', 'varp'].** . Do you know if this error is related to this pull request? and is there any fix to it so that I can save processed h5ad after cellbender and able to read it again? Thank you very much!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051:190,error,error-in-scanpy-,190,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246#issuecomment-1247444051,7,"['Avail', 'avail', 'error']","['Available', 'available', 'error', 'error-in-scanpy-']"
Availability,"@stefanpeidli's code gives this error. `ValueError: Cannot take a larger sample than population when 'replace=False'`. If a group has less than required number observations, it shouldn't subsample. ```python; target_cells = 1000; cluster_key = ""cell_type"". grouped = adata.obs.groupby(cluster_key); downsampled_indices = []. for _, group in grouped:; if len(group) > target_cells:; downsampled_indices.extend(group.sample(target_cells).index); else:; downsampled_indices.extend(group.index). adata_downsampled = adata[downsampled_indices]; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/987#issuecomment-1397060295:32,error,error,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/987#issuecomment-1397060295,1,['error'],['error']
Availability,"@vladie0, would you mind pulling again and checking if it works now?. @flying-sheep if at least four people can't install the package (including in a clean conda environment on a lab mate's machine), what do you call it? I don't think it's our fault, but I think there's a bug somewhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/601#issuecomment-482107875:244,fault,fault,244,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/601#issuecomment-482107875,1,['fault'],['fault']
Availability,"@xie186, are the variable names within each of your objects are unique?. I would guess that would be the problem. Here's a simple case that would throw this error:. ```python; import anndata as ad, numpy as np, pandas as pd. a = ad.AnnData(np.ones((3, 2)), var=pd.DataFrame(index=[""a"", ""a""])); b = ad.AnnData(np.ones((3, 3)), var=pd.DataFrame(index=[""a"", ""b"", ""c""])). a.concatenate(b); ```. I think our merge operation for the variables is only well defined if variable names are unique with each of the objects. I'm not sure there's a good default result here other than throwing an error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1409#issuecomment-694683604:157,error,error,157,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1409#issuecomment-694683604,2,['error'],['error']
Availability,A rough implementation of glmpca in python is now available here: https://github.com/willtownes/glmpca-py . I will try to get it organized as an installable package tomorrow and add unit tests. Issues/ pull requests welcome.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-541384867:50,avail,available,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/868#issuecomment-541384867,1,['avail'],['available']
Availability,A temporary fix is to downgrade scipy to 1.4.1.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1300#issuecomment-655340510:22,down,downgrade,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1300#issuecomment-655340510,1,['down'],['downgrade']
Availability,"AFAICT, I think the parallelization you're seeing will be due to the underlying calls in statsmodels. If you turn down the number of threads blas can use, do you see the same utilization?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1396#issuecomment-683633085:114,down,down,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1396#issuecomment-683633085,1,['down'],['down']
Availability,"API. All of the dependencies of this would be optional. In effect, this would be a very shallow wrapper that is only interesting for people who already have a working R installation etc. and use Scanpy along with R packages. As there are quite many of these people, this is definitely meaningful.; > . That'd make things a lot easier for many people (including myself 😃), I agree. However. 1) There are (and will be) so many R packages about single cell, so once we open the door, there might be so many requests about these packages so that it'd be difficult to decide what to include and what not to include. The decision might be a bit arbitrary. This is why I suggested a contrib repo, which will have everything users request (as soon as there is someone who is willing to maintain it), in a `use at your own risk` way... 2) There might be several bug reports about rpy2 itself or thin wrappers or R installation or R packages themselves. I was wondering whether this might introduce more maintenance burden, although supported packages will be limited. > The code would still look proper. Implementing tests for these wrappers is maybe not so important as these are only shallow interfaces. It would be easier to have this in the main scanpy repository than setting up a scanpy-contrib: I imagine less people will like to contribute and take the burden of maintaining another repository. PS: anndata is a different story. That's something that is meant to be so basic that it doesn't need a lot of maintenance an contributions.; > ; > What do you think?. Alternatively, we can just prepare jupyter notebooks with some Python 3 and some R cells in it (which is super easy via rpy2 magics anyway) for some R packages/functions like mnn or SIMLR and put those in scanpy_usage as a reference for the community. For example:. ![image](https://user-images.githubusercontent.com/1140359/38873972-4953977a-4257-11e8-8675-a238738eb558.png). Another question is other single cell Python packages like magi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/125#issuecomment-382002901:1211,mainten,maintenance,1211,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125#issuecomment-382002901,1,['mainten'],['maintenance']
Availability,"About adding all powers of adjacency matrix - i implemented it at first as you did, but then i thought that it was redundant and changed to the present variant. My thought was that the hexagonal connectivity structure would allow to get all paths of less than n_rings with only n_rings power. And this works in practice, but i agree that there can be some edge cases with isolated node blocks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1383#issuecomment-701247872:115,redundant,redundant,115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1383#issuecomment-701247872,1,['redundant'],['redundant']
Availability,"About dpt_order in the Moignard example, if we plot the pseudotime vs. dpt-order at last manually like follows, ; `plt.figure(figsize=(8,8)); plt.plot(adata.smp['dpt_order'], adata.smp['dpt_pseudotime']); plt.xlabel('dpt-order'); plt.ylabel('pseudotime')`; we'll get; ![download 1](https://user-images.githubusercontent.com/20141984/28011291-687c20e0-6594-11e7-8068-472b4ab4d8a8.png); which is totally chaotic, unlike the one we get through `sc.pl.dpt`. Anyway, did I misunderstand the concept of dpt-order or is there a bug about this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/27#issuecomment-314053618:270,down,download,270,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27#issuecomment-314053618,1,['down'],['download']
Availability,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors; 2. Weighting the graph; 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python; class WrappedAffinities(openTSNE.affinity.Affinities):; def __init__(self, neighbors, symmetrize=True, verbose=False):; self.verbose = verbose; P = neighbors; if symmetrize:; P = (P + P.T) / 2; total = P.sum(); if not np.isclose(total, 1.):; P = P / total; self.P = P; ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here?. > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-761950200:506,avail,available,506,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-761950200,1,['avail'],['available']
Availability,"About the commit process: That's far far too much work to do it like you suggested. I don't have the time for this. . About the rules: . 1. ""I don't like replacing `x == False` with `not x` in all cases. Sometimes a variable could be a container, and an error should be thrown. I think cases have to be evaluated for this."" . This should be covered by tests. In any case it is not good style and a violation. 2. ""Whats with changing from single letter variables inside expressions? Seems fine to me."". They are redefinitions of earlier variables and trip up flake8. We can call them whatever we want as long it s not `l` again. . 3. ""`lambda's also are generally fine."". See comment at the section. 4. ""Whats up with removing leading `#`s from comments?"" Not my choice either. What we have now is pep8 and flake8 compliant. If you're not happy with this we can ignore the rule. 5. ""So, some of the things you've adding a `# noqa` to look like bugs. I think we need to have a plan in place for doing something about these. Do you have any suggestions?"". The noqa ignore a rule for a specific line. I did not want to ""fix"" these things myself since Python is a dynamic language and you never know what happens :) Ideally we eventually get rid of all noqas, but not in this PR and not by me. I don't know the internals well enough to know whether this could have any side effects.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1689#issuecomment-785831068:254,error,error,254,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689#issuecomment-785831068,1,['error'],['error']
Availability,"Actually, no need to post more. A labmate managed to find this too. It looks like it has something to do with Matplotlib and the `TkAgg` backend (see: https://github.com/matplotlib/matplotlib/issues/13414). While this error doesn't occur in my normal environment, I can reproduce this error in a conda environment:. ```sh; conda create -yn conda_scanpy scanpy; conda activate conda_scanpy; python -c ""import matplotlib.pyplot as plt; plt.figure()""; ```. We were able to get plotting to work by switching to the `Agg` backend. You can do this by adding the following lines to the top of your script:. ```python; import matplotlib as mpl; mpl.use(""Agg""); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/567#issuecomment-479346876:218,error,error,218,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/567#issuecomment-479346876,2,['error'],['error']
Availability,"Addendum: different errors are generated depending on which axis is first sliced. The data set I'm loading is a dense matrix. ```; >>> data.X.dtype; dtype('<f4'); >>> data[:,0][0,:]; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__; return self._getitem_view(index); File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view; return AnnData(self, oidx=oidx, vidx=vidx, asview=True); File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 669, in __init__; self._init_as_view(X, oidx, vidx); File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 694, in _init_as_view; uns_new = deepcopy(self._adata_ref._uns); File ""/usr/lib/python3.6/copy.py"", line 180, in deepcopy; y = _reconstruct(x, memo, *rv); File ""/usr/lib/python3.6/copy.py"", line 307, in _reconstruct; y[key] = value; File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 444, in __setitem__; _init_actual_AnnData(adata_view); File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 367, in _init_actual_AnnData; adata_view._init_as_actual(adata_view.copy()); File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 880, in _init_as_actual; self._check_dimensions(); File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1879, in _check_dimensions; .format(self._n_obs, self._obs.shape[0])); ValueError: Observations annot. `obs` must have number of rows of `X` (1), but has 2638 rows.; >>> data[0,:][:,0]; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1303, in __getitem__; return self._getitem_view(index); File ""/cellxgene/venv/lib/python3.6/site-packages/anndata/base.py"", line 1307, in _getitem_view; return AnnData(self, oidx=oidx, vidx=vidx, asview=True); File ""/cellxg",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/332#issuecomment-433745600:20,error,errors,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/332#issuecomment-433745600,1,['error'],['errors']
Availability,"Advantage of networkx is that it's easily installed... But yes, we should remove it in the future. I think with anaconda, one gets all the igraph and louvain stuff to work very easily without compiling. Without using Grohlke's binaries... One just needs to document this probably. At the latest when igraph and louvain are easily installed, networkx can be removed... PS: I'm currently preparing scanpy 1.0; there will be some slight changes to make the API less redundant... So for now, please no big changes...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/97#issuecomment-370144822:463,redundant,redundant,463,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/97#issuecomment-370144822,1,['redundant'],['redundant']
Availability,"After fixing the above error locally and continuing I ran into a similar error in the next step:; `sc.external.tl.palantir_results(...)` internally [calls](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L294) `run_palantir(ms_data=ms_data, ...)` with keyword `ms_data` which seems to have changed to just `data` in the [recent version of palantir](https://github.com/dpeerlab/Palantir/blob/master/src/palantir/core.py#L35).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2608#issuecomment-1671743412:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608#issuecomment-1671743412,2,['error'],['error']
Availability,"Ah, I didn't know others are also automatically downloaded, very nice. paul15 uses `sc.utils.check_presence_download()`, while others use `check_datafile_present_and_download()` via `readwrite.read()`, though. Is this intentional?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-364331847:48,down,downloaded,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-364331847,1,['down'],['downloaded']
Availability,"Ah, I think this was reported before in #769. Would you mind checking if the error still occurs on master?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/936#issuecomment-560232016:77,error,error,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/936#issuecomment-560232016,1,['error'],['error']
Availability,"Ah, yeah that's what I meant. If I use `setup()`, the tests on the linux server fail. However, the images generated are similar (RMSD < 10) to images made on my MacBook after running `setup()`. On the PAGA notebook, I saw errors like that when I was playing around with the dpi. Maybe fig size or dpi is being changed?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-435728828:222,error,errors,222,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-435728828,1,['error'],['errors']
Availability,Ah? The code seems like it just returns an empty list when there’s no results. Where is the error thrown?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/467#issuecomment-464011097:92,error,error,92,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-464011097,1,['error'],['error']
Availability,"Alright! I've got a little example case I'd probably be using for a test case [here](https://gist.github.com/ivirshup/2a0d9a785339b719e7d372027ae2df31) (doublet prediction by simulation and projection). My current thoughts:. * Since we need to be working in the same feature space, we'll at least need PCA projection, but this is pretty easy:. <details>; <summary> Basic PCA projection </summary>. ```python; def pca_update(tgt, src, inplace=True):; # TODO: Make sure we know the settings (just whether to center?) from src; if not inplace:; tgt = tgt.copy(); if sparse.issparse(tgt.X):; X = tgt.X.toarray(); else:; X = tgt.X.copy(); X -= np.asarray(tgt.X.mean(axis=0)); tgt_pca = np.dot(X, src.varm[""PCs""]); tgt.obsm[""X_pca""] = tgt_pca; return tgt; ```. </details>. * Are you planning on storing the UMAP object in the AnnData? That would make transformation easier, but I see how on-disk representation could get complicated.; * What order should we do this in? Would you like everything to be accomplished by this PR or should we break it up?; * Are we introducing a general transfer learning api? Probably worth considering that a bit. Some relevant questions:; * Does the syntax still work for cases other than 1-to-1 transfer? ; * How do we deal with concatenation/ joins? The current `concatenate` doesn't join things like `obsm`.; * Alternatively, does everything have to be in the same AnnData? It would solve issues with having `var` be the same, but could complicate a lot of other code (many functions would need some kind of masking argument).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/576#issuecomment-481525842:1538,mask,masking,1538,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/576#issuecomment-481525842,1,['mask'],['masking']
Availability,Also ping @flying-sheep since I believe you wrote the initial version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1344#issuecomment-666259323:5,ping,ping,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1344#issuecomment-666259323,1,['ping'],['ping']
Availability,"Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1506#issuecomment-733652124:399,down,downloading,399,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506#issuecomment-733652124,1,['down'],['downloading']
Availability,"Also, can you replicate the problem with the available Scanpy datasets?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/787#issuecomment-524200077:45,avail,available,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787#issuecomment-524200077,1,['avail'],['available']
Availability,"Also, set up johnnydep and then do:. `johnnydep --output-format pinned scanpy_scripts; `; and after trundling for a very long time and emitting a lot of messages it gives up with:. ```. Given no hashes to check 0 links for project 'scipy': discarding no candidates; ERROR: Could not find a version that satisfies the requirement scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0 (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0rc2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0b1, 1.0.0rc1, 1.0.0rc2, 1.0.0, 1.0.1, 1.1.0rc1, 1.1.0, 1.2.0rc1, 1.2.0rc2, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0rc1, 1.4.0rc2, 1.4.0, 1.4.1, 1.5.0rc1, 1.5.0rc2, 1.5.0); ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1273#issuecomment-653294084:266,ERROR,ERROR,266,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273#issuecomment-653294084,2,['ERROR'],['ERROR']
Availability,"Also, you may want to change the error that is shown if a non-AnnData object is passed to the function. I put it as TypeError, because I didn't find how you have previously called that error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/100#issuecomment-371099043:33,error,error,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/100#issuecomment-371099043,2,['error'],['error']
Availability,"An error jumped out when normalizing, turns out I had a bad dataset mixed in and after filter there were no cell left, hence the error. Thanks!!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/121#issuecomment-381527583:3,error,error,3,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/121#issuecomment-381527583,2,['error'],['error']
Availability,"An error was raised when values_to_plot=""logfoldchanges"" was provided.; ```python; sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=5,; groupby='leiden_0.1',; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmax=20,; vmin=-20,; key='leiden_0.1_marker_filtered',; show=False; ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3049#issuecomment-2107458334:3,error,error,3,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049#issuecomment-2107458334,1,['error'],['error']
Availability,Any update on this ? I'm still getting the same error even with the development version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2361#issuecomment-1944940981:48,error,error,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1944940981,1,['error'],['error']
Availability,Anyone familiar with the travis error?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/199#issuecomment-404874304:32,error,error,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/199#issuecomment-404874304,1,['error'],['error']
Availability,"Apologies for again, the late response @fidel! I married and moved to the US with twin babies last week. And in between, I spilled something over my laptop... Yes, please go ahead and remove redundant code and add further tests. We'll merge this PR eventually. And yes, we can think about a `develop` branch starting from 1.3. What do you say, @flying-sheep?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-418062501:191,redundant,redundant,191,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-418062501,1,['redundant'],['redundant']
Availability,"Are we committing to support sparse-in-dask?. I’m defaulting to `ARRAY_TYPES_SUPPORTED`, which marks sparse as xfail. That’s how we treat other dask-capable utils so far. You can see the errors with. ```console; $ pytest -vv --runxfail scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_{subset_inplace_consistency,no_inplace} -k sparse; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-full-dask_array_sparse-cell_ranger] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-full-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[inplace-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_subset_inplace_consistency[copy-subset-dask_array_sparse-seurat] - TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_su",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122:187,error,errors,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906123122,1,['error'],['errors']
Availability,"Are you sure about numba 0.43? This very much looks like a bug in numba. > It seems that `top_segment_proportions_sparse_csr` is new for scanpy 1.4.5. What makes you think that? It’s been there since @ivirshup added `calculate_qc_metrics` in #316. A second way for this to fail is:. ```pytb; NotImplementedError: No definition for lowering UniTuple(int64 x 2).shape; ...; numba.errors.LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); No definition for lowering UniTuple(int64 x 2).shape. File ""_qc_.py"", line 390:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; prev = 0; for j, n in enumerate(ns):; ^. [1] During: lowering ""$phi382.1_shape.158 = getattr(value=$380for_iter.2, attr=shape)"" at _qc.py (408); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/978#issuecomment-572698263:378,error,errors,378,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978#issuecomment-572698263,1,['error'],['errors']
Availability,"Are you sure that the genes are in `adata.var_names` in the gene symbol format that you are using to subset the object? In other words, is `'Ada' in adata.var_names` `True`? I'd just like to check whether you don't have e.g., Ensembl IDs as your variable names by chance. Regarding normalization... there are other normalization methods. I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Otherwise, we have recently compiled a best practices pipeline in the group, which uses Scran's pooling strategy to normalize the data. This is implemented in R, but can easily be used in a python-based workflow via [`anndata2ri`](www.github.com/flying-sheep/anndata2ri). A case study using the best practices (with scran and anndata2ri) is available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/510#issuecomment-488011785:851,avail,available,851,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-488011785,1,['avail'],['available']
Availability,"Are you talking about the `collections.abc.Mapping` in this case? [From the 3.7 docs](; https://docs.python.org/3/library/typing.html#classes-functions-and-decorators):. > In general, `isinstance()` and `issubclass()` should not be used with types. Additionally, those functions just throw an error for subscripted generics, so you definitely can't do `isinstance(m, Mapping[str, int])`. I don't think I'm totally clear on the differences in intended use cases for `ABC`s vs `Type`s. Are types only for annotation? Should ABCs not be used for annotations?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-445102460:293,error,error,293,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-445102460,1,['error'],['error']
Availability,"Arguments for and against converting values in `downsample_counts`:. If we don't convert dtypes back to what they originally were, there's a slight performance boost since we don't have to have two copies. I we return an array of integers we run into trouble downstream with functions that aren't tested with integer arrays. Issues from this have been opened a few times, so when I wrote this I thought it might be worth just maintaining the input type. I'm not sure I agree with that now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/865#issuecomment-552292197:259,down,downstream,259,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/865#issuecomment-552292197,1,['down'],['downstream']
Availability,"As an alternative, I'd be up for just deprecating raw all together, as I think it causes more problems than it solves. I was talking about this recently with @falexwolf, who has come to a similar conclusion. This could be done on the `anndata` side, and just warn whenever `raw` is set. If no `raw` is present, then none of the weird behavior should come up. > I wonder how important it is to keep genes that are filtered out due to being expressed in too few cells anyway. Might be important for integration? But hopefully this could be solvable by just knowing what annotation was used so you can safely assume the missing values are 0. Also, what level of filtering are you doing here? I've tend to go `min_cells=1`. I think we do need to have a more general solution for having a ""feature-select-ed"" subset of the data, but think this can be done with `mask` argument. E.g. `sc.pp.pca(adata, mask=""highly_variable"")` (I believe we've talked about this before). This does run into memory usage problems if want do a densifying transform on the data, though I have doubts about whether this can be a good representation of the data. This can be technically solved by using a block sparse matrix type, but I'm not sure if any practically usable implementations of this are currently available.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-819998988:857,mask,mask,857,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-819998988,3,"['avail', 'mask']","['available', 'mask']"
Availability,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):; """"""; Choose array aligned with obs annotation.; """"""; is_layer = layer is not None; is_raw = use_raw is not False; is_obsm = obsm is not None; is_obsp = obsp is not None; choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)); assert choices_made <= 1; if choices_made == 0:; return adata.X; elif is_layer:; return adata.layers[layer]; elif use_raw:; return adata.raw.X; elif is_obsm:; return adata.obsm[obsm]; elif is_obsp:; return adata.obsp[obsp]; else:; assert False, (; ""That was unexpected. Please report this bug at:\n\n\t""; "" https://github.com/theislab/scanpy/issues""; ); ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/828#issuecomment-560072919:796,mask,masks,796,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828#issuecomment-560072919,2,"['error', 'mask']","['error', 'masks']"
Availability,"As expected the two other links here were of no use.; I also replictaed the problem in Python (not Jupyter) and get this unhepful message:. scanpy.pp.neighbors(adatas[1]); WARNING: You\u2019re trying to run this on 19151 dimensions of `.X`, if you really want this, set `use_rep='X'`.; Falling back to preprocessing with `sc.pp.pca` and default params.; Segmentation fault (core dumped). I know cpp is like this. But I can not even find the core.dump anywhere. Please help!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2361#issuecomment-1313461261:367,fault,fault,367,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1313461261,1,['fault'],['fault']
Availability,"As this issue is not closed I'll add a question here. . Is it possible, or if not could it be added, that the cells in the heatmaps are sorted within the groupby variables. Either by pseudotime if availible or just clustered simply by hierarchical clustering. This could add a more visually and intuitive pleasing ordering of cells. For example as in my figure above the groupby miss some property of the data with pattern over cells. If the cell ordering was random or default this pattern could not be seen.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/349#issuecomment-460428844:197,avail,availible,197,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/349#issuecomment-460428844,1,['avail'],['availible']
Availability,"As you can see from the error output, this is an error within loompy. I assume you don't have the most recent version of loompy - there used to be a few bugs in it. Try with an update installation of loompy. I'm running 0.2.8 and never had any problem with it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/154#issuecomment-389513091:24,error,error,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/154#issuecomment-389513091,2,['error'],['error']
Availability,AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:2797,Error,Error,2797,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"Assuming you're on a debian based linux, please check the following:; - `echo $PATH` shows your PATH variable.; - `which git` shows you the location of your git installation. If nothing is shown, you need to install it.; - `apt install git` if you haven't installed it yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1257#issuecomment-636457516:73,echo,echo,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1257#issuecomment-636457516,1,['echo'],['echo']
Availability,"At some point we changed the return values of the anndata slicing and that is why I think the check for sparse was needed. My recommendation is to replace this whole block. ```python; for g in _gene_names:; if adata.raw is not None and use_raw:; X_col = adata.raw[:, g].X; if gene_symbols:; g = adata.raw.var[gene_symbols][g]; else:; X_col = adata[:, g].X; if gene_symbols:; g = adata.var[gene_symbols][g]; if issparse(X_col):; X_col = X_col.toarray().flatten(); X_col = X_col.toarray().flatten(); new_gene_names.append(g); df[g] = X_col; ```. by ; ```python; df = sc.get.obs_df(adata, _gene_names, use_raw=use_raw, gene_symbols=gene_symbols; new_gene_names = df.columns; ```. `sc.get.obs_df` is a well tested function and using it makes it easier for maintenance.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1669#issuecomment-801174773:752,mainten,maintenance,752,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669#issuecomment-801174773,1,['mainten'],['maintenance']
Availability,"At the moment we're trying to clean up `scIB` that it becomes easier to use. We're still not certain how to best deal with metrics that rely on R and C++ code though. The current plan is to make a more usable pypi package where some metrics give you a warning on additional requirements/manual C++ compilation. Apologies for the usability mess that a package that also assesses usability has become ^^. I'd prefer to keep it separate for now to facilitate maintenance and citation though. That being said, maybe we could think about an optional requirement for scIB to integrate them? At least when we've cleaned up our side of things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/915#issuecomment-763835114:456,mainten,maintenance,456,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915#issuecomment-763835114,1,['mainten'],['maintenance']
Availability,"At this point I'm not a big fan of moving back to bioconda either.; * anndata is not bio-specific and should go to conda-forge anyway; * it's debatable if it was a mistake to move scanpy, but moving it back causes confusion and more harm than good IMO. > Why have separate package registries for biology vs everything else?. probably because bioconda predates conda-forge? . > Just saw there's already a pr for this!; > ; > https://github.com/BioContainers/multi-package-containers/pull/2209. The only downside of this is that we need to update that file manually for every release of scanpy/anndata",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160571955:502,down,downside,502,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160571955,1,['down'],['downside']
Availability,"Awesome, thanks for the suggestion to look in the .uns variable! Just to confirm, are the available palettes options that can be used with the palette keyword in the call to the sc.pl.tsne() function listed in the palettes.py file? For example things like vega_20_scanpy, zeileis_26, and godsnot_64?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/156#issuecomment-390299178:90,avail,available,90,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156#issuecomment-390299178,1,['avail'],['available']
Availability,"B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 71.915,07 msec task-clock:u # 14,035 CPUs utilized ( +- 9,53% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.168.035 page-faults:u # 29,496 K/sec ( +- 9,58% ); 	 191.815.791.770 cycles:u # 4,844 GHz ( +- 9,53% ) (83,37%); 	 10.610.492.234 stalled-cycles-frontend:u # 10,05% frontend cycles idle ( +- 9,44% ) (83,34%); 	 59.853.476.395 stalled-cycles-backend:u # 56,69% backend cycles idle ( +- 9,56% ) (83,32%); 	 257.750.810.841 instructions:u # 2,44 insn per cycle; 	 # 0,13 stalled cycles per insn ( +- 9,57% ) (83,33%); 	 45.773.330.764 branches:u # 1,156 G/sec ( +- 9,58% ) (83,33%); 	 1.147.567.613 branch-misses:u # 4,56% of all branches ( +- 9,54% ) (83,37%); 	; 	 5,1241 +- 0,0242 seconds time elapsed ( +- 0,47% ); ```. - this PR:. ```console; $ git switch hvg_PR_numba; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 113.085,21 msec task-clock:u # 15,789 CPUs utilized ( +- 9,56% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.636.606 page-faults:u # 26,373 K/sec ( +- 9,55% ); 	 310.410.832.165 cycles:u # 5,002 GHz ( +- 9,55% ) (83,35%); 	 14.117.222.045 stalled-cycles-frontend:u # 8,30% frontend cycles idle ( +- 9,46% ) (83,38%); 	 75.813.970.243 stalled-cycles-backend:u # 44,56% backend cycles idle ( +- 9,57% ) (83,35%); 	 373.047.679.552 instructions:u # 2,19 insn per cycle; 	 # 0,11 stalled cycles per insn ( +- 9,57% ) (83,34%); 	 67.830.590.839 branches:u # 1,093 G/sec ( +- 9,58% ) (83,35%); 	 1.702.825.180 branch-misses:u # 4,56% of all branches ( +- 9,56% ) (83,28%); 	; 	 7,1623 +- 0,0560 seconds time elapsed ( +- 0,78% ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266:1654,fault,faults,1654,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266,1,['fault'],['faults']
Availability,"Based on [this conversation](https://discourse.scverse.org/t/scgen-generate-irreproducible-output/1622/3) on the scverse discourse site I found out that the behavior shown here does not happen if I install scanpy and pytorch (CUDA) from PyPI. It is however still happening if I install scanpy and pytorch (CUDA) using conda. I still do not know why this is happening but this shows it is not likely a problem with scanpy but some strange interaction. I will leave here the description of the packages installed in both cases for reference, and then close the issue:. 1. The behavior shown in this issue does not happen if I create an environment in conda with python installed, and then install all packages using pip like this:. ```; conda create -n scanpy_test1 python; pip install scanpy leidenalg scvi-tools; pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118; ```. This allows me to have GPU support with scvi-tools and different runs are reproducible. The packages in this environment:. <details><summary>Packages</summary>; <p>. # Name Version Build Channel; _libgcc_mutex 0.1 conda_forge conda-forge; _openmp_mutex 4.5 2_gnu conda-forge; absl-py 1.4.0 pypi_0 pypi; adjusttext 0.8 pypi_0 pypi; aiohttp 3.8.5 pypi_0 pypi; aiosignal 1.3.1 pypi_0 pypi; airr 1.4.1 pypi_0 pypi; anndata 0.9.1 pypi_0 pypi; anyio 3.7.1 pypi_0 pypi; arrow 1.2.3 pypi_0 pypi; asttokens 2.2.1 pyhd8ed1ab_0 conda-forge; async-timeout 4.0.2 pypi_0 pypi; attrs 23.1.0 pypi_0 pypi; awkward 2.3.1 pypi_0 pypi; awkward-cpp 21 pypi_0 pypi; backcall 0.2.0 pyh9f0ad1d_0 conda-forge; backoff 2.2.1 pypi_0 pypi; backports 1.0 pyhd8ed1ab_3 conda-forge; backports.functools_lru_cache 1.6.5 pyhd8ed1ab_0 conda-forge; beautifulsoup4 4.12.2 pypi_0 pypi; blessed 1.20.0 pypi_0 pypi; brotli-python 1.0.9 py311ha362b79_9 conda-forge; bzip2 1.0.8 h7f98852_4 conda-forge; ca-certificates 2023.7.22 hbcca054_0 conda-forge; certifi 2022.12.7 pypi_0 pypi; charset-normalizer 2.1.1 pypi_0 pypi; chex 0.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:874,down,download,874,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205,1,['down'],['download']
Availability,"Based on my experience setting a single cutoff for all datasets will not work, as I've used a lot of different cutoffs depending on the distributions. I would echo @ivirshup's suggestion of looking at distributions. Joint distributions being a lot more important than individual histograms. There's a small discussion about it in our [best practices paper](https://www.embopress.org/lookup/doi/10.15252/msb.20188746)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/718#issuecomment-507264814:159,echo,echo,159,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/718#issuecomment-507264814,1,['echo'],['echo']
Availability,"Below is code that reproduces the error. What I've already tried is 1) updating all the packages 2) reverting to the versions I had prior and 3) creating a new virtual environment and reinstalling everything. None of them worked. . ```; # import libraries; import numpy as np; import pandas as pd; import scanpy as sc; import scvelo as scv; # download data; adata = scv.datasets.pancreas(); # preprocess ; sc.pp.filter_cells(adata, min_counts=200); sc.pp.filter_genes(adata, min_cells=10); adata.raw = adata; sc.pp.highly_variable_genes(; adata, ; n_top_genes=3000, ; flavor='seurat_v3', ; subset=True; ); sc.tl.pca(adata); # find neighbors -- this is the bit that errors; sc.pp.neighbors(; adata, ; n_neighbors=20,; n_pcs=30, ; metric='cosine', ; random_state=312; ); ```. The error is below: . ```; OMP: info #276: omp_set_nested_routine is deprecated, please use omp_set_max_active_levels instead. ; ```; The output of `pip freeze` detailing all of my package versions is attached. My Python version is 3.11.6, and I'm using a 2020 Intel MacBook Pro running Sonoma v14.3. ; [requirements.txt](https://github.com/scverse/scanpy/files/14074316/requirements.txt)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2361#issuecomment-1913368683:34,error,error,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1913368683,4,"['down', 'error']","['download', 'error', 'errors']"
Availability,"Both are available on conda forge. I might be able to help if you show me. 1. the command and environment file you used; 2. the output (in English: you can use e.g. `env LANG=C conda ...` for that). Please format everything as a code block and don’t just paste it into the comment box, [see here](https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax#quoting-code)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3029#issuecomment-2077238728:9,avail,available,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029#issuecomment-2077238728,1,['avail'],['available']
Availability,"Both of these modules are not in the docs and not referenced in any tutorial and I never considered them mature code... I always planned on fixing these... but my bandwidth for this is limited... I should not have merged them into master, that's my fault... Won't happen again...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/392#issuecomment-445515498:249,fault,fault,249,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/392#issuecomment-445515498,1,['fault'],['fault']
Availability,But I think it's a little different. It's probably easier to implement since we still have all dependencies available at collection time.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088708723:108,avail,available,108,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088708723,1,['avail'],['available']
Availability,"But I think scanpydoc is very confused now for some reason. Documentation build is broken, it's visible in ~all~ some recent PRs too and there is not much we can do without the help of @falexwolf or @flying-sheep or @ivirshup, because we cannot even see the error message. My local builds are just fine 🤷",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1204#issuecomment-645460915:258,error,error,258,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204#issuecomment-645460915,1,['error'],['error']
Availability,"But also, that looks like an h5py issue. Do you still get the error if you try `import h5py` in that environment?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/587#issuecomment-479721635:62,error,error,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479721635,1,['error'],['error']
Availability,But the error comes from your variable names being tuples. The following fixes it.; ```; adata.var_names = [i[0] for i in adata.var_names]; ```. Let me think where it would be best to output a warning. I'm not quite sure where else it would lead to collisions. Do you need tuples in the index?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/365#issuecomment-440431843:8,error,error,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365#issuecomment-440431843,1,['error'],['error']
Availability,"By default, scanpy took the expression data saved at adata.raw if that is not available it took the data from adata.X. If you are loading the expression data from csv or txt file, try to save adata.raw = data, before slicing for HVGs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517#issuecomment-1770949492:78,avail,available,78,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-1770949492,1,['avail'],['available']
Availability,"Can rank_genes_groups be linked to use diffxpy on top of the available methods? . I am using the following code to convert the output of rank_genes_groups to a data frame, in case is useful:. ```PYTHON; def rank_genes_groups_df(adata, key='rank_genes_groups'):; # create a data frame with columns from .uns['rank_genes_groups'] (eg. names, ; # logfoldchanges, pvals). ; # Ideally, the list of columns should be consistent between methods; # but 'logreg' does not return logfoldchanges for example. dd = []; groupby = adata.uns['rank_genes_groups']['params']['groupby']; for group in adata.obs[groupby].cat.categories:; cols = []; # inner loop to make data frame by concatenating the columns per group; for col in adata.uns[key].keys():; if col != 'params':; cols.append(pd.DataFrame(adata.uns[key][col][group], columns=[col])); ; df = pd.concat(cols,axis=1); df['group'] = group; dd.append(df). # concatenate the individual group data frames into one long data frame; rgg = pd.concat(dd); rgg['group'] = rgg['group'].astype('category'); return rgg.set_index('group'); ```. This results on a table like this:. ![image](https://user-images.githubusercontent.com/4964309/64006299-5789a880-cb12-11e9-9196-305a318b9395.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/723#issuecomment-526515294:61,avail,available,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/723#issuecomment-526515294,1,['avail'],['available']
Availability,Can this just be inferred under the hood/raise a warning? It's a very frustrating error and not clear at all what the root issue for an end user.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1406#issuecomment-1442407575:82,error,error,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1406#issuecomment-1442407575,1,['error'],['error']
Availability,Can we customize the contents of left hand table of contents drop down?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2220#issuecomment-1090204379:66,down,down,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2220#issuecomment-1090204379,1,['down'],['down']
Availability,"Can we reopen this issue? I still don't see this functionality available. The ask is to be able to specify the number of rows or columns for the arrangement of the output panels from `sc.pl.violin`. Right now if I plot 8 genes, for example, they all show up on one row, yielding tiny plots. It would be nice to be able to pass in something like `ncols=4` so that the 8 panels will be arranged as a 2x4 instead of a 1x8.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/348#issuecomment-745609837:63,avail,available,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/348#issuecomment-745609837,1,['avail'],['available']
Availability,"Can you call `del adata.uns['cell_ontology_class_colors']`? This should throw a better error message... I can do that soon, I wonder how you managed to produce the error... cannot be anything related to a recent update... Hm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/363#issuecomment-439745461:87,error,error,87,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363#issuecomment-439745461,2,['error'],['error']
Availability,"Can you give me the full code you ran for testing and the results from numpy testing for; `np.testing.assert_array_equal(adata.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""])`; `np.testing.assert_array_equal(adata.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data)`.; The first one should give you an error. The second one shouldn't. How big is your dataset?; Please note that if you use scanpy 1.9.6 that changes of this PR won't have taken effect yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2655#issuecomment-1822719952:320,error,error,320,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1822719952,1,['error'],['error']
Availability,Can you provide an example to reproduce. From this issue #28 it seems to be related to dense matrices. Can try transforming `adata=sc.datasets.pbmc68k_reduced()` to see if you trigger the error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1114#issuecomment-627888788:188,error,error,188,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114#issuecomment-627888788,1,['error'],['error']
Availability,"Caught it. I had forgotten that arguments only get evaluated once, so if you mutate them, there is state which is maintained to other calls. I think the unhelpful `abort` message is from `louvain-igraph` expecting a weight vector of the right shape, which ended up with the error:. ```; libc++abi.dylib: terminating with uncaught exception of type char const*; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/248#issuecomment-419698370:274,error,error,274,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/248#issuecomment-419698370,1,['error'],['error']
Availability,"Changing it to a property throws a different error:. <details>; <summary> from make html </summary>. ```sh; reading sources... [ 5%] generated/classes/scanpy.pl.DotPlot ; Exception occurred:; File ""/usr/local/lib/python3.8/site-packages/sphinx/util/docfields.py"", line 369, in transform; new_list += fieldtype.make_field(fieldtypes, self.directive.domain, items,; TypeError: make_field() got an unexpected keyword argument 'inliner'; The full traceback has been saved in /var/folders/bd/43q20k0n6z15tdfzxvd22r7c0000gn/T/sphinx-err-qbzn5se8.log, if you want to report the issue to the developers.; Please also report this if it was a user error, so that a better error message can be provided next time.; A bug report can be filed in the tracker at <https://github.com/sphinx-doc/sphinx/issues>. Thanks!; make: *** [html] Error 2; ```. </details>. <details>; <summary> contents of the referenced log file </summary>. ```python; # Sphinx version: 4.1.0; # Python version: 3.8.10 (CPython); # Docutils version: 0.16 release; # Jinja2 version: 2.11.2; # Last messages:; # reading sources... [ 2%] dev/documentation; # reading sources... [ 2%] dev/external-tools; # reading sources... [ 3%] dev/getting-set-up; # reading sources... [ 3%] dev/index; # reading sources... [ 3%] dev/release; # reading sources... [ 4%] dev/testing; # reading sources... [ 4%] dev/versioning; # reading sources... [ 4%] ecosystem; # reading sources... [ 5%] external; # reading sources... [ 5%] generated/classes/scanpy.pl.DotPlot; # Loaded extensions:; # sphinx.ext.mathjax (4.1.0) from /usr/local/lib/python3.8/site-packages/sphinx/ext/mathjax.py; # sphinxcontrib.applehelp (1.0.2) from /usr/local/lib/python3.8/site-packages/sphinxcontrib/applehelp/__init__.py; # sphinxcontrib.devhelp (1.0.2) from /usr/local/lib/python3.8/site-packages/sphinxcontrib/devhelp/__init__.py; # sphinxcontrib.htmlhelp (2.0.0) from /usr/local/lib/python3.8/site-packages/sphinxcontrib/htmlhelp/__init__.py; # sphinxcontrib.serializinghtml (1.1.5",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1946#issuecomment-877995557:45,error,error,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946#issuecomment-877995557,4,"['Error', 'error']","['Error', 'error']"
Availability,Changing to WIP since I'd like to improve failure handling before this gets merged.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/573#issuecomment-478207900:42,failure,failure,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478207900,1,['failure'],['failure']
Availability,"Completely agree, Gökcen!. How I just thought about dealing with this in the past couple of minutes: could we not make a submodule *rtools*? We could show the contained wrapper functions on an extra page of the API. All of the dependencies of this would be optional. In effect, this would be a very shallow wrapper that is only interesting for people who already have a working R installation etc. and use Scanpy along with R packages. As there are quite many of these people, this is definitely meaningful. The code would still look proper. Implementing tests for these wrappers is maybe not so important as these are only shallow interfaces. It would be easier to have this in the main scanpy repository than setting up a `scanpy-contrib`: I imagine less people will like to contribute and take the burden of maintaining another repository. PS: `anndata` is a different story. That's something that is meant to be so basic that it doesn't need a lot of maintenance an contributions. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/125#issuecomment-381984759:955,mainten,maintenance,955,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125#issuecomment-381984759,1,['mainten'],['maintenance']
Availability,"Cool! . > * Mask out genes which aren't expressed in the compared groups (since there's not too much point in getting and correcting a pvalue for them). I think masking out might be problematic because, `n_genes=adata.n_vars` should return all genes in any case. . > * Revert change (would bring back issue of genes with variance of 0). I feel like using scipy function will slightly increase the maintainability (and simplicity) of the code, so I'm fine with keeping the scipy switch. > * Wrap the t-test with something like `np.errstate` to hide the warning. This sounds good. Replacing weird scipy warning with a proper scanpy warning would also make sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/629#issuecomment-489105754:12,Mask,Mask,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629#issuecomment-489105754,2,"['Mask', 'mask']","['Mask', 'masking']"
Availability,Could you come up with the minimum amount of commands you'd need to run to reproduce this? It would also be helpful if this could be done using generated or publicly available data. [Something like this](http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) would be great.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1701#issuecomment-787877279:166,avail,available,166,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701#issuecomment-787877279,1,['avail'],['available']
Availability,"Could you please do `Dict[KeyType, ValueType]` instead of `dict` in the type annotations?. @falexwolf you forgot that the types will be added to the shift-tab info too: https://github.com/theislab/scanpy/blob/10f8a3c8aa5cfa4431db2a10f1f3cc088072e788/scanpy/__init__.py#L42. So yes, @LuckyMD please remove all *redundant* type info in the docs. The info for `method` and `normalize` should stay, the rest can go with absolutely no loss of information anywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/549#issuecomment-476111286:310,redundant,redundant,310,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-476111286,1,['redundant'],['redundant']
Availability,"Could you please provide more information about his error? How do you create the scanpy tmp?. In addition, the result of sc.tl.umap is stored in the scanpy file as obsm['X_umap']. You can try to display these data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1954#issuecomment-883854761:52,error,error,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1954#issuecomment-883854761,1,['error'],['error']
Availability,Could you post the full error traceback so that I see where the error is raised?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-456634106:24,error,error,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-456634106,2,['error'],['error']
Availability,Could you suggest some error handling behavior here? I think there could definitely be a more helpful error message.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1504#issuecomment-732724704:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504#issuecomment-732724704,2,['error'],['error']
Availability,"Could you throw a more informative error message for `copy=False`? Maybe:. `NotImplementedError(""Inplace subsampling is not implemented for backed objects"")`. ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2624#issuecomment-1691514632:35,error,error,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2624#issuecomment-1691514632,1,['error'],['error']
Availability,"Current thinking on the test failures: #2129 was fixed upstream in pandas, so is no longer needed. This is needed, but I can't retrigger the builds because Azure is down in Europe.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2120#issuecomment-1040372589:29,failure,failures,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2120#issuecomment-1040372589,2,"['down', 'failure']","['down', 'failures']"
Availability,"Currently there's an error being raised because the following images in don't match. path: `scanpy/tests/notebooks/_images_paga_paul15_subsampled/paga_path.png`. **Expected**; ![paga_path](https://user-images.githubusercontent.com/8322751/90666060-de033280-e21a-11ea-83f9-684908586f6e.png). **Actual**; ![paga_path](https://user-images.githubusercontent.com/8322751/90666074-e2c7e680-e21a-11ea-9f08-fc495d6762b0.png). **Diff**; ![paga_path-failed-diff](https://user-images.githubusercontent.com/8322751/90666089-e78c9a80-e21a-11ea-9e0c-4e7e6a80d140.png). I'm going to update expected to match actual, but I need some help to see if this is okay",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1382#issuecomment-676542244:21,error,error,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1382#issuecomment-676542244,1,['error'],['error']
Availability,D scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stack,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:2632,Error,Error,2632,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"Dear @LouisFaure,. thank you very much for the high quality PR.; A couple of questions:; 1. Do you think that we should check for whether GPUs are available if any of the GPU accelerated methods were chosen? This would allow us to exit more nicely if we were requesting GPU support but none were found; 2. I think that we should homogenize the parameter names for the method selection. Sometimes they are called 'method', sometimes 'flavor' and then you're also using 'device'. I myself am a fan of 'device' to switch between CPU and GPU implementations. However, then it would be unclear which method to use when several GPU accelerated algorithms for a task are implemented. Do you have better ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-815285176:147,avail,available,147,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533#issuecomment-815285176,1,['avail'],['available']
Availability,"Dear All,; running the tutorial `pbmc3k.ipynb`. I get a similar error than above:; ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-23-ea8d9dc47463> in <module>; ----> 1 sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/scanpy/preprocessing/highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace); 115 # a normalized disperion of 1; 116 one_gene_per_bin = disp_std_bin.isnull(); --> 117 gen_indices = np.where(one_gene_per_bin[df['mean_bin']])[0].tolist(); 118 if len(gen_indices) > 0:; 119 logg.msg(. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in __getitem__(self, key); 909 key = check_bool_indexer(self.index, key); 910 ; --> 911 return self._get_with(key); 912 ; 913 def _get_with(self, key):. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key); 951 return self.loc[key]; 952 ; --> 953 return self.reindex(key); 954 except Exception:; 955 # [slice(0, 5, None)] will break if you convert to ndarray,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs); 3732 @Appender(generic.NDFrame.reindex.__doc__); 3733 def reindex(self, index=None, **kwargs):; -> 3734 return super(Series, self).reindex(index=index, **kwargs); 3735 ; 3736 def drop(self, labels=None, axis=0, index=None, columns=None,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4354 # perform the reindex on the axes; 4355 return self._reindex_axes(axes, level, limit, tolerance, method,; -> 4356 fill_value, copy).__finalize__(self); 4357 ; 4358 def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264:64,error,error,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264,1,['error'],['error']
Availability,"Dear Olivia,; as I understand, you get a; ```; KeyError: 'Wfdc18'; ```; when calling; ```; adata1 = adata[:, filter_result.gene_subset]; adata1.var.ix['Wfdc18']; ```; Right? So, 'Wfdc18' is no longer `adata1.var_names`. You can also check by typing; ```; print('Wfdc18' in adata1.var_names); ```; which should print `False`. Regarding plotting: as stated in the [basic tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb) in box [22], you have to pass `use_raw=False` if you want to access `adata.X` in plotting if `adata.raw` has been set, otherwise it assumes that you want to plot the raw data.; ```; sc.pl.pca(adata1, color='Wfdc18', use_raw=False); ```; which will throw an error after filtering if 'Wfdc18' is no longer there. Does this help and explain what you observe?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/109#issuecomment-375856560:734,error,error,734,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109#issuecomment-375856560,1,['error'],['error']
Availability,"Dear both, . correlation matrices are available now. Following our usual split into tools and plotting, you can call . `sc.tl.correlation_matrix(adata,name_list, n_genes=20, annotation_key=None, method='pearson')`. for correlation matrix calculation. ; I have left out a few parameters because I wrote the function actually to conveniently plot results from DE testing, but the basic functionality is the following: . _adata_ is the usual AnnData object you are working with. ; _name_list_ is a string containing gene names and should be specified. ; _n_genes_ cuts the name_list if the number specified is smaller then the length of the list, so set this high enough if you want to work with large data ; _annotation_key_ allows you to specify a string that works as the key in the AnnData object where results are stored. By default, the key is ""Correlation_matrix"". The method basically wraps the pd.DataFrame.corr method, which allows you to specify the correlation method ('pearson', 'spearman', 'kendall'). . I use it for smaller data so it has not been optimized for performance (yet), but I tested the method for 3k cells and 600 genes and ended up with a runtime of ~8 seconds. I hope that is conveniently fast enough for you (if not let us know). . After calling the tool, you can plot correlation matrices (using a wrapper for seaborn heatmap) by calling. `sc.pl.correlation_matrix(adata, annotation_key=None)`. This function searches basically only the AnnData annotation (again, if no key specified, ""Correlation_matrix"" is the default). Hope this does the job!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/72#issuecomment-361891662:38,avail,available,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72#issuecomment-361891662,1,['avail'],['available']
Availability,"Dear professor&nbsp;Philipp A. Thank you of your patience.; I've attached my Anndata and codes in the attachment. Kind regards. ; Original Email; ; . Sender:""Philipp A.""< ***@***.*** &gt;;. Sent Time:2024/6/7 19:28. To:""scverse/scanpy""< ***@***.*** &gt;;. Cc recipient:""FessenSimon""< ***@***.*** &gt;;""Author""< ***@***.*** &gt;;. Subject:Re: [scverse/scanpy] unexpected error in sc.pl.dpt_timeseries anddpt_groups_pseudotime (Issue #3086). ; Please create a fully reproducible example. I can’t help if I don’t have an AnnData object that doesn’t behave like yours.; ; —; Reply to this email directly, view it on GitHub, or unsubscribe.; You are receiving this because you authored the thread.Message ID: ***@***.***&gt;; . 	; 	 		 			从QQ邮箱发来的超大附件 	; 	 		 				 					 						 							 						 					; 					 						 							repro.zip 							 (321.0MB, 2024年7月8日 16:26) 						 						 							进入下载页面 							：https://wx.mail.qq.com/ftn/download?func=3&k=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&key=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&code=5cf58db9&from=",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3086#issuecomment-2155872130:370,error,error,370,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086#issuecomment-2155872130,2,"['down', 'error']","['download', 'error']"
Availability,"Dear scverse authors (@flying-sheep, @LucaMarconato et al.), because of issues like these, maybe think about a sophisticated staging environment a la Bioconductor to ensure that packages are compatible with each other. If you do a `conda install scanpy` that finishes without any error, it cannot be that `import scanpy` fails with an error resulting from an incompatible matplotlib version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3029#issuecomment-2362123395:280,error,error,280,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029#issuecomment-2362123395,2,['error'],['error']
Availability,Did you check if the expected and actual images were significantly different. Some times I get errors locally because is difficult to have an identical environment as the one used by Travis.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1418#issuecomment-698870987:95,error,errors,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1418#issuecomment-698870987,1,['error'],['errors']
Availability,"Do you get an exception message or something else? If you can also copy paste the error message here, we can debug it more easily.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/749#issuecomment-515127872:82,error,error,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749#issuecomment-515127872,1,['error'],['error']
Availability,"Do you know how that entry could have been filled with `NaN`?. The plots and errors you were showing above are consistent with all the values being ""null"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1701#issuecomment-787868527:77,error,errors,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701#issuecomment-787868527,1,['error'],['errors']
Availability,"Do you know which step of the script the results start differing? That would help in cutting down where the issue is occurring. If not, it would be useful if you could share objects with different results from the various machines. You could use the `sc.datasets.pbmc3k` for this (if your data is private). Would you also be able to share the output of `numba -s` from each of these environments? Different CPUs can give different results from numba code due to the features available. Ping resident windows expert @Koncopd",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2114#issuecomment-1016440947:93,down,down,93,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1016440947,3,"['Ping', 'avail', 'down']","['Ping', 'available', 'down']"
Availability,"Do you mean that If I want to do use `scanpy.tl.louvain`, I can use `scanpy.tl.leiden` instead? I can `pip install scanpy[leiden]` but it will not change the error message in `scanpy.tl.louvain` with option `flavor='vtraag'`. When I try `pip install scanpy[louvain]`, it has the error `legacy-install-failure`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1283#issuecomment-1638255295:158,error,error,158,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283#issuecomment-1638255295,3,"['error', 'failure']","['error', 'failure']"
Availability,Does anyone have a nice instruction set on how I can reproduce the travis python 3.5 environment? @flying-sheep? Maybe I can hunt down the cause of the error then... although it's apparently only sporadic according to @ivirshup :/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/549#issuecomment-478667021:130,down,down,130,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-478667021,2,"['down', 'error']","['down', 'error']"
Availability,"Does this cause the same issue?. ```python; import numpy as np; import umap. umap.UMAP().fit_transform(np.random.randn(10_000, 20)); ```. And when you say ""dies"", is there a segfault message, or are you seeing a jupyter kernel failure message?. In general, this sounds like a numba issue. I'd recommend taking searching the `umap-learn` or `numba` repositories for similar issues.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1567#issuecomment-754547843:227,failure,failure,227,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1567#issuecomment-754547843,1,['failure'],['failure']
Availability,"Don't think so. I think these are closer to errors I was getting locally a few weeks ago, but couldn't get CI to reproduce.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2140#issuecomment-1041497012:44,error,errors,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2140#issuecomment-1041497012,1,['error'],['errors']
Availability,Downgrading `scikit-learn` to `0.20.3` does not resolve the error...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/666#issuecomment-496837522:0,Down,Downgrading,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-496837522,2,"['Down', 'error']","['Downgrading', 'error']"
Availability,"Due to a misconfiguration in Travis setup, all tests are now running only with Python 3.7 now and there is a mysterious HDF error somewhat related to Python 3.7 and pytables.; Python version is fixed in https://github.com/theislab/scanpy/pull/201, so until we have Python 3.7 tests, we are good.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/199#issuecomment-405085782:124,error,error,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/199#issuecomment-405085782,1,['error'],['error']
Availability,ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - I,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62040,ERROR,ERROR,62040,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63354,ERROR,ERROR,63354,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68099,ERROR,ERROR,68099,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"Either that, or allow the downstream code to gracefully handle `inf` values.; It is the binning procedure for both 'seurat' and 'cell_ranger' that seem to be a problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/763#issuecomment-517842921:26,down,downstream,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763#issuecomment-517842921,1,['down'],['downstream']
Availability,"Encountered this same error, not clear what is causing it. . ``` ; sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); adata.raw = adata; sc.pp.scale(adata, max_value=10); sc.pp.filter_genes(adata, min_cells=2); sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000); ; ```; With the same error:. ```; File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts; f""Bin edges must be unique: {repr(bins)}.\n""; ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,; -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,; 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,; 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,; 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,; inf]).; You can drop duplicate edges by setting the 'duplicates' kwarg; ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/509#issuecomment-1147252922:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509#issuecomment-1147252922,3,['error'],['error']
Availability,Encountering the same error. Updating h5py did not seem to help. Any advice on this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1372320558:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1372320558,1,['error'],['error']
Availability,Error here; ![image](https://github.com/scverse/scanpy/assets/117483585/c23b446d-f5f9-4775-95ce-eda0a49aba81). ![image](https://github.com/scverse/scanpy/assets/117483585/09ee6450-66b0-43e2-8079-fcb3e06735d4),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2494#issuecomment-1564798184:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494#issuecomment-1564798184,1,['Error'],['Error']
Availability,"Error when trying this where `X` is a dask array with sparse chunks:. ```python; result = sc.pp.highly_variable_genes(adata, inplace=False); ```. <details>; <summary> Traceback </summary>. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/dask/array/reductions.py:363, in partial_reduce(func, x, split_every, keepdims, dtype, name, reduced_meta); 362 try:; --> 363 meta = func(reduced_meta, computing_meta=True); 364 # no meta keyword argument exists for func, and it isn't required. File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/dask/array/reductions.py:685, in mean_combine(pairs, sum, numel, dtype, axis, computing_meta, **kwargs); 684 ns = deepmap(lambda pair: pair[""n""], pairs) if not computing_meta else pairs; --> 685 n = _concatenate2(ns, axes=axis).sum(axis=axis, **kwargs); 687 if computing_meta:. TypeError: _cs_matrix.sum() got an unexpected keyword argument 'keepdims'. During handling of the above exception, another exception occurred:. IndexError Traceback (most recent call last); Cell In[19], line 1; ----> 1 result = sc.pp.highly_variable_genes(adata, inplace=False); 2 result. File /mnt/workspace/mambaforge/envs/scanpy-dev/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw); 77 @wraps(fn); 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:; 79 if len(args_all) <= n_positional:; ---> 80 return fn(*args_all, **kw); 82 args_pos: P.args; 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File /mnt/workspace/repos/scanpy/scanpy/preprocessing/_highly_variable_genes.py:702, in highly_variable_genes(***failed resolving arguments***); 699 del min_disp, max_disp, min_mean, max_mean, n_top_genes; 701 if batch_key is None:; --> 702 df = _highly_variable_genes_single_batch(; 703 a",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906001725:0,Error,Error,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1906001725,1,['Error'],['Error']
Availability,"Even I changed it manually, still error with CERTIFICATE_VERIFY_FAILED:. ```; >>> import scanpy as sc; >>> adata_ref = sc.datasets.pbmc3k_processed(); pbmc3k_processed.h5ad: 0.00B [00:00, ?B/s]; Traceback (most recent call last):; File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1317, in do_open; encode_chunked=req.has_header('Transfer-encoding')); File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1229, in request; self._send_request(method, url, body, headers, encode_chunked); File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1275, in _send_request; self.endheaders(body, encode_chunked=encode_chunked); File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1224, in endheaders; self._send_output(message_body, encode_chunked=encode_chunked); File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output; self.send(msg); File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send; self.connect(); File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect; server_hostname=server_hostname); File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket; session=session; File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create; self.do_handshake(); File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake; self._sslobj.do_handshake(); ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper; return f(*args, **kwargs); File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1472#issuecomment-721326665:34,error,error,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472#issuecomment-721326665,1,['error'],['error']
Availability,"Exact same error also happened to me in my analysis, need a fix.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1446#issuecomment-1566468673:11,error,error,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446#issuecomment-1566468673,1,['error'],['error']
Availability,Exactly same error here.; info:; scanpy==1.4.6 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.5 scipy==1.3.1 pandas==1.0.0 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1151#issuecomment-611362371:13,error,error,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151#issuecomment-611362371,1,['error'],['error']
Availability,"Exactly the same error message pops up when inputting `np.int64` data into `sc.pp.log1p()`. This is with the latest scanpy, and using data that has otherwise worked well when not using `sc.pp.downsample_counts()`. I thus wouldn't consider this resolved, although I can open another issue as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-475722334:17,error,error,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475722334,1,['error'],['error']
Availability,"Exactly, the error was introduced by some third party update or so. Therefore there was no need for 6e797fa, and it even is is wrong, the second line *needs* to be. ```py; colors = cmap(normalize(mean_flat)); ```. It’s both faster and necessary: `Normalize` determines vmin and vmax from the first time it’s called when they’re not set / set to `None`. And when you call it with `normalize(mean_flat[0])` (what happens in the list comprehension), vmin gets set to `min(mean_flat[0]) == mean_flat[0]` instead of `min(mean_flat)`. please do. ```sh; git reset --hard a4b3ccd88f0412461813838d5435ce0cc0b10883; git push -f; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/390#issuecomment-446104893:13,error,error,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/390#issuecomment-446104893,1,['error'],['error']
Availability,"FEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py; >>> scanpy-master]$ git init; Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/; >>> scanpy-master]$ git tag v1.4.5.dev0; fatal: Failed to resolve 'HEAD' as a valid ref.; >>> scanpy-master]$ pip install -e .; Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master; Complete output from command python setup.py egg_info:; Traceback (most recent call last):; File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>; from setuptools_scm import get_version; ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>; from scanpy import __author__, __email__; File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>; __version__ = version(__name__); File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version; return version(package); File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version; return distribution(package).version; File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution; return Distribution.from_name(package); File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name; raise PackageNotFoundError(name); importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Dow",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/838#issuecomment-533019090:1156,Down,Download,1156,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838#issuecomment-533019090,1,['Down'],['Download']
Availability,"FIXED: Updating adata.X to a scipy csr sparse matrix using `adata.X = scipy.sparse.csr_matrix(adata.X)` fixed this error. . I still get `RuntimeWarning: invalid value encountered in sqrt std = np.sqrt(var)` when running `sc.pp.scale(adata, max_value=10)` even after forcing to a csr matrix, but doesn't seem to affect downstream results...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-718318538:115,error,error,115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-718318538,2,"['down', 'error']","['downstream', 'error']"
Availability,"FWIW, I stumbled upon a related issue this morning where my kernel just crashes/restarts computing neighbors. . For me it appears to crop up when the number of neighbors is <15, metric doesn't appear to matter. I've been upgrading/downgrading various dependencies, and I'm fairly certain this has to do with the call to [`NNDescent` in `umap.umap_.py`](https://github.com/lmcinnes/umap/blob/b1223505ca56ae104feb35e4196227277d1e8058/umap/umap_.py#L328) as if I import that directly, it raises the same errors. Currently have `numba=0.52` `llvmlite=0.35.0` `scanpy=1.7.1` `pynndescent=0.5.2` `umap-learn=0.5.1`. Rebuilding my environment from scratch and will update with a complete package list.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696#issuecomment-797603893:231,down,downgrading,231,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696#issuecomment-797603893,2,"['down', 'error']","['downgrading', 'errors']"
Availability,"Faced exactly the same problem with file ""GSE185477_GSM3178784_C41_SC_raw_counts.zip"" from [GSE185477](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE185477). The advice from @hurleyLi helped, thanks a lot! But the error is quite confusing. It would be great to read files without extra actions for the user, but is it possible to at least change the error message? E.g.; ```python; try:; ....; except KeyError:; raise KeyError(""Unexpected error, probably due to Cellranger version. Make sure to unarchive gzipped file coming from Cellranger v2""); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1916#issuecomment-1296918392:222,error,error,222,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916#issuecomment-1296918392,3,['error'],['error']
Availability,"Fidel, sorry to say, but I've run into some issues. Most of these actually didn't have to do with this PR, but were additional things that broke from #1499. I'll give you a few examples of what I've found, mostly by contrast with the current behaviour of 1.6.1. ```python; import scanpy as sc, pandas as pd, numpy as np. M, N = (5, 3); adata = sc.AnnData(; X=np.zeros((M, N)),; obs=pd.DataFrame(; np.arange(M * 3).reshape((M, 3)),; columns=[""repeated_col"", ""repeated_col"", ""var_id""],; index=pd.Index([f""cell_{i}"" for i in range(M)], name=""obs_index""),; ),; var=pd.DataFrame(; index=pd.Index([""var_id""] + [f""gene_{i}"" for i in range(N-1)], name=""var_index""),; ),; ); ```. ## Repeated column in `adata.obs`. I think this should be an error. This is because downstream functions (like plotting) currently assume that for each key input here, there will be one output column. Turns out this isn't exactly pandas behaviour with repeated column values, but I do think it's reasonable. ```python; M, N = 5, 3; adata = sc.AnnData(; X=np.zeros((M, N)),; obs=pd.DataFrame(; np.arange(M * 2).reshape((M, 2)),; columns=[""repeated_col"", ""repeated_col""],; index=[f""cell_{i}"" for i in range(M)],; ),; var=pd.DataFrame(; index=[f""gene_{i}"" for i in range(N)],; ), ; ); sc.get.obs_df(adata, [""repeated_col""]); ```. ### This pr (gets both columns). ```; repeated_col repeated_col; obs_index ; cell_0 0 1; cell_1 3 4; cell_2 6 7; cell_3 9 10; cell_4 12 13; ```. ### 1.6 (errors). ```pytb; ~/miniconda3/envs/scanpy-1.6/lib/python3.8/site-packages/pandas/core/internals/blocks.py in __init__(self, values, placement, ndim); 140 ; 141 if self._validate_ndim and self.ndim and len(self.mgr_locs) != len(self.values):; --> 142 raise ValueError(; 143 f""Wrong number of items passed {len(self.values)}, ""; 144 f""placement implies {len(self.mgr_locs)}"". ValueError: Wrong number of items passed 2, placement implies 1; ```. Not a great error, could definitley be improved. ## Key in adata.obs.columns and adata.var_names. In thi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421:732,error,error,732,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421,2,"['down', 'error']","['downstream', 'error']"
Availability,"File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 941, in fit_predict; self.fit(X); File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 919, in fit; self._min_spanning_tree) = hdbscan(X, **kwargs); File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 615, in hdbscan; core_dist_n_jobs, **kwargs); File ""C:\Users\Reda\Anaconda3\lib\site-packages\joblib\memory.py"", line 352, in __call__; return self.func(*args, **kwargs); File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 274, in _hdbscan_boruvka_kdtree; tree = KDTree(X, metric=metric, leaf_size=leaf_size, **kwargs); File ""sklearn\neighbors\_binary_tree.pxi"", line 1061, in sklearn.neighbors._kd_tree.BinaryTree.__init__; File ""sklearn\neighbors\_dist_metrics.pyx"", line 289, in sklearn.neighbors._dist_metrics.DistanceMetric.get_metric; TypeError: __init__() got an unexpected keyword argument 'check_pickle'. How to fix this error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1252#issuecomment-747903214:974,error,error,974,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252#issuecomment-747903214,1,['error'],['error']
Availability,"First, make sure your versions of numba and umap are up to date. Then running this without jupyter, just in python. I think jupyter is likely hiding whatever error the python process is crashing with. E.g.:. ```sh; $ python3 -c ""import numpy; import umap""; ```. If this fails, I think you should be opening an issue upstream with numba or umap (if you can figure out which one is at fault). I've had this sort of thing happen a few times. Some of the causes were:. * Multiple versions of C libraries being linked to; * Threading backends not working. I've been able to work around both of these in the past by using conda environments.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1567#issuecomment-755097946:158,error,error,158,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1567#issuecomment-755097946,2,"['error', 'fault']","['error', 'fault']"
Availability,"For context, the option was added in #334, and I think the scope for other feature types was much more limited at the time. > Would it already be worth either making gex_only a required input?. I'm not sure the `gex_only` argument even entirely makes sense anymore. I think a `feature_type` argument would make more sense. Erroring if nothing is passed and there are multiple kinds sounds reasonable to me, as multimodality should be handled explicitly. For backwards compatibility I think deprecation warnings for a release cycle when either `gex_only` is used or nothing is passed and there are multiple feature types present could work. -----------. Moving the 10x reading functions had been discussed in: #1387",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1949#issuecomment-879616528:323,Error,Erroring,323,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1949#issuecomment-879616528,1,['Error'],['Erroring']
Availability,"For me is working properly with an earlier version of scanpy and the same matplotlib version. Can you downgrade and test if the problem is only happening in the last version. Also, you can try to see if the problem is related to some matplotlib parameters by resetting them.; ```PYTHON; matplotlib.rcdefaults(); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/998#issuecomment-575066688:102,down,downgrade,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/998#issuecomment-575066688,1,['down'],['downgrade']
Availability,"For me this was solved by filtering out genes that were not expressed in any cell!; `sc.pp.filter_genes(adata, min_cells=1)`; If I include a batch_key in the hvg function, I still get the error. I guess in that case you have to ensure that every gene is expressed in every batch? Seems like a bug to fix",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-870384617:188,error,error,188,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-870384617,1,['error'],['error']
Availability,"For me, it was a different combination of versions, I guess Scanpy 1.9.8 and matplotlib 3.8 that caused the error. It's not about fixing specific instances but the problem of version mismatches of complex interacting software packages in general. And this has to run in an automated fashion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3029#issuecomment-2364261485:108,error,error,108,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029#issuecomment-2364261485,1,['error'],['error']
Availability,"For me,; adata[(adata[:,'elav'].X>0).flatten(), : ] works. otherwise, it gives error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/599#issuecomment-609054998:79,error,error,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/599#issuecomment-609054998,1,['error'],['error']
Availability,"For some reason I don't see the figures here on the Github page (and get an error message when I click on the link), but they showed fine in the email notification I received. Looks good!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-822057782:76,error,error,76,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-822057782,1,['error'],['error']
Availability,"For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3061#issuecomment-2112892549:48,down,down,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061#issuecomment-2112892549,1,['down'],['down']
Availability,"For those interested in using the GPU accelerated functions leiden, draw_graph_fa, I have made them available on the following gist:; https://gist.github.com/LouisFaure/9302aa140d7989a25ed2a44b1ce741e8. I have also included in that code `load_mtx`, which reads and convert mtx files into anndata using cudf. I tested on a 654Mo mtx containing 56621 cells x 20222 genes, I can obtain a 13X speedup (using RTX8000)! . ![image](https://user-images.githubusercontent.com/27488782/164707560-30c0c9fe-6bfe-4fcb-ac2c-0d8a503081b6.png). I expect this to scale even better with higher number of cells. I could also add this wrapper into scanpy once CI is ready.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-1106431960:100,avail,available,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533#issuecomment-1106431960,1,['avail'],['available']
Availability,Found the problem. I was running the library using python v3.9 with numba v0.51. Compatibility for python 3.9 is only available in the (currently) latest version of numba v0.53. . This incompatibility generated the crash in the pynndescent library. Why it worked for certain sizes and no other remains a mistery...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1652#issuecomment-779686831:118,avail,available,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652#issuecomment-779686831,1,['avail'],['available']
Availability,"Found the same error in our internal workflows. Saved the data to h5py files, but could not open them anymore for some reason. Error:. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 155 try:; --> 156 return func(elem, *args, **kwargs); 157 except Exception as e:. /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_group(group); 531 if encoding_type:; --> 532 EncodingVersions[encoding_type].check(; 533 group.name, group.attrs[""encoding-version""]. /opt/conda/lib/python3.7/enum.py in __getitem__(cls, name); 356 def __getitem__(cls, name):; --> 357 return cls._member_map_[name]; 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-20-38a594ec7d06> in <module>; ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 424 d[k] = read_dataframe(f[k]); 425 else: # Base case; --> 426 d[k] = read_attribute(f[k]); 427 ; 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 161 parent = _get_parent(elem); 162 raise AnnDataReadError(; --> 163 f""Above error raised while reading key {elem.name!r} of ""; 164 f""type {type(elem)} from {parent}.""; 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-1146346336:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-1146346336,2,"['Error', 'error']","['Error', 'error']"
Availability,"Fresh install in a new env gives me the same error (jupyter kernel crashes):; ```; conda create --name squidpy python=3.8 seaborn scikit-learn statsmodels numba pytables; conda activate squidpy; conda install -c conda-forge leidenalg python-igraph; pip install scanpy squidpy imctools stardist; ```; And here's the `sc.logging.print_versions()`:; ```; -----; anndata 0.7.5; scanpy 1.7.1; sinfo 0.3.1; -----; PIL 8.1.2; anndata 0.7.5; asciitree NA; backcall 0.2.0; cairo 1.20.0; cffi 1.14.5; cmocean 2.0; constants NA; cycler 0.10.0; cython_runtime NA; dask 2021.03.0; dateutil 2.8.1; decorator 4.4.2; docrep 0.3.2; fasteners NA; get_version 2.1; h5py 2.10.0; highs_wrapper NA; igraph 0.8.3; imagecodecs 2020.12.24; imageio 2.9.0; ipykernel 5.5.0; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; networkx 2.5; numba 0.52.0; numcodecs 0.7.3; numexpr 2.7.3; numpy 1.20.1; packaging 20.9; pandas 1.2.3; parso 0.8.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.17; ptyprocess 0.7.0; pycparser 2.20; pygments 2.8.1; pyparsing 2.4.7; pytz 2021.1; pywt 1.1.1; scanpy 1.7.1; scipy 1.6.0; seaborn 0.11.1; sinfo 0.3.1; six 1.15.0; skimage 0.18.1; sklearn 0.24.1; squidpy 1.0.0; statsmodels 0.12.2; storemagic NA; tables 3.6.1; texttable 1.6.3; tifffile 2021.3.5; tornado 6.1; traitlets 5.0.5; typing_extensions NA; wcwidth 0.2.5; xarray 0.17.0; yaml 5.4.1; zarr 2.6.1; zmq 22.0.3; -----; IPython 7.21.0; jupyter_client 6.1.11; jupyter_core 4.7.1; notebook 6.2.0; -----; Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]; Linux-3.10.0-1062.1.2.el7.x86_64-x86_64-with-glibc2.10; 72 logical CPU cores, x86_64; -----; Session information updated at 2021-03-12 11:42; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696#issuecomment-797629745:45,error,error,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696#issuecomment-797629745,1,['error'],['error']
Availability,"From slack, @ilan-gold mentioned that the median calculation I suggested may not work (https://dask.discourse.group/t/median-with-masked-array-behaves-unexpectedly/70). It could be replaced with something like:. ```python; da.from_delayed(; delayed(np.median)(; delayed(counts[counts > 0]); ),; shape=(),; meta=np.ndarray,; dtype=counts.dtype,; ); ```. Or probably better:. ```python; def nonzero_median(x):; return np.ma.median(np.ma.masked_array(x, x > 0)). da.from_delayed(; delayed(nonzero_median)(counts),; shape=(),; meta=np.ndarray,; dtype=counts.dtype,; ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2856#issuecomment-1981060407:130,mask,masked-array-behaves-unexpectedly,130,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2856#issuecomment-1981060407,1,['mask'],['masked-array-behaves-unexpectedly']
Availability,"From the error message, you may want to try to convert the dense matrix to sparse matrix format as follows:. ```python; from scipy.sparse impor csr_matrix; adata.X = csr_matrix(adata.X); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1645#issuecomment-778224048:9,error,error,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1645#issuecomment-778224048,1,['error'],['error']
Availability,"From the traceback, it'ss look like it's scvelo https://github.com/theislab/scvelo; Can you post this error with a reproducible example in scvelo repo ?. Will close this, feel free to reopen if problem persist",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1433#issuecomment-704248522:102,error,error,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1433#issuecomment-704248522,1,['error'],['error']
Availability,"GSE145328 is from NCBI GEO. [GSE139555_RAW.tar](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE139555) is another example that gives the same error. These are the output files generated by Cell Ranger and uploaded to NCBI GEO, based on the authors' notes in their [paper](https://www.nature.com/articles/s41586-020-2056-8). . Some examples from NCBI GEO that can be read without errors: [GSE173231](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE173231) and [GSE158803](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE158803).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1916#issuecomment-874096004:149,error,error,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916#issuecomment-874096004,2,['error'],"['error', 'errors']"
Availability,Github actions are down. It seems like they have problems at least once a week: https://twitter.com/githubstatus. I'd be fine with having pre-commit be a required check. I'm a little antsy about having something that goes down frequently be required though.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1563#issuecomment-787870905:19,down,down,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563#issuecomment-787870905,2,['down'],['down']
Availability,"Given the old function now raises an error, could you at least add a; FutureWarning (or np.exceptions.VisibleDeprecationWarning) indicating the; new function to be used? Thanks!. On Wed, 7 June 2023, 05:35 Philipp A., ***@***.***> wrote:. > Closed #2500; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500&g=ZWVjM2FjODk0ZjdmMTI1Nw==&h=N2Y4NmFmODU2ZTBlYjI1NzEzZDVlY2M3ZDQxMmVkMGVkZjY2OGMxZjEzMjZiMjNlODhmMGFhMTkwYjFmNGVjOQ==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>; > as not planned.; >; > —; > Reply to this email directly, view it on GitHub; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500%23event-9456493371&g=ZGJmZGZhMzNmOTM5ZTgzYQ==&h=Y2JmZjM5MDc2MjMzNjM3MGQwMzk1MDYxZmE3MDZlYzBiNWEzYzdjMTMwNWY5MjgxNTU5YmQ3NDI0ZDBjNWRhZg==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>,; > or unsubscribe; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/notifications/unsubscribe-auth/AUHCMAWZ7ISUHUBPHQDLLCDXKBDOHANCNFSM6AAAAAAY3HAO3E&g=NDU3YTZlZTA4ZDE0MzNhZQ==&h=OWQzOWMxNDgxMjZkZGM3ZWUxMmQ1ZTFlN2UwNjI5ZDI4YjFmMDA3OGVmYjc5MTljZDVkMDlhMTE1YjRiODBmNg==&p=YzJlOmltbXVuYWk6YzpnOjlhYTRmOGNmMDU2NDdjZTQ1ZTI0NjFjZmQ1OTY3NjljOnYxOmg6VA==>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >. -- ; PLEASE NOTE: The information contained in this message is privileged and ; confidential, and is intended only for the use of the individual to whom it ; is addressed and others who have been specifically authorized to receive ; it. If you are not the intended recipient, you are hereby notified that any ; dissemination, distribution, or copying of this communication is strictly ; prohibited. If you have received this communication in error, or if any ; problems occur with the transmission, please contact the sender.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580655895:37,error,error,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580655895,5,"['checkpoint', 'error']","['checkpoint', 'error']"
Availability,"Good to hear! Looking forward to learning more about it.; PS: Having a doublet detection tool in `tl` would be fine, I'd say... `pp` and `tl` are just meant to give a rough orientation for users... in some cases, it's not completely clear what *preprocessing* and what *downstream* analysis is...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-400277845:270,down,downstream,270,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-400277845,1,['down'],['downstream']
Availability,"Great that you fixed it! :). I'm in principle happy to merge the pull request! However, it contains a lot of the previous commits to master by other people; maybe you haven't properly rebased your branch to master at some point? Looking at the diff across the whole request, I see mostly old things from the 25 commits before. So, (1) could you point me to the diff across all your commits that you actually did? (2) Are we going to have a messed up history with redundant commits on the master branch if I merge this, I don't think so, but I'm not 100% sure. Sorry for the additional work, but blindly merging something into master is of course too dangerous, and going through each single commit is too tedious. ;). Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/248#issuecomment-420660906:463,redundant,redundant,463,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/248#issuecomment-420660906,1,['redundant'],['redundant']
Availability,"Great to hear! Usually when there’s weird, site-specific errors, I say I can’t help because I don’t have SSH access and “my crystal ball is currently out of order”. Seems like my crystal ball worked just fine these days!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-668185146:57,error,errors,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-668185146,1,['error'],['errors']
Availability,Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1490#issuecomment-727717155:50,error,error,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490#issuecomment-727717155,1,['error'],['error']
Availability,"Great!. I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1490#issuecomment-726498381:198,error,error,198,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490#issuecomment-726498381,1,['error'],['error']
Availability,"Great, thank you, @andrea-tango and @Koncopd!. @andrea-tango, would you make a PR? We can then look at how you solved this. In principle, I'm very hesitant to add `diffxpy` as a dependency of Scanpy. It depends on Tensorflow itself, which is a large dependency. What would be OK would be to have a wrapper in `scanpy.external`, but I don't know whether this makes sense. Why not using `diffxpy`s Volcano plots right away?. Regarding the discrepancy between `wilxocon` in `diffxpy` and `scanpy`. There obviously shouldn't be any and there also shouldn't be duplicated code, here, at all. The only reason that Scanpy has its own Wilcoxon implementation was that there was no implementation available that would scale to large sparse data. That's why @tcallies wrote the present implementation about 1.5 years ago. He benchmarked with scipy's Wilcoxon test. @davidsebfischer, can you shed light on why and how you implemented your Wilcoxon? Shouldn't we have a comparison? At the time, @tcallies wrote [this](https://github.com/theislab/scanpy_usage/blob/master/171106_t-test_wilcoxon_comparison/Generic%20Comparison%20T-Test%20Wilcoxon-Rank-Sum%20Test.ipynb) and these [tests](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_rank_genes_groups.py). How did you write your tests?. We were just talking about `log2FC`, which is such a simple quantity and should evidently be properly computed by `rank_genes_groups`. We just had this other PR on it (https://github.com/theislab/scanpy/pull/519). @tcallies, any thoughts from your side?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471322809:688,avail,available,688,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471322809,1,['avail'],['available']
Availability,"Great, thanks @LuckyMD! That makes a lot of sense. Aside from diffxpy, are there other packages you recommend for more robust DE approaches in these (or related) scenarios? Thanks again for your advice - and sorry for hijacking this conversation!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061820029:119,robust,robust,119,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061820029,1,['robust'],['robust']
Availability,"Great, thanks for the feedback. Hopefully this merge and commit fix everything. I wasn't able to see what errors were causing the readthedocs build fail as the ""Details"" link just took me to a page that said ""SORRY / This page does not exist yet."", so let me know if there are any other issues.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1306#issuecomment-661224338:106,error,errors,106,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306#issuecomment-661224338,1,['error'],['errors']
Availability,"Great. Please ping me here when you upload the file to `scanpy_usage` and feel free to close the issue then. I'll update my script to link directly to `scanpy_usage`. > Regarding the result: the high PCs can change drastically depending on the platform and the random seed. I've seen clustering results changing completely after I became aware of it. . I don't have much experience with randomized PCA, but this is very disturbing, no? Was your feeling that the PCs themselves changed strongly (as measured, I don't know, by the %% of total captured variance, or maybe angle between subspaces, etc.), or is it rather that clustering outcome is dangerously sensitive to small changes in the data? I think this is something worth investigating.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/325#issuecomment-435797047:14,ping,ping,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325#issuecomment-435797047,1,['ping'],['ping']
Availability,"HI everyone, . I have the excat same issue, which prevents me from performing further analysis. ; What I did : ; - dropna(), still boolean values, which poses the same error again (boolean values are NANs appearently); - fillna(0) : replaced all NAN values with 0, but this poses a problem later in the analysis when i lognormalize the data (log(0) = inf).; How do you guys deal with these sorts of problems with your data ? . I don't think the mt colum should contain boolean values... (cf. screeshot); Please correct me if i am wrong, and thank you in advance for your help. ![Screenshot from 2021-12-13 17-17-56](https://user-images.githubusercontent.com/45742503/145848639-6d7c6ee6-a38f-4c48-b38a-c8339984e360.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1259#issuecomment-992636183:168,error,error,168,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259#issuecomment-992636183,1,['error'],['error']
Availability,"HI, I tried to do what you suggested but I am getting an error saying `ValueError: only one regex group is supported with Index`.; I have multiple h5ad files with varying n_obs × n_vars. Here is my code:; ```adatas = [an.read_h5ad(filename) for filename in filenames]; batch_names = []; for i in range(len(adatas)):; adatas[i].var_names_make_unique(); batch_names.append(filenames[i].split('.')[0]); print(i,adatas[i]). adata = adatas[0].concatenate(adatas[1:],; batch_key = 'ID',; uns_merge=""unique"",; index_unique=None,; batch_categories=batch_names); ``` . and this produces the above error. Can anyone help?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/702#issuecomment-1431464728:57,error,error,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/702#issuecomment-1431464728,2,['error'],['error']
Availability,"HI, I tried to do what you suggested but I am getting an error saying `ValueError: only one regex group is supported with Index`.; I have multiple h5ad files with varying n_obs × n_vars. Here is my code:; ```adatas = [an.read_h5ad(filename) for filename in filenames]; batch_names = []; for i in range(len(adatas)):; adatas[i].var_names_make_unique(); batch_names.append(filenames[i].split('.')[0]); print(i,adatas[i]). adata = adatas[0].concatenate(adatas[1:],; batch_key = 'ID',; uns_merge=""unique"",; index_unique=None,; batch_categories=batch_names); ```. and this produces the above error. Can anyone help?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/267#issuecomment-1431472348:57,error,error,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/267#issuecomment-1431472348,2,['error'],['error']
Availability,"Ha, no I'm not on the mattermost. ivirshup@gmail.com. Though if you could cut down the dataset to something small and more shareable that would be helpful as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1698#issuecomment-826441704:78,down,down,78,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1698#issuecomment-826441704,1,['down'],['down']
Availability,"Ha, that’s what I meant, that you said it doesn’t make sense. > If multiple genomes are found and the user did not specify one, an error will be thrown. This is because there are no structural assurances the genomes will match to the same samples. I very much agree!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/442#issuecomment-456793309:131,error,error,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442#issuecomment-456793309,1,['error'],['error']
Availability,"Had same problem. It seems it tries to look for all gene names present in the anndata object,; rather than the cell cycle genes that are requested?. I have previously checked that the s_genes and g2m_genes in call; sc.tl.score_genes_cell_cycle(gdata, s_genes=s_found, g2m_genes=g2m_found); are in the data. use_raw=False ; makes it run without error. Error message below. Note that printout of gene names in data at the beginning matches the list of keyErrors it spits out. ```; Gene_names_in_data:; Index(['HES4', 'C1orf159', 'TNFRSF18', 'TNFRSF4', 'ATAD3C', 'PRKCZ',; 'AL365255.1', 'GPR153', 'TNFRSF25', 'DNAJC11',; ...; 'MCF2', 'SPANXA2-OT1', 'AFF2', 'LINC00894', 'MAMLD1', 'PDZD4', 'F8',; 'TMLHE-AS1', 'PRKY', 'UTY'],; dtype='object', length=3658). calculating cell cycle phase; computing score 'S_score'; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-82-30815e6b6381> in <module>; 20 print(gdata.var.index); 21 ; ---> 22 sc.tl.score_genes_cell_cycle(gdata, s_genes=s_found, g2m_genes=g2m_found); 23 ; 24 gdata.obs[""cellcycle""] = gdata.obs[""phase""]. ~/.pyenv/versions/6_tes/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs); 247 ctrl_size = min(len(s_genes), len(g2m_genes)); 248 # add s-score; --> 249 score_genes(adata, gene_list=s_genes, score_name='S_score', ctrl_size=ctrl_size, **kwargs); 250 # add g2m-score; 251 score_genes(adata, gene_list=g2m_genes, score_name='G2M_score', ctrl_size=ctrl_size, **kwargs). ~/.pyenv/versions/6_tes/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw); 128 _adata = adata.raw if use_raw else adata; 129 ; --> 130 _adata_subset = _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata; 131 if issparse(_adata_subset.X):; 132 obs_avg = pd.Series(. ~/.pyenv/version",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1599#issuecomment-767782350:344,error,error,344,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1599#issuecomment-767782350,2,"['Error', 'error']","['Error', 'error']"
Availability,"Had this issue again recently using python 3.7, and the solution above wasn't enough to solve it. Turns out I also needed to download the tables .whl file: `pip install .\h5py-2.10.0-cp37-cp37m-win_amd64.whl .\tables-3.6.1-cp37-cp37m-win_amd64.whl numpy==1.20.0 --user --force-reinstall`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-954032488:125,down,download,125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-954032488,1,['down'],['download']
Availability,"Hah, I've gotten much better at numba since I wrote this function. I figured out I can just get the core part to work on floats and don't have to worry about casting between types. Makes this a much easier decision. Now floats aren't converted to integers in the first place. > We should also take care not to downcast more incompatible types: int32 can be expressed as float64, but not in float32. int64 has to stay int64. I think we can be a little flexible on this, and just generally follow numpy promotion rules (except for when they're bad).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/865#issuecomment-558449713:310,down,downcast,310,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/865#issuecomment-558449713,1,['down'],['downcast']
Availability,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once?. -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold; * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function?. > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-758355448:1055,avail,available,1055,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-758355448,1,['avail'],['available']
Availability,Has this error been fixed? Facing the same issue for scanpy version 1.7.2,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1579#issuecomment-876093110:9,error,error,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1579#issuecomment-876093110,1,['error'],['error']
Availability,"Have you rebooted the python after updating anndata? Can you paste the exact error you're seeing? Are you allowed to share the object you're having trouble loading?. OP's error is bizarre, e.g. the last part seems to be pointing to an empty line. Like the package was updated but the python was not restarted. I can't recreate the exact one he's seeing, but I've managed to get other disjoint errors along those lines by updating anndata to 0.8.0 in a second terminal while the python in question is still running.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1450229185:9,reboot,rebooted,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1450229185,4,"['error', 'reboot']","['error', 'errors', 'rebooted']"
Availability,Hello ; I did what you told me .. and I got this error. I changed the version of those . ![image](https://user-images.githubusercontent.com/48261734/65530250-302dbd80-debd-11e9-8026-761cd8571849.png). **matplotlib==3.1.1**. ![image](https://user-images.githubusercontent.com/48261734/65530196-17250c80-debd-11e9-8c19-986293e57d92.png),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/852#issuecomment-534634792:49,error,error,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/852#issuecomment-534634792,1,['error'],['error']
Availability,"Hello @Zethson ; Thanks for the response.; I read the paper. I understand that using the raw data to calculate the maker genes of clusters is an appropriate way, but the raw data was not regressed out with mitochondrial genes, gene counts, cell cycle scores...So there will be so many mito genes ranked on the top of the marker gene list. What shall we do with these mito genes?. In Seurat, they did every downstream analysis and plotting by using the log-transformed and scaled data (see below, the scaled dots in Seurat violin plot). Scanpy draws all plots by setting `use_raw=True`. I'm wondering which method is better?; ![image](https://user-images.githubusercontent.com/75048821/149460182-c5c11295-ca78-4bfe-aa8b-d13bade4b21f.png). Thanks!; Best,; YJ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2029#issuecomment-1012803791:406,down,downstream,406,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2029#issuecomment-1012803791,1,['down'],['downstream']
Availability,"Hello @davidhbrann ,; Sorry for the late response.; I tried again without typing the `--user` in the Anaconda Powershell. Please see below. Step1: install without force. Didn't work. Proceed to Step2.; ```python; (base) C:\WINDOWS\system32>conda activate Python38; (Python38) C:\WINDOWS\system32>pip install scikit-misc; Requirement already satisfied: scikit-misc in c:\users\park_lab\appdata\roaming\python\python38\site-packages (0.1.4); Requirement already satisfied: numpy in c:\users\park_lab\anaconda3\envs\python38\lib\site-packages (from scikit-misc) (1.20.3); ```; Step2: force install.; ```python; (Python38) C:\WINDOWS\system32>pip install scikit-misc --force; Collecting scikit-misc; Using cached scikit_misc-0.1.4-cp38-cp38-win_amd64.whl (142 kB); Collecting numpy; Downloading numpy-1.21.5-cp38-cp38-win_amd64.whl (14.0 MB); |████████████████████████████████| 14.0 MB 3.3 MB/s; Installing collected packages: numpy, scikit-misc; Attempting uninstall: numpy; Found existing installation: numpy 1.20.3; Uninstalling numpy-1.20.3:; Successfully uninstalled numpy-1.20.3; ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\Users\\Park_Lab\\anaconda3\\envs\\Python38\\Lib\\site-packages\\~umpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll'; Consider using the `--user` option or check the permissions.; ```; Step3: same errors.; ```python; sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3'); sc.pl.highly_variable_genes(adata); ImportError Traceback (most recent call last); ~\anaconda3\envs\Python38\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 52 try:; ---> 53 from skmisc.loess import loess; 54 except ImportError:. ~\AppData\Roaming\Python\Python38\site-packages\skmisc\loess\__init__.py in <module>; 50 """"""; ---> 51 from ._loess import (loess, loess_model, loess_i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342:779,Down,Downloading,779,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342,1,['Down'],['Downloading']
Availability,"Hello @ivirshup , I met the errors. ; ```python; from hashlib import sha256; import anndata as ad; from sklearn.decomposition import PCA. adata = ad.read_h5ad(""C:/Users/Park_Lab/Documents/PC1.h5ad""); print(sha256(adata.X).hexdigest()). pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0). print(sha256(pca.fit_transform(adata.X)).hexdigest()). ValueError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_3908/912381655.py in <module>; 8 pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0); 9 ; ---> 10 print(sha256(pca.fit_transform(adata.X)).hexdigest()). ValueError: ndarray is not C-contiguous; ```; change to this, same error.; ```python; from hashlib import sha256; import anndata as ad; from sklearn.decomposition import PCA. adata = ad.read_h5ad(""C:/Users/Park_Lab/Documents/PC1.h5ad""); print(sha256(adata.X).hexdigest()). pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0); a=adata.X.copy(order='C'). print(sha256(pca.fit_transform(a)).hexdigest()). ValueError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_3908/1058352035.py in <module>; 8 pca = PCA(n_components=50, svd_solver=""arpack"", random_state=0); 9 a=adata.X.copy(order='C'); ---> 10 print(sha256(pca.fit_transform(a)).hexdigest()). ValueError: ndarray is not C-contiguous",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2114#issuecomment-1021455251:28,error,errors,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1021455251,2,['error'],"['error', 'errors']"
Availability,"Hello @ivirshup ,; Can you upzip these files? Please download all 7 files (.zip and .z01-.z06), and use winzip, winrar, 7-zip or bandizip to unzip the Downloads.zip file. It includes three h5ad files. I also share these three h5ad files into your gmail. I use `adata.write('C:/Users/Park_Lab/Documents/PC1.h5ad', compression='gzip')` to write these files.; And use `adata = sc.read('C:/Users/Park_Lab/Documents/PC1.h5ad')` to read these files. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2114#issuecomment-1020616654:53,down,download,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114#issuecomment-1020616654,2,"['Down', 'down']","['Downloads', 'download']"
Availability,"Hello @ivirshup thanks for this!. Quick question (still very new to python). Upon following your suggestion I get this error:; AttributeError: module 'scanpy.api.tl' has no attribute '_utils'. I then proceeded to install utils (pip install utils), and then; import utils. But still doesn't work. I assume it's because I'm not loading it correctly into the environment for scanpy to use but I don't know how?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/769#issuecomment-519061562:119,error,error,119,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769#issuecomment-519061562,1,['error'],['error']
Availability,"Hello again, some months later. Unfortunately I haven’t used scanpy for a while and now I’m back I found that only two flavors are available for Louvain processing, `igraph` and `vtraag`. The latter allows for resolution parameter but relies on `python-louvain`, right? the reason for my “but” is that I’m having issues with that module on OSX, which I understand it is not a specific scanpy issue. I’ll ask again: what’s wrong with `networkx` and `community` modules? I’m asking because flavor `taynaud` is no more available",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/97#issuecomment-440373090:131,avail,available,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/97#issuecomment-440373090,2,['avail'],['available']
Availability,"Hello! I also have been running into issues when trying to use the `gene_symbols` parameter with the `sc.pl.dotplot()` function despite the column with the proper `gene_symbols` being in my `adata.var` Data Frame. . ```; $ adata.var.columns; $ sc.pl.dotplot(adata, marker_genes, 'clusters', dendrogram=True, gene_symbols='alternate_gene_symbols'). ==============================================================================. Index(['gene_symbols', 'feature_types', 'n_cells', 'highly_variable', 'means',; 'dispersions', 'dispersions_norm', 'mean', 'std',; 'alternate_gene_symbols'],; dtype='object'). ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); File ~/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621, in Index.get_loc(self, key, method, tolerance); 3620 try:; -> 3621 return self._engine.get_loc(casted_key); 3622 except KeyError as err:. File ~/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/_libs/index.pyx:136, in pandas._libs.index.IndexEngine.get_loc(). File ~/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/_libs/index.pyx:163, in pandas._libs.index.IndexEngine.get_loc(). File pandas/_libs/hashtable_class_helper.pxi:5198, in pandas._libs.hashtable.PyObjectHashTable.get_item(). File pandas/_libs/hashtable_class_helper.pxi:5206, in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'alternate_gene_symbols'; ... ```. When I tried setting `adata.var['gene_symbols'] = adata.var['alternate_gene_symbols']` and trying to generate a `dotplot` with a random gene present in `alternate_gene_symbols`, I ran into the following error: . ```; ...; KeyError: ""Could not find keys '['KH.C1.159.']' in columns of `adata.obs` or in adata.raw.var['gene_symbols'].""; ```. It seems that `sc.pl.dotplot()` is expecting `gene_symbols` that are present in the `adata.raw.var` Data Frame versus the `adata.var` Data Frame. Is this the expected behavior for this ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1636#issuecomment-1284430963:853,toler,tolerance,853,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1636#issuecomment-1284430963,1,['toler'],['tolerance']
Availability,Hello!. Hoping to reopen this discussion as I've just encountered the same error whilst trying to do some label transfer via `scArches`. My reference object is [AIDA](https://data.humancellatlas.org/explore/projects/f0f89c14-7460-4bab-9d42-22228a91f185) PBMCs and my query data object is a combined object from [here](https://www.ncbi.nlm.nih.gov/bioproject/PRJNA605083) and [here](https://ngdc.cncb.ac.cn/bioproject/browse/PRJCA003616). **Versions**; scanpy v1.9.3; scarches v0.5.9; anndata v0.9.2 ; numpy v1.24.4; pandas v2.0.3 ; scvi-tools v1.0.3,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2034#issuecomment-1678915525:75,error,error,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2034#issuecomment-1678915525,1,['error'],['error']
Availability,"Hello, ; I have run this command again in the fresh conda environment. Again I get the same error as before. AttributeError Traceback (most recent call last); c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\sinfo\main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 194 try:; --> 195 mod_version = _find_version(mod.__version__); 196 except AttributeError:. AttributeError: module 'importlib_metadata' has no attribute '__version__'. During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last); <ipython-input-3-c71c26e11b3b> in <module>; ----> 1 sc.logging.print_versions(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\logging.py in print_versions(file); 159 try:; 160 buf = sys.stdout = io.StringIO(); --> 161 sinfo(dependencies=True); 162 finally:; 163 sys.stdout = stdout. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\sinfo\main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 196 except AttributeError:; 197 try:; --> 198 mod_version = _find_version(mod.version); 199 except AttributeError:; 200 try:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\sinfo\main.py in _find_version(mod_version_attr); 40 return joined_tuple; 41 elif callable(mod_version_attr):; ---> 42 return mod_version_attr(); 43 else:; 44 # print(f'Does not support module version of type {type(mod_ver_attr)}'). TypeError: version() missing 1 required positional argument: 'distribution_name'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1932#issuecomment-883208028:92,error,error,92,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932#issuecomment-883208028,1,['error'],['error']
Availability,"Hello, I am using the folder where I store the raw data for the analysis. There is no error message when I run the command but it does not generate any file or object with this name or any name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1795#issuecomment-817682376:86,error,error,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795#issuecomment-817682376,1,['error'],['error']
Availability,"Hello, I get the same error when importing scanpy on 7bridges. ```pytb; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); /tmp/ipykernel_109/912249142.py in <module>; ----> 1 import scanpy as sc. /opt/conda/lib/python3.9/site-packages/scanpy/__init__.py in <module>; 14 from . import tools as tl; 15 from . import preprocessing as pp; ---> 16 from . import plotting as pl; 17 from . import datasets, logging, queries, external, get, metrics, experimental; 18 . /opt/conda/lib/python3.9/site-packages/scanpy/plotting/__init__.py in <module>; 14 from ._preprocessing import filter_genes_dispersion, highly_variable_genes; 15 ; ---> 16 from ._tools.scatterplots import (; 17 embedding,; 18 pca,. /opt/conda/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in <module>; 8 from matplotlib.colors import Normalize; 9 from matplotlib import pyplot as pl; ---> 10 from matplotlib import rcParams, colormaps; 11 from anndata import AnnData; 12 from typing import Union, Optional, List, Sequence, Iterable, Mapping, Literal. ImportError: cannot import name 'colormaps' from 'matplotlib' (/opt/conda/lib/python3.9/site-packages/matplotlib/__init__.py); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2173#issuecomment-1693404137:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1693404137,1,['error'],['error']
Availability,"Hello, I'm having a bit of trouble with this. I know the issues is closed, but I thought it might be better to continue this discussion rather than start a new one, though I can do that if you prefer. I have an AnnData object `adata` with ensembl ids as `adata.var_name` and mouse gene symbols under the column `adata.var[“gene_name”]`. When I call:; `sc.pl.umap(adata, color=['ENSMUSG00000074637'])`; It plots no problem. However, when I call:; `sc.pl.umap(adata, color=['Sox2'], gene_symbol='gene_name')`; I get the following error:; ```; Traceback (most recent call last):. File ""<ipython-input-559-05c51c5cc5d6>"", line 1, in <module>; sc.pl.umap(adata, color=['Sox2'], gene_symbol='gene_name'). File ""/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap; return plot_scatter(adata, basis='umap', **kwargs). File ""/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 275, in plot_scatter; use_raw=use_raw, gene_symbols=gene_symbols). File ""/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 670, in _get_color_values; .format(value_to_plot, adata.obs.columns)). ValueError: The passed `color` Sox2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['timepoint', 'replicate_id', 'n_genes', 'percent_mito', 'n_counts',; 'louvain'],; dtype='object'); ```; Inspecting adata.var[""gene_name""] give:; ```; index; ENSMUSG00000002459 Rgs20; ENSMUSG00000033740 St18; ENSMUSG00000067879 3110035E14Rik; ENSMUSG00000025912 Mybl1; ENSMUSG00000016918 Sulf1; ENSMUSG00000025938 Slco5a1; ENSMUSG00000025930 Msc; ENSMUSG00000025921 Rdh10; ENSMUSG00000025777 Gdap1; ENSMUSG00000025776 Crispld1; ENSMUSG00000025927 Tfap2b; ENSMUSG00000025931 Paqr8; ENSMUSG00000026158 Ogfrl1; ...; ```; I'm not sure what I'm doing wrong here. I can do just about anything using the ensembl ids, but I am having a lot of trouble using the gene symbols. I would like to be abl",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/455#issuecomment-472756442:528,error,error,528,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-472756442,1,['error'],['error']
Availability,"Hello,. I am having a similar issue with `read_10x_mtx`, except my error is showing `Key Error: 1` and it is from 10X data we produced ourselves, do doesn't involve a GEO incompabitibility. Error below:. ```. >>> juno = sc.read_10x_mtx(path = ""../../Data/juno_influenza_pilot/hash_t_cells/umi_count""); Traceback (most recent call last):; File ""/home/daniel/miniconda/envs/scvi/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 3361, in get_loc; return self._engine.get_loc(casted_key); File ""pandas/_libs/index.pyx"", line 76, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/index.pyx"", line 108, in pandas._libs.index.IndexEngine.get_loc; File ""pandas/_libs/hashtable_class_helper.pxi"", line 2131, in pandas._libs.hashtable.Int64HashTable.get_item; File ""pandas/_libs/hashtable_class_helper.pxi"", line 2140, in pandas._libs.hashtable.Int64HashTable.get_item; KeyError: 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/daniel/miniconda/envs/scvi/lib/python3.8/site-packages/scanpy/readwrite.py"", line 481, in read_10x_mtx; adata = read(; File ""/home/daniel/miniconda/envs/scvi/lib/python3.8/site-packages/scanpy/readwrite.py"", line 552, in _read_v3_10x_mtx; var_names = genes[1].values; File ""/home/daniel/miniconda/envs/scvi/lib/python3.8/site-packages/pandas/core/frame.py"", line 3455, in __getitem__; indexer = self.columns.get_loc(key); File ""/home/daniel/miniconda/envs/scvi/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 3363, in get_loc; raise KeyError(key) from err; KeyError: 1. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1916#issuecomment-927497782:67,error,error,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916#issuecomment-927497782,3,"['Error', 'error']","['Error', 'error']"
Availability,"Hello,. I am having problems with reading in multiple h5 files using the code snipped that was posted by falexwolf. I am doing:; ```; filenames = ['./a.h5', './b.h5', './c.h5', './d.h5']; adatas = [sc.read_10x_h5(filename, gex_only = True) for filename in filenames]; adata = adatas[0].concatenate(adatas[1:], batch_key='gene_ids', batch_categories=filenames); ```. With or without the batch_key and batch_categories arguments I get the same error:; ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-20-e23ba2ca6e37> in <module>; 1 filenames = ['./a.h5', './b.h5', './c.h5', './d.h5']; 2 adatas = [sc.read_10x_h5(filename, gex_only = True) for filename in filenames]; ----> 3 adata = adatas[0].concatenate(adatas[1:], batch_key='gene_ids'). ~/anaconda3/lib/python3.7/site-packages/anndata/_core/anndata.py in concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas); 1764 fill_value=fill_value,; 1765 index_unique=index_unique,; -> 1766 pairwise=False,; 1767 ); 1768 . ~/anaconda3/lib/python3.7/site-packages/anndata/_core/merge.py in concat(adatas, axis, join, merge, uns_merge, label, keys, index_unique, fill_value, pairwise); 817 # Annotation for other axis; 818 alt_annot = merge_dataframes(; --> 819 [getattr(a, alt_dim) for a in adatas], alt_indices, merge; 820 ); 821 . ~/anaconda3/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy); 529 dfs: Iterable[pd.DataFrame], new_index, merge_strategy=merge_unique; 530 ) -> pd.DataFrame:; --> 531 dfs = [df.reindex(index=new_index) for df in dfs]; 532 # New dataframe with all shared data; 533 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/anaconda3/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0); 529 dfs: Iterable[pd.DataFrame], new_index, merge_strategy=merge_unique; 530 ) -> pd.DataFrame:; --> 531 dfs = [df.reindex(inde",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683:442,error,error,442,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683,1,['error'],['error']
Availability,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) ; running Louvain clustering; using the ""louvain"" package of Traag (2017); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain; louvain.set_rng_seed(random_state); AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version?. thanks for your help,; Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1191#issuecomment-628933774:56,error,error,56,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191#issuecomment-628933774,1,['error'],['error']
Availability,"Hello,. I just type ""import scanpy"", and it still shows the error message. . Here is my code. . ```py; import scanpy; ```. Here is what the computer showed after I ran this code:. ```pytb; AttributeError Traceback (most recent call last); <ipython-input-2-135279188441> in <module>; ----> 1 import scanpy. ~/Documents/scanpy/scanpy/scanpy/__init__.py in <module>; 34 # the actual API; 35 from ._settings import settings, Verbosity # start with settings as several tools are using it; ---> 36 from . import tools as tl; 37 from . import preprocessing as pp; 38 from . import plotting as pl. ~/Documents/scanpy/scanpy/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~/Documents/scanpy/scanpy/scanpy/tools/_sim.py in <module>; 23 ; 24 from .. import _utils; ---> 25 from .. import readwrite; 26 from .._settings import settings; 27 from .. import logging as logg. ~/Documents/scanpy/scanpy/scanpy/readwrite.py in <module>; 7 import numpy as np; 8 import pandas as pd; ----> 9 import tables; 10 import anndata; 11 from anndata import (. ~/anaconda3/lib/python3.6/site-packages/tables/__init__.py in <module>; 91 ; 92 # Necessary imports to get versions stored on the cython extension; ---> 93 from .utilsextension import (; 94 get_pytables_version, get_hdf5_version, blosc_compressor_list,; 95 blosc_compcode_to_compname_ as blosc_compcode_to_compname,. tables/utilsextension.pyx in init tables.utilsextension(). ~/anaconda3/lib/python3.6/site-packages/tables/tables/__init__.py in <module>; 122 from .flavor import restrict_flavors; 123 from .description import *; --> 124 from .filters import Filters; 125 ; 126 # Import the user classes from the proper modules. ~/anaconda3/lib/python3.6/site-packages/tables/tables/filters.py in <module>; 27 from tables.req_versions import min_blosc_bitshuffle_version; 28 ;",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/853#issuecomment-539798622:60,error,error,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/853#issuecomment-539798622,1,['error'],['error']
Availability,"Hello,. Yes that is exactly what @flying-sheep mentioned. Instead of having a dot plot of gene expression, we would have the option of a surface plot with smoothed gene expression values.; I will try to run this on a pubicly available Visium dataset (mentioned in one of the scanpy tutorials) to show the outcome. On the other hand, it is not necessary to limit this option to regular grids (although in Visium datasets, it is regular). In this way, the function can be used in a more general case.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1287#issuecomment-706185841:225,avail,available,225,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1287#issuecomment-706185841,1,['avail'],['available']
Availability,"Hello,. my issue is similar to the ones above, so I hope you can help me with that. I tried to read in some sample data from a liver cell database ([Liver Cell Atlas](https://www.livercellatlas.org/download.php)) with the function sc.read_10x_mtx. When I pass in the data just like that, I get a KeyError: 1. ; I adjusted the file to have two more columns (with numbers 1:x as gene IDs and a feature types column with ""Gene Expression"" in all rows) , but then I get the following Error: ValueError: Length of passed value for var_names is 31054, but this AnnData has shape: (389056, 31053). I think this is because the function treats the column names as values, but I don’t know why. When I look at the features file with pandas, it is displayed correctly. Any suggestions? Thanks a lot in advance!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1916#issuecomment-1551477163:198,down,download,198,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916#issuecomment-1551477163,2,"['Error', 'down']","['Error', 'download']"
Availability,"Hello,; I am also getting the ""'tuple' object has no attribute 'tocsr'"" error and appreciate your help with that. I am using the latest scanpy and numpy:. scanpy==1.4.4.post1; numpy==1.18.2. The full command and error:; ```; adata_pp = adata.copy(); sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after=1e6); sc.pp.log1p(adata_pp); sc.pp.pca(adata_pp, n_comps=15); sc.pp.neighbors(adata_pp); sc.tl.louvain(adata_pp, key_added='groups', resolution=0.5); ```. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-13-50ed2ff29926> in <module>; 4 sc.pp.log1p(adata_pp); 5 sc.pp.pca(adata_pp, n_comps=15); ----> 6 sc.pp.neighbors(adata_pp); 7 sc.tl.louvain(adata_pp, key_added='groups', resolution=0.5). /Anaconda_python3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy); 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,; 94 method=method, metric=metric, metric_kwds=metric_kwds,; ---> 95 random_state=random_state,; 96 ); 97 adata.uns['neighbors'] = {}. Anaconda_python3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 681 knn_distances,; 682 self._adata.shape[0],; --> 683 self.n_neighbors,; 684 ); 685 # overwrite the umap connectivities if method is 'gauss'. /Anaconda_python3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 322 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors); 323 ; --> 324 return distances, connectivities.tocsr(); 325 ; 326 . AttributeError: 'tuple' object has no attribute 'tocsr'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1154#issuecomment-611248366:72,error,error,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154#issuecomment-611248366,2,['error'],['error']
Availability,"Hello,; I am now facing a problem of failure in computing neighbours when using scanpy or scvelo; when I tried to use the . `sc.pp.neighbors(labelled, n_neighbors=5, n_pcs=4)`; or; `scv.pp.moments(raw, n_pcs=30, n_neighbors=30)`; it will always reports that. ```pytb; `computing neighbors; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs); 743 try:; --> 744 yield; 745 except NumbaError as e:. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/lowering.py in lower_block(self, block); 229 loc=self.loc, errcls_=defaulterrcls):; --> 230 self.lower_inst(inst); 231 self.post_block(block). ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/lowering.py in lower_inst(self, inst); 327 val = self.lower_assign(ty, inst); --> 328 self.storevar(val, inst.target.name); 329 . ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/lowering.py in storevar(self, value, name); 1277 name=name); -> 1278 raise AssertionError(msg); 1279 . AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last); <ipython-input-37-db298150880d> in <module>; ----> 1 scv.pp.moments(raw, n_pcs=30, n_neighbors=30). ~/.conda/envs/rpy/lib/python3.9/site-packages/scvelo/preprocessing/moments.py in moments(data, n_neighbors, n_pcs, mode, method, use_rep, use_highly_variable, copy); 62 ; 63 if n_neighbors is not None and n_neighbors > get_n_neighs(adata):; ---> 64 neighbors(; 65 adata,; 66 n_neighbors=n_neighbors,. ~/.conda/envs/rpy/lib/python3.9/site-packages/scvelo/preprocessing/neighbors.py in neighbors(adata, n_neighbors, n_pcs, use_rep, use_highly_variable, knn, random_state, method, metric, metric_kwds, num_threads, copy); 161 warnings.simplefilter(""ignore""); 162 neighbors = Neighbors(adata",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796:37,failure,failure,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796,2,"['error', 'failure']","['errors', 'failure']"
Availability,"Hello,; I am trying to use the wrapper class and I am getting error; RRuntimeError: Error in `[.data.frame`(meta.data, , ii, drop = FALSE) : ; undefined columns selected; Could you please suggest me what should I do; Its on line ro.r('seurat_obj = as.Seurat(adata, counts=""X"",data=NULL)'); Thank you",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-982525338:62,error,error,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-982525338,2,"['Error', 'error']","['Error', 'error']"
Availability,"Hello,; I've gotten scanpy working on my local computer, but for memory reasons I need to move to our server (linux). I am running into the same errors as above - any advice is appreciated!. Skipping optional fixer: buffer; Skipping optional fixer: idioms; Skipping optional fixer: set_literal; Skipping optional fixer: ws_comma; running build_ext; Cannot find the C core of igraph on this system using pkg-config.; We will now try to download and compile the C core from scratch.; Version number of the C core: 0.7.1.post6; We will also try: 0.7.1; ; Version 0.7.1.post6 of the C core of igraph is not found among the nightly builds.; Use the --c-core-version switch to try a different version.; ; Could not download and compile the C core of igraph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/138#issuecomment-518220318:145,error,errors,145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138#issuecomment-518220318,3,"['down', 'error']","['download', 'errors']"
Availability,"Hello,; This command (sc.logging.print_versions()) gives me the error pasted below:; AttributeError Traceback (most recent call last); c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\sinfo\main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 194 try:; --> 195 mod_version = _find_version(mod.__version__); 196 except AttributeError:. AttributeError: module 'importlib_metadata' has no attribute '__version__'. During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last); <ipython-input-19-c71c26e11b3b> in <module>; ----> 1 sc.logging.print_versions(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\logging.py in print_versions(file); 159 try:; 160 buf = sys.stdout = io.StringIO(); --> 161 sinfo(dependencies=True); 162 finally:; 163 sys.stdout = stdout. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\sinfo\main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 196 except AttributeError:; 197 try:; --> 198 mod_version = _find_version(mod.version); 199 except AttributeError:; 200 try:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\sinfo\main.py in _find_version(mod_version_attr); 40 return joined_tuple; 41 elif callable(mod_version_attr):; ---> 42 return mod_version_attr(); 43 else:; 44 # print(f'Does not support module version of type {type(mod_ver_attr)}'). TypeError: version() missing 1 required positional argument: 'distribution_name'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1932#issuecomment-874660246:64,error,error,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932#issuecomment-874660246,1,['error'],['error']
Availability,"Hello,I am having the same problem. ; When I run this:; ```python; from umap import UMAP; ```; It occurs this error. ```python; TypeError Traceback (most recent call last); File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\errors.py:823, in new_error_context(fmt_, *args, **kwargs); [822](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=821) try:; --> [823](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=822) yield; [824](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=823) except NumbaError as e:. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\lowering.py:293, in BaseLower.lower_block(self, block); [291](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=290) with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; [292](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=291) loc=self.loc, errcls_=defaulterrcls):; --> [293](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=292) self.lower_inst(inst); [294](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=293) self.post_block(block). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\lowering.py:438, in Lower.lower_inst(self, inst); [437](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=436) ty = self.typeof(inst.target.name); --> [438](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=437) val = self.lower_assign(ty, inst); [439](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/lowering.py?line=438) argidx = None. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\l",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:110,error,error,110,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659,5,['error'],"['error', 'errors']"
Availability,"Here is the summary:; * `_set_default_colors_for_categorical_obs()` moved from scatterplots to _utils. No modifications; * `_set_colors_for_categorical_obs()` moved from scatterplots to _utils. No modifications; * `_validate_palette()` function added, extracting the relevant code from `scatterplots.py:_get_color_values()`; * `adjust_palette()` was removed as this functionality is replicated to some extent by `_set_default_colors_for_categorical_obs()`; * `add_colors_for_categorical_sample_annotation()` was simplified by using the above functions. FYI: the error from `sc.pl.paga` that I had was caused because the expected output of `adjust_palette()` was `Cycler` but the function actually returned the original type of `palette` which could be `ListedColorMap`, `cabc.Sequence` or `Cycler`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/869#issuecomment-540517150:562,error,error,562,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/869#issuecomment-540517150,1,['error'],['error']
Availability,"Here's [test code](https://gist.github.com/jorvis/da877d89fd159b2fb7dfba26705f7ceb) and my output is:. ```pytb; Initial shape: 737280x28002; After min_genes: 5128x28002; After max_genes: 1431x28002; Traceback (most recent call last):; File ""/tmp/test_cell_and_gene_filter.py"", line 22, in <module>; sc.pp.filter_genes(adata, min_cells=3); File ""/home/jorvis/git/scanpy/scanpy/preprocessing/simple.py"", line 152, in filter_genes; adata.var['n_cells'] = number; File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2519, in __setitem__; self._set_item(key, value); File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2585, in _set_item; value = self._sanitize_column(key, value); File ""/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py"", line 2760, in _sanitize_column; value = _sanitize_index(value, self.index, copy=False); File ""/usr/local/lib/python3.6/dist-packages/pandas/core/series.py"", line 3121, in _sanitize_index; raise ValueError('Length of values does not match length of ' 'index'); ValueError: Length of values does not match length of index; ```. Note that this same error displays on both of the following lines:. ```python; sc.pp.filter_genes(adata, min_cells=3); sc.pp.filter_genes(adata, max_cells=1000); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-364468317:1133,error,error,1133,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-364468317,1,['error'],['error']
Availability,"Here's a link to the docs [https://scanpy.readthedocs.io/](), it's also available at the top of the github repo. EDIT: Whoops, posted some wrong info about how 10x pre v3 datasets are read before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/587#issuecomment-480108879:72,avail,available,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-480108879,1,['avail'],['available']
Availability,"Here's some initial distribution plots for comparison:. Legend: ; - red lines are 0.5% and 99.5% quantiles, a trick used in some cytof papers to deal with extreme outliers (believed to be technical artifacts); here, I simply use it to move the bulk of the data in visible range for the first two plots; while the values are merely a heuristic, the spirit of it follows nonparametric statistics so is pretty reliable in practice. ### raw (ADT counts):; ![image](https://user-images.githubusercontent.com/20694664/83345454-4956fb80-a2e1-11ea-8ae7-e13dfcc10cac.png). ### geometric mean (as used in Issac's notebook); ![image](https://user-images.githubusercontent.com/20694664/83345468-6f7c9b80-a2e1-11ea-8a42-acad50bfb66b.png). seems to only changes the scale, not the shape, so unless I made an error in implementation... it's probably not useful. ### simple log(n+1) (as used in RNAseq); ![image](https://user-images.githubusercontent.com/20694664/83345487-a05cd080-a2e1-11ea-858e-4d98621d12e6.png). can suffer from discretization at low values... note: even though Seurat/Scanpy/Loupe all use different bases, the log base doesn't really matter; it just changes the scale, not the shape/distinguishing power. ### hyperbolic arcsin (as used in CyTOF); ![image](https://user-images.githubusercontent.com/20694664/83345476-81f6d500-a2e1-11ea-8f68-ddff22ffe853.png). not as noisy as log at low values, and doesn't assert that zeros have to be Laplace smoothed with a pseudocount of +1. ### biexponential family (as used in flow cytometry); ![image](https://user-images.githubusercontent.com/20694664/83345554-6fc96680-a2e2-11ea-8112-3bdc09260e63.png). best smoothing so far in the low counts, because that's what it was designed to do. in this case, it is the newest of this family: `vlog(alpha=0, beta=12, xmax=70000, zmax=1)`; - https://doi.org/10.1002/cyto.a.23017; - https://doi.org/10.1002/cyto.a.22030; - https://doi.org/10.1002/cyto.a.20258. ### centered log ratio (as used in CITEseq paper); ![im",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1117#issuecomment-636429530:407,reliab,reliable,407,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117#issuecomment-636429530,2,"['error', 'reliab']","['error', 'reliable']"
Availability,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this!. However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values.; ```; log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2); ```; In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. ; ```; log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))); ```; Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/519#issuecomment-471321720:713,down,down-weighted,713,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-471321720,2,"['down', 'robust']","['down-weighted', 'robust']"
Availability,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-244-764977f87ce6> in <module>; ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'); 2 sc.pp.pca(ad_sub); 3 sc.pp.neighbors(ad_sub); 4 sc.tl.umap(ad_sub); 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key); 413 ; 414 if flavor == 'seurat_v3':; --> 415 return _highly_variable_genes_seurat_v3(; 416 adata,; 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace); 82 x = np.log10(mean[not_const]); 83 model = loess(x, y, span=span, degree=2); ---> 84 model.fit(); 85 estimat_var[not_const] = model.outputs.fitted_values; 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'; ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1182#issuecomment-708677512:84,error,error,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182#issuecomment-708677512,2,['error'],['error']
Availability,"Hey @chris-rands,. This is a really interesting topic. Sorry in advance for the wordy reply... You are absolutely correct that log transformation removes the perfect comparison of relative expression values that mean normalization provides. Aside from CPM normalization (as provided by `sc.pp.normalize_total()`) not being a good normalization technique anyway (this is argued by any more advanced normalization methods paper, e.g., the [scran pooling paper](http://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-0947-7)), there are a couple of things to consider here:; 1. Do we even want relative expression counts?; 2. What assumptions do downstream methods have on the distribution of expression values. For the first question: relative gene expression values ignore differences in cell sizes/number of molecules in the cell. There are some molecules whose numbers scale with the size of the cell, and others that don't (e.g., many housekeeping genes). Choosing relative over absolute expression values to compare gene expression across cells would be helpful to compare expression of those genes that scale with size, but not the others.... so there's not really a perfect answer here. Thus, removing all effects of total counts may not be the desirable outcome. Secondly, many downstream methods assume normally distributed expression data (e.g., DE methods like: t-tests, limma, MAST, or several batch correction/data integration methods). Log transformation is used as a variance stabilization to approximate a normal distribution (quite often poorly, but better than without). This leads to many methods performing better with log transformation. IMO, the ideal approach is probably something like scVI, GLMPCA, or scTransform, where you fit a model directly to the count data and use the residuals to describe the data. This would address both steps of normalization and variance stabilization at the same time. If we have a good model to describe the data, the residuals should",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643:655,down,downstream,655,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643,1,['down'],['downstream']
Availability,"Hey @falexwolf, thanks for your note. I apologize for the late reply - I was away at a conference and had little time to work on this. ; I agree that this is a cleaner way of doing this and will be more robust to outliers, even if it's at the expense of the approximation. Like @LuckyMD mentioned, this function is generally used for more basic differential testing, so further exploration of differential expression can rely on more complicated downstream analysis. Out of curiosity, I'll also calculate what the error of the approximation is, just to have an idea. I'm a little limited in bandwidth at the moment, but this is an easy change that I should be able to implement this week. Sorry for the delay - I'll submit the changes soon!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/519#issuecomment-474084027:203,robust,robust,203,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-474084027,3,"['down', 'error', 'robust']","['downstream', 'error', 'robust']"
Availability,"Hey @giovp & @ivirshup,; hope you had a good start into 2022! I was getting a twitter request recently asking about when this PR will be merged - are there any news on the timeline yet?. For the PR itself I made suggestions for the few remaining points (see my previous post) - just ping me here if you have feedback on that or if there is anything else to do!. Looking forward to wrap this up :); Best, Jan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-1030169133:283,ping,ping,283,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-1030169133,1,['ping'],['ping']
Availability,"Hey @gokceneraslan,. I'm surprised at how you describe the contents of `adata.var['highly_variable']` when `batch_key` is set. I wrote a function that does pretty much exactly the same thing building upon use of `batch_key` for our data integration benchmarking, as I thought this wasn't available in scanpy. I recall looking through the code and thinking this was missing. Maybe we can compare functions for that to see if we're doing exactly the same thing or not?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1032#issuecomment-616820714:288,avail,available,288,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032#issuecomment-616820714,1,['avail'],['available']
Availability,"Hey! Just to chime in, I believe plotting functions also expect categoricals and I've had errors from other functions as well about obs columns not being categorical. I think that was `rank_genes_groups`, but I'm not sure.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1747#issuecomment-800937743:90,error,errors,90,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1747#issuecomment-800937743,1,['error'],['errors']
Availability,Hey!. I think this is probably related to https://github.com/theislab/anndata2ri/issues/63. Maybe try downgrading your `anndata2ri` version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-866769550:102,down,downgrading,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-866769550,1,['down'],['downgrading']
Availability,"Hey!. We do it as they do in Seurat. See [here](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb), available through the [examples page](http://scanpy.readthedocs.io/en/latest/examples.html):; ```; adata = adata[adata.obs['percent_mito'] < 0.05, :]; ```; in Box 8. Does this help you or do you need more?. Best,; lex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/122#issuecomment-381551334:147,avail,available,147,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/122#issuecomment-381551334,1,['avail'],['available']
Availability,"Hey!; > * What methods/ tools?; I am mainly thinking about normalization and data integration methods. For example scran pooling, sctransform, scNorm, Seurat data integration, LIGER... etc. I have most of those already... But anyone is welcome to contribute for anything they regularly use. > * How would you handle R depencies?; So far I've been ignoring this problem and just assuming people have an R environment installed that has the relevant packages. You could just stick a `require(package)` in the function called by `rpy2` and then if would give you an `R` error you can interpret. The plan would be to make this a set of convenience functions, but not a cleanly installable module I guess... I'm not sure how you could get any python setup to install R dependencies for you... > * And (probably hard and definitely not necessary at first) could we use [arrow](https://arrow.apache.org/docs/python/) to speed up data transfer?; This looks interesting... but I don't entirely understand it... you'd have to have a a separate data structure that can move been languages, and be interpreted as an R data structure or `AnnData` depending on where it's used? Most methods are designed to run on a particular class of object. How would this help if you always have to convert to that type of object? So far I've just been using `anndata2ri` to ensure we have an `SCE` object which can be converted to other `R` data structures.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-590143256:567,error,error,567,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-590143256,1,['error'],['error']
Availability,"Hey!; Using the latest verisons of scanpy and anndata, I have tried reproducing this via:; ```; adata = sc.datasets.pbmc3k(); sc.pp.filter_genes(adata, min_counts = 10); sc.pp.filter_cells(adata, min_counts = 10); sc.pp.normalize_per_cell(adata); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, subset=True); adata = adata[:, adata.var[""highly_variable""]]; sc.pp.scale(adata); ```. and I don't get an error. Could you reproduce this error with one of the datasets in `sc.datasets`? That way I could try to reproduce your error. Also, which version of anndata and scanpy are you on?. Other than that, you don't need the line `adata = adata[:, adata.var[""highly_variable""]]` if you use `subset=True` in the `sc.pp.highly_variable_genes()` call.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/738#issuecomment-511205979:451,error,error,451,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/738#issuecomment-511205979,3,['error'],['error']
Availability,"Hey, sorry for being slow here. upon looking into this again, it is the case that `read_10x_mtx` has to make strong assumptions on the files being generated by Cell Ranger. This is also reflected in the filenames this software outputs. Is there a widely used processing pipeline which does not adhere to this file naming?; If yes, scanpy should indeed be able to deal with this;; If no, custom workflows would actually be more reliably dealt with by using a small custom reading script as suggested by @flying-sheep above:. > Hi! That function is for reading the files output by [cellranger’s mex option](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/output/matrices). Your files have been renamed by someone in a way we can’t predict, and you should just adapt the little code needed to read them yourself:; > ; > https://github.com/theislab/scanpy/blob/e6e08e51d63c78581bb9c86fe6e302b80baef623/scanpy/readwrite.py#L324-L341; > ; > Took me 3 minutes:; > ; > ```python; > samples = []; > for sample in range(1, 10):; > s = read(; > path / f'{sample}.matrix.mtx',; > cache=cache,; > cache_compression=cache_compression,; > ).T; > genes = pd.read_csv(path / f'{sample}.genes.tsv', header=None, sep='\t'); > s.var_names = genes[0]; > s.var['gene_symbols'] = genes[1].values; > s.obs_names = pd.read_csv(path / f'{sample}.barcodes.tsv', header=None)[0]; > samples.append(s); > adata = AnnData.concatenate(samples); > ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/882#issuecomment-1759283694:427,reliab,reliably,427,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/882#issuecomment-1759283694,1,['reliab'],['reliably']
Availability,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. ; [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf); [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/519#issuecomment-475983631:122,error,error,122,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-475983631,4,['error'],['error']
Availability,"Hey, thanks for the request. To be able to reproduce and help, it is a big aid for us if you can supply a code sample that we can run: that is, with some dummy data (the datasets scanpy readily supplies are great for that), and the error/unexpected behaviour you get. I think in your case this would be e.g. ```py; import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); adata.obs[""louvain""] = adata.obs[""louvain""].cat.set_categories(new_categories=[""0"", ""1"", ""2"", ""3"", ""4"", ""5"", ""6"", ""7"", ""8"", ""9"", ""10"", ""11""]); sc.pl.violin(adata, keys='n_counts', groupby='louvain'); ```. Yielding; ```; ValueError: The palette dictionary is missing keys: {'11'}; ```. Is that the issue you are facing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3005#issuecomment-2066525588:232,error,error,232,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005#issuecomment-2066525588,1,['error'],['error']
Availability,"Hey,; So I don't understand how I can get around this issue with the wilcoxon test. I'm following the scanpy tutorial and getting this 'ValueError: math domain error'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/566#issuecomment-582366998:160,error,error,160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/566#issuecomment-582366998,1,['error'],['error']
Availability,"Hey,; thanks a lot for raising this @Kiliankleemann! And thanks a lot for showing the Version details, big help here. I'll look into this, for the moment it appears that for the violin plot; - indeed as @JacquesFGD mentioned it seems that using seaborn-0.13.0 raises this error when setting `multi_panel=True`: the plot obtainable from `multi_panel=False` seems to work.; - as @bbimber noted, using seaborn-0.12.2 seems to work, also with the `multi_panel=True` option. For urgent violin plots, either of these two options should produce them. Will get back to this asap.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2680#issuecomment-1762847854:272,error,error,272,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680#issuecomment-1762847854,1,['error'],['error']
Availability,"Hey. I also thought about the intersection but didn't implement it as the default output for two reasons. . 1) it can be too harsh, especially if there is some biological variation between batches. When we sort the genes based on in how many batches they're detected as HVG and on mean normalized dispersion, there is still a chance for the user to catch such ""biological"" genes with a high n_top_genes value. . 2) Output of highly_variable_genes should be consistent regardless of batch_key option. So n_top_genes and mean/dispersion cutoff flavors should still work the same way. I feel like using the intersection directly as the output violates that. However, making `'highly_variable': np.nansum` part available in adata.var is a good idea. Then users can manually make the selection more stringent by selecting genes where this value == nbatches.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/614#issuecomment-485822437:707,avail,available,707,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/614#issuecomment-485822437,1,['avail'],['available']
Availability,"Hi @Celine-075,. constructing the neighborhood graph is not guaranteed to be reproducible; * across different machines; * across different package versions; * with different number of CPU threads available to your session. (see also https://github.com/scverse/scanpy/issues/2014). If all of these things are constant between your two versions, then it's a bug. . Also: are you sure the clustering has actually changed (by comparing the cell barcodes)? Or is it just the UMAP that looks differently, but the clusters are the same?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2956#issuecomment-2020630719:196,avail,available,196,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2956#issuecomment-2020630719,1,['avail'],['available']
Availability,"Hi @FADHLyemen,. You can export the raw count table (before calculating the percentage) into R for downstream analysis using `edgeR`. You can follow the following link to find further information: https://bioconductor.org/books/release/OSCA/multi-sample-comparisons.html#differential-abundance. Regards,; Mikhael",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1831#issuecomment-845906745:99,down,downstream,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1831#issuecomment-845906745,1,['down'],['downstream']
Availability,"Hi @GouQiao - it's been a while since this specific incident so I don't 100% remember / have the code anymore. However, I have run into this problem in general when using AnnData and it's usually resolved by one of two paths:. 1. Check the version of `h5py` that you have installed and perhaps it is too new and an older version resolves the issue. ; 2. Some components of AnnData are not implemented in the function, `.write_h5ad()`. One example that comes to mind is the umap or pca transformer. These objects are not handled well by `.h5py` (at least natively in my experience) and are better off saved independently as dictionaries using `pickle`. That being said, I think there is probably a more robust solution I am not aware of - I know in several instances transformers are able to be saved (e.g., the Scanpy tutorials). . Does this help at all? Happy to be of further assistance if possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1275#issuecomment-996451713:702,robust,robust,702,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275#issuecomment-996451713,1,['robust'],['robust']
Availability,"Hi @JayalalKJ ,; as you also pointed out, this issue is related to an environment in https://github.com/theislab/single-cell-tutorial; It's best if you open an issue there and directly address maintainers of that repo. ; Beside that, we can't really help you in this case because we don't have enough information on the error and also it relates to an external package. We could provide you with more help if you post the complete error log, but pls do so not here but in the other repo.; Hope this is helpful",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1220#issuecomment-702550857:320,error,error,320,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220#issuecomment-702550857,2,['error'],['error']
Availability,"Hi @JonathanShor,. you don't need to create a custom API. One point of Scanpy is to provide convenient access via `anndata` to many single-cell packages around. The only thing needed for that is to provide a very simple interface like [this](https://github.com/theislab/scanpy/blob/master/scanpy/tools/phate.py#L8-L145) or [this](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/mnn_correct.py#L4-L104) or several of the other tools... Simply click on the GitHub links in the Scanpy docs... If your package works reliably, both the restrictions you mention should in principle not prevent adding your package. Of course, in the future, we want all elements of Scanpy to scale to millions of cells, not just the core tools. But for a lot of people, it's right now helpful to have a large number of tools available also for relatively small datasets. The only problem is to avoid cluttering the Scanpy API with virtually any tool there is. Tools in the API should have passed a certain quality check. Doublet detection is a difficult problem. Already last autumn, we played around with @swolock 's tool but didn't end up using it - it was good, but in our situation, it didn't seem to apply (are you eventually going to distribute a package for it @swolock ?). I myself quickly wrote a tool, too, but it didn't work well. Just yesterday, [this](https://www.biorxiv.org/content/early/2018/06/20/352484) appeared. Then there is also [this](https://www.biorxiv.org/content/early/2018/04/04/234872) on ""empty cell detection"". There are more tools out there, I think... What I mean is: computationally detecting doublets is still something where the field has not agreed on a consensus. Just like batch correction. Therefore, I would not add a tool `tl.doublet_detection` or `tl.detect_doublets` to the API at this stage. There are two options. Either we create a `.beta` module of the API for tools that don't even have a preprint and add your tool and similar cases in the future there. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-399367409:532,reliab,reliably,532,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-399367409,2,"['avail', 'reliab']","['available', 'reliably']"
Availability,"Hi @Koncopd ,. The error fixed here [df8bbaf](https://github.com/theislab/scanpy/pull/1248/commits/df8bbaf5ffb58eb37d4b80ef62819f69b8fce023). Thank you!. > Hi, @awnimo , sorry for the delay.; > It seems that this PR breaks test_harmony_timeseries.py. I get; > ; > ```; > E ValueError: 'time_points' column does not contain Categorical data; > ; > ../../external/tl/_harmony_timeseries.py:140: ValueError; > ```; > ; > On master the test works fine.; > Could you check and fix this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1248#issuecomment-703754388:19,error,error,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1248#issuecomment-703754388,1,['error'],['error']
Availability,"Hi @Koncopd, my data are indeed already normalised. @fidelram I generated the data merging a few datasets using ```bbknn```. But when I tried on a single sample, I got the same error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-445151260:177,error,error,177,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-445151260,1,['error'],['error']
Availability,"Hi @LuckyMD ,. Thanks so much for getting back to me this quickly. I just want to clarify that I am not running this analysis with the built-in 10x data set, I have followed the tutorial as seen on the link in the report, which says: ""The data consist in 3k PBMCs from a Healthy Donor and are freely available from 10x Genomics"". I have downloaded the file from the following URL, as seen in the tutorial:. http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz. This is also the same URL found on this link, directly from 10x:. https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k. The 10x summary [here](https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_web_summary.html) mentions LYZ as one of the most differentially expressed genes, yet it is missed by the sample analysis as performed in the Scanpy tutorial. As both use the exact same count matrix as a source, there are two possibilities here as far as I can see: either the thresholds and filtering parameters in the tutorial are inaccurate and miss important marker genes, or there is a bug that drops these genes. My question is which of the following is true. From your answer I would assume it's the former, in which case maybe a disclaimer pointing this out would be helpful in the tutorial page? I think, as it stands, the average user would assume important marker genes such as LYZ would not be missed by even a rough analysis of a PBMC data set. For reference, the [tutorial](https://satijalab.org/seurat/v3.2/pbmc3k_tutorial.html) which the Scanpy one is apparently based on finds LYZ as a very important contributor to the first principal component.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1338#issuecomment-665580053:300,avail,available,300,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338#issuecomment-665580053,2,"['avail', 'down']","['available', 'downloaded']"
Availability,"Hi @LuckyMD - thanks for your reply! Yeah that makes sense. I'm performing these corrections using a subset of highly variable genes, so I guess to ""make up"" for the loss of ""true"" HVGs in the new subclusters of cells I could select a higher number of HVGs to perform the original alignment? As well as maybe using a larger number of components for downstream applications from the low-dimensional embedding outputted by the original alignment. Does that make sense to you?. One more question - when performing differential gene expression analysis, what is your preferred pipeline/method when using aligned datasets? I generally do not perform the correction on the gene expression matrix when aligning, and I think doing DE with corrected matrices is not as common. So maybe other methods that use batch as a covariate would be preferable (e.g. diffxpy or others?) Would really appreciate any suggestions here!. PS. many congratulations on the benchmarking integration paper in Nature Methods - excellent work and very useful resource for the field!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766:349,down,downstream,349,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162#issuecomment-1061085766,1,['down'],['downstream']
Availability,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)?; 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression?; 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. ; 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already?. And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/490#issuecomment-588132560:800,avail,available,800,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490#issuecomment-588132560,1,['avail'],['available']
Availability,"Hi @LuckyMD,. Thank you for your rapid reply!; In mnnCorrect's paper, the authors claimed that ComBat cannot be applied to some single-cell RNA sequencing data, since there are always multiple different cell types in each dataset, how do you think about that? ; Maybe, ComBat cannot handle well with the cases where different cell types are influenced by the batch effect in different ways or levels.; I am afraid that batch effects are not accurately corrected, and I am still puzzled about which method may give better results, i.e., calculating marker genes basing on batch-corrected data or including batch as a covariate in the raw data. (Is there any available paper discussing this problem?). In addition, I will check `adata.var` soon. Thanks,; BP",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/691#issuecomment-502557529:657,avail,available,657,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691#issuecomment-502557529,1,['avail'],['available']
Availability,"Hi @Olivia117,. Let's see if I can help. I think there are a few misunderstandings here. It appears that you are mixing the `adata.var['highly_variable']` approach with the `adata.obsm['X_geneset1']` approach Alex suggested. Firstly, there is a typo in Alex' code above. It should read:; ```; adata.obsm['X_geneset1'] = adata[:,['gene1', 'gene2', 'gene3', 'gene4']].X; sc.pp.neighbors(adata, use_rep='X_geneset1'); ```; I believe. Your error is due to this typo. The command is interpreting `'Map7d1'` as a cell index rather than a gene index. However, there are also a few other things.; 1. `adata.var['highly_variable']` takes a boolean list, so you should assign e.g., `[True, True, False, False]` if you are interested in only the first two genes out of a total of 4 genes in the dataset. This can be trivially extended to select your Gene1, Gene,... Gene500 that you are interested in. When using this approach you will need to run `sc.pp.pca(adata, svd_solver='arpack', use_highly_variable=True)` and `sc.pp.neighbors(adata)` before clustering with louvain or leiden. This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering.; 2. If you don't want to use the route via PCA, you need to assign to `adata.obsm` as Alex suggests (with my typo correction above). Even if you do not have anything in `adata.obsm`, it should still work. If you want to put something in `adata.obsm`, just run `sc.pp.pca(adata, svd_solver='arpack')` and you will see `adata.obsm['X_pca']` appear. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/510#issuecomment-487980089:436,error,error,436,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-487980089,1,['error'],['error']
Availability,"Hi @SNRNS, . `sc.pl.umap` looks for the UMAP coordinates that should be stored in `adata.obsm`, specifically it looks for coordinates in `adata.obsm['X_umap']`. These coordinates are computed and stored by `sc.tl.umap`. If `adata.obsm['X_umap']` does not exist the plotting function does return an error which I think is pretty self-explanatory:. `KeyError: ""Could not find entry in 'obsm' for 'umap'.\nAvailable keys are: ['X_pca'].""`. It must be that you have some coordinates already stored in `adata.obsm['X_umap']`, this could happen because you have subset the current adata from a bigger one, for which you had computed the UMAP, or maybe you got the data already preprocessed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1460#issuecomment-718760332:298,error,error,298,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1460#issuecomment-718760332,1,['error'],['error']
Availability,"Hi @VladimirShitov . Thank you for the help (and the information about leiden vs UMAP). I think the code provided shows something slightly different. You are plotting False vs True here, but we would want something like False vs all. So, the True violin plot would be a little different. Regardless, I am just going to down this route :D",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2485#issuecomment-1542320460:319,down,down,319,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2485#issuecomment-1542320460,1,['down'],['down']
Availability,"Hi @Zethson ,; The reason why we introduced flavors here is that we wanted the traditional implementation to be present in case anyone wanted to use it. We just introduced our implementation as a faster alternative to the already available one. In case replacing the code is required, we can do that as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1511587339:230,avail,available,230,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1511587339,1,['avail'],['available']
Availability,"Hi @Zethson! Thanks for your reply. However, I get the same errors when pulling it from conda-forge.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2000#issuecomment-920976313:60,error,errors,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000#issuecomment-920976313,1,['error'],['errors']
Availability,"Hi @alkhairohr! Strange bug -- never seen it before. The latest UMAP version I've been using with SAM is `0.4.1`. Can you downgrade UMAP to that version and try again? If that fixes your issue, then I'll add `umap<=0.4.1` requirement to the `setup.py` file for SAM as a stopgap until I figure out the issue. Meanwhile, I'll try upgrading to `0.4.4` and see if I can reproduce the error. As @giovp said, because this is a SAM issue, I'll follow up on this issue with a thread on my github repo and ping you there. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1293#issuecomment-702387945:122,down,downgrade,122,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293#issuecomment-702387945,3,"['down', 'error', 'ping']","['downgrade', 'error', 'ping']"
Availability,"Hi @aopisco ! @falexwolf I ran into the same problem but got everything to work by deleting all the unnecessary items in adata.uns. ```py; keep = ['neighbors', ]; keys = list(adata.uns.keys()); for key in keys:; if key not in keep:; del adata.uns[key]; ```; I don't get errors anymore but I fear that this might cause other problems I'm currently unaware of.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/363#issuecomment-513808772:270,error,errors,270,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363#issuecomment-513808772,1,['error'],['errors']
Availability,"Hi @cartal, it wouldn't be very hard to export to a 10x h5 file, but I'd need to write a custom function for it. Why is it needed? Does 10x offer any downstream analysis that you'd want to use on the data? I thought there are none, hence there is only `sc.read_10x_h5` and no `sc.write_10x_h5`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/262#issuecomment-422093244:150,down,downstream,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/262#issuecomment-422093244,1,['down'],['downstream']
Availability,"Hi @chris-rands . It would help to have the whole error traceback here to be able to diagnose this a bit better. @jorvis Did you find the solution to your issue, and if so could you post it here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/667#issuecomment-520159182:50,error,error,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/667#issuecomment-520159182,1,['error'],['error']
Availability,"Hi @cornhundred,. While I can't speak for the intention of the authors of MNN, typically one would use 3000-6000 highly variable genes in scRNA-seq data analysis. That tends to cover the most important sources of variation. If you have a very deeply sequenced dataset from a sensitive scRNA-seq protocol (Smart-seq2/mcSCRB-seq?) with a lot of heterogeneity, you could make an argument for using more. Generally, 10,000 is a lot though. I would probably use fewer genes. The new `highly_variable_genes()` function does not subset the genes anymore, but instead creates a `.var['highly_variable']` column which stores a boolean variable indicating which genes are highly variable and which are not. You should be able to use this column to subset adata.var_names as an input to `sce.mnn_correct()` via the `var_index` and `var_subset` parameters. Using these inputs should not subset your `AnnData` object. Batch correction can create negative gene expression levels. People tend to deal with this differently. Some people force pre-batch-correction zeros to remain zero, others cast negative values to zero, and others again ignore it. I don't think there's a best approach to this. In the end you will probably get similar results in terms of embedding and trajectory inference. You just have to be careful how you interpret the gene expression values themselves. I have so far ignored it. By the way, I've written a bit about these topics in my best practices tutorial. The case study that goes with the manuscript (currently under review) is publicly available [here](https://github.com/theislab/single-cell-tutorial)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/449#issuecomment-458072946:1553,avail,available,1553,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/449#issuecomment-458072946,1,['avail'],['available']
Availability,"Hi @davidsebfischer, I am writing a simple jupyter notebook where I am analysing the 10x_pbmc68k_reduced.h5ad data. I selected only clusters 0 and 1:; `twoClusters = adata[np.logical_or(adata.obs.louvain == '0', adata.obs.louvain == '1')]; `. Running `sc.tl.rank_genes_groups(twoClusters, groupby='louvain, method='wilcoxon', corr_method=''bonferroni)`, I obtained the following genes. ![image](https://user-images.githubusercontent.com/26186755/54123532-ec2f0b80-43f7-11e9-8c2f-f506b9170e55.png). Trying with `diffxxy` library,; `test = de.test.wilcoxon(data=twoClusters, grouping=""louvain""); `; there is the following error: _All numbers are identical in mannwhitneyu_. > @andrea-tango please use dev right now. For this test, I used the version downloaded with pip.; I can clone the repository and use the diffxpy dev branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471519124:620,error,error,620,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471519124,2,"['down', 'error']","['downloaded', 'error']"
Availability,"Hi @falexwolf, thanks for the solution you provided above for reading multiple files. I tried it and it worked when I had just 2 files. I am trying the same code with 23 files and I am getting an error message in the concatenation step. Any idea on how to fix this ? Thanks. ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-20-662b857d9182> in <module>; 12 adatas.obs['cell_names'] = pd.read_csv(path + sample + 'barcodes.tsv.gz', header=None)[0].values; 13 ; ---> 14 adata = adatas[0].concatenate(adatas[1:]). /Applications/anaconda3/lib/python3.7/site-packages/anndata/core/anndata.py in concatenate(self, join, batch_key, batch_categories, index_unique, *adatas); 1908 ; 1909 if any_sparse:; -> 1910 sparse_format = all_adatas[0].X.getformat(); 1911 X = X.asformat(sparse_format); 1912 . AttributeError: 'numpy.ndarray' object has no attribute 'getformat'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/267#issuecomment-602964900:196,error,error,196,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/267#issuecomment-602964900,1,['error'],['error']
Availability,"Hi @falexwolf, yes I will be making my method available. A [rough version](https://github.com/swolock/woublet) is already on github, and I also played around with adding it to my [scanpy fork](https://github.com/swolock/scanpy) (though not the right way -- I added it to `tl` rather than `pp`). I'll hopefully clean it up and release something more official when I have the chance.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-400090424:46,avail,available,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-400090424,1,['avail'],['available']
Availability,"Hi @fidelram ,. Thanks for the response.; I think either or both would be great. Excuse my ignorance, what's the efficient to interact with scanpy, I am guessing `annData` ? If `annData` I am again guessing that the object can be efficiently made given the CSR/CSC sparse matrix or is there already a support to import other binary matrix formats ?. Currently alevin dumps [EDS](https://github.com/COMBINE-lab/EDS) (a binary matrix format), and I wrote a small Rust library to convert it to other formats (h5, csv, mtx) and found EDS is faster to load and uses less memory, at least in R. We have a support of EDS in R world through Mike Love's awesome `tximport` package. Since scanpy provides great support and efficient implementation of various single-cell analyses for the python world, I'd love to make EDS import and alevin interaction for downstream processing as efficient as possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/856#issuecomment-538028764:847,down,downstream,847,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/856#issuecomment-538028764,1,['down'],['downstream']
Availability,"Hi @fidelram, good to see you :smile:. I was working on the Galaxy integration. I tested that with the `1.3.2` version from Bioconda. I tested with adata from krumsiek11. - For colors, I tried with `sc.pl.scatter(adata=adata, x='EKLF', y='Cebpa', color=['EgrNab', 'cJun']) and I got the error:. ```; ...; and (color is None or color in adata.obs.keys() or color in adata.var.index)):; File ""path/to/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 2035, in __contains__; hash(key); TypeError: unhashable type: 'list'; ```. - For components: the command was . ```; sc.pl.scatter(; adata=adata,; x='EKLF',; y='Cebpa',; color='EgrNab',; layers=('X', 'X', 'X'),; use_raw=False,; sort_order=True,; components='all',; projection='2d',; legend_loc='right margin',; legend_fontsize=1,; legend_fontweight='normal',; palette='viridis',; frameon=True,; right_margin=1.0,; size=1.0,; show=False,; save='.png'); ```; and the error:. ```; components = np.array(components).astype(int) - 1; ValueError: invalid literal for int() with base 10: 'all'; ```. Did I put the parameters in a wrong way?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/311#issuecomment-431284136:287,error,error,287,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/311#issuecomment-431284136,2,['error'],['error']
Availability,"Hi @flying-sheep , I’m using Scanpy on an HPC system, and even though the administrator updated it to the latest version, I'm still encountering the same error. -----; anndata 0.9.2; scanpy 1.10.2; -----; PIL 9.5.0; asciitree NA; asttokens NA; astunparse 1.6.3; backcall 0.2.0; bottleneck 1.3.6; cffi 1.15.0; cloudpickle 2.2.1; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.2; dask 2024.5.2; dateutil 2.9.0.post0; debugpy 1.5.1; decorator 4.4.2; defusedxml 0.7.1; dill 0.3.8; dot_parser NA; entrypoints 0.4; executing 0.8.3; fasteners 0.18; google NA; h5py 3.8.0; igraph 0.10.8; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.1.2; joblib 1.4.0; jupyter_server 1.18.1; kiwisolver 1.4.2; legacy_api_wrap NA; leidenalg 0.10.1; llvmlite 0.42.0; louvain 0.8.2; lz4 4.3.2; markupsafe 2.1.1; matplotlib 3.6.0; mpl_toolkits NA; msgpack 1.0.5; natsort 8.4.0; numba 0.59.0; numcodecs 0.12.1; numexpr 2.8.4; numpy 1.23.5; packaging 21.3; pandas 2.1.0; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.23.0; prompt_toolkit 3.0.20; psutil 5.9.1; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 16.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydot 1.4.2; pygments 2.16.1; pynvml NA; pyparsing 3.0.9; pytz 2022.1; ruamel NA; scipy 1.11.2; seaborn 0.13.2; session_info 1.0.0; setuptools 61.2.0; six 1.16.0; sklearn 1.3.2; sphinxcontrib NA; stack_data 0.2.0; statsmodels 0.14.0; tblib 2.0.0; texttable 1.6.7; threadpoolctl 2.2.0; tlz 0.12.2; toolz 0.11.2; torch 2.2.0+cu121; torchgen NA; tornado 6.1; tqdm 4.63.0; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; xxhash NA; yaml 6.0; zarr 2.15.0; zipp NA; zmq 22.3.0; zoneinfo NA; zope NA; -----; IPython 8.4.0; jupyter_client 7.1.2; jupyter_core 4.10.0; jupyterlab 3.4.4; notebook 6.4.12; -----; Python 3.9.12 (main, Apr 5 2022, 06:56:58) [GCC 7.5.0]; Linux-3.10.0-1160.99.1.e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3215#issuecomment-2330378344:154,error,error,154,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215#issuecomment-2330378344,1,['error'],['error']
Availability,"Hi @genecell,. We have a review paper on current best-practices in scRNA-seq analysis which is coming out soon in Molecular Systems Biology that discusses this a bit. The issue with batch correction in scRNA-seq data isn't that batch affects different cell types differently, but rather that if cell type compositions change between batches, then transcriptional differences between the cell types that differ between the batches confound the technical batch effect estimation. So you end up correcting for more than just the technical effect. This means that you can use Combat if the cell type compositions are expected to be similar between batches. Indeed, ComBat is shown to outperform MNN for simple batch correction scenarios ([kBet paper](http://www.nature.com/articles/s41592-018-0254-1)). Inspite of the above argument, the better way to do things is definitely to include batch as a covariate. That way you don't underestimate your background variance. In the case of marker gene detection, this is not quite so problematic as:; 1. It is an easy problem, as cell-type differences tend to be very pronounced so you should always detect a signal even with non-optimal methods.; 2. The p-values you calculate from marker gene detection are inflated anyway and therefore not meaningful. We discuss the above points in our manuscript. I'm not aware whether using corrected data for differential expression testing is discussed anywhere else though. If you email me, I could forward you a copy of the manuscript, but it should be available in MSB in the next weeks. The issue with inflated p-values is also discussed is a few other places like [here](https://www.biorxiv.org/content/early/2018/11/05/463265).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/691#issuecomment-502582404:1535,avail,available,1535,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691#issuecomment-502582404,1,['avail'],['available']
Availability,"Hi @giovp! The test data is too large, it’ll take scanpy a long time to clone once this is in `master`. The way we fix it is that we replace the data and then merge our changes into commit bb70446 (creating a new commit from the two and eliminating any trace of the big dataset). For reference, the test data `filtered_feature_bc_matrix.h5` is <100kb. I’d say you find the smallest of the 10x example datasets, reduce it so the (non-image) data is <100kb all in all, and delete the hires pic. The code should work if there’s only the lores pic anyway, right?. An alternative would be to mark our tests as “internet” tests and dynamically download the data, but I think it’s better to always run the spatial tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1024#issuecomment-586185661:638,down,download,638,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1024#issuecomment-586185661,1,['down'],['download']
Availability,"Hi @giovp,; no worries, I hope you had a good TAC meeting! And thanks a lot for picking this up again, fixing the docs and also for starting the new issue on batch integration. I saw some of the github automated tests test are failing now, but I don't really understand the error messages tbh ;) Are they even related to the execution of the code provided by this PR?. If there is anything I should look into, let me know - I have some time for this next week!; Best, Jan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-1049902277:274,error,error,274,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-1049902277,1,['error'],['error']
Availability,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/526#issuecomment-471488594:599,down,downstream,599,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526#issuecomment-471488594,2,['down'],['downstream']
Availability,"Hi @hl324,. That argument is only available in scanpy 1.10, while you appear to have scanpy 1.9.8 installed. Could you try upgrading scanpy?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2981#issuecomment-2040195862:34,avail,available,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2981#issuecomment-2040195862,1,['avail'],['available']
Availability,"Hi @hyjforesight!. As mentioned in the paper, plotting corrected data is definitely the way forward. I'm not sure about regressing out all of these biological covariates (like regressing out MT fraction). In general, it can be quite informative to find that you have different MT gene expression between clusters. This can highlight different respiratory (and maybe metabolic) activity as well as data quality differences. Otherwise, feel free to just ignore the MT genes by masking them from the analysis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2029#issuecomment-1012982205:475,mask,masking,475,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2029#issuecomment-1012982205,1,['mask'],['masking']
Availability,"Hi @ilan-gold,. Regarding your thought in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2134651481), we can enable or disable Intel optimization from outside the code. However, users might not be aware of how to use this feature. Instead, if we add it to scanpy directly, all scanpy users will know the same option available. If we agree with the option discussed in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2114783668 ), I can proceed with updating the t-SNE file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3061#issuecomment-2136745993:341,avail,available,341,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061#issuecomment-2136745993,1,['avail'],['available']
Availability,"Hi @ivirshup , I replaced the one test image that was causing a failure, as you suggested. (And I checked to make sure the image makes sense... it does...) I think this should do it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1771#issuecomment-844219743:64,failure,failure,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1771#issuecomment-844219743,1,['failure'],['failure']
Availability,"Hi @ivirshup ,; It just fixed when I installed the library directly from pip. Since I was following the documentation for library installation, the command mentioned in the documentation is downloading an outdated version. . Thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1334#issuecomment-733647903:190,down,downloading,190,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334#issuecomment-733647903,1,['down'],['downloading']
Availability,"Hi @ivirshup ,; Thanks for your help.; Versions:; ```; In [1]: import numba; In [2]: numba.__version__; Out[2]: '0.45.0'; ```; I had to downgrade the original numba version in order to MNN_correct to work according to a Stackoverflow post.; Now I updated anndata through conda:; ```conda update anndata```; And ran this code (minus highly variable gene calculation):; ```; adataCombat = sc.read_h5ad(results_file); #Run combat:; # sc.pp.highly_variable_genes(adataCombat); sc.pp.pca(adataCombat, svd_solver='arpack'); sc.pp.combat(adataCombat, key='sample'); sc.pp.neighbors(adataCombat, n_pcs =50); ```; with even worse output:; ```; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: ; Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:; def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:; <source elided>; g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old); sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])); ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:; def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:; <source elided>; sum2 = sum2 ** 2; sum2 = sum2.sum(axis=1); ^. @numba.jit; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: ; Compilation is falling back to object mode WITHOUT looplifting enabled be",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1164#issuecomment-614594656:136,down,downgrade,136,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164#issuecomment-614594656,1,['down'],['downgrade']
Availability,"Hi @ivirshup, ; I am part of Intel Labs and we are trying to accelerate the genomics pipeline. We are trying to push some changes into scanpy details about which are mentioned in the blog : [https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Intel-Labs-Accelerates-Single-cell-RNA-Seq-Analysis/post/1390715#:~:text=Intel%20Labs%20has%20accelerated%20a,of%20a%20single%20A100%20GPU.](url) ; We are facing some issues while pushing some changes in the leiden and louvain. The error states some issues with pca in the scanpy/tests/external/test_scrublet.py::test_scrublet_params when we have not made any changes for the same. Can you please help us to resolve this issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2409#issuecomment-1429441613:503,error,error,503,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2409#issuecomment-1429441613,1,['error'],['error']
Availability,"Hi @ivirshup, it used to work 6 months ago. As discussed in https://github.com/saezlab/omnipath/issues/54#issuecomment-1950265944, it seems it was an error with the package `requests_cache`. Installing the latest version from GitHub solves the issue so I'll close this then, thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2861#issuecomment-1950276269:150,error,error,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2861#issuecomment-1950276269,1,['error'],['error']
Availability,"Hi @john-jiangyong,. The error is that your covariate you group by should be a categorical, while it is not at the moment. You could run:; `adata.obs[‘seurat_clusters’] = adata.obs[‘seurat_clusters’].astype(‘category’)` To turn the covariate into a categorical. Note the code above might not be 100% correct as i’m typing from my phone and haven’t verified.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1414#issuecomment-692506550:25,error,error,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1414#issuecomment-692506550,1,['error'],['error']
Availability,"Hi @marcellp,. The point of the tutorial is to easily become familiarized with Scanpy-based analysis of scRNA-seq data rather than to allow the exploration of a comprehensive dataset. Thus, the pbmc3k object is a reduced version of the one that can be downloaded from the 10X website to make everything run much faster. If you want to take a look at the full object, you would have to download the object from 10X and run the tutorial with that dataset (I believe it's called 2.7k PBMCs there). I'm not 100% sure how this object was generated, but I assume the number of genes were reduced to leave only the most highly variable genes in the dataset with sufficient levels of expression. This is often done in scRNA-seq analysis to reduce the number of features to calculate e.g., PCA-based embeddings for downstream analysis. Thus, it is not uncommon for some genes to not be taken into account when generating an embedding. If you want more background on scRNA-seq analysis in general, I would recommend [this introductory paper](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1338#issuecomment-665549817:252,down,downloaded,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1338#issuecomment-665549817,3,['down'],"['download', 'downloaded', 'downstream']"
Availability,"Hi @saiteja-danda,. I cannot reproduce your code above as I don't have your data. Could you try to generate a minimal reproducible example with data from e.g., `sc.datasets.pbmc68k_reduced()`?. In general, could you check the output of `adata.obs['km'].value_counts()` to check whether the covariate you added was correctly stored? What output are you getting? You didn't share an error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1452#issuecomment-707656885:381,error,error,381,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1452#issuecomment-707656885,1,['error'],['error']
Availability,"Hi @vitkl . thanks a lot for the feedback, all noted, we'll work toward enabling large tissue image available for storing+plotting. Will keep this open for reference!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1436#issuecomment-706060782:100,avail,available,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436#issuecomment-706060782,1,['avail'],['available']
Availability,"Hi Alex!. Sorry for this long delay, I just forgot completely.; Maybe I wasn't clear enough in my original post, here is where the issue lies:; ; When I run . ```py; sc.tl.rank_genes_groups(adata_f, groupby = 'ClusterName', groups = 'all'); ```. everything is fine and I get my desired result. However, when I just change the reference setting. ```py; sc.tl.rank_genes_groups(adata_f, groupby = 'ClusterName', reference='CA', groups = 'all'); ```. then I get the following error. ```pytb; 100 groups_order = [str(n) for n in groups_order]; 101 if reference != 'rest' and reference not in set(groups_order):; --> 102 groups_order += [reference]; 103 if (reference != 'rest'; 104 and reference not in set(adata.obs[groupby].cat.categories)):. TypeError: must be str, not list; ```. I absolutely understand how to solve this - as you said, I can just use the tutorial call and select groups explicilty. ```py; sc.tl.rank_genes_groups(adata_f, groupby = 'ClusterName', reference='CA', groups = ['OPC', 'Granule']); ```. and then it works again. I was just wondering whether this is the desired behavior - most users will leave the `groups` attribute at it's default setting when they change the `reference` attribute and wonder why it does not work - at least that was my idea. Maybe I am wrong.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/346#issuecomment-445219624:473,error,error,473,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/346#issuecomment-445219624,1,['error'],['error']
Availability,"Hi Alex!; Before, I filtered gene with `min_mean` and `min_disp`, and left about 1300 genes for downstream analysis. Maybe the dataset is highly similar, so I reduce the gene number and choose the top 200 highly variable genes and it run without error. ; Thanks a lot,; Jiping",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/33#issuecomment-324831221:96,down,downstream,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/33#issuecomment-324831221,2,"['down', 'error']","['downstream', 'error']"
Availability,"Hi Alex, ; The psutil issue by updating it has apparently gone away, however later on when I call `sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True)`; , I get the following error. The igraph I am using is V 0.1.11.; Many thanks; Hashem; `DeprecationWarning Traceback (most recent call last); <ipython-input-20-fb44185f2d28> in <module>(); 1 ; ----> 2 sc.tl.louvain(adata_corrected, n_neighbors=10, resolution=1.3, recompute_graph=True); 3 . /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, n_neighbors, resolution, n_pcs, random_state, flavor, directed, recompute_pca, recompute_distances, recompute_graph, n_dcs, n_jobs, copy); 78 directed = False; 79 if not directed: logg.m(' using the undirected graph', v=4); ---> 80 g = utils.get_igraph_from_adjacency(adjacency, directed=directed); 81 if flavor == 'vtraag':; 82 import louvain. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed); 41 def get_igraph_from_adjacency(adjacency, directed=None):; 42 """"""Get igraph graph from adjacency matrix.""""""; ---> 43 import igraph as ig; 44 sources, targets = adjacency.nonzero(); 45 weights = adjacency[sources, targets]. /ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/igraph/__init__.py in <module>(); 6 __license__ = ""MIT""; 7 ; ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, ""; 9 ""this visualization library has been renamed to ""; 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient.`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35#issuecomment-324587457:208,error,error,208,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35#issuecomment-324587457,1,['error'],['error']
Availability,"Hi Alex,. Below is the error I get. Thank you for looking at this. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-12-4fad8adf5d00> in <module>; ----> 1 sc.pl.pca(adata, color='CD3D'). ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\plotting\tools\scatterplots.py in pca(adata, **kwargs); 148 If `show==False` a `matplotlib.Axis` or a list of it.; 149 """"""; --> 150 return plot_scatter(adata, basis='pca', **kwargs); 151 ; 152 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\plotting\tools\scatterplots.py in plot_scatter(adata, color, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, basis, groups, components, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 275 color_vector, categorical = _get_color_values(adata, value_to_plot,; 276 groups=groups, palette=palette,; --> 277 use_raw=use_raw); 278 ; 279 # check if higher value points should be plot on top. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\plotting\tools\scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw); 658 # check if value to plot is in var; 659 elif use_raw is False and value_to_plot in adata.var_names:; --> 660 color_vector = adata[:, value_to_plot].X; 661 ; 662 elif use_raw is True and value_to_plot in adata.raw.var_names:. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in __getitem__(self, index); 1307 def __getitem__(self, index):; 1308 """"""Returns a sliced view of the object.""""""; -> 1309 return self._getitem_view(index); 1310 ; 1311 def _getitem_view(self, index):. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\anndata\base.py in _getitem_view(self, index); 1311 def _getitem_view(self, index):; 1312 oidx, vidx = self._normalize_indices(index); -> 1313 return AnnData(",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-456954317:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-456954317,1,['error'],['error']
Availability,"Hi Alex,; I managed to get the log working by using your function to convert to AnnData rather than mine. (adata = sc.AnnData(x)). However, coloring the plots still does not work. I get the following error.; TypeError: object of type 'numpy.int64' has no len(). You can reproduce the error by the following; ### Load Data; x = pd.read_csv('Trial_data.csv', delimiter=',', index_col=0); ### Drop DAPI; x = x.drop(list(x.filter(regex='DAPI.', axis=1)), axis=1); ### Convert to AnnData; adata = sc.AnnData(x); ### Filter cells; sc.pp.filter_cells(adata, min_genes=1); sc.pp.filter_genes(adata, min_cells=1); adata.obs['n_counts'] = adata.X.sum(axis=1); ### Normalize data; sc.pp.log1p(adata); ### PCA; sc.tl.pca(adata, svd_solver='arpack'); sc.pl.pca(adata); sc.pl.pca(adata, color='CD3D'). I also tried it on a different dataset.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-456461004:200,error,error,200,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-456461004,2,['error'],['error']
Availability,"Hi Brian,; Did you do any subsetting of your adata between running `rank_genes_groups` and `filter_rank_genes_groups`? The only way I can reproduce your error is by removing genes from my adata in between the two commands.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1487#issuecomment-726776364:153,error,error,153,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487#issuecomment-726776364,1,['error'],['error']
Availability,"Hi Dylan,. This is an issue with the new h5py package, which @ivirshup already fixed on master (https://github.com/theislab/scanpy/commit/928d475a8e2d2901c5744c3afc75e2d5a1b65f29). For now, you can downgrade your h5py package to 2.9.0 using `pip install h5py==2.9.0` as a workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/832#issuecomment-530529513:198,down,downgrade,198,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832#issuecomment-530529513,1,['down'],['downgrade']
Availability,"Hi I am having a similar issue where I would like to set the tick locations on the colorbar. Using similar code as above. ```; ax = sc.pl.tsne(adata, color = 'gene', show=False); fig = plt.gcf(); cbar_ax = fig.axes[-1]; cbar_ax.set_yticks([0,1]); ```; I get the following error 'UserWarning: Use the colorbar set_ticks() method instead'. How can I access the colorbar specifically?. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/337#issuecomment-726207918:272,error,error,272,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/337#issuecomment-726207918,1,['error'],['error']
Availability,"Hi I cannot seem to read in my visium HD raw data with the spatialdata-io; Heres what I used and the error I keep receiving. I have tried setting dataset_id to none, """" and some possible identifiers. ; I have a non zarr data format. . ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[54], line 1; ----> 1 sdata = visium_hd(path_read). File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:95, in visium_hd(path, dataset_id, filtered_counts_file, bin_size, bins_as_squares, fullres_image_file, load_all_images, imread_kwargs, image_models_kwargs, anndata_kwargs); 92 images: dict[str, Any] = {}; 94 if dataset_id is None:; ---> 95 dataset_id = _infer_dataset_id(path); 96 filename_prefix = f""{dataset_id}_""; 98 def load_image(path: Path, suffix: str, scale_factors: list[int] | None = None) -> None:. File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:361, in _infer_dataset_id(path); 359 files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith(suffix)]; 360 if len(files) == 0 or len(files) > 1:; --> 361 raise ValueError(; 362 f""Cannot infer `dataset_id` from the feature slice file in {path}, please pass `dataset_id` as an argument.""; 363 ); 364 return files[0].replace(suffix, """"). ValueError: Cannot infer `dataset_id` from the feature slice file in /Users/DarthRNA/Downloads/1299_1_XS_VHD_v2_outs, please pass `dataset_id` as an argument.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2973#issuecomment-2458530172:101,error,error,101,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973#issuecomment-2458530172,2,"['Down', 'error']","['Downloads', 'error']"
Availability,"Hi I had this problem as well with 1.6.0 it was triggered by scanpy's test code. ```; scanpy.api (unittest.loader._FailedTest) ... ERROR. ======================================================================; ERROR: scanpy.api (unittest.loader._FailedTest); ----------------------------------------------------------------------; ImportError: Failed to import test module: scanpy.api; Traceback (most recent call last):; File ""/usr/lib/python3.9/unittest/loader.py"", line 470, in _find_test_path; package = self._get_module_from_name(name); File ""/usr/lib/python3.9/unittest/loader.py"", line 377, in _get_module_from_name; __import__(name); File ""/<<PKGBUILDDIR>>/.pybuild/cpython3_3.9_scanpy/build/scanpy/api/__init__.py"", line 27, in <module>; from . import pl; File ""/<<PKGBUILDDIR>>/.pybuild/cpython3_3.9_scanpy/build/scanpy/api/pl.py"", line 1, in <module>; from ..plotting._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot; ImportError: cannot import name 'stacked_violin' from 'scanpy.plotting._anndata' (/<<PKGBUILDDIR>>/.pybuild/cpython3_3.9_scanpy/build/scanpy/plotting/_anndata.py). ----------------------------------------------------------------------; Ran 1 test in 0.000s. ```. I ended up with this patch to get the tests to run successfully.; ```; --- a/scanpy/api/pl.py; +++ b/scanpy/api/pl.py; @@ -1,4 +1,7 @@; -from ..plotting._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot; +from ..plotting._anndata import scatter, violin, ranking, clustermap, heatmap, tracksplot; +from ..plotting._stacked_violin import stacked_violin; +from ..plotting._dotplot import dotplot; +from ..plotting._matrixplot import matrixplot; ; from ..plotting._preprocessing import filter_genes_dispersion, highly_variable_genes; ; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1397#issuecomment-765003952:131,ERROR,ERROR,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1397#issuecomment-765003952,2,['ERROR'],['ERROR']
Availability,"Hi Ilan, thanks for your interest. One of the main advantages of Marsilea is the flexibility for layout plots and adding/removing components compared to the pre-defined visualization APIs in Scanpy. From my perspective, there could be two ways of integration: . 1) Reimplement some of the visualization APIs in scanpy using Marsilea, but we don't expose Marsilea to the user. You will always have a plot with known rendered size and fixed layout compared to directly using matplotlib. This could significantly reduce the code base complexities on the scanpy side, so less maintenance work. 2) Exposing the Marsilea API, we can create a visualization object that simulates the Marsilea API but is tailored specifically for `AnnData`. Maybe include some data transformation and aggregation functions that the user could directly apply during visualization. But this design doesn't make much difference compared to directly using Masilea as shown in the [notebook](https://scanpy.readthedocs.io/en/stable/how-to/plotting-with-marsilea.html).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2444#issuecomment-2352637693:572,mainten,maintenance,572,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444#issuecomment-2352637693,1,['mainten'],['maintenance']
Availability,"Hi Isaac, I have a related question: does your expression atlas; downloader also store the coordinate and all the meta data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-476540482:65,down,downloader,65,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476540482,1,['down'],['downloader']
Availability,"Hi Isaac,. When I try to set n_comps equal to 2 (trying to do a diffmap in 2; components), I get an error message saying that it must be greater than 2.; I was wondering why?. On Sun, Jul 7, 2019 at 4:25 AM Isaac Virshup <notifications@github.com>; wrote:. > I'm not sure what you're asking about here. Could you provide a little; > more context?; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/675?email_source=notifications&email_token=AKIOHVNZFKCE63C4KLO45KTP6GSAPA5CNFSM4HSIFHXKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODZLG7PQ#issuecomment-508981182>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AKIOHVL7254C36JSP374JOTP6GSAPANCNFSM4HSIFHXA>; > .; >; -- ; Harvard-MIT MD-PhD Student; G1, Biophysics; Lander Lab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/675#issuecomment-508997047:100,error,error,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/675#issuecomment-508997047,1,['error'],['error']
Availability,"Hi Issac,; Thank you for looking into this. I tried downgrading to python 3.7 but the; error still persists. Best,; Philip. On Tue, Apr 28, 2020 at 12:16 AM Isaac Virshup <notifications@github.com>; wrote:. > @phamidko <https://github.com/phamidko>, could you export that conda; > environment with conda list --export? I'd like to see if I can recreate; > with your environment.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/1183#issuecomment-620426227>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AJ7QRZ6CCZW74XVYGDEPRFDROZ7CRANCNFSM4MRFHJHQ>; > .; >. <envlist moved to next post by @ivirshup>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1183#issuecomment-620631436:52,down,downgrading,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183#issuecomment-620631436,2,"['down', 'error']","['downgrading', 'error']"
Availability,"Hi Julie,. Could it be that you saved your dataset after running `min_counts=2` so that when you reloaded it there were no more genes with `min_counts<2` in the dataset to filter out? . Regarding the minimal example.. it would be good to show the different behaviour in a reproducible way (for example using a dataset from `sc.datasets`). We do not have the same error you do when running the function between scanpy 1.3.7 and 1.4.0.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/501#issuecomment-479507574:363,error,error,363,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501#issuecomment-479507574,1,['error'],['error']
Availability,"Hi Malte and Isaac, many thanks for this! Ah, yes that other issue was; opened after I opened this one. I did search for the error message before I; opened the ticket, but I didn't search again while the ticket was open. The easiest workaround for me is simply to not use .raw anymore, for a; pipeline, it's not really needed anyways. Yes, I can see why it's important for file backed data, I just cannot see a; use case for file backed mode either. Any useful operations on file backed; data will be too slow anyways for practical use, and anyone can get a; high-RAM machine these days on Amazon for a few hours, so I've always; wondered file backed mode exists. (sidenote: File backed data is again a; feature that sounds rather complicated to implement. As a user I love; libraries that are small, stable and don't change a lot, especially for; very foundational things like anndata. I guess it's a matter of development; philosophy here). Also, yes, it's because I don't use scanpy interactively; that I don't see the use case for views. anyhow, thanks again, also for all your work on Scanpy!. On Wed, Jul 31, 2019 at 6:27 AM Isaac Virshup <notifications@github.com>; wrote:. > I've just spent a while trying to replicate, before realizing I've seen; > this issue before over on AnnData (theislab/anndata#182; > <https://github.com/theislab/anndata/issues/182>). I've got some good and; > bad news about this. It's fixed on master, but that fix is slated to be; > release in v0.7, which has intentionally breaking changes.; >; > I find views very useful when dealing with large datasets interactively.; > They're also important for file backed data, since copies are extremely; > expensive in that case.; >; > Unlike numpy, AnnData objects should always return a view when subset. If; > you'd like to get copies, you could add a .copy() to the end of your; > subsetting statement.; >; > —; > You are receiving this because you modified the open/close state.; > Reply to this email directly, view ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/728#issuecomment-516740578:125,error,error,125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728#issuecomment-516740578,1,['error'],['error']
Availability,"Hi Michael:. Thanks for your suggestion, I run the tutorial without changing anything: https://github.com/scverse/scanpy-tutorials/raw/master/pbmc3k.ipynb, ; ![image](https://user-images.githubusercontent.com/33963919/209399067-2287268f-a77c-4f12-ba5b-d56e4370b2f2.png). My `scanpy` can't do down dimension correctly in the `pbmc3k` data.; ![image](https://user-images.githubusercontent.com/33963919/209398837-d2f77dfa-5855-4bf7-9c7d-33625909af09.png); Can you please let me know what is wrong?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2386#issuecomment-1364270613:292,down,down,292,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386#issuecomment-1364270613,1,['down'],['down']
Availability,"Hi Raphaël!. Thanks!. What do you mean with ""I just stumbled upon the same error, maybe due to the installation method."" - which error?. Regarding the typo: Hm, are you running Scanpy 0.4.4; if you run an early version, this was 'Phase' with a captical 'P'; since 0.4.3+7 it's 'phase'; like all the other annotations. Cheers,; Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/82#issuecomment-368964431:75,error,error,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82#issuecomment-368964431,2,['error'],['error']
Availability,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap?. I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed?. Thank you for your kind help. Best regards,. Lirong. 获取 Outlook for iOS<https://aka.ms/o0ukef>; ________________________________; 发件人: Sergei R. <notifications@github.com>; 发送时间: Wednesday, April 22, 2020 12:44:36 PM; 收件人: theislab/scanpy <scanpy@noreply.github.com>; 抄送: plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>; 主题: Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> .; Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1.; You can also install scanpy from github where it is fixed or just wait for a new scanpy release. ―; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1181#issuecomment-617911861:285,error,error,285,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181#issuecomment-617911861,1,['error'],['error']
Availability,"Hi ShuhuaGao,. thanks for your input! Monocle 2 has many more options for preprocessing, that's right. I believe though that you should get along with the limited options of Scanpy for a robust pseudotime and branching inference using DPT; simply because DPT is very robust. Nonetheless I have to admit that I've not worked with an extensive number of data types. From this experience, my understanding is the following. * for RNA-Seq data, you should normalize and extract highly-variable genes. this is most simply done by using the procedure of cell ranger [`sc.pp.recipe_zheng17`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/recipes.py#L59-L78) (example [here](https://github.com/theislab/scanpy_usage/tree/master/170503_zheng17)) or, if you want more control, the Seurat workflow (example [here](https://github.com/theislab/scanpy_usage/tree/master/170505_seurat)); * for qPCR, a simple log-normalization ([sc.pp.log1p](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L280-L298)) should suffice (see example [here](https://github.com/theislab/scanpy_usage/tree/master/170501_moignard15)); you might though consider ""normalizing per cell / UMI correction"", one of the steps done in RNA-seq part ([`sc.pp.normalize_per_cell`](https://github.com/theislab/scanpy/blob/373dc325bdc24754dd658bc06b818987de6d568c/scanpy/preprocessing/simple.py#L405-L452)). Ask if you have further questions. 😄",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/26#issuecomment-312623579:187,robust,robust,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26#issuecomment-312623579,2,['robust'],['robust']
Availability,"Hi Sidney,. Thanks for the pull request. igraph and louvain are kind of heavy dependencies (e.g. takes long time to compile them and they're not easily available via PyPI for all platforms etc.), this is why they are excluded from requirements file. It's written in the [installation document](https://scanpy.readthedocs.io/en/latest/installation.html) that these need to be installed manually. Also, there should be proper error messages stating that these must be installed separately when their functionality is needed for a function in scanpy and cannot be found. Did you get any other error regarding these packages?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/176#issuecomment-397543101:152,avail,available,152,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/176#issuecomment-397543101,3,"['avail', 'error']","['available', 'error']"
Availability,"Hi Thank you for getting back to me. I updated it and now when I try to import scanpy as sc I get the following error:. LookupError Traceback (most recent call last); ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/__init__.py in <module>; 89 ; ---> 90 __version__ = get_version(root="".."", relative_to=__file__); 91 del get_version. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/setuptools_scm/__init__.py in get_version(root, version_scheme, local_scheme, write_to, write_to_template, relative_to, tag_regex, fallback_version, fallback_root, parse, git_describe_command); 142 config = Configuration(**locals()); --> 143 return _get_version(config); 144 . ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/setuptools_scm/__init__.py in _get_version(config); 146 def _get_version(config):; --> 147 parsed_version = _do_parse(config); 148 . ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/setuptools_scm/__init__.py in _do_parse(config); 117 ""https://github.com/user/proj/archive/master.zip ""; --> 118 ""use git+https://github.com/user/proj.git#egg=proj"" % config.absolute_root; 119 ). LookupError: setuptools-scm was unable to detect version for '/Users/kabitabaral/miniconda3/envs/scanpy/lib/python3.6/site-packages'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj. During handling of the above exception, another exception occurred:. ModuleNotFoundError Traceback (most recent call last); ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/compat.py in pkg_version(package); 56 try:; ---> 57 from importlib.metadata import version as v; 58 except ImportError:. ModuleNotFoundError: No module named 'importlib.metadata'. During handling of",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1154#issuecomment-611202845:112,error,error,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154#issuecomment-611202845,1,['error'],['error']
Availability,"Hi [gmoore5](https://github.com/gmoore5),. I assume this might be too late for you, but hopefully it's still useful for someone searching for this error. I could resolve this by:; - Restarting the kernel; - Setting the directory using `sc.settings.figdir = ""path/to/folder/""` (instead of sc._settings.ScanpyConfig.figdir = 'path/to/folder/')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1981#issuecomment-1082447079:147,error,error,147,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981#issuecomment-1082447079,1,['error'],['error']
Availability,"Hi all!. I just wanted to jump in with @sophietr and say that implementing a cell cycle classification function like Seurat's [CellCycleScoring](https://github.com/satijalab/seurat/blob/master/R/scoring.R) function would be a nice addition to the preprocessing options. Would be valuable to keep an eye on in downstream exploration and could then be easily regressed out if needed. Also, do you guys have any opinions about the inclusion of imputation/smoothing strategies? I've been messing around with including it in analysis pipelines, but still haven't really settled on when to include them. If there's interest, [MAGIC](https://github.com/pkathail/magic) seems like a great option and is currently implemented in Python.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/45#issuecomment-356611882:309,down,downstream,309,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/45#issuecomment-356611882,1,['down'],['downstream']
Availability,"Hi all, @flying-sheep @falexwolf . Wanted to echo Alejandro and highlight this is a critical bug, since nearly every function carries a use_raw flag, and the assumption that .raw contains counts is used explicitly or implicitly in numerous scanpy functions. We just realized that a massive dataset we've been processing for ~6 weeks also has no reads in the .raw despite saving it prior to log1p/normalize functions. I am not sure it's helpful, but we see this bug in version scanpy 1.9.8, but in an old dataset/environment with scanpy 1.6.0, .raw correctly preserved counts.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3073#issuecomment-2147646580:45,echo,echo,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073#issuecomment-2147646580,1,['echo'],['echo']
Availability,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds); 367 ; 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); 370 scores[np.isnan(scores)] = 0; 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611:69,error,error,69,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611,2,['error'],['error']
Availability,"Hi there - random question, but for some reason, after applying this plotting solution, it specifically then leads to an error being thrown when the adata object is written (I double checked, and this doesn't happen if this `scv.pl.scatter` command isn't called). . `--> 103 write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs)`. `TypeError: Can't implicitly convert non-string objects to strings`. Is something stored in the object that is specific to this here, that can lead to an AnnData write error? The issue relates to the .obs column, and I can certainly save the adata object if not running this plotting command. I also checked the dtypes of the obs columns, and there doesn't seem to be anything out of the ordinary there either. Any help would be appreciated, it took me some time to figure out this was causing the issue! (and it's a bit frustrating to not be able to save an object just from running a plot command)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/955#issuecomment-1862227440:121,error,error,121,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/955#issuecomment-1862227440,2,['error'],['error']
Availability,"Hi there!. I am having a similar issue when trying to install Scanpy using conda in Ubuntu. I have uninstalled and installed Anaconda so it is the newest version and still amb getting the same error. Pip install though works well. I was wondering if you could help me with the issue as it is vry interesting for me to install it with conda. The output when installing is the following one:. > Collecting package metadata (current_repodata.json): done; > Solving environment: failed with initial frozen solve. Retrying with flexible solve.; > Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; > Collecting package metadata (repodata.json): done; > Solving environment: failed with initial frozen solve. Retrying with flexible solve.; > Solving environment: - ; > Found conflicts! Looking for incompatible packages.; > This can take several minutes. Press CTRL-C to abort.; > failed ; > ; > UnsatisfiableError: The following specifications were found to be incompatible with each other:; > ; > Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:; > ; > - feature:/linux-64::__glibc==2.31=0; > - feature:|@/linux-64::__glibc==2.31=0; > ; > Your installed version is: 2.31",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1298#issuecomment-1008789859:193,error,error,193,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1298#issuecomment-1008789859,2,"['Avail', 'error']","['Available', 'error']"
Availability,"Hi there, I am having the same issue as above. I have tried the fix that @Xparx has provided but it yields more problems. See the below error which I am now receiving:. ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: float() argument must be a string or a number, not 'csc_matrix'. The above exception was the direct cause of the following exception:. ValueError Traceback (most recent call last); <ipython-input-48-abf5bf78cb77> in <module>; ----> 1 sc.pl.dpt_timeseries(adata_HVG). ~/.conda/envs/python3/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in dpt_timeseries(adata, color_map, show, save, as_heatmap); 159 if as_heatmap:; 160 # plot time series as heatmap, as in Haghverdi et al. (2016), Fig. 1d; --> 161 timeseries_as_heatmap(; 162 adata.X[adata.obs['dpt_order_indices'].values],; 163 var_names=adata.var_names,. ~/.conda/envs/python3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in timeseries_as_heatmap(X, var_names, highlights_x, color_map); 197 _, ax = pl.subplots(figsize=(1.5 * 4, 2 * 4)); 198 ax.imshow(; --> 199 np.array(X, dtype=np.float_),; 200 aspect='auto',; 201 interpolation='nearest',. ValueError: setting an array element with a sequence.; ```. I thought that this might be something to do with the fact that the `np.ones` object is a numpy array instead of a pandas series so I tried substituting this with the line `adata.uns['dpt_changepoints'] = pd.Series(np.ones(adata.obs['dpt_order_indices'].shape[0] - 1))` instead, but this still yielded the same error. Thanks in advance!. Update: I just tried to run this command having used `branching=1' in my analysis and not performing the above correction (even though I know it's inappropriate for my particular system, branching=0 is what I want to use) and it still yielded the same error. As such I think perhaps this could be something independent of the above issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/409#issuecomment-719627140:136,error,error,136,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/409#issuecomment-719627140,3,['error'],['error']
Availability,"Hi there,; stumbled on this by chance when debugging a similar problem - though I'd share my gained insight:. As @LuckyMD already pointed out [here](https://github.com/theislab/scanpy/issues/435#issuecomment-475722334), the root of the problem is feeding `np.int64` into `sc.preprocessing.log1p`. More specifically, the problem occurs in `log1p_array` [here](https://github.com/theislab/scanpy/blob/8829f2b80b7b347d4d933f3eaa1a8d959f35cd60/scanpy/preprocessing/_simple.py#L318). When specifying `out` in `np.log1p`, the input types need to be castable. However, `np.log1p` returns `np.floatX` (type code double precision `'d'`) which cannot be cast to `np.int64` (type code long integer `'l'`). The error is reproducible with this small snippet of code:. ```python; import numpy. a = np.zeros(shape=(1, 1), dtype='int64'); np.log1p(x=a, out=a); ```. The error can be prevented like this:. ```python; import numpy. a = np.zeros(shape=(1, 1), dtype='int64'); a = np.log1p(x=a); ```. In the case of `scanpy`, this would mean replacing [this](https://github.com/theislab/scanpy/blob/8829f2b80b7b347d4d933f3eaa1a8d959f35cd60/scanpy/preprocessing/_simple.py#L318) line of code by `X = np.log1p(X)`. The drawback being that the operation is no longer `inplace`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-680727659:699,error,error,699,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-680727659,2,['error'],['error']
Availability,"Hi to all, thanks for your interest in glmpca. I have been thinking of doing a python package now that the R package is finished and it would be an honor to have it included in scanpy. Can you give me a sense of how urgently you would need the package (ie what is the typical release cycle)? Also let me note a few caveats about the method:; * It does not handle zero inflation (which ZINB-WAVE does). However, we argue in our paper that despite large numbers of zeros, UMI data are not zero-inflated. We do not make any claim about the appropriateness of the glmpca model for non-UMI data (eg Smart-Seq read counts), which may actually be zero-inflated, although you could certainly run it with eg the negative binomial likelihood.; * glmpca is an alternative to PCA but not necessarily a replacement to PCA. For example, it is at least 10x slower than PCA and we are still working on the big data implementation for sparse matrices (in other words, we assume you can load the data matrix in dense form, which can be limiting).; * We describe a fast approximation to GLM-PCA in the paper which involves transforming raw counts to either Pearson or deviance residuals from a null model then applying standard PCA to that. This approach is just as fast as PCA as long as the null model can be computed in closed-form, which is what we have implemented here: https://github.com/willtownes/scrna2019/blob/master/util/functions.R#L164 . The idea is similar to the sctransform approach used by seurat, but the computation is simpler and faster.; * We also provide a deviance-based gene filtering method which is an alternative to using highly variable genes. This and the residuals functions will be available as an R package on bioconductor. I look forward to collaborating with you all to help make these methods available to a wider community!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-540672230:1695,avail,available,1695,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/868#issuecomment-540672230,2,['avail'],['available']
Availability,"Hi! Sorry, my bad. That parameter was undocumented, and I added it to the wrong docstring building block. It’s available in all scatterplots for dimension reductions, like `pca`, `tsne` and so on.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/545#issuecomment-475158480:111,avail,available,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/545#issuecomment-475158480,1,['avail'],['available']
Availability,"Hi! Thanks for the answer. Installing and importing h5py helped. I think I got scanpy to run. However, I am stuck again at reading the .mtx file; ; Since I am new to scanpy I am just following your tutorial. I run the following comand and get the subsequent error bellow. . ```py; adata = sc.read_10x_mtx(; 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) # write a cache file for faster subsequent reading; ```; ```pytb; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-17-e7dd3543f8df> in <module>(); 2 'C:\\Users\\correap\\Documents\\03152019_scRNAseq\\filtered_feature_bc_matrix_1', # the directory with the `.mtx` file; 3 var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); ----> 4 cache=True) # write a cache file for faster subsequent reading; 5 ; 6 . ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, gex_only); 244 else:; 245 adata = _read_v3_10x_mtx(path, var_names=var_names,; --> 246 make_unique=make_unique, cache=cache); 247 if not gex_only:; 248 return adata. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache); 277 Read mex from output from Cell Ranger v3 or later versions; 278 """"""; --> 279 adata = read(os.path.join(path, 'matrix.mtx.gz'), cache=cache).T # transpose the data; 280 genes = pd.read_csv(os.path.join(path, 'features.tsv.gz'), header=None, sep='\t'); 281 if var_names == 'gene_symbols':. ~\AppData\Local\Continuum\anaconda3\lib\site-packages\scanpy\readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 76 return _read(filename, backed=backed, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733:258,error,error,258,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-479994733,1,['error'],['error']
Availability,"Hi! Thanks for using scanpy!. The error is in [`anndata`](https://github.com/theislab/anndata) so filing a bug there would be more fitting. I did it for you: https://github.com/theislab/anndata/issues/23. ---. Lastly, please do ```` ```pytb ```` for your python tracebacks blocks so we get syntax highlighting:. > ````markdown; > I also get the error when I try to use it with jupyter notebook:; > ; > ```pytb; > import scanpy.api as sc; > ; > Traceback (most recent call last):; > ; > File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-> packages/IPython/core/interactiveshell.py"", line 2910, in run_code; > exec(code_obj, self.user_global_ns, self.user_ns); > ; > […]; > ; > SyntaxError: invalid syntax; > ```; > ````. This would look like this:. > I also get the error when I try to use it with jupyter notebook:; > ; > ```pytb; > import scanpy.api as sc; > ; > Traceback (most recent call last):; > ; > File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code; > exec(code_obj, self.user_global_ns, self.user_ns); > ; > […]; > ; > SyntaxError: invalid syntax; > ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/160#issuecomment-391972041:34,error,error,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160#issuecomment-391972041,3,['error'],['error']
Availability,"Hi!. It looks like you have too many 0 count genes in your dataset. I would filter genes and cells before calculating highly variable genes. In case you're interested, I've been working on a tutorial for single-cell RNA-seq analysis. It's available [here](www.github.com/theislab/single-cell-tutorial)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/509#issuecomment-468852316:239,avail,available,239,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509#issuecomment-468852316,1,['avail'],['available']
Availability,"Hi, . Actually that's not what I've experienced - if you compare with default rank_genes_groups test you get genes with positive **and** negative logFC, which means that the test reports both upregulated and downregulated genes in that comparison, but again, it's not symmetric - please try on a test dataset for yourself.. Also if I take lists produced by A vs B comparison and B vs A and filter the genes by a common adjusted p-value cutoff (0.05 let's say) I would get lists of different sizes, so all of that makes me think that the tests are not symmetric/two-sided.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/919#issuecomment-554364259:208,down,downregulated,208,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/919#issuecomment-554364259,1,['down'],['downregulated']
Availability,"Hi, . I just stumbled upon the same error, maybe due to the installation method.; Anyway, I got it fixed but since my package was outdated and it's been a while since I used python maybe the next point as already been solved:. -typo issue in the notebook examples (phase instead of Phase); at In [8] when you call the pca.scatter function with color 'phase'. > ValueError: ""phase"" is invalid! specify valid sample annotation, one of ['n_genes', 'percent_mito', 'n_counts', 'dropouts', 'complexity', 'S_score', 'G2M_score', 'Phase', 'X_diffmap0', 'louvain_groups']. Very nice package and notebooks BTW,; Raphaël",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/82#issuecomment-368930312:36,error,error,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/82#issuecomment-368930312,1,['error'],['error']
Availability,"Hi, . I updated the pipeline to use [this singularity container](https://github.com/icbi-lab/borst2021/releases/download/containers-0.2.0/vanderburg_edger.sif). The problem persists.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2014#issuecomment-944868481:112,down,download,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2014#issuecomment-944868481,1,['down'],['download']
Availability,"Hi, . I've been getting the same error when trying to use `sc.pp.normalize_total` after `sc.pp.downsample_counts.` Normalize total returns a CSR sparse matrix of type `<class 'numpy.int64'>`, which then causes `sc.pp.normalize_total` to error. Not sure where the correct `dtype` should take place.; 	; ```python; pbmc = sc.datasets.pbmc68k_reduced(); pbmc.X = pbmc.raw.X; sc.pp.downsample_counts(pbmc, counts_per_cell=500); sc.pp.normalize_total(pbmc, target_sum=1e4); ```. Here's the traceback:. ```pytb; Normalizing counts per cell. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-136-3305b6c650f4> in <module>; 2 pbmc.X = pbmc.raw.X; 3 sc.pp.downsample_counts(pbmc, counts_per_cell=500); ----> 4 sc.pp.normalize_total(pbmc, target_sum=1e4). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layers, layer_norm, inplace); 166 adata.obs[key_added] = counts_per_cell; 167 if hasattr(adata.X, '__itruediv__'):; --> 168 _normalize_data(adata.X, counts_per_cell, target_sum); 169 else:; 170 adata.X = _normalize_data(adata.X, counts_per_cell, target_sum, copy=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_normalization.py in _normalize_data(X, counts, after, copy); 14 after = np.median(counts[counts>0]) if after is None else after; 15 counts += (counts == 0); ---> 16 counts /= after; 17 if issparse(X):; 18 sparsefuncs.inplace_row_scale(X, 1/counts). TypeError: ufunc 'true_divide' output (typecode 'd') could not be coerced to provided output parameter (typecode 'l') according to the casting rule ''same_kind''; ```. ```; >>> pbmc.X; <700x765 sparse matrix of type '<class 'numpy.int64'>'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-538776417:33,error,error,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-538776417,2,['error'],['error']
Availability,"Hi, . Thanks for the quick reply!. I'm attaching the output for `combined_bbknn.obs['scNym']`:. ![Screenshot 2021-03-01 at 11 09 39](https://user-images.githubusercontent.com/3297906/109489440-ca187300-7a7e-11eb-943d-270c0273c3fc.png). This is really weird. When I tested it on my macbook I created a new environment and the problem persisted. However, there I downgraded to `scanpy==1.6` as well, the problem persisted, but the `NA`s weren't there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1701#issuecomment-787867150:361,down,downgraded,361,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701#issuecomment-787867150,1,['down'],['downgraded']
Availability,"Hi, ; I'm having similar issues in using sc.tl.ingest(adata, adata_ref, obs='louvain').; I have updated my Scanpy 1.4.6 and anndata to 0.7.1.; I'm getting the following error message.; ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-71-27e22cc8f823> in <module>; ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). ~/opt/anaconda3/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs); 119 ; 120 for method in embedding_method:; --> 121 ing.map_embedding(method); 122 ; 123 if obs is not None:. ~/opt/anaconda3/lib/python3.7/site-packages/scanpy/tools/_ingest.py in map_embedding(self, method); 407 """"""; 408 if method == 'umap':; --> 409 self._obsm['X_umap'] = self._umap_transform(); 410 elif method == 'pca':; 411 self._obsm['X_pca'] = self._pca(). ~/opt/anaconda3/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _umap_transform(self); 396 ; 397 def _umap_transform(self):; --> 398 return self._umap.transform(self._obsm['rep']); 399 ; 400 def map_embedding(self, method):. ~/opt/anaconda3/lib/python3.7/site-packages/umap/umap_.py in transform(self, X); 2006 try:; 2007 # sklearn pairwise_distances fails for callable metric on sparse data; -> 2008 _m = self.metric if self._sparse_data else self._input_distance_func; 2009 dmat = pairwise_distances(; 2010 X, self._raw_data, metric=_m, **self._metric_kwds. AttributeError: 'UMAP' object has no attribute '_input_distance_func'; ```. Appreciate your comments.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1092#issuecomment-623064541:169,error,error,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092#issuecomment-623064541,1,['error'],['error']
Availability,"Hi, ; That was from my own datasets, but I also used the data from here, https://github.com/theislab/single-cell-tutorial/blob/master/latest_notebook/Case-study_Mouse-intestinal-epithelium_1906.ipynb, and got the same error. ```; adata_mnn = adata.copy(); adata_list = [adata_mnn[adata_mnn.obs['sample'] == i] for i in adata_mnn.obs['sample'].unique()]; adata_list; ```. ```; [View of AnnData object with n_obs × n_vars = 2267 × 12818; obs: 'sample', 'region', 'donor', 'n_counts', 'log_counts', 'n_genes', 'mt_frac', 'size_factors'; var: 'gene_id', 'n_cells'; uns: 'log1p'; layers: 'counts',; View of AnnData object with n_obs × n_vars = 1976 × 12818; obs: 'sample', 'region', 'donor', 'n_counts', 'log_counts', 'n_genes', 'mt_frac', 'size_factors'; var: 'gene_id', 'n_cells'; uns: 'log1p'; layers: 'counts',; View of AnnData object with n_obs × n_vars = 1663 × 12818; obs: 'sample', 'region', 'donor', 'n_counts', 'log_counts', 'n_genes', 'mt_frac', 'size_factors'; var: 'gene_id', 'n_cells'; uns: 'log1p'; layers: 'counts',; View of AnnData object with n_obs × n_vars = 2356 × 12818; obs: 'sample', 'region', 'donor', 'n_counts', 'log_counts', 'n_genes', 'mt_frac', 'size_factors'; var: 'gene_id', 'n_cells'; uns: 'log1p'; layers: 'counts',; View of AnnData object with n_obs × n_vars = 2422 × 12818; obs: 'sample', 'region', 'donor', 'n_counts', 'log_counts', 'n_genes', 'mt_frac', 'size_factors'; var: 'gene_id', 'n_cells'; uns: 'log1p'; layers: 'counts',; View of AnnData object with n_obs × n_vars = 1773 × 12818; obs: 'sample', 'region', 'donor', 'n_counts', 'log_counts', 'n_genes', 'mt_frac', 'size_factors'; var: 'gene_id', 'n_cells'; uns: 'log1p'; layers: 'counts']; ```. ```; import mnnpy; corrected = mnnpy.mnn_correct(*adata_list, batch_key=""sample""); ```. ```; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-35-7ad830fcd907> in <module>; 1 import mnnpy; ----> 2 corrected = mnnpy.mnn_correct(*a",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1367#issuecomment-674176537:218,error,error,218,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367#issuecomment-674176537,1,['error'],['error']
Availability,"Hi, @GeoffSCollins ! To do that, you need to add new columns to `adata.obs` table. A column should contain one value (e.g. `True`) for the group of interest and another value (e.g. `False`) for all the other groups. This is how you can create such columns for each of the values of column `leiden`:. ```python; import pandas as pd. adata.obs = pd.concat([; adata.obs,; pd.get_dummies(adata.obs[""leiden""], prefix=""is_cell_type"").astype(bool).astype(""category""),; ], axis=1); ```. Then you can build a violin plot:. ```python; sc.pl.violin(adata, keys=""total_counts"", groupby=""is_cell_type_NK""); ```; ![download-8](https://user-images.githubusercontent.com/35199218/236865939-768d759a-a581-4ba9-acb9-0104cbf16efd.png). I hope this is useful! Also, a small note: ""UMAP cluster"" is not a correct term. Clusters are obtained completely independently of UMAP by running leiden clustering algorithm. UMAP is just a nice visualisation (which is, however, built ignorant of cluster information).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2485#issuecomment-1538590107:601,down,download-,601,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2485#issuecomment-1538590107,1,['down'],['download-']
Availability,"Hi, @brianpenghe .; The current version of scanpy is 1.8.1, it is hard to check the errors for the version which is 1.5 year old (1.5.0). Could you try updating scanpy and checking if the error persists?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1990#issuecomment-916371848:84,error,errors,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990#issuecomment-916371848,2,['error'],"['error', 'errors']"
Availability,"Hi, @eroell, I understand what you're saying. You're referring to tests with signed test statistics, like t-tests and Wilcoxon tests. You mentioned that larger scores typically correspond to lower p-values, and conversely, scores further from 0 also tend to have lower p-values. However, I am currently confused about what the positive and negative values of these scores represent. Previously, I believed that positive scores indicated upregulation and negative scores indicated downregulation, but recent results have shown me that this viewpoint is incorrect.; ![image](https://github.com/scverse/scanpy/assets/103617127/5f7d7b5b-939d-4ffe-8822-b68b59ac354f)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2586#issuecomment-2104192246:480,down,downregulation,480,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586#issuecomment-2104192246,1,['down'],['downregulation']
Availability,"Hi, @vikram0010 .; Downgrading umap to 0.39 should help.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1092#issuecomment-623084047:19,Down,Downgrading,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092#issuecomment-623084047,1,['Down'],['Downgrading']
Availability,"Hi, Alex,. Many thanks for your quick reply. I just saw your reply as it is almost 10PM in Singapore now. It is understandable to perform quality control, in-cell normalization and to extract the highly variable genes for ordering. I got your point. For your reply about qPCR, do we need a log normalization? I think a log transform is only required for RNA-Seq data to get a non-skewed normal distribution. As for qPCR data, the delta_Ct value is actually already in a log scale. In the example you have mentioned, there is no call of sc.pp.log1p, either. Instead, we just read the data by ; `adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url)`; and no more processing is applied. As can be found from the original paper, the so-called dCt_value is just defined as HK_Ct - Ct, where HK_Ct is the mean Ct of 4 housing keeping genes on a cell-wise basis. . Besides, in many cases, there may be no UMI data available. In such a case, the normalization per cell for RNA-Seq is actually to compute the FPKM/TPM to compensate for the sequencing depth, right? Usually, the RNA-Seq data in FPKM form is already provided in publications. And then we work on this data to find the highly variable genes. (Just personal understanding. I am new to this field from mechatronics engineering.). Anyway, thanks again for your help. I noticed that there are no examples for pseudo-time ordering with RNA-Seq data. Maybe I can provide one in the near future, as I am working on gene network modeling based on the pseudo-time information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/26#issuecomment-312650646:927,avail,available,927,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/26#issuecomment-312650646,1,['avail'],['available']
Availability,"Hi, I am also still receiving this error!. > ---------------------------------------------------------------------------; > ValueError Traceback (most recent call last); > <ipython-input-141-e471c5e20fbd> in <module>; > ----> 1 sc.tl.rank_genes_groups(adata, 'louvain_05',n_genes=100,method=""wilcoxon"",use_raw=False); > ; > e:\programs\python\python38\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, layer, **kwds); > 398 mean_rest, var_rest = _get_mean_var(X[mask_rest]); > 399 ; > --> 400 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; > 401 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); > 402 scores[np.isnan(scores)] = 0; > ; > ValueError: math domain error. How can I deal with it? I though it was a bug that is fixed now!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/566#issuecomment-611280022:35,error,error,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/566#issuecomment-611280022,2,['error'],['error']
Availability,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: ; ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/493#issuecomment-477674448:155,error,error,155,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493#issuecomment-477674448,1,['error'],['error']
Availability,"Hi, I cloned this repo, switched to `modern-rng`, and installed it with `pip`. I was able to reproduce the same error.; ```; Exception ignored in: <class 'ValueError'>; Traceback (most recent call last):; File ""numpy\random\_generator.pyx"", line 622, in numpy.random._generator.Generator.integers; File ""numpy\random\_bounded_integers.pyx"", line 2881, in numpy.random._bounded_integers._rand_int32""; ValueError: high is out of bounds for int32; ```; I am using numpy 1.26, which is the numpy version required by this branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3041#issuecomment-2332066283:112,error,error,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041#issuecomment-2332066283,1,['error'],['error']
Availability,"Hi, I don’t see any errors in your example. Can you please specify what you expected to happen and how what happened differs from that?. Also please provide code as text (in a Markdown code block), not as images.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2819#issuecomment-1903490064:20,error,errors,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2819#issuecomment-1903490064,1,['error'],['errors']
Availability,"Hi, I encountered the same error as odorea. But it could not be solved by renaming `igraph` to `jgraph`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/807#issuecomment-534443201:27,error,error,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807#issuecomment-534443201,1,['error'],['error']
Availability,"Hi, I have downgrade my numab version to 0.51, it works",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-812989390:11,down,downgrade,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-812989390,1,['down'],['downgrade']
Availability,"Hi, I have fixed the issue.; It appears that adding, subtracting or dividing numpy.ndarrays with scipy.sparse matrices returns a numpy.matrix. numpy_array /= scipy_sparse_matrix, This command changed the type of numpy_array to numpy.matrix which caused downstream problems. So, you have to transfer the matrix to sparse format again for downstream analysis.; I used the command 'adata.X = scipy.sparse.csr_matrix(adata.X) ' after dividing the measured counts by the size factor.; So, I paste it here as a note of warning when performing this type of operation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/456#issuecomment-459623293:253,down,downstream,253,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/456#issuecomment-459623293,2,['down'],['downstream']
Availability,"Hi, I just wanted to bring this back up again because I've been logging some of the issue's I've encountered. It seems we're at a bit of a philosophical divide, so perhaps it's best for me to just register which use cases I have that AnnData / scanpy are personally causing me friction:. Instead of pasting all errors, I'm just going to paste code blocks I wish worked. Note, these are actual use cases I have regularly encountered. **1. Cannot pass AnnData to numpy or sklearn operators**. ```python; import scanpy as sc; import numpy as np; import pandas as pd; import matplotlib.pyplot as plt; from sklearn import decomposition, cluster. data = np.random.normal(size=(100,10)); adata = sc.AnnData(data). # All of the following raise errors; np.sqrt(adata); adata[:, adata.var_names[0:3]] - adata[:, adata.var_names[3:6]]. adata.obsm['X_PCA'] = decomposition.PCA(2).fit_transform(adata); ```; To answer the question above, I think it should return the whole AnnData object, like how DataFrames return themselves. I don't know if we think it should ""update"" the original AnnData. I'm also confused by how this results in a performance decrease? If I do `adata = np.sqrt(adata)` then isn't this the same footprint as modifying inplace? If I do `adata_sq = np.sqrt(adata)` then my intention is to duplicate the adata object. In this case, it is my intention to create a duplicate object, and I would like AnnData to respect this intention. ; **2. Requirement to use .var_vector or .obs_vector for single columns**; ```python; # This works as expected; adata[:, adata.var_names[0:3]]. # I wish this did as well.; adata[:, adata.var_names[0]]; ```; **3. .var_vector doesn't return a Series**. ```python; pdata = pd.DataFrame(data); # Returns series; pdata[0]. # Returns ndarray; adata.var_vector[0]; ```. **4. Clusters as categories creates confusing scatterplots**; ```python; sc.pp.neighbors(adata); sc.tl.leiden(adata). plt.scatter(adata.obs['leiden'], adata.X[:,0]); ```; Produces the following plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-607952458:311,error,errors,311,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-607952458,2,['error'],['errors']
Availability,"Hi, I tried that and got this error. I think it's because it's recognizing both antibody data and gene data and throwing an error. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[7], line 13; 11 key = get_second_to_last_split(path); 12 print(key); ---> 13 adata = sq.read.visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True); 15 # Create unique cell identifiers; 16 adata.obs_names = f'sample_{key}_' + adata.obs_names. File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/popari_env/lib/python3.12/site-packages/squidpy/read/_read.py:67, in visium(path, counts_file, library_id, load_images, source_image_path, **kwargs); 34 """"""; 35 Read *10x Genomics* Visium formatted dataset.; 36 ; (...); 64 - :attr:`anndata.AnnData.uns` ``['spatial']['{library_id}']['metadata']`` - various metadata.; 65 """""" # noqa: E501; 66 path = Path(path); ---> 67 adata, library_id = _read_counts(path, count_file=counts_file, library_id=library_id, **kwargs); 69 if not load_images:; 70 return adata. TypeError: squidpy.read._utils._read_counts() got multiple values for keyword argument 'count_file'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3113#issuecomment-2406243805:30,error,error,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113#issuecomment-2406243805,2,['error'],['error']
Availability,"Hi, I've recently been searching for the functionalities listed above and came across this issue from 2020. Are there any updates on when these functions might potentially be available? :) Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1133#issuecomment-1739825913:175,avail,available,175,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1133#issuecomment-1739825913,1,['avail'],['available']
Availability,"Hi, Isaac,. Thank you for your reply. The matrix that I load is the output of; cellranger, we use 10X generate the library. Follow your; recommended tutorial, I can't small size it. Do you have any other; suggestions? The code is: adata = sc.read_10x_mtx(; 'D:/.../.../filtered_feature_bc_matrix/', var_names='gene_symbols',; cache=True) . Thank you so much. Best regards,. Shangyu. Isaac Virshup <notifications@github.com> 于2020年6月5日周五 上午2:31写道：. > The idea behind a self contained example is to give me something that I; > can run on my machine. Ideally you'd be able to put something together with; > randomly generated data that still gave this error. If that's difficult,; > you could keep removing elements from your data until you find the minimal; > object that can reproduce this. Here is a good blog post on how to do this; > <https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports>.; >; > Right now, I'm unable to reproduce the error you're seeing. Do you think; > you could try and create an example you could share with me? This could; > even be sharing your data as an h5ad file.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/1259#issuecomment-639309900>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ALYYCBLMIG7FAT7MMJIDC2DRVCNM3ANCNFSM4NOZJRCQ>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1259#issuecomment-640293437:649,error,error,649,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259#issuecomment-640293437,2,['error'],['error']
Availability,"Hi, It's not available in scanpy at the moment, but I wrote a wrapper for it via `rpy2` and `anndata2ri` which is available here:; https://github.com/normjam/benchmark/blob/master/normbench/methods/ad2seurat.py",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-590009483:13,avail,available,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-590009483,2,['avail'],['available']
Availability,"Hi, can you please create an issue with a minimal reproducible example?. Alternatively please add a unit test that will trigger your newly added branch. You’ll be able to see if that worked when this comment goes away:. > ![grafik](https://github.com/user-attachments/assets/46daf9ee-93c4-4576-bbcd-c1b17c090e0d). Lastly, please follow the [pre-commit instructions](https://results.pre-commit.ci/run/github/80342493/1726160235.3-pI6xDsREqRW19ZysrYpg):. > ```pytb; > src/scanpy/preprocessing/_pca.py:268:13: E722 Do not use bare `except`; > |; > 266 | try:; > 267 | pca_.partial_fit(chunk); > 268 | except:; > | ^^^^^^ E722; > 269 | continue; > |; > ```; > ; > Found 1 error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3227#issuecomment-2371113084:668,error,error,668,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3227#issuecomment-2371113084,1,['error'],['error']
Availability,"Hi, everyone, @DawnChou , @Aeget1000 , @iamsalil . I faced the same problem as well. TLDR: choose a higher `span` value in `sc.pp.highly_variable_genes`. The default is 0.3, which caused an error for me as well. 0.5 worked fine in my case. The information below might be interesting for developers or anyone who wants to understand this error more deeply. I got the error when using HLCA data. If scanpy developers are interested, I can point to the dataset to reproduce this problem. It is quite big, but I don't know any other example yet. The error is caused by [this line](https://github.com/scverse/scanpy/blob/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_highly_variable_genes.py#L84C20-L84C20). I got it when selecting HVGs by ""dataset"" batch key in HLCA. Batch ""Sims_2019"" caused the problem. Surprisingly, relationships between `mean` and `var` as well as between `x` and `y` seemed ok:. ![mean_var_relationship](https://github.com/scverse/scanpy/assets/35199218/c3462393-acb5-40fd-80eb-0a45172adce9). ![x_y_relationship](https://github.com/scverse/scanpy/assets/35199218/00e0f6e4-c7d9-4a3d-aeb3-655f185f4f0e). However, something was still causing the problem. I tried to locate the error in the[ loess calucation](https://github.com/has2k1/scikit-misc/blob/269f61e722f81c5bfea964b80b3c20871f2ffe22/skmisc/loess/src/_loess.pyx#L919) in the original package but did not succeed. Anyway, this is a bit out of the scope of scanpy. Setting `span` to a higher value (0.5) solved the problem for me. If there is no strong argument against it, I suggest changing the default value from 0.3 to 0.5. By the way, there is another potential bug in [this function](https://github.com/scverse/scanpy/blob/27e5f1fa62ec05ee9db0dfa7a9decbf8f25caa31/scanpy/preprocessing/_highly_variable_genes.py#L84C20-L84C20). If all the values are constant and `not_const` only consists of False, kernel dies when trying to run `model.fit()`. Maybe it is prevented previously, but in case it isn't, you m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2669#issuecomment-1768365664:190,error,error,190,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669#issuecomment-1768365664,4,['error'],['error']
Availability,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3261#issuecomment-2376233635:97,error,error,97,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261#issuecomment-2376233635,4,['error'],['error']
Availability,"Hi, please provide the data you use, otherwise this is not reproducible:. ```pytb; FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '\external/CytAssist_FFPE_Human_Lung_Squamous_Cell_Carcinoma_filtered_feature_bc_matrix.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2778#issuecomment-1845023488:265,error,error,265,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2778#issuecomment-1845023488,1,['error'],['error']
Availability,"Hi, sorry for the delay, sure,. I have my adata object and let's say a key 'group' in the annotation that can either be A or B for each cell, and then I do:; sc.tl.rank_genes_groups(adata, groupby='group', n_genes=1000). As a result, from the object attributes I can get the tables of DE genes, so I get a table for group A vs rest (which is only group B in this case) and for group B vs rest (which is only group A). Both of these lists contain both upregulated and downregulated DE genes, but are not symmetrical. Let me know if this is unclear. . Thank you. . Sincerely, ; Anna Arutyunyan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/919#issuecomment-555278819:467,down,downregulated,467,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/919#issuecomment-555278819,1,['down'],['downregulated']
Availability,"Hi, thanks again for your interest in GLM-PCA. We welcome its inclusion in scanpy, but some caveats are that it is about 10x slower than PCA and we are still working to improve its numerical stability and ability to handle sparse data matrices. . With that in mind, we have put together an implementation of [Pearson and deviance residuals](https://github.com/kstreet13/scry/blob/master/R/nullResiduals.R) as an approximation to GLM-PCA via the [scry R package](https://github.com/kstreet13/scry). These residuals, based on binomial and poisson approximation to multinomial, can be computed in closed form so they are computationally as fast as log-transforming. The sctransform method uses a negative binomial likelihood which doesn't have a closed form solution and is more complicated to implement (although we do recomment it from a statistical validity standpoint). . In addition to the null residuals, the scry package has an implementation of [feature selection via deviance](https://github.com/kstreet13/scry/blob/master/R/featureSelection.R), which may also be of interest as an alternative to highly variable genes. This is also a closed form computation. Both the feature selection and null residuals functions allow adjusting for categorical batch labels. I do hope to implement both of these in python eventually but it's pretty far down my to-do list. Given the functions are fairly simple, I welcome anyone to go ahead and copy them into python if they find it potentially useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-593125190:1346,down,down,1346,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/868#issuecomment-593125190,1,['down'],['down']
Availability,"Hi, thanks for the suggestion! Are you referring to [this function](https://rdrr.io/bioc/batchelor/man/multiBatchPCA.html) ?; It sounds a bit like `ingest` but with multiple datasets, pinging @Koncopd to see what's his take on this",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1289#issuecomment-660090356:184,ping,pinging,184,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289#issuecomment-660090356,1,['ping'],['pinging']
Availability,"Hi, thanks for your answer. How do you remove a graph slot from a Seurat object? When I try, I get this error:; ```; > dataset@graphs <- NULL; Error in (function (cl, name, valueClass) : ; assignment of an object of class “NULL” is not valid for @‘graphs’ in an object of class “Seurat”; is(value, ""list"") is not TRUE; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/598#issuecomment-487517773:104,error,error,104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487517773,2,"['Error', 'error']","['Error', 'error']"
Availability,"Hi, this is fixed on master. You can temporarily downgrade scipy to avoid this error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1313#issuecomment-656318884:49,down,downgrade,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313#issuecomment-656318884,2,"['down', 'error']","['downgrade', 'error']"
Availability,"Hi, was it just fixed? If I clone right now, will I not have to downgrade scipy?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1313#issuecomment-656337276:64,down,downgrade,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313#issuecomment-656337276,1,['down'],['downgrade']
Availability,"Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb. You can use `scanpy` directly on the `AnnData` objects that are parsed.; For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. . Hope this helps 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2973#issuecomment-2033480485:360,down,download,360,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973#issuecomment-2033480485,1,['down'],['download']
Availability,"Hi,. Can I ask if you are using the data from the tutorial? If not, then there are a a few potential sources of error here:; 1. You may have not aligned against the mitochondrial genome (Cell Ranger versions < 2.0 don't do this); 2. You may have mouse data, in which case it should be lower case `mt-` instead of `MT-`.; 3. Your data may have been pre-processed to take out mitochondrial genes. I recall looking through quite a few datasets where there were really no mitochondrial genes. Scanpy doesn't automatically filter out mitochondrial genes. You could also check if you have any mitochondrial genes by just outputting this line: `adata.var_names.str.startswith('MT-')`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/639#issuecomment-491470751:112,error,error,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/639#issuecomment-491470751,1,['error'],['error']
Availability,"Hi,. Check your `sc.pp.pca()` results. This is normally the origin of the differences. If you use `svd_solver='arpack'` it's more reproducible between systems (and more robust in general), but there will still be some differences due to the underlying numeric libraries.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/681#issuecomment-499118751:169,robust,robust,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/681#issuecomment-499118751,1,['robust'],['robust']
Availability,"Hi,. Currently using covariates in `sc.tl.rank_genes_groups()` is not implemented. In the Wilcoxon and t-test versions this is also not possible. However, in logistic regression this could be added. As a coarse approximation you could correct for batch using `sc.pp.combat()` and then use the corrected data instead of `adata.raw` (which is the default) to calculate marker genes. However, generally I would not recommend performing statistical analysis on batch-corrected data for other tests. Regarding your `anndata2ri` error... you could also check `adata.var` columns to see if any are categorical, but numeric.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/691#issuecomment-502549720:523,error,error,523,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/691#issuecomment-502549720,1,['error'],['error']
Availability,"Hi,. First, the error that you are reporting has to do with series types of the dataframes. Howerver, it's very difficult to provide inputs, because it's unclear what `database` and `groupA` are. Can you report a reproducible example? Also, can you update to scanpy 1.6?. Thank you",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1426#issuecomment-706535883:16,error,error,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1426#issuecomment-706535883,1,['error'],['error']
Availability,"Hi,. I get the same error that OP posted. I have the latest versions of both scanpy and anndata. When I run it locally on my Jupyter notebook there is no error and it works but when I run it on Jupyter lab I get that error. How should I go about fixing this ?. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/727#issuecomment-1159774050:20,error,error,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/727#issuecomment-1159774050,3,['error'],['error']
Availability,"Hi,. I have modified version 1.4, but i think git only allow latest version to; fork. Is there any other simple way, so that i can share my code for Scanpy; version 1.4. Thanks,; Khalid. On Sat, May 4, 2019 at 2:26 AM Philipp A. <notifications@github.com> wrote:. > seems like you did something wrong. the commit you added (74540cc; > <https://github.com/theislab/scanpy/commit/74540cc133ca9cfe0744ca9d3b250454a76a9c4d>); > reverts a lot of changes we made since.; >; > i assume you just copied all your code over the current master branch, and; > not the version of the master branch as it was when you made the changes.; >; > you need to find the version of scanpy that you downloaded before you made; > your changes and modify that one to have just the changes you want to; > commit. otherwise we have no idea what your actual changes are.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/630#issuecomment-489194292>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOBLBVFOZLO23ZCULELPTR7U3ANCNFSM4HKUCBXA>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/630#issuecomment-492076397:676,down,downloaded,676,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/630#issuecomment-492076397,1,['down'],['downloaded']
Availability,"Hi,. Is your `mito_genes` vector all boolean? And does it have a non-zero sum? You seem to be getting NA values according to the error I guess.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/647#issuecomment-492964767:129,error,error,129,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/647#issuecomment-492964767,1,['error'],['error']
Availability,"Hi,. The issues I was mostly running into were that when saving the anndata; variable as a h5ad file, 'pheno_jaccard_ig' was not compatible with this; action. So, I had to either remove pheno_jaccard_ig from the anndata object; and then save it as h5ad or convert it to a sparse matrix. This also; happened with a few other functions I tried on the anndata object, and I; kept getting the error ""this function is not compatible with COO matrix; format"", always talking about pheno_jaccard_ig. Therefore, since a sparse; matrix object does not have any problems with the functions I was running; on adata, changing pheno_jaccard_ig to a sparse matrix from the start makes; sense to circumvent any of those issues I was getting before. I hope this makes sense.; Thank you,; Deena Shefter. On Wed, Jul 27, 2022 at 6:10 PM Lukas Heumos ***@***.***>; wrote:. > Hi,; >; > could you please provide more details? What issues did you run into?; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/scverse/scanpy/pull/2295#issuecomment-1197424392>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AMILUOEK7J64GU3YOR7DB53VWGXULANCNFSM534YT5ZA>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2295#issuecomment-1274299180:389,error,error,389,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2295#issuecomment-1274299180,1,['error'],['error']
Availability,"Hi,. This bug report may be better placed in the single-cell-tutorial repo as you're having issues with how the tools are chained. A few things to check:; - Are you using sparse matrices in your data?; - are the size factors you get all real numbers (not `NaN`)?. I've seen this error before... just can't remember what the issue was. I think it was sparse matrices.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/641#issuecomment-491765979:279,error,error,279,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/641#issuecomment-491765979,1,['error'],['error']
Availability,"Hi,. This might have to do with scipy 1.3.0. If you downgrade to 1.2.1 this should work for the moment. Scipy 1.3.0 compatibility is being fixed atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/695#issuecomment-503465544:52,down,downgrade,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/695#issuecomment-503465544,2,['down'],['downgrade']
Availability,"Hi,. We get this error without swapping axes:. The code is ; ```; genes = [""DES"", ""CD34"", ""COL1A1""]; sc.pl.stacked_violin(adata, genes, groupby = ""leiden_0.1"", ); ```; The error is ; ```; IndexError Traceback (most recent call last); <ipython-input-35-8f09494e5255> in <module>; ----> 1 sc.pl.stacked_violin(adata, genes, groupby = ""leiden_0.1""). ~/anaconda3/lib/python3.6/site-packages/scanpy/plotting/anndata.py in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, figsize, dendrogram, var_group_positions, var_group_labels, var_group_rotation, layer, stripplot, jitter, size, scale, order, swap_axes, show, save, row_palette, **kwds); 929 axs_list.append(ax); 930 ax = sns.violinplot('variable', y='value', data=df, inner=None, order=order,; --> 931 orient='vertical', scale=scale, ax=ax, color=row_colors[idx], **kwds); 932 ; 933 if stripplot:. IndexError: list index out of range; ```. However, I would still consider the addition because in many cases where the amount of genes is considerable, if the user wants the genes to be in the rows, `swap_axes = True` should be necessary, and they would not be able to color the violins according to the clusters of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/465#issuecomment-461450618:17,error,error,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/465#issuecomment-461450618,2,['error'],['error']
Availability,"Hi,. You could just create a new `.obs` variable with the two groups and the perform `sc.tl.rank_genes_groups()` over this variable. For example, you could do something like this:. ```; adata.obs['groups'] = ['group 1' if int(i) < 9 else 'group 2' for i in adata.obs['louvain']]; sc.tl.rank_genes_groups(adata, groupby='groups', key_added='group_DE_results'); ```. as there are only two groups the top-ranked genes for either groups will be the up-regulated genes in that group (and down-regulated in the other group) that are most differentially expressed between the groups. . You should however note that `rank_genes_groups` is not a particularly sensitive test for differential gene expression. While it is good for a quick exploratory analysis, other tools like limma or MAST may give you more DEG results.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/397#issuecomment-447140464:483,down,down-regulated,483,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/397#issuecomment-447140464,1,['down'],['down-regulated']
Availability,"Hi,. please format your code and the error.; Also, please provide a more in depth description. What were you trying to do? A minimal example helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1951#issuecomment-882743129:37,error,error,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951#issuecomment-882743129,1,['error'],['error']
Availability,"Hi,. thanks for the input and the nice description. Agree that this would be nice to have within scanpy itself. And agree, as you’ve shown in your example, that this should be the case when setting `copy=True`. I have set up a draft PR for the moment, with a suggestion where the error message especially persists when `copy=False`; I’d suggest to keep it this way:. - Overwriting the backed file seems not to be the expected behaviour to me; - Writing a new file for backing would occur in a rather hidden manner, confusing the user or even unexpectedly further fill the disk at worst over time",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2495#issuecomment-1683604054:280,error,error,280,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495#issuecomment-1683604054,1,['error'],['error']
Availability,"Hi,; I converted the obs and values in string and it worked.; Thanks. On Mon, 29 Jul 2019 at 06:59, Isaac Virshup <notifications@github.com>; wrote:. > Hi. I just tried running that, and wasn't able to reproduce that error.; > Here's what I ran:; >; > import scanpy as sc; >; > adata = sc.datasets.pbmc3k(); > sc.pp.filter_genes(adata, min_counts=1); > sc.pp.log1p(adata); > sc.pp.highly_variable_genes(adata, min_mean=0.0001, max_mean=3, min_disp=0.5); > sc.pl.highly_variable_genes(adata); > adata = adata[:, adata.var['highly_variable']]; >; > Could you update to the latest releases (scanpy 1.4.4, anndata 0.6.22); > and try that?; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/747?email_source=notifications&email_token=ACPDY4U77PLSKFM4ZNQRBYLQBZ2LBA5CNFSM4IG2HWJ2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD27SWAA#issuecomment-515844864>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACPDY4VLMX7TXWMWLRDBTPLQBZ2LBANCNFSM4IG2HWJQ>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/747#issuecomment-516115061:217,error,error,217,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/747#issuecomment-516115061,1,['error'],['error']
Availability,"Hi,; I tried to set the y-axis limit, but failed with the error:. >>> axes = sc.pl.stacked_violin(adata, marker_genes, groupby='cell_types', rotation=90,swap_axes=True,row_palette='muted',yticklabels=True,show=False); >>> for ax in axes:; ... ax.set_ylim(0, 5); ...; Traceback (most recent call last):; File ""<stdin>"", line 2, in <module>; AttributeError: 'str' object has no attribute 'set_ylim'. I use scanpy 1.8.1.; Do you have any idea? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/386#issuecomment-921089934:58,error,error,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/386#issuecomment-921089934,1,['error'],['error']
Availability,Hi. I can’t copy/paste/run the above code sample. There’s nowhere you define `adata`. Please add some code that uses some builtin dataset or so and reproduces the error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1367#issuecomment-673941590:163,error,error,163,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1367#issuecomment-673941590,1,['error'],['error']
Availability,"Hi. I just tried running that, and wasn't able to reproduce that error. Here's what I ran:. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k(); sc.pp.filter_genes(adata, min_counts=1); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, min_mean=0.0001, max_mean=3, min_disp=0.5); sc.pl.highly_variable_genes(adata); adata = adata[:, adata.var['highly_variable']]; ```. Could you update to the latest releases (scanpy `1.4.4`, anndata `0.6.22`) and try that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/747#issuecomment-515844864:65,error,error,65,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/747#issuecomment-515844864,1,['error'],['error']
Availability,"Hi. I'm struggling with the same issue that is not resolved with the suggestions above (using other scipy version==1.2.1). I have scanpy==1.6.0 and scipy==1.5.2 in my environment. I am using Ubuntu in Windows. And when I import scanpy in jupyter notebook, I get the error:. **`ImportError: cannot import name 'IndexMixin' from 'scipy.sparse.sputils' (/home/levinbioinformatics/anaconda3/envs/scgen-env/lib/python3.7/site-packages/scipy/sparse/sputils.py)`**. Please advise!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/643#issuecomment-691921390:266,error,error,266,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/643#issuecomment-691921390,1,['error'],['error']
Availability,"Hi. Please see below for the minimal script used. Thanks!. ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scvelo as scv; import matplotlib.pyplot as plt; from pathlib import Path. scv.settings.set_figure_params('scvelo'). sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.settings.autosave = True; sc.settings.autoshow = False; sc.set_figure_params(scanpy=True, dpi=80, dpi_save=160, frameon=False, vector_friendly=False, format='pdf'). adata = sc.read_loom(""./Velocyto_comb.loom""). sc.pp.filter_cells(adata, min_genes=1000); sc.pp.filter_genes(adata, min_cells=10). print('\nDoing initial filtering...\nKeeping', len(adata.obs_names), 'cells and', len(adata.var_names), 'genes.\n'). mito_genes = adata.var_names.str.startswith('MT-'); # Calculate the percent of genes derived from mito vs genome; # the `.A1` is only necessary as X is sparse (to transform to a dense array after summing); adata.obs['percent_mito'] = np.sum(; 	adata[:, mito_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1; # add the total counts per cell as observations-annotation to adata; adata.obs['n_counts'] = adata.X.sum(axis=1).A1. sc.pl.violin(adata, ['n_genes', 'n_counts', 'percent_mito'],; 			 jitter=0.4, multi_panel=True, save = '_preFiltering_plot.pdf', show = False); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/567#issuecomment-478651835:294,error,errors,294,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/567#issuecomment-478651835,1,['error'],['errors']
Availability,"Hm, I researched a bit more. psutil doesn't seem to cause problems and also, this has not been a problem within Scanpy for any user up to now. If you start a terminal with `python` and type; ```; import psutil; psutil.process_iter(); ```; does this throw an error? I'd really like to know what's going on. If you want a quick fix; you can simply comment out line 773 in your file `/ifs/devel/hashem/sw-v1/conda/lib/python3.6/site-packages/scanpy/readwrite.py`; this should cause no problem for your applications.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35#issuecomment-324476821:258,error,error,258,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35#issuecomment-324476821,1,['error'],['error']
Availability,"Hm, PyTorch 1.12.1 doesn’t seem to be available, otherwise I was able to install all package versions you specified. I created an attempt at a reproducer here, but it just runs in less than a second for me: https://github.com/flying-sheep/scanpy-2531. No idea how to further debug this. Looks like you’re on macOS. one of the new M1 or M2 ones?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2531#issuecomment-1609286107:38,avail,available,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531#issuecomment-1609286107,1,['avail'],['available']
Availability,"Hm, but it looks like https://scanpy.readthedocs.io/en/latest/api/scanpy.api.tl.score_genes.html should be reproducible with the default settings. In what you describe, only pca, louvain and umap have stochastic elements all of which set a default seed in the function call. I have never observed issues with reproducibility there. Can we narrow it down to score_genes? Or do you think it's somewhere else?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/313#issuecomment-431367763:349,down,down,349,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/313#issuecomment-431367763,1,['down'],['down']
Availability,"Hm, looking at the errors, they don't seem to be really related to the changes in this PR, no?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2140#issuecomment-1041473484:19,error,errors,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2140#issuecomment-1041473484,1,['error'],['errors']
Availability,"Hm, strange, the notebook is in the tests... I also just ran it through myself, manually, everything got me exactly the same results as available online: my versions are; ```; scanpy==1.3.7+86.g2c80c7a anndata==0.6.17+1.ga0cd0c6 numpy==1.14.6 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.19.1 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 ; ```. Could it be that you're using an older anndata or scanpy or something? I think I added the notebook to the tests around Scanpy 1.3 or so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/445#issuecomment-457346216:136,avail,available,136,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/445#issuecomment-457346216,1,['avail'],['available']
Availability,"Hm, strange; how did you manage to obtain integer cluster names? Did you manually rename them? `adata.obs['louvain_groups'].cat.categories` should always be strings. If you use integers, you should also pass `reference=18` and not `reference='18'`. But the use of integers is strongly discouraged and probably not stable... I only could reproduce a similar error when running `sc.tl.rank_genes_groups(adata, 'louvain_groups', groups=['0'], reference='9')` in the [clustering example notebook](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb):. ```pytb; ValueError: reference = 9 needs to be one of group_by = ['0', '1', '2', '3', '4', '5', '6', '7'].; ```. PS: The error is raised by the following. ```py; if (reference != 'rest' ; and reference not in set(adata.obs[group_by].cat.categories)): ; raise ValueError('reference = {} needs to be one of group_by = {}.' ; .format(reference, ; adata.obs[group_by].cat.categories.tolist())); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/94#issuecomment-369132536:357,error,error,357,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/94#issuecomment-369132536,2,['error'],['error']
Availability,"Hm, there’s something messed up with the test runner. It fails these tests:. ```; scanpy/tests/test_embedding_plots.py::test_visium_circles FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variab",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:930,ERROR,ERROR,930,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,"Hm, this is really strange. Sorry about this. The docker image might be out-of-date now - you compiled, @flying-sheep, what do you think?. But you shouldn't need the docker image to exactly reproduce the results. Which versions do you run?. The latest version of the tutorial says; ```; scanpy==1.0.2 anndata==0.5.8 numpy==1.14.1 scipy==1.0.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 python-igraph==0.7.1 louvain==0.6.1 ; ```. Your error is a Pandas error - do you run an older or more recent version of Pandas that might cause the problem?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/158#issuecomment-390636495:446,error,error,446,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158#issuecomment-390636495,2,['error'],['error']
Availability,"Hm. the conda package doesn’t list availability for windows: https://anaconda.org/bioconda/scanpy, just “conda install linux-64 v1.3.7, osx-64 v1.3.7”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-462259888:35,avail,availability,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-462259888,1,['avail'],['availability']
Availability,"Hmm, that sounds like the code is trying to do something like `['a', 'b'] * 1.5`, i.e. repeating a sequence by multiplying. But the line the error points to looks correct: `np.multiply` should try to do element-wise multiplication as intended. Please create a minimal reproducible example. We don’t know what in `slide` causes the bug because we don’t know what it is.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2499#issuecomment-1588980574:141,error,error,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2499#issuecomment-1588980574,1,['error'],['error']
Availability,"Hmm, weird that it didn't fail against master. Also that I forgot to back port the nice plot errors to 1.7.x. TODO: https://github.com/theislab/scanpy/pull/1587#issuecomment-787808128",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1699#issuecomment-787809506:93,error,errors,93,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1699#issuecomment-787809506,1,['error'],['errors']
Availability,"Hmm. I'm not able to replicate the exact error, but I get a different one. Could you try running:. ```python; adata = adata.copy(); ```. right before `normalize_total` and see if that works?. ----------------------. Update: tried on a different machine and could replicate your error. The issue is that `normalize_total` doesn't make sure the anndata object isn't a view before assigning to it. As a work-around, you can just run `adata = adata.copy()` before `sc.pp.normalize_total(adata)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1183#issuecomment-621000991:41,error,error,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183#issuecomment-621000991,2,['error'],['error']
Availability,"Hmm... you are right, that should also create an error by the above logic. It does look like this check is done for the case that `adata.n_vars < n_comps` here:; https://github.com/theislab/scanpy/blob/be1a0555252cfd97b9d00f51dc5fbab462588da0/scanpy/preprocessing/_simple.py#L472-L477. I'm not sure why that wasn't also done for `n_obs`. @Koncopd you made this fix at the time... any reason for not also checking `adata.n_obs` in the same way? Could quickly add a check for `adata.n_obs` unless there is a reason not to @ivirshup, @flying-sheep?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1051#issuecomment-586494795:49,error,error,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051#issuecomment-586494795,1,['error'],['error']
Availability,"Hmm...I must admit I don't understand why a ""view"" exists. Views are often tricky to get right, especially in a complex datastructure like anndata. They also slow down processing, especially if users may not be aware that the object they have is a view of something else. I don't see a good use case for views in my pipeline at least. Is there a way to switch off all views in anndata and just return a copy when slicing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/728#issuecomment-516291062:163,down,down,163,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728#issuecomment-516291062,1,['down'],['down']
Availability,"Hmmm, you got it to successfully run? The last thing I had posted was failures in testing (see above)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-367706813:70,failure,failures,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-367706813,1,['failure'],['failures']
Availability,Hmmm. I am getting this error with scipy 1.4.1. New install of phenograph so I don't have an older version to roll back to. Hopefully they fix this soon!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1407#issuecomment-699501883:24,error,error,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1407#issuecomment-699501883,1,['error'],['error']
Availability,"Honestly a bit lost elsewise. Think that what is shown above is only a Numba warning, but not an error. Not sure what kills the kernel... Anybody else has an idea @scverse/scanpy ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2359#issuecomment-1291786208:97,error,error,97,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359#issuecomment-1291786208,1,['error'],['error']
Availability,"Hopefully last update on this PR. What I did:; - I noticed a regression on the method `rank_genes_groups_violin`, therefore I reverted back the code to the original one and I added an additional method `genes_groups_violin` which should be used if we want to pass the list of genes directly to the violin plot. The code is just a POC, but maybe it can be integrated; - Within the same method `rank_genes_groups_violin`, I found a bug: the ax variable was overwritten for each group (I don't know if it gave you error before). In my case, all the plots were merged into a single figure, every one on top of the previous ones; - Additionally, the parameters `gene_symbols` and `computed_distribution` were not defined within the method `rank_genes_groups_violin`. I added a default parameter (`None`) for `gene_symbols`, since it was defined in the docstring. With `computed_distribution` I didn't know what you wanted to do so I temporarily commented the line that used it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/141#issuecomment-387106636:511,error,error,511,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/141#issuecomment-387106636,1,['error'],['error']
Availability,"How about MultiIndex?; ```python; df = adata.var.reset_index().set_index(['gene_ids', 'index']); adata2 = sc.AnnData(X = adata.X, var = df); ```. user can subset genes based on:; ```python; genes = ['CD69', 'CD44', 'CXCR5']; idx = adata2.var.index.get_level_values('index').isin(genes); adata2[:,idx]; ```. Seems to initialize ok but throws an issue with `get.py` line 139 when trying to plot with `sc.pl.violin`:; ```python; genes2 = adata2[:,idx].var.index; sc.pl.violin(adata2, genes2). ## error; gene_names = pd.Series(adata.var_names, index=adata.var_names); ```; `initializing a Series from a MultiIndex is not supported`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1719#issuecomment-793798821:493,error,error,493,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719#issuecomment-793798821,1,['error'],['error']
Availability,"How about a `check_values` argument which defaults to `True`, and replacing the error with a warning like:. ""Your data doesn't appear to be have integer values, but this method expects raw count data. Proceed with caution."". `check_values` is nice and generic, and could be used in other functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1642#issuecomment-777188844:80,error,error,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1642#issuecomment-777188844,1,['error'],['error']
Availability,How are the download speeds/ hosting for figshare? Do they mirror to different regions? I recall some painful download times from Australia. It's also probably pretty stable. Could also use `scverse.org` for permanent URIs?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2124#issuecomment-1025836805:12,down,download,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124#issuecomment-1025836805,2,['down'],['download']
Availability,"How did you installed scanpy?. Try:. conda install --file requirements.txt. this may install all the right versions of the packages that you need. On Thu, Oct 4, 2018 at 2:26 AM ar-baya <notifications@github.com> wrote:. > Hi, I am reproducing this tutorial; > https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170503_zheng17/zheng17.ipynb; >; > the line sc.pp.neighbors(adata) produces the following error:; >; > Inconsistency detected by ld.so: dl-version.c: 205:; > _dl_check_map_versions: Assertion `needed != NULL' failed!; >; > Ubuntu 18.04; > Python 3.6.6; >; > scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4; > scikit-learn==0.19.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1; >; > Can you help me? Thank You; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/280>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1Sgm2UxCRL2y2-EGlah7YmtIrmmeks5uhVXGgaJpZM4XHKo6>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/280#issuecomment-426896350:421,error,error,421,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280#issuecomment-426896350,1,['error'],['error']
Availability,How to avoid the 'HTTP Error 403: Forbidden' exactly? I reinstalled scanpy and still have this issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1334#issuecomment-705184936:23,Error,Error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334#issuecomment-705184936,1,['Error'],['Error']
Availability,"How? As said, they’re just for people and IDEs. Scanpy doesn’t use them. It doesn’t throw errors in case something doesn’t fit. We could use https://pypi.org/project/typecheck-decorator/ to throw errors when something is passed that doesn’t fit the annotations. However, doing so has a performance hit and requires flawless annotations (because if the annotations were wrong, that *would* start suddenly throwing errors). I’m just adding type annotations to improve user friendliness by being more clear what functions accept, and because it makes writing documentation easier.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-441252542:90,error,errors,90,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-441252542,3,['error'],['errors']
Availability,"Huh. This is really weird, since it looks like it's almost entirely due to scipy sparse indexing. Must have something to do with versions. Two things:. * If you upgrade scipy, do you still run into this error?; * Could you get the version info from an environment where you've only imported scanpy and run this command?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1670#issuecomment-783074166:203,error,error,203,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670#issuecomment-783074166,1,['error'],['error']
Availability,"I addressed some of the points in your review already and will finish latest on Monday :). > > tests that check if combinations of input arguments lead to expected output (in terms of returned shapes/columns/...) and don't break the function; > > tests that check if warnings/errors are raised for ""common mistakes"" (inappropriate data, nonsense input argument combinations..); > ; > yes both makes sense, it would also be useful to come up with a dummy example for which the actual output could be tested against. This is done in seurat_v3 for instance, but in that case it's kind of straightforward because the ""expected"" is the output computed with original implementation (and as you catched in #1732 it's still might not be enough smile ).; > another random thing that comes to mind re this specific case is to make sure that indexing etc. is consistent and robust, as you seem to have to sort and resort a fair bit in the hvg implementation. Sounds good, thanks for the input! I will prepare some tests early next week.; ; > on another note, I was thinking if it makes sense to also release a short tutorial together with the PR (that would be on theislab/scanpy_tutorials) ? I think that for a lot of people the term ""pearson residuals"" could be alienating, and so they'd rather stick to `normalize_total` for comfort (but they shouldn't!). So maybe just something easy like pearson res norm + umap and hvg plots ? curious to hear what you and the others @ivirshup @LuckyMD think about it. I think that would be really nice - I'd very happy prepare to some examples if everyone agrees that this would be useful to have :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-797689998:276,error,errors,276,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-797689998,2,"['error', 'robust']","['errors', 'robust']"
Availability,"I also encountered this h5py dll error on a Windows 10 machine when trying to install scanpy. Fixed following these instructions, followed by `pip install numpy==1.20` due to a subsequent numpy version conflict with numba. > > In case anyone has this error again, here is what worked for me:; > > ; > > * go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; > > * with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; > > * scanpy should work now; > > ; > > This worked on mine and also on a colleagues windows laptop.; > > I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users.; > ; > this helped me out as well",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040:33,error,error,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-1018430040,5,"['down', 'error']","['download', 'downloaded', 'error']"
Availability,"I also experienced this a few times, and took me some time to understand what is going on. I fully agree with @ivirshup, we should improve the error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1504#issuecomment-748161925:143,error,error,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504#issuecomment-748161925,1,['error'],['error']
Availability,I also got the similar error. ![image](https://user-images.githubusercontent.com/49429496/66826207-8652c580-ef7e-11e9-9168-5c19aa666354.png); ![image](https://user-images.githubusercontent.com/49429496/66826292-bd28db80-ef7e-11e9-801e-1d2dfbf01cb8.png),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/757#issuecomment-542159460:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757#issuecomment-542159460,1,['error'],['error']
Availability,I also have encountered this same error when trying to use sc.pl.violin,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2680#issuecomment-1757262413:34,error,error,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680#issuecomment-1757262413,1,['error'],['error']
Availability,"I also have the same problem and I tried to use `pip install louvain`, but I cannot install the package and it says `legacy-install-failure`. The GitHub for the [louvain](https://github.com/vtraag/louvain-igraph/tree/master) says,. > Warning; > ; > This package has been superseded by the [leidenalg](https://github.com/vtraag/leidenalg) package and will no longer be maintained.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1283#issuecomment-1637853756:132,failure,failure,132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1283#issuecomment-1637853756,1,['failure'],['failure']
Availability,I also just tried to run on a Windows machine (to make sure it was not just something to do with the memory management in my Linux machine which has 128GB RAM) with 64GB RAM and 6 cores @3.6GHz and also get Memory error at the normalization step when trying to process the 1.3M neuron file.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/511#issuecomment-469746553:214,error,error,214,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511#issuecomment-469746553,1,['error'],['error']
Availability,I also saw this with `python-igraph` version 0.10. Downgrading to `0.9.9` fixed the issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2339#issuecomment-1261132252:51,Down,Downgrading,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339#issuecomment-1261132252,1,['Down'],['Downgrading']
Availability,"I always got a kernel restart when run:. `sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)`. Also my memory is enough. This error comes from pbmc3k.ipynb file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2361#issuecomment-1289062735:124,error,error,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1289062735,1,['error'],['error']
Availability,"I am also currently trying to figure out how to get around this. I am getting this error when calling `sc.pl.rank_genes_groups_violin` using a ""gene_symbols"" parameter (this function works when that parameter is omitted but the x-axis labels are not what I desire). In my case, `adata.uns[""rank_genes_groups""][""names""]` content is set to `adata.var_names` (where the index column is separate from what is being passed to the ""gene_symbols"" parameter outlined earlier). I am running anndata==0.7.8 and scanpy==1.8.2 so this issue has been around for a couple release versions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2256#issuecomment-1131777861:83,error,error,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256#issuecomment-1131777861,1,['error'],['error']
Availability,"I am also experiencing this issue. Running the following code:; ```; import pandas as pd; import scanpy as sc; import anndata. print(pd.__version__); print(sc.__version__); print(anndata.__version__); adata = sc.datasets.pbmc68k_reduced(); adata.obs[""single_cat""] = 1; adata.obs['single_cat'] = pd.Categorical(adata.obs['single_cat']); adata.write('/tmp/adata.h5ad'); sc.read('/tmp/adata.h5ad'); ```. Returns this error message:; ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-5-adde38d13544> in <module>; ----> 1 sc.read('/tmp/adata.h5ad'). /usr/local/anaconda3/envs/diffxpy/lib/python3.6/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs); 95 filename, backed=backed, sheet=sheet, ext=ext,; 96 delimiter=delimiter, first_column_names=first_column_names,; ---> 97 backup_url=backup_url, cache=cache, **kwargs,; 98 ); 99 # generate filename and read to dict. /usr/local/anaconda3/envs/diffxpy/lib/python3.6/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs); 497 if ext in {'h5', 'h5ad'}:; 498 if sheet is None:; --> 499 return read_h5ad(filename, backed=backed); 500 else:; 501 logg.debug(f'reading sheet {sheet} from file {filename}'). /usr/local/anaconda3/envs/diffxpy/lib/python3.6/site-packages/anndata/readwrite/read.py in read_h5ad(filename, backed, chunk_size); 445 else:; 446 # load everything into memory; --> 447 constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size); 448 X = constructor_args[0]; 449 dtype = None. /usr/local/anaconda3/envs/diffxpy/lib/python3.6/site-packages/anndata/readwrite/read.py in _read_args_from_h5ad(adata, filename, mode, chunk_size); 500 if not backed:; 501 f.close(); --> 502 return AnnData._args_from_dict(d); 503 ; 504 . /usr/local/anaconda3/envs/d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/102#issuecomment-566126409:414,error,error,414,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/102#issuecomment-566126409,1,['error'],['error']
Availability,"I am also getting the error `RuntimeWarning: invalid value encountered in log; dispersion = np.log(dispersion)` when running `sc.pp.highly_variable_genes(adata, min_mean=1.7, max_mean=5, min_disp=0.5, flavor='seurat')` on log scale data in the adata.X slot with mean=0 and max=16.336065. Any ideas?. Update: I just noticed that my adata.X contains a numpy array instead of a sparse matrix. Perhaps that's the issue? Will try updating to a sparse matrix and will report back",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-718294561:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-718294561,1,['error'],['error']
Availability,"I am also getting the error when running. sc.pp.neighbors(). AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32. I tried pip uninstall numba and pip install numba==0.52.0 and numba==0.51.0, but nothing works. I had umap-learn 0.4.6, and updating it resolved the issue for me:; conda install -c conda-forge umap-learn",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799#issuecomment-867004309:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799#issuecomment-867004309,1,['error'],['error']
Availability,I am also running into the same error. Thank you!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/252#issuecomment-421671797:32,error,error,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/252#issuecomment-421671797,1,['error'],['error']
Availability,"I am also unable to install scanpy on mac OS. I tried using python 3.8.x . 3.7.x and 3.6.x. ```; (base) $ conda activate SCA. (SCA) $ conda --version; conda 4.8.2. (SCA) $ python --version; Python 3.6.10 :: Anaconda, Inc. (SCA) $ conda install -c bioconda scanpy; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \ ; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versions; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1142#issuecomment-609514112:679,Avail,Available,679,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142#issuecomment-609514112,1,['Avail'],['Available']
Availability,I am attaching reduced files. I could reproduce the error with this dataset. Color names are `colors_dataset.txt` file. Note that python script is renamed to `.py.txt` . There was an error in `paga` related plotting function as well. . [R_pca_seurat.txt](https://github.com/theislab/scanpy/files/2455948/R_pca_seurat.txt); [R_annotation.txt](https://github.com/theislab/scanpy/files/2455949/R_annotation.txt); [colors_dataset.txt](https://github.com/theislab/scanpy/files/2455950/colors_dataset.txt); [planaria.py.txt](https://github.com/theislab/scanpy/files/2455953/planaria.py.txt),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/286#issuecomment-427822048:52,error,error,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286#issuecomment-427822048,2,['error'],['error']
Availability,I am encountering the same error. Have you fixed it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2669#issuecomment-1733630090:27,error,error,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669#issuecomment-1733630090,1,['error'],['error']
Availability,"I am experiencing a similar issue with a dataset I am using. This runs fine:; ```; variable_genes_min_mean = 0.01; variable_genes_max_mean = 5; variable_genes_min_disp = 0.5. sc.pp.filter_genes_dispersion(adata_gex, ; min_mean=variable_genes_min_mean, ; max_mean=variable_genes_max_mean, ; min_disp=variable_genes_min_disp,; flavor='seurat',; log = True); ```. But this:; ```; variable_genes_min_mean = 0.01; variable_genes_max_mean = 5; variable_genes_min_disp = 0.5. sc.pp.highly_variable_genes(adata_gex, ; min_mean=variable_genes_min_mean, ; max_mean=variable_genes_max_mean, ; min_disp=variable_genes_min_disp,; flavor = 'seurat') ; ```. Throws the following error: ; ```; /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scipy/sparse/data.py:135: RuntimeWarning: overflow encountered in expm1; result = op(self._deduped_data()); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: overflow encountered in square; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_utils.py:18: RuntimeWarning: invalid value encountered in subtract; var = (mean_sq - mean**2) * (X.shape[0]/(X.shape[0]-1)); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85: RuntimeWarning: overflow encountered in log; dispersion = np.log(dispersion); /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85: RuntimeWarning: invalid value encountered in log; dispersion = np.log(dispersion); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-71-69d6424effb2> in <module>; 3 max_mean=variable_genes_max_mean,; 4 min_disp=variable_genes_min_disp,; ----> 5 flavor = 'seurat') . /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preproces",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-598826026:664,error,error,664,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-598826026,1,['error'],['error']
Availability,I am getting an error elsewhere that I want to revise before submitting a final version. Hopefully tomorrow,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/425#issuecomment-460068606:16,error,error,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/425#issuecomment-460068606,1,['error'],['error']
Availability,"I am getting the same error in a much more basic setting:; ```; paul=sc.datasets.paul15(); sc.pl.scatter(paul, x=paul.var_names[0], y=paul.var_names[1]); ```; ...; > TypeError: object of type 'numpy.int64' has no len()",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/333#issuecomment-434297999:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333#issuecomment-434297999,1,['error'],['error']
Availability,I am getting the same error. > Exception: Data must be 1-dimensional,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/598#issuecomment-487687285:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487687285,1,['error'],['error']
Availability,"I am getting this error when I run scanpy.pp.neighbors(adata); As far as I know, I have the latest packages mentioned here.; anndata 0.7.6 pypi_0 pypi; louvain 0.7.0 py38h9dedd22_1 conda-forge; pandas 1.1.3 py38hb1e8313_0; python-igraph 0.9.1 py38h3dab7cd_0 conda-forge; scanpy 1.7.2 pypi_0 pypi; scikit-learn 0.23.2 py38h959d312_0; scipy 1.6.3 py38h431c0a8_0 conda-forge; statsmodels 0.12.0 py38haf1e3a3_0; umap-learn 0.5.1 py38h50d1736_0 conda-forge. Is there probably another package that is outdated?. **EDIT: Not sure what module I updated but now it works. I use 'conda update --all' and others to do that.** . thanks",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1154#issuecomment-835038994:18,error,error,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154#issuecomment-835038994,1,['error'],['error']
Availability,"I am getting this same error, namely when I run `sc.pl.umap(adata, color='pid')` I see `UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored` and then `adata.uns['pid_colors']` all gets set to gray, and my whole UMAP plot looks gray instead of being color by 'pid.'. I am using scanpy 1.9.1 and matplotlib 3.6.3. Can someone advise me what I need to upgrade to avoid this error, or how I can work around it with my current package versions? I see that #2212 upped the required matplotlib to 3.4, but since I'm at 3.6.3 I thought I should be okay. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2208#issuecomment-1477955919:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208#issuecomment-1477955919,2,['error'],['error']
Availability,"I am more and more convinced about having a single package for the reasons @adamgayoso mentioned. To address a few concerns from above: . ---. > > Who manages the sub-packages?; > ; > Scverse (also it's one package not many). We are talking about 5-15 readers that have been touched a handful of times in 4-5 years. I don't think this is a complicated package to maintain. Agree that one person needs to take the lead on releases (probably very infrequent). Scverse core developers could take turns (e.g. every 6 months) in being ""lead maintainer"", i.e. in charge of releases and first-responders to issues (delegating them to the most appropriate people). This has the additional advantage that everything needs to be documented to a point that there can't be a single point of failure. . ---. > Also it's nice when you install a package call a function and it works, less nice to have to start mucking around with dependencies. ```; pip install scio[all]; ```. could be broadly advertised in the README. Packages could still use the slimmer version, e.g. in scirpy, I could depend on ; `scio[vdj]`. . ---. > I think there are formats where there isn't one obvious ""right way"" to represent them as an AnnData object (e.g. visium), so having a canonical reading/ writing function is difficult. I think we should aim at having one obvious ""right way"" to represent something with AnnData and MuData. A common `scio` package could be a way to achieve that. . > I know squidpy will be changing its representation and I think muon should have changes to the ATAC representation. Also muon and scvi-tools read in different things from 10x atac data. A solution to that would be versioned schemata. E.g. whatever squidpy uses now is the ""spatial schema `v1`"". When we come up with a better way it becomes the ""spatial schema `v2`"". Old schemata will be deprecated but can stick around for a while. If a schema is experimental and subject to active changes it can be `v0.1`. . ```python; scio.spatial.read_vis",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1387#issuecomment-1059727261:779,failure,failure,779,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1387#issuecomment-1059727261,1,['failure'],['failure']
Availability,"I am not so sure, but you may get that error when the matrix contains columns of only ceros. Did you do any filtering of the data before?. Fidel Ramírez . > Am 24.07.2018 um 07:51 schrieb Alex Wolf <notifications@github.com>:; > ; > Can you try running with n_jobs=1?; > ; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/212#issuecomment-407333853:39,error,error,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/212#issuecomment-407333853,1,['error'],['error']
Availability,"I am not sure what was causing this error, but it must be somewhat idiosyncratic as the issue is resolved in a fresh env. Thanks! Closing this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1275#issuecomment-654493614:36,error,error,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1275#issuecomment-654493614,1,['error'],['error']
Availability,"I am running into the same issue and unfortunately running the steps as described here https://github.com/theislab/scanpy/issues/1567#issuecomment-968181500 does not solve my problem. My kernel systematically dies when I run `sc.pp.neighbors` (even with only 1,000 cells). What I am also confused about is that this used to work - I am guessing I updated a package somewhere that broke everything but I cannot identify what. This is my config:; - MacBook Pro (13-inch, M1, 2020) - macOS Big Sur 11.5.2; - python 3.8.8; - numpy 1.20.0; - numba 0.51.2; - umap-learn 0.5.2. I have tried running the following code in Jupyter and then in a script to see if I could get more info on the bug:; ```; unhealthy_cells = sc.read_h5ad(""path/to/file""). unhealthy_cells.layers[""counts""] = unhealthy_cells.X.copy(). sc.pp.normalize_total(unhealthy_cells,target_sum=10000). sc.pp.log1p(unhealthy_cells). sc.pp.scale(unhealthy_cells). sc.tl.pca(unhealthy_cells). sc.pp.neighbors(unhealthy_cells); ```; When I run it as a python script, I get the following error when getting to `sc.pp.neighbors` (everything else works): ; `zsh: illegal hardware instruction`. Is there anything I could do? ; Thank you for your help!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1567#issuecomment-1024104927:1040,error,error,1040,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1567#issuecomment-1024104927,1,['error'],['error']
Availability,I am still getting the file not found error because when downloading it's lacking the `gz` extension. Will manually change but sharing so you are aware! @ivirshup,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/587#issuecomment-1191042470:38,error,error,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/587#issuecomment-1191042470,2,"['down', 'error']","['downloading', 'error']"
Availability,"I am still getting this error even after doing filtering. This was my code for filtering : . sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=1). Can you please help me with this ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/509#issuecomment-1079812544:24,error,error,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509#issuecomment-1079812544,1,['error'],['error']
Availability,I am surprised that this is coming out. I thought I had solved the issue as I don't get the error. Thanks @flying-sheep for addressing this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/794#issuecomment-531248281:92,error,error,92,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794#issuecomment-531248281,1,['error'],['error']
Availability,"I am using Anaconda/Jupyter in my PC. When I try to downgrade numba, I run into issues of numba dependency packages in Anaconda so I am stuck!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341#issuecomment-670191957:52,down,downgrade,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341#issuecomment-670191957,1,['down'],['downgrade']
Availability,"I am using a sampling technique, which samples few rows without descreasing; performance. So speed is more than 10X time faster for larger dataset with; similar accuracy. On Tue, May 21, 2019 at 3:37 AM MalteDLuecken <notifications@github.com>; wrote:. > I'm not sure I entirely understand what the weights are based on. I'm; > trying to understand when you would suggest someone use your approach. Why; > do you give one cell a weight of 125? With this type of weight distribution; > you are basically manually changing the marker gene calculation focusing; > nearly only on a single cell. That seems strange to me.; >; > I'm trying to understand the need for scanpy to support weighted; > observations. At the moment I don't see when you would want to differently; > weight the observations... I'm familiar with using weights if I have some; > form of measurement error or uncertainty between samples. I don't really; > see how that holds here. Do you weight the cells based on some kind of; > quality score?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGOC4EI2YTU53XEGMJI3PWL4XZA5CNFSM4HMZ5G72YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVZ3LJA#issuecomment-494122404>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOFRJXHAWVT6W4YKY63PWL4XZANCNFSM4HMZ5G7Q>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494124913:866,error,error,866,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494124913,1,['error'],['error']
Availability,I believe @fidelram isn't super available for scanpy stuff until next month. I figured we could talk about this then.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1649#issuecomment-802501619:32,avail,available,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1649#issuecomment-802501619,1,['avail'],['available']
Availability,"I believe it is, pinging @Koncopd who probably knows more about it. If this is desired behaviour, we could close this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1211#issuecomment-702374955:17,ping,pinging,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1211#issuecomment-702374955,1,['ping'],['pinging']
Availability,"I can do that. I have a pickled object that I can share with you (how?).; Here is how you reproduce the error:; ```; import scanpy.api as sc; import pickle. # Load the object; with open(""example.pkl"",""rb"") as handle:; adata = pickle.load(handle). # Run Scanpy; sc.tl.rank_genes_groups(adata,groupby=""celltype""); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/365#issuecomment-440420960:104,error,error,104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365#issuecomment-440420960,1,['error'],['error']
Availability,"I can recover the previous behavior, i.e., different runs of the notebook give identical UMAP and leiden clusters, by downgrading to scanpy version 1.9.2 (and also pandas to version 1.5.3). I do this in conda and in this environment other relevant installed package versions are numpy 1.23.5, scipy 1.10.1 and scikit-learn 1.2.2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2480#issuecomment-1531696555:6,recover,recover,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1531696555,2,"['down', 'recover']","['downgrading', 'recover']"
Availability,"I can reproduce, this is the error that I get:; ![afbeelding](https://github.com/scverse/scanpy/assets/22346363/2ea5b86b-31f8-42ba-a2f7-c536168222a7). From a first glance it seems like the default for randint is used which is `int32`. I can check whether switching to `int64` fixes the issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2041118729:29,error,error,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2041118729,1,['error'],['error']
Availability,"I copied your code to a google colabs instance and ran into a Type Error similar to the one above:; https://colab.research.google.com/drive/1LYxOAuNqaJHGfRjNjyluUHk9BFsmkWa4?usp=sharing . Error message:; ```; TypeError Traceback (most recent call last); <ipython-input-3-9abce68d1753> in <module>(); 4 sc.tl.dpt(adata); 5 sc.tl.paga(adata, groups='paul15_clusters'); ----> 6 sc.pl.paga_path(adata, nodes=['1Ery'], keys=['Gata2', 'Btg2', 'Btg1']). 5 frames; /usr/local/lib/python3.6/dist-packages/matplotlib/image.py in set_data(self, A); 697 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):; 698 raise TypeError(""Invalid shape {} for image data""; --> 699 .format(self._A.shape)); 700 ; 701 if self._A.ndim == 3:. TypeError: Invalid shape (3, 43, 1) for image data; ```. Versions: ; ```; scanpy==1.7.0 ; anndata==0.7.5 ; umap==0.5.0 ; numpy==1.19.5 ; scipy==1.4.1 ; pandas==1.1.5 ; scikit-learn==0.22.2.post1 ; statsmodels==0.10.2 ; python-igraph==0.8.3 ; leidenalg==0.8.3; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953#issuecomment-778212671:67,Error,Error,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953#issuecomment-778212671,2,['Error'],['Error']
Availability,"I definitely don't define the consensus, but I normally prefer FDR correction. It makes a bit more sense to me to correct for a false discovery rate, rather than a test-based error, if you are only interested in the rejected null hypotheses. . They also test for FDR control in a [recent comparison of differential testing methods](http://www.nature.com/doifinder/10.1038/nmeth.4612).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/289#issuecomment-428239213:175,error,error,175,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289#issuecomment-428239213,1,['error'],['error']
Availability,"I did a little more looking into this, and think I see what's going on. If you set the host, it sends a query to the host to make sure it's real. If it doesn't get a 200 response, it silently fails and does not set the host. Every time I've checked, `www.ensembl.org` returns some `30*` code, which is a redirect, and would successfully fill any query anyways. `asia.ensembl.org` might have actually been down when I was checking, but it might be worth updating the docs that this probably won't work with `www.ensembl.org`. Also I'm pretty sure setting the host at instantiation would never work, cause I don't see it happening in their `__init__` function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/242#issuecomment-419692328:405,down,down,405,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/242#issuecomment-419692328,1,['down'],['down']
Availability,"I did notice this warning in later versions of scanpy but only for index of `var` and `obs` not the table columns themselves. The loom file i'm loading contains this variable as an integer int64 type. I simply load the data and convert to categorical. . ```; adata = sc.read_loom(lf); adata.obs.columns = [""cellid"", ""hpf""]; adata.obs[""hpf""] = adata.obs[""hpf""].astype('category'); ```; This does not raise a warning, which seems like it would be hard to catch as I work on the dataframe directly.; Setting a dataframe with an integer index raises a warning as you mentioned. However if this is intended then I can understand this error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/422#issuecomment-453877645:629,error,error,629,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/422#issuecomment-453877645,1,['error'],['error']
Availability,"I do want to know why this [jupyter notebook](https://nbviewer.org/github/theislab/paga/blob/master/planaria/planaria.ipynb) can use 'neoblast 1' as root, a string you know, but cause error now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/909#issuecomment-1188988922:184,error,error,184,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/909#issuecomment-1188988922,1,['error'],['error']
Availability,"I don't feel well adding a large dataset to the repository. Adding something subsampled and rather low-dimensional would be fine. Alternatively, you could also just add a dataset that is automatically downloaded: as [here](https://github.com/theislab/scanpy/blob/7646c947f632ea7b09fea783e32a017136cfed24/scanpy/datasets/__init__.py#L104-L106) or [here](https://github.com/theislab/scanpy/blob/7646c947f632ea7b09fea783e32a017136cfed24/scanpy/datasets/__init__.py#L142-L144). As both travis and readthedocs will cache this, it should be a viable solution that avoids bloating the repository with several MB of data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/207#issuecomment-405508287:201,down,downloaded,201,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/207#issuecomment-405508287,1,['down'],['downloaded']
Availability,"I don't know how to fix this in the code, but I do find a workaround to specify a color palette. Turns out both `sc.pl.umap()` and `sc.pl.scatter()` accept a color palette if it's from `seaborn` color palette:. ```py; sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette='Set3'); ```. throws the above error message. But if I use. ```py; sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=sns.color_palette('Set3')); ```. if works as expected. Also you can manually assign a color list as :. ```py; sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=[; '#000000', '#575757', '#AD2323', '#2A4BD7', '#1D6914', ; '#814A19', '#8126C0', '#A0A0A0', '#81C57A', '#9DAFFF', ; '#29D0D0', '#FF9233', '#FFEE33', '#E9DEBB', '#FFCDF3', ; '#F2F3F4'; ]); ```. `palette=sc.pl.palettes.zeileis_28` works because `sc.pl.palettes.zeileis_28` is already a list of color. This also works for the `palete` argument in`sc.pl.umap()`, but it changes the `adata.uns['louvain_colors']` column values and will change other plots when using this column for plotting. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1438#issuecomment-1641632885:318,error,error,318,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438#issuecomment-1641632885,1,['error'],['error']
Availability,I don't know what is happening with the new matplotlib but I had to increase the tolerance for the image comparison in order for the tests to pass. Locally I noticed small differences in the margins and axis labels. Also I noticed that running a single test is different than running several tests at once. This probably has to do with some internal matplotlib parameters that are modified. . At least the tests are passing now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-426281432:81,toler,tolerance,81,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-426281432,1,['toler'],['tolerance']
Availability,"I don't like codacy, it's really flaky with its checks (e.g. errors appear and disappear at random). That's why we disabled it in the first place.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/648#issuecomment-815457252:61,error,errors,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/648#issuecomment-815457252,1,['error'],['errors']
Availability,"I don't need to manually pass size with `edgecolor='none'`. I'll see if I can replicate in a conda environment, and then try to cut down the example a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/293#issuecomment-429227670:132,down,down,132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/293#issuecomment-429227670,1,['down'],['down']
Availability,"I don't remember getting these errors before. Are you not getting them now, and did you get them before?. Also, where did the images in the repo get generated?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-432047736:31,error,errors,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-432047736,1,['error'],['errors']
Availability,"I don't think this is a segfault, but a `TypeError`. I believe this is due to using an out of date version of `numba`. Could you update that and let me know if the error persists?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1193#issuecomment-622662852:164,error,error,164,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193#issuecomment-622662852,1,['error'],['error']
Availability,"I don’t consider it breaking. If I understod you right, the only change in behavior are that not specifying a genome works now in cases where there’s only one. No longer throwing an error is a perfectly fine change!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/442#issuecomment-456713441:182,error,error,182,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442#issuecomment-456713441,1,['error'],['error']
Availability,I downloaded the folder from GitHub and then installed Scanpy and it worked for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/544#issuecomment-475911257:2,down,downloaded,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544#issuecomment-475911257,1,['down'],['downloaded']
Availability,"I downloaded the github source archive at the 1.8.2 tag. The build process applies a few patches viewable [here](https://salsa.debian.org/med-team/python-scanpy/-/tree/master/debian/patches). One is a small change to some R code, and the other is I marked several more tests as needs internet because the Debian builds in an environment without network access and those ultimately tried to download something. (And it's really unclear if we can legally redistributed the 10x pbmc3k dataset.). The Debian build file is (here)[https://salsa.debian.org/med-team/python-scanpy/-/blob/master/debian/rules] though mostly it lets you see what tests I was skipping because of missing dependencies. Also if I set a color like in_tissue, or array_row the data shows up. I can paste the full build log if you'd like but this is the dependencies installed and the environment variables. . ```; Build-Origin: Debian; Build-Architecture: amd64; Build-Date: Sun, 14 Nov 2021 20:11:26 +0000; Build-Path: /<<PKGBUILDDIR>>; Installed-Build-Depends:; adduser (= 3.118),; adwaita-icon-theme (= 41.0-1),; autoconf (= 2.71-2),; automake (= 1:1.16.5-1),; autopoint (= 0.21-4),; autotools-dev (= 20180224.1+nmu1),; base-files (= 12),; base-passwd (= 3.5.52),; bash (= 5.1-3.1),; binutils (= 2.37-8),; binutils-common (= 2.37-8),; binutils-x86-64-linux-gnu (= 2.37-8),; blt (= 2.5.3+dfsg-4.1),; bsdextrautils (= 2.37.2-4),; bsdutils (= 1:2.37.2-4),; build-essential (= 12.9),; bzip2 (= 1.0.8-4),; ca-certificates (= 20211016),; coreutils (= 8.32-4.1),; cpp (= 4:11.2.0-2),; cpp-11 (= 11.2.0-10),; dash (= 0.5.11+git20210903+057cd650a4ed-3),; dbus (= 1.12.20-3),; dbus-bin (= 1.12.20-3),; dbus-daemon (= 1.12.20-3),; dbus-session-bus-common (= 1.12.20-3),; dbus-system-bus-common (= 1.12.20-3),; dbus-user-session (= 1.12.20-3),; dconf-gsettings-backend (= 0.40.0-2),; dconf-service (= 0.40.0-2),; debconf (= 1.5.79),; debhelper (= 13.5.2),; debianutils (= 5.5-1),; dh-autoreconf (= 20),; dh-python (= 5.20211105),; dh-strip-no",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2048#issuecomment-969885616:2,down,downloaded,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048#issuecomment-969885616,2,['down'],"['download', 'downloaded']"
Availability,"I encounter the same error as well when i tried sc.pp.normalize_total(adata, target_sum=5e4). . Environment:; scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. [conda list]; https://github.com/phamidko/codesnippets/blob/master/scanpy-conda-list.txt; [ipynb]; https://github.com/phamidko/codesnippets/blob/master/Tissue-Tcell-activation.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1183#issuecomment-620365477:21,error,error,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183#issuecomment-620365477,1,['error'],['error']
Availability,"I encounter this same problem, if I call `sc.pp.log1p(x)` before culate hvg with seurat3, the error is gone, it have correlation with the adata.X is sparse or dense in my view.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1825#issuecomment-1140150507:94,error,error,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825#issuecomment-1140150507,1,['error'],['error']
Availability,"I encountered the same error (KeyError: 1) when trying to load the .mtx file with scanpy.read_10x_mtx(). After several unsuccessful attempts at renaming the columns and indices in the 'genes.tsv' file in different ways, I found a workaround that worked for me:. 1. Import the .mtx file separately using scanpy.read_mtx().; 2. Convert the imported data to a pandas DataFrame using .to_df().; 3. Manually name the columns and indices using the 'barcodes.tsv' and 'features.tsv' files, respectively. This approach allowed me to bypass the KeyError and successfully load the data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2053#issuecomment-2133703888:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2053#issuecomment-2133703888,1,['error'],['error']
Availability,"I encountered the same problem, when I created a small artificial `AnnData` with a single gene in `gene_list` for some unit test. Here is my analysis of the problem:. In this line; https://github.com/scverse/scanpy/blob/63141908601632638db8a79e8a1dfa8509cd27af/scanpy/tools/_score_genes.py#L182; `control_genes` was actually empty, hence the index error.; The reason for the empty `control_genes` genes is; https://github.com/scverse/scanpy/blob/63141908601632638db8a79e8a1dfa8509cd27af/scanpy/tools/_score_genes.py#L173; `control_genes` contained some genes before (in my artificial case only one), but they are removed here, since the genes in `control_genes` also appeared in `gene_list`. I think this is where the bug resides:; I assume `control_genes` should not contain genes from `gene_list` in the first place. Hence, this line; https://github.com/scverse/scanpy/blob/63141908601632638db8a79e8a1dfa8509cd27af/scanpy/tools/_score_genes.py#L167; would need to be changed/complemented:; An additional filter for not being a gene in `gene_list` should fix this issue, if I understand this code correctly. That being said, I suppose that this issue appears rather rarely in the realistically sized datasets. I assume, that the probability of *accidentally* picking genes from `gene_list` as `control_genes` decreases with increasing number of genes.; At least I have not encountered this exception in my experimental datasets.; Furthermore, this issue does not make the result *wrong*, as far as I understand the algorithm, because the control genes are selected randomly anyway.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2153#issuecomment-1910410846:348,error,error,348,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153#issuecomment-1910410846,1,['error'],['error']
Availability,I figure out this error by myself.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2003#issuecomment-920879255:18,error,error,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003#issuecomment-920879255,1,['error'],['error']
Availability,"I found a workaround that does not require downloading the `.whl` file for `numpy=1.19.5`. ; By default, MKL is included when you install numpy with conda. It's good to do this in a new environment.; ```; conda create -n scanpy_env; conda activate scanpy_env; conda install numpy=1.19; conda install seaborn scikit-learn statsmodels numba pytables; conda install -c conda-forge python-igraph leidenalg; pip install scanpy==1.8.1; ```; Now I can run `sc.pp.highly_variable_genes()` with no problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1020416116:43,down,downloading,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1020416116,1,['down'],['downloading']
Availability,"I found that after doing deep copy, sc.tl.pca doesn't change the PC values in the object, which may affect the downstream umap and Leiden clustering. . But why? I thought a deep copied object was supposed to behave the same as the non-deep copy one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1239#issuecomment-631872010:111,down,downstream,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239#issuecomment-631872010,1,['down'],['downstream']
Availability,"I get an error trying to merge multiples slides using the code in the tutorial. Is it possible to install the scanpy version the tutorial is using?. ```python; adata = adata.concatenate(; list(slides.values()),; batch_key=""sample"",; uns_merge=""unique"",; batch_categories=list(sample_data['sample_name'].values), ; index_unique=None; ); ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-4-fe8a54a66c17> in <module>; 40 uns_merge=""unique"",; 41 batch_categories=list(sample_data['sample_name'].values),; ---> 42 index_unique=None; 43 ); 44 . TypeError: concatenate() got an unexpected keyword argument 'uns_merge'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1254#issuecomment-635702014:9,error,error,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254#issuecomment-635702014,1,['error'],['error']
Availability,I get an identical error as @hemantgujar,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/455#issuecomment-1146151546:19,error,error,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-1146151546,1,['error'],['error']
Availability,"I get same error as @KabitaBaral1 after updating to scanp==1.4.6, namely: `AttributeError: module 'cairo' has no attribute 'version_info'` also see the issue #1166",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1154#issuecomment-614331672:11,error,error,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154#issuecomment-614331672,1,['error'],['error']
Availability,"I got similar error when I was trying to use .h5 file from cellbender output. I have multiome data. . ```pytb; `>>> adata = scanpy.read_10x_h5(""/sc/arion/projects/hmDNAmap/snHeroin/analysis/ARC_TD005235-354/outs/cellbender/cb_feature_bc_matrix_filtered.h5"", gex_only=False)`; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py"", line 183, in read_10x_h5; adata = _read_v3_10x_h5(filename, start=start); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py"", line 268, in _read_v3_10x_h5; _collect_datasets(dsets, f[""matrix""]); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py"", line 256, in _collect_datasets; dsets[k] = v[:]; File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/dataset.py"", line 738, in __getitem__; selection = sel2.select_read(fspace, args); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/selections2.py"", line 101, in select_read; return ScalarReadSelection(fspace, args); File ""/sc/arion/work/gujarh01/software/anaconda3/lib/python3.9/site-packages/h5py/_hl/selections2.py"", line 86, in __init__; raise ValueError(""Illegal slicing argument for scalar dataspace""). > **ValueError: Illegal slicing argument for scalar dataspace**; ```. `>>> scanpy.logging.print_versions()`. anndata 0.8.0; scanpy 1.9.1. PIL 8.4.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.14.6; cloudpickle 2.0.0; colorama 0.4.4; concurrent NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.10.0; dateutil 2.8.2; defusedxml 0.7.1; encodings NA; fsspec 2021.08.1; genericpath NA; h5py 3.3.0; igraph 0.9.6; jinja2 2.11.3; joblib 1.1.0; kiwisolver 1.3.1; leidena",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2203#issuecomment-1129213572:14,error,error,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203#issuecomment-1129213572,1,['error'],['error']
Availability,I got the same error with scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.3 scipy==1.3.2 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.2 python-igraph==0.7.1 louvain==0.6.1; But I am so glad to find answer here and thanks a lot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/769#issuecomment-559832485:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769#issuecomment-559832485,1,['error'],['error']
Availability,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2037449650:65,error,errors,65,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2037449650,1,['error'],['errors']
Availability,I guess it has to do with the dependency on `scipy`. Downgrading to a previous setup of packages did the trick for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1407#issuecomment-690967045:53,Down,Downgrading,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1407#issuecomment-690967045,1,['Down'],['Downgrading']
Availability,"I guess this comes down to what you interpret an `NA` value as. If I want to show another category, I give it a name and it's shown. Doing this is very easy. If I don't assign a category to a group of observations, I would interpret this as this group of observations not being relevant in the context.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1355#issuecomment-668515906:19,down,down,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1355#issuecomment-668515906,1,['down'],['down']
Availability,"I had some issue with `io.BytesIO()` from the fix proposed above. . So, I used `R` to generate scatter plots as below:. ```py; import anndata2ri; import logging. import rpy2.rinterface_lib.callbacks as rcb; import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR); ro.pandas2ri.activate(); anndata2ri.activate(). %load_ext rpy2.ipython; ```; Convert adata_p and adata_g to R objects. ```r; ro.globalenv['r_adata_p'] = adata_p; ro.globalenv['r_adata_g'] = adata_g; ```. ```r; %%R -w 800 -h 400 -u px. library(Seurat); library(viridis); library(viridisLite); library(ggplot2); library(cowplot). df_poor= data.frame(; total_counts = colData(r_adata_p)$total_counts,; n_genes_by_counts = colData(r_adata_p)$n_genes_by_counts,; pct_counts_mt = colData(r_adata_p)$pct_counts_mt; ). df_good= data.frame(; total_counts = colData(r_adata_g)$total_counts,; n_genes_by_counts = colData(r_adata_g)$n_genes_by_counts,; pct_counts_mt = colData(r_adata_g)$pct_counts_mt; ). #head(df); # Create a scatter plot using ggplot2; p2 <- ggplot(data = df_poor, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +; geom_point() +; scale_color_viridis() +; labs(title = ""poor (after outlier and mitochrondrial gene removal)"") +; theme_minimal(). g2 <- ggplot(data = df_good, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +; geom_point() +; scale_color_viridis() +; labs(title = ""good (after outlier and mitochrondrial gene removal)"") +; theme_minimal(). p2 + g2; ```. ![Screenshot from 2023-12-13 11-25-03](https://github.com/scverse/scanpy/assets/3212461/f016798e-aa7a-4601-9fad-f85d54877c2d)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1258#issuecomment-1853651085:263,ERROR,ERROR,263,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258#issuecomment-1853651085,1,['ERROR'],['ERROR']
Availability,"I had the exact same issue and error message at that step in the tutorial. I installed scanpy using pip, because installing with conda was not working.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1010#issuecomment-578570558:31,error,error,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010#issuecomment-578570558,1,['error'],['error']
Availability,"I had this error in the past. Try with a different mirror, you can look them from [here](http://www.ensembl.org/info/about/mirrors.html). For example, I usually use `useast.ensembl.org`. Hope it helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/242#issuecomment-416231775:11,error,error,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/242#issuecomment-416231775,1,['error'],['error']
Availability,"I had to use the pbmc3k dataset for testing, as the error doesn't occur on blobs or pbmc68k_reduced. To test I need sufficient genes that have 0 variance in a subset of the cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/824#issuecomment-530426113:52,error,error,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824#issuecomment-530426113,1,['error'],['error']
Availability,"I have a similar problem. And this does not seam to be related to any python package version as I have 4 data sets loaded from CellRanger h5 files.; With two of these files the neighbors function works and with two it fails with likely a seg fault as a cpp_abort_hook process takes over. This is REALLY annoying as I also get this problem with a random number of different single cell data sets. I assume there is some issue with a dataset that results in a cpp error.; I do not want to debug that as cpp errors are a pain. Can you guess what the problem might be?; The cpp breaks after the multiprocessor step. The Python process has used my 10 processors to the max for some time, but then fallen back to 100%. So it seams it might be after collecting whatever has been produced in the first multiprocessor step.; Can you tell me what that could be so I can implement a test into my scripts? It also probably would be a good idea if you could implement that test into your package. I'll check the two other links, too. If I do not come back here assume both links were not helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2361#issuecomment-1313450128:242,fault,fault,242,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1313450128,3,"['error', 'fault']","['error', 'errors', 'fault']"
Availability,"I have also encountered this error, but specifically in the scanpy tutorial outlined [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). That should make reproducibility easier. The error occurs under the _Finding Marker Genes_ heading, specifically the following line:. ```py; sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20); ```. With an error output of the following:. ```pytb; ranking genes; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[49], line 1; ----> 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); 2 sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: '",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453:29,error,error,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453,3,['error'],['error']
Availability,I have also got exactly the same error !,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/769#issuecomment-519000488:33,error,error,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769#issuecomment-519000488,1,['error'],['error']
Availability,"I have an AnnData object whose .X matrix has been transformed by size factor division, +1 and log. Subsequent ```sc.pp.highly_variable_genes(dataset, flavor='cell_ranger', n_top_genes=1000)``` yields the ```ValueError: Bin edges must be unique: ... You can drop duplicate edges by setting the 'duplicates' kwarg``` error discussed above. Transformation to a sparse matrix did not alleviate the error, and neither did any other solutions suggested. Edit: **However!** While I could not get ```flavor='cell_ranger'``` to work on the data I normalised myself, ```flavor='seurat'``` has worked okay. Therefore, I recommend people also encountering this error to stick with this second flavour, because as I understand it they utilise a similar methodology.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-751495201:315,error,error,315,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-751495201,3,['error'],['error']
Availability,I have an exact same error as well. By dropping one of the samples the issue was gone. Any ideas?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3103#issuecomment-2217913872:21,error,error,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103#issuecomment-2217913872,1,['error'],['error']
Availability,"I have been unable to get this to look good by default. It can be made to look good by playing around with the parameters, but then we're not really saving the user much effort. A strategy that seemed to work okay was to repel the labels from the points, followed by a second repulsion from other labels. But then I had to redraw the lines manually. Current thoughts are to punt this down the road. Maybe there will be a better solution in the future, or maybe there's a clever parameterization fix I hadn't thought of.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1513#issuecomment-839597935:384,down,down,384,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513#issuecomment-839597935,1,['down'],['down']
Availability,"I have larger number of cells than 50. but sc.tl.pca(adata, use_highly_variable_genes = False) resolved my error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/432#issuecomment-499145170:107,error,error,107,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432#issuecomment-499145170,1,['error'],['error']
Availability,"I have problem installing and importing scrublet on windows please can you help me; Here is my code !pip install scrublet; PackagesNotFoundError: The following packages are not available from current channels:. - annoy. Current channels:. - https://conda.anaconda.org/conda-forge/win-64; - https://conda.anaconda.org/conda-forge/noarch; - https://repo.anaconda.com/pkgs/main/win-64; - https://repo.anaconda.com/pkgs/main/noarch; - https://repo.anaconda.com/pkgs/r/win-64; - https://repo.anaconda.com/pkgs/r/noarch; - https://repo.anaconda.com/pkgs/msys2/win-64; - https://repo.anaconda.com/pkgs/msys2/noarch; - https://conda.anaconda.org/pytorch/win-64; - https://conda.anaconda.org/pytorch/noarch. To search for alternate channels that may provide the conda package you're; looking for, navigate to. https://anaconda.org/. and use the search bar at the top of the page.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-1755962194:177,avail,available,177,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-1755962194,1,['avail'],['available']
Availability,"I have replicated the error using local installation with 'pip3 install scanpy'; When I run the regress_out code on a jupyter notebook, same error appears.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/687#issuecomment-502349575:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/687#issuecomment-502349575,2,['error'],['error']
Availability,"I have the same error on scanpy 1.9.5, seaborn 0.13.0, the error seems to be specific to 'multi_panel = True' and produces 3 empty graphs that all inherit the ""n_genes_by_counts"" x-label instead of the proper one.; The same graph is produced normally with 'multi_panel = False'. `sc.pl.violin(full_adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_MT'], multi_panel=True, stripplot=False)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2680#issuecomment-1761837779:16,error,error,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680#issuecomment-1761837779,2,['error'],['error']
Availability,I have the same problem. Didn't expect it is due to the anndata package. ; Downgrade anndata to 0.10.2 solve this problem.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2806#issuecomment-1892881600:75,Down,Downgrade,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2806#issuecomment-1892881600,1,['Down'],['Downgrade']
Availability,I have this exact error!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2141#issuecomment-1981711229:18,error,error,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2141#issuecomment-1981711229,1,['error'],['error']
Availability,"I have tried using latest version of anndata(0.16.9), still got the same error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/598#issuecomment-493672904:73,error,error,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-493672904,1,['error'],['error']
Availability,I hope everybody had a good New Year break! Just pinging @ivirshup again because I think it'd be great to move forward with this. Also wanted to ping @falexwolf as I know he did a lot of work on dim reduction etc. Cheers.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-757850250:49,ping,pinging,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-757850250,2,['ping'],"['ping', 'pinging']"
Availability,"I hve to clarify: I tried out the fix provided above from @flying-sheep and it does the job for me, but the error persists on the `master` branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953#issuecomment-778184917:108,error,error,108,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953#issuecomment-778184917,1,['error'],['error']
Availability,"I input pip show scipy I get:. Name: scipy; Version: 1.4.1; Summary: SciPy: Scientific Library for Python; Home-page: https://www.scipy.org; Author: None; Author-email: None; License: BSD; Location: /home/ubuntu/.local/lib/python3.6/site-packages; Requires: numpy; Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata; You are using pip version 18.0, however version 20.2b1 is available.; You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:; Name: scanpy; Version: 1.5.1; Summary: Single-Cell Analysis in Python.; Home-page: http://github.com/theislab/scanpy; Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrés R. Muñoz-Rojas; Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de; License: BSD; Location: /home/ubuntu/.local/lib/python3.6/site-packages; Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata; Required-by: ; You are using pip version 18.0, however version 20.2b1 is available.; You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user; when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1252#issuecomment-635681942:1346,avail,available,1346,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252#issuecomment-635681942,1,['avail'],['available']
Availability,I installed it now but still have the issue of HTTP Error 403.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1334#issuecomment-733637978:52,Error,Error,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1334#issuecomment-733637978,1,['Error'],['Error']
Availability,I installed leidenalg through conda today and encountered the same error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2341#issuecomment-1265542125:67,error,error,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341#issuecomment-1265542125,1,['error'],['error']
Availability,"I just got the same error with a similar situation. . I get umap coordinates from a collaborator, which I store in `adata.obs`. Before the last update this worked:; `sc.pl.scatter(adata, x='UMAP1', y='UMAP2', color='cell_type_class')`; Now, this produces a `IndexError: Key ""UMAP1"" is not valid observation/variable name/index.` error. Now I need to run this for the same plot:; `sc.pl.scatter(adata, x='UMAP1', y='UMAP2', color='cell_type_class', use_raw=False)`. These covariates are all in `adata.obs.keys()`. It seems that `use_raw` is taking precendence over `x` and `y` being from `adata.obs`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/728#issuecomment-512184351:20,error,error,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728#issuecomment-512184351,2,['error'],['error']
Availability,I just had another thought... it seems like this might have to do with the initial `sc.tl.paga()` call. There you get a runtime warning about overflow in long scalars. Maybe check if you get any meaningful output in `adata.uns['paga/connectivities']` or `adata.uns['paga/connectivities_tree']`. It might just be all `nan` in there due to the above errors. Could it be that you have a 32-bit windows version and the code is trying to use 64-bit floats? Maybe that's the overflow error?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/852#issuecomment-534977199:348,error,errors,348,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/852#issuecomment-534977199,2,['error'],"['error', 'errors']"
Availability,I just had the same error occur when trying to save my objects,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/515#issuecomment-469460276:20,error,error,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515#issuecomment-469460276,1,['error'],['error']
Availability,I just had the same issue because I downgraded my matplotlib elsewhere.; So it should work if you upgrade your matplotlib.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2332#issuecomment-1254363045:36,down,downgraded,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332#issuecomment-1254363045,1,['down'],['downgraded']
Availability,"I just noticed that the reply I sent Saturday bounced due to ‘unknown error’. I thought I should provide an update in case other Windows users encounter something similar. After identifying the correct version of the several on the link below, I noticed that it was also necessary to install Pycairo. I then found I needed to install the Louvain algorithm to resolve the issue. The vtraag website indicates this algorithm has been superseded by the Leiden algorithm, which I installed with no problem. Thanks much for your reply within hours, on a weekend no less. From: Koncopd [mailto:notifications@github.com]; Sent: Saturday, May 25, 2019 2:15 PM; To: theislab/scanpy <scanpy@noreply.github.com>; Cc: Moos, Malcolm <Malcolm.Moos@fda.hhs.gov>; Mention <mention@noreply.github.com>; Subject: Re: [theislab/scanpy] igraph problems (#138). @RicedeKrispy<https://github.com/RicedeKrispy>; Hi, if you are using Windows, you can try to install python-igraph from the wheel here; https://www.lfd.uci.edu/~gohlke/pythonlibs/#python-igraph. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/138?email_source=notifications&email_token=AMEIEFZ2OGJSDDXGY4TRK4TPXF62HA5CNFSM4E5ZJQRKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODWHWUII#issuecomment-495938081>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AMEIEFZFWYPQB7BP5HHCM23PXF62HANCNFSM4E5ZJQRA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/138#issuecomment-502908611:70,error,error,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138#issuecomment-502908611,1,['error'],['error']
Availability,"I just saw on zulip that some of the functions in codaplot could be helpful here, sorry for the late reply. I'll post some more details on what is available in the package here tomorrow :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2194#issuecomment-1143890664:147,avail,available,147,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2194#issuecomment-1143890664,1,['avail'],['available']
Availability,"I just stumbled upon a similar bug using SciKit Learn. It's not ScanPy, but this issue is the only result Google returned when I looked up my error. Here's my crash log:. ```; Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV); Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110; Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11; Termination Reason: Namespace SIGNAL, Code 0xb; Terminating Process: exc handler [0]. VM Regions Near 0x110:; --> ; __TEXT 000000010ddfb000-000000010ddfd000 [ 8K] r-x/rwx SM=COW /usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:; crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread; 0 libdispatch.dylib 	0x00007fff4fb578e1 _dispatch_root_queue_push + 108; 1 libBLAS.dylib 	0x00007fff24844c9a rowMajorTranspose + 546; 2 libBLAS.dylib 	0x00007fff24844a65 cblas_dgemv + 757; 3 multiarray.cpython-36m-darwin.so	0x00000001104e3f86 gemv + 182; 4 multiarray.cpython-36m-darwin.so	0x00000001104e3527 cblas_matrixproduct + 2807; 5 multiarray.cpython-36m-darwin.so	0x00000001104a9b27 PyArray_MatrixProduct2 + 215; 6 multiarray.cpython-36m-darwin.so	0x00000001104aeabf array_matrixproduct + 191; 7 org.python.python 	0x000000010de4712e _PyCFunction_FastCallDict + 463; 8 org.python.python 	0x000000010dead0e6 call_function + 491; 9 org.python.python 	0x000000010dea5621 _PyEval_EvalFrameDefault + 1659; 10 org.python.python 	0x000000010dead866 _PyEval_EvalCodeWithName + 1747; ```. It's not very useful as it's the same as the OP's, but it might help shifting the blame to a common dependency of SciKit Learn and ScanPy (like BLAS having an issue with macOS' Grand Central Dispatch).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/182#issuecomment-408848214:142,error,error,142,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182#issuecomment-408848214,2,"['error', 'fault']","['error', 'fault']"
Availability,"I know this is a bit specific, but the current sc.pl.rank_genes_groups() and sc.pl.rank_genes_groups_violin() have a 'gene_symbols' argument to allow display based on other columns in .var. For example, if I have this in Var:. ```; Var columns:; gene_symbol; index ; ENSMUSG00000000001 Gnai3; ENSMUSG00000000028 Cdc45; ENSMUSG00000000031 H19; ENSMUSG00000000037 Scml2; ENSMUSG00000000049 Apoh; ```. I can just pass 'gene_symbol' as the column I want to be used for any/all displays instead of the ensembl ID all the time. It would be great if something like this were consistently available anywhere gene labels were needed in the plotting functions. Perhaps the common argument would be better called 'display_label' or something like that instead.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/646#issuecomment-493156408:581,avail,available,581,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/646#issuecomment-493156408,1,['avail'],['available']
Availability,"I like @flying-sheep's very last solution. To enable this for truly large-scale data and AnnData's that are backed on disk we need a much more efficient transposition implementation, which will probably need to return a view. That's problematic as it will break backwards compat (`.T` returns a copy these days). But it's good as it will allow adding fields to `.var`. @LuckyMD: At the time, when you mentioned that you wanted to plot over genes in scatter, I was fine with with having the scatter wrapper and assuming no ambiguity in obs and var keys. Now, I'd advocate for @flying-sheep's solution. Of course, we'll maintain the feature in `pl.scatter` when refactoring its code (a lot of it became redundant after fidel introduced the completely rewritten scatter plots).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/375#issuecomment-441473742:701,redundant,redundant,701,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375#issuecomment-441473742,1,['redundant'],['redundant']
Availability,"I like that CI for notebooks!. Question, what should be happening here? I'm a little confused about how the path isn't a directory, but you're going to write a file inside of it? If this is the problem, I think having `exists_ok=True` will still error. In general, I believe we'd previously decided to not create parent directories for writing automatically (mentioned in https://github.com/theislab/anndata/pull/364, and I think talked about in a zoom call?). This follows other tools better, which just throw an error if your parent directory doesn't exist. I personally like this approach better because it'll throw an error for typos, instead of doing the wrong thing. The only exception here is for the `datasets` module, which should create the directory it will store data in. I would recommend you explicitly create the directory in your code if needed. @falexwolf @flying-sheep, I would like to remove the directory creation code from `_check_datafile_present_and_download`. Do you think this will be a problem? It's not documented, so I'm leaning towards just removal instead of deprecation, but could be convinced to just warn for a cycle.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1305#issuecomment-661712907:246,error,error,246,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1305#issuecomment-661712907,3,['error'],['error']
Availability,"I like that this method is fairly simple, and could have a meaningful cutoff, but I think I'd like more evidence of it's usefulness before thinking about including it. I have two main points of concern:. * Are there examples of this method being used outside of the glmPCA paper? I would at least like to know that reasonable results can be found downstream of this.; * In the glmPCA paper, the identified genes are highly correlated (~1) with highly expressed genes, and lowly correlated (~.3 with highly variable gene selection. While I'm not sure which highly variable gene method they compared against, should the low correlation with common practice give us pause?. <img width=""784"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/112927072-2515b680-9160-11eb-967a-373536aad6d1.png"">. @giovp",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1765#issuecomment-809874884:347,down,downstream,347,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1765#issuecomment-809874884,1,['down'],['downstream']
Availability,"I like the idea! Better error messages, and getting our modalities a bit under control is a great goal as well!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3048#issuecomment-2106927009:24,error,error,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048#issuecomment-2106927009,1,['error'],['error']
Availability,"I like this idea. * While we should be conservative about adding new keywords, this fits well with `vmin` and `vmax`; * The docs for this argument should mention that users should pass a diverging palette with it, and probably have an example; * If `norm` is passed along at the same time, an error should be thrown; * It looks like there is a bunch of repeated code handling generating the `norm`, could this get put into a common utility function?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1551#issuecomment-748422767:293,error,error,293,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551#issuecomment-748422767,1,['error'],['error']
Availability,"I looked through the R `fastica` package, and I think one of the main differences was the default tolerance. I've changed that and results seem a bit better. I don't think I have a great reference point to evaluate it though. Any chance you could provide a vignette of ICA being used with single cell data, so we can see if the python version can recapitulate the results?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/767#issuecomment-519397103:98,toler,tolerance,98,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767#issuecomment-519397103,1,['toler'],['tolerance']
Availability,"I managed to get past the error by adding; ```; RUN locale-gen en_US.UTF-8; ENV LC_ALL en_US.UTF-8; ```; to the [Dockerfile](https://gist.github.com/pwl/a26726fda94ac7f4cbfb57e4fe98bf28). Before that the default locale was set to `POSIX`, which caused all of these problems. This is a weird choice of defaults as clearly python code doesn't work as expected. Thanks for helping out @flying-sheep!. EDIT: just to clarify, this dockerfile is not an example of how to install scanpy, it's just a demonstration of how to circumvent the issues with locales. In particular, several libraries are missing and scanpy does not complete the installation. Feel free to update this Dockerfile or add one to the scanpy repository.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/43#issuecomment-344235559:26,error,error,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43#issuecomment-344235559,1,['error'],['error']
Availability,"I mean any smFISH or highly-multiplexed protein technology. The plot I have in mind is this:; This visualisation is implemented in our package (in active development - we haven't released yet): https://cell2location.readthedocs.io/en/latest/cell2location.plt.html#cell2location.plt.mapping_video.plot_spatial; ![download-20](https://user-images.githubusercontent.com/22567383/95405951-0ea94380-0911-11eb-84bf-6f712da7875c.png). I agree that the original images can be quite large so it is probably better to not load them by default. However, it is useful to have an option to load. For the Visium data, the utility of using fullres depends on image quality and the goals. Generally, cell diameter in highres images is just 1-4 pixels meaning that a cropped image with, say 10*10 spots will look pixelated and may not be enough to recognise small structures like a gland or a blood vessel, not mentioning cell morphologies or staining (e.g. eosinophils containing red granules).; For single-cell resolution data, it is often useful to zoom in to see if only cells of specific morphology express the gene, like Agt below.; ![download-19](https://user-images.githubusercontent.com/22567383/95405958-12d56100-0911-11eb-9a9b-3a2faa3fa660.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1436#issuecomment-705283276:312,down,download-,312,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436#issuecomment-705283276,2,['down'],['download-']
Availability,"I mean, @vtraag is is the person I’d believe when asked which algorithm is superior, so we could. 1. add `sc.tl.leiden` as an alternative that doesn’t have a flavour argument.; 2. make `leidenalg` a dependency and `louvain-igraph` an optional one.; 3. when calling `sc.tl.louvain` (no matter the flavor used), emit a ``DeprecationWarning('We recommend to use `sc.tool.leiden` instead. Refer to its documentation for details')``. This meets the following goals:. - education: people will learn why we recommend the new function; - ease of use: no weird errors pop up suddenly; - reproducibility: If `louvain-igraph` is installed, the code works exactly as before (with an added warning), else it crashes. we could do the following within `sc.tl.louvain` to help users:. ```py; try:; import louvain; except ImportError:; raise ImportError(; 'The package “louvain-igraph“ is not installed. '; 'Try using `sc.tl.leiden` in case you do not need '; 'to reproduce results produced using `sc.tl.louvain`'; ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/350#issuecomment-437039831:552,error,errors,552,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/350#issuecomment-437039831,1,['error'],['errors']
Availability,"I meet this problem last days, I uninstall the python-igraph package and reinstall it. then the error disappear.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/961#issuecomment-620301726:96,error,error,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/961#issuecomment-620301726,1,['error'],['error']
Availability,"I might also have a corrupted install of anndata, let me reboot my system and see if the error persists.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2978#issuecomment-2035502211:57,reboot,reboot,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978#issuecomment-2035502211,2,"['error', 'reboot']","['error', 'reboot']"
Availability,I ran into the same error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/432#issuecomment-498925141:20,error,error,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/432#issuecomment-498925141,1,['error'],['error']
Availability,"I ran into this recently - the problem can occur when batch key has many cells in each batch (see plot). Increasing the span from the default of 0.3 to 0.5 seems to have ""fixed"" the error. Increasing the filtering stringency for lowly expressed genes (to min_gene=500, min_cells=10) also gets rid of the error. ```; sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); ```; ```; sc.pp.highly_variable_genes(; adata,; layer=""counts"",; flavor=""seurat_v3"",; n_top_genes=num_hvgs,; batch_key='sex_cell_subtype',; span=0.5; ); ```; <img width=""580"" alt=""image"" src=""https://user-images.githubusercontent.com/4561831/234303299-74bee98d-94a8-40a8-b0dd-cc10eac1acec.png"">",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1504#issuecomment-1521864773:182,error,error,182,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504#issuecomment-1521864773,2,['error'],['error']
Availability,"I ran your code snippet multiple times on my end and I got the same results each time. Is this true for you as well? If both you and your partner can generate the same results consistently each time, then it is strange that your results disagree with each other... Some followup questions I have:; 1) Are ALL packages the same version? (Packages like Numba, scipy, sklearn, etc. should also be the same version to remove that as a potential source of variability); 2) Are you guys using the same operating system? ; 3) Can you run UMAP directly on the randomly generated matrix to see if your embeddings are the same? If they are, UMAP is likely not at fault.; 4) If you perturb your nearest neighbor matrix by adding noise to the edges such that the total edge weight differs by ~0.001 between perturbations, can you recreate the big differences in the UMAP projection? Small differences in the edge weights of the nearest neighbor graph CAN lead to huge differences in the UMAP projection if the graph has no inherent structure (which should be the case for randomly generated data).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1009#issuecomment-578310404:653,fault,fault,653,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009#issuecomment-578310404,1,['fault'],['fault']
Availability,I read some forum threads saying that we need to downgrade matplotlib,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1094#issuecomment-629808985:49,down,downgrade,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094#issuecomment-629808985,1,['down'],['downgrade']
Availability,I recently had a discussion with @LisaSikkema about how much you can overshoot here. The suggestion was made to use 100 PCs. Can we robustly compute that many or do the numerical methods break down when too little variance is represented by a PC? I recall @falexwolf mentioning this at some point.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/872#issuecomment-590110278:132,robust,robustly,132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/872#issuecomment-590110278,2,"['down', 'robust']","['down', 'robustly']"
Availability,"I reckon that's a fair consideration. In the end we don't use `sc.tl.rank_genes_groups()` for complex DE tests that require this amount of detail, but instead for marker gene calculations where it's mainly about ranking genes. It would be interesting to see the error of the approximation though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/519#issuecomment-471500111:262,error,error,262,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519#issuecomment-471500111,1,['error'],['error']
Availability,I saw this error in my analysis as welll.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1446#issuecomment-782180615:11,error,error,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446#issuecomment-782180615,1,['error'],['error']
Availability,"I see no reason why the possibility shouldn't exist to run the weighted version on the full graph. I'm still curious about the quality of the outcome though. Using protein-protein interaction data, I've noticed that similarity scores perform worse than using network neighbourhoods based on cutoffs to cluster data (this does not have to be the case for scRNA-seq of course). In the latter case you require cells to be each others nearest neighbours to create dense network regions, rather than highly similar transcriptomes based on one calculation of similarity. I would have thought the cutoff approach is more robust to changing similarity metrics as well. It's definitely worth testing this though. Maybe I'm just too skeptical of similarity metrics over all. @fidelram do you have labels on your data where you could verify the quality of those two partitions?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/240#issuecomment-416161676:614,robust,robust,614,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/240#issuecomment-416161676,1,['robust'],['robust']
Availability,I skimmed through the code only briefly yesterday but I think the problem might be that both `x` and `y` need to be specified: The error message seems to indicate so and the two lines seemingly responsible for the problem are the only ones where `x` and `y` are **not** both specified. I'll have a closer look at it in a bit.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1420#issuecomment-694079984:131,error,error,131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1420#issuecomment-694079984,1,['error'],['error']
Availability,"I still get the same error with `useast`. ```python; sc.queries.mitochondrial_genes(""useast.ensembl.org"", ""hsapiens""); ```; <details>; <summary>The output and traceback</summary>. ```python; You must set the host (e.g. f.host='www.ensembl.org' ; You must set the host (e.g. f.host='www.ensembl.org' ; You must set the host (e.g. f.host='www.ensembl.org' ; You must set the host (e.g. f.host='www.ensembl.org' ; You must set the host (e.g. f.host='www.ensembl.org' ; You must set the host (e.g. f.host='www.ensembl.org' ; ---------------------------------------------------------------------------; EmptyDataError Traceback (most recent call last); <ipython-input-4-66c3fcd14dab> in <module>(); ----> 1 sc.queries.mitochondrial_genes(""useast.ensembl.org"", ""hsapiens""). ~/github/scanpy/scanpy/queries/__init__.py in mitochondrial_genes(host, org); 40 ; 41 # parsing mitochondrial gene symbols; ---> 42 res = pd.read_csv(StringIO(s.query(xml)), sep='\t', header=None); 43 res.columns = ['symbol', 'chromosome_name']; 44 res = res.dropna(). /usr/local/lib/python3.6/site-packages/pandas/io/parsers.py in parser_f(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision); 676 skip_blank_lines=skip_blank_lines); 677 ; --> 678 return _read(filepath_or_buffer, kwds); 679 ; 680 parser_f.__name__ = name. /usr/local/lib/python3.6/site-packages/pandas/io/parsers.py in _read(filepath_or_buffer, kwds); 438 ; 439 # Create the parser.; --> 440 parser = TextFileReader(file",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/242#issuecomment-416814067:21,error,error,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/242#issuecomment-416814067,1,['error'],['error']
Availability,"I still had the same error with `scanpy` 1.4.5, in my case updating `anndata` solved the issue, but now I've hit the slow concatenation problem https://github.com/theislab/anndata/issues/303",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/942#issuecomment-580322693:21,error,error,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/942#issuecomment-580322693,1,['error'],['error']
Availability,I stumbled across the same error with scanpy==1.4.5.1 anndata==0.7.1 umap==0.4.2. Did not quite understand the solution for this issue. What should I do?. Best wishes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1036#issuecomment-627825582:27,error,error,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036#issuecomment-627825582,1,['error'],['error']
Availability,"I think I find the reason. When run sc.tl.louvain(adata), louvain_colors will be saved in adata.uns, sc.pl.paga will use louvain_colors. But, when run sc.tl.louvain(adata) again with another resolution and then rerun sc.tl.paga, louvain_colors will not be updated, and the error occurs!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/381#issuecomment-456264112:273,error,error,273,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/381#issuecomment-456264112,1,['error'],['error']
Availability,"I think I found a way around it. The issue here is the error is thrown when the new louvain groups are created by the adata.obs['louvain_colors'] are not updated until the plotting sc.pl function is run. Therefore, when you try to slice anything, it throws out an index out of bounds error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/833#issuecomment-531440165:55,error,error,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833#issuecomment-531440165,2,['error'],['error']
Availability,"I think `pandas` provides a good template for the question of `np.min(adata)`. `np.min(df)` gives the minimum value stored in the dataframe, not the minimum value in the `Index` (aka `obs`) or `Columns` (aka `var`). Given `AnnData` is basically a way of storing data and metadata associated with both the rows and columns of that data, it goes without saying (in my opinion at least) that numerical methods applied to `adata` should be applied to `adata.X`. Re: slicing, I think it makes sense to have explicit slicing for one or the other (i.e. `loc` and `iloc`) and then a default slicing (i.e. `adata['Cell A',:]`) which takes both position-based and name-based slicing if the two are unambiguous. It wouldn't be hard to include a check that says if the names are a) integers and b) not simply a RangeIndex (ie names and positions are the same) then throw a warning or an error asking the user to specify which of name or position they want.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-584144674:875,error,error,875,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-584144674,1,['error'],['error']
Availability,"I think an error should be thrown, thus the user can figure out what to do. ; @nh3 I don't understand the part about the `different summarization`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/926#issuecomment-555494385:11,error,error,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/926#issuecomment-555494385,1,['error'],['error']
Availability,"I think it might be enough to leave it to random chance. As it is now, `sc.pl.umap` works with 70 colors, which aren't easily distinguishable -- but neighboring clusters seem to always be distinguishable. The easiest fix to this issue would just be to support a larger color palette -- maybe even kicking the can down the road up to ~150 colors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2313#issuecomment-1240055609:313,down,down,313,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313#issuecomment-1240055609,1,['down'],['down']
Availability,"I think it would be nice to start small, then gradually add to this. I'd nominate `black` as the first step, then using `pre-commit` on CI, then adding more tools. I like `black` for a starting place since we can just run it over both dev and stable branches and be confident in nothing breaking. For anything that requires more manual intervention, I think we'll have to wait until close to a new stable branch being cut so we don't have to worry about conflicts during backports. I had also thought `isort` could be a good starting place, but it might actually be some work to turn on due to ""partially initialized module"" errors (*imperative programming strikes again!*). <details>; <summary> Some initial settings for `isort` </summary>. ```toml; [tool.isort]; profile = ""black""; multi_line_output = 3; skip = ""scanpy/__init__.py""; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1563#issuecomment-777223132:625,error,errors,625,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563#issuecomment-777223132,1,['error'],['errors']
Availability,"I think it’s pretty impossible to know if they’ll render – Depends on the fonts available on the system and the way the font rendering stack falls back to other fonts. My approach would be to check which systems have the problem, and if it’s only some Linux server or some obsolete stuff like e.g. Windows versions up to Vista, ignore it. If it’s a commonly used and still supported desktop OS / Linux distribution, we have to deal with it. The reason I excluded Linux servers is that server admins often set up things minimalistically, excluding “GUI stuff” so trying to support those highly heterogenous systems will only bring pain. When people want better fonts, then fontconfig is happy to provide them with the means to do so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/805#issuecomment-528244541:80,avail,available,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805#issuecomment-528244541,1,['avail'],['available']
Availability,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there.; 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1177#issuecomment-618890788:289,avail,available,289,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177#issuecomment-618890788,1,['avail'],['available']
Availability,"I think saying discrete was redundant with independent, in that each component should correspond to a signal in the data. > And so you're saying 1, 5, and 7 being given as solutions to ICA is non-optimal. I'm not sure how to interpret it. I know that if I run an analysis on the same dataset with 20 components I get more independent ones. My impression is the ""failure modes"" of linear decompositions like this are not well characterized. > It feels strange to generally say that ICA is better as higher dimensions. I probably wouldn't say this. I think there are different use cases, and ICA components may be easier to interpret than PCA components. I was also just at a talk by Elana Fertig (who knows much more about this kind of thing than I do) where one of the take aways was ""different decompositions for different use-cases"". I think I'll still use PCA for clustering and generating UMAPs. > while at lower dimensions there is redundant information compared to PCA. I'd note that there is no order to ICA components.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/941#issuecomment-560219393:28,redundant,redundant,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/941#issuecomment-560219393,3,"['failure', 'redundant']","['failure', 'redundant']"
Availability,"I think that if you store a categorical value in a pandas dataframe (like; .obs) the storage of this redundant information is quite efficient. In a; quick search I found this:; https://towardsdatascience.com/make-working-with-large-dataframes-easier-at-least-for-your-memory-6f52b5f4b5c4. On Wed, May 22, 2019 at 3:59 PM MalteDLuecken <notifications@github.com>; wrote:. > To clarify a bit... I think it would be good to enable something like:; > sc.pl.umap(adata, color=(uns_dict_key, obs_column)); >; > Where the sc.pl.umap() function then does:; >; > if isinstance(color, tuple):; > color_vector = [adata.uns[color[1]+""_linked_data""][color[0]]][adata.obs[color[1]]]; > sc.pl.plot_scatter(adata, color=color_vector, ...); >; > It might need to be a pandas dataframe rather than a dictionary with the; > above setup.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/658?email_source=notifications&email_token=ABF37VINUTKOPIDJADJOMMTPWVGT3A5CNFSM4HOUNBK2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODV7ENLQ#issuecomment-494814894>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABF37VL26UDSJCBGW67HNNLPWVGT3ANCNFSM4HOUNBKQ>; > .; >. -- . Fidel Ramirez",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/658#issuecomment-495177880:101,redundant,redundant,101,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/658#issuecomment-495177880,1,['redundant'],['redundant']
Availability,"I think the issue that there are references to the `DotPlot` class, but no doc page get's generated for that class. I think this can be fixed by adding something like:. ```rst; Classes used for these plots:. .. autosummary::; :toctree: . pl._dotplot.DotPlot; ```. to the doc-string of the plotting module. Once this exists, there might be some other errors that pop up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1210#issuecomment-651513742:350,error,errors,350,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210#issuecomment-651513742,1,['error'],['errors']
Availability,"I think the main issue with the docs building right now is that there are references to the `DotPlot` class, but there isn't any page built for those to link to. I'm not sure the `**kwargs` argument is causing an issue, since the docs for `sc.queries.enrich` have this, and seem to work fine: https://scanpy.readthedocs.io/en/stable/api/scanpy.queries.enrich.html. I have had issues with doc build errors failing to show up if you just try and build the docs again. It might be worth running `make clean` before each `make build` to see what happens.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1309#issuecomment-655334219:398,error,errors,398,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1309#issuecomment-655334219,1,['error'],['errors']
Availability,"I think the plotting parameter would make a lot of sense. We should take a few things into account though when determining defaults here.; 1. Not all methods have log fold changes (`'logreg'` for example); 2. Ordering based on log FC will be different than based on the scoring (lowly expressed genes will typically have higher logFC). I'm not sure how meaningful the plot would then be...; 3. We initially didn't have any fold changes or p-values at all, partially because the marker gene DE test setup is ill-defined. You test gene in two groups where the groups are defined based on the genes you test... that will generate inflated p-values. Hence it might be a good idea to only consider the test as a way to order genes rather than a robust statistical test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1152#issuecomment-610607335:740,robust,robust,740,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1152#issuecomment-610607335,1,['robust'],['robust']
Availability,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks.; code. ```; x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'; Train_name = 'Baron'; Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'; Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata); all_adata = all_adata.concatenate(test_adata); ```. error; ```; AnnData object with n_obs × n_vars = 2133 × 22757; AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>; File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate; out.var.columns.str.extract(pat, expand=False); File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__; accessor_obj = self._accessor(obj); File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__; self._inferred_dtype = self._validate(data); File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate; raise AttributeError(""Can only use .str accessor with string values!""); AttributeError: Can only use .str accessor with string values!; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3261#issuecomment-2399331404:103,error,error,103,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261#issuecomment-2399331404,2,['error'],['error']
Availability,"I think the spring export function currently fails because it only checks whether each column in `adata.obs` is a pandas categorical variable (`not is_categorical(adata.obs[obs_name])`) and, if not, assumes it's a continuous variable and then tries to join a str with an integer. . If you look at your file `data.obs` contains a number of categorical variables that are currently numpy objects; ```pytb; data.obs.dtypes; ClusterID int32; ClusterName object; RNA_snn_res_0_5 object; nCount_RNA float32; nFeature_RNA int32; orig_ident object; percent_mt float32; seurat_clusters object; louvain category; dtype: object; ```. As a quick fix, I think you can do something like this:; ```python; adata = data.copy(); obj_cols = adata.obs.columns[adata.obs.dtypes == np.object]; adata.obs[obj_cols] = adata.obs[obj_cols].astype('category') ; sce.exporting.spring_project(adata, './pbmc3k', 'draw_graph', subplot_name='force1', overwrite=True); ```; Not sure what's the best way to fix it for the future: check for other dtypes or uses f-strings to avoid the str concatenation errors?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/889#issuecomment-590643431:1070,error,errors,1070,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/889#issuecomment-590643431,1,['error'],['errors']
Availability,"I think there's definitely room for more plotting libraries in the ecosystem, but have some doubts about whether all needs can be met by one library. I personally use `seaborn`/ `matplotlib`, `bokeh`, `datashader`, and `altair` for different cases. I also think making a good plotting API is exceedingly difficult, especially if you target both high and low level use cases. I would note that the plotting code in scanpy feels like some of the most maintenance intensive code in the library. > provides helper functions for handling colors, saving figures, etc. We can do a bit more of this here. But of course, much of it would end up being `matplotlib` specific. > encourages a consistent plotting API (e.g. by defining abstract base classes). I'd be interested in hearing specific thoughts on this. I've personally been thinking it would be nice to lean on `seaborn` plotting classes more heavily here, potentially contributing features upstream. Here's one example https://github.com/mwaskom/seaborn/issues/2487 of a feature which could fit the `AnnData` data model nicely. > there is quite some duplicated code in the plotting section. We'd definitely like to reduce the amount of duplicated code, which is what drove the addition of `sc.get`. This seems to be working out internally, if slowly. > All the scanpy helper functions for plotting (e.g. savefig_or_show, _set_color_for_categorical_obs etc.) are private scanpy functions. I'd like to move towards stabilizing this. I'm not sure how much we'd want to provide plotting library specific code, vs. more generic helpers. Right now the most obvious addition is `_set_color_for_categorical_obs`, which I'd also like to make accessible through `sc.get`. Adding `groupby` support to `anndata` would help a lot here too (https://github.com/theislab/anndata/issues/556). `save_fig_or_show` is something that I don't think we should export, and may need a rework (#1508).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1832#issuecomment-838305749:449,mainten,maintenance,449,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832#issuecomment-838305749,1,['mainten'],['maintenance']
Availability,"I think this is currently bugged by: https://github.com/numba/numba/issues/6774. It's a weird bug: some code just doesn't execute, unless I swap out a `prange` with a `range`, in which case it errors. Unless I add an expression that does nothing. Then it can work, except it's doing the expensive computation again 🤯. It looks like this won't be solved by the next numba release, so working around it will be necessary for timely inclusion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/915#issuecomment-788791783:193,error,errors,193,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/915#issuecomment-788791783,1,['error'],['errors']
Availability,"I think this looks good and simple enough. Could you please fix the CI errors?. Also there’s 3 added optional deps: cuml, cudf, and cugraph. I assume they’re all different CUDA packages. Could you add them into an `extra` in setup.py?. The RAPIDS umap branch doesn’t use a metric argument. Does it support metrics other than euclidean?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/830#issuecomment-534438279:71,error,errors,71,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830#issuecomment-534438279,1,['error'],['errors']
Availability,"I think this may be already implemented in https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.ingest.html, however, this function contains extra integration and label transfer steps that are not needed for all applications. It would be great if this could be disentangled to make the umap transform available as a separate function on scanpy umaps. Also, it seems that this function does not use scanpy umap to calculate umap so changes may be needed in how scanpy umap is currently calculated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2259#issuecomment-1237340704:308,avail,available,308,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259#issuecomment-1237340704,1,['avail'],['available']
Availability,"I think this more of an enhancement than a bug, though an error message saying we don't have a way to color by boolean values would be more clear. What would you expect this to look like? Which styling options apply here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1646#issuecomment-777891088:58,error,error,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1646#issuecomment-777891088,1,['error'],['error']
Availability,"I think this problem may cause by `seaborn`!. The following code should reproduce the error:. ```; import scanpy as sc; import seaborn as sns; sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(); sc.pl.umap(pbmc, color = 'phase'); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-863089065:86,error,error,86,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-863089065,1,['error'],['error']
Availability,"I think you have some variables which are the same for all samples. This leads to a division by zero error, which numba is not handling gracefully or mentioning. Here's how to find those values:. ```python; np.where((adata.X[[0], :] == adata.X).all(axis=0)); ```. I believe if you filter these out, this should work. I'm not sure if there is a correct value for Morans I or Gearys C in this case. Should we error?. --------------------. Numba bug report: https://github.com/numba/numba/issues/6976",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1698#issuecomment-826743830:101,error,error,101,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1698#issuecomment-826743830,2,['error'],['error']
Availability,"I think you're all good. Taking another look at the function I believe I had actually tried to completely replace the whole thing (since the logic is fairly convoluted), which ended up breaking functions that relied on the convoluted parts. I think ultimately the whole function should be replaced, ideally using `sc.get._get_obs_rep`. At that point we can rename the argument and make it more widely available.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2179#issuecomment-1081877491:401,avail,available,401,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179#issuecomment-1081877491,1,['avail'],['available']
Availability,"I thought it was breaking due to a couple behavior changes:. One case where the results would be different is the call `sc.read_10x_h5(h5pth)`, where the file at `h5pth` is a legacy formatted file which contains `mm10` and `hg38` genomes. Prior to this PR, only the `mm10` genome would be read in. Now, an error is thrown. . If the file had the `v3` format (also containing two genomes), now values for features from both genomes would be read in, instead of just `mm10`. Even better than removing an error, previously `v3` files would get all the vars filtered out and not throw an error!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/442#issuecomment-456723024:306,error,error,306,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/442#issuecomment-456723024,3,['error'],['error']
Availability,"I took about 20 minutes on it, but couldn't figure out how to add more annotations. I've got interactive versions with hover over, but log scale is bugged in those libraries... I believe the bins that are the darkest shade in the minimum cluster size for the unweighted graph actually correspond to a minimum cluster size of 1 cell. Megakaryocytes were detected as a distinct cluster every time that k was 10 in the unweighted case, but no other times. I think that when we make a call on ""this is a kind of cell"" from unsupervised clustering, those results should be robust. That is, if there's strong signal in the data and your clustering algorithm can pick up that signal, good clusters shouldn't change much if you vary the parameters a little. If you can pick any parameters from a wide range and get results that are pretty consistent, that seems like good data and a good method to me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-488191694:568,robust,robust,568,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-488191694,1,['robust'],['robust']
Availability,"I tried debug by myself and this is what I found at the break point: when the color represented by RGB values, such as `[array([0.29803922, 0.44705882, 0.69019608]), array([0.86666667, 0.51764706, 0.32156863]), array([0.33333333, 0.65882353, 0.40784314]), array([0.76862745, 0.30588235, 0.32156863])]`, it throws error. It may also cause by the default setting of `seaborn`. Since you have fixed it in #1886 , this problem should be fixed too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1884#issuecomment-864689573:313,error,error,313,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1884#issuecomment-864689573,1,['error'],['error']
Availability,I tried downgrading umap-learn to 0.4.6 but then sc.pp.neighbors won't work. I've been using scanpy 1.5.0,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1579#issuecomment-909192114:8,down,downgrading,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1579#issuecomment-909192114,1,['down'],['downgrading']
Availability,"I tried to set `var_names` from gene_symbols, and I get a warning message:; `Variable names are not unique. To make them unique, call `.var_names_make_unique`.`. In calling `adata.var_names_make_unique()` I get the error:; `TypeError: unsupported operand type(s) for +: 'float' and 'str'`. I can ignore this and take it through most of the analysis and am able to make the plots and rank the genes by name, however, I am unable to save. Calling `adata.write('./write/adata.h5ad')` gives the following error:. ```; File ""pandas/_libs/src/inference.pyx"", line 1472, in pandas._libs.lib.map_infer. TypeError: object of type 'float' has no len(); ```. Also, the clustering is slightly different, I'm guessing from not having unique gene names. I've looked through the documentation for `sc.pl.rank_genes_groups_*` and cannot figure out how to keep the index as the Ensembl gene ID and just use gene_symbols to call the plots (`sc.pl.violin`, etc.) and use the `sc.tl.rank_genes_groups`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/455#issuecomment-473778184:215,error,error,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-473778184,2,['error'],['error']
Availability,I updated it to python 3.6.8 and it gets past that error point. ; Thank you very much for all your help.; Cheers.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/734#issuecomment-509622325:51,error,error,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/734#issuecomment-509622325,1,['error'],['error']
Availability,"I updated release notes and added a test for this specific case. I did not write many tests before, so I looked at the other tests and tried to stick to what I saw there. I noted something unexpected when writing the test: When used `np.mean` and `np.var(.., ddof=1)` to compare against the test failed because some of the variances were off. The current version of the test uses `sc.pp._utils._get_mean_var()` (thats what `highly_variable_genes()` uses internally...), and does not fail.. Is it ok to use that instead? Is it expected that numpy and `_get_mean_var()` are slightly different here?. Test code with numpy ground truth:; ```; def test_seurat_v3_mean_var_output_with_batchkey_vs_numpy():; pbmc = sc.datasets.pbmc3k(); pbmc.var_names_make_unique(); n_cells = pbmc.shape[0]; batch = np.zeros((n_cells), dtype=int); batch[1500:] = 1; pbmc.obs[""batch""] = batch. true_mean = np.mean(pbmc.X.toarray(), axis=0); true_var = np.var(pbmc.X.toarray(), axis=0, ddof=1). result_df = sc.pp.highly_variable_genes(; pbmc, batch_key='batch', flavor='seurat_v3', n_top_genes=4000, inplace=False; ); np.testing.assert_allclose(true_mean, result_df['means'], rtol=2e-05, atol=2e-05); np.testing.assert_allclose(true_var, result_df['variances'], rtol=2e-05, atol=2e-05); ```; Test output:; ```; E AssertionError: ; E Not equal to tolerance rtol=2e-05, atol=2e-05; E ; E Mismatched elements: 172 / 32738 (0.525%); E Max absolute difference: 0.01117667; E Max relative difference: 0.00013328; E x: array([0., 0., 0., ..., 0., 0., 0.], dtype=float32); E y: array([0., 0., 0., ..., 0., 0., 0.]). tests/test_highly_variable_genes.py:279: AssertionError; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1732#issuecomment-797052072:1321,toler,tolerance,1321,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1732#issuecomment-797052072,1,['toler'],['tolerance']
Availability,I updated to 1.3.3 but the error still persists. One important thing I didnt mention before: I am running python/scanpy on a Windows machine. @Donovan-CG do you also use Windows?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/333#issuecomment-435784820:27,error,error,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/333#issuecomment-435784820,1,['error'],['error']
Availability,I upgraded loompy and scanpy as well but now I am getting an other error. ![screen shot 2018-08-29 at 19 21 34](https://user-images.githubusercontent.com/42487820/44782019-db881800-abc0-11e8-8948-90aa0b0c20a1.png). ![screen shot 2018-08-29 at 19 14 14](https://user-images.githubusercontent.com/42487820/44782040-eb076100-abc0-11e8-961e-75b4ba0c8ec7.png),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/247#issuecomment-416903663:67,error,error,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/247#issuecomment-416903663,1,['error'],['error']
Availability,"I was also investigating how `leiden` got `use_weights=True` by default, and noticed the lack of discussion. Seems like it just sorta happened when `leiden` got added #361?. I think it'd be pretty different from clustering on the embedding, because the embedding has constraints based on things like minimum distance two points can be from each other, and the number of dimensions it's embedded in. On the binarized KNN-graph, I think we've actually talked about this before (#240). I personally think using a weighted graph makes more sense. For example, say you have a cell type of which occurs 15 times in your dataset, but you've set k to 30. With a binarized graph there will be a less clear signal that this is a distinct cell-type. From a slightly more empirical/ anecdotal perspective, on a couple datasets I tested, total degree of the generated graph was sub-linear (looked log-ish) w.r.t. `k` for the weighted umap graph. Here's using one of the bone marrow donors from the hca immune census (y-axis is log scaled so you can still see the total weighted degree increase):. ![image](https://user-images.githubusercontent.com/8238804/56469005-400d2580-6477-11e9-98f1-b9dfe70bd1d7.png). To me, this suggested a stable representation of the dataset was being found. As a connected point, in my experience clustering results seems fairly robust to `k` for weighted graphs above a low threshold (I think dataset dependent, but 30-60 range). Using an unweighted graph, there is a much stronger dependence on `k` and some smaller clusters seem less stable (show up in a smaller proportion of clustering solutions from a parameter space).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-485242638:1344,robust,robust,1344,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-485242638,1,['robust'],['robust']
Availability,"I was following the documentation and kept getting failures when I tried to pass additional args to violin() via kwargs, and found that kwargs was only [added to violin 6 days ago](https://github.com/theislab/scanpy/blame/master/scanpy/plotting/anndata.py#L347). Yay (and thanks) for the updates)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/85#issuecomment-371026156:51,failure,failures,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/85#issuecomment-371026156,1,['failure'],['failures']
Availability,"I was referring to both the instability and what i understood to mean non-robustness to different datasets. But it seems a ""use case"" is an analytical step here, rather than a particular dataset to be analysed. That makes it a lot better, and it means there is work to be done but a general best practice conclusion would be reachable. . In that case it's only the instability of the algorithm that is the issue per dataset. And in the case where you're doing exploratory analysis for a new dataset, you don't typically have a validation dataset, which makes this pretty challenging for end users of the method. Enrichment could be a way forward I guess... I'm not the biggest fan of using enrichment results as a measure for success though. Enrichment results still require quite a bit of interpretation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/941#issuecomment-560323107:74,robust,robustness,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/941#issuecomment-560323107,1,['robust'],['robustness']
Availability,"I will check. Meanwhile, I realized that some errors were introduced in the latest plotting functions, thus I started working in a list of tests to avoid those problems in the future.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/204#issuecomment-405303780:46,error,errors,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/204#issuecomment-405303780,1,['error'],['errors']
Availability,"I will close the issue for now, as based on the provided information and the discussion so far, it seems that the question has been addressed and hopefully resolved :). However, please don't hesitate to start user questions on [scverse discourse](https://discourse.scverse.org/), or software & maintenance releated things here. Or reopen the issue if you think I missed your point!. Thanks for being a part of our community! :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2821#issuecomment-1951935265:294,mainten,maintenance,294,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2821#issuecomment-1951935265,1,['mainten'],['maintenance']
Availability,"I will close this issue because there is an external solution available. We may think about integrating this specific plot into Scanpy at some point, but I don't see it happening anytime soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1824#issuecomment-953646449:62,avail,available,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1824#issuecomment-953646449,1,['avail'],['available']
Availability,"I would agree the results of `sc.pp.filter_genes(..., inplace=False)` are not the most intuitive. Instead of returning a filtered anndata, it returns which cells would have been filtered and the stats which were used to make this decision. This is documented under the `Returns` section for these functions. What you might want is. ```python; mask, _ = sc.pp.filter_cells(adata, min_genes=200, inplace=False); a = adata[mask].copy(); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2030#issuecomment-993648137:343,mask,mask,343,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2030#issuecomment-993648137,2,['mask'],['mask']
Availability,"I would probably just pass those through with kwargs. At the moment, I'm not sure I would include this within scanpy, since it's fairly easy for users to do on their own and I'm not sure many people would want to use it. Using a mask to just scale a subset of the data could fit under a possible `mask` keyword argument.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2142#issuecomment-1046729522:229,mask,mask,229,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2142#issuecomment-1046729522,2,['mask'],['mask']
Availability,"I'd be up for all of the numbered ones. IIRC, I had some issues with the trailing whitespace/ end of file fixers and some binary files/ csvs in the test suite. I'm a bit worried about false positives with `check-large-files`, but so long as it's easy to allow certain things (e.g. intentionally added test data) it should be fine. In terms of breaking these things down into small tasks/ PRs how about: (1), (2, 3), (4, 5)?. `prettier` looks a bit heavy and like it's targeting a lot of stuff we don't use, so you'd have to make a good case.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1563#issuecomment-842799143:365,down,down,365,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563#issuecomment-842799143,1,['down'],['down']
Availability,"I'd like to bump the version requirement down a bit, since it seems like it's not that uncommon to pin `map-learn` lower than 0.5.5: https://github.com/search?q=%2F%5B%22%27%5D%3Fumap-learn%5B%22%27%5D%3F%5B%3D%3E%3C%5D%2B%2F&type=code. The cellxgene one is worrying",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2870#issuecomment-1957629969:41,down,down,41,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2870#issuecomment-1957629969,1,['down'],['down']
Availability,"I'm actually testing and tweaking someone else's code that was written a while ago. I assume they used; `import scanpy.api as sc` because it was appropriate then. I personally resolved my issue by downgrading versions, I just wanted to bring this up!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1397#issuecomment-683807774:197,down,downgrading,197,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1397#issuecomment-683807774,1,['down'],['downgrading']
Availability,"I'm also getting a separate error:; ""simplicial_set_embedding() missing 3 required positional arguments: 'densmap', 'densmap_kwds', and 'output_dens'""; When I run scanpy.tl.umap. Not sure if this is related.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2169#issuecomment-1064638508:28,error,error,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169#issuecomment-1064638508,1,['error'],['error']
Availability,"I'm also getting this list error, but @brianpenghe 's suggestion of using `swap_axes=True` also seems to have fixed the problem. At least it shows a plot now, although not sure if its correct yet",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/405#issuecomment-471151481:27,error,error,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/405#issuecomment-471151481,1,['error'],['error']
Availability,"I'm also seeing the same error when using `sc.ppl.scatter`:; `sc.pl.scatter(adata, color='louvain', basis=""umap"", palette=""tab20"")`. ![image](https://user-images.githubusercontent.com/7407663/47046149-80a38380-d162-11e8-9865-6548c7e9454d.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/286#issuecomment-430393368:25,error,error,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/286#issuecomment-430393368,1,['error'],['error']
Availability,"I'm also suddenly having this problem with ""ValueError: Length of values (1) does not match length of index()"" for certain Scanpy functions like `sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac')` and numpy functions `adata.obs['log_counts'] = np.log(adata.obs['n_counts'])`. The error is not due to a problem with my adata file because it reproduces with datasets that were previously error-free.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2008#issuecomment-944874522:291,error,error,291,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008#issuecomment-944874522,2,['error'],"['error', 'error-free']"
Availability,"I'm getting an error loading scanpy (#739 ), and it points to the line you moved about deferring loading of umap-learn. . When I revert back to commit abf95c645828e29edf5a7a27b05d9397f3c36f65 (the commit a couple before this), it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/704#issuecomment-511887782:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704#issuecomment-511887782,1,['error'],['error']
Availability,"I'm getting the same error from RStudio with reticulate:. From the console:. ```; py_install('scanpy'); Collecting package metadata (current_repodata.json): ...working... done; Solving environment: ...working... done. # All requested packages already installed. Collecting package metadata (current_repodata.json): ...working... done; Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.; Collecting package metadata (repodata.json): ...working... done; Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve. PackagesNotFoundError: The following packages are not available from current channels:. - scanpy. Current channels:. - https://conda.anaconda.org/conda-forge/linux-64; - https://conda.anaconda.org/conda-forge/noarch; - https://repo.anaconda.com/pkgs/main/linux-64; - https://repo.anaconda.com/pkgs/main/noarch; - https://repo.anaconda.com/pkgs/r/linux-64; - https://repo.anaconda.com/pkgs/r/noarch. To search for alternate channels that may provide the conda package you're; looking for, navigate to. https://anaconda.org. and use the search bar at the top of the page. Error: one or more Python packages failed to install [error code 1]; ```. If I switch to the terminal and try `pip` or `conda` I get:. ```; pip install scanpy; ```. ```; Requirement already satisfied: scanpy in /home/tsundoku/anaconda3/lib/python3.7/site-packages (1.4.5.post2); Requirement already satisfied: setuptools-scm in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from scanpy) (3.3.3); Requirement already satisfied: scipy>=1.3 in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from scanpy) (1.3.2); Requirement already satisfied: pandas>=0.21 in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from scanpy) (0.25.3); Requirement already satisfied: packaging in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from scanpy) (19.2); Requirement already satisfied: natsort in /home/tsundoku/anacond",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990#issuecomment-575281452:21,error,error,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990#issuecomment-575281452,2,"['avail', 'error']","['available', 'error']"
Availability,"I'm getting the same error using the CellBender tutorial output. Attaching the file to make it easier to reproduce. [tiny_10x_pbmc_filtered.h5.zip](https://github.com/scverse/scanpy/files/8766499/tiny_10x_pbmc_filtered.h5.zip). `sc.logging.print_versions()`. ```; -----; anndata 0.7.8; scanpy 1.9.1; -----; PIL 9.0.1; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; doubletdetection 4.2; entrypoints 0.4; executing 0.8.3; google NA; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.9; ipykernel 6.10.0; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.2; leidenalg 0.8.9; llvmlite 0.38.0; louvain 0.7.1; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; mudata 0.1.1; muon 0.1.2; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.2; organize_metadata NA; packaging 21.3; pandas 1.4.1; parso 0.8.3; pexpect 4.8.0; phenograph 1.5.7; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.28; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.6; pyparsing 3.0.7; pytz 2022.1; scikits NA; scipy 1.8.0; seaborn 0.11.2; session_info 1.0.0; setuptools 62.0.0; setuptools_scm NA; six 1.16.0; sklearn 1.0.2; stack_data 0.2.0; statsmodels 0.13.2; tables 3.7.0; texttable 1.6.4; threadpoolctl 3.1.0; tornado 6.1; tqdm 4.63.1; traitlets 5.1.1; typing_extensions NA; umap 0.5.2; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 8.2.0; jupyter_client 7.1.2; jupyter_core 4.9.2; notebook 6.4.10; -----; Python 3.9.11 (main, Mar 28 2022, 10:10:35) [GCC 7.5.0]; Linux-4.15.0-142-generic-x86_64-with-glibc2.27; -----; Session information updated at 2022-05-24 15:05; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2203#issuecomment-1136479284:21,error,error,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203#issuecomment-1136479284,1,['error'],['error']
Availability,"I'm getting this too. This could be a problem with numpy's random: ; https://github.com/DLR-RM/stable-baselines3/issues/1579 ; https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py; Line 185 ; `part = g.community_leiden(**clustering_args)`. calls the following. community.py; Line 442; ```; membership, quality = GraphBase.community_leiden(; graph,; edge_weights=weights,; node_weights=node_weights,; resolution=resolution,; normalize_resolution=(objective_function == ""modularity""),; beta=beta,; initial_membership=initial_membership,; n_iterations=n_iterations,; ); ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**; Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3028#issuecomment-2078897575:818,error,error,818,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028#issuecomment-2078897575,1,['error'],['error']
Availability,"I'm having some trouble debugging whatever is going wrong with the notebook tests here. I get the same results if I run `pytest` on my machine, but don't get a failure if I run the code manually. Additionally, I don't get an error (the `abort`) if I *only* run the notebook tests (`pytest -k ""test_pbmc3k""`). Pretty sure the error is happening on the call to louvain in the notebook tests – an `assert False` fails the tests, one after gives current result – but I can't reproduce the abort interactively. Any idea what's going on/ how I can get a more helpful error message here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/248#issuecomment-419695136:160,failure,failure,160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/248#issuecomment-419695136,4,"['error', 'failure']","['error', 'failure']"
Availability,"I'm having some trouble reproducing this. Can you provide a complete example that reproduces this. I need to be able to recreate the data that causes this error for you locally. On my end, this works:. ```python; import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); sc.tl.rank_genes_groups(pbmc, groupby=""louvain"", method=""wilcoxon""); sc.tl.filter_rank_genes_groups(; pbmc,; min_fold_change=1,; min_in_group_fraction=0.25,; max_out_group_fraction=0.5,; use_raw=False,; ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1670#issuecomment-782792403:155,error,error,155,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670#issuecomment-782792403,1,['error'],['error']
Availability,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:; ```; In [23]: adata.write(""cellxgene.h5ad"") ; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-23-33b15d710f71> in <module>; ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense); 2222 compression=compression,; 2223 compression_opts=compression_opts,; -> 2224 force_dense=force_dense,; 2225 ); 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs); 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs); 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs); ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs); 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs); 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs); 103 if key in f:; 104 del f[key]; --> 105 _write_method(type(value))(f, key, value, dataset_kwargs); 106 ; 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs); 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):; 204 for sub_key, sub_value in value.items():; --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs); 206 ; 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs); 103 if key in f:; 104 del f[key",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/832#issuecomment-544968526:20,error,error,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832#issuecomment-544968526,4,"['down', 'error']","['downgrade', 'error']"
Availability,I'm having the same issue using pp.neighbors for a slightly different clustering purpose. It seems to handle ~200k data points just fine but above ~300k gives `Segmentation fault (core dumped)` no matter how much memory I allocate to the job. ; The quick fix with threads above did not work for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2361#issuecomment-1426965264:173,fault,fault,173,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1426965264,1,['fault'],['fault']
Availability,I'm having this issue where I read in and merge multiple anndata's with concat. I can't run any of the plotting functions because I get this error. I tried to convert all object/string obs to categorical (except obs names) but I can't really get around it at all.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/166#issuecomment-1696555861:141,error,error,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166#issuecomment-1696555861,1,['error'],['error']
Availability,I'm having trouble reproducing this error. Could you share what versions you have installed (ideally also try updating these to the latest releases) and see if you can replicate the issue on one of the datasets in `sc.datasets`?. I think you should probably do differential expression plots using the same values you used to compute the differential expression in most cases.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2046#issuecomment-963259525:36,error,error,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2046#issuecomment-963259525,1,['error'],['error']
Availability,"I'm not sure I agree with your interpretation of your total degree plot. To me, increasing `k` is meant to have the effect of densifying the network, and thus obtaining a lower resolution view of the manifold. It is somewhat analogous to choosing a lower resolution value for `leiden` or `louvain` clustering. What you see is that in the weighted case, the overall degree does not really increase (thus possibly neither does the overall density), so that increasing `k` may have little effect on clustering at all. This is the most I can get from this plot... as density is really about local changes and not the global degree increase. But I would still ask whether it is a good thing that increasing `k` has little effect? Does increasing `k` then change the clustering results (in the weighed case?). I wonder if the observation that you find smaller clusters better in the weighted case is robust. That would suggest that weights can counteract resolution limit issues, which would be very interesting...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-485700014:894,robust,robust,894,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-485700014,1,['robust'],['robust']
Availability,I'm not sure I entirely understand what the weights are based on. I'm trying to understand when you would suggest someone use your approach. Why do you give one cell a weight of 125? With this type of weight distribution you are basically manually changing the marker gene calculation focusing nearly only on a single cell. That seems strange to me. I'm trying to understand the need for scanpy to support weighted observations. At the moment I don't see when you would want to differently weight the observations... I'm familiar with using weights if I have some form of measurement error or uncertainty between samples. I don't really see how that holds here. Do you weight the cells based on some kind of quality score?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494122404:584,error,error,584,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494122404,1,['error'],['error']
Availability,"I'm not sure that pytest issue convinced me importlib is a good thing... A few of the recent *pytest developer* comments that caught my eye were:. > FWIW I'm convinced at this point that we should not change the import-mode to importlib anytime soon, some things just get harder to setup for out-source testing setups. > > We're interested in making our tests future-proof; >; > One way to do that is to add addopts = --importmode=prepend to your pytest.ini file. We don't intend to remove the prepend mode in the future at all. > FTR, IMO we probably should not change the default to importlib anytime soon (or ever)... . I would be up for a PR that only moved things outside of the test module. Things that would probably slow down or prevent merging would include:. * Changing the import mode; * Changing organization of tests; * Changing calling conventions for pytest. All of these things seem like they can be done in other PRs easily after test utilities are moved. Right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2225#issuecomment-1098230922:729,down,down,729,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225#issuecomment-1098230922,1,['down'],['down']
Availability,I'm not sure what is the cause of the problem and how to resolve it. But it I remove everything in the metadata aside from index and genecount/genenumber the error does not come up. So one solution is to save metadata to a csv and save the adata without too much metadata info.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1891204482:158,error,error,158,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1891204482,1,['error'],['error']
Availability,I'm pretty sure it's the pandas 0.23 issue... same error message as the one encountered here: https://github.com/theislab/scanpy/issues/158,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/162#issuecomment-391991529:51,error,error,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162#issuecomment-391991529,1,['error'],['error']
Availability,I'm pretty sure none of you are having the same issue as the original one reported here. Compare @abuchin 's error message of `KeyError: 'dict'` to the original poster's error of `OSError: Can't read data`. The thing you're seeing is a new one stemming from an update to anndata. You're trying to read in a `h5ad` file created with a newer version of the package with your older one. I think the cutoff point is 0.8.0 but I could be mistaken. Upgrade your anndata and you should be ok.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-1198015945:109,error,error,109,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-1198015945,2,['error'],['error']
Availability,"I'm pushing this from 1.9, but am also considering how well posed the issue is. There's a fairly complicated relationship between this kind of ""normalization"" and the `norm`, `vmin`, `vmax`, etc. arguments. I think this would need a tutorial (at least) to go with it. Some thoughts:. * Basically, what this feature is is an additional transformation applied to the summarized values before they are mapped to colors. This could (and probably should) also be available for sizes of the dots.; * This is kinda covered by matplotlib's `norm` values, but those can only be applied to all the data at once – not per group.; * If we make it easier to split out getting summarized dataframe then plotting the values, this could largely be handled in user code.; * If you are doing a `z-score` normalization, surely you'd want a centered colorbar and diverging palette?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1757#issuecomment-1084726453:458,avail,available,458,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757#issuecomment-1084726453,1,['avail'],['available']
Availability,"I'm thinking `n_comps` should default to `None`, and we'd define behaviour like:. ```python; if n_comps is None:; min_dim = min(adata.n_vars, adata.n_obs); if 50 >= min_dim:; n_comps = min_dim - 1; else:; n_comps = 50; ```. and we let sklearn throw an error if the user specified a number of components that doesn't work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1051#issuecomment-586662503:252,error,error,252,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051#issuecomment-586662503,1,['error'],['error']
Availability,"I've been able to pin down the culprit.; Excluding this line ```adata = adata[:, adata.var.highly_variable]``` allows Leiden clustering to populate",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2330#issuecomment-1249550226:22,down,down,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330#issuecomment-1249550226,1,['down'],['down']
Availability,"I've been thinking it would be good to add a `mask` argument to a number of functions. I think `mask_vars=~(adata.var[""mito""] | adata.var[""ribo""])` could work here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1744#issuecomment-800775264:46,mask,mask,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744#issuecomment-800775264,1,['mask'],['mask']
Availability,"I've encountered similar issue last week and it was because `adata.obs` contained a column which was `n_obs x 1` `scipy.sparse.spmatrix`. The below code reproduces the formatter issue (`pandas==1.3.3`):. ```python; import scanpy as sc; from scipy.sparse import csr_matrix. adata = sc.datasets.pbmc3k(); adata.X = csr_matrix(adata.X); adata.obs['total_counts'] = adata.X.sum(1) # is sparse, pandas doesn't complain; adata.obs # raises the formatter error; ```. <details>. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/IPython/core/formatters.py in __call__(self, obj); 700 type_pprinters=self.type_printers,; 701 deferred_pprinters=self.deferred_printers); --> 702 printer.pretty(obj); 703 printer.flush(); 704 return stream.getvalue(). ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/IPython/lib/pretty.py in pretty(self, obj); 392 if cls is not object \; 393 and callable(cls.__dict__.get('__repr__')):; --> 394 return _repr_pprint(obj, self, cycle); 395 ; 396 return _default_pprint(obj, self, cycle). ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/IPython/lib/pretty.py in _repr_pprint(obj, p, cycle); 698 """"""A pprint that just redirects to the normal repr function.""""""; 699 # Find newlines and replace them with p.break_(); --> 700 output = repr(obj); 701 lines = output.splitlines(); 702 with p.group():. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/core/frame.py in __repr__(self); 993 else:; 994 width = None; --> 995 self.to_string(; 996 buf=buf,; 997 max_rows=max_rows,. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/core/frame.py in to_string(self, buf, columns, col_space, header, index, na_rep, formatters, float_format, sparsify, index_names, justify, max_rows, min_rows, max_cols, show_dimensions, decimal, line_width, max_colwidth, encoding); 1129 decimal=decimal,; 1130 ); -> 1131 return fmt",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2008#issuecomment-947943666:448,error,error,448,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008#issuecomment-947943666,1,['error'],['error']
Availability,"I've encountered this error as well. deleting the raw attributes did not help but what worked was changing the CSR matrix to an array. so `adata.X = adata.X.toarray()`. Hopefully, this will help others.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1295#issuecomment-797806911:22,error,error,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295#issuecomment-797806911,1,['error'],['error']
Availability,"I've figured out what was causing my error. The scanpy function to read in `features.tsv.gz` expects three columns: `['gene_symbols, 'gene_ids', 'feature_types']`; Where 'feature types' is a text string like 'Gene Expression' and usually repeated along the whole length of the file.; The file I was reading in was from HTO data and only had one column:. > Hashtag1-GTCAACTCTTTAGCG; > Hashtag2-TTCCGCCTCTCTTTG; > Hashtag3-AAGTATCGTTTCGCA; > unmapped. So if others run into this same error, just add in some extra columns to the `features.tsv` file so it doesn't error out when looking for the extra columns. Something like this (different features file):. >RP11-34P13.7	RP11-34P13.7	Gene Expression; >FO538757.3	FO538757.3	Gene Expression; >FO538757.2	FO538757.2	Gene Expression; >AP006222.2	AP006222.2	Gene Expression; >RP4-669L17.10	RP4-669L17.10	Gene Expression. It would also be helpful if scanpy would validate the number of columns at the start. At the moment it looks like it reads in the whole `.mtx` file before trying to map the feature names and producing this error, so it takes a while to fail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1916#issuecomment-1286404697:37,error,error,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916#issuecomment-1286404697,4,['error'],['error']
Availability,"I've fixed the error I was getting, which was posted on another issue and referenced here.; Here's the solution that worked for me:; https://github.com/scverse/scanpy/issues/1916#issuecomment-1286404697",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2053#issuecomment-1286416876:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2053#issuecomment-1286416876,1,['error'],['error']
Availability,"I've found a workaround, when I downgrade to `anndata=0.6.22.post1` (still with `scanpy==1.4.5.post2`), it generates an output with `paga_path` but also this warning:. ```; FutureWarning: In anndata v0.7+, arrays contained within an AnnData object will maintain their dimensionality. For example, prior to v0.7 `adata[0, 0].X` returned a scalar and `adata[0, :]` returned a 1d array, post v0.7 they will return two dimensional arrays. If you would like to get a one dimensional array from your AnnData object, consider using the `adata.obs_vector`, `adata.var_vector` methods or accessing the array directly.; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/953#issuecomment-583346609:32,down,downgrade,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/953#issuecomment-583346609,1,['down'],['downgrade']
Availability,"I've got one minor comment left (one last redundant print statement), but otherwise I'm good.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-480637170:42,redundant,redundant,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-480637170,1,['redundant'],['redundant']
Availability,"I've got two main reasons for thinking they should be more visible:. 1. If I'm trying to find what tools are available through scanpy for a certain task, it should be very obvious where that might be available. For example, if I want to know what's available for batch correction, I (the user) am probably not too fussed about whether it's in the scanpy codebase or not.; 2. As a method developer, it'd encourage me to integrate my method if I saw it'd be highly visible and that other people were doing it. Right now there are links, but users still have to go to see the notes with those links, go to a separate page, and scroll for a bit to see any particular method. . Another strategy could be a top level `External API` heading underneath the `API` heading? Then there could be an expandable table of contents (how I typically navigate the site) to get an idea of what's there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/588#issuecomment-479739101:109,avail,available,109,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/588#issuecomment-479739101,3,['avail'],['available']
Availability,"I've managed to fix this up a bit. Missing (or masked - for `groups`) values in categorical arrays are now always plotted on bottom and use a default color. For spatial plots this default color is transparent. This has led to some code simplification. Surprisingly, this didn't break any tests locally, so a bunch of new tests are probably needed. Continuous values are still a little weird. Right now the points don't show up on embedding plots, and mess up all the colors for spatial plots.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1356#issuecomment-674738421:47,mask,masked,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1356#issuecomment-674738421,1,['mask'],['masked']
Availability,"I've punted on this issue for getting the expression atlas downloader added. I think it'd be worth changing the default data directory at the same time as dealing with configuration more generally, so related breaking changes can happen together. I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. [Everett](https://everett.readthedocs.io/en/latest/index.html) seems nice, but maybe a little immature. I like the ability to use context managers (making testing easier) and the auto documentation features. Generally, I think there should be a longer planning discussion about how configuration works. But that could be multiple issues. For example:. * Could we not change global state for plotting? We could shift over to using the `pyplot.rc_context` manager internally.; * What's the appropriate way to set logging level? It seems to keep changing and breaking things; * What's the appropriate precedence for config setting? I'd think `set in session > environment variable > config file > defaults`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-478214932:59,down,downloader,59,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478214932,1,['down'],['downloader']
Availability,"I've used it a bit, and have gotten nice results. I think I've mentioned it before (#938), but that was on an unrelated issue so it's good to have. The results are nice:. <details>; <summary> Example usage </summary>. ```python; from adjustText import adjust_text. def gen_mpl_labels(; adata, groupby, exclude=(), ax=None, adjust_kwargs=None, text_kwargs=None; ):; if adjust_kwargs is None:; adjust_kwargs = {""text_from_points"": False}; if text_kwargs is None:; text_kwargs = {}. medians = {}. for g, g_idx in adata.obs.groupby(groupby).groups.items():; if g in exclude:; continue; medians[g] = np.median(adata[g_idx].obsm[""X_umap""], axis=0). if ax is None:; texts = [; plt.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items(); ]; else:; texts = [ax.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items()]. adjust_text(texts, **adjust_kwargs). with plt.rc_context({""figure.figsize"": (8, 8), ""figure.dpi"": 300, ""figure.frameon"": False}):; ax = sc.pl.umap(pbmc, color=""Low-level celltypes"", show=False, legend_loc=None, frameon=False); gen_mpl_labels(; pbmc,; ""Low-level celltypes"",; exclude=(""None"",), # This was before we had the `nan` behaviour; ax=ax,; adjust_kwargs=dict(arrowprops=dict(arrowstyle='-', color='black')),; text_kwargs=dict(fontsize=14),; ); fig = ax.get_figure(); fig.tight_layout(); plt.show(); ```. </details>. ![image](https://user-images.githubusercontent.com/8238804/100496350-81af9780-31a7-11eb-8b38-2eb7f914c1a1.png). I believe you're also supposed to be able to make the text repel from points, so they don't sit on top of your data, but I had some trouble getting that working at the time. I'm a bit antsy about having this as a required dependency since maintenance [doesn't seem too active](https://pypi.org/project/adjustText/#history). Could be an optional dependency, used with `legend_loc=""adjust_text""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1513#issuecomment-735051689:1710,mainten,maintenance,1710,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513#issuecomment-735051689,1,['mainten'],['maintenance']
Availability,"IIRC, it's discussed in more detail in Malte's paper:. > ; In the same way that cellular count data can be normalized to make them comparable between cells, gene counts can be scaled to improve comparisons between genes. Gene normalization constitutes scaling gene counts to have zero mean and unit variance (z scores). This scaling has the effect that all genes are weighted equally for downstream analysis. There is currently no consensus on whether or not to perform normalization over genes. While the popular Seurat tutorials (Butler et al, [2018](https://www.embopress.org/doi/full/10.15252/msb.20188746#core-msb188746-cit-0020)) generally apply gene scaling, the authors of the Slingshot method opt against scaling over genes in their tutorial (Street et al, [2018](https://www.embopress.org/doi/full/10.15252/msb.20188746#core-msb188746-cit-0125)). The preference between the two choices revolves around whether all genes should be weighted equally for downstream analysis, or whether the magnitude of expression of a gene is an informative proxy for the importance of the gene. In order to retain as much biological information as possible from the data, we opt to refrain from scaling over genes in this tutorial. https://www.embopress.org/doi/full/10.15252/msb.20188746. Since there has been no new development on this topic, we cited Malte and also opted not to scale. This is also discussed by Malte himself in the issue that was cited above. I cannot comment on spatial data itself and make confident statements here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2963#issuecomment-2034415456:388,down,downstream,388,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2963#issuecomment-2034415456,2,['down'],['downstream']
Availability,"If it is caused by the same score, how to ensure the uniquenss? Thanks. I did not receive the var.unique.name error thus I think it was not caused by duplicate gene names. It is neurips 2021 single cell competition dataset.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2819#issuecomment-1906382163:110,error,error,110,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2819#issuecomment-1906382163,1,['error'],['error']
Availability,"If we pinned `umap-learn>=0.5.1`.1 it would be impossible to install scvelo, since [it pins umap<0.5](https://github.com/theislab/scvelo/blob/1659cc8e00a45fcf87cd80a7013aae5531744613/requirements.txt#L9). We can ban umap 0.5.0 specifically. It's generally important that scanpy has a broad-ish range of versions it's comparable with, since there's a lot downstream. I'd be happy bump umap to above 0.4 though, since it has been a while for that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-846949206:354,down,downstream,354,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-846949206,1,['down'],['downstream']
Availability,"If you don’t share the error, we can’t help you. Could you include the full error traceback?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3049#issuecomment-2107534834:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049#issuecomment-2107534834,2,['error'],['error']
Availability,"In #706 @LuckyMD gives a minimal working example in [this comment](https://github.com/theislab/scanpy/issues/706#issuecomment-505335006) that may give you a useful starting point. Their advice to create/post a way to reproduce the error is good too, as it may help you identify the source of the problem in the process (and make it easier for others to help troubleshoot)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/952#issuecomment-567617566:231,error,error,231,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/952#issuecomment-567617566,1,['error'],['error']
Availability,"In case anyone has this error again, here is what worked for me:. - go to https://www.lfd.uci.edu/~gohlke/pythonlibs/ and download a .whl file for h5py. For python 3.6 on a 64bit windows OS this is the file h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl; - with your conda environment activated, install that wheel file using `python -m pip install --user --force-reinstall h5py‑2.10.0‑cp36‑cp36m‑win_amd64.whl` (change the file name to the one you downloaded).; - scanpy should work now. This worked on mine and also on a colleagues windows laptop. I guess the problem is that you need a C++ compiler to build the necessary H5DF libraries. This works fine in UNIX based OS (Mac and Linux), but in windows you would need to download the most recent C++ compiler from some microsoft build tools website or alongside Visual Studio. So installing a prebuildt wheel for windows circumwents that problem. I wonder when h5py people will ever fix this for us poor Windows users.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-828487442:24,error,error,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-828487442,4,"['down', 'error']","['download', 'downloaded', 'error']"
Availability,"In my experience, this happens if batch key is not None and one or more batches have low number of cells. Does it make sense to catch this error and simply skip the problematic batch or inform the user that batch doesn't have enough cells?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1504#issuecomment-748548060:139,error,error,139,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504#issuecomment-748548060,1,['error'],['error']
Availability,"In supplementary figure 9 of our paper, I did a light comparison of tools using the demuxlet data as ground truth: https://www.cell.com/cms/10.1016/j.cels.2020.05.010/attachment/040c239d-1e70-42a4-8974-9fbd75c65551/mmc1.pdf; Which I think is a fine first stab at getting at this comparison, but it could be better. Hashsolo performance was comparable with other methods but is able to recover cell types with lower CMO counts. . I think that sounds great. That's an issue we had as well, but I noticed it occurring for NK cells in kidney; ![Screen Shot 2021-01-13 at 9 18 30 AM](https://user-images.githubusercontent.com/6864886/104486266-5d095680-5580-11eb-971e-c882063f2a45.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-759597008:385,recover,recover,385,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-759597008,1,['recover'],['recover']
Availability,"In that case, I don't fully understand this typing and will just continue reading quietly ;). I assumed it would throw errors as for example in C++.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-441254115:119,error,errors,119,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-441254115,1,['error'],['errors']
Availability,"In the current release, we check for the counts being integer valued. kallisto can assign partial counts, (e.g a gene can have 1.5 counts) which triggers the check, triggering an error. For the next bugfix release we've softened consequences of this check failing to a warning, and the check can be skipped. See discussion in #1642 and #1679 for details.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1782#issuecomment-814591832:179,error,error,179,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782#issuecomment-814591832,1,['error'],['error']
Availability,"In the error it looks like numba requires numpy < 1.20, so you could try installing the `numpy‑1.19.5+mkl` whl from https://www.lfd.uci.edu/~gohlke/pythonlibs/#numpy before installing the scikit-misc one from https://www.lfd.uci.edu/~gohlke/pythonlibs/#scikit-misc? . When you get the `Requirement already satisfied` error from `pip install`, you might need to first do `pip uninstall <pkg>` before installing",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000950644:7,error,error,7,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000950644,2,['error'],['error']
Availability,"In theory I think we can do most of that. In practice, I got some errors. I think it would be worth formalizing what the supported interface for doing multimodal analysis is. I'd really like it to be uniform. I could see it being based on keys in `.var`:. ```python; adata.var[""gex""] = adata.var[""expression_type""] == ""Gene Expression""; sc.pl.pca(adata, var_key=""gex""); sc.pl.pca(adata, color=[""Protein1"", ""Protein2""]); # This also has the nice feature that it could abstract out the current `use_highly_variable` argument; ```. View based:. ```python; gex_view = adata[:, adata.var[""expression_type""] == ""Gene Expression""]; sc.pp.pca(gex_view) # Calculate pca on gene expression; sc.pl.pca(adata, color=[""Protein1"", ""Protein2""]); ```. Different expression types could be put under `.obsm` (probably the closest ""analogy"" to `SingleCellExperiment`'s `assays()`). But this raises questions of what counts as a variable, and I think would take more work to implement. Of course, there are many other ways this could be done as well. As it could impact APIs throughout `scanpy`, I think input from @falexwolf and @flying-sheep is important here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/479#issuecomment-464417618:66,error,errors,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/479#issuecomment-464417618,1,['error'],['errors']
Availability,"Indeed it was enlightening and useful...However, still gives me an error... ```pytb; type(adata); anndata.base.AnnData. adata.write_loom('./filtered_gene_bc_matrices_h5.loom'); ... writing to '.loom' file densifies sparse matrix; Converting to csc format; Creating; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-8-333dccc1e180> in <module>(); ----> 1 adata.write_loom('./filtered_gene_bc_matrices_h5.loom'). /anaconda3/lib/python3.6/site-packages/anndata/base.py in write_loom(self, filename); 1736 """"""; 1737 from .readwrite.write import write_loom; -> 1738 write_loom(filename, self); 1739 ; 1740 @staticmethod. /anaconda3/lib/python3.6/site-packages/anndata/readwrite/write.py in write_loom(filename, adata); 71 if os.path.exists(filename):; 72 os.remove(filename); ---> 73 create(filename, X, row_attrs=row_attrs, col_attrs=col_attrs); 74 ; 75 . /anaconda3/lib/python3.6/site-packages/loompy/loompy.py in create(filename, matrix, row_attrs, col_attrs, file_attrs, chunks, chunk_cache, dtype, compression_opts); 1019 ; 1020 if scipy.sparse.issparse(matrix):; -> 1021 return _create_sparse(filename, matrix, row_attrs, col_attrs, file_attrs, chunks, chunk_cache, dtype, compression_opts); 1022 ; 1023 # Create the file (empty). /anaconda3/lib/python3.6/site-packages/loompy/loompy.py in _create_sparse(filename, matrix, row_attrs, col_attrs, file_attrs, chunks, chunk_cache, dtype, compression_opts); 982 if ds is None:; 983 logging.info(""Creating""); --> 984 ds = create(filename, matrix[:, ix:ix + window].toarray(), row_attrs, ca, file_attrs, chunks, chunk_cache, dtype, compression_opts); 985 else:; 986 logging.info(""Adding columns""). /anaconda3/lib/python3.6/site-packages/loompy/loompy.py in create(filename, matrix, row_attrs, col_attrs, file_attrs, chunks, chunk_cache, dtype, compression_opts); 1033 ; 1034 for key, vals in row_attrs.items():; -> 1035 ds.set_attr(key, vals, axis=0); 1036 ; 1037",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/154#issuecomment-389486091:67,error,error,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/154#issuecomment-389486091,1,['error'],['error']
Availability,"Interesting! I was coming across this error in #2816 (where there is a fix), but only with older versions of dependencies. Probably worth back porting that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2830#issuecomment-1910515749:38,error,error,38,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2830#issuecomment-1910515749,1,['error'],['error']
Availability,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>; <summary> me trying </summary>. ```python; isaac@Mimir:~/tmp/genomic-features-docs; $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy; [ ... ]; isaac@Mimir:~/tmp/genomic-features-docs; $ conda activate test-2978 ; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ ipython; from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help.; [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""); Out[4]: <Version('0.9.0')>. In [5]: quit(); (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ pip install -U anndata; Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0); Collecting anndata; Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB); [ ... ]; Downloading anndata-0.10.6-py3-none-any.whl (122 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00; Downloading array_api_compat-1.6-py3-none-any.whl (36 kB); Installing collected packages: array-api-compat, anndata; Attempting uninstall: anndata; Found existing installation: anndata 0.9.0; Uninstalling anndata-0.9.0:; Successfully uninstalled anndata-0.9.0; Successfully installed anndata-0.10.6 array-api-compat-1.6; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ conda list | grep anndata; anndata 0.10.6 pypi_0 pypi; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ ipython; imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""); Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2978#issuecomment-2039433757:984,Down,Downloading,984,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978#issuecomment-2039433757,1,['Down'],['Downloading']
Availability,"Is there a way to filter for a set of genes, where if any one of the genes in a list are expressed, those cells will be plotted? I've tried switching Xparx's solution to a list, but receive the error ""ValueError: Buffer has wrong number of dimensions (expected 1, got 0)"". I've also tired chansigit's method, but find that flatten returns as not found?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/599#issuecomment-873451217:194,error,error,194,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/599#issuecomment-873451217,1,['error'],['error']
Availability,"Is there any particular reason why DPT fails when you don't have enough genes? I get this error when I select 23 genes for use. ```; scipy.sparse.linalg.eigen.arpack.arpack.ArpackError: ARPACK error 3:; No shifts could be applied during a cycle of the Implicitly restarted Arnoldi iteration.; One possibility is to increase the size of NCV relative to NEV.; ```. with a lot of warnings. Also, is there any particular reason why on some datasets, you can't find significant genes via filter_gene_dispersion? Does that mean that dataset is bad?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/25#issuecomment-313218328:90,error,error,90,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/25#issuecomment-313218328,2,['error'],['error']
Availability,"Is this something for scanpy external or for scanpy core? It seems like a core-type functionality, but given external development easier to credit correctly in scanpy external? and there's ofc the question of maintenance if it's put into core.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1432#issuecomment-698851156:209,mainten,maintenance,209,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432#issuecomment-698851156,1,['mainten'],['maintenance']
Availability,It appears this was an issue related to anndata2ri- scipy 1.0.1 was being installed when installing anndata2ri. Installing scanpy first prevented this issue. ; I use pip install --user for scanpy because otherwise I receive an error message: ; Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; My workaround has been to use --user as a directory and add a path to import scanpy.; I'm sorry for the trouble thank you for the help.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1252#issuecomment-636118302:227,error,error,227,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252#issuecomment-636118302,1,['error'],['error']
Availability,It causes exactly the same issue when I run:. ```; import numpy as np; import umap; ```; There is no segfault message. The jupyter kernel failure message is: . _Kernel restarting. The kernel appears to have died. It will restart automatically._,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1567#issuecomment-754566053:138,failure,failure,138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1567#issuecomment-754566053,1,['failure'],['failure']
Availability,"It doesn’t. We could also. 1. wait to merge this until `skmisc` has a new release or; 2. throw a special error when people try to use seurat v3 with numpy 2. Sadly(?) Python doesn’t allow packages to add constraint to other packages’ dependencies, else we could tell the resolver that all currently release skmisc versions are incompatible with numpy 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3115#issuecomment-2182602501:105,error,error,105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115#issuecomment-2182602501,1,['error'],['error']
Availability,"It is an enrichment analysis but foot-print based: we don't just look at the elements of a pathway/TF but also the biological downstream effects that occur when said biological process is active. ; ""Annotation/ Enrichment Analysis"" fits but it would be good to also mention somewhere that they are foot-print based. Would this be okay?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1767#issuecomment-810829669:126,down,downstream,126,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1767#issuecomment-810829669,1,['down'],['downstream']
Availability,"It is said that ""Be reminded that it is not advised to use the corrected data matrices for differential expression testing."" in scanpy document (http://scanpy.readthedocs.io/en/latest/api/scanpy.api.pp.mnn_correct.html) when execute MNN correction. However, Haghverdi Laleh (the one who presents MNN correction strategy, https://www.nature.com/articles/nbt.4091) says ""MNN correction improves differential expression analyses, After batch correction is performed, the corrected expression values can be used in routine downstream analyses such as clustering prior to differential gene expression identification"" in his Nature Biotech paper. So, I am a little confused. We have compared some corrections methods, such as regress_out, combat, MNN and MultiCCA (used by seurat), the results show that MNN and CCA have a better effect than regress_out and combat.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/168#issuecomment-395615173:519,down,downstream,519,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/168#issuecomment-395615173,1,['down'],['downstream']
Availability,It looks like in your initial call to `sc.pl.pca` you are not specifying `use_raw=True`. Do you still get this error when you do?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1277#issuecomment-703829011:111,error,error,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277#issuecomment-703829011,1,['error'],['error']
Availability,"It looks like the new release breaks most of our usage from (at least) a change in arguments to `simplicial_set_embedding` (ping @Koncopd). <details>; <summary> Example error </summary>. ```pytb; n_epochs = 0 if maxiter is None else maxiter; > X_umap = simplicial_set_embedding(; X,; neighbors['connectivities'].tocoo(),; n_components,; alpha,; a,; b,; gamma,; negative_sample_rate,; n_epochs,; init_coords,; random_state,; neigh_params.get('metric', 'euclidean'),; neigh_params.get('metric_kwds', {}),; verbose=settings.verbosity > 3,; E TypeError: simplicial_set_embedding() missing 3 required positional arguments: 'densmap', 'densmap_kwds', and 'output_dens'; ```. </details>. It looks like there is also a lot of cool stuff in the new release!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1509#issuecomment-743966308:124,ping,ping,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1509#issuecomment-743966308,2,"['error', 'ping']","['error', 'ping']"
Availability,It looks like the same `AssertionError: Error: Image files did not match.` error I was getting locally from some of the spatial tests. I haven't touched this so not sure what's going on there.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2231#issuecomment-1140780018:40,Error,Error,40,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1140780018,2,"['Error', 'error']","['Error', 'error']"
Availability,"It looks like this error occurs whenever `batch_key` is specified and `inplace=False`. MCVE:. ```python; import scanpy as sc; pbmc = sc.datasets.pbmc68k_reduced(); pbmc.X = pbmc.raw.X # So we have reasonable values to calculate on. # These do not throw an error:; sc.pp.highly_variable_genes(pbmc, batch_key=""phase""); sc.pp.highly_variable_genes(pbmc, inplace=False). # This throws an error; sc.pp.highly_variable_genes(pbmc, batch_key=""phase"", inplace=False); ```. This does raise the question of what `inplace=False` should return for the batch case. I'd think a recarray (maybe this should change to a dataframe?) with metrics for each of the batches. You could end up with columns with names like: `means_{batch1}`, `dispersions_{batch1}` etc. @danielStrobl, what were you expecting this to return?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/758#issuecomment-517145132:19,error,error,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758#issuecomment-517145132,3,['error'],['error']
Availability,It looks like this may have stalled a bit. Is anyone currently working on making some form of doublet detection available from scanpy?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-481057117:112,avail,available,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-481057117,1,['avail'],['available']
Availability,"It looks like those warning are being raised from `scipy.stats.distributions.t.sf`. . This was also happening in the tests, but there's already a bunch of warnings in the tests so we didn't see it. ~~I believe we didn't get this warning from the older code because of these lines:~~. ```python; dof[np.isnan(dof)] = 0		; pvals = stats.t.sf(abs(scores), dof)*2 # *2 because of two-tailed t-test; ```. I don't think it's the above lines anymore, since the replacing the `ttest_ind_from_stats` call with the following still throws the warning:. ```python; df, denom = stats.stats._unequal_var_ttest_denom(; v1=var_group, n1=ns_group, v2=var_rest, n2=ns_rest; ); df[np.isnan(df)] = 0; scores, pvals = stats.stats._ttest_ind_from_stats(; mean_group, mean_rest, denom, df; ); ```. Other than that, potential solutions include:. * Mask out genes which aren't expressed in the compared groups (since there's not too much point in getting and correcting a pvalue for them); * Revert change (would bring back issue of genes with variance of 0); * Wrap the t-test with something like `np.errstate` to hide the warning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/629#issuecomment-488907170:824,Mask,Mask,824,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629#issuecomment-488907170,1,['Mask'],['Mask']
Availability,"It looks like your adata object is corrupted. You should be able to type; `adata.X` to get the matrix. How are you generating the adata object?. On Thu, Dec 6, 2018 at 5:56 PM ltosti <notifications@github.com> wrote:. > Hi there,; >; > When running sc.pp.highly_variable_genes(adata.X) I get the following; > error:; >; > AttributeError: X not found; >; > I then ran sc.pp.highly_variable_genes(adata) and got the following:; >; > ValueError: Bin edges must be unique: array([nan, inf, inf, inf, inf, inf,; > inf, inf, inf, inf, inf, inf, inf,inf, inf, inf, inf, inf, inf, inf, inf]).; > You can drop duplicate edges by setting the duplicates kwarg; >; > The older sc.pp.filter_genes_dispersion(adata.X) works fine.; >; > Do you know how to fix this?; >; > Thank you!; >; > *Info*: scanpy==1.3.4 anndata==0.6.13 numpy==1.15.3 scipy==1.1.0; > pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 python-igraph==0.7.1; > louvain==0.6.1; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/391>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1RPErIznAoUd0DwpbdlEjkOUyjTdks5u2Uw4gaJpZM4ZG6Jw>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-444950693:309,error,error,309,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-444950693,1,['error'],['error']
Availability,"It looks to me like the sklearn dependency was update more due to bugs in earlier 0.21.* releases series, see 7716bfdec3cb9bd19923a91180dabc35ffd7709a. We don't promise compatibility with older versions of sklearn, so downgrading is not a good long-term solution. @Koncopd might also be able to give some advice on this, as I believe he has been using pytorch with scanpy, though I'm not sure if this is via conda environments.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1121#issuecomment-604799158:218,down,downgrading,218,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121#issuecomment-604799158,1,['down'],['downgrading']
Availability,It seems that something wrong happened for the Seurat meta slot. The code told that this error happened when AnnData tried to construct obs attribute. ; I am afraid this beyond my scope since I cannot access your data for further debugging,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/598#issuecomment-487647761:89,error,error,89,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487647761,1,['error'],['error']
Availability,"It seems that upgrading from 1.8.1 to 1.8.2 introduce an error on umap version checking, mentioned by #1978 (and a potential solution); > Why are we using umap.__version__ instead of importlib.metadata.version('umap-learn')?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2045#issuecomment-963422681:57,error,error,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2045#issuecomment-963422681,1,['error'],['error']
Availability,"It seems that you are using an online notebook. I also received this error on Colab. But when I ran the same code on the PC terminal, everything went well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2332#issuecomment-1256252146:69,error,error,69,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332#issuecomment-1256252146,1,['error'],['error']
Availability,"It seems to be scanpy-scripts itself. johnnydep analysis shows these (99% of lines removed):; ```. 2020-07-20 18:57:50 [info ] init johnnydist [johnnydep.lib] dist=scipy<1.3.0,>=1.2.0 parent=scanpy-scripts; 2020-07-20 18:58:10 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata<0.6.20; 2020-07-20 18:59:17 [info ] init johnnydist [johnnydep.lib] dist=scipy~=1.0 parent=anndata>=0.6.15; 2020-07-20 18:59:26 [info ] init johnnydist [johnnydep.lib] dist=scipy>=0.19.1 parent=scikit-learn>=0.19.1; 2020-07-20 18:59:58 [info ] init johnnydist [johnnydep.lib] dist=scipy>=1.3.1 parent=umap-learn>=0.3.0; ```. and later. ```; 2020-07-20 19:00:14 [info ] merged specs [johnnydep.lib] dist=scanpy-scripts extras=; set() name=scipy spec=<SpecifierSet('<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0', prereleases=True)>. ```. It cannot match both <1.3.0 and >= 1.3.1, and eventually bails out with:. ```; ERROR: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0; pip._internal.exceptions.DistributionNotFound: No matching distribution found for scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0; subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'pip', 'wheel', '-vvv', '--no-deps', '--no-cache-dir', '--disable-pip-version-check', '--pro; gress-bar=off', 'scipy<1.3.0,>=0.19.1,>=1.0,>=1.0.1,>=1.2.0,>=1.3.1,~=1.0']' returned non-zero exit status 1.; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1273#issuecomment-661285497:920,ERROR,ERROR,920,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273#issuecomment-661285497,1,['ERROR'],['ERROR']
Availability,It seems to be something about the `genes.tsv`. I replaced it with another genes.tsv and it didn't produce errors.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2053#issuecomment-973500395:107,error,errors,107,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2053#issuecomment-973500395,1,['error'],['errors']
Availability,"It seems you do not always end up with n-1 neighbors, because for n=3, you suddenly get differing number of neighbors:; ```python; import scanpy as sc; adata = sc.datasets.blobs(n_observations=5). for n_neighbors in [1, 2, 3]:; sc.pp.neighbors(adata, n_neighbors=n_neighbors); print(f'n_neighbors = {n_neighbors}:\n', adata.uns['neighbors']['connectivities'].A); ```; Output:; ```; n_neighbors = 1:; [[0. 0. 0. 0. 0.]; [0. 0. 0. 0. 0.]; [0. 0. 0. 0. 0.]; [0. 0. 0. 0. 0.]; [0. 0. 0. 0. 0.]]; n_neighbors = 2:; [[0. 0. 0. 1. 0.]; [0. 0. 1. 0. 0.]; [0. 1. 0. 0. 0.]; [1. 0. 0. 0. 1.]; [0. 0. 0. 1. 0.]]; n_neighbors = 3:; [[0. 0.5849553 0. 1. 0.5849636 ]; [0.5849553 0. 1. 0.5849678 0. ]; [0. 1. 0. 0.58496827 0. ]; [1. 0.5849678 0.58496827 0. 1. ]; [0.5849636 0. 0. 1. 0. ]]; ```; It is been while that I read about UMAP and can't get my head around why this happens right now. Relying on UMAP seems a good idea to me, maybe the corner case `n_neighbors=1` should just be catched with a more meaningful error message?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1706#issuecomment-788885174:1002,error,error,1002,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706#issuecomment-788885174,1,['error'],['error']
Availability,It started to go wrong with ff26149 and all I changed there was that I moved the `if inplace:` statement up to the user tests instead of down to where the outputs were written. Is python 3.5 somehow sensitive to whitespace after if statements? I found a whitespace after the `if inplace: `... maybe that's it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/549#issuecomment-478395193:137,down,down,137,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549#issuecomment-478395193,1,['down'],['down']
Availability,"It still does not work for me, even in a virtualenv. I always get:; ```. #Using legacy setup.py install for umap-learn, since package 'wheel' is not installed.; #ERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible. cd /usr/common/lib/python3.6/Envs; rm -rf ~/.cache/pip #make download clearer; python3 -m venv scanpy_scripts; source scanpy_scripts/bin/activate; python -m pip install -U pip; python -m pip install scanpy_scripts; #same error; python -m pip install -U setuptools #39.2 -> 47.3.1; python -m pip install scanpy_scripts; #same error; python -m pip install -U wheel; python -m pip install scanpy_scripts; #same error; echo $PYTHONPATH; #is blank. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1273#issuecomment-653279039:162,ERROR,ERROR,162,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273#issuecomment-653279039,6,"['ERROR', 'down', 'echo', 'error']","['ERROR', 'download', 'echo', 'error']"
Availability,It turned out that this is definitely something wrong with my system setup. After I circumvented the bug above by clearing `README.rst` I found another package that spits out the same error (`louvain`).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/43#issuecomment-342897102:184,error,error,184,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43#issuecomment-342897102,1,['error'],['error']
Availability,"It would be good to have an open issue here for why we pin matplotlib to a lower version. If I try upgrading it, I get a few failures in the tests for heat maps as well as 3d plotting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/787#issuecomment-532125401:125,failure,failures,125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787#issuecomment-532125401,1,['failure'],['failures']
Availability,"It would help to tell *where* in the code the error is thrown. Please provide a traceback. > Does using adata.var_names_make_unique() also makes the variable names of adata.X unique?. If X is a DataFrame, yes. Otherwise X doesn’t have any names stored inside (`var_names` are stored as `.var.index`.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763974778:46,error,error,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763974778,1,['error'],['error']
Availability,"It's **a** thing, not yet **the** thing. For directed PAGA follow [this](https://github.com/theislab/paga/issues/11) while always double checking with your single cell velocities as it is not yet perfectly robust.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/792#issuecomment-523843131:206,robust,robust,206,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792#issuecomment-523843131,1,['robust'],['robust']
Availability,"It's a bug that there is no error output. I haven't thought about drawing the PAGA graph in higher dimensions yet, hence no possibility to initialize from that. One could think about adding this functionality... but I don't know how meaningful that is at this stage.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/306#issuecomment-430363010:28,error,error,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/306#issuecomment-430363010,1,['error'],['error']
Availability,"It's only 538 cells, so it's a small file, I can send it to you, if you want to have a look.; ________________________________; From: MalteDLuecken <notifications@github.com>; Sent: Monday, April 20, 2020 2:42:07 PM; To: theislab/scanpy <scanpy@noreply.github.com>; Cc: Augusto Escalante <ae_rodriguez_@hotmail.com>; Author <author@noreply.github.com>; Subject: Re: [theislab/scanpy] Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error (#1172). It's hard to say what's going on here. There seems to be sth happening in sc.pp.combat() so I would evaluate this separately from sc.pp.highly_variable_genes(). It would be important to have a minimal reproducible example it seems. —; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1172#issuecomment-616527285>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AFZKH4VCL573RRAU55AHS23RNQ7J7ANCNFSM4ML4AVXA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1172#issuecomment-616528291:467,error,error,467,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172#issuecomment-616528291,1,['error'],['error']
Availability,"It's only on master, but I don't think that would change anything here. The fix was for cases where `sc.pp.highly_variable_genes()` outputs an error due to bin boundaries being duplicated as genes were unexpressed. . I reckon this is not actually a bug. It's a possible scenario that no genes are highly variable in all batches, no? Is `highly_variable_intersection` `False` everywhere, or is `highly_variable_nbatches` somehow false? The former can be `False` if your batches are heterogeneous.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/935#issuecomment-559392108:143,error,error,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/935#issuecomment-559392108,1,['error'],['error']
Availability,"Its an issue with numba. See here https://github.com/jmschrei/apricot/blob/98693788ca315ceceeb2eb0f4ce8526f40e0049b/README.md. *Update* Quoting from the REAME above. > If you get an error that looks like; > ; > Inconsistency detected by ld.so: dl-version.c: 224: _dl_check_map_versions: Assertion `needed != NULL' failed!; > ; > or a segmentation fault when importing apricot for the first time then you should try reinstalling numba through conda using; > ; > conda install numba.; > ; > or; > ; > pip install numba==0.39.0; > ; > The issue appears to be with the most recent verson of numba, v0.40.0. Downgrading to numba v0.39.0 should solve the issue. ; > . That means numba should be frozen to v0.39.0 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/280#issuecomment-427364460:182,error,error,182,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280#issuecomment-427364460,3,"['Down', 'error', 'fault']","['Downgrading', 'error', 'fault']"
Availability,"I’ll take a look if you update your issue with a code block that I can copy, that will download the dataset and then reproduce the error without me having to go to any website and download anything manually.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2819#issuecomment-1906406640:87,down,download,87,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2819#issuecomment-1906406640,3,"['down', 'error']","['download', 'error']"
Availability,"I’m unsure if we can help you with this, as it’s your system creating his error and we don’t have access to the data. There’s multiple possible causes and solutions:. - a misunderstanding: The arrays should require `310385 * 8563 * 8B = 21.3 GB`, no idea why it says 10. But of course that’s still not close to 100GB unless other people/processes are using the machine, or other arrays are allocated. Can you track the memory usage and see if it spikes close to the maximum before the code crashes?; - our implementation allocates memory it shouldn’t: this is the only one we can fix, but we’d have to figure out under which circumstances that happens, and where in our code.; - some machine problem, [like many people on stackoverflow](https://www.google.com/search?q=site%3Astackoverflow.com+%22Unable+to+allocate%22+%22GiB+for+an+array+with+shape%22+%22and+data+type%22): maybe your sysadmin can help?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2551#issuecomment-1630946384:74,error,error,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551#issuecomment-1630946384,1,['error'],['error']
Availability,"I’ve only found this problem in the wild when people tried to create a figure with a dimension of size 0. It implies that either matplotlib passes some faulty instructions to libpng or that your libpng installation is broken. It’s very unlikely that it’s a problem with scanpy. Does something simple with matplotlib work? Just `pyplot.scatter([0,1], [0,1])` or so?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/852#issuecomment-534002026:152,fault,faulty,152,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/852#issuecomment-534002026,1,['fault'],['faulty']
Availability,"Just a heads up, it looks like Pandas 1.3.3 might break things again, was experiencing errors that I was able to resolve by downgrading. I can create a new issue if you'd like. Error below so you can determine if this is the same issue or not:; ```; adata.obs['log_counts'] = np.log(adata.obs['n_counts']); File ""/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py"", line 3612, in __setitem__; self._set_item(key, value); File ""/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py"", line 3784, in _set_item; value = self._sanitize_column(value); File ""/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py"", line 4509, in _sanitize_column; com.require_length_match(value, self.index); File ""/opt/conda/lib/python3.8/site-packages/pandas/core/common.py"", line 531, in require_length_match; raise ValueError(; ValueError: Length of values (1) does not match length of index (38978); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1918#issuecomment-925478453:87,error,errors,87,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1918#issuecomment-925478453,3,"['Error', 'down', 'error']","['Error', 'downgrading', 'errors']"
Availability,"Just added a test and changed the behaviour of scale a little more.; The case of zero variance was until now replace with an arbitrary tiny variance, which arbitrarily blew up the scaled value and made it completely meaningless `scale[scale == 0] = 1e-12`.; Now I put instead `scale[scale == 0] = 1`. This yields the same result for `zero_center == True`: all values set to `0`, anyway (but with less arbitrary magic numbers and maybe less rounding errors). But if `zero_zenter == False`, unscalable values are untouched. This only affected the dense codepath where zero-centering was done afterwards anyway due to the original bug. Therefore this is no code breaking change.; But I also moved this statement before the sparse check to have consistent handling of sparse and dense data. Before that the sparse path wrote infs in the values (unchecked divison by zero) - this is a potentially code breaking change, but it only leads to the behaviour already stated in the documentation. I personally think that code relying on this undocumented behaviour should be rewritten, anyway...; In the new test I explicitly check for this behaviour to make it well defined.; Similar for integer datatypes (resulted in an error), they are now converted to floating point for scaling and return a copy. BTW: In order to make the tests run in my conda environment, I had to remove every reference to compare_images from matplotlib.testing.compare. There seems to be a version conflict in the version checking... It always gave errors like the following:; `________________ ERROR collecting scanpy/tests/test_plotting.py ________________; scanpy/tests/test_plotting.py:16: in <module>; from matplotlib.testing.compare import compare_images; ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/testing/compare.py:240: in <module>; _update_converter(); ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/testing/compare.py:222: in _update_converter; mpl._get_executable_info(""gs""); ~/.conda/envs/cus",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1160#issuecomment-615407330:449,error,errors,449,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1160#issuecomment-615407330,1,['error'],['errors']
Availability,"Just came across this - still think its a good idea, other `make_blobs` arguments are also available and setting different random states might come in handy. Will make a small PR... If you think its not worth it we can also close the issue :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1429#issuecomment-1759763329:91,avail,available,91,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1429#issuecomment-1759763329,1,['avail'],['available']
Availability,"Just checked using this dockerfile, works flawlessly:. ```dockerfile; FROM continuumio/miniconda. RUN conda install python=3.8; RUN pip install flit>=3.1; RUN git clone https://github.com/theislab/scanpy.git; WORKDIR /scanpy; # Go to the mainline-pip branch if it hasn’t been merged into master yet; RUN git checkout mainline-pip || true; RUN FLIT_ROOT_INSTALL=1 flit install -s --dep=develop # Make development install of scanpy; # Make sure the dist-info folder has a plus in its name; RUN SCANPY_VERSION=$(python -c 'from importlib.metadata import version; print(version(""scanpy""))') && \; echo $SCANPY_VERSION | grep '+' &&; test -d /opt/conda/lib/python3.8/site-packages/scanpy-$SCANPY_VERSION.dist-info; # Install project that depends on scanpy; RUN pip install scvelo; # Make sure it’s still a dev install; RUN test -L /opt/conda/lib/python3.8/site-packages/scanpy; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1702#issuecomment-788200617:593,echo,echo,593,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1702#issuecomment-788200617,1,['echo'],['echo']
Availability,Just checked.. same thing applies for windows. It returns an error until you `conda install pytables`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-462140641:61,error,error,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-462140641,1,['error'],['error']
Availability,"Just checking to make sure we're working with the same data, since there could be different errors coming from that. The PR should do the right thing on `pbmc3k`. Could you check if it works for you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/421#issuecomment-453899907:92,error,errors,92,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/421#issuecomment-453899907,1,['error'],['errors']
Availability,"Just delete MY2L, or use sc.pl.dotplot . . > On 25 Feb 2019, at 18:37, rojin <notifications@github.com> wrote:; > ; > I get the following error when I tun dotplot:; > ; > `ValueError Traceback (most recent call last); > in (); > ----> 1 sc.pl.rank_genes_groups_dotplot(vitro,['MYL2'], groupby='louvain'); > ; > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, key, show, save, **kwds); > 409; > 410 _rank_genes_groups_plot(adata, plot_type='dotplot', groups=groups, n_genes=n_genes,; > --> 411 groupby=groupby, key=key, show=show, save=save, **kwds); > 412; > 413; > ; > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds); > 291; > 292 # sum(list, []) is used to flatten the gene list; > --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []); > 294; > 295 if plot_type == 'dotplot':; > ; > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in (.0); > 291; > 292 # sum(list, []) is used to flatten the gene list; > --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []); > 294; > 295 if plot_type == 'dotplot':; > ; > ValueError: no field of name MYL2; > `; > ; > Do we need to store marker genes within the adata object?; > ; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/502#issuecomment-467172649:138,error,error,138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/502#issuecomment-467172649,1,['error'],['error']
Availability,Just got reminded of this PR... @ivirshup Should we maybe ping somebody else from the Scanpy team to join the discussion / review here?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-871319496:58,ping,ping,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-871319496,1,['ping'],['ping']
Availability,"Just saw that I forgot to comment on these two issues that @ivirshup mentioned above:. > ## Feature selection on an already transformed matrix; > ; > Would it be reasonable to include a way to compute the deviant genes from pearson normalized matrix? Ideally, we should not have to compute it twice to get all the results in one object. The easiest would probably be to add an `return_hvgs` option to `normalize_pearson_residuals()`, which would allow to skip our RAM-optimized HVG selection function for cases where speed / efficiency is needed and RAM usage is not a concern. ; This would give the same HVGs as our current function, but won't offer the batch correction currently implemented -- unless we implement the same batch correction option for `normalize_pearson_residuals()`, i.e. to compute residuals for each batch separately and then simply concatenate across cells... I would have to think a bit if this makes sense (maybe it does) and what properties these batch-corrected residuals will have. (@dkobak, do you want to comment?). If we can live without the batch correction for this ""fast lane case"", I can also just implement it without. Let me know!. > ## Docs consistency; > ; > A number of parameters are available in multiple functions. Would it make sense to use some of our tooling so there's only one place to edit these?. Sounds good - I think @giovp was suggesting something similar earlier, but recommended to wait for the next PR with this. > We really need another way to handle this (e.g. the way we do it in Squidpy with package constants) but this is for another PR. I have no experience with package constant yet but just let me know if I should do something here :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-903315698:1225,avail,available,1225,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-903315698,1,['avail'],['available']
Availability,"LGTM! . Don't worry about the test failures, those are due to a networkx update changing how plots look, which we'll deal with.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1950#issuecomment-887218018:35,failure,failures,35,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1950#issuecomment-887218018,1,['failure'],['failures']
Availability,"Like you say, the difference between this and `ingest` is joint PCA calculation vs asymmetric batch integration. This function is the first step in the `fastMNN` function, which I have found in some cases yields very sensible batch correction results. It would be awesome to see `multiBatchPCA` +/- `fastMNN` available in scanpy. I am aware of the python implementation of `mnncorrect`, but I think this still operates on expression values rather than a PCA representation (correct me if I am wrong..). Without going all the way the batch correction, `multiBatchPCA` is useful where different experiments have very different numbers of cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1289#issuecomment-671228353:309,avail,available,309,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1289#issuecomment-671228353,1,['avail'],['available']
Availability,"Look at the documentation before you ask questions. The object returned from the function you called doesn’t return a matplotlib object, it returns a dictionary, assuming that the ‘show’ parameter is off. You can’t loop through a dictionary like an array, you need to retrieve the keys access individual values and then use the ‘ylim’ property. Get Outlook for iOS<https://aka.ms/o0ukef>; ________________________________; From: ZxyChopcat ***@***.***>; Sent: Thursday, September 16, 2021 1:24:05 PM; To: theislab/scanpy ***@***.***>; Cc: Vekeria, Jai Patel ***@***.***>; Comment ***@***.***>; Subject: Re: [theislab/scanpy] How to use stacked_violin with variable y-axis limits between rows? (#386). Hi,; I tried to set the y-axis limit, but failed with the error:; `>>> axes = sc.pl.stacked_violin(adata, marker_genes, groupby='cell_types', rotation=90,swap_axes=True,row_palette='muted',yticklabels=True,show=False). for ax in axes:; ... ax.set_ylim(0, 5); ...; Traceback (most recent call last):; File """", line 2, in; AttributeError: 'str' object has no attribute 'set_ylim'; `; I use scanpy 1.8.1.; Do you have any idea? Thanks!. —; You are receiving this because you commented.; Reply to this email directly, view it on GitHub<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Ftheislab%2Fscanpy%2Fissues%2F386%23issuecomment-921089934&data=04%7C01%7Cjai.vekeria%40pitt.edu%7C4da79e06909d45b4b4e508d97936c8d4%7C9ef9f489e0a04eeb87cc3a526112fd0d%7C1%7C0%7C637674098542578553%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=t3jhsNr2Q3IlftHnubs6%2FWZyy%2FAijC2BWJ18Ih41Py0%3D&reserved=0>, or unsubscribe<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAL6KD25HVPRX7SK4DD5UPE3UCIR3LANCNFSM4GH7A7BA&data=04%7C01%7Cjai.vekeria%40pitt.edu%7C4da79e06909d45b4b4e508d97936c8d4%7C9ef9f489e0a04eeb87cc3a526112fd0d%7C1%7C0%7C637674098542578553%7CUnknown%7CTWF",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/386#issuecomment-921104209:759,error,error,759,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/386#issuecomment-921104209,1,['error'],['error']
Availability,"Look at the virtualenv example - PYTHONPATH was empty. The johnnydep application does not actually do an install, it just downloads all the pieces a package calls for and looks at all the listed requirements - and it gives the same version restriction conflict as an actual installation attemp.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1273#issuecomment-659028734:122,down,downloads,122,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1273#issuecomment-659028734,1,['down'],['downloads']
Availability,"Looking at the commits page I can see that the tests has been failing for some days already. . First was a problem with a notebook test (test_pbmc3k) that seems innocuous but should be addressed. This is related to release 1.4.3 (https://github.com/theislab/scanpy/commit/85acb6c8949d43d08a26437dceab4fa5db79e246). The commits are unrelated to the failing test so I assume that some dependency was updated . However, after this commit https://github.com/theislab/scanpy/commit/115d635bf950354509053d976b90c1db518bcffe more errors are found. But again, I don't see any relevant changes that will cause the problems. One of the errors is that statsmodels is using a deprecated module from scipy.misc:. ```; > from scipy.misc import factorial; E ImportError: cannot import name 'factorial'; ../../../virtualenv/python3.6.7/lib/python3.6/site-packages/statsmodels/distributions/edgeworth.py:7: ImportError; ```. This was introduced after scipy 1.3 was recently updated (https://github.com/statsmodels/statsmodels/issues/5759). It seems that currently, the only solution is to install statsmodels directly from the master branch. Or downgrade scipy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/661#issuecomment-495552166:523,error,errors,523,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495552166,3,"['down', 'error']","['downgrade', 'errors']"
Availability,"Looking at this again, now that I have gone through everything, I think we actually need to check types directly and shouldn't rely on `isbacked` because it is possible to do something like `adata.layers['foo'] = sparse_dataset(g_layer)` and this should also error our with a helpful message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3048#issuecomment-2107583455:259,error,error,259,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048#issuecomment-2107583455,1,['error'],['error']
Availability,"Looks good then! Great that you followed https://github.com/theislab/scanpy/pull/503#issuecomment-471331400 and named it `harmony_integrate` instead of generally `harmony`. Not sure if `obsm_{in,out}_field` are good names. Maybe use something more speaking? I think we use `basis` or `rep` for something like `X_pca` elsewhere. Please also fix doc build errors and the `.travis.yml` conflict. (“Kor**s**unsky19” is a typo I guess, and I think it should be `kwargs` instead of `**kwargs`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1306#issuecomment-661049767:354,error,errors,354,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306#issuecomment-661049767,1,['error'],['errors']
Availability,"Looks like the issue goes deeper, to `get_version` being called on RTD. Seems like some interaction of that package and the environment. Ping @flying-sheep",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1900#issuecomment-869127933:137,Ping,Ping,137,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1900#issuecomment-869127933,1,['Ping'],['Ping']
Availability,"Looks like the same error hit in #585, as well as https://github.com/theislab/scanpy/pull/493#issuecomment-477674448. @flying-sheep I haven't been able to reproduce, but maybe we should just throw an `__init__.py` in there, since it fixes this for @fbrundu, before the `v1.4.1` release?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/601#issuecomment-482069731:20,error,error,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/601#issuecomment-482069731,1,['error'],['error']
Availability,"Looks like this is not available for python yet ([docs](https://docs.microsoft.com/en-us/azure/devops/pipelines/test/codecoverage-for-pullrequests?view=azure-devops#prerequisites)). > While you can collect and publish code coverage results for many different languages using Azure Pipelines, the code coverage for pull requests feature discussed in this document is currently available only for .NET and .NET core projects using the Visual Studio code coverage results format (file extension .coverage). Support for other languages and coverage formats will be added in future milestones.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1576#issuecomment-758366276:23,avail,available,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1576#issuecomment-758366276,2,['avail'],['available']
Availability,"Many thanks for everyone's input. The bug is indeed due to an issue with Pandas ≥1.3. I am running Scanpy 1.8.1 and I can confirm that the indexing problem remains with Pandas 1.3.0, 1.3.2, and the latest 1.3.4, but resolves when downgrading to 1.2.5",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2008#issuecomment-948031374:230,down,downgrading,230,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008#issuecomment-948031374,1,['down'],['downgrading']
Availability,"Matplotlib 3.4 has dropped 3.6 support. Since matplotlib is our most painful dependency (reliably causes test failures when it updates), it's a great time to drop 3.6.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1697#issuecomment-809011473:89,reliab,reliably,89,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697#issuecomment-809011473,2,"['failure', 'reliab']","['failures', 'reliably']"
Availability,Maybe downgrade numba for the time being? IDK to which version though. @stuartarchibald has more insight here. Please follow numba/numba#5955 for updates!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341#issuecomment-670189681:6,down,downgrade,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341#issuecomment-670189681,1,['down'],['downgrade']
Availability,"Merging this, docs are failing to build from intersphinx since numpy's docs are down. This commit has built on read the docs before, so I'm happy to assume it still does. Thanks @giovp!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1512#issuecomment-759329104:80,down,down,80,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512#issuecomment-759329104,1,['down'],['down']
Availability,"Miniconda3/envs/py48/lib/contextlib.py?line=129) try:; --> [131](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=130) self.gen.throw(type, value, traceback); [132](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=131) except StopIteration as exc:; [133](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=132) # Suppress StopIteration *unless* it's the same exception that; [134](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=133) # was passed to throw(). This prevents a StopIteration; [135](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=134) # raised inside the ""with"" statement from being suppressed.; [136](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=135) return exc is not value. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\errors.py:837, in new_error_context(fmt_, *args, **kwargs); [835](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=834) else:; [836](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=835) tb = None; --> [837](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=836) raise newerr.with_traceback(tb); [838](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=837) elif use_new_style_errors():; [839](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=838) raise e. LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x00000242239BD700> (trying to write member #1). File ""D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\umap\layouts.py"", line 53:; def rdist(x, y):; <source elided>; dim = x.shape[0]; for i in range(dim):; ^. During: lowering ""$20c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:32631,error,errors,32631,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659,1,['error'],['errors']
Availability,Minor addendum that I'm not sure is worth it's own issue. I had thought we were gonna use `q` instead of `p` for the prefix of the string values. The error that raised was:. ```python; ValueError: could not convert string to float: 'q99'; ```. I think we should probably recommend the correct usage in the error instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/800#issuecomment-524526783:150,error,error,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800#issuecomment-524526783,2,['error'],['error']
Availability,"Mmh no, it does work as you expect, just need to turn the dendrogram off.; ```python; pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_dict = {; ""1"": [""GNLY"", ""NKG7""],; ""0"": [""CD3D""],; ""2"": [""CD79A"", ""MS4A1""],; ""4"": [""CD79A"", ""MS4A1""],; ""3"": [""FCER1A""],; }. sc.pl.heatmap(; pbmc,; marker_genes_dict,; groupby=""clusters"",; vmin=-2,; vmax=2,; cmap=""RdBu_r"",; dendrogram=False,; swap_axes=True,; ); ```. or just pass the list of markers (list, not mapping); ```python; pbmc = sc.datasets.pbmc68k_reduced(); sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_list = [""GNLY"", ""NKG7""]. sc.pl.heatmap(; pbmc,; marker_genes_list,; groupby=""clusters"",; vmin=-2,; vmax=2,; cmap=""RdBu_r"",; dendrogram=True,; swap_axes=True,; ); ```. If you pass a dict with incomplete annotation and request dendrogram, then it fails, and the warning says this clearly:; ```; WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different.; categories: 0, 1, 2, etc.; var_group_labels: 1, 0, 2, etc.; ```; and it still produces a plot (yet unordered). The `var_group_labels` is also described in `help(sc.pl.heatmap)` as you pointed out. I think the misunderstanding is that passing a mapping or a list the behaviour is different, although potentially expected since a mapping and a list are different things. This could probably be explained clearer in the `var_names` argument yes. Just to go back to your original problem, in your case you were using as mapping categories that were not present in your `groupby` key altogether. This is a different issue, and probably the function should have thrown an error saying `var_group_labels` are not present in `categories`. . If you feel like opening a PR for this, we would really appreciate!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1479#issuecomment-723051024:1700,error,error,1700,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479#issuecomment-723051024,1,['error'],['error']
Availability,"My code also has the same bug problem, may I ask, how to solve it?. `adata.raw = adata # keep full dimension safe; sc.pp.highly_variable_genes(; adata,; flavor=""seurat_v3"",#; n_top_genes=2000,; layer=""counts"",; batch_key=""orig.ident"",; subset=True,; span=1; ); `. Error output. `ValueError Traceback (most recent call last); Cell In[13], line 3; 1 #高变基因选取; 2 adata.raw = adata # keep full dimension safe; ----> 3 sc.pp.highly_variable_genes(; 4 adata,; 5 flavor=""seurat_v3"",#; 6 n_top_genes=2000,; 7 layer=""counts"",; 8 batch_key=""orig.ident"",; 9 subset=True,; 10 span=1; 11 ); 13 filename = 'melanoma_sw_high_var.h5ad'; 14 adata.write(filename). File ~/miniconda3/envs/scanpy/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:441, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 439 sig = signature(_highly_variable_genes_seurat_v3); 440 n_top_genes = cast(int, sig.parameters[""n_top_genes""].default); --> 441 return _highly_variable_genes_seurat_v3(; 442 adata,; 443 layer=layer,; 444 n_top_genes=n_top_genes,; 445 batch_key=batch_key,; 446 check_values=check_values,; 447 span=span,; 448 subset=subset,; 449 inplace=inplace,; 450 ); 452 if batch_key is None:; 453 df = _highly_variable_genes_single_batch(; 454 adata,; 455 layer=layer,; (...); 462 flavor=flavor,; 463 ). File ~/miniconda3/envs/scanpy/lib/python3.12/site-packages/scanpy/preprocessing/_highly_variable_genes.py:87, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 85 x = np.log10(mean[not_const]); 86 model = loess(x, y, span=span, degree=2); ---> 87 model.fit(); 88 estimat_var[not_const] = model.outputs.fitted_values; 89 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:927, in _loess.loess.fit(). ValueError: b'Extrapolation not allowed with blending'`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2853#issuecomment-2019348837:264,Error,Error,264,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2853#issuecomment-2019348837,1,['Error'],['Error']
Availability,"My main point is that having an implicit mapping between colors and the categories is not that user or developer friendly. It seems to me like it'd be simpler to just have the mapping be explicit. This wouldn't change much from right now, except for cutting down on some boiler plate in a bunch of plotting functions. That example was just to demonstrate that it could even be simpler to have an explicit mapping, since we don't have to do:. ```python; dict(zip(adata.obs[key].cat.categories, adata.uns[key + ""_colors""])); # and instead could just do:; adata.uns[key + ""_colors""]; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/596#issuecomment-480739679:258,down,down,258,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/596#issuecomment-480739679,1,['down'],['down']
Availability,"My preference would be to throw a more informative error. Something like: ""Could not calculate statistics for group {group_name} since it only contains one sample."". I don't like that groups would be implicitly excluded from the results. In general I would expect each category of `adata.obs[""cat""]` to be in the results of `sc.tl.rank_genes_groups(adata, ""cat"")`. If they can implicitly be excluded, I think that will lead to more confusing downstream behavior. Does that sound reasonable @pinin4fjords, @Koncopd?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1490#issuecomment-725881193:51,error,error,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490#issuecomment-725881193,2,"['down', 'error']","['downstream', 'error']"
Availability,"My suspicion is that this is more likely to do with the plotting functions, than the calculation. I think the issue is that previously the axis limits weren't being set (though they were calculated). Now they are set, but it turns out they were calculated on the full range of scores – not just the plotted ones. Here's what a potential fix looks like:. <details>; <summary> Big images </summary>. Without fix:. ![tmp](https://user-images.githubusercontent.com/8238804/88772041-7cbfe480-d1c3-11ea-80e9-9ea26c3d4cea.png). With fix:. ![tmp_new](https://user-images.githubusercontent.com/8238804/88772070-88aba680-d1c3-11ea-8872-16a26103b892.png). </details>. What do you think? (ping @fidelram)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1335#issuecomment-665499836:677,ping,ping,677,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1335#issuecomment-665499836,1,['ping'],['ping']
Availability,"My thinking on this right now is that:. * The code for masking logic (pre this PR) is kind of a mess; * This PR doesn't make the code nicer. But the performance benefit is quite good, and for sure the operation `X[mask_obs, :] = scale_rv` is something we don't want to do with sparse matrices. I also think we could get even faster, plus a bit cleaner if we instead modified scale array to use something like what I suggest [here](https://github.com/scipy/scipy/issues/20169#issuecomment-1973335172) to accept a `row_mask` argument:. ```python; from scipy import sparse; import numpy as np; from operator import mul, truediv. def broadcast_csr_by_vec(X, vec, op, axis):; if axis == 0:; new_data = op(X.data, np.repeat(vec, np.diff(X.indptr))); elif axis == 1:; new_data = op(X.data, vec.take(X.indices, mode=""clip"")); return X._with_data(new_data); ```. Which *I think* would be something like:. ```python; def broadcast_csr_by_vec(X, vec, op, axis, row_mask: None | np.ndarray):; if row_mask is not None:; vec = np.where(row_mask, vec, 1); if axis == 0:; new_data = op(X.data, np.repeat(vec, np.diff(X.indptr))); elif axis == 1:; new_data = op(X.data, vec.take(X.indices, mode=""clip"")); return X._with_data(new_data); ```. Or, since we're doing numba already we could do just write out the operation with a check to see if we're on a masked row (which *should* be even faster since we're not allocating anything extra). I think either of these solutions would be simpler since we do the masking all in one place, and don't have to have a second update step.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2942#issuecomment-2024951345:55,mask,masking,55,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2942#issuecomment-2024951345,3,['mask'],"['masked', 'masking']"
Availability,Never mind... I just can't seem to read the difference between 'on_data' and 'on data'. The error didn't really help I guess.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/88#issuecomment-366284420:92,error,error,92,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88#issuecomment-366284420,1,['error'],['error']
Availability,"Nice! But may I ask why you’re still importing everything from umap instead of from pynndescent?. I’d assume if we’d do that we’d be more robust to further umap updates, no?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1038#issuecomment-584787583:138,robust,robust,138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1038#issuecomment-584787583,1,['robust'],['robust']
Availability,No idea about the error in the performance test. @flying-sheep ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/945#issuecomment-561423626:18,error,error,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/945#issuecomment-561423626,1,['error'],['error']
Availability,No longer getting errors on plotting tests. Was this being actively worked on? I think it's ready to close otherwise.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-453901572:18,error,errors,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-453901572,1,['error'],['errors']
Availability,"No matter what it returns, it definitely shouldn't make stuff fail. I think that `downsample_counts` was returning integers before the most recent PR as well. iirc, I made `downsample_counts` use integers because a) numba was failing inference unless I was explicit about integers and b) downsampling counts only makes sense for integer valued numbers. At the time I couldn't see a reason to convert the output to a different type. I figure that `log1p` should be able to take an integer valued expression matrix. However, I tried to implement that and ended up adding a lot of flow control to an already flow control heavy function, which got ugly:. <details>; <summary> 🍝 </summary>. ```python; def log1p(data, copy=False, chunked=False, chunk_size=None):; """"""Logarithmize the data matrix. Computes `X = log(X + 1)`, where `log` denotes the natural logarithm. Parameters; ----------; data : :class:`~anndata.AnnData`, `np.ndarray`, `sp.sparse`; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; copy : `bool`, optional (default: `False`); If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""; if copy:; if not isinstance(data, AnnData):; data = data.astype(np.floating); data = data.copy(); elif not isinstance(data, AnnData) and np.issubdtype(data.dtype, np.integer):; raise TypeError(""Cannot perform inplace log1p on integer array""). def _log1p(X):; if issparse(X):; np.log1p(X.data, out=X.data); else:; np.log1p(X, out=X). return X. if isinstance(data, AnnData):; if not np.issubdtype(data.X.dtype, np.floating):; data.X = data.X.astype(np.floating, copy=False); if chunked:; for chunk, start, end in data.chunked_X(chunk_size):; data.X[start:end] = _log1p(chunk); else:; _log1p(data.X); else:; _log1p(data). return data if copy else None; ```. </details>. I'll give that another shot, and open a PR. On the return type of `downsample_coun",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239:288,down,downsampling,288,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239,1,['down'],['downsampling']
Availability,"No problem!. > The idea for uns concatenation is exactly that one yes. Basically, if the keys are unique, then concatenate, if they are the same, override and throw a warning. I was thinking that this should have multiple modes, chosen by an argument like `merge_uns`. I'm thinking options would be:. * `None`: the default. Maintain current behaviour of just not merging.; * `""unique""`: Only keep values which are uniquely specified; * `""identical""`: Only keep values which are the same in all objects; * `""override""`: Just take the first value from each. You wouldn't have to implement all of these, just one that makes spatial concatenation work for now. > With respect to mixed anndata objects (e.g. one visium adata concatenated with one scRNA-seq), I will just concatenate the obsm and add empty entries to the one missing (like zeros) or something along the lines of masked arrays (although I don't think it's particularly useful in this case). Could there be a `fill_value ` argument here? A way for people to specify what the fill value should be?. I'm mainly against masked arrays since I don't think they're going to work with sparse matrices, and I'm not sure about other array subtypes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1105#issuecomment-599924513:873,mask,masked,873,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105#issuecomment-599924513,2,['mask'],['masked']
Availability,"No problem, gave a chance to optimize the code a bit (peak memory was about 3x AnnData size, now down to about 2x).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/316#issuecomment-437745410:97,down,down,97,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316#issuecomment-437745410,1,['down'],['down']
Availability,No problem. I think increasing the test coverage should be prioritised to make scanpy more robust.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/114#issuecomment-378183576:91,robust,robust,91,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/114#issuecomment-378183576,1,['robust'],['robust']
Availability,"No, i see the same test failures on the PR unrelated to plotting. No, i haven't looked yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020492061:24,failure,failures,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020492061,1,['failure'],['failures']
Availability,"No, the matplotlib error message was really confusing... the 'on data' and 'right margin' locations are scanpy features and should be in the error message... wanted to do this anyways. :wink:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/88#issuecomment-366300686:19,error,error,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/88#issuecomment-366300686,2,['error'],['error']
Availability,"No, there is no such way in DPT. We had good experience with manually choosing it. In our opinion, no one really came up with a sound and reliable statistical way of detecting the number of branching points, independent of the underlying algorithm. The best attempts to solve the problem though might be found within [Monocle 2](http://biorxiv.org/content/early/2017/02/21/110668) or [K-Branches](http://biorxiv.org/content/early/2016/12/15/094532).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/11#issuecomment-285361766:138,reliab,reliable,138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/11#issuecomment-285361766,1,['reliab'],['reliable']
Availability,"No, there is no way to get any sort of correction of the counts with this method; it's just for correcting the principal components. You can use `X_pca_harmony` for downstream analyses that by default use `X_pca`, such as computing the neighbor graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2314#issuecomment-1240116924:165,down,downstream,165,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314#issuecomment-1240116924,1,['down'],['downstream']
Availability,"No, those “invalid instruction” errors pop up sometimes. I think they’re caused by some dependency being compiled for an instruction set that not all GitHub runners support. Ways to deal with it:. 1. just restart until it works (annoying, but not much work); 2. figure out broken dependency, then; 1. if the wheel on PyPI is broken, raise an issue upstream; 2. if we compile it in the runner ourselves, set a compile flag to make it only use instructions that are compatible with all runners (i.e. not `-m arch=native` but select [an older architecture](https://en.wikipedia.org/wiki/X86-64#Microarchitecture_levels))",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2742#issuecomment-1814222794:32,error,errors,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2742#issuecomment-1814222794,1,['error'],['errors']
Availability,"Nope, that link brings me to a login page, and when I log in with my github account it gives me an error. I merged master again and added newlines; hopefully this fixes the issue. I'll give you access to my fork as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1306#issuecomment-662072716:99,error,error,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1306#issuecomment-662072716,1,['error'],['error']
Availability,"Not sure if still required (the code in the anndata repo is close to this), but here is a minimal example:; ```py; import scanpy as sc; adata = sc.datasets.pbmc3k(); h5adfile = 'pbmc3k.h5ad'; adata.write(h5adfile); a1 = sc.read_h5ad(h5adfile); a2 = sc.read_h5ad(h5adfile, backed='r+'); sc.tl.score_genes(a1, ['KIR3DL2-1', 'AL590523.1', 'CT476828.1']); # OK; sc.tl.score_genes(a2, ['KIR3DL2-1', 'AL590523.1', 'CT476828.1']); # ERROR ; ```. thanks..",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/883#issuecomment-545478497:426,ERROR,ERROR,426,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/883#issuecomment-545478497,1,['ERROR'],['ERROR']
Availability,"Not sure we can do a lot with just a traceback. Could you create a [minimal example](http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) to reproduce this error, and describe what you were trying to do?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/567#issuecomment-477832283:171,error,error,171,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/567#issuecomment-477832283,1,['error'],['error']
Availability,NotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacke,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:2338,Error,Error,2338,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"Now the error is something like: The value is not valid, please use a valid number a percentile as `pN` or a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/800#issuecomment-526495713:8,error,error,8,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800#issuecomment-526495713,1,['error'],['error']
Availability,OK I computed the neighbors using umap-learn 0.5.1 and then downgraded to 0.4.6 for UMAP. Not elegant but so far so good.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1579#issuecomment-909198091:60,down,downgraded,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1579#issuecomment-909198091,1,['down'],['downgraded']
Availability,"OK I install umap 0.4 . ```; pip install git+git://github.com/lmcinnes/umap@0.4dev; ```. However, it doesn't seem to run any faster and actually throws an error now. ```; sc.pp.neighbors(adata_B, n_neighbors=100, n_pcs=11); ```; gives; ```; AttributeError Traceback (most recent call last); <timed eval> in <module>. /opt/miniconda3/envs/py37_2/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy); 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,; 94 method=method, metric=metric, metric_kwds=metric_kwds,; ---> 95 random_state=random_state,; 96 ); 97 adata.uns['neighbors'] = {}. /opt/miniconda3/envs/py37_2/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 681 knn_distances,; 682 self._adata.shape[0],; --> 683 self.n_neighbors,; 684 ); 685 # overwrite the umap connectivities if method is 'gauss'. /opt/miniconda3/envs/py37_2/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 322 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors); 323 ; --> 324 return distances, connectivities.tocsr(); 325 ; 326 . AttributeError: 'tuple' object has no attribute 'tocsr'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/913#issuecomment-553019440:155,error,error,155,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/913#issuecomment-553019440,1,['error'],['error']
Availability,"OK great. The same errors as on master happen, so this didn’t introduce any failures. Thank you very much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/390#issuecomment-446335721:19,error,errors,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/390#issuecomment-446335721,2,"['error', 'failure']","['errors', 'failures']"
Availability,"OK! Thanks! @fidelram Should we simply regenerate all images using `matplotlib.testing.setup()`, which seems to be the most stable way to go and in the future restrict ourselves to that? I guess this is closer to a reliable test setup for all the images than the current solution via `mpl.use(""agg"")`. Also the name suggests that matplotlib does it this way. But you did some research at the time when introducing the first tests, right?. Thanks for the comment on the PAGA notebook, too, @ivirshup. I'll make sure that I didn't hard-code anything into the plotting functions that might collide with anything else happening on travis... but it's astonishing... In the meanwhile I work-around with a data-base test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-435729565:215,reliab,reliable,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-435729565,1,['reliab'],['reliable']
Availability,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```; In [1]: sc.pp.combat(adata_Combat, key='sample'); /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace.; from pandas.core.index import RangeIndex; /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).; ""(https://pypi.org/project/six/)."", FutureWarning); scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0; Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:; 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide; change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()); Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)); Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)); Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat); extracting highly variable genes; Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>; sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1172#issuecomment-616468922:249,error,error,249,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172#issuecomment-616468922,2,"['avail', 'error']","['available', 'error']"
Availability,"OK, as I wrote here: https://github.com/scverse/scanpy/issues/2359#issuecomment-1909651108. > We have no native code in Scanpy, so we don’t cause segfaults. If there’s anything we can mitigate, we will, if someone demonstrates a reproducible problem with up-to-date dependencies. Reinstalling your environment often helps. If not, please give us a way to completely reproduce this just from copyable code, i.e. . 1. a lockfile (environment.yaml or requirements.txt) containing the exact versions of everything in your environment; 2. a block of code that throws the error when run in that environment (code should download the data necessary to reproduce the issue). Then we can help",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2361#issuecomment-1909658183:566,error,error,566,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361#issuecomment-1909658183,2,"['down', 'error']","['download', 'error']"
Availability,"OK, so you’re using Python < 3.8 and `importlib_metadata`. The line `umap_version = version(""umap-learn"")` throws an error. It works for me with the same setup:. ```console; $ python -c 'from importlib_metadata import version; print(version(""umap-learn""))'; 0.3.0; ```. You said in #704 that it works “with a commit a few before” that one. You could use `git bisect` to figure out which commit exactly make a difference, but I think the issue might be either. 1. the way umap-learn 0.3.9 is installed on your system. maybe it doesn’t have proper metadata or so. you should have a directory called `umap_learn-0.3.9-py3.7.egg-info` right next to the `umap` package.; 2. You have an older version of `importlib_metadata` with a bug or so. The code basically does this:. ```py; from importlib_metadata import Distribution; def version(name):; for resolver in Distribution._discover_resolvers():; for d in resolver(name):; return d.metadata['Version']; raise PackageNotFoundError(name); ```. I don’t see how importing or not importing umap should change this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/739#issuecomment-511980962:117,error,error,117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/739#issuecomment-511980962,1,['error'],['error']
Availability,"OK, this should be mostly it. Maybe some cleanup, but no major changes. Test failures are all the server for `ebi_expression_atlas` breaking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2809#issuecomment-1910279573:77,failure,failures,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1910279573,1,['failure'],['failures']
Availability,"OK; now I have more time. The error thrown at ; ```; 207 df['dispersion_norm'] = (df['dispersion'].values # use values here as index differs; --> 208 - disp_mean_bin[df['mean_bin']].values) \; 209 / disp_std_bin[df['mean_bin']].values; ```; astonishes me. The line has been working for me on pandas 0.19.2 and 0.20.3 and for others for other versions for many months already. Do you have an old pandas version? The line should work as `disp_mean_bin` has been computed from `disp_grouped = df.groupby('mean_bin')['dispersion']` [here](https://github.com/theislab/scanpy/blob/65503d34d6b9d0a1d23e831d6daeba86856b3eee/scanpy/preprocessing/simple.py#L215); i.e., the Series 'mean_bin' was used to initialize the index of `disp_mean_bin`. Hence, you should be able to index with 'mean_bin'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/34#issuecomment-324469115:30,error,error,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34#issuecomment-324469115,1,['error'],['error']
Availability,OR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessi,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:60732,ERROR,ERROR,60732,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,OR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessi,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62535,ERROR,ERROR,62535,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,OR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62211,ERROR,ERROR,62211,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"Of course it is, but it’s a sequence of sequences (… of sequences of sequences …):. ```py; >>> list(iter(np.array([[1,2],[3,5]]))) ; [array([1, 2]), array([3, 5])]; ```. Yes, 0D-arrays aren’t sequences, but I’m OK with runtime errors if you pass one of those here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/839#issuecomment-533874937:227,error,errors,227,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839#issuecomment-533874937,1,['error'],['errors']
Availability,"Oh, I had assumed the test failures were related. Any idea what's up with those?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020439130:27,failure,failures,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2118#issuecomment-1020439130,1,['failure'],['failures']
Availability,"Oh, and I just realized it's meant to be `backed=False` and `backed=True`. I'd assumed the documentation was wrong, as `backed=True` and `backed=""True""` both throw the error:. ```python; ValueError: Invalid mode; must be one of r, r+, w, w-, x, a; ```. And I'd never checked `backed=False`. That's probably more for another issue though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/263#issuecomment-421873798:168,error,error,168,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/263#issuecomment-421873798,1,['error'],['error']
Availability,"Oh, huh, I thought allowing modifications was on by default. My bad. . > Yes, now that you made everything a property, I would have expected it to take much longer than 10 minutes. It's great that you did!. I figured it'd be good to with everything being consistent. Plus documentation for the settings is now available through `?sc.settings.{setting}`!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/573#issuecomment-479744957:310,avail,available,310,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479744957,1,['avail'],['available']
Availability,"Oh, sorry, I had completely missed your comment here!. > It looks great!. Thanks! Can I ask why you used leiden clustering on this?. > One first improvement could be to expose a parameters that explicitly ask for the number of rings in the neighbors. This should be easy enough. I'm curious as to whether this it's better to leave this up to whatever algorithm is being used however, since the one step graph has some nice properties. It'd probably be important to include distance in the multistep graph. > Btw, how do I push to this specific PR from my local repo?. This should be fairly straight forward. If you're using the github cli, I think it should just be:. ```sh; gh pr checkout 1383; # whatever changes; git push; ```. Let me know if that gives you errors, since it might be a repository permissions issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1383#issuecomment-691844681:761,error,errors,761,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1383#issuecomment-691844681,1,['error'],['errors']
Availability,"Oh, thanks! Sorry for the long downtime, the whole family was sick... I'm going through the PR now. The tests question was actually targeted towards @davidsebfischer, but thanks anyways! The comparison question was also targeted to @davidsebfischer, @tcallies. But if you do it, @andrea-tango, awesome!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/460#issuecomment-471327039:31,downtime,downtime,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/460#issuecomment-471327039,1,['downtime'],['downtime']
Availability,Ok I think this is a bug - notebooks paul15.ipynb fails with the same error - see Section ; ### Using a preprocessing recipe. adata = paul15_raw(); sc.pp.recipe_zheng17(adata),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/34#issuecomment-324336195:70,error,error,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/34#issuecomment-324336195,1,['error'],['error']
Availability,"Ok so it doesnt work, again, even with pip... @ivirshup I tried the code you wrote, and it gives me the same error:. `` AttributeError: module 'cairo' has no attribute 'version_info'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1166#issuecomment-614798701:109,error,error,109,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166#issuecomment-614798701,1,['error'],['error']
Availability,"Ok, I identified the root cause of the neighbor error and reported it as a bug: . https://github.com/scverse/scanpy/issues/2244. This probably happens because you have duplicated rows or cells with almost identical gene counts",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2085#issuecomment-1110814854:48,error,error,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085#issuecomment-1110814854,1,['error'],['error']
Availability,"Ok, so I downgraded to numba version 0.52.0 and that seems to be working well as of 5 minutes ago. . Thanks for your help!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-813536425:9,down,downgraded,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-813536425,1,['down'],['downgraded']
Availability,"Okay @ivirshup , think I've addressed your comments:. - old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). New sce.pp.scrublet now the main exposed function, with scrublet_simulate_doublets() function available for advanced users.; - plot function moved to scanpy/external/pl.py as scrublet_score_distribution().; - functions linked via 'See also' sections.; - tests added for 'scrublet()' and scrublet_simlulate_doublets().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476#issuecomment-727953553:304,avail,available,304,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476#issuecomment-727953553,1,['avail'],['available']
Availability,"Okay, when I run this:; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, ""bulk_labels"", method=""wilcoxon""); sc.tl.filter_rank_genes_groups(adata, min_fold_change=3); I get no error. ; Can you find a reproducible example of your error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1487#issuecomment-726806853:196,error,error,196,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487#issuecomment-726806853,2,['error'],['error']
Availability,"Once again, I got this error, even if I didn't import `seaborn`. ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-10-a5c62c51242c> in <module>; 1 # plt.figure(figsize=(10, 10)); 2 rcParams['figure.figsize'] = 8, 8; ----> 3 sc.pl.umap(all_dataset['pdac_pengj_02'], color='cluster', legend_loc='on data', legend_fontsize='small', title='', frameon=False). f:\tools\miniconda3\envs\deside2\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in umap(adata, **kwargs); 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 602 """"""; --> 603 return embedding(adata, 'umap', **kwargs); 604 ; 605 . f:\tools\miniconda3\envs\deside2\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 244 groups=groups,; 245 ); --> 246 color_vector, categorical = _color_vector(; 247 adata,; 248 value_to_plot,. f:\tools\miniconda3\envs\deside2\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _color_vector(adata, values_key, values, palette, na_color); 1128 return values, False; 1129 else: # is_categorical_dtype(values); -> 1130 color_map = _get_palette(adata, values_key, palette=palette); 1131 color_vector = values.map(color_map).map(to_hex); 1132 . f:\tools\miniconda3\envs\deside2\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_palette(adata, values_key, palette); 1103 _utils._set_default_colors_for_categorical_obs(adata, values_key); 1104 else:; -> 1105 _utils._validate_palette(adata, values_key); 1106 return dict",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1884#issuecomment-865741927:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1884#issuecomment-865741927,1,['error'],['error']
Availability,"One more point for the mask argument, would be useful in plotting to allow things like plotting expression with some clusters masked out (#759).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-824590137:23,mask,mask,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-824590137,2,['mask'],"['mask', 'masked']"
Availability,"Oops, didn't mean to close this initially. The datasets still don't download right on master. I've opened #1102 to fix it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1082#issuecomment-599176533:68,down,download,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082#issuecomment-599176533,1,['down'],['download']
Availability,"Owee, I'm MrMeeseeks, Look at me. There seem to be a conflict, please backport manually. Here are approximate instructions:. 1. Checkout backport branch and update it. ```; git checkout 1.9.x; git pull; ```. 2. Cherry pick the first parent branch of the this PR on top of the older branch:; ```; git cherry-pick -x -m1 bf5f27aa9e968de6e73fc7abb46a89084ddf6880; ```. 3. You will likely have some merge/cherry-pick conflict here, fix them and commit:. ```; git commit -am 'Backport PR #2831: Prepare 1.9.8, stop ignoring citation errors'; ```. 4. Push to a named branch:. ```; git push YOURFORK 1.9.x:auto-backport-of-pr-2831-on-1.9.x; ```. 5. Create a PR against branch 1.9.x, I would have named this PR:. > ""Backport PR #2831 on branch 1.9.x (Prepare 1.9.8, stop ignoring citation errors)"". And apply the correct labels and milestones. Congratulations — you did some good work! Hopefully your backport PR will be tested by the continuous integration and merged soon!. Remember to remove the `Still Needs Manual Backport` label once the PR gets merged. If these instructions are inaccurate, feel free to [suggest an improvement](https://github.com/MeeseeksBox/MeeseeksDev).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2831#issuecomment-1911960423:528,error,errors,528,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2831#issuecomment-1911960423,2,['error'],['errors']
Availability,"PPS: I see that I'm getting test failures with some github automatic tests, with none of the failures clearly coming from the code I edited -- do you know what is going on here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-902986463:33,failure,failures,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-902986463,2,['failure'],['failures']
Availability,PS: `pbmc68k_reduced` and `toggleswitch` are from back in the days; they should remain the only examples that actually have the data in the repository and the PyPI distributions. All other datasets should download their data from some stable URL...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-476589204:205,down,download,205,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476589204,1,['down'],['download']
Availability,"Perf measurements for the use case of running the HVG tests on my machine (not very accurate, and not very reminiscent of how users use it). Tests get a bit slower, real world gets faster. - scanpy master:. ```console; $ git switch master; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 71.915,07 msec task-clock:u # 14,035 CPUs utilized ( +- 9,53% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.168.035 page-faults:u # 29,496 K/sec ( +- 9,58% ); 	 191.815.791.770 cycles:u # 4,844 GHz ( +- 9,53% ) (83,37%); 	 10.610.492.234 stalled-cycles-frontend:u # 10,05% frontend cycles idle ( +- 9,44% ) (83,34%); 	 59.853.476.395 stalled-cycles-backend:u # 56,69% backend cycles idle ( +- 9,56% ) (83,32%); 	 257.750.810.841 instructions:u # 2,44 insn per cycle; 	 # 0,13 stalled cycles per insn ( +- 9,57% ) (83,33%); 	 45.773.330.764 branches:u # 1,156 G/sec ( +- 9,58% ) (83,33%); 	 1.147.567.613 branch-misses:u # 4,56% of all branches ( +- 9,54% ) (83,37%); 	; 	 5,1241 +- 0,0242 seconds time elapsed ( +- 0,47% ); ```. - this PR:. ```console; $ git switch hvg_PR_numba; $ perf stat -r 10 -B hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py; 	 Performance counter stats for 'hatch run +py=3.11 test:run -n0 scanpy/tests/test_highly_variable_genes.py' (10 runs):; 	; 	 113.085,21 msec task-clock:u # 15,789 CPUs utilized ( +- 9,56% ); 	 0 context-switches:u # 0,000 /sec; 	 0 cpu-migrations:u # 0,000 /sec; 	 1.636.606 page-faults:u # 26,373 K/sec ( +- 9,55% ); 	 310.410.832.165 cycles:u # 5,002 GHz ( +- 9,55% ) (83,35%); 	 14.117.222.045 stalled-cycles-frontend:u # 8,30% frontend cycles idle ( +- 9,46% ) (83,38%); 	 75.813.970.243 stalled-cycles-backend:u # 44,56% backend cycles idle ( +- 9,57% ) (83,35%); 	 373.047.679.552 instructions:u # 2,19 insn per cycle; 	 ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266:617,fault,faults,617,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612#issuecomment-1688394266,1,['fault'],['faults']
Availability,"Personally, I don't like it because; * Explicit is better than implicit; * there could be cases where I would like to plot Ensembl/Entrez or whatever identifier I have in `var_names` directly, even if I have a `gene_symbols` column available.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/385#issuecomment-443412025:232,avail,available,232,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/385#issuecomment-443412025,1,['avail'],['available']
Availability,Phneograph was recently updated and also new wrappers are available in external thanks to @awnimo @Koncopd .; Does this work for you @asmariyaz23 ? I will close this but feel free to reopen,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1407#issuecomment-706139788:58,avail,available,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1407#issuecomment-706139788,1,['avail'],['available']
Availability,"Ping @WeilerP @adamgayoso, since you've both raised this idea today",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1832#issuecomment-1028414654:0,Ping,Ping,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832#issuecomment-1028414654,1,['Ping'],['Ping']
Availability,Ping @fidelram,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1591#issuecomment-761747050:0,Ping,Ping,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1591#issuecomment-761747050,1,['Ping'],['Ping']
Availability,Ping @flying-sheep,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1241#issuecomment-631952736:0,Ping,Ping,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1241#issuecomment-631952736,1,['Ping'],['Ping']
Availability,"Ping @ivirshup. I wanna merge this if possible, it'd be great if you can have a look at the reply above. Together with this PR and https://github.com/theislab/scanpy/pull/1488, it would be great to do gene-set enrichment of all cell types at once without loops \o/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1388#issuecomment-724859143:0,Ping,Ping,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1388#issuecomment-724859143,1,['Ping'],['Ping']
Availability,Ping. This is a needed in the https://github.com/clara-parabricks/rapids-single-cell-examples so that we can make our notebooks reproducible. It's a trivial addition to propagate the `random_state` argument to the RAPIDS UMAP estimator. Any chance this can be considered for review?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1474#issuecomment-722610470:0,Ping,Ping,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1474#issuecomment-722610470,1,['Ping'],['Ping']
Availability,"Pinging this, as I've encountered it as well. I ran into non-reproducible UMAPs when rerunning code/notebooks and systematically went through my pipeline to find the source(s) of error, one of which was `sc.tl.score_genes_cell_cycle`. Setting the random seed externally did not help, but @Iwo-K's comment got me on the right track. I am now using the following simple hack, which fixes the issue for me:. ```python; adata.X = adata.X.astype('<f8') # Make float64 to ensure stability; sc.tl.score_genes_cell_cycle(adata, use_raw=False,; s_genes=cc_s_genes, g2m_genes=cc_g2m_genes,; random_state=0); adata.X = adata.X.astype('<f4') # Return to float32 for consistency; ```. Would be great if this would be fixed internally, perhaps using @Iwo-K's solution?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/313#issuecomment-849730924:0,Ping,Pinging,0,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/313#issuecomment-849730924,2,"['Ping', 'error']","['Pinging', 'error']"
Availability,"Please adapt the corresponding test to:. ```; @pytest.mark.parametrize(""flavor"", [""default"", ""use_fastpp""]); def test_scale(flavor):; adata = pbmc68k_reduced(); adata.X = adata.raw.X; v = adata[:, 0 : adata.shape[1] // 2]; # Should turn view to copy https://github.com/scverse/anndata/issues/171#issuecomment-508689965; assert v.is_view; with pytest.warns(Warning, match=""view""):; sc.pp.scale(v, flavor=flavor); assert not v.is_view; assert_allclose(v.X.var(axis=0), np.ones(v.shape[1]), atol=0.01); assert_allclose(v.X.mean(axis=0), np.zeros(v.shape[1]), atol=0.00001); ```. It fails for me with `FAILED scanpy/tests/test_preprocessing.py::test_scale[use_fastpp] - numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540014267:677,error,errors,677,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540014267,1,['error'],['errors']
Availability,Please check this issue: #456 . Your data in `adata.raw` are probably `np.matrix`. You can either format to `np.ndarray` or to `scipy.sparse.csr_matrix()` to solve this. Note you are using `adata.raw.X` and not `adata.X` in `rank_genes_groups()` by default. So your proposed line of code will not solve your error. Please instead use for example:. `adata.raw.X = scipy.sparse.csr_matrix(adata.raw.X)`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1467#issuecomment-715475234:308,error,error,308,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1467#issuecomment-715475234,1,['error'],['error']
Availability,"Please provide more details. What is `folder` in your case and what is the error message? Follow the issue template, please.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1795#issuecomment-817677727:75,error,error,75,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795#issuecomment-817677727,1,['error'],['error']
Availability,"Please re-open this; currently receiving this error with Python 3.9.7 and scanpy 1.8.2. Just in case it's useful, CPU flags including instruction sets are pasted below. fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 popcnt aes xsave avx f16c lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs xop skinit wdt lwp fma4 tce nodeid_msr tbm topoext perfctr_core perfctr_nb cpb hw_pstate ssbd ibpb vmmcall bmi1 arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1823#issuecomment-983551937:46,error,error,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1823#issuecomment-983551937,1,['error'],['error']
Availability,"Probably is, I think the `nan`s are for all zero genes. But I think there's a better solution than a procedural warning and data that causes errors downstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/581#issuecomment-478798294:141,error,errors,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-478798294,2,"['down', 'error']","['downstream', 'errors']"
Availability,"Putting `basis` first is fine as `plot_scatter` is an internal function that doesn't appear in the API. The `arrows` should evtl appear in all embeddings; so that's fine. All of these scatter functions should have exactly the same arguments. So, it's not the fault of your PR but my fault, as I haven't pulled the change through. Due to `scvelo`, `arrows` might also disappear... So, let's not worry about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/539#issuecomment-474329957:259,fault,fault,259,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539#issuecomment-474329957,2,['fault'],['fault']
Availability,"PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; 12 warnings and 3 errors generated.; error: command '/usr/bin/clang' failed with exit code 1; [end of output]; ; note: This error originates from a subprocess, and is likely not a problem with pip.; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Attempting uninstall: fa2; Found existing installation: fa2 0.3.5; Uninstalling fa2-0.3.5:; Successfully uninstalled fa2-0.3.5; Running setup.py install for fa2 ... error; error: subprocess-exited-with-error; ; × Running setup.py install for fa2 did not run successfully.; │ exit code: 1; ╰─> [212 lines of output]; Installing fa2 package (fastest forceatlas2 python implementation); ; >>>> Cython is installed?; Yes; ; >>>> Starting to install!; ; running install; running build; running build_py; creating build; creating build/lib.macosx-12.3-x86_64-3.10; creating build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/fa2util.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/__init__.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/forceatlas2.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; running egg_info; writing fa2.egg-info/PKG-INFO; writing dependency_links to fa2.egg-info/dependency_links.txt; writing requirements to fa2.egg-info/requires.txt; writing top-level names to fa2.egg-info/top_level.txt; reading manifest file 'fa2.egg-info/SOURCES.txt'; reading manifest template 'MANIFEST.in'; adding license file 'LICENSE'; writing manifest file 'fa2.egg-info/SOURCES.txt';",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:17206,error,error,17206,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,3,['error'],['error']
Availability,R scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65491,ERROR,ERROR,65491,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,R scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportErr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69572,ERROR,ERROR,69572,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:60893,ERROR,ERROR,60893,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - Imp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68757,ERROR,ERROR,68757,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportErr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64835,ERROR,ERROR,64835,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,RROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; s,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3703,ERROR,ERROR,3703,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,RROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - Im,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61879,ERROR,ERROR,61879,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,RROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportErro,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69085,ERROR,ERROR,69085,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,RROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_grou,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:72198,ERROR,ERROR,72198,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,RROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64340,ERROR,ERROR,64340,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"Re: #1649. Does this still need a max fold change argument?. More generally, how complex do we want the filtering available through these functions (and `sc.get.rank_genes_groups_df`) to be? Is it most straight forward to recommend passing the gene names, and recommend users generate these by manipulating the dataframe returned by `rank_genes_groups_df`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1529#issuecomment-781059091:114,avail,available,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529#issuecomment-781059091,1,['avail'],['available']
Availability,"Re: quotes: Yes, the difference is that escape sequences work in double quoted strings. So for me a double quoted string in otherwise single quoted TOML means “pay attention, this one has special stuff in it”. Re: Build: The problem is that. 1. we’re installing louvain and it; 2. [doesn’t have a Python 3.9 wheel](https://pypi.org/project/louvain/#files), which causes us to download the sdist,; 3. [Sets `2to3=True` in setup.py](https://github.com/vtraag/louvain-igraph/blob/0.7.0/setup.py#L827-L828), for which [setuptools has removed support](https://setuptools.pypa.io/en/latest/history.html#v58-0-0). I think the best course of action would be to just port louvain to Python 3 only, and until then make sure our build environment as setuptools 57 installed. See https://github.com/vtraag/louvain-igraph/issues/57. Or we can deactivate louvain tests, skip installing it in the tests, and let people who need it deal with that. Or we ask @vtraag to upload Python 3.9 and 3.10 wheels, then we kicked the problem back two releases.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2042#issuecomment-967619897:376,down,download,376,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2042#issuecomment-967619897,1,['down'],['download']
Availability,"Re: testing externals, I've tried my best to just test the way it interfaces with scanpy. i.e., if MAGIC silently fails to return the correct output, scanpy tests would pass so long as the output is the right type / shape. If MAGIC throws an error when run from scanpy, this might be something you would like to address (i.e. by contacting the relevant external developer) regardless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/988#issuecomment-573589189:242,error,error,242,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/988#issuecomment-573589189,1,['error'],['error']
Availability,"Realised this functionality is already available via `pip install "".[dev]""`. May be good to mention somewhere, though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1419#issuecomment-694244682:39,avail,available,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1419#issuecomment-694244682,1,['avail'],['available']
Availability,"Regarding the other packages: of course, we will also interface those as optional dependencies... But I'd do it from the original Scanpy repo. To me, the whole problem is simply about keeping a clean structure and throwing clear error messages if optional dependencies are not installed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/125#issuecomment-382344862:229,error,error,229,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125#issuecomment-382344862,1,['error'],['error']
Availability,"Reopen if more info is available, please.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2343#issuecomment-1290776224:23,avail,available,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343#issuecomment-1290776224,1,['avail'],['available']
Availability,"Right after booting up my Docker container, this is the result of `conda list | grep anndata`:. `anndata 0.8.0 pyhd8ed1ab_1 conda-forge`. Then, after running `pip install anndata --upgrade`, and then again `conda list | grep anndata`:. `anndata 0.10.6 pypi_0 pypi`. At this point, `pkg_version('anndata')` errors out as described.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2978#issuecomment-2037957505:306,error,errors,306,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978#issuecomment-2037957505,1,['error'],['errors']
Availability,"Right now I do not get the error if I do these steps:. ```py; sc.pp.normalize_per_cell(adata, counts_per_cell_after=norm_counts_per_cell); sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=n_top_genes); sc.pp.regress_out(adata, ['n_counts', 'percent_mito']); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/667#issuecomment-520178937:27,error,error,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/667#issuecomment-520178937,1,['error'],['error']
Availability,"Running `0.10.3` here. I had a similar error message, originating in a **mismatch of the indices of the obs-like dataframes** of the `AnnData` object. Although it was not exactly the same (sorry i don't have it here), maybe this can be a hint. Here is how i solved the issue. ```python; ### Have a look at the indices; for key, obs_matrix in adata.obsm.items():; if hasattr(obs_matrix, ""index""):; print(key); print(obs_matrix.index); print(adata.obs_names); print(adata.obs.index). ### If there's a mismatch, you can fix by running something like:; for key, obs_matrix in adata.obsm.items():; if hasattr(obs_matrix, ""index""):; obs_matrix.index = adata.obs_names; ```. I also had a similar error message when there was a mismatch in the _name_ of the index, or if the name of the index was also the _name of a column_. Note that if there is a mismatch, the `adata.write_h5ad` function _does not_ crash. While reading the saved file with `ad.read_h5ad` _will crash_. Suggestion for developers: When the `AnnData.write_h5ad` method is called, check the homogeneity of the indices, and raise an exception if there is a mismatch. Suggestion for users: make sure all the index are the same, have the same name, and that no column has the same name.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-2162803279:39,error,error,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-2162803279,2,['error'],['error']
Availability,Same error here.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2239#issuecomment-1539132164:5,error,error,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1539132164,1,['error'],['error']
Availability,"Same error here...any ideas?. ```; -----; anndata 0.8.0; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 9.0.1; PyQt5 NA; anndata 0.8.0; anndata2ri 0.0.0; atomicwrites 1.4.0; autoreload NA; backcall 0.2.0; backports NA; beta_ufunc NA; binom_ufunc NA; bs4 4.10.0; cached_property 1.5.2; cffi 1.15.0; chardet 4.0.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.2; dask 2022.02.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dunamai 1.10.0; entrypoints 0.4; fsspec 2022.02.0; get_version 3.5.4; h5py 3.6.0; igraph 0.9.9; ipykernel 6.9.1; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; kiwisolver 1.3.2; leidenalg 0.8.9; llvmlite 0.38.0; louvain 0.7.1; markupsafe 2.1.0; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.0; numpy 1.21.5; packaging 21.3; pandas 1.3.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.27; psutil 5.9.0; ptyprocess 0.7.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.7; pytz 2021.3; pytz_deprecation_shim NA; rpy2 3.4.2; scanpy 1.8.2; scipy 1.7.3; seaborn 0.11.2; setuptools 59.8.0; sinfo 0.3.1; sip NA; six 1.16.0; sklearn 1.0.2; soupsieve 2.3.1; sphinxcontrib NA; spyder 5.2.2; spyder_kernels 2.2.1; spydercustomize NA; statsmodels 0.13.2; storemagic NA; tables 3.7.0; texttable 1.6.4; threadpoolctl 3.1.0; tlz 0.11.2; toolz 0.11.2; tornado 6.1; traitlets 5.1.1; typing_extensions NA; tzlocal NA; wcwidth 0.2.5; wurlitzer 3.0.2; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 7.32.0; jupyter_client 7.1.2; jupyter_core 4.9.2; -----; Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]; Linux-5.4.0-109-generic-x86_64-with-debian-bullseye-sid; 16 logical CPU cores, x86_64; -----; Session information updated at 2022-04-20 18:16; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2239#issuecomment-1104127300:5,error,error,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1104127300,1,['error'],['error']
Availability,"Same error occurred when using the default leiden with weights as well; downgrading python-igraph to 0.9.11 fixed the issue.; leidenalg is dependent on python-igraph (0.10.0 for my conda) and igraph (0.9.10), and I suppose the version discrepancy caused the problem. Or you can replace tl.leiden with leiden algorithm in python-igraph:. adjacency = sc._utils._choose_graph(adata, obsp=None, neighbors_key=None); g = sc._utils.get_igraph_from_adjacency(adjacency); clustering = g.community_leiden(objective_function='modularity', weights='weight', resolution_parameter=0.5); adata.obs['leiden_igraph_weight'] = pd.Series(clustering.membership, dtype='category', index=adata.obs.index). sc.pl.umap(adata, color='leiden_igraph_weight')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2339#issuecomment-1262134575:5,error,error,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339#issuecomment-1262134575,2,"['down', 'error']","['downgrading', 'error']"
Availability,"Same here, downgrading made everything work",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1407#issuecomment-691088607:11,down,downgrading,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1407#issuecomment-691088607,1,['down'],['downgrading']
Availability,"Same here. adata.uns['log1p'][""base""] = None eliminated the error, but the FC seems weird. ; I compared the FC results with Seurat FindMarker results, which used the same FC calcualtion. For most genes, Scanpy resulted in much higher FC (some gets 30 or more), which I have never seen.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2239#issuecomment-1414959276:60,error,error,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239#issuecomment-1414959276,1,['error'],['error']
Availability,Same issue here. Downgrading scipy from 1.5.4 to 1.2.1 helps.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/643#issuecomment-720711607:17,Down,Downgrading,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/643#issuecomment-720711607,1,['Down'],['Downgrading']
Availability,"Same problem here. So glad that I found this ticket. From flying-sheep's commit, it looks like either upgrading scanpy to the newest version or downgrading pandas would work. There is also some anndata version requirement going up, no idea why.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/450#issuecomment-458954075:144,down,downgrading,144,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-458954075,1,['down'],['downgrading']
Availability,"Scanorama's `nn_approx` uses annoy, which is a package that has caused many a headache due to its instability. From my experience, these segfaults started showing up since 1.17.x got released, and tend to begin happening more consistently if anything is installed into the environment after annoy itself somehow. Downgrading to 1.16.3 via pip tends to make them go away. It would be neat if there was some sort of more reliable workaround, keeping annoy stable and not bothering the user.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2866#issuecomment-1976231395:313,Down,Downgrading,313,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2866#issuecomment-1976231395,2,"['Down', 'reliab']","['Downgrading', 'reliable']"
Availability,"Scanpy core maintenance is done by the core team, while in external the maintenance is expected by the external contributor. Of course the scanpy core team grows as well... so i think this is a organization question maybe for @ivirshup and @flying-sheep.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1432#issuecomment-698886893:12,mainten,maintenance,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432#issuecomment-698886893,2,['mainten'],['maintenance']
Availability,Seems like this is still an issue. I am getting this error below randomly. It disappears after trying sometime later with the exact code and files... scanpy==1.9.4 anndata==0.9.2 umap==0.5.3 numpy==1.23.4 scipy==1.11.2 pandas==2.1.4 scikit-learn==1.3.0 statsmodels==0.14.0 igraph==0.10.6 louvain==0.8.1 pynndescent==0.5.10. `adata=sc.read_h5ad('foo.h5ad')`; Error:; `AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.group.Group'> from /.`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1890353810:53,error,error,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1890353810,3,"['Error', 'error']","['Error', 'error']"
Availability,Seems this has been fixed in https://github.com/bioconda/bioconda-recipes/pull/21423. ; `1.4.6` is available again.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1146#issuecomment-613471671:99,avail,available,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1146#issuecomment-613471671,1,['avail'],['available']
Availability,Several HTTP errors,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2798#issuecomment-1885167604:13,error,errors,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2798#issuecomment-1885167604,1,['error'],['errors']
Availability,"Should be fixed in scipy 1.11.3: https://github.com/scipy/scipy/issues/18716. You only have 1.10.1 installed. Please try upgrading. If the error persists, feel free to follow up!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3141#issuecomment-2210675845:139,error,error,139,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141#issuecomment-2210675845,1,['error'],['error']
Availability,"Should the reference object where you learn the transformation (currently `adata`) always be a subset of the data you're going to apply the transformation to (`adata2`)? If so, instead of passing a separate object, could there be a mask of which samples to train on?. If not, what do you think about making this a separate function? Maybe `combat_by_reference`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1501#issuecomment-730233047:232,mask,mask,232,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501#issuecomment-730233047,1,['mask'],['mask']
Availability,"Since I saw this just linked to another issue (#2540), I'll post my updates and ways I got around this (since I had to re-investigate this last week for a separate script). We have not updated our Scanpy on our platform since I posted this ticket (though will soon), but I ran into another situation where the code worked on an older version of scanpy but not on a later version which was running on my machine. I just wrote a try/except block to handle this. ```python3; """"""; One of the scanpy versions introduced a bug that was recently fixed, ; where pl.rank_genes_groups works but not pl.rank_genes_groups_<plot>. ; I believe it is because adata.var.index is being stored as the ; adata.uns ""gene_symbol"" output for tl.rank_genes_groups, ; and pl.rank_genes_groups correctly looks for the adata.var.index, ; but pl.rank_genes_groups_<plot> is erroneously looking for the adata.var.gene_symbol there instead (per my supplied ""gene_symbols"" arg). Seems to work in scanpy 1.7.2 but is broke in 1.8.2; """""". ax = sc.pl.rank_genes_groups(adata, groups=[query_cluster],; gene_symbols='gene_symbol', n_genes=n_genes, save=""_comp_ranked.png""). try:; # Try 1.7.2 way first; ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,; gene_symbols=""gene_symbol"", n_genes=n_genes, save=""_comp_violin.png""); except:; # Use gene names if that doesn't work; gene_names = adata.var.loc[adata.uns[""rank_genes_groups""]['names'][query_cluster]][""gene_symbol""][:n_genes].tolist(); ax = sc.pl.rank_genes_groups_violin(adata, groups=query_cluster, use_raw = False,; gene_symbols=""gene_symbol"", gene_names=gene_names, save=""_comp_violin.png""). ```. Earlier, I had mentioned using `use_raw=True` for the previous script I had this issue with, but ultimately removed that parameter due to some other downstream things",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2258#issuecomment-1625573706:1802,down,downstream,1802,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2258#issuecomment-1625573706,1,['down'],['downstream']
Availability,"Since we don't know when a release of `pynndescent` will go out, I think it's fine to keep this a little hacky for now. I think it can be less hacky than now doing something like this:. ```python; from_init = pynndescent.NNDescent(train, n_neighbors=15, init_graph=indices); from_init._rp_forest = rp_forest; query_indices_init, query_distances_init = from_scratch.query(test); ```. Once a release of pynndescent comes out we can support doing it the proper way. . I'd say it's up to you whether you want to have the kinda hacky solution or not. I definitely don't want UMAP to be pinned to below 0.5 when we release 1.7 proper, and it would be good for ingest to work with UMAP 0.5. The only downside I see to the kinda hacky solution as an intermediate is that you're fixing it twice. I don't think it'll be hard to go from this to the clean version however. -------------------------. I haven't looked into what needs to happen for the UMAP embedding transfer stuff to work. Is that pretty straight forward?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1589#issuecomment-762553133:693,down,downside,693,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1589#issuecomment-762553133,1,['down'],['downside']
Availability,"So I guess basic difference is that this one can convert starfish to anndata ""online"" without having to read from disk the anndata object. Also, my understanding with `save_anndata` method is that it doesn't export all the features we might want (e.g. area of segmentation masks or others, to be stored in obs). However, this could also be fixed by sending a PR there and modifying what is saved in anndata of the expression matrix.; What do you guys think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1362#issuecomment-671884211:273,mask,masks,273,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1362#issuecomment-671884211,1,['mask'],['masks']
Availability,"So I just reproduced this error for `sc.pp.log1p()` using my own data after using the `sc.pp.downsample_counts()` function. It might have to do with that?. i noticed that `sc.pp.downsample_counts()` returns `np.int64` rather than `np.float64` I reckon that's what the log transformation is complaining about. If I add the line:; ```; adata.X = adata.X.astype(np.float64); ```; after the downsampling call, it works again. Maybe add that to `sc.pp.log1p()`? Or change `sc.pp.downsample_counts()` to return `np.float64`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-475709600:26,error,error,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475709600,2,"['down', 'error']","['downsampling', 'error']"
Availability,"So I just tried to install the package from the master branch by running. ```; pip install git+https://github.com/theislab/scanpy.git; ```; (by the way, you can update the Installation section of the README.md because the above line is equivalent to cloning the repository and running pip install on that.) The installation failed with; ```; Collecting git+https://github.com/theislab/scanpy.git; Cloning https://github.com/theislab/scanpy.git to /tmp/pip-203inirx-build; Complete output from command python setup.py egg_info:; running egg_info; creating pip-egg-info/scanpy.egg-info; writing pip-egg-info/scanpy.egg-info/PKG-INFO; writing dependency_links to pip-egg-info/scanpy.egg-info/dependency_links.txt; writing entry points to pip-egg-info/scanpy.egg-info/entry_points.txt; writing requirements to pip-egg-info/scanpy.egg-info/requires.txt; writing top-level names to pip-egg-info/scanpy.egg-info/top_level.txt; writing manifest file 'pip-egg-info/scanpy.egg-info/SOURCES.txt'; warning: manifest_maker: standard file '-c' not found; ; error: package directory 'scanpy/exs' does not exist; ; ----------------------------------------; Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-203inirx-build/; The command '/bin/sh -c pip install --upgrade --no-cache-dir git+https://github.com/theislab/scanpy.git' returned a non-zero code: 1; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/7#issuecomment-284343715:1043,error,error,1043,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/7#issuecomment-284343715,2,['error'],['error']
Availability,"So actually, I run a test on a fresh docker image (with this [Dockerfile](https://gist.github.com/pwl/005c781cbe19f5e961b59366f738caaf)) and it still fails to install scanpy with the same error. I had some success with changing the default python encoding to utf-8 as shown in the Dockerfile but it only works when calling python3 directly and not for pip3. However, it worked with python2. I guess python3 is not supported by scanpy, is that correct?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/43#issuecomment-343252579:188,error,error,188,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43#issuecomment-343252579,1,['error'],['error']
Availability,"So assuming that we are only interested in downsampling, then I'd say `NearMiss` and related are straightforward and scalable (just need to compute a kmeans whcih is really fast)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/987#issuecomment-1043141030:43,down,downsampling,43,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/987#issuecomment-1043141030,1,['down'],['downsampling']
Availability,"So far as I can tell, any further downstream operations also acts on layers... so it is not useful to store raw counts there since they will just be modified with counts normalization, log normalization, etc. Storing things in layers sequentially, I just end up with a bunch of layers that all are identically fully processed rather than preserving the raw-er aspect of the counts matrix. Not sure if this is new behavior but it is super frustrating",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2261#issuecomment-2070663668:34,down,downstream,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2261#issuecomment-2070663668,1,['down'],['downstream']
Availability,"So it appears to me that the difference between the discrete and continuous colours is purely an internal `scanpy` decision. Plotting with `matplotlib` and a `pd.Categorical` returns the same error as before. ![image](https://user-images.githubusercontent.com/8499679/73891118-81719480-4841-11ea-8752-b7490d89f4bd.png). An alternative would be to explicitly return a categorical from the clustering function, i.e. rather than ensuring that the clustering returns an array of `str`, ensure that it returns a categorical where the categories are ints. Categorical (string) output: scanpy works, matplotlib errors:. <details>. ![image](https://user-images.githubusercontent.com/8499679/73891608-a1ee1e80-4842-11ea-97b8-16c4618a894f.png). </details>. Integer output: matplotlib works, scanpy mistakenly uses continuous colormap:. <details>. ![image](https://user-images.githubusercontent.com/8499679/73891676-bd592980-4842-11ea-8043-5ed74693ee28.png). </details>. Cateogrical (integer) output: both work. <details>. ![image](https://user-images.githubusercontent.com/8499679/73891704-ccd87280-4842-11ea-91c1-445b1574d812.png). </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-582657247:192,error,error,192,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-582657247,2,['error'],"['error', 'errors']"
Availability,"So it looks like we definitely started downloading the rc for numpy relecently: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6661&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=22c10d56-3e3b-5f98-5bc6-b33384a21306 (from last week or something, downloading 1.26.4) vs https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=efb91c47-e839-5730-ecc5-cc752bc791b5 (downloading the 2.0 rc)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3048#issuecomment-2112322713:39,down,downloading,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048#issuecomment-2112322713,3,['down'],['downloading']
Availability,"So it will only work on non-negative expression values without any pre-process?; I guess that make sense, thank you for the reply. The version of the package:. scanpy==1.4.6 anndata==0.7.1 umap==0.4.0 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. The AnnData objects were all read through same commands without any modification. sc.read_10x_h5(filepath, gex_only=False). the dataset I used to test them are:. https://support.10xgenomics.com/single-cell-vdj/datasets/2.2.0/vdj_v1_hs_nsclc_5gex; https://support.10xgenomics.com/single-cell-gene-expression/datasets/3.0.0/pbmc_10k_protein_v3; https://support.10xgenomics.com/single-cell-gene-expression/datasets/3.0.0/malt_10k_protein_v3. It appears to me that it only works on the v2 nsclc h5 data. I was trying to merge the three data sets and run through SAM to compare with the result of BBKNN, didn't work. So I tried to run each of them individually in the loop. I guess it won't work on CITESeq data without other processing?. I tried removed all the antibody read counts from adata.X and ran it once, still got same error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1157#issuecomment-614976989:1135,error,error,1135,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157#issuecomment-614976989,1,['error'],['error']
Availability,So my X actually contained negative values. I removed my _scanpy.pp.scale_ step and tried this downsampling step earlier in my pipeline and its working. Thanks for taking time to help with this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2131#issuecomment-1033885282:95,down,downsampling,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2131#issuecomment-1033885282,1,['down'],['downsampling']
Availability,"So my idea was the following:; If you have a full dataset and some genes are 0 everywhere, except in the cells in cluster A, then you filter out cluster A in your new dataset, and recompute everything... those genes now have 0 variance in your filtered dataset. That would give you an error that didn't appear before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/653#issuecomment-494330011:285,error,error,285,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/653#issuecomment-494330011,1,['error'],['error']
Availability,"So the format seems to be correct. Do you have the genes that are apparently missing in your object? You can check this for all the values that are mentioned in the `KeyError` output at the bottom of your error report. For example, is this statement `True`?; `'USP1' in [str(i) for i in adata.var_names]`. If not, your `adata` object might just be missing the cell cycle genes you are looking for. How many genes are in your object?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1599#issuecomment-762881039:205,error,error,205,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1599#issuecomment-762881039,1,['error'],['error']
Availability,"So the issue is incompatibilities between versions of sphinx and their `objects.inv`? Is there an open issue in sphinx for this?. > > Do you expect this to be compatible with older sphinx versions?; >; > Of course! Why would it not be?. Mostly because the inner workings of Sphinx are a mystery to me, so I have no idea what features your changes rely on 😆. This was mainly me asking if we should bump the minimum version of sphinx allowed. Maybe we should if there are issues with the `objects.inv`s?. > Maybe we can link to the dev docs?. Or we could add the classes to nitpick ignore? Then once the docs are rebuilt it will do the right thing without any intervention, and we don't have to be keeping an eye out for this. My main concern here is that the `scipy.github.io` address may not be permanent, similar to how numpy temporarily used a github.io address while they revamped their docs. Basically, it may just break or go down without notice. I thought we could even just trigger a new build of the anndata stable docs, but there's an issue there, probably to do with sphinx not being pinned on release. I do want to make a new anndata release soon-ish though. -----------. I'm happy for you to pick one of the approaches and merge it. AnnData could also use a fix for this, I've temporarily just pinned sphinx below 4.1 there too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1948#issuecomment-880405295:931,down,down,931,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1948#issuecomment-880405295,1,['down'],['down']
Availability,"So the user experience will be:. 1. They’ll go through the example notebooks where they’ll learn how to download data. → The notebooks should mention where to configure the cache directory. 2. They’ll download data, probably not paying attention to the output immediately. → We should mention where the data are every time they get loaded (Either from the web or from the cache dir. Maybe even mention that the location can be configured in settings?). 3. Maybe they’ll eventually look at the settings module in the online documentation. → We should explain there that the default uses appdirs, and what directories that maps to on different OSs. 4. A user in some misconfigured HPC environment who manages to not see any of the warnings will end up filling heir home directory by downloading data to the default directory (Is that possible or will there be no error?). → We should mention that the directoy can be globally configured for all libraries and applications using XDG_CACHE_HOME, and for scanpy using `scanpy settings cachedir ....` or `scanpy.settings.cachedir = ....`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-477119702:104,down,download,104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477119702,4,"['down', 'error']","['download', 'downloading', 'error']"
Availability,So there is both a plot and error output? That would explain why not all is shown …,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3102#issuecomment-2154498462:28,error,error,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102#issuecomment-2154498462,1,['error'],['error']
Availability,"So this would be a reproducible example:. ```py; import gzip; import shutil; from urllib.request import urlopen; from pathlib import Path. from tqdm.notebook import tqdm; import scanpy as sc. url = ""https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE194122&format=file&file=GSE194122%5Fopenproblems%5Fneurips2021%5Fmultiome%5FBMMC%5Fprocessed%2Eh5ad%2Egz"". path = Path(""data/GSE194122_openproblems_neurips2021_multiome_BMMC_processed.h5ad""); if not path.is_file():; with (; urlopen(url) as raw,; tqdm.wrapattr(raw, ""read"", total=int(raw.headers[""Content-Length""])) as wrapped,; gzip.open(wrapped, 'rb') as f_in,; path.open('wb') as f_out,; ):; shutil.copyfileobj(f_in, f_out). adata_atac = sc.read(path); adata_atac.X = (adata_atac.X > 0)*1; sc.pp.highly_variable_genes(adata_atac, n_top_genes=13634); adata_atac = adata_atac[:,adata_atac.var['highly_variable']]; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2819#issuecomment-1910369113:232,down,download,232,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2819#issuecomment-1910369113,1,['down'],['download']
Availability,"So you want to e.g., downweight the likelihood of sampling cells with a particular feature (like a common cell type), and upweight others. What do you want to use this weighting for now in the `sc.tl.rank_genes_groups` function? Or in the visualization functions you changed?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494111085:21,down,downweight,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494111085,1,['down'],['downweight']
Availability,"So, without any evidence, I think it should be fine. The reason I had put an error in the first place is that the typical behavior is to pass log normalized data to this HVG function, and I didn't want people to run this incorrectly. I think another solution would be to just throw a UserWarning, though in a way I like the idea of having an argument that disables the `check_nonnegative_integer()`. I think I would call it `enforce_counts_seurat_v3` though. You might also consider bypassing the check if the flag is set, because it can be slowish for large datasets.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1642#issuecomment-776841793:77,error,error,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1642#issuecomment-776841793,1,['error'],['error']
Availability,"Some notes/observations from my side towards choosing the proper resolution: . - the Leiden algorithm depends on a random seed. With a different random seed, you might get a different number of clusters with the same resolution; - a sensible resolution depends on the input data: when clustering on data processed with `sc.tl.diffmap` a much lower resolution will give the same number of clusters than without. ; - I performed a hyperparameter search for the resolution (steps of 0.005) on a large dataset of CD8+ T cells. I observed that at certain resolution ranges, the number of clusters is stable. In my case, I was looking for subtypes of CD8+ T cells and hypothesized that at ~0.1 and ~0.3 I would find something biologically meaningful. Would be interesting to re-do that on the PBMC dataset. I would expect a plateau at a resolution that recovers the well-known cell types CD8+, CD4+, etc. . ![2019-06-03_09:53:34_911x604](https://user-images.githubusercontent.com/7051479/58785259-7ea10e80-85e5-11e9-8e0b-789e2e74754a.png); **Fig:** hyperparameter search for resolution in steps of 0.005. The graph shows the resolution vs. detected number of Leiden-clusters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/670#issuecomment-498153336:847,recover,recovers,847,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/670#issuecomment-498153336,1,['recover'],['recovers']
Availability,"Some tests are still failing, but not because of `uns/spatial`. They all throw errors along these lines:; ```; assert 'Error: Image files did not match.\n RMS Value: 15.114361035293829\n; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1105#issuecomment-600196432:79,error,errors,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105#issuecomment-600196432,2,"['Error', 'error']","['Error', 'errors']"
Availability,"Some ways I like to work with the code:. * Left side of screen is text editor, right side is terminal/ docs/ something else; * 86 characters available if I have a side bar open, 95 without; * Split code browser; * 84 columns with a side bar open, 95 without. 120 is too long for this. Also this is a pretty wide laptop screen (16-inch). I believe Alex uses a MacBook Air with even more limited screen real estate.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1694#issuecomment-787409697:141,avail,available,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1694#issuecomment-787409697,1,['avail'],['available']
Availability,"Sorry about the wait, had to focus on getting the last release out. Now we can do new features!. > But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default; * Consolidate implementation to a single well maintained library; * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points?. * `tsne` should allow weights to be passed through (whether perplexity based, or not); * There should be a warn",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-773051636:569,error,error,569,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-773051636,1,['error'],['error']
Availability,Sorry for all the trouble. I just wanted to download from your dropbox link but the file wasn't there anymore...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-457869163:44,down,download,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-457869163,1,['down'],['download']
Availability,"Sorry for being offline for a few hours and great that you could resolve it. In the next version, this confusion will not appear again. Even though, obviously, any Scanpy release reproduces all examples on https://github.com/theislab/scanpy_usage, we're still at an early stage in the package. Things are progressing very fast and structure and maintenance of the package are becoming more and more professional. Also, soon, many new features and examples where other Python packages are used will be added. Thank you for a bit of patience at this stage.; Alex. PS: We now have an initial version of the documentation: https://scanpy.readthedocs.io.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35#issuecomment-324638985:345,mainten,maintenance,345,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35#issuecomment-324638985,1,['mainten'],['maintenance']
Availability,"Sorry for opening this thread again, but I think I've run into the same problem. Here's my code and error:; ```; mat_all = sc.read_loom(filename=""RSV.loom""); sc.pp.pca(mat_all); sc.pp.neighbors(mat_all); sc.tl.umap(mat_all); ```; The error message:; ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); /tmp/31048.tmpdir/ipykernel_3245/2128514342.py in <module>; 3 sc.pp.pca(mat_all); 4 sc.pp.neighbors(mat_all); ----> 5 sc.tl.umap(mat_all); 6 sc.pl.tsne(mat_all, color=""cluster"",legend_loc=""on data"",; 7 size=20, save=True). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 192 default_epochs = 500 if neighbors['connectivities'].shape[0] <= 10000 else 200; 193 n_epochs = default_epochs if maxiter is None else maxiter; --> 194 X_umap = simplicial_set_embedding(; 195 X,; 196 neighbors['connectivities'].tocoo(),. TypeError: simplicial_set_embedding() missing 3 required positional arguments: 'densmap', 'densmap_kwds', and 'output_dens'; ```. And the versions I've been running:; anndata 0.7.8; asttokens 2.0.5; bcrypt 3.2.0; Bottleneck 1.3.2; brotlipy 0.7.0; cached-property 1.5.2; certifi 2021.10.8; cffi 1.15.0; charset-normalizer 2.0.12; chart-studio 1.1.0; click 8.0.4; cmake 3.22.2; colorama 0.4.4; conda 4.11.0; conda-package-handling 1.7.3; cryptography 36.0.1; cycler 0.11.0; Cython 0.29.20; devtools 0.8.0; dunamai 1.9.0; executing 0.8.2; fa2 0.3.5; Fabric 1.6.1; fonttools 4.29.1; get_version 3.5.4; h5py 3.6.0; idna 3.3; igraph 0.9.9; install 1.3.5; joblib 1.1.0; kiwisolver 1.3.2; legacy-api-wrap 1.2; llvmlite 0.38.0; loom 0.0.18; loompy 3.0.6; mamba 0.15.3; matplotlib 3.5.1; mkl-fft 1.3.1; mkl-random 1.2.2; mkl-service 2.4.0; MulticoreTSNE 0.1; natsort 8.1.0; networkx 2.6.3; numba 0.55.1; numexpr 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1579#issuecomment-1062410460:100,error,error,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1579#issuecomment-1062410460,2,['error'],['error']
Availability,"Sorry for the late reply, the notifications for this thread got sent to my spam folder. @giovp . - I think so! It’s not difficult to extend it to more latent variables. We could allow them to specify any column(s) in the `obs` DataFrame.; - Hmm, I think `statsmodels` can do regression on lots of different models, but from the source paper it sounds like using Poisson was simplest/fastest and did not affect the results too much when compared to negative binomial regression. I think parameter estimation for other models might be a bit more involved.; - I think that would be pretty straightforward. What outputs are you referring to, specifically?; - I’ve been testing by computing correlations between the genes from the python and R implementations. You could also compare rank-ordering of cells by variance. Another approach might be to compare the output of downstream analysis methods (like clustering) to see if the results are similar, and compare to the output of unprocessed data as a negative control.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1643#issuecomment-786183077:866,down,downstream,866,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1643#issuecomment-786183077,1,['down'],['downstream']
Availability,Sorry for the late reply. The issue seems to only occur in Win10 but not Linux. No error on linux using the exact same codes.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696#issuecomment-814555908:83,error,error,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696#issuecomment-814555908,1,['error'],['error']
Availability,"Sorry for the super-late response! I just worked through almost 60 issues starting with the most recent, this is the last one... Sorry about that. `paga_path` requires computing a pseudotime before-hand as one needs to order cells at single-cell resolution along the path. I added a more meaningful error message stating that. PS: Now, there is also a test for PAGA [here](https://github.com/theislab/scanpy/blob/master/scanpy/tests/notebooks/test_paga_paul15_subsampled.py), making sure that the canonical use ([here](https://nbviewer.jupyter.org/github/theislab/paga/blob/master/blood/paul15/paul15.ipynb)) remains unchanged.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/328#issuecomment-435736335:299,error,error,299,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/328#issuecomment-435736335,1,['error'],['error']
Availability,"Sorry, I forgot about this. Not sure why the CI was falling. The only errors I get locally were due to problems with matching images.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2231#issuecomment-1139755842:70,error,errors,70,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2231#issuecomment-1139755842,1,['error'],['errors']
Availability,"Sorry, just realizing that this function expects logarithmized data. My fault.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/763#issuecomment-517851311:72,fault,fault,72,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763#issuecomment-517851311,1,['fault'],['fault']
Availability,"Sorry, this seems to be a UMAP issue. To really dig down to this, you'd probably run this using the UMAP package and submit a bug report there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/257#issuecomment-418822885:52,down,down,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/257#issuecomment-418822885,1,['down'],['down']
Availability,"Sort of separate but also, an error writing such data with `adata.write(""results.h5ad"")`. Traceback:; ```; TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'uns/rank_genes_groups_filtered/names' of <class 'h5py._hl.files.File'> from /.; ```. `del adata.uns[""rank_genes_groups_filtered""]` and the .write() call succeeds",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1651#issuecomment-779382361:30,error,error,30,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1651#issuecomment-779382361,2,['error'],['error']
Availability,"Sorta!. ![image](https://user-images.githubusercontent.com/8238804/108616034-ce7cd480-745d-11eb-93e4-996a912c5041.png). Not sure if it's not working because something is wrong with the configuration, because it doesn't work with PRs, or that it takes a bit for search results to be available. One downside of using this over algolia's search is that we get search analytics through algolia, while we'd have to upgrade our readthedocs subscription to have access to that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1672#issuecomment-782797773:282,avail,available,282,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1672#issuecomment-782797773,2,"['avail', 'down']","['available', 'downside']"
Availability,"Sounds good, we are currently hosting the whole scanpy-scripts as a bioconda package, but we could look into having it as pip installable as well. Does this means that scanpy administrators are happy to have the scanpy-scripts code poured here to make them pip installable, or that you want to contribute the pip packaging to the repo where we currently have scanpy-scripts? We have travis testing for our scripts layer, that would make maintenance easier on your side, as it would detect any changes on scanpy that break the scripts layers (taking you to only break API if extremely necessary - in turn making your tool more stable for external users).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/281#issuecomment-437031478:437,mainten,maintenance,437,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/281#issuecomment-437031478,1,['mainten'],['maintenance']
Availability,"Sounds great, @falexwolf! I did notice the slow-down and agree it's not great. That's a great suggestion, I'll take a look. Thanks, glad it helped!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-427484003:48,down,down,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-427484003,1,['down'],['down']
Availability,"Sounds like a great idea. generally the order should be the same as in the signature, but I don’t see a problem in reshuffling the lovain args to match the leiden ones. We have to be careful with details though: e.g. `partition_type` needs to be slightly different for both:. ```rst; Type of partition to use. Defaults to :class:`~louvain.RBConfigurationVertexPartition`.; For the available options, consult the documentation for :func:`~louvain.find_partition`.; ```; ```rst; Type of partition to use. Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`.; For the available options, consult the documentation for :func:`~leidenalg.find_partition`.; ```. @falexwolf do you think we should go ahead with https://pypi.org/project/legacy-api-wrap (and introduce `*` in `louvain`’s signature` or do you think we can slightly reshuffle the last few arguments of `louvain` without considering it a backwards compat break?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/570#issuecomment-477971741:381,avail,available,381,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/570#issuecomment-477971741,2,['avail'],['available']
Availability,"Starting from the end: I think if you could upload the clustering results from the Scanpy paper / PAGA preprint to the scanpy github repo, it would be great. I still have the dropbox link of course, but I guess in the long run it's better if that file was located here and linked from the https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells page. The issue with 1 cell missing was because I did not specify `header=None` when loading it with Pandas :) So my error, not yours. The file is correct as is. That said, I am worried about the influence the random seed in randomized PCA seems to give in this case. Let me show you how it looks:. ![mln-tsne-clustering-comparison](https://user-images.githubusercontent.com/8970231/47555195-71af9480-d90b-11e8-85fb-a3e8dcb7a66f.png). I would be fine with some cells getting into other clusters depending on the random seed, and it would even be okay if small clusters changed their identities, but what we see here is a very drastic change of the cluster structure. Are you sure that the only difference is the randomized PCA outcome? Can it be that some of the default parameters in `sc.pp.recipe_zheng17`, `sc.pp.neighbors`, or `sc.tl.louvain` changed since when you ran the clustering? The scanpy code I posted above is the full code I used, and I ran it yesterday after updating scanpy via pip. BTW, the visualization above is taken from https://www.biorxiv.org/content/early/2018/10/25/453449 which we posted yesterday. Any comments very welcome! I hope you don't mind being thanked in the acknowledgements!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/325#issuecomment-433334926:496,error,error,496,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/325#issuecomment-433334926,1,['error'],['error']
Availability,"Still happens in 2023. If I use `palette=sc.pl.palettes.zeileis_28` it works, but when I use `palette='Set2'` I got the same error",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1438#issuecomment-1626976895:125,error,error,125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438#issuecomment-1626976895,1,['error'],['error']
Availability,Still have to use scipy 1.4.1 or 1.4.2. There's now 1.6.1 but this also results in the same error...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1407#issuecomment-795204132:92,error,error,92,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1407#issuecomment-795204132,1,['error'],['error']
Availability,"Still occurring, though it's a really weird case. Here's some code to reproduce:. ```python; a = sc.AnnData(np.ones((100, 100))); sc.pp.pca(a); # RuntimeWarning: invalid value encountered in true_divide; # self.explained_variance_ / total_var.sum(); sc.pl.pca(a) # Throws the same error as above; a.uns[""pca""]; ```. ```; {'params': {'zero_center': True, 'use_highly_variable': False},; 'variance': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,; 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,; 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],; dtype=float32),; 'variance_ratio': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,; nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,; nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,; nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],; dtype=float32)}; ```. Though I do get the same behaviour with `svd_solver=""randomized""`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/264#issuecomment-766319589:281,error,error,281,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/264#issuecomment-766319589,1,['error'],['error']
Availability,"Still the error message could be a lot better. I’ve made the same mistake,; it’s easy to forget to log the data. On Fri 2 Aug 2019 at 23:36, Stephen Fleming <notifications@github.com>; wrote:. > Closed #763 <https://github.com/theislab/scanpy/issues/763>.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/763?email_source=notifications&email_token=AACL4TL6QHUQMHIBKEQT5GLQCSSFFA5CNFSM4IJBAFAKYY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOS3M3XBA#event-2530851716>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AACL4TM5VZDC544TAQPK7NDQCSSFFANCNFSM4IJBAFAA>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/763#issuecomment-517929825:10,error,error,10,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763#issuecomment-517929825,1,['error'],['error']
Availability,"Sure, I can do this. I'll submit a PR in a bit. @bfurtwa could you post the full stack trace for this error to help me find the problem please? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1277#issuecomment-701591572:102,error,error,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277#issuecomment-701591572,1,['error'],['error']
Availability,"Sure, I’ll happily elaborate!. As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py; def test_score_genes():; adata = TODO # create test data here; gene_list = TODO; gene_pool = TODO; gene_list, gene_pool, get_subset = _check_score_genes_args(; adata, gene_list, gene_pool, use_raw=use_raw, layer=layer; ). bins = list(_score_genes_bins(; gene_list,; gene_pool,; ctrl_as_ref=False, # needs to be renamed; ctrl_size=50,; n_bins=25,; get_subset=get_subset,; )). assert 0 not in map(len, bins); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3167#issuecomment-2264758331:882,degraded,degraded,882,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167#issuecomment-2264758331,1,['degraded'],['degraded']
Availability,"Sure, this works as a workaround. Thing is, if I call doublets like described in the scrublet README, I do not get an error:; This works:; ```python; import scrublet as scr; import scanpy as sc; adata = sc.datasets.paul15(). scrub = scr.Scrublet(X); doublet_scores, predicted_doublets = scrub.scrub_doublets(); ```; So is this upstream?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1645#issuecomment-778326318:118,error,error,118,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1645#issuecomment-778326318,1,['error'],['error']
Availability,"Sure:. ```; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-161-7b672fc51046> in <module>; ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False). ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs); 724 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 725 """"""; --> 726 return embedding(adata, 'pca', **kwargs); 727 ; 728 . ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 226 itertools.product(color, idx_components); 227 ):; --> 228 color_vector, categorical = _get_color_values(; 229 adata,; 230 value_to_plot,. ~/miniconda3/envs/sc/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer); 1031 ):; 1032 # We should probably just make an index for this, and share it over runs; -> 1033 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][; 1034 0; 1035 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key); 4095 if is_scalar(key):; 4096 key = com.cast_scalar_indexer(key, warn_float=True); -> 4097 return getitem(key); 4098 ; 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1277#issuecomment-703164973:1649,error,error,1649,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277#issuecomment-703164973,1,['error'],['error']
Availability,"TCTCATN', 'AATCTATCACAN', 'CTCCCTTTTGCN', 'TTTGACACCGCC',; 'CGCGCCTTGTCA', 'AACCTTTGATGG',; ...; 'TATCTGTAATCA', 'ATGGGTGAACAG', 'TCCGATAGTGGA', 'TTGTCAATCTCT',; 'CGGTGGCTGAGT', 'TCCATATCAGGG', 'TGGCGTTAGTAT', 'TTCTTCTGGTTT',; 'ACTATGGCTGGT', 'CGTGAACCCTGT'],; dtype='object', length=1500); >>> print(all((adata00a.var_names == day_x.var_names).all() for day_x in adata_list)); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<stdin>"", line 1, in <genexpr>; NameError: name 'adata00a' is not defined; >>> print(adata.var_names, adata); Index(['GTGCCATATTCN', 'TCGCAGCCTGCT', 'CTGTAGCCCCCA', 'TGTATGTTGCTT',; 'CAGTATCTCATN', 'AATCTATCACAN', 'CTCCCTTTTGCN', 'TTTGACACCGCC',; 'CGCGCCTTGTCA', 'AACCTTTGATGG',; ...; 'GCCCAGGTGCCA', 'GACGAAACCATG', 'CCCGCCCAAGTT', 'GTGCGTTAAGTG',; 'TCCTACCTGTAC', 'CACACTGATGAT', 'CAGCATACTCCN', 'AGAAACCTTGGG',; 'GACATAAATCAG', 'AGGGGTGACGAC'],; dtype='object', length=3971) AnnData object with n_obs × n_vars = 119446 × 3971 ; obs: 'batch', 'tech'; ```; The `adata00a` threw some errors as it hadn't been defined yet, and I wan't totally sure what you were trying to reference there, but I tried with both just `adata` and `day00a` and it still threw errors (not defined and ValueError respectively). Assuming that you just wanted the var_names for each day I just ran them separately and also got the cell barcodes:. ```; >>> print(day01.var_names); Index(['CCGTCATCTTCT', 'GATTCGATTTCC', 'TTTTGGCCGTTA', 'TGAGTTTTTATN',; 'CCGTCTCTACTN', 'ATAAGTTGCTTG', 'CCGTCGCAAGGT', 'ACACCTTGGAAA',; 'AGCCCGCCCAGN', 'GAAAATCGATCN',; ...; 'AACCCGCCCAGN', 'CCCATCGACTGA', 'GCGGAAGGCGCT', 'TACTTGGTTTGC',; 'GTCTTGGTTACC', 'CTCGCGGCCGTT', 'CCCAAATTTCGT', 'CCGGAGGTTTAG',; 'CTAAACGGCTGT', 'GAAATGAGGATG'],; dtype='object', length=500); >>> print(day02.var_names); Index(['AACCATCAGCGG', 'GTCCCACTACAT', 'CCCTTTCCGAGN', 'AGGGCACTTTGG',; 'CCTGAGAAGCGT', 'GGGGCTGTTGGG', 'ACTGACTTACCC', 'CAAGACTACTAT',; 'GCATTATGTCCC', 'TTCGGTGTCATG',; ...; 'AGCAGCGTTATA', 'A",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/914#issuecomment-553986902:1254,error,errors,1254,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/914#issuecomment-553986902,2,['error'],['errors']
Availability,"Tbh, I found out about `groups` after writing the function and looking for a way to put the dots in front. Maybe there is a simpler way to do this... But then the command you suggest gives an error on my own data if I don't also specify `color='bulk_labels'` (works for the pbmc68k, but doesn't colour anything in), and then it just puts all the labels on the same plot and doesn't create small multiples.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/955#issuecomment-566487331:192,error,error,192,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/955#issuecomment-566487331,1,['error'],['error']
Availability,"Test failures are not mine, seems like numba breaks on python 3.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-777364572:5,failure,failures,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-777364572,1,['failure'],['failures']
Availability,"Tested scvelo's vs scanpy's `pl.scatter` (will share test modules + notebooks later). scvelo entails scanpy's functionality (and adds a couple extensions as explained above), except for the following:; - we don't have `left_margin` and `right_margin` attributes (don't think they're necessary).; - point `size` convention acc. to scanpy (if settings._rcParams_style == 'scanpy') else slightly adjusted.; - when `basis` is in `.var_names`, then an unspliced/spliced phase portrait is plotted (I guess that's not needed in scanpy?). Further we have some more defaults:; - if `basis` is None, then use a default basis in the given order if available: umap, tsne, pca; - if `color` is None, then use a default color in the given order if available: clusters, louvain; - if `frameon` is None, then only set frame if it is not embedding and axes values do matter.; - if `color_map` is None, then use 'viridis_r' if vals in [0,1], else matplotlib's default. Further, these can be used interchangeably: `size` and `s`, `color` and `c`, `color_map` and `cmap`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/617#issuecomment-554758886:637,avail,available,637,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/617#issuecomment-554758886,2,['avail'],['available']
Availability,"Thank you @stuartarchibald, it sure is! The error happens when numba tries to JIT-compile `top_segment_proportions_sparse_csr`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1341#issuecomment-668005293:44,error,error,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1341#issuecomment-668005293,1,['error'],['error']
Availability,"Thank you for all your thoughts! That's very interesting and helpful!. > although it would also make sense for log1p to be a class method, given that it only needs to exist for AnnData objects. Yes! I also think so. But then the question is which function makes into AnnData and which doesn't. Right now we only put functionality that is related to bookkeeping of the data into AnnData. Everything else remains out of it, even it's something as simple as `log1p`... but that's just a safeguard towards cluttering the object... I agree that it would be more convenient to have some of this in `AnnData`. I guess numpy went a similar way: not all of numpy's functions are available as `np.ndarray`'s class methods. > In such a library it's easy to switch between an in-place or copying workflow, to inspect intermediate output if desired. Interesting! I never thought of this. > This behavior is what numpy.log1p itself is doing here, for that matter–with an out argument it still returns the array. Yes! I think that's a good solution. The `out` argument is very verbose and allows setting a second name for the reference to the modified object, which is returned in addition. I thought about making `inplace` the default for Scanpy's function or not for a long time and finally decided for the unorthodox choice of making it the default - having in mind that AnnData's will become pretty large and at some point backed on disk (which hugely limits the possibilities of how you can write pipelines). Then the `out` rationale doesn't work anymore, as, by default, there simply is no second reference around... Again, thank you for your perspective. And, I'll merge this as soon as having figured out the `chunked` issue. Should be tomorrow or so...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/191#issuecomment-403313076:670,avail,available,670,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191#issuecomment-403313076,1,['avail'],['available']
Availability,"Thank you for the detailed response @mrocklin!. > It would be great to get a slimmed down version of the operations that you're running with pydata/sparse and submit those to the issue tracker there. I will try to produce a test case and post it there. > Another option would be to see if you can swap out Anndata for Xarray. This has been discussed before (https://github.com/theislab/anndata/issues/32) but the sticking point was sparse support.; Perhaps with some of the techniques being discussed in this issue it might become an option again, with all the benefits you outlined. > I could imagine that these might be in scope for NVidia folks to work on in a few months (no promises though). If you wanted to raise these as issues there to track things that would be helpful. Thanks - I've opened issues for these features on the CuPy issue tracker.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/921#issuecomment-557463310:85,down,down,85,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/921#issuecomment-557463310,1,['down'],['down']
Availability,"Thank you for these thoughts!. I guess the high documentation quality in R stems from the Bioconductor project, which really set some standards. Nothing like this exists in Python - everyone just does what he or she wants. There are few people thinking about setting up something similar to Bioconductor for Python - but this will likely take some time... With Scanpy, we try to provide documentation at the Standards of the big packages: numpy, scipy, statsmodels, seaborn, scikit-learn, h5py, pytables, etc. There are many more and all of them have great docs. I think, with Scanpy, one can still do a lot better. Tuturials tend to be too short. Also, there should be a properly rendered html output of the notebooks - with a button where you can simply download it and then run it yourself to start playing around with it. Hope we will have this in a couple of weeks. And yes, other packages maybe just need to take time. But I'd guess that this will get much better soon...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/74#issuecomment-364055498:756,down,download,756,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74#issuecomment-364055498,1,['down'],['download']
Availability,"Thank you for your thoughts!. 1. `normalize_per_cell` needs to remove zero-expression cells as these can't be normalized, the alternative would be to require it as a preprocessing step; but you're right, wflynny, I'll frame it as a fall-back for `normalize_per_cell` in the next version and output a warning... which will make things backwards compatible...; 2. Any filtering operation on the cells/observations should also affect `.raw`. I'll look into this today. ; 3. Any filtering operation on the variables should **not** affect `.raw`. I didn't know that this gives problems in `rank_genes_groups`? Of course, you don't find everything in `.X` that you find in `.raw.X` and you'll get a key error if you try to; but is there a fundamental problem, @LuckyMD?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/210#issuecomment-407038976:697,error,error,697,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/210#issuecomment-407038976,1,['error'],['error']
Availability,"Thank you so much for the feedback!; I'll definitely talk to the admin, but I am not sure he would update. Considering conda, I've tried using ; conda create -n scanpy python=3.6 scanpy; conda activate scanpy. It creates the environment, but then apparently I need to run a jupyter notebook from the terminal for the environment to be activated. When trying to do it, I am getting a ""Jupyter Notebook requires JavaScript"" error, and I can't figure out how to solve it while connecting through ssh, because running ""jupyter notebook --no-browser"" generates a token I can use only on the local machine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/561#issuecomment-477340341:422,error,error,422,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-477340341,1,['error'],['error']
Availability,"Thank you so much for the reply.; Error posted above is happening in two independent datasets possibly due to confounding factors as you mentioned. Though I don't quite comprehend what is a confounding factor in my specific case. . Here is the output of the batches and covariates as requested. ```python; pd.crosstab(adata.obs[""384plate""], adata.obs[""age_group""]); ```. ```pytb; age_group Old YoungAdult Pediatric Fetal NewBorn; 384plate ; 27YOMP1 0 368 0 0 0; 27YOMP2 0 383 0 0 0; 27YOMP3 0 184 0 0 0; BM01152P1 0 384 0 0 0; BM01152P2 0 384 0 0 0; BM01158P1 0 0 382 0 0; BM01158P2 0 0 384 0 0; BM8182P1 0 55 0 0 0; FBFLP5L2 0 0 0 382 0; FBML1 0 0 0 378 0; FBML2 0 0 0 322 0; FBP5L1 0 0 0 377 0; FLP5L1 0 0 0 381 0; FLP5L3 0 0 0 338 0; FLP6L1 0 0 0 376 0; FLP6L2 0 0 0 383 0; FLP6L3 0 0 0 53 0; UCB250P1 0 0 0 0 382; UCB250P2 0 0 0 0 384; UCB250P3 0 0 0 0 150; UCB259P1 0 0 0 0 373; UCB259P2 0 0 0 0 376; UCB270P1 0 0 0 0 382; UCB270P2 0 0 0 0 128; UCBBMP4 0 41 272 0 63; UCBBMP5 0 0 0 0 325; hHSCP1B1 379 0 0 0 0; hHSCP1B2 359 0 0 0 0; hHSCP1B3 377 0 0 0 0; hHSCP2B1 376 0 0 0 0; hHSCP2B2 350 0 0 0 0; hHSCP3B1 371 0 0 0 0; hHSCP3B2 340 0 0 0 0; hHSCP4B1 290 0 0 0 0; ```. ```python; pd.crosstab(adata.obs[""384plate""], adata.obs[""sex""]); ```. ```pytb; sex F M U; 384plate ; 27YOMP1 0 368 0; 27YOMP2 0 383 0; 27YOMP3 0 184 0; BM01152P1 0 384 0; BM01152P2 0 384 0; BM01158P1 0 382 0; BM01158P2 0 384 0; BM8182P1 0 55 0; FBFLP5L2 0 55 327; FBML1 0 0 378; FBML2 0 0 322; FBP5L1 0 0 377; FLP5L1 0 0 381; FLP5L3 0 338 0; FLP6L1 0 376 0; FLP6L2 0 71 312; FLP6L3 0 0 53; UCB250P1 0 382 0; UCB250P2 0 384 0; UCB250P3 0 150 0; UCB259P1 0 373 0; UCB259P2 0 376 0; UCB270P1 0 382 0; UCB270P2 0 128 0; UCBBMP4 0 376 0; UCBBMP5 0 325 0; hHSCP1B1 0 379 0; hHSCP1B2 173 186 0; hHSCP1B3 216 161 0; hHSCP2B1 0 376 0; hHSCP2B2 350 0 0; hHSCP3B1 0 371 0; hHSCP3B2 158 182 0; hHSCP4B1 0 290 0; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1606#issuecomment-766498505:34,Error,Error,34,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1606#issuecomment-766498505,1,['Error'],['Error']
Availability,"Thank you so much for your explanation, I've tried your code, it's not working yet, I think I should go through my previous code, I'm sure something is wrong. But I understand what you said, I'll try to figure out the errors. ; Thanks again!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1035#issuecomment-584256959:218,error,errors,218,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1035#issuecomment-584256959,1,['error'],['errors']
Availability,"Thank you very much ,I've resolved the error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2982#issuecomment-2044414191:39,error,error,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2982#issuecomment-2044414191,1,['error'],['error']
Availability,"Thank you very much. I could remove the graph slot and this error is gone, but now I have a new error: . ```; ---------------------------------------------------------------------------; Exception Traceback (most recent call last); <ipython-input-2-aae861244dfa> in <module>; ----> 1 adata = sc.read_loom('dataset.loom'). /opt/conda/lib/python3.7/site-packages/anndata/readwrite/read.py in read_loom(filename, sparse, cleanup, X_name, obs_names, var_names, dtype, **kwargs); 184 var=var,; 185 layers=layers,; --> 186 dtype=dtype); 187 return adata; 188 . /opt/conda/lib/python3.7/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 670 layers=layers,; 671 dtype=dtype, shape=shape,; --> 672 filename=filename, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. /opt/conda/lib/python3.7/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . /opt/conda/lib/python3.7/site-packages/anndata/base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. /opt/conda/lib/python3.7/site-packages/pandas/core/frame.py in __init__(self, data, index, columns, dtype, copy); 390 dtype=dtype, copy=copy); 391 elif isinstance(data, dict):; --> 392 mgr = init_dict(data, index, columns, dtype=dtype); 393 elif isinstance(data, ma.MaskedArray):; 394 import numpy.ma.mrecords as mrecords. /opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py in init_dict(data, index, columns, dtype); 210 arrays = [data[k] for k in keys]; 211",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/598#issuecomment-487609885:60,error,error,60,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487609885,2,['error'],['error']
Availability,Thank you! IDK how I missed that it’s used further down.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/789#issuecomment-522966587:51,down,down,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/789#issuecomment-522966587,1,['down'],['down']
Availability,Thank you! If you add a few more details we can fix this quickly: Which call will update the groups but not the color and which call will error out with which stack trace? Please add the the traceback to your comment this:. ````md; ```python; sc.tl.something(adata); ```. ```pytb; XError Traceback (most recent call last); ....; XError: some message.; ```; ````,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/833#issuecomment-531482480:138,error,error,138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833#issuecomment-531482480,1,['error'],['error']
Availability,"Thank you! I’d prefer a nicer, more explicit error that describes the problem. You could use sth like:. ```py; if not is_categorical_dtype(adata.obs[groupby].dtype):; raise ValueError(; f""The column `adata.obs[groupby]` needs to be categorical, ""; f""but the {groupby!r} column is of dtype {adata.obs[groupby].dtype}.""; ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1029#issuecomment-584665061:45,error,error,45,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1029#issuecomment-584665061,1,['error'],['error']
Availability,"Thank you! So you say it doesn’t work, but I see a green checkmark. Would you mind adding a test that exposes the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-364153382:114,error,error,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-364153382,1,['error'],['error']
Availability,"Thank you~ Firstly, it's an AssertionError in sc.pp.normalize_per_cell step ; secondly , toy example csv data is presented as below:. ```; Group,Group1,Group1,Group3,Group6,Group5; Gene1,11,0,0,14,0; Gene2,12,17,9,34,11; Gene3,0,0,0,0,2; ```. so, u can test this error locally by:. ```python; df = pd.read_csv('data/dropout/dropout1/counts.csv', index_col=0); genes = df.index.values; barcodes = df.columns; adata = sc.AnnData(np.transpose(df.values), var=pd.DataFrame(genes), obs=pd.DataFrame(barcodes)); adata.var_names_make_unique(); sc.pp.filter_genes(adata, min_cells=1); adata.raw = adata; sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4); ```; lastly, the version is 1.4.3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/727#issuecomment-508621001:263,error,error,263,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/727#issuecomment-508621001,1,['error'],['error']
Availability,"Thanks @flying-sheep for the thorough feedback! I made the changes. There is still a Travis CI error about slow_to_import modules. Since trimap is now in external, I am now sure how this test is being affected.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/862#issuecomment-561830094:95,error,error,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/862#issuecomment-561830094,1,['error'],['error']
Availability,"Thanks @giovp for your quick reply! I upgraded pandas and ran your code with the pbmc dataset. This ran fine. On my own dataset it is still giving the same error. So maybe something is wrong with the way I created adata. Because my code ran fine before upgrading scanpy and I found this issue: https://github.com/theislab/single-cell-tutorial/issues/28#issue-576248363 I thought it might be a real bug. ; After running your example I will just look into how I created adata to see if I can find the error. ; This is what it looks like now: ; ```; AnnData object with n_obs × n_vars = 2773 × 3783 ; obs: 'n_genes', 'plate', 'platebatch', 'stage', 'well_no', 'ERCC_genes', 'n_total_counts', 'percent_mito', 'n_counts', 'percent_ribo', 'percent_protein_coding', 'percent_lincRNA', 'sum_lincRNA', 'percent_antisense', 'sum_antisense', 'percent_miRNA', 'sum_miRNA', 'percent_bidirectional_promoter_lncRNA', 'sum_bidirectional_promoter_lncRNA', 'percent_snoRNA', 'n_counts_norm', 'Chat_norm_expr', 'cellnr', 'louvain', 'velocity_self_transition', 'lineages', 'root_cells', 'end_points', 'velocity_pseudotime'; var: 'ENS_names', 'geneid', 'feature', 'chr', 'fullname', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'velocity_gamma', 'velocity_r2', 'velocity_genes'; uns: 'louvain', 'louvain_colors', 'neighbors', 'pca', 'plate_colors', 'stage_colors', 'umap', 'velocity_graph', 'velocity_graph_neg', 'velocity_settings', 'rank_genes_groups'; obsm: 'X_pca', 'X_tsne', 'X_umap', 'velocity_tsne', 'velocity_umap'; varm: 'PCs'; layers: 'Ms', 'Mu', 'spliced', 'unspliced', 'variance_velocity', 'velocity'; ```. The adata.X of the pbmc data is `scipy.sparse.csr.csr_matrix`; My adata.X is `numpy.ndarray`. This probably results in the problem of the difference in dimensions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1114#issuecomment-601076097:156,error,error,156,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114#issuecomment-601076097,2,['error'],['error']
Availability,"Thanks @ivirshup ! In addition to changing the documentation, it would probably make sense to throw an error if these two arguments are passed together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2136#issuecomment-1051175372:103,error,error,103,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2136#issuecomment-1051175372,1,['error'],['error']
Availability,"Thanks @ivirshup that worked nicely, I should have thought of it. I'll remove our h5py pin once anndata 0.7.5 is available on Conda (have you seen that it's failing right now? https://github.com/conda-forge/anndata-feedstock/pull/13)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1490#issuecomment-726165481:113,avail,available,113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490#issuecomment-726165481,1,['avail'],['available']
Availability,"Thanks Alex! That's great, thanks also for adding me to the authors list. I haven't seen that patsy error on my Ubuntu machine either.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/398#issuecomment-451888324:100,error,error,100,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/398#issuecomment-451888324,1,['error'],['error']
Availability,"Thanks a lot for the useful comments & I am a great admirer of scanpy, @falexwolf . I am trying to cluster cells based on specific gene sets (same as @biskra). I am working with loom files & after the data preprocessing and finding out highly variable genes, I have subgrouped the HVG(s) into five different categories by functional annotation/pathway enrichment analysis. Then I tried to subset 'adata' to the gene group I am interested in to carry out the embedding & clustering:. adata = adata[:, adata.var['highly_variable']]. #From the highly variable genes, let's say I want to use Gene1, Gene2,... Gene500 for the Louvain clustering instead of the PCA. Then, I tried to do what you suggested before:. #I have nothing stored under adata.obsm; adata.var['highly_variable'] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. I am getting this error despite the fact that these genes are in the HVG list: ; #KeyError: ""None of [Index(['Map7d1', 'Ndufa2', 'Klc2', 'Slc35b2'], dtype='object')] are in the [index]"". If this works, then the community graph can be computed:; sc.pp.neighbors(adata, use_rep='highly_variable'). I shall be grateful if you can help.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/510#issuecomment-487964976:845,error,error,845,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510#issuecomment-487964976,1,['error'],['error']
Availability,"Thanks a lot. ---Original---; From: ""James ***@***.***&gt;; Date: Thu, Sep 29, 2022 00:06 AM; To: ***@***.***&gt;;; Cc: ""Sijian ***@***.******@***.***&gt;;; Subject: Re: [scverse/scanpy] sc.tl.leiden(adata,use_weights=False) (Issue#2339). ; I also saw this with python-igraph version 0.10. Downgrading to 0.9.9 fixed the issue.; ; —; Reply to this email directly, view it on GitHub, or unsubscribe.; You are receiving this because you authored the thread.Message ID: ***@***.***&gt;",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2339#issuecomment-1261162964:290,Down,Downgrading,290,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339#issuecomment-1261162964,1,['Down'],['Downgrading']
Availability,"Thanks both, just to clarify, I am using the `min_in_group_fraction` and `max_out_group_fraction` args for `sc.tl.rank_genes_groups_filtered()`, which are not available as custom cutoff args for `sc.queries.enrich()` (otherwise I agree entirely)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1043#issuecomment-586153305:159,avail,available,159,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043#issuecomment-586153305,1,['avail'],['available']
Availability,Thanks but the error persists even after using `adata.obs_names_make_unique()`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763966212:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763966212,1,['error'],['error']
Availability,"Thanks everyone! I wonder how this affects one-pipeline-for-everything; portals, like the EBI single cell expression atlas... and standarized; pipelines like cellranger. On Mon, Jul 1, 2019 at 3:29 PM MalteDLuecken <notifications@github.com>; wrote:. > Based on my experience setting a single cutoff for all datasets will not; > work, as I've used a lot of different cutoffs depending on the; > distributions. I would echo @ivirshup <https://github.com/ivirshup>'s; > suggestion of looking at distributions. Joint distributions being a lot; > more important than individual histograms. There's a small discussion about; > it in our best practices paper; > <https://www.embopress.org/lookup/doi/10.15252/msb.20188746>; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/718?email_source=notifications&email_token=AACL4TMTNHMCCFM7MGMIZ73P5IBDPA5CNFSM4H4DUZEKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODY6D6LQ#issuecomment-507264814>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AACL4TKKTTZ4IHBJJDFAPKLP5IBDPANCNFSM4H4DUZEA>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/718#issuecomment-507267593:418,echo,echo,418,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/718#issuecomment-507267593,1,['echo'],['echo']
Availability,"Thanks for a quick response and the comments. > The main change here is passing None instead of 0 to total, right?. It was actually setting it in the contructor, rather than assigning it to the tqdm object (the latter doesn't work). Here's before:; ![old](https://user-images.githubusercontent.com/46717574/100207740-3b88d880-2f08-11eb-882f-cae14be0837e.png); and after:; ![new](https://user-images.githubusercontent.com/46717574/100207756-3fb4f600-2f08-11eb-85f8-5938ff04572d.png). > Also: this makes some errors with files still existing make much more sense. I had no idea KeyboardInterrupt doesn't inherit from Exception. I didn't know that either, so I looked it up (it actually inherits from `BaseException` among other things:; https://docs.python.org/3/library/exceptions.html#exception-hierarchy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1507#issuecomment-733582404:507,error,errors,507,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507#issuecomment-733582404,1,['error'],['errors']
Availability,"Thanks for getting back to me. I fixed the formatting errors and moved trimap to scanpy external. ; trimap is no longer imported by default, so the overall import time is unaffected. ; I also added an example to the docstring. Please let me know if further fixes are required.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/862#issuecomment-541174606:54,error,errors,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/862#issuecomment-541174606,1,['error'],['errors']
Availability,"Thanks for getting back. I ran the reproducer on my system and it indeed works perfectly. Very weird. . When I ran the reproducer, I did get one warning:; ```; WARNING: The candidate selected for download or install is a yanked version: 'scipy' candidate (version 1.11.0 at https://files.pythonhosted.org/packages/2f/b5/b5387cdafc66805907424c3a95f773b84a5d452a0925801c6218727a766e/scipy-1.11.0-cp311-cp311-macosx_10_9_x86_64.whl (from https://pypi.org/simple/scipy/) (requires-python:<3.13,>=3.9)); Reason for being yanked: License Violation; ```; Other than that, it worked fine. I have a feeling it might be an issue with the installation? That scipy warning is suspicious? I'm using mamba (mambaforge specifically) to manage my packages, maybe something went wrong there. Have you hear of any issues with mamba? Let me trouble shoot my environment and I'll report back. . Yes, I am running macOS, but it's not the Apple Silicon, I'm still using the older Intel processors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2531#issuecomment-1619051615:196,down,download,196,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531#issuecomment-1619051615,1,['down'],['download']
Availability,"Thanks for letting me know!. If it's working in the newest version, there's not much for us to fix. Please let us know if you run into the error on the latest release!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2046#issuecomment-963465126:139,error,error,139,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2046#issuecomment-963465126,1,['error'],['error']
Availability,"Thanks for opening a new issue for this, and the info. Could you let me know a bit more about how you've installed scanpy? E.g. what OS, did you use conda or pip, etc. My guess would be that this is numba related (which, from reporting the cpu flags, I'm guessing you suspect too). Are you able to import `numba`? If so, what about `pynndescent` and `umap`? I'm trying to figure out if some code in scanpy is triggering the error, or if it's one of our dependencies. ---------------. Initially mentioned in https://github.com/theislab/scanpy/issues/1823#issuecomment-983551937",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2062#issuecomment-983814860:424,error,error,424,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2062#issuecomment-983814860,1,['error'],['error']
Availability,"Thanks for opening an issue!. Many of the function in scanpy do not support being applied on a backed anndata. `highly_variable_genes` hasn't had support for out of core computation implemented, so it errors. Better out of core support is something we're working for. Is it possible to load `X` into memory here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2147#issuecomment-1049155583:201,error,errors,201,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147#issuecomment-1049155583,1,['error'],['errors']
Availability,"Thanks for opening the issue. Can you provide a full traceback with any warnings?. I can replicate this when passing count data, but the issue there seems to have to do with us assuming we're getting log transformed data. I do not see this error when I pass log normalized data. E.g. this works:. ```python; import scanpy as sc; a = sc.read_h5ad(""/Users/isaac/Downloads/GSE158055_covid19.h5ad""); sc.pp.log1p(a); sc.pp.highly_variable_genes(a, n_top_genes=3000, flavor=""seurat""); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2193#issuecomment-1081867209:240,error,error,240,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193#issuecomment-1081867209,2,"['Down', 'error']","['Downloads', 'error']"
Availability,"Thanks for pointing out the error in the documentation. This only affects the scatter plots. I observed that most people I interact with prefer the scatter plots without the frames. But we can change this back if it worries you. No problem. You have become the plotting expert for Scanpy, I'd say; so your opinion obviously counts a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/229#issuecomment-411656016:28,error,error,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/229#issuecomment-411656016,1,['error'],['error']
Availability,"Thanks for reporting @dawe and thanks for updating @WeilerP .; I ran into the same problem with the pip version.; When using **python 3.9** in a fresh virtual enviroment, there's an error related to llvmlite:; <details>; <summary>; error message; </summary>. ```; Building wheel for llvmlite (setup.py) ... error; ERROR: Command errored out with exit status 1:; command: /home/mischko/test/python_virtual/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/setup.py'""'""'; __file__='""'""'/tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/setup.py'""'""';f = getattr(tokenize, '""'""'open'""'""', open)(__file__) if os.path.exists(__file__) else io.StringIO('""'""'from setuptools import setup; setup()'""'""');code = f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-rb92hbao; cwd: /tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/; Complete output (15 lines):; running bdist_wheel; /home/mischko/test/python_virtual/bin/python /tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/ffi/build.py; LLVM version... 11.1.0; ; Traceback (most recent call last):; File ""/tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/ffi/build.py"", line 191, in <module>; main(); File ""/tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/ffi/build.py"", line 181, in main; main_posix('linux', '.so'); File ""/tmp/pip-install-u4ja11ve/llvmlite_860b580657d846f1993072c1a58436b0/ffi/build.py"", line 143, in main_posix; raise RuntimeError(msg); RuntimeError: Building llvmlite requires LLVM 10.0.x or 9.0.x, got '11.1.0'. Be sure to set LLVM_CONFIG to the right executable path.; Read the documentation at http://llvmlite.pydata.org/ for more information about building llvmlite.; ; error: command '/home/mischko/test/python_virtual/bin/python' failed with exit code 1; ; ERR",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1799#issuecomment-830137752:182,error,error,182,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799#issuecomment-830137752,5,"['ERROR', 'error']","['ERROR', 'error', 'errored']"
Availability,"Thanks for the H/T @ivirshup ! I was able to find the library ids and I also added the metadata as suggested. This should do for now. I have also changed the plotting function to make it work with the new `uns` structure. The idea for uns concatenation is exactly that one yes. Basically, if the keys are unique, then concatenate, if they are the same, override and throw a warning. With respect to mixed anndata objects (e.g. one visium adata concatenated with one scRNA-seq), I will just concatenate the obsm and add empty entries to the one missing (like zeros) or something along the lines of masked arrays (although I don't think it's particularly useful in this case).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1105#issuecomment-599627259:597,mask,masked,597,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105#issuecomment-599627259,1,['mask'],['masked']
Availability,"Thanks for the PR. . One concern that I have is that similar solutions do not exists for other plotting functions. For coherence, ideally the `annot_col` argument should be available for other cases. Thus, I think that a better and more generic approach would be to simply modify your genes names in the `AnnData` object and let all plotting functions use those names. For this, you simply do:. ```PYTHON; adata.var = adata.var.reset_index().set_index(annot_col); # adata.var_names is automatically updated; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/376#issuecomment-441017256:173,avail,available,173,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/376#issuecomment-441017256,1,['avail'],['available']
Availability,"Thanks for the bug report! I think we've just fixed the first and third issue in #729, but I'm not to sure about the second. Could you try updating to the newest release of AnnData and letting us know if the error still occurs?. Would you mind also letting us know if this error occurs when you use one of the built in datasets, like `sc.datasets.pbmc3k()`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/731#issuecomment-509464033:208,error,error,208,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/731#issuecomment-509464033,2,['error'],['error']
Availability,Thanks for the contribution. This is great. I tried hash solo. This tool should be external as the maintenance and code falls outside the core development. The documentation should also point to the main developer of the functionality and give the due credits.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1432#issuecomment-699862845:99,mainten,maintenance,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432#issuecomment-699862845,1,['mainten'],['maintenance']
Availability,"Thanks for the docker image. I'll take a look at that when I can. I thought I had pinpointed the error via print statements in the tests and fixed it, but it's back now and when I put print statements the error is gone :/. Might try to experiment with Travis a bit by just pushing to #583. I don't know much about Travis, so not sure how cache comes into play here... or how Travis builds work. I guess it'll be a bit of reading later. Haven't tried forking to check what happens... good idea.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/580#issuecomment-478996906:97,error,error,97,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/580#issuecomment-478996906,2,['error'],['error']
Availability,"Thanks for the explanation. But what do you mean by ""discrete"" here?. And so you're saying 1, 5, and 7 being given as solutions to ICA is non-optimal. I guess that's just local optima that are found. It feels strange to generally say that ICA is better as higher dimensions still separate out clusters, while at lower dimensions there is redundant information compared to PCA.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/941#issuecomment-560100063:338,redundant,redundant,338,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/941#issuecomment-560100063,1,['redundant'],['redundant']
Availability,"Thanks for the explanations @ivirshup! This makes quite a bit more sense to me now (the block sparse matrix stuff). If I understand the `.raw` removal alternative correctly, then you would want to add masks to every operation in scanpy that is not DE and work with `.layers`? I assume that e.g., MT or ribo genes are mainly removed for cellular representation analysis. Some people will also want to remove them from DE analysis to have a set of results that are easy to interpret and have less multiple testing burden. It seems to me that adding masking like this would be quite a large endeavour, no?. > What if a highly variable gene in one dataset just isn't present in another? Is it because it wasn't found in that dataset at all, or because it was only present in a few cells? If it was only present in a few cells, how can I be sure a particular cell type wasn't just poorly represented in that dataset?. I don't see this as such a big issue. If you assume anything filtered out was removed because it was predominantly 0, then it would not have been included in the HVG set of that dataset anyway. So you can assume it would not be in the HVG intersection for that dataset and if you add it, then a 0 for each cell would probably not be that problematic. And whether this was due to a particular cell type being poorly represented can be answered by the gene set that you do have for these cells. Typically there is sufficient gene-gene covariance that you still keep this signal somehow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-822616661:201,mask,masks,201,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-822616661,2,['mask'],"['masking', 'masks']"
Availability,"Thanks for the feedback and sorry for the delay. The code snippet using `sklearn.decomposition.FastICA` gave me quite similar results to PCA for my data in terms of the downstream UMAP visualisations (when I simply embedded 50 components in the neighbourhood graph). One difference is that the ICA was slower to compute. I am not confident to create a vignette, as I'm unclear what the 'correct' results should look like. I have not tried the `picard` implementation yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/767#issuecomment-540457004:169,down,downstream,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767#issuecomment-540457004,1,['down'],['downstream']
Availability,"Thanks for the fix!. For the `p` vs `q` thing, I was just thinking if the user passes a string that doesn't start with `p`, the error message could be something like `""ValueError: Couldn't understand string value '{passed_val}' for vmax. Percentile cutoffs can be specified like 'p99' (99th percentile).""`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/800#issuecomment-526476496:128,error,error,128,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800#issuecomment-526476496,1,['error'],['error']
Availability,"Thanks for the help. I have traced the randomness to sc.tl.score_genes_cell_cycle. Even if I explicitly state the random state to be 0, two repeats of score_genes_cell_cycle from the same data would give different downstream clustering. On the other hand, if I use one score_genes_cell_cycle output and repeat the downstream clustering methods, the clusters are the same. ; I am currently using scanpy==1.3.1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/313#issuecomment-432462799:214,down,downstream,214,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/313#issuecomment-432462799,2,['down'],['downstream']
Availability,"Thanks for the long response @ivirshup!. For 1. I think a ufunc should always act on adata.X and I want it to return the adata object with the sqrt applied to adata.X. Adding support for the sklearn operators would be great. For the second part, my intention is for the result to be `adata[:, adata.var_names[0:3]].X - adata[:, adata.var_names[3:6]].X`, and it's fine with me in the varnames are lost so long as the obsnames are kept. If they're not the same shape, then I would expect the same error as pandas throws. For 2. I think its okay if you return a dense 1-d array when I access a single column vector. I don't understand where the confusion is coming in with adata.X changing when you access a single column, but that's not been an issue for me. For the rest, I hope you can survey the community to figure out how rare my use-cases are. I would like scanpy / anndata to fit into my existing workflow that I picked up while learning matplotlib / pandas / numpy. I want slicing an AnnData to behave like slicing a DataFrame; I want clusters to be ints; I want to apply a transformation to a data-container and get the whole container returned with the transformation applied to the values. . I can come up with workarounds for all of the choices you've made here. That's not the issue. I raised this comment because these workarounds add overhead to getting my work done. I'm not going to change my work flow to match your design choices where they diverge from the apis for sklearn / numpy / pandas etc. I know I'm not the only one with these wants (e.g. @scottgigante has similar frustrations), but I don't know how prevalent these frustrations are. I think at the end of the day, my concern here boils down to what infrastructure you put in place to make sure the needs of the community are balanced with the intentions of the developers. I think the efforts be cellxgene are a great model for this, and I would happily get involved with figuring out the best way to incorporate community ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-609066004:495,error,error,495,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-609066004,1,['error'],['error']
Availability,Thanks for the nice report submission. The code error is caused by the categories being integers when the code expect an 'str'. This is an easy fix. . The mapping of labels to color being different when colors are not in `adata.uns` is because the mapping is not saved (Fig 2 and 3). It is also an easy fix but requires the modification of `adata.uns` to save the colors. This is already done in `sc.pl.embedding` so should be OK to do but I would like to know @ivirshup opinion. For Fig 1. when there are more cells the problem is not there or maybe is simply not visible But I have some idea on how to address it. For Fig 6 I really don't know.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1591#issuecomment-762778317:48,error,error,48,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1591#issuecomment-762778317,1,['error'],['error']
Availability,"Thanks for the reference, I added a number of tests to where you mentioned. I also changed the `broadcasting` method for `markers` so now it has the same process as `color` and `dimensions`, and therefore if broadcasting fails, the output error is more understandable (same as when `color` and `dimensions` broadcasting fails). I also added a test for `marker broadcasting`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2545#issuecomment-1631633257:239,error,error,239,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2545#issuecomment-1631633257,1,['error'],['error']
Availability,"Thanks for the reply, unfortunately pandas dataframe conversion gives me this error . `pd.DataFrame(adata.raw.X).to_csv(filename_raw_x)`. `ValueError: DataFrame constructor not properly called!`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/506#issuecomment-468005012:78,error,error,78,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506#issuecomment-468005012,1,['error'],['error']
Availability,"Thanks for the report!. `scanpy.read_10x_h5` is expecting the files for the count matrices, not the UMI info. So it's throwing a non-sensical error. `read_10x_h5` is expecting files like `filtered_feature_bc_matrix.h5` or `raw_feature_bc_matrix_h5.h5`. For example:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_feature_bc_matrix.h5",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2149#issuecomment-1049152162:142,error,error,142,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149#issuecomment-1049152162,1,['error'],['error']
Availability,"Thanks for the report. I can broadly reproduce the error for passing `values_to_plot`. The error I get is a little different, but I expect that's due to pandas versions. A more minimal example:. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed().raw.to_adata(); sc.tl.rank_genes_groups(adata, groupby=""louvain"", reference=""B cells""). # Errors with any of ['scores', 'logfoldchanges', 'pvals', 'pvals_adj','log10_pvals', 'log10_pvals_adj']; sc.pl.rank_genes_groups_dotplot(adata, values_to_plot='logfoldchanges'); ```. <details>; <summary> Traceback </summary>. ```pytb; ERROR: the given dot_color_df data frame has a different shape thanthe data frame used for the dot size. Both data frames needto have the same index and columns; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /var/folders/bd/43q20k0n6z15tdfzxvd22r7c0000gn/T/ipykernel_62013/1545772980.py in <module>; 1 while len(possible_vals) > 0:; ----> 2 sc.pl.rank_genes_groups_dotplot(adata, values_to_plot=possible_vals.pop()); 3 . ~/github/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds); 861 tl.rank_genes_groups; 862 """"""; --> 863 return _rank_genes_groups_plot(; 864 adata,; 865 plot_type='dotplot',. ~/github/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 534 from .._dotplot import dotplot; 535 ; --> 536 _pl = dotplot(; 537 adata,; 538 var_names,. ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911:51,error,error,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078#issuecomment-991361911,4,"['ERROR', 'Error', 'error']","['ERROR', 'Errors', 'error']"
Availability,"Thanks for the report. I'm having trouble reproducing this behaviour locally. Two thoughts:. 1. It looks like there's a newer version of leidenalg available, could you upgrade that?; 2. Maybe there is something about the neighborhood graph. Could you either: reproduce this with some dummy data (e.g. `sc.datasets.blobs`) or share the `test` object?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2906#issuecomment-1997818178:147,avail,available,147,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2906#issuecomment-1997818178,1,['avail'],['available']
Availability,"Thanks for the suggestion! If putting it inside the class, I'd rather go for a subclass of AnnData. But I'd prefer to have the sc.pp namespace for all preprocessing methods. I expect that a lot of different methods could still come. If you always have to wonder whether this might be something that is already in AnnData or just in the sc.pp or applies to a data matrix X, it's hard to keep track. If everything just applies to X, it's easy. You still can make errors, like I did above, something like `adata.var = adata.var[gene_filter]` should work, right, whereas the `adata.var_names = adata.var_names[gene_filter]` from above will not work and should throw a sensible error... I'll again have a look. Please, for now, don't do anything. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/4#issuecomment-278581479:461,error,errors,461,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/4#issuecomment-278581479,2,['error'],"['error', 'errors']"
Availability,"Thanks for the suggestion. Actually, I am using cellxgene which takes the; h5ad file as an input. when using anndata.write() function, it only output; the anndata.X as the expression matrix. And also there is no option of; useRaw here.; Also, I tried to re-assign anndata.X = anndata.raw.X, but it returns an; error saying its wrong shape.; Do you have any suggestions?. Thanks a lot!. On Mon, Jun 3, 2019 at 6:03 AM Maximilian Haeussler <; notifications@github.com> wrote:. > The scanpyToCellbrowser function has an option useRaw that will use the; > .raw matrix, if present, for the .tsv export.; >; > Otherwise, the raw matrix of all genes is stored as ad.raw.X and the; > variable names are in ad.raw.var. You can use scanpyToCellbrowser to write; > the matrix and all annotations, or anndataToTsv to write just the matrix.; > Or use code from there to write your own.; >; > On Fri, May 31, 2019 at 5:14 PM Jing He <notifications@github.com> wrote:; >; > > Hi, the expression matrix I exported from adata.write only have the top; > > variable genes. Is there a way to output the raw matrix including all; > genes?; > >; > > —; > > You are receiving this because you were mentioned.; > > Reply to this email directly, view it on GitHub; > > <; > https://github.com/theislab/scanpy/issues/262?email_source=notifications&email_token=AACL4TNOFS6MLIH44P6J5HDPYE6ENA5CNFSM4FU553M2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODWVQBGI#issuecomment-497746073; > >,; > > or mute the thread; > > <; > https://github.com/notifications/unsubscribe-auth/AACL4TORHPOQ2GTWTUGTAI3PYE6ENANCNFSM4FU553MQ; > >; > > .; > >; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/262?email_source=notifications&email_token=AAUAIIIOXG5HSDCKTFYS7KLPYTT6BA5CNFSM4FU553M2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODWY5RAA#issuecomment-498194560>,; > or mute the thread; > <https://github.com/n",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/262#issuecomment-499091368:310,error,error,310,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/262#issuecomment-499091368,1,['error'],['error']
Availability,"Thanks for this contribution! Can you look at the travis errors? See https://github.com/theislab/scanpy/pull/797#issuecomment-536861482 for background. To fix formatting errors you can use https://github.com/psf/black. Furthermore, can you add a small example to the docstring? (see for example: https://github.com/theislab/scanpy/blob/master/scanpy/external/tl/_palantir.py)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/862#issuecomment-540005836:57,error,errors,57,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/862#issuecomment-540005836,2,['error'],['errors']
Availability,"Thanks for your comments, I understand the struggle of implementing CI for GPU code!. @Zethson here are my answers to your questions:; 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice.; 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. ; `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-816665412:170,avail,available,170,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533#issuecomment-816665412,1,['avail'],['available']
Availability,"Thanks for your help. It works fine now! I have tried several times this day, but end up with failure. It works fine now following your method!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2339#issuecomment-1261170036:94,failure,failure,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339#issuecomment-1261170036,1,['failure'],['failure']
Availability,Thanks for your interest! It would be cool if `Marsilea` could be part of `Scanpy`. . The `Marsilea` is shipped with a wide range of plot options which already include the [dot plot](https://marsilea.readthedocs.io/en/latest/tutorial/heatmap.html#matrix-heatmap-with-sized-elements) (We call it Sized Heatmap). Here is a [list](https://marsilea.readthedocs.io/en/latest/api/plots.html) of all available plot options for your reference. . Any further suggestions or requests to expand the plot options are welcome.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2512#issuecomment-1598070226:393,avail,available,393,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2512#issuecomment-1598070226,1,['avail'],['available']
Availability,"Thanks for your reply! (And no worries - mine is even later). . I see your point about ecosystem vs. external. My main qualm about ecosystem (at least in its current form) is that it's just links to external projects that happen to use scanpy, and the burden of downloading these projects, learning their unique syntax, and seeing how they apply to the scanpy project at hand is off-loaded to the user. The main reason I have pushed for inclusion in external is the convenience of being able to call the function with a single scanpy command, in a format the user is already very familiar with. On the other hand, I do see your point about code maintenance and syncing between my project and scanpy. Changes in my shannonca project might necessitate changes in the wrapper function. That said, since my wrapper is very agnostic to the underlying methods used, I would hope this wouldn't have to happen very often (basically, it just controls where the inputs are found and where the outputs are deposited. This wouldn't change unless scanpy's architecture did). However, as currently written, the documentation may have to change more frequently since it refers to specific function arguments used in my package. For now, I am willing to open a new pull request into ecosystem (if that is the correct workflow) and you can feel free to close this issue. For future releases, if you want to combine the convenience of external with the low maintenance burden of ecosystem, you might consider allowing external modules to ""outsource"" their documentation. So in scanpy's documentation, a function F under external would simply have the format sc.external.tl.F(adata, **kwargs), where **kwargs is passed directly to a method maintained by the tool developer, with a link to a docstring in the external repository. I would happily make this for shannonca as a proof of concept, if you think it's worth trying.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1780#issuecomment-911791808:262,down,downloading,262,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780#issuecomment-911791808,3,"['down', 'mainten']","['downloading', 'maintenance']"
Availability,"Thanks for your reply, @falexwolf. I was looking through the same error and I can't really understand why the results are different - it might be a difference in accuracy levels between the manual wilcoxon method that was used before, and the built-in scipy.stats function I used. I looked at the differences and they indeed look marginal. **Edit:** I actually just went back through the check results, and the comparison between the results before and after are pretty much identical - it could just be a difference in bit-depth. For example, it's tagging (2.292195 , 5.7448500e-01) as different from (2.292195 , 0.574485). . I also compared a before-after with my dataset and I get very similar marker genes, albeit in slightly different order (see attached images). I don't really know what would be the best way to address these differences - I am simply using the built in spicy.stats function and not changing the output it gives me. Could this marginal difference be caused by the estimation in the ""chunk"" approach used in the previous version? Even with this marginal difference, I would assume that using the scipy function is more ""accurate"". Please let me know what you would prefer and what would be the best way to proceed.; ![figure_1_newwilcox](https://user-images.githubusercontent.com/37122760/46375973-c93b4700-c662-11e8-8581-b85a28e36dbc.png); ![figure_1_originalwilcox](https://user-images.githubusercontent.com/37122760/46375974-c93b4700-c662-11e8-810b-48238394be1e.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/270#issuecomment-426424354:66,error,error,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/270#issuecomment-426424354,1,['error'],['error']
Availability,"Thanks for your response. As of today that's correct: AWS, GCP and DO. Azure support is a work in progress at the moment. It should be available by the end of this month most likely. Do you have a hard deadline on this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1793#issuecomment-881369655:135,avail,available,135,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793#issuecomment-881369655,1,['avail'],['available']
Availability,"Thanks for your thorough response! And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823:819,down,downstream,819,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-474080823,1,['down'],['downstream']
Availability,"Thanks on that method @ivirshup - our version was written before I was maintainer, and maybe that function wasn't available. . Happy to adopt whatever general approach you recommend.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1955#issuecomment-886548222:114,avail,available,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955#issuecomment-886548222,1,['avail'],['available']
Availability,"Thanks! A little bit of context. We needed this aggregation for one of the projects using pseudobulks of the data. We could use scanpy aggregation methods for simple averaging, but to test the outlier-robust median aggregation, we had to write our code. scanpy didn't have it for some reason, so @farhadmd7 kindly agreed to contribute here. Perhaps someone else will find it helpful, too. @eroell, what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3180#issuecomment-2258670730:201,robust,robust,201,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180#issuecomment-2258670730,1,['robust'],['robust']
Availability,"Thanks! It works! I used your first suggestion. I'm mostly an R user, but in the past I worked on python. I haven't used it for ages and the first thing of R I'm really missing is the help. Here, I can google commands and errors for standard libraries but for example, in the case of new tools, I can just rely on few examples or tutorials.. Or it would be nice for example, also have a list of all the functions in scanpy, with explanation of inputs, outputs and explanation of them. Your documentation is really helpful and well-structured, but I feel a bit limited by that aspect. ; Cheers, ; Elisabetta",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/74#issuecomment-363800572:222,error,errors,222,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74#issuecomment-363800572,1,['error'],['errors']
Availability,"Thanks! So my understanding is that you are saying that `neighbors` function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that `gauss` out of it, I guess?). > From an API stand point, I would like the ""blessed"" tsne workflow to be dead obvious. I'm thinking:; > `sc.pp.neighbors_tsne(adata)`; > `sc.tl.tsne(adata)`; > How many arguments is it going to take to make this work if this functionality is in sc.pp.neighbors? At a minimum, k=30, method=tsne_affinity, nn_method=""annoy"", right?. I'd say `perplexity=30, method='tsne'`. I don't see why t-SNE should use annoy if UMAP uses pynndescent. This does not matter for the algorithm. So `nn_method` could either be included in all `neighbors` functions or into none, IMHO. In any case,; ```; sc.pp.neighbors_tsne(adata); sc.tl.tsne(adata); ```. would also be fine with me. I think it's important that the following works:. ```; sc.pp.neighbors(adata); sc.tl.tsne(adata); ```. and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). But if somebody wants to do the ""actual"" t-SNE, then they can run `sc.pp.neighbors_tsne(adata)` first. I think this makes sense. . One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs `neighbors_tsne` (or both `neighbors` and `neighbors_tsne`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-759329085:1290,down,downstream,1290,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-759329085,1,['down'],['downstream']
Availability,"Thanks!. On Wed, Jun 7, 2023 at 9:34 AM Philipp A. ***@***.***> wrote:. > I had the same thought and opened #2505; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2505&g=NmVkM2RiMWY2M2U4YzZhYw==&h=YTlmZWU5MDlhNTJlOWJjMTkxZDczZTg2MGE2ODdiNzU2NmIwYjE2OTMzZTczY2M1ZjNlNzEyM2Q0Mjc1OWM5Yg==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>; > to track that!; >; > —; > Reply to this email directly, view it on GitHub; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/scverse/scanpy/issues/2500%23issuecomment-1580835422&g=YWNlMjU3YjI5ODM4NTJkYQ==&h=ZTJiNzVlYzQ0NzM5YmY0ZTdiMWEzMDQ2MmQ0MGMwOWZmZTVlOGRhN2JmYjZiYTcxYjg1Nzg3OTRjMzEwZDY3OA==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>,; > or unsubscribe; > <https://checkpoint.url-protection.com/v1/url?o=https%3A//github.com/notifications/unsubscribe-auth/AUHCMAR6XJXLYMBK224NMETXKB7MDANCNFSM6AAAAAAY3HAO3E&g=OGRhMDE2YzcyZWIwNGMxNg==&h=M2I1NTIwM2JlNTIwNjA4MGViYjE3YTRmYjQ0MWM3NzNhYzNkNjBlNzVjYjg1NDUwMGVkMjJhNWFkYmZlZTIxYQ==&p=YzJlOmltbXVuYWk6YzpnOjBhNjA3ZDgxZmY2OGQ1YTVjYWY3YWUzM2MzZGM0MDU3OnYxOmg6VA==>; > .; > You are receiving this because you authored the thread.Message ID:; > ***@***.***>; >. -- ; PLEASE NOTE: The information contained in this message is privileged and ; confidential, and is intended only for the use of the individual to whom it ; is addressed and others who have been specifically authorized to receive ; it. If you are not the intended recipient, you are hereby notified that any ; dissemination, distribution, or copying of this communication is strictly ; prohibited. If you have received this communication in error, or if any ; problems occur with the transmission, please contact the sender.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580840698:126,checkpoint,checkpoint,126,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500#issuecomment-1580840698,4,"['checkpoint', 'error']","['checkpoint', 'error']"
Availability,"Thanks- that doesn't seem to be as easy as I was thinking.. ; 1. I think for most applications that I have in mind I would be interested in the relative differences. Are cells distributed differently in two conditions, regardless of whether there are more cells overall in one of the conditions?; 2. My bad, I thought the were already calculated over a grid layout.. would that also require to down sample the larger cell population to match the smaller one?; 3. That would be very cool, but having this for qualitative assessment would be already useful. Ok, thanks - will do if I come up with a satisfying solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/575#issuecomment-478274180:394,down,down,394,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-478274180,1,['down'],['down']
Availability,Thanks. Can you share the code that produces the error? Maybe also the image as well?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1405#issuecomment-686782513:49,error,error,49,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1405#issuecomment-686782513,1,['error'],['error']
Availability,"Thanks. I tried this as well. The problem that I had was that going back to a Boolean for subsetting was not easy:; ```python; adata.obs['boolean'] = adata.obs['boolean'].astype(str).astype('category'); adata[adata.obs['boolean'].astype(bool)]; ```; This throws a key error:; ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-26-3fef793fe5bd> in <module>; ----> 1 adata[adata.obs['boolean'].astype(bool)]. /opt/conda/lib/python3.7/site-packages/anndata/_core/anndata.py in __getitem__(self, index); 1085 def __getitem__(self, index: Index) -> ""AnnData"":; 1086 """"""Returns a sliced view of the object.""""""; -> 1087 oidx, vidx = self._normalize_indices(index); 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1089 . /opt/conda/lib/python3.7/site-packages/anndata/_core/anndata.py in _normalize_indices(self, index); 1066 ; 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1068 return _normalize_indices(index, self.obs_names, self.var_names); 1069 ; 1070 # TODO: this is not quite complete... /opt/conda/lib/python3.7/site-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1); 32 index = index[0].values, index[1]; 33 ax0, ax1 = unpack_index(index); ---> 34 ax0 = _normalize_index(ax0, names0); 35 ax1 = _normalize_index(ax1, names1); 36 return ax0, ax1. /opt/conda/lib/python3.7/site-packages/anndata/_core/index.py in _normalize_index(indexer, index); 99 not_found = indexer[positions < 0]; 100 raise KeyError(; --> 101 f""Values {list(not_found)}, from {list(indexer)}, ""; 102 ""are not valid obs/ var names or indices.""; 103 ). KeyError: 'Values [True, True, True, (.... I shorten this part....) True, True, True, True, True, True, True, True, True, True, True, True, True, True], are not valid obs/ var names or indices.'; ```; while this works:; ```python; adata[adata.obs['boolean'].astype(bool) == True]; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1646#issuecomment-778331854:268,error,error,268,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1646#issuecomment-778331854,1,['error'],['error']
Availability,"Thanks. The dataset is here:. https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE194122. Sicne it is from GSE, I think it is easy to download and it is formed into h5ad format (the multiome part).; GSE194122_openproblems_neurips2021_multiome_BMMC_processed.h5ad.gz. Code:. ```; adata_atac.X = (adata_atac.X > 0)*1; sc.pp.highly_variable_genes(adata_atac, n_top_genes=13634); adata_atac = adata_atac[:,adata_atac.var['highly_variable']]; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2819#issuecomment-1906521560:136,down,download,136,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2819#issuecomment-1906521560,1,['down'],['download']
Availability,"That error is not specific to scanpy. It would be good to know which; library is causing the problem such that it can be updated but most likely; is either numpy, scipy, matplotlib or sklearn. Maybe try to update those; packages and see if the error goes away or try to google the error to find; some solution. On Fri, Oct 5, 2018 at 2:59 PM Dilawar Singh <notifications@github.com>; wrote:. > Same issue here. Using pip +pyhton3.7 and not conda to install from pypi.; > Is there a way to resolve it without installing using conda?; >; > Logs:; >; > [dilawars@chamcham scanpy_exp]$ python planaria.py; > /home1/dilawars/.local/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses; > import imp; > scanpy==1.3.1 anndata==0.6.10 numpy==1.15.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.0 statsmodels==0.9.0 python-igraph==0.7.1; > ... storing 'clusters' as categorical; > computing tSNE; > using data matrix X directly; > using the 'MulticoreTSNE' package by Ulyanov (2017); > finished (0:02:53.98); > saving figure to file ./figures/tsne_full.pdf; > computing neighbors; > using data matrix X directly; > Inconsistency detected by ld.so: dl-version.c: 205: _dl_check_map_versions: Assertion `needed != NULL' failed!; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/280#issuecomment-427357518>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1WzuXR5Mhpb3jNte9UkVDqzQjb1pks5uh1eZgaJpZM4XHKo6>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/280#issuecomment-427359171:5,error,error,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/280#issuecomment-427359171,3,['error'],['error']
Availability,"That is a wonderful solution! I will give it a shot shortly. Thank you so much for your help!. Here's some example code of how Seurat handles cluster scoring and merging with random forests and OOBE:. ```; pbmc <- ValidateClusters(pbmc, pc.use = 1:30, top.genes = 30). pbmc <- BuildClusterTree(pbmc, ; do.reorder = T, ; reorder.numeric = T). node.scores <- AssessNodes(pbmc). node.scores[order(node.scores$oobe,decreasing = T),] -> node.scores. nodes.merge <- node.scores[which(node.scores[,2] > 0.1),]; nodes.to.merge <- sort(nodes.merge$node) ; pbmc.merged <- pbmc. for (n in nodes.to.merge); {; pbmc.merged <- MergeNode(pbmc.merged, n); }. ```. Here's an explanation, as this code was derived from this recent (and awesome) publication:; ; From page 6 of the Supplementary Methods of Plass et al 2018: http://science.sciencemag.org/content/early/2018/04/18/science.aaq1723. To prevent obtaining spurious clusters result of overclustering, the robustness of the clusters was calculated using the function AssessNodes from Seurat. For each cluster, the average expression of all variable genes (4910) is computed and a phylogenetic tree based on the distance matrix in gene expression space is computed. Next, it computes an Out of Bag Error for a random forest classifier trained on each internal node split of the tree. We recursively build a tree and assessed all its nodes, merging all clusters with an out of bag error bigger than 0.1 until no such nodes were found.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/362#issuecomment-440912410:946,robust,robustness,946,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/362#issuecomment-440912410,3,"['Error', 'error', 'robust']","['Error', 'error', 'robustness']"
Availability,"That is evidently a problem of [psutil](https://pypi.python.org/pypi/psutil); do you have an old version of it? I have tested with 5.2.2 and 5.1.2. Earlier, psutil seemed to have had a [different convention](https://stackoverflow.com/questions/31216835/python-psutil-psutil-get-process-list-error). But both is not related to Scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/35#issuecomment-324463747:291,error,error,291,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/35#issuecomment-324463747,1,['error'],['error']
Availability,"That looks great Isaac, thanks a lot!. > * Restructure how elements are added to `uns`, as mentioned in [theislab/anndata#295 (comment)](https://github.com/theislab/anndata/issues/295#issuecomment-596164456). . agree, I also think that it could be best in the case of different data types (not visium). It's also best if the tree structure does not change in case of concatenation. > * Rename `obsm[""X_spatial""]` to `obsm[""coords""]` or `obsm[""spatial""]`. . what about `X_coords` ?. > * There is a natural connectivity for the observations from the adjacency of wells. This should be easy to add to obsp, or should just be added to obsp when `read_visum` is called. I'm thinking `""spatial_connectivity""` for the default key name. . This was also in the plans but further down the line (support for multiple slices should be first). I could have a look at this soon. What about re-open the `theislab/spatial` branch and merge this PR there? I could then work on how to handle the new `uns` structure in the plotting functions and have a definitive version of multiple slices support in anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1088#issuecomment-596448147:770,down,down,770,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1088#issuecomment-596448147,1,['down'],['down']
Availability,"That problem occurs within h5py (we just wrap the underlying OSError) and isn’t a consequence of how scanpy uses h5py. The relevant part of the traceback is:. ```pytb; OSError: Can't read data (file read failed:; time = Sat Aug 1 13:27:54 2020,; filename = '/path.../filtered_gene_bc_matrices.h5ad',; file descriptor = 47,; errno = 5,; error message = 'Input/output error',; buf = 0x55ec782e9031,; total read size = 7011,; bytes this sub-read = 7011,; bytes actually read = 18446744073709551615,; offset = 0); ```. The reported filename looks weird: `'/path.../filtered_gene_bc_matrices.h5ad'`. Is that file on some network share or colab or so? Because that’d explain wonky I/O. 18 exabytes (18 quintillion bytes!) read seems really off too!. I assume `self.group[""data""][...]` tries to read all the data for `.X` and some bug or connection problem tells h5py that there’s 18 exabytes. h5py then asks the OS to give them those 18 exabytes which the OS politely denies. See also:. - https://github.com/googlecolab/colabtools/issues/559; - https://forum.hdfgroup.org/t/errors-accessing-hdf5-over-cifs-and-or-nfs/6341",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-667531196:336,error,error,336,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-667531196,3,['error'],"['error', 'errors-accessing-']"
Availability,"That sounds right, yes. Looking forward to this being available.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/72#issuecomment-362374369:54,avail,available,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72#issuecomment-362374369,1,['avail'],['available']
Availability,"That's a good point! I just added the Benjamini-Hochberg correction to the Wilcoxon code (as well as to the t-tests) and left that as the default. I left the Bonferroni code in there and marked the place with comments. If and when the pull request is complete, they can choose what to keep and remove the extra comments. Either way, since the uncorrected p-values are also outputted, the user can choose whichever correction they want downstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/289#issuecomment-428734103:435,down,downstream,435,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/289#issuecomment-428734103,1,['down'],['downstream']
Availability,"That's a good point, and it is not:; ```python; reducer = umap.UMAP(min_dist=0.5); embedding = reducer.fit_transform(adata.obsm[""X_scVI""]); adata.obsm[""X_umap""] = embedding; ```; again produces stable results on only 3/4 CPUs. . Ok, let's forget about UMAP. It's only a nice figure to get an overview of the data and I don't use it for downstream stuff. Irreproducible clustering, on the other hand, is quite a deal-breaker, as for instance cell-type annotations depend on it. I mean, why would I even bother releasing the source code of an analysis alongside the paper if it is not reproducible anyway? . I found out a few more things: ; - the leiden algorithm itself seems deterministic on all 4 nodes, when started from a pre-computed `adata.obsp[""connectivities""]`. ; - when running `pp.neighbors` with `NUMBA_DISABLE_JIT=1`, the clustering is stable on all four nodes (but terribly slow, ofc); - when rounding the connectivities to 3-4 digits, the clustering is also stable (plus the total runtime is reduced from 2:30 to 1:50min). ```python; adata.obsp[""connectivities""] = np.round(adata.obsp[""connectivities""], decimals=3); adata.obsp[""distances""] = np.round(adata.obsp[""distances""], decimals=3); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2014#issuecomment-946539365:336,down,downstream,336,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2014#issuecomment-946539365,1,['down'],['downstream']
Availability,That's an HTTP error. You need to report this to the data hoster aka EBI,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2449#issuecomment-1465762834:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449#issuecomment-1465762834,1,['error'],['error']
Availability,That's good too. Right now it's throwing a warning not an error. Is that meant to happen?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/800#issuecomment-526890943:58,error,error,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800#issuecomment-526890943,1,['error'],['error']
Availability,"That's not a bug, that's a feature ;). You can only compute as many PCs as the minimum number of dimensions in n_samples and n_features. Do you feel as though the error message is unclear on this? I feel as though changing the default to match the setting can be dangerous as may not recall how many PCs were used then.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1051#issuecomment-586474464:163,error,error,163,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051#issuecomment-586474464,1,['error'],['error']
Availability,"That's odd. sklearn calculates the explained variance and variance ratio as follows:; ```python; # Calculate explained variance & explained variance ratio; X_transformed = U * Sigma; self.explained_variance_ = exp_var = np.var(X_transformed, axis=0); if sp.issparse(X):; _, full_var = mean_variance_axis(X, axis=0); full_var = full_var.sum(); else:; full_var = np.var(X, axis=0).sum(); self.explained_variance_ratio_ = exp_var / full_var; ```. I do it in the same way:; ```python; X_pca = (u * s)[:, idx] # sort PCs in decreasing order; ev = X_pca.var(0). total_var = _get_mean_var(X)[1].sum(); ev_ratio = ev / total_var; ```; I'll investigate... EDIT: Strange, your assertion error is not reproducible on my end. The code runs fine for me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-593741930:677,error,error,677,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-593741930,1,['error'],['error']
Availability,"That's very strange. I will take a look. On Mon, Mar 18, 2019 at 4:09 PM Fabian Rost <notifications@github.com>; wrote:. > I have a dataset for which I have an observation that is only available; > for some cells. When I make a scatter plot that I color code for this; > observation not all cells are plotted:; >; > import randomimport scanpy as sc; >; > adata = sc.datasets.blobs(); > adata.obs['property'] = 630 * [float(""nan"")] + 10 * [1]; >; > sc.tl.pca(adata); > sc.pl.pca(adata, color='property', size=50); >; > While this should plot 10 cells it only shows one cell:; > [image: image]; > <https://user-images.githubusercontent.com/7300030/54540172-caa1c700-4997-11e9-946e-01c1e04dd2d2.png>; > I can get the plot I want by filtering cells first:; >; > sc.pl.pca(adata[adata.obs['property'] == 1], color='property', size=50); >; > [image: image]; > <https://user-images.githubusercontent.com/7300030/54540221-e60cd200-4997-11e9-9b53-e9917bd01c59.png>; > Would you agree that scanpy should plot all cells that have a valid; > observation?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/536>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1X3Le-1usPntk050roRY9vedXEHHks5vX6wMgaJpZM4b6BYA>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/536#issuecomment-474007740:185,avail,available,185,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536#issuecomment-474007740,1,['avail'],['available']
Availability,That’s super redundant now. Please extract all that text from `doc_scatter_bulk` into another variable and import and use that one instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/557#issuecomment-476508242:13,redundant,redundant,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557#issuecomment-476508242,1,['redundant'],['redundant']
Availability,"That’s weird, but that might be another issue, please check out #1378. /edit: seems to be a conda bug that only occurs on windows due to flit ([legally](https://www.python.org/dev/peps/pep-0376/#record)) writing windows newlines into the RECORD file, and conda reading them as two newlines each and then crashing. ---. This PR adds instructions on how to integrate with conda, which I screenshotted. It fails for me with this error:. ```; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound: ; - loompy[version='>=3.0.5']; ```. But since loompy 3.x isn’t on conda-forge, that’s correct. Seems that resolving anndata’s dependencies on conda is currently not possible and you need to wait until loompy gets upgraded on conda-forge. Or until Quansight-Labs/beni#3 is resolved and you can specify that you don’t want all deps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1377#issuecomment-675423209:426,error,error,426,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1377#issuecomment-675423209,1,['error'],['error']
Availability,"The Jaccard metric, taken from umap, I believe, returns for a pair of vectors x and y the Jaccard distance between their sets of nonzeros. ([Code](https://github.com/theislab/scanpy/blob/7975f0774c0737bccfc312be0f2a81a3922c2185/scanpy/neighbors/umap/distances.py#L156).). In the case that you feed the raw or logged gene expression matrix, this is reasonable: it's the fraction of genes with nonzero expression shared by the two cells. If you compute this on PCA vectors, however, which are essentially all nonzero, you are getting some version of the complete graph, downsampled to k in some random way. This would explain why clustering and embedding based on that graph is garbage. While investigating this, we (me and @sidneymbell) came across some behavior that may or may not be the desired default. If you call `tools._utils.choose_representation` with `use_rep=None, n_pcs=None`, then it will return `X_pca` (all columns) because `X_pca[:,:None] = X_pca`, which will be the top 50 PCs if one is running with defaults. I might have expected this to instead return `X`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/177#issuecomment-399263207:568,down,downsampled,568,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/177#issuecomment-399263207,1,['down'],['downsampled']
Availability,The Numba parallel error also occurred to me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/749#issuecomment-528179543:19,error,error,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749#issuecomment-528179543,1,['error'],['error']
Availability,"The checks shouldn't take any time. But you're right; you're also slicing the `.var` and the `.varm` annotations if you make this call and we could check whether this perceivably slows down things (only for very large data, I guess). If it does, it would be very simple to add an accessor `.slice_X` that enables convenient slicing of the data matrix. That's a bit ugly but would vanish in the plotting function. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/244#issuecomment-422400480:185,down,down,185,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/244#issuecomment-422400480,1,['down'],['down']
Availability,"The current model is stable and has been successfully used in many instances. It will also be available in Scanpy 1.2. In addition, there will be another model. General improvements only regard the ease of use of PAGA and are model-independent anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/96#issuecomment-393972623:94,avail,available,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/96#issuecomment-393972623,1,['avail'],['available']
Availability,"The data also allows to detect a next issue: When multiple genes have the same value of `disp_cut_off`. Can be found if here e.g. dont do `sc.pp.normalize_total`:. ```py; import scanpy as as; adata = sc.datasets.pbmc3k(); # sc.pp.normalize_total(adata, target_sum=10000); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000); adata.var[""highly_variable""].sum(); ```; ```; 10367; ```; Which is due to many genes having the value selected for the `disp_cut_off` here, having . ...`x[n-2]` = `x[n-1 ]` = `x[n]` = `x[n+1] `= `x[n+2]`... https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L408-L418. I tried to check how Seurat is proceeding in such a case, expecting to see how it breaks the ties. (data downloaded from [here](https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz)); Here I'm actually not sure how to turn off the `scale.factor` argument? Its set to 10'000 by default. ```R; library(dplyr); library(Seurat); library(patchwork). pbmc.data <- Read10X(data.dir = ""filtered_gene_bc_matrices/hg19/""). pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k""). pbmc <- NormalizeData(pbmc, normalization.method = ""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot"", nfeatures = 10000). length(VariableFeatures(pbmc)); ```; ```; 2292; ```; However, it turns out Seurat seems to restrict to the genes which are variable in the sense of passing the set mean threshold and normalized dispersion thresholds. These thresholds are ignored in scanpy if the number of genes is given. So not really an insight of how to break ties in this case. Would suggest to make a new issue, which the potential project on comparing the frameworks could address.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3157#issuecomment-2255759888:816,down,downloaded,816,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157#issuecomment-2255759888,1,['down'],['downloaded']
Availability,The error happened because the ingest cannot use neighbors generated from harmony.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2351#issuecomment-1275594865:4,error,error,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2351#issuecomment-1275594865,1,['error'],['error']
Availability,The error seems to be that [`rdist`](https://github.com/lmcinnes/umap/blob/0.3.8/umap/umap_.py#L663) is called from [`umap.umap_.optimize_layout`](https://github.com/lmcinnes/umap/blob/0.3.8/umap/umap_.py#L776) with float64 arrays while it can only handle float32 arrays. There seem to have been a few changes in umap [between 0.3.8 and 0.3.9](https://github.com/lmcinnes/umap/compare/0.3.8...0.3.9) maybe you should try 0.3.9.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/666#issuecomment-496845071:4,error,error,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-496845071,1,['error'],['error']
Availability,"The idea behind a self contained example is to give me something that I can run on my machine. Ideally you'd be able to put something together with randomly generated data that still gave this error. If that's difficult, you could keep removing elements from your data until you find the minimal object that can reproduce this. [Here is a good blog post on how to do this](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports). Right now, I'm unable to reproduce the error you're seeing. Do you think you could try and create an example you could share with me? This could even be sharing your data as an `h5ad` file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1259#issuecomment-639309900:193,error,error,193,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259#issuecomment-639309900,2,['error'],['error']
Availability,"The idea of having ""smart subsample"" functionality available in scanpy has been a topic of discussion for a while. I would like to see a benchmark of these methods on single cell data before choosing one to include here. Are you aware of anything in this space?. Update:. It looks like the lab it's from have put out some writing on this: https://dl.acm.org/doi/pdf/10.1145/3388440.3412409",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2862#issuecomment-1948573055:51,avail,available,51,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2862#issuecomment-1948573055,1,['avail'],['available']
Availability,"The initial problem is due to the fact that the new 'highly_variable_genes' function does not take numpy arrays anymore: https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/highly_variable_genes.py. It's also mentioned in the docs, but we should, of course, have thrown a clear error message. Now it does: https://github.com/theislab/scanpy/commit/a578ced0b2e44b26998fb9e08c5bb0ffb82a7a4b. To return the annotation, one can set `inplace=False`. But the updated plotting function also takes the full `AnnData` object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-445515304:294,error,error,294,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-445515304,1,['error'],['error']
Availability,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1484#issuecomment-725894623:91,error,error,91,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484#issuecomment-725894623,4,"['error', 'failure']","['error', 'failure']"
Availability,"The issue that you mention has been reported to matplotlib 3.1 and the; solution is to downgrade to 3.0*. I just updated the dependencies of; scanpy to be matplotlib 3.0. As soon as this is solved we will update the; dependencies. On Mon, May 27, 2019 at 3:33 PM bioguy2018 <notifications@github.com> wrote:. > Dear all; > I would like to project my umap from scanpy in 3d but I have faced the; > following problem:; >; > ValueError: operands could not be broadcast together with remapped shapes; > [original->remapped]: (0,4) and requested shape (816,4); >; > It's very strange because before I update some of my packages, I could run; > it it with no problem with the following packages:; >; > scanpy==1.4.1 anndata==0.6.19 numpy==1.16.3 scipy==1.2.1 pandas==0.23.4; > scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1+4.bed07760; > louvain==0.6.1; >; > but after updating some of my packages it was not possible due to that; > error!; >; > scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1; > pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0; > python-igraph==0.7.1+4.bed07760 louvain==0.6.1; >; > Should I roll back to the previous version of annadata or scanpy? has; > anyone ran this feature with my package version with no problems?; >; > Thanks a lot; >; > Here are the packages I use; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/663?email_source=notifications&email_token=ABF37VPMR3WSZT3FIGCFNJ3PXPPJ3A5CNFSM4HP4ASU2YY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GWBCDVA>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABF37VJLTRD6ZHIBLZIRHYLPXPPJ3ANCNFSM4HP4ASUQ>; > .; >. -- . Fidel Ramirez",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/663#issuecomment-496226076:87,down,downgrade,87,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/663#issuecomment-496226076,2,"['down', 'error']","['downgrade', 'error']"
Availability,"The main change here is passing `None` instead of `0` to `total`, right?. Also: this makes some errors with files still existing make much more sense. I had no idea `KeyboardInterrupt` doesn't inherit from `Exception`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1507#issuecomment-733508444:96,error,errors,96,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507#issuecomment-733508444,1,['error'],['errors']
Availability,The max categorical error was one that I thought was addressed by anndata 0.6.18. I assume this is still on 0.6.22rc1? There was previously a switch from defaulting to ordered categoricals to unordered instead. There are quite a few unit tests... but clearly not perfect coverage. Others will be able to say more about the coverage than me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/728#issuecomment-508770744:20,error,error,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728#issuecomment-508770744,1,['error'],['error']
Availability,"The nans (with a proper warning) would be the right way but having data that causes downstream is not an option. As an intermediate solution, I added a note to the docs and made them zeros:; https://github.com/theislab/scanpy/commit/dce2be194a6ff865ecaeb939f3c990f6c3b0e244",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/581#issuecomment-479412666:84,down,downstream,84,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-479412666,1,['down'],['downstream']
Availability,"The only issue I can think of was when I was creating the object. Before I used to transfer the `adata.obs` dataframe to a new one by doing `adata_new.obs = adata_old.obs`. When I did this in `scanpy==1.7.1` the transfer didnÄt show any errors, but it didn't copy. This was fixed when I added the `.copy()` to that command. . When I ran the same thing on a macbook pro, the labels somehow disappeared after calculating highly variable genes. . I have been using this notebook since `scanpy==1.6` and it didn't give me any problems until I upgraded to `scanpy==1.7.1`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1701#issuecomment-787874441:237,error,errors,237,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701#issuecomment-787874441,1,['error'],['errors']
Availability,The only solution so far is to increase the tolerance threshold of the tests! I don't know where those differences come from. Is always a problem. I will be very glad if you find a better solution.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/317#issuecomment-431812136:44,toler,tolerance,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/317#issuecomment-431812136,1,['toler'],['tolerance']
Availability,"The original line was; ```; zero_center = zero_center if zero_center is not None else False if issparse(adata_comp.X) else True; ```; which did the expected thing, @flying-sheep introduced the bug 22 days ago in https://github.com/theislab/scanpy/commit/ce10d02f58c3308b60c23c43a36949b6aeed3ea8. Damn, I wouldn't have expected such a thing in a commit ""improved docs"". It went into release 1.3.4 and 1.3.5... Of course, it's my fault. I should have written a test in the first place. @Koncopd: can you write a test for PCA both for sparse and dense data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/393#issuecomment-446372971:428,fault,fault,428,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/393#issuecomment-446372971,1,['fault'],['fault']
Availability,The package is now available on [pypi](https://pypi.org/project/glmpca/0.1.0/) and there is an [automated test suite](https://github.com/willtownes/glmpca-py/blob/master/tests/glmpca_tests.py).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-541505929:19,avail,available,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/868#issuecomment-541505929,1,['avail'],['available']
Availability,"The problem is not the collapsible thing. I still don't see the images here but only links instead, and when I click on a link e.g. https://user-images.githubusercontent.com/5758119/115158730-f0768a00-a08f-11eb-939a-1b9c35373fae.png I get an error message that the image cannot be displayed because it contains errors. Odd. Maybe it's something weird on my side.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-822059389:242,error,error,242,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-822059389,2,['error'],"['error', 'errors']"
Availability,"The problem is that it does not install at all. ; When I run; ```; conda create -n test; conda activate test; conda install python=3.11; conda install -c conda-forge scanpy; ```; I get an error output for the last line, which is:; ```; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/osx-64::__osx==10.16=0; - feature:|@/osx-64::__osx==10.16=0; - scanpy -> matplotlib-base[version='>=3.4'] -> __osx[version='>=10.12']. Your installed version is: 10.16; ```. Repeating this with python=3.10 does not give an error.; Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```; Collecting numba>=0.41.0; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod; Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:188,error,error,188,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,4,"['Avail', 'error']","['Available', 'error']"
Availability,The remaining failed test is related to matplotlib 3.1.0 and 3d scatter plots. There is a report of a similar error (https://github.com/matplotlib/matplotlib/issues/14298). My suggestion is to wait for those issues to be solved and then upgrade the dependencies.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/661#issuecomment-496144015:110,error,error,110,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-496144015,1,['error'],['error']
Availability,"The same error happens to me, @Blohrer . **Versions:**. > scanpy==1.6.0 anndata==0.7.4 umap==0.4.6 numpy==1.18.5 scipy==1.5.0 pandas==1.0.5 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1295#issuecomment-705222557:9,error,error,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295#issuecomment-705222557,1,['error'],['error']
Availability,"The same error in `sc.pp.highly_variable_genes` can pop up also if you forget to `sc.pp.filter_genes(adata, min_cells=0)` before running normalization and logging. Some informative error messages could for sure save some time here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/763#issuecomment-1137813331:9,error,error,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763#issuecomment-1137813331,2,['error'],['error']
Availability,The same exact error also happens using the docker image suggested on the web site; fastgenomics/scanpy,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/158#issuecomment-390604622:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158#issuecomment-390604622,1,['error'],['error']
Availability,The solution do downgrade to pandas=0.22 worked for me. Thanks,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/158#issuecomment-391277887:16,down,downgrade,16,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158#issuecomment-391277887,1,['down'],['downgrade']
Availability,"The tests have a tolerance parameter that is set high. The problem is that the stripplot shows different results each time. Also, different versions of matplotlib and seaborn have slight differences.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1422#issuecomment-694859994:17,toler,tolerance,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422#issuecomment-694859994,1,['toler'],['tolerance']
Availability,The tolerances need to be tight enough that the tests do anything though …. I’ve seen and fixed quite some tests where the tolerances meant that completely broken output was accepted.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1898157315:4,toler,tolerances,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1898157315,2,['toler'],['tolerances']
Availability,The travis CI failure looks unrelated to this PR.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1828#issuecomment-840023795:14,failure,failure,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1828#issuecomment-840023795,1,['failure'],['failure']
Availability,"The variable folder has one file in .h5ad format as input or raw data. No, I execute the code correctly because every time I run this command or move forward with other commands, the number on the kernel increases without any error message. But in a folder, no object is generated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1795#issuecomment-817693943:226,error,error,226,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795#issuecomment-817693943,1,['error'],['error']
Availability,There is an issue with the new Scipy. `statsmodels` is conflicting with it. Either downgrade scipy or upgrade statsmodels as soon as they fixed it.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/660#issuecomment-495141236:83,down,downgrade,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/660#issuecomment-495141236,1,['down'],['downgrade']
Availability,"There might be couple of things that's available in umap but not in pynndescent such as sparse matrix support https://github.com/lmcinnes/pynndescent/issues/6 Since we typically use PCs, it's mostly fine. But in cases where users do sc.pp.neighbors(., use_rep=""X"") with a sparse adata.X this can be a problem. My 2 cents 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/522#issuecomment-470900854:39,avail,available,39,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522#issuecomment-470900854,1,['avail'],['available']
Availability,There was an issue where values were being set as rgb values unintentionally which should be fixed by #1886. Can you give an example of how this was causing problems? What would cause you to hit errors here?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1884#issuecomment-864681671:195,error,errors,195,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1884#issuecomment-864681671,1,['error'],['errors']
Availability,"There's a possibility of negative values depending on how careful you are with compensation and whether or not you clip values, but at least in my case the counts matrix was always non-negative. **Edit:** But that shouldn't matter because NNDescent is routinely called on PCA-embedded data which is zero centered, right? . If I can find a small subset of the matrix that produces this error reliably, I will share that with the `pynndescent` repo and link back here. Currently that's challenging given the original size of the matrix (a few million observations).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696#issuecomment-802982688:385,error,error,385,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696#issuecomment-802982688,2,"['error', 'reliab']","['error', 'reliably']"
Availability,"There’s a few uses:. 1. Humans. Once you understand the syntax ([very easy](https://docs.python.org/3/library/typing.html), i just get `Generator` wrong all the time) it improves your understanding what a function really accepts and returns; 2. IDEs. They’ll get better when inferring the types of variables and will show you more actual problems in the code and less false positives; 3. Testing. Some projects use mypy to check if all code in your repo typechecks properly, which can be integrated into a test suite; 4. Runtime type checking. Has a performance hit (as said) but given proper type hints, it makes your code safer and the error messages better (“Function blah excepted a parameter foo of type Bar, but you passed a foo of type Baz”). i’m not planning to do 3 and 4 (yet, and probably never)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-441256142:638,error,error,638,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-441256142,1,['error'],['error']
Availability,"There’s two differences:; 1. `np.unique(...)` returns the values sorted, `pd.Series(...).unique()` returns them in original order (this already makes the scores not match). This probably changes the sampling, but I wonder why the score difference is so large here! With only that change, I get:. > Arrays are not equal; >; > Mismatched elements: 2730 / 2730 (100%); > Max absolute difference: 0.22674037; > Max relative difference: 1581.75673912. 2. what you said: The original approach samples from the full list of genes in each bin, then restricts the sample to valid ones. Your approach samples from the valid genes in each bin. So if a bin e.g. contains mostly invalid genes, the original code adds only a few genes for that bin, while yours adds the maximum possible number. So the questions is: is the sampling bias introduced in the original code wanted? If not, you not only made the code more resilient, but also more objective.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2875#issuecomment-1963784907:903,resilien,resilient,903,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2875#issuecomment-1963784907,1,['resilien'],['resilient']
Availability,"This can’t be it, `__init__.py` is [optional since Python 3.3](https://www.python.org/dev/peps/pep-0420/). I also don’t see that import error, `import scanpy` works perfectly. Can you specify how you got that?. ```py; >>> import scanpy, anndata; >>> scanpy.external.tl.palantir(anndata.AnnData()); ImportError: ; please install palantir: . git clone git://github.com/dpeerlab/Palantir.git; cd Palantir; sudo -H pip3 install .; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/585#issuecomment-479508185:136,error,error,136,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/585#issuecomment-479508185,1,['error'],['error']
Availability,"This error happened to me too when working on a small dataset and scoring a single gene with ctrl_size=1. This happens at random in the following line: https://github.com/scverse/scanpy/blob/383a61b2db0c45ba622f231f01d0e7546d99566b/scanpy/tools/_score_genes.py#L168. I was working on a small test dataset with limited features and calling the `score_genes_cell_cycle` function, where only 1 cell cycle gene is left and ctrl_size is set as follows:; https://github.com/scverse/scanpy/blob/383a61b2db0c45ba622f231f01d0e7546d99566b/scanpy/tools/_score_genes.py#L258",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2153#issuecomment-1956738660:5,error,error,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153#issuecomment-1956738660,1,['error'],['error']
Availability,"This error is certainly caused by ""scikit-learn"". I abandoned this conda environment and created a new one by `conda create -n Scanpy -c conda-forge scikit-learn`[https://scikit-learn.org/stable/install.html](url).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2165#issuecomment-1058039729:5,error,error,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165#issuecomment-1058039729,1,['error'],['error']
Availability,"This error message was hard to debug! Indeed it is due to the behavior of `sc.pp.neighbors`. Cells are sometimes given different numbers of neighbors. Sometimes that the errant cells have a number of neighbors greater than zero (unlike as seen in #2244, where the # of neighbors of some cells was 0). My fix builds on the one above and was:; ```; b = np.array(list(map(len, adata_ref.obsp['distances'].tolil().rows))) # number of neighbors of each cell; adata_ref_subset = adata_ref[np.where(b == DEFINED_NEIGHB_NUM-1)[0]] # select only those with the right number; sc.pp.neighbors(adata_ref_subset, DEFINED_NEIGHB_NUM) # rebuild the neighbor graph; ```; ___; @ViriatoII Your comment helped me fix things – but your fix itself didn't work for me. First, when I use `adata_ref = adata_ref[b]`, with `b` defined as above, it interprets `b` not as a boolean mask but as an index, returning a single cell duplicated over and over. I'm not sure what the intended behavior is here. My solution is to use `adata_ref[np.where(b == n_neigh-1)[0]]`. However, this subselection changes the number of neighbors that other cells have. For example, for my data,. ```; b = np.array(list(map(len,adata_ref.obsp['distances'].tolil().rows))); print(""Before subselecting"", np.unique(b, return_counts = True)). adata_ref_subset = adata_ref[np.where(b == DEFINED_NEIGHB_NUM-1)[0]]; c = np.array(list(map(len,adata_ref_subset.obsp['distances'].tolil().rows))); print(""After subselecting"", np.unique(c, return_counts = True)); ```; yields; ```; Before subselecting, (array([13, 14]), array([ 28, 1161359])); After subselecting, (array([10, 11, 12, 13, 14]),; array([ 15, 1, 633, 46, 1160664]))); ```. To solve both problems I needed to rebuild the neighbor graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2085#issuecomment-1382325586:5,error,error,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085#issuecomment-1382325586,2,"['error', 'mask']","['error', 'mask']"
Availability,This feature is not used by pl.umap() or pl.draw_graph(). These functions do not search in the raw and return the error` IndexError: index 0 is out of bounds for axis 0 with size 0` when using gene_symbols that are only present in raw.; Could this feature also be implemented for these funtions?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1277#issuecomment-701367442:114,error,error,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277#issuecomment-701367442,1,['error'],['error']
Availability,"This feature is still in the development version of scanpy, therefore not available in the released scanpy version yet. See https://github.com/theislab/scanpy/issues/560 for more details.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/565#issuecomment-477833445:74,avail,available,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/565#issuecomment-477833445,1,['avail'],['available']
Availability,"This functionality is available through `muon`: https://muon.readthedocs.io/en/latest/api/generated/muon.tl.leiden.html. Sorry for the confusion, but that tutorial is based on a development branch which is out of date and should be taken down. I'm also going to close this issue, since multimodal analysis in general is handled through `muon`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1818#issuecomment-2061253111:22,avail,available,22,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818#issuecomment-2061253111,2,"['avail', 'down']","['available', 'down']"
Availability,"This has been discussed previously: https://github.com/theislab/scanpy/issues/1451, https://github.com/mwaskom/seaborn/issues/1423. I don't think that this sort of normalization is necessarily invalid or wrong, just situational. I also think it makes sense to mimic prior art, and this is how the argument works in seaborn. I do agree that just `x / max(abs(x))` is useful, and more often what people want to use here (if scaling at all). I like suggestion 2. more for this. I would suggest the following api:. ```python; normalization: Optional[Union[str, Callable[np.ndarray, np.ndarray]] (default: None); Normalization to apply to values. Can be selected from ""z-score"", ""minxmax_scale"", etc. or a Callable.; normalization_axis: Literal[""var"", ""group""] (default: ""var""); If a `normalization` is passed, which dimension of the data to normalize along.; ```. It would be nice if the normalization method was mentioned by default in the legend, but that can be difficult with how matplotlib doesn't really do text wrapping with it's notebook backend. Arguably, for `dotplot` `normalization` should be available for both size and color. What to you think @gokceneraslan @fidelram?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1757#issuecomment-804509620:1101,avail,available,1101,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757#issuecomment-804509620,1,['avail'],['available']
Availability,This is all looks fine and should work perfectly. I'd need an example with some data and the lines of code that produce the error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/365#issuecomment-440391801:124,error,error,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/365#issuecomment-440391801,1,['error'],['error']
Availability,"This is great, thanks! Now just for the neighbours `use_hvgs=` parameter and then we're sorted for using HVGs for downstream analysis without filtering the whole dataset.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/284#issuecomment-427676209:114,down,downstream,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/284#issuecomment-427676209,1,['down'],['downstream']
Availability,"This is identical with #2339. The simplest way is to downgrade `python-igraph` to `0.9.9`, https://github.com/scverse/scanpy/issues/2339#issuecomment-1261132252",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2341#issuecomment-1271333881:53,down,downgrade,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341#issuecomment-1271333881,1,['down'],['downgrade']
Availability,"This is mainly a fix for cases when multiple genes have zero variance. The output in that case was that `sc.pp.highly_variable_genes()` failed as the bin boundaries were too close to one another. The error I got is:; ```; ValueError: Bin edges must be unique: array([ -inf, 9.99999996e-13, 9.99999996e-13, 3.71624832e-03,; 4.50723944e-03, 5.04237041e-03, 7.96065722e-03, 9.17631686e-03,; 1.15813100e-02, 1.34968273e-02, 1.62843971e-02, 1.89858746e-02,; 2.27864407e-02, 2.76163086e-02, 3.43018658e-02, 4.27573830e-02,; 5.52219763e-02, 7.87758350e-02, 1.42211060e-01, 3.10728383e+00,; inf]).; You can drop duplicate edges by setting the 'duplicates' kwarg; ```. I figured the best way forward would be to exclude those genes from the function, rather than changing the bins in the `_highly_variable_genes_single_batch()` function with the `duplicates` argument as suggested in the error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/824#issuecomment-529840088:200,error,error,200,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824#issuecomment-529840088,2,['error'],['error']
Availability,"This is not related, and most certainly separate issue. <can start a new thread > ; I am getting memory error with sc.tl.pca; What is your recommendation? . Traceback (most recent call last):; File ""timeseriesScanpy.py"", line 111, in <module>; sc.tl.pca(adata, svd_solver='arpack') # svd_solver='arpack' is important for reproducibility; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 498, in pca; X = adata_comp.X.toarray() # Copying the whole adata_comp.X here, could cause memory problems; File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/compressed.py"", line 1024, in toarray; out = self._process_toarray_args(order, out); File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/base.py"", line 1186, in _process_toarray_args; return np.zeros(self.shape, dtype=self.dtype, order=order); MemoryError",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1193#issuecomment-622663649:104,error,error,104,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193#issuecomment-622663649,1,['error'],['error']
Availability,"This is not the case study code. I think this comes from the PAGA tutorial. So I can't really say whether this is normal. I typically don't have PAGA errors or warnings. . Most of the errors seem to be deprecation warnings, so that should be fine... but the ""finite values"" on posx and posy error I haven't come across. It looks like this is on Windows. Is there a matplotlib issue with windows?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/852#issuecomment-534975285:150,error,errors,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/852#issuecomment-534975285,3,['error'],"['error', 'errors']"
Availability,"This is quite a common error on our internal servers @Hrovatin. I have been getting around it by reading from a different server, and then it just often works. It would be great if you can figure our what the issue might be.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-667898329:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-667898329,1,['error'],['error']
Availability,"This is the error with the development version:. ```; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-36-2ee11f6b7699> in <module>; ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs); 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 733 """"""; --> 734 return embedding(adata, 'pca', **kwargs); 735 ; 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 243 itertools.product(color, idx_components); 244 ):; --> 245 color_source_vector = _get_color_source_vector(; 246 adata,; 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups); 1016 ):; 1017 # We should probably just make an index for this, and share it over runs; -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][; 1019 0; 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key); 4095 if is_scalar(key):; 4096 key = com.cast_scalar_indexer(key, warn_float=True); -> 4097 return getitem(key); 4098 ; 4099 if isinstance(key, slice):. IndexError: index 0 is out of bound",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1277#issuecomment-703912344:12,error,error,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277#issuecomment-703912344,3,"['Down', 'error']","['Downloads', 'error']"
Availability,"This is the origin of the error:. Some of the cells don't have neighbours at the variable adata_ref.obsp['distances'].tolil().rows:. ```; array([list([223, 280, 316, 5791]), list([3877, 5899, 7766, 7807]),; list([165, 304, 423, 713]), ..., list([]),; list([94, 865, 7077, 7666]), list([])], dtype=object); ## (the maximum 4 elements of each list comes from having run sc.pp.neighbors(adata_ref, n_neighbors = 5)) ##; ```. The above array is impossible to stack with np.stack due to the sublists having different lengths. A potential solution might be filtering out those cells without neighbours, though this is suboptimal. I have tried it and new rows remain empty. Only after repeating it a second time, it works:. ```; DEFINED_NEIGHB_NUM =5; sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref, n_neighbors = DEFINED_NEIGHB_NUM ); sc.tl.umap(adata_ref). b = np.array(list(map(len,adata_ref.obsp['distances'].tolil().rows))) == DEFINED_NEIGHB_NUM -1; adata_ref = adata_ref[b]; ```. A better solution would be correcting the Nearest Neighbour assignment so that it doesn't create empty distance lists. Did I understand this correctly?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2085#issuecomment-1104437780:26,error,error,26,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085#issuecomment-1104437780,1,['error'],['error']
Availability,This is the output of `sc.logging.print_versions()`:; ```; scanpy==1.4.3 anndata==0.6.20 umap==0.3.8 numpy==1.16.3 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.21.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1; ``` . Probably downgrading of `scikit-learn` might help?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/666#issuecomment-496828520:235,down,downgrading,235,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/666#issuecomment-496828520,1,['down'],['downgrading']
Availability,"This is updated in the newest version of the module, where it looks for either `tissue_positions.csv` or `tissue_positions_list.csv`. The code on the github project works, but unfortunately the most recent version on PyPi was from Mar 2, 2023. . An easy fix is to download the github project directly, using something like ; `pip install git+https://github.com/scverse/scanpy.git#egg=scanpy`. I did it recently in a Google Colaboratory Notebook with a file with `tissue_positions.csv`, and it worked.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2488#issuecomment-1650697912:264,down,download,264,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488#issuecomment-1650697912,1,['down'],['download']
Availability,"This is what I'm running; ```; bcType = 'NobatchCorr'; sc.pp.normalize_total(adata, target_sum=1e4, exclude_highly_expressed=True, key_added='Norm_Factor'); sc.pp.log1p(adata); adata.raw = adata; sc.pp.highly_variable_genes(adata, n_top_genes=4000, batch_key='batch'); #adata = adata[:, adata.var.highly_variable]; sc.pp.scale(adata, max_value=10); sc.pp.pca(adata, use_highly_variable=True, svd_solver='full', n_comps =n_pcs, random_state=10); sc.pp.neighbors(adata, n_pcs=n_pcs, use_rep='X_pca', random_state=10); sc.tl.umap(adata, random_state=10); sc.tl.leiden(adata,resolution=resolution, key_added=bcType, random_state=10); ```; The code never fails, but Leiden parameters are not present in the adata as it should. Running; ```; sc.pl.umap(adata,color=['overall'], palette=colors_list); ```; gives the above error, but if I comment out ```adata = adata[:, adata.var.highly_variable]``` it works, I'm unsure why atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2330#issuecomment-1249667836:815,error,error,815,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330#issuecomment-1249667836,1,['error'],['error']
Availability,"This looks great!. A few ideas:. * For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above (https://github.com/theislab/scanpy/pull/794#issuecomment-523515331) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap?; * For the string based quantile selection, is there another package which allows writing operations like this? My concern is that string based DSLs can get messy. It would be nice to make sure we're choosing a unambiguous spec which we can extend in the future and use in other functions. An example of a spec would be SQL reduction operations (like `PERCENTILE_DISC`), but hopefully there would be something less verbose.; * For the basis argument, could we not require the key in `obsm` start with `X_`? I'm thinking the key would just go through a check like:. ```python; if basis in adata.obsm:; basis_key = basis; elif f""X_{basis}"" in adata.obsm:; basis_key = f""X_{basis}""; else:; raise KeyError(; f""Could not find entry in `obsm` for '{basis}'.\n""; f""Available keys are: {list(adata.obsm.keys())}.""; ); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/794#issuecomment-523732596:1245,Avail,Available,1245,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794#issuecomment-523732596,1,['Avail'],['Available']
Availability,This looks like an bug in the most recent release of `louvain`. Try downgrading?. I would also recommend using `leiden` clustering instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1191#issuecomment-622229246:68,down,downgrading,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191#issuecomment-622229246,1,['down'],['downgrading']
Availability,"This looks like an issue with `mnn_correct` , and is probably more appropriate for that repo (https://github.com/chriscainx/mnnpy). I would note that on my end I'm able to replicate the warnings but not the error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1167#issuecomment-615006407:207,error,error,207,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167#issuecomment-615006407,1,['error'],['error']
Availability,"This looks really cool. I don't see how this is a solution to the many groups issue though. Especially as you'd likely have the densities of many groups overlapping in the same area. Otherwise, I don't really know of a heuristic to assess whether the kde is reliable. I am okay with removing the 10 groups threshold and just letting the user deal with the mess... but maybe that's not the kindest thing to do. This is essentially a discussion of flexibility vs ease-of-use. Might merit a more principled discussion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/719#issuecomment-560101154:258,reliab,reliable,258,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/719#issuecomment-560101154,1,['reliab'],['reliable']
Availability,"This seems to have something to do with not being able to estimate the variance within a group. If you add thes lines:; ```; adata.X[0,:] = np.array([1.,1.,1.]); adata.X[11,:] = np.array([1.,1.,1.]); ```; to your data, then it works as expected. I assume this is due to `NaN` being set to 1 in the p-value calculation. The t-test isn't defined in this case. Not sure what the error for `""logreg""` is though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/620#issuecomment-486582258:376,error,error,376,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/620#issuecomment-486582258,1,['error'],['error']
Availability,"This solves the problem with PYTHONPATH approach (without flit). The problem with flit is:; I didn't want to create a new environment or get my conda packages accidentally replaced by installations from pip, so i tried; `flit install --deps none -s` and `flit install --pth-file --deps none` and received the same error after running `conda list`.; It has been reported [here](https://github.com/conda/conda/issues/9074) already. Yes, it has dist-info there. Importing works fine with the flit installed packages, but i also want to be able to use `conda list`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1378#issuecomment-675477069:314,error,error,314,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1378#issuecomment-675477069,1,['error'],['error']
Availability,"This works with a non-backed adata, this works:. ```python; sc.pl.pca(adata[:, :5], color=""0""); ```. I'm not totally sure what exactly the other backed modes are supposed to do (especially when called instantiated by `read`, but none of them work either. `r`, `r+`, and `a` return similar errors, while `x`, `w`, and `w+` don't work, but that's because the file exists.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/263#issuecomment-421872224:289,error,errors,289,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/263#issuecomment-421872224,1,['error'],['errors']
Availability,"This would be very easy to implement with: `sc.get.obs_df(adata, keys)`. That would not solve the problem of (I believe) constant genes giving errors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/492#issuecomment-766321134:143,error,errors,143,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492#issuecomment-766321134,1,['error'],['errors']
Availability,"Three things:. 1. If that is a feature, then this is a bug (runs without error):. ```python; import numpy as np; import scanpy as sc; import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 10))); sc.pp.pca(adata); ```. 2. Defaults should work without tuning.; 3. > I feel as though changing the default to match the setting can be dangerous as may not recall how many PCs were used then. Given that I'm running `sc.pp.pca` without setting `n_comps`, I contend that the average user does not remember what the default value is. It would make more sense in both cases (`n_features <= n_comps` and `n_samples <= n_comps`) to throw a warning and set n_comps to the maximum allowable value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1051#issuecomment-586479275:73,error,error,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051#issuecomment-586479275,1,['error'],['error']
Availability,"To answer the following question:. > 2. what you said: The original approach samples from the full list of genes in each bin, then restricts the sample to valid ones. Your approach samples from the valid genes in each bin.; >; > So if a bin e.g. contains mostly invalid genes, the original code adds only a few genes for that bin, while yours adds the maximum possible number.; >; > So the questions is: is the sampling bias introduced in the original code wanted? If not, you not only made the code more resilient, but also more objective. After going through the original [code from Seurat](https://github.com/satijalab/seurat/blob/c54e57d3423b3f711ccd463e14965cc8de86c31b/R/utilities.R#L280C3-L303), it seems to me that there's not equivalent to removing genes to be scored from the control gene set.; From what I can tell, if one of the genes to be scored happens to be chosen as the background, it will be included in the calculation.; But please correct me if that's not the case. So if the original implementation does not remove score genes from the control gene set, we would simply need to remove the following line: https://github.com/scverse/scanpy/blob/ec4457470618efd85da3c7b29f951cab01a49e3a/scanpy/tools/_score_genes.py#L169. (Note: if we want to keep the current behaviour, we should still remove the line above, since it would be redundant)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2875#issuecomment-2015316358:505,resilien,resilient,505,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2875#issuecomment-2015316358,2,"['redundant', 'resilien']","['redundant', 'resilient']"
Availability,"To make you reproduce my error, here is what I did with a Docker image:. 1. `singularity -d build sc_velocyto0.17.17_scannpy1.6.0_scvelo0.2.2.img docker://xie186/scrna_tutorial:0.1.0`. 2. sudo ufw allow 8689. 3. `singularity run --nv sc_velocyto0.17.17_scannpy1.6.0_scvelo0.2.2.img jupyter-lab --ip=<your_ip> --port=8689 --no-browser `. Then in browser, open '<your_ip>:8689' and run the code below in jupyterlab. . The data and code I ran is shown as below:. * Go to: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE132188. * Search ""GSE132188_RAW.tar"". * Download the file.; Uncompress the files:. ```; tar xvf GSE132188_RAW.tar; ```; You will get the following files.; ```; GSM3852752_E12_5_counts.tar.gz; GSM3852753_E13_5_counts.tar.gz; GSM3852754_E14_5_counts.tar.gz; GSM3852755_E15_5_counts.tar.gz; ```; Uncompress: ; ```; mkdir -p E12_5_counts/; tar zxvf GSM3852752_E12_5_counts.tar.gz --directory E12_5_counts/; mkdir -p E13_5_counts/; tar zxvf GSM3852753_E13_5_counts.tar.gz --directory E13_5_counts/; mkdir -p E14_5_counts/; tar zxvf GSM3852754_E14_5_counts.tar.gz --directory E14_5_counts/; mkdir -p E15_5_counts/; tar zxvf GSM3852755_E15_5_counts.tar.gz --directory E15_5_counts/; ```. Code:. ```; import numpy as np; import matplotlib.pyplot as pl; import numpy as np; import scanpy as sc; import scanpy.external as sce; import pandas as pd; from anndata import AnnData; import seaborn as sns; from scipy.sparse import csr_matrix; import networkx as nx; import xlsxwriter; from matplotlib import rcParams; import seaborn as sns; import scipy as sci; #GSEApy: Gene Set Enrichment Analysis in Python.; #import gseapy as gp; sc.settings.verbosity = 3; sc.logging.print_versions(). # Read cellranger files for all four samples; filename = './E12_5_counts/mm10/matrix.mtx'; filename_genes = './E12_5_counts/mm10/genes.tsv'; filename_barcodes = './E12_5_counts/mm10/barcodes.tsv'. e125 = sc.read(filename).transpose(); e125.var_names = np.genfromtxt(filename_genes, dtype=str)[:, 1]; e125",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1409#issuecomment-694668315:25,error,error,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1409#issuecomment-694668315,2,"['Down', 'error']","['Download', 'error']"
Availability,"To see tracebacks, you need to scroll up from the end past the enormous [warnings list](https://dev.azure.com/scverse/scanpy/_build/results?buildId=4765&view=logs&j=50ff7263-9206-5a84-1219-938c9ee7fde7&t=2e49bd34-47bd-5a56-3183-6247e293d44d&l=1951) (I’m working on that), then you see the actual error. ```pytb; E UserWarning: The problem size 5 minus the constraints size 0 is too small relative to the block size 4. Using a dense eigensolver instead of LOBPCG iterations.No output of the history of the iterations. /opt/hostedtoolcache/Python/3.11.6/x64/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/lobpcg/lobpcg.py:493: UserWarning; ```. This test has stared to become flaky some time ago, needs some investigation to make this work reliably again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2739#issuecomment-1803777453:296,error,error,296,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2739#issuecomment-1803777453,2,"['error', 'reliab']","['error', 'reliably']"
Availability,Tried with the group option but got an `Value error: The truth value of a Index is ambiguous.` As I didn't know how to deal with it I just applied the function @LuckyMD posted above and it worked perfectly alright.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/955#issuecomment-897602161:46,error,error,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/955#issuecomment-897602161,1,['error'],['error']
Availability,"Two ideas: ; 1. pass to `embedding` `show=False, save=False` and then call `save_fig_or_show` within `pca` with the user values for `show` and `save`.; 2. allow `embedding` to rename any axis using a parameter like `component_labels`. Thus, this feature is not specific to PCA but also available to any other embedding.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1470#issuecomment-724573518:286,avail,available,286,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470#issuecomment-724573518,1,['avail'],['available']
Availability,"UMAP is a scatterplot, thus the X and Y dimension both carry information, jitter would distort the data (beyond what UMAP already does) ; ; If you're concerned about overplotting, you can try changing the size and alpha or downsampling: ; `sc.pl.umap(adata, size = 5, alpha = 0.5)`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2768#issuecomment-1917783573:223,down,downsampling,223,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2768#issuecomment-1917783573,1,['down'],['downsampling']
Availability,"Um, it wasn't me. ```; CondaHTTPError: HTTP 000 CONNECTION FAILED for url <https://conda.anaconda.org/conda-forge/linux-64/xorg-libxdmcp-1.1.2-h470a237_7.tar.bz2>; ```. Also, downsampling from 3785143 finished after an hour, but definitely had the wrong answer (all counts in one gene). I'm not sure what to make of this, since it's given reasonable results for smaller tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/340#issuecomment-435273679:175,down,downsampling,175,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/340#issuecomment-435273679,1,['down'],['downsampling']
Availability,Update: I was able to get rid of the error by pip installing `dask` manually in my conda environment.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2210#issuecomment-1088508941:37,error,error,37,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2210#issuecomment-1088508941,1,['error'],['error']
Availability,"Update: Nvm, I figured this out. Tt had to do with `qualname_overrides`, which I've updated. <details>; <summary> Old problem </summary>. @flying-sheep, weird sphinx bug I'm running into:. * The readthedocs builds are failing after commit fc83ec3; * The error is:. ```pytb; scanpy/scanpy/external/pp/_bbknn.py:docstring of scanpy.external.pp.bbknn:24: WARNING: py:class reference target not found: sklearn.neighbors._dist_metrics.DistanceMetric; ```. * The error will still occur as long as this has been added:. ```rst; .. plot::; :context: close-figs. >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> sc.tl.umap(adata); ```. * If I remove the `sc.tl.umap` line, the builds work fine, as `sklearn.neighbors.DistanceMetric` resolves and no warning is thrown. For now, I'm going to remove the type annotation from `sc.external.pp.bbknn`, since it's causing the error. Any ideas why calling `sc.tl.umap` means `sklearn.neighbors._dist_metrics.DistanceMetric` can no longer resolve? I assume it has something to do with packages being imported in an unexpected order, but also this is real weird. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1632#issuecomment-775780103:254,error,error,254,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1632#issuecomment-775780103,3,['error'],['error']
Availability,Using RMM works but only to a certain extend. As far as I understand it you can oversubscribe VRAM to a maximum of 2X. If you go above that you’ll get a memory alloc error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1533#issuecomment-1107449372:166,error,error,166,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533#issuecomment-1107449372,1,['error'],['error']
Availability,"Using `adata.T.write_csvs(skip_data=False)` gives you this. If you only want the data matrix, you can also do `adata.to_df().to_csv()` using pandas. The last call will soon be available in a release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/314#issuecomment-431635269:176,avail,available,176,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/314#issuecomment-431635269,1,['avail'],['available']
Availability,"We can compute any kind of residual in principle (NB right now, Poisson + log normal soon) in batchglm, this is also not restricted to categorical covariates and automatically selects whether closed form is available. The implmentation is numerically very stable. I think it could be a potential backend for this, @willtownes?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/868#issuecomment-593266979:207,avail,available,207,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/868#issuecomment-593266979,1,['avail'],['available']
Availability,"We could possibly add another parameter, (`handle_duplicates`, `duplicates_action`?), which could specify how to do this. I think the best default behavior for this is to throw an error. @fidelram, @VolkerBergen what do you think? I know we've been trying to reduce complexity in these methods, so is this worth it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/926#issuecomment-555323780:180,error,error,180,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/926#issuecomment-555323780,1,['error'],['error']
Availability,"We currently distribute `scanpy` through `conda-forge`, so I would recommend using that for up to date versions. Will this still error if you've done that?. Also, it's a little unclear if your session info came from the conda environment you're running into issues with. Is this definitely the case? There shouldn't be that new of releases of scanpy or anndata available through bioconda as far as I know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2172#issuecomment-1063056234:129,error,error,129,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172#issuecomment-1063056234,2,"['avail', 'error']","['available', 'error']"
Availability,"We didn't use the weights in Louvain (https://github.com/theislab/scanpy/blob/297d6246ccfbf398f771cee1bd4b81b57fc27c76/scanpy/tools/_louvain.py#L31)?. Why did you decide to change the default in Leiden; (https://github.com/theislab/scanpy/blob/297d6246ccfbf398f771cee1bd4b81b57fc27c76/scanpy/tools/_leiden.py#L31)? I'm fine with it, but a brief discussion would have been appropriate. :wink:. @LuckyMD; > how different is that to clustering on the UMAP embedding directly?; It's very different. The choice of weights will likely not have a dramatic effect, you're always clustering a graph that proxies neighborhoods in high-dimensional space. If you embed this structure in 2 or 3 d, even if you use the fantastic UMAP for it, you'll make errors (https://twitter.com/falexwolf/status/1108284982001315840). Also, the most computationally intense part is the embedding optimization, not the graph construction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/586#issuecomment-484424732:740,error,errors,740,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/586#issuecomment-484424732,1,['error'],['errors']
Availability,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/517#issuecomment-471465918:327,down,downstream,327,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517#issuecomment-471465918,1,['down'],['downstream']
Availability,"We have a backwards compatibility wrapper, I have no idea how this error can be possible:. https://github.com/theislab/anndata/blob/41eadb2a76d91ae455faf01afd2382143b9af4b2/anndata/_core/anndata.py#L2137-L2140",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1027#issuecomment-587178083:67,error,error,67,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027#issuecomment-587178083,1,['error'],['error']
Availability,"We have a few built in: https://github.com/theislab/scanpy/blob/master/scanpy/datasets/builtin.py. But AFAIK there’s no scRNA-Seq ones that aren’t dynamically downloaded. I think for tests we should add a small built-in one, and make sure it doesn’t end up in the binary wheels when building.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-364159311:159,down,downloaded,159,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-364159311,1,['down'],['downloaded']
Availability,"We just merged an update on the `downsample_counts` function by @ivirshup; evidently, the data type shouldn't be changed by downsampling, should it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-475782293:124,down,downsampling,124,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475782293,1,['down'],['downsampling']
Availability,"We probably have two problems:. 1. CI doesn’t run; 2. Scanpy got harder to use for people. I think the first [is easy to fix](https://github.com/numba/numba/blob/c13c840a8f1f038c1e78472db472a8f19a0bd564/numba/core/config.py#L309): We just `export NUMBA_THREADING_LAYER=workqueue` in our tests. The second is harder, but first I want to note something:. > This was fine in the past, since pynndescent/ umap were forcing a workqueue backend which is always available. I wouldn’t call that situation *fine*, doing things at import time or even just requiring a certain value as configurable global state is bad behavior. This means our solution for the second shouldn’t be that we hardcode a threading layer to use here. We could make it configurable on our end or something, but no import time global state change. #1933 only fixes CI … also bad issue number, yikes!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1931#issuecomment-874649964:455,avail,available,455,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931#issuecomment-874649964,1,['avail'],['available']
Availability,"We ran some data through spaceranger 3.0.1 locally, and in doing so found that 10X have reduced redundancy in the `spatial` folder of the binned outputs by moving the tissue images to a new, central location. This understandably breaks the existing loader. A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument `spaceranger_image_path` to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2992#issuecomment-2230448251:495,robust,robust,495,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992#issuecomment-2230448251,1,['robust'],['robust']
Availability,"We require matplotlib 3.x for other parts of scanpy, so that’s not a real solution. As you can see in the traceback, the error happens in `networkx`. It has been fixed in networkx/networkx#3179 ([networkx 2.3](https://networkx.github.io/documentation/stable/release/release_2.3.html)) in April 2019. So you should upgrade networkx instead of downgrading matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1227#issuecomment-661039650:121,error,error,121,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227#issuecomment-661039650,2,"['down', 'error']","['downgrading', 'error']"
Availability,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1528#issuecomment-743207565:94,down,download,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528#issuecomment-743207565,1,['down'],['download']
Availability,"We should definitely maintain the type in layers, and that means maintaining the type in .X makes sense too. We should also take care not to downcast more incompatible types: int32 can be expressed as float64, but not in float32. int64 has to stay int64.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/865#issuecomment-558138634:141,down,downcast,141,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/865#issuecomment-558138634,1,['down'],['downcast']
Availability,"We were getting a lot of errors from dask tests because they were relying on test helpers from anndata 0.10. It's a small number of functions, but it depends on the types in the compat module so is difficult to copy out. To work around this I've temporarily bumped the minimum required version of anndata up to 0.10, but we definitely shouldn't actually do that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895765916:25,error,errors,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895765916,1,['error'],['errors']
Availability,"We will start to return helpful errors for when we don't support something, and allow currently passing things to continue as such.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3004#issuecomment-2063950003:32,error,errors,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004#issuecomment-2063950003,1,['error'],['errors']
Availability,"Well, I know nothing, maybe you already have everything, but I could; look at an example? The advantage of the expression atlas is that they; have really good meta data. That's provided through their downloadable; files, as far as I remember. So if you got everything that is in their; downloadable meta data files, then you certainly have everything of; interest.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-476556129:200,down,downloadable,200,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476556129,2,['down'],['downloadable']
Availability,"Well, I think it is better to be consistent with the paper [Diffusion pseudotime robustly reconstructs lineage branching](https://www.nature.com/nmeth/journal/v13/n10/full/nmeth.3971.html) since this paper first introduces the diffusion pseudotime concept. In Figure 1 (c) of this paper, there is a _DPT order_. It seems the dpt order in this paper is just a global rank for each individual cell according to their pseudotime. Therefore, I suggest that the adata.smp['dpt_order'] and the one in the figure should have the same meaning, though IMHO dpt_order only matters for cells on the same branch. If we extract cells by their dpt_group, then the dpt_order is still applicable even though it is not continuous now. . In short, I think a dpt_order defined as the global rank by pseudotime like the one in the original paper is more understandable. By the way, if there are multiple branches in the diffusion map, is there some way to assign the cells to a certain branch? That is to say, can we provide an _adata.smp['branch']_ field?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/27#issuecomment-314766836:81,robust,robustly,81,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/27#issuecomment-314766836,1,['robust'],['robustly']
Availability,"Went with properties for everything except private variables. Took a little longer than 10 minutes, but I think it's mostly there. Got all the tests to pass on my machine, but I bet other things will fail. I also haven't tested what'll happen with the docs, though I did have to modify some of the documentation code. * The `verbosity` settings might be trouble. I changed the value again... but this should stop an error I'm getting with bbknn and be consistent with the python logging module. ; * The settings imports are ugly. Wasn't sure how to import a variable from a parent module. Is this possible?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/573#issuecomment-479505756:416,error,error,416,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-479505756,1,['error'],['error']
Availability,What is the content of the variable `folder`? There must be an error message or else you are not executing the code.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1795#issuecomment-817683273:63,error,error,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795#issuecomment-817683273,1,['error'],['error']
Availability,"What is there in the latest update:; - The simple adoption, at the heart of this PR, that `flavor=seurat_v3_paper` matches Seurat better when using `batch_key`.; - The `flavor=seurat_v3` remains untouched, hence not a breaking change.; - The doc is more detailed now. What is not there:; - Refactoring of single vs multi batch. Reason: While this effort will enhance code maintenance, it may quickly require almost the entire _highly_variable_genes.py to be touched. Suggest to do this thorough & separately?; - orthogonality of flavor and ordering. Reason: I think this is very hard to understand and match against other methods for users. . > If it makes sense to offer a common set of orderings for all flavors, it should definitely be a separate option. Does it make sense? There isn't benchmarking literature I know, and the flavors don't offer a decoupled ordering choice themselves. From user issues, I experience the consistency with other tools to be the primary concern.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2792#issuecomment-1919485285:372,mainten,maintenance,372,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2792#issuecomment-1919485285,1,['mainten'],['maintenance']
Availability,"What version of bbknn are you using? I think it might be out of date if you didn't get an error from `save_knn=False`. Also, this works for me:. ```python; import scanpy as sc; import scanpy.external as sce. pbmc = sc.datasets.pbmc68k_reduced(); sce.pp.bbknn(pbmc, batch_key='bulk_labels'); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/770#issuecomment-519007245:90,error,error,90,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770#issuecomment-519007245,1,['error'],['error']
Availability,What version of scanpy are you using? I don't see a function called `_get_color_values` in `scatterplots.py` in the HEAD version. Can you try installing the development version and seeing if you get the same error? The issue might be that the version you are currently using does not include the fix I made above. ```; git clone https://github.com/theislab/scanpy.git; cd scanpy; pip install .; ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1277#issuecomment-703887451:208,error,error,208,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277#issuecomment-703887451,1,['error'],['error']
Availability,"What we're really after is the more general ability to execute different d/e tools without too much extra work, and have the results stored consistently in the annData for whatever downstream applications (plotting or otherwise), or just so that they're available for consumers of our annData objects. But maybe if it's something you guys aren't keen on we can just code it up in our own software layer.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1955#issuecomment-886464475:181,down,downstream,181,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955#issuecomment-886464475,2,"['avail', 'down']","['available', 'downstream']"
Availability,What would be a useful default?. I would assume: Drop identical observations and throw an error if observations with the same ID but different data exist.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/55#issuecomment-354442003:90,error,error,90,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/55#issuecomment-354442003,1,['error'],['error']
Availability,Whats the timeline here? When will there be a release that includes this fix? Or should I downgrade pandas in the meantime?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1015#issuecomment-585115015:90,down,downgrade,90,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1015#issuecomment-585115015,1,['down'],['downgrade']
Availability,"When I did `pip install --user scikit-misc` in my shell and then in python tried the line that errored for you `from skmisc.loess import loess`, everything worked fine for me. Also, depending on how conda is setup `pip install --user` might install it in your home directory, rather than the conda env. So you could also try activating the conda env and then running `pip install scikit-misc --force`. . Can you print out the full traceback of what happens when you run `from skmisc.loess import loess`? If that was causing the `ImportError` it might be easier to see outside of the try/except block. You can also try `import skmisc; print(skmisc.__file__)` to see what that returns. I also see some related issues (https://github.com/has2k1/scikit-misc/issues/12), which could indicate that it did not install correctly because it did not install the cython scripts properly on windows. The solution (install the numpy+mkl .whl first) in https://github.com/has2k1/scikit-misc/issues/4 might work?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340:95,error,errored,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340,1,['error'],['errored']
Availability,"When I input pip show scipy I get:. Name: scipy; Version: 1.4.1; Summary: SciPy: Scientific Library for Python; Home-page: https://www.scipy.org; Author: None; Author-email: None; License: BSD; Location: /home/ubuntu/.local/lib/python3.6/site-packages; Requires: numpy; Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata; You are using pip version 18.0, however version 20.2b1 is available.; You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:; Name: scanpy; Version: 1.5.1; Summary: Single-Cell Analysis in Python.; Home-page: http://github.com/theislab/scanpy; Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrés R. Muñoz-Rojas; Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de; License: BSD; Location: /home/ubuntu/.local/lib/python3.6/site-packages; Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata; Required-by: ; You are using pip version 18.0, however version 20.2b1 is available.; You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user; when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct vers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1252#issuecomment-635681942:474,avail,available,474,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252#issuecomment-635681942,1,['avail'],['available']
Availability,"When I read. > like Union[OrderedDict, pd.Series], this is a fine substitute for Intersect[Mapping, Sequence]. in the context of. > An example I could think of is needing key value lookup which is also ordered could be thought of as the intersection of Mapping and Sequence types. then `Intersect[Mapping, Sequence]` expects a new ""intersection object"" (here just an `OrderedDict`), which is to me an ""intersection way"" of subclassing - and the first is `OneOf`. So these are different things. My point is (repeating what Philipp said): in practice (in all the numerical stuff that I've done so far, including Scanpy), I have never encountered the need for defining such an intersection object on the typing level. I just overload functions using `OneOf` and account for differences in the passed objects attributes via `if isinstance(...):`... If I need a function that only eats a ""weird intersection type object"", I'll go and define the corresponding class and throw an error if the function gets fed something different. Fortunately, that happens quite rarely; but yeah, I had cases where I only wanted an `OrderedDict` but neither a `dict` or a `list`. But I'd never call this an ""intersection type"". @ivirshup You didn't explain the ""type lattice"": but according to what I learned about `Union` and `Intersection` in this thread, the sets involved in the mentioned ""set operations on the type lattice"" should have elements that are ""properties"" of types (as they are not restricted to actual class attributes, this, unfortunately, doesn't tell you right away which ""property"" you are intersecting: ""being ordered"", ""having a key accesor"", ""having a certain numerical range""). Right? Union and Intersection then refer to the maximal set of properties of the objects you pass. As each passed object can be characterized by a set of properties, all that naming makes sense. But for someone reading the docs, who isn't expected to know about all the properties of all each object that comes along th",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/373#issuecomment-443966884:973,error,error,973,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/373#issuecomment-443966884,1,['error'],['error']
Availability,"When I run sc.rank_genes_groups() on my gene expression data, I do get separate matrices for names, scores, pvals, and pvals_adj. However, the scores don't match the pvals. In other words, with decreasing pvals, we don't always have increasing score. I did check out the description on the main documentations page, and they say they're calculating the zscores underlying the distribution, however if that's the case shouldn't it always be higher with decreasing pval? Also, I went through the code: it looks like they're calculating the scores on the absolute values instead of the real values--why is this? Are the scores basically U1 values corresponding to the pvalues, in whcih case once again lower pvalues should always have higher scores right?; ares calculated from the p-values? What'e the relation between the two. I have ran sc.rank_genes_groups() on my gene expression data, and I have generated the matrix for cluster-1 versus the rest, for reference. You can see that one, the pavlues don't increase as we go down the rows; and two, the scores seem kinda arbitrary to the p-values. What am I missing here? Thanks a lot, and sorry for the wordy question. [ClusterOneVsRest.csv](https://github.com/scverse/scanpy/files/12242378/ClusterOneVsRest.csv)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/701#issuecomment-1662515521:1024,down,down,1024,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/701#issuecomment-1662515521,1,['down'],['down']
Availability,"When using **scanpy.pl.paga_path**, I experience the same error as @plrlhb12 (TypeError: **float() argument must be a string or a number, not 'csr_matrix'**) and I can also only generate a plot after deleting adata.raw. As a consequence, I can only plot genes that are filtered for high variability during preprocessing and still present in adata.var.gene_ids. ; I would be glad if there was a way to make it work without deleting adata.raw and therefore being able to plot also non-highly variable genes! Thank you!. **Versions:**; > anndata==0.7.4 matplotlib==3.3.0 numpy==1.19.1 pandas==1.1.0 scanpy==1.6.0 scipy==1.5.2 sklearn==0.23.1 igraph==0.8.2 leidenalg==0.8.1 umap==0.4.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1295#issuecomment-690431766:58,error,error,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1295#issuecomment-690431766,1,['error'],['error']
Availability,Which server do you suggest? - I had tried a couple with no success. I am having a lot of trouble with it - I am getting errors when reading different parts of the file - even when trying to use just h5py.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-667921094:121,error,errors,121,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-667921094,1,['error'],['errors']
Availability,"While the single command works `adata = adata[adata[: , 'A'].X > 1, :]`. The compound command gives me the following error: ; TypeError: unsupported operand type(s) for &: 'SparseCSRView' and 'SparseCSRView'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1870#issuecomment-1058394641:117,error,error,117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1870#issuecomment-1058394641,1,['error'],['error']
Availability,"With pandas 1.3.4 and 1.3.3. * I can't replicate the initial issue; * I can replicate @michalk8's example. This looks very upstream in pandas. I will try and submit an issue/ check that this hasn't been reported to pandas already tomorrow. This may be a kinda easy fix (e.g. check value shape better during column assignment in pandas), but it can take a bit to figure out how to fix things there. AFAIK, we removed calls in scanpy which assigned (n x 1) matrices to pandas because of related, non-formatting error. Is the current scanpy release assigning these matrices anywhere?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2008#issuecomment-948025046:509,error,error,509,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008#issuecomment-948025046,1,['error'],['error']
Availability,"With respect to the heatmap, indeed it is possible to transpose the matrix.; Currently, this option is only available for `stacked_violin`. I thought; about adding this option to other plots like heatmap, matrixplot and; dotplot but I have not find the time and it is always possible to save the; figure and rotate it so it has low priority for me. The changes are not as; trivial as simply rotating the matrix as all other elements need to be; adjusted. On Wed, Nov 7, 2018 at 3:03 AM Alex Wolf <notifications@github.com> wrote:. > @fidelram <https://github.com/fidelram> should be the expert for this...; > 😄; >; > —; > You are receiving this because you were mentioned.; >; >; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/349#issuecomment-436477272>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1b_dlMN1mihuJIbXg2lPmMJvgqGgks5usj-FgaJpZM4YRQ7g>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/349#issuecomment-436548839:108,avail,available,108,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/349#issuecomment-436548839,1,['avail'],['available']
Availability,"Would be good to know if there's any nice tooling around this, as this could make fixtures and parametrized tests a bit difficult. For example, not installing `dask` makes test collection fail in the `test_normalization.py` file. <details>; <summary> Error </summary>. ```pytb; _______________________ ERROR collecting scanpy/tests/test_normalization.py ________________________; ImportError while importing test module '/Users/isaac/github/scanpy/scanpy/tests/test_normalization.py'.; Hint: make sure your test modules/packages have valid Python names.; Traceback:; ../../miniconda3/envs/scanpy-minimal/lib/python3.9/importlib/__init__.py:127: in import_module; return _bootstrap._gcd_import(name[level:], package, level); scanpy/tests/test_normalization.py:5: in <module>; import dask.array as da; E ModuleNotFoundError: No module named 'dask'; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088611630:251,Error,Error,251,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211#issuecomment-1088611630,2,"['ERROR', 'Error']","['ERROR', 'Error']"
Availability,"Would love to starting November, ping me if thats still relevant",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2288#issuecomment-1233188895:33,ping,ping,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2288#issuecomment-1233188895,1,['ping'],['ping']
Availability,"Would you mind reading through the link I sent and cutting this back?. This doesn't fit the ""reproducible"" criteria (I don't have that data file), and I'm not sure which line actually causes the error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/567#issuecomment-478795943:195,error,error,195,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/567#issuecomment-478795943,1,['error'],['error']
Availability,"Yeah agree this is inconsistent, I'd say we should either correct the documentation + throw an error when the wrong argument is passed, or implement the matplotlib options. @ivirshup what do you think?. In [_anndata.py](https://github.com/scverse/scanpy/blob/11d0b8e992ad145eeb3f666aa4e006bd204272de/scanpy/plotting/_anndata.py#L38-L54) plotting script, VALID_LEGENDLOCS is set (not sure in which plotting functions that is eventually used), could we use something similar for the above example?; ```python; VALID_LEGENDLOCS = {; 'none',; 'right margin',; 'on data',; 'on data export',; 'best',; 'upper right',; 'upper left',; 'lower left',; 'lower right',; 'right',; 'center left',; 'center right',; 'lower center',; 'upper center',; 'center',; }; ```; Also related to issue #2322",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2229#issuecomment-1256989255:95,error,error,95,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2229#issuecomment-1256989255,1,['error'],['error']
Availability,"Yeah, I was thinking even an error. Something that says ""this operation doesn't really make sense with genes with no counts, so we're doing {}"". On the other hand, I figure you can't go that wrong just doing what `sklearn` does, which is zeroes. For sure! I'm trying to remember why I went with pbmc3k in the first place. I think I was getting a failure for pbmc3k but not the smaller one? In any case, this should be covered by `test_pbmc3k.py` notebook now. Two quick related asides:. * It would be good to have tests that actually hit the parts of `neighbors` where non-pairwise distances are found (>4096 cells I think). ; * I've been pretty successful at speeding up the tests by just running them in parallel. Stuff like this might be good to have in some dev docs. Is there a place for that kind of thing right now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/581#issuecomment-479438348:29,error,error,29,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/581#issuecomment-479438348,2,"['error', 'failure']","['error', 'failure']"
Availability,"Yeah, it's not working . Here https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.violin.html they say; > Wraps [seaborn.violinplot()](https://seaborn.pydata.org/generated/seaborn.violinplot.html#seaborn.violinplot) for [AnnData](https://anndata.readthedocs.io/en/stable/generated/anndata.AnnData.html#anndata.AnnData). but when you add `orient='h'` or `orient='v'` to the `sc.pl.violin` run, it fails wit this error:; ```; TypeError: seaborn.categorical.violinplot() got multiple values for keyword argument 'orient'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2092#issuecomment-1513930164:419,error,error,419,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2092#issuecomment-1513930164,1,['error'],['error']
Availability,"Yeah, so this is not a bug. It's just that there is no HVG that is shared between all of your batches. I would suggest selecting the number of HVGs that are shared by all batches but 1, and then go down to all batch but 2 if you want more HVGs. For example:; `adata.var['highly_variable'] = adata.var['highly_variable_nbatches'] == adata.obs.batch.nunique()-1`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/935#issuecomment-559552890:198,down,down,198,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/935#issuecomment-559552890,1,['down'],['down']
Availability,"Yeah, two out of three of the HPCs I have access to don't make using a jupyter server particularly easy (one corporate firewall, one government). I use that with the other one, but it's down this week 😢",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/263#issuecomment-422629703:186,down,down,186,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/263#issuecomment-422629703,1,['down'],['down']
Availability,"Yes I am still getting this error, my version of anndata==0.7.1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1114#issuecomment-615097979:28,error,error,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114#issuecomment-615097979,1,['error'],['error']
Availability,"Yes, I'll send an example in a bit, recovered variable genes seem wildly discrepant. I can get to this tomorrow! Thanks for your quick response",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2780#issuecomment-1865046956:36,recover,recovered,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2780#issuecomment-1865046956,1,['recover'],['recovered']
Availability,"Yes, agreed. I was only talking about consistency between the raised error and docs. And yes, will open a PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2128#issuecomment-1027896930:69,error,error,69,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2128#issuecomment-1027896930,1,['error'],['error']
Availability,"Yes, it should work without downgrading.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1313#issuecomment-656362456:28,down,downgrading,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1313#issuecomment-656362456,1,['down'],['downgrading']
Availability,"Yes, one could think about doing it that way. I had in mind slowly transitioning to notebooks that download data and run through automatically. One can build docs with them https://nbsphinx.readthedocs.io and possibly use them for testing. In these notebooks, there won't be any images... so it would be fine to add them to the scanpy repo. It's essentially the same thing as in the numpy etc. tutorials... only that not writing this in .rst but in notebook form gives the user the neat feature of being able to download an executable notebook. For now, everything is built via https://nbviewer.jupyter.org/. Maybe you haven't yet realized the new layout of https://scanpy.readthedocs.io/en/latest/examples.html... But this is still too manual... No hurry with these things, though...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/74#issuecomment-364063478:99,down,download,99,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74#issuecomment-364063478,2,['down'],['download']
Availability,"Yes, sorry, that was my fault. Rerunning the tests for this PR",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/791#issuecomment-523152544:24,fault,fault,24,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/791#issuecomment-523152544,1,['fault'],['fault']
Availability,"Yes, the 'leiden_colors' field in `.uns` will only be updated if needed, i.e., if the number of categories in the `leiden` field in `.obs` exceeds the number of available colors. As Fidel mentions, passing `palette` will automatically trigger resetting the colors according to the chosen palette.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/420#issuecomment-453700295:161,avail,available,161,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/420#issuecomment-453700295,1,['avail'],['available']
Availability,"Yes, this is related to the fact that `sanitize_anndata` cannot be meaningfully applied to a view of `AnnData`. You're right that one should also account for this case... I'll give it a thought. At least there should be a proper error hinting people to call `sc.utils.sanitize_anndata` when trying the call you mention. Thank you very much for pointing this out. :smile: It should have happened also before version 1.1, though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/166#issuecomment-393834418:229,error,error,229,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166#issuecomment-393834418,1,['error'],['error']
Availability,"Yes, this was my impression too. However there is a documented option; ""Switch to Windows containers"" which is available if you right click on the; Docker icon in the taskbar and this allows one to run vms using a Windows; kernel. On Fri, Sep 6, 2024, 3:36 AM Philipp A. ***@***.***> wrote:. > If you want to try it out, I give instructions for how to reproduce the; > error with a Docker container for Windows in the cross-referenced issue; >; > Yes please. I’m confused how Windows comes into play though since I thougt; > that Docker always runs on a Linux kernel – natively on Linux and in a VM; > on macOS and Windows.; >; > —; > Reply to this email directly, view it on GitHub; > <https://github.com/scverse/scanpy/issues/2969#issuecomment-2333436219>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AH2OS47KNFAVTYUHGAMORILZVFLRXAVCNFSM6AAAAABFM3NQROVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGMZTGQZTMMRRHE>; > .; > You are receiving this because you were mentioned.Message ID:; > ***@***.***>; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2969#issuecomment-2334006260:111,avail,available,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969#issuecomment-2334006260,2,"['avail', 'error']","['available', 'error']"
Availability,"Yes, we already have a good mask for sparse scaling. Boolean arrays are very effective for indicating where computations should be performed, as they eliminate the need for copying and reintegration. One clear example is the `tl.score_genes` function. masks there as booleans for the nanmean is a lot more efficent but less pythonic",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2234#issuecomment-2311895711:28,mask,mask,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234#issuecomment-2311895711,2,['mask'],"['mask', 'masks']"
Availability,"Yes, you have the choice of either having 'gene_symbols' as your index or 'gene_ids', what is not in the index is available as a column in `.var`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/382#issuecomment-443398154:114,avail,available,114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/382#issuecomment-443398154,1,['avail'],['available']
Availability,"Yes. I'm interested in many of the things here. Thank you for pinging me. I'm happy to engage going forward in a variety of ways. Let's start with a few responses. > I tried looking at pydata sparse with Dask, but it ran a lot slower than regular scipy.sparse (which is what Scanpy uses). It would be great to get a slimmed down version of the operations that you're running with pydata/sparse and submit those to the issue tracker there. @hameerabbasi is usually pretty responsive, and I know that he appreciates learning about new use cases of pydata/sparse. > So I wrote a wrapper around scipy.sparse to implement NumPy's __array_function__ protocol. This allows sparse arrays to be chunks in a Dask array. This approach seemed promising, with basic operations able to take take advantage of multiple cores and run faster than regular scipy.sparse. Thoughts on adding this to scipy.sparse itself so that we can avoid the wrapper? cc @rgommers. > It turned out that by using Anndata arrays, Dask has to materialize intermediate data more than is necessary in order to populate the Anndata metadata. This is because the way Anndata works means that its metadata must be computed eagerly after each operation in the Zheng17 recipe, rather than lazily for the whole computation (which is the way Dask works). Another option would be to see if you can swap out Anndata for Xarray. This is a big change obviously, and probably pretty disruptive to the existing codebase, but it would align you with many other software projects and scientific communities that are currently thinking about these exact same problems. My guess is that in the long run it would save you time, assuming that Xarray DataArrays meet your needs semantically. > Many operations work, however cupyx.scipy.sparse has a number of missing features that mean it can’t be used for Zheng17 yet. It would require significant work in CuPy to get it working:. I could imagine that these might be in scope for NVidia folks to work on in a f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/921#issuecomment-557191880:62,ping,pinging,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/921#issuecomment-557191880,2,"['down', 'ping']","['down', 'pinging']"
Availability,"You can check if the mirror is working by using the url:. http://<ensembl_biomart_mirror>/biomart/martview. This is the url used internally by bioservices. The available mirrors are listed [here](http://www.ensembl.org/info/about/mirrors.html). For example, at the moment the mirror useast is not available. > Service Temporarily Unavailable; > The server is temporarily unable to service your request due to maintenance downtime or capacity problems. Please try again later. I think we can close this issue since it's not related to the scanpy's code.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/242#issuecomment-456889768:160,avail,available,160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/242#issuecomment-456889768,4,"['avail', 'downtime', 'mainten']","['available', 'downtime', 'maintenance']"
Availability,"You can interchange the cluster order (reference with the cluster your intersted in) and get only-upregulated ones for the inverted comparison (hence down-regulated genes) or set `rankby_abs` to `True`, which will then give you down-regulated genes in addition to up-regulated ones.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/625#issuecomment-487175852:150,down,down-regulated,150,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/625#issuecomment-487175852,2,['down'],['down-regulated']
Availability,"You can’t supply a string here, as mentioned in the docstring:. > `root`: If choosing a tree layout, this is the index of the root node or a list of root node indices. If this is a non-empty vector then the supplied node IDs are used as the roots of the trees (or a single tree if the graph is connected). If this is `None` or an empty list, the root vertices are automatically calculated based on topological sorting. @falexwolf the code for the error indicates that supplying a string is intended, but not properly implemented. I quickly whipped up #910, please finish it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/909#issuecomment-551772902:447,error,error,447,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/909#issuecomment-551772902,1,['error'],['error']
Availability,You could just output `NaN` for all genes that were masked? That would be accurate as the test would fail in that case anyway. That should solve `n_genes == adata.n_vars`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/629#issuecomment-489134176:52,mask,masked,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/629#issuecomment-489134176,1,['mask'],['masked']
Availability,"You could use conda ([relevant docs](https://scanpy.readthedocs.io/en/stable/installation.html#bioconda)). Not having a GUI shouldn't matter, but I'm not sure if Tkinter is an installation dependency for `matplotlib`. If you're getting an error related to an interactive backend when you try to plot, you can switch the [matplotlib backend](https://matplotlib.org/faq/usage_faq.html#what-is-a-backend).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/595#issuecomment-480657396:239,error,error,239,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/595#issuecomment-480657396,1,['error'],['error']
Availability,"You don't have to use HVGs for downstream analysis, but it is typically done for two reasons (at least):; 1. Using fewer genes is computationally less expensive for downstream analysis.; 2. The signal-to-noise ratio is better with highly variable genes than in the full gene set. The second point is usually particularly important, as even if one single gene doesn't contribute as much to the PCA if it has lower variance, if you have 15000 low-variance genes this does affect the embedding. If you'd like a rationale for why HVGs are used, please see our [best-practices review](http://msb.embopress.org/lookup/doi/10.15252/msb.20188746)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1578#issuecomment-759366430:31,down,downstream,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1578#issuecomment-759366430,2,['down'],['downstream']
Availability,"You just saw in your output line [7], that you get back a tuple from `mnn_correct()`. This is also what it says in the error you get. Thus, `adata[0]` is your anndata object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/873#issuecomment-544365236:119,error,error,119,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/873#issuecomment-544365236,1,['error'],['error']
Availability,"Your approach won’t work, since `test_pca_warnings` discards all our testing filters. What we had does work. PS: the comment “We explicitly handle these errors in tests” applies to the whole block of filters below, so please don’t insert `ignore` filters into that block.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2905#issuecomment-1997139220:153,error,errors,153,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2905#issuecomment-1997139220,1,['error'],['errors']
Availability,"You’re right! I wasn’t aware of PEP 508. The build appears to fail [here](https://travis-ci.org/theislab/scanpy/jobs/550248884#L285), but actually fails much later, due to numpy/numpy#13790. I filed pypa/pip#6651 to deal with the error being unclear.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/704#issuecomment-505780384:230,error,error,230,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/704#issuecomment-505780384,1,['error'],['error']
Availability,"ZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; 12 warnings and 3 errors generated.; error: command '/usr/bin/clang' failed with exit code 1; [end of output]; ; note: This error originates from a subprocess, and is likely not a problem with pip.; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Attempting uninstall: fa2; Found existing installation: fa2 0.3.5; Uninstalling fa2-0.3.5:; Successfully uninstalled fa2-0.3.5; Running setup.py install for fa2 ... error; error: subprocess-exited-with-error; ; × Running setup.py install for fa2 did not run successfully.; │ exit code: 1; ╰─> [212 lines of output]; Installing fa2 package (fastest forceatlas2 python implementation); ; >>>> Cython is installed?; Yes; ; >>>> Starting to install!; ; running install; running build; running build_py; creating build; creating build/lib.macosx-12.3-x86_64-3.10; creating build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/fa2util.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/__init__.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/forceatlas2.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; running egg_info; writing fa2.egg-info/PKG-INFO; writing dependency_links to fa2.egg-info/d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:16914,ERROR,ERROR,16914,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,1,['ERROR'],['ERROR']
Availability,[ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1809,ERROR,ERROR,1809,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,[ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1956,ERROR,ERROR,1956,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2688,ERROR,ERROR,2688,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2397,ERROR,ERROR,2397,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2250,ERROR,ERROR,2250,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3567,ERROR,ERROR,3567,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:2835,ERROR,ERROR,2835,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3276,ERROR,ERROR,3276,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,[ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-Fals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3129,ERROR,ERROR,3129,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,"[Here are the specific lines for their cluster ordering](https://github.com/GreenleafLab/ArchR/blob/6765ad962d4d8dcb292a326071c9b5c30c25918e/R/Clustering.R#L368-L383). They do a hierarchical clustering on the mean position of each cluster in the reduced dimensional space. We don't necessarily have access to that space (which may not even exist, e.g. BBKNN graph) at clustering time so we can't use this exact method. ### Current thoughts. My preferences in APIs lean towards modularity and shallowness. I like that the `leiden` function pretty much only computes `leiden` clusters, nothing else. I don't love the idea of adding complexity or computation on top of that. I also think ""gives better label orderings"" is a vague target which is hard to have meaningful tests for, so can be difficult to support. I think this would be a little convenient, but I don't see it being very convenient. I would like to hear if other people would really like this feature. At the moment, I don't think it's utility outweighs it's downsides to me. What I would be more for is some sort of `relabel_clusterings` utility function, which just does the relabelling and could have multiple ways of doing so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2016#issuecomment-948076348:1021,down,downsides,1021,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2016#issuecomment-948076348,1,['down'],['downsides']
Availability,"[Here's the `AnnData` object](https://cloudstor.aarnet.edu.au/plus/s/oYjEB26gWJdaA4R) which will reproduce the error if you call: `sc.tl.dpt(adata, n_branchings=N)` where N > 3. @falexwolf, maybe you could help with diagnosis here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/749#issuecomment-635762909:111,error,error,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749#issuecomment-635762909,1,['error'],['error']
Availability,"[The documentation for `AnnData.write_csvs`](https://anndata.readthedocs.io/en/latest/anndata.AnnData.write_csvs.html) tells you. > It is not possible to recover the full AnnData from the output of this function. Use write() for this. Sorry for that! We thought that not having a function to read back those CSVs, we won’t lull people into the false security that the AnnData object can be safely restored from CSVs. But if you have nothing else but those files, you can of course try to use [`pandas.read_csv`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) to read the `.obs` and `.var` dataframes and do something like. ```py; adata = AnnData(; pd.read_csv('output/X.csv').asarray(),; pd.read_csv('output/obs.csv'),; pd.read_csv('output/var.csv'),; { # adata.uns; 'some_thing': pd.read_csv('output/some_thing.csv'),; },; pd.read_csv('output/obsm.csv'),; pd.read_csv('output/varm.csv'),; ); ```. You might have to fiddle with parameters to `pandas.read_csv`, like `index_col`, and obsm/varm might not be able to be specified as data frames.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/399#issuecomment-447793340:154,recover,recover,154,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/399#issuecomment-447793340,1,['recover'],['recover']
Availability,[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_compare - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:47371,Error,Error,47371,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"\roaming\python\python38\site-packages (0.1.4); Requirement already satisfied: numpy in c:\users\park_lab\anaconda3\envs\python38\lib\site-packages (from scikit-misc) (1.20.3); ```; Step2: force install.; ```python; (Python38) C:\WINDOWS\system32>pip install scikit-misc --force; Collecting scikit-misc; Using cached scikit_misc-0.1.4-cp38-cp38-win_amd64.whl (142 kB); Collecting numpy; Downloading numpy-1.21.5-cp38-cp38-win_amd64.whl (14.0 MB); |████████████████████████████████| 14.0 MB 3.3 MB/s; Installing collected packages: numpy, scikit-misc; Attempting uninstall: numpy; Found existing installation: numpy 1.20.3; Uninstalling numpy-1.20.3:; Successfully uninstalled numpy-1.20.3; ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\Users\\Park_Lab\\anaconda3\\envs\\Python38\\Lib\\site-packages\\~umpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll'; Consider using the `--user` option or check the permissions.; ```; Step3: same errors.; ```python; sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3'); sc.pl.highly_variable_genes(adata); ImportError Traceback (most recent call last); ~\anaconda3\envs\Python38\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 52 try:; ---> 53 from skmisc.loess import loess; 54 except ImportError:. ~\AppData\Roaming\Python\Python38\site-packages\skmisc\loess\__init__.py in <module>; 50 """"""; ---> 51 from ._loess import (loess, loess_model, loess_inputs, loess_control,; 52 loess_outputs, loess_prediction,. ImportError: DLL load failed while importing _loess: The specified module could not be found. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_11028/1877627730.py in <module>; ----> 1 sc.pp.highly_variable_genes(adata, n_top_genes=50",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342:1398,error,errors,1398,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342,1,['error'],['errors']
Availability,"__(self, *args, **kwargs); 207 kwargs[r_k] = v; --> 208 return (super(SignatureTranslatedFunction, self); 209 .__call__(*args, **kwargs)). File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/robjects/functions.py:131, in Function.__call__(self, *args, **kwargs); 130 new_kwargs[k] = cv.py2rpy(v); --> 131 res = super(Function, self).__call__(*new_args, **new_kwargs); 132 res = cv.rpy2py(res). File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/rinterface_lib/conversion.py:45, in _cdata_res_to_rinterface.<locals>._(*args, **kwargs); 44 def _(*args, **kwargs):; ---> 45 cdata = function(*args, **kwargs); 46 # TODO: test cdata is of the expected CType. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/rinterface.py:817, in SexpClosure.__call__(self, *args, **kwargs); 816 if error_occured[0]:; --> 817 raise embedded.RRuntimeError(_rinterface._geterrmessage()); 818 return res. RRuntimeError: Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : ; duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B. During handling of the above exception, another exception occurred:. RInterpreterError Traceback (most recent call last); Cell In[48], line 1; ----> 1 get_ipython().run_cell_magic('R', '-i data -i data_tod -i genes -i cells -i soupx_groups -o out', '\n# specify row and column names of data\nrownames(data) = genes\ncolnames(data) = cells\n# ensure correct sparse format for table of counts and table of droplets\ndata <- as(data, ""sparseMatrix"")\ndata_tod <- as(data_tod, ""sparseMatrix"")\n\n# Generate SoupChannel Object for SoupX \nsc = SoupChannel(data_tod, data, calcSoupProfile = FALSE)\n\n# Add extra meta data to the SoupChannel object\nsoupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data))\nsc = setSoupProfile(sc, soupProf)\n# Set cluster inf",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277:2138,Error,Error,2138,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277,1,['Error'],['Error']
Availability,_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/ne,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:57575,ERROR,ERROR,57575,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:58911,ERROR,ERROR,58911,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/ne,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:55905,ERROR,ERROR,55905,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1518,ERROR,ERROR,1518,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,_genes_pearson_residuals_batch[csr_matrix-float32-100n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[spatial] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_dimension_broadcasting - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_marker_broadcasting - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_compare - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatm,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:46488,Error,Error,46488,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-viridis] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-rgba] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_trackspl,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:5132,Error,Error,5132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-False] PASSED [ 83%]; ```. s,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:5019,ERROR,ERROR,5019,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:58577,ERROR,ERROR,58577,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbor,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:56907,ERROR,ERROR,56907,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"`E ImportError: cannot import name 'settings' from partially initialized module 'scanpy' (most likely due to a circular import) (/home/vsts/work/1/s/scanpy/__init__.py); `. Meh, it's hell to track this down now. I assume that autopep8 removed an unused variable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1689#issuecomment-785044073:202,down,down,202,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689#issuecomment-785044073,1,['down'],['down']
Availability,"```; $ python -m scanpy.tests.blackdiff 10. /home/travis/virtualenv/python3.7.1/lib/python3.7/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/travis/build/theislab/scanpy"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). /home/travis/virtualenv/python3.7.1/bin/python: No module named scanpy.tests.blackdiff; ```. Not sure why this happened, but we well we're using black with pre-commit now anyways so w/e. Does this need fixing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1689#issuecomment-785089639:209,error,errors,209,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689#issuecomment-785089639,2,['error'],['errors']
Availability,"```; FAILED scanpy/tests/test_plotting.py::test_violin - AssertionError: Error: Im...; FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - AssertionError: E...; ```. Sigh, again not related.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1974#issuecomment-900226530:73,Error,Error,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1974#issuecomment-900226530,1,['Error'],['Error']
Availability,"```; Warning, treated as error:; /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/2134/scanpy/plotting/_anndata.py:docstring of scanpy.plotting._anndata.dendrogram:31:Exception occurred in plotting scanpy-pl-dendrogram-1; from /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/2134/docs/generated/scanpy.pl.dendrogram.rst:; Traceback (most recent call last):; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2134/lib/python3.8/site-packages/matplotlib/sphinxext/plot_directive.py"", line 517, in _run_code; exec(code, ns); File ""<string>"", line 3, in <module>; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/2134/scanpy/tools/_dendrogram.py"", line 139, in dendrogram; corr_condensed = distance.squareform(1 - corr_matrix); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2134/lib/python3.8/site-packages/scipy/spatial/distance.py"", line 2363, in squareform; is_valid_dm(X, throw=True, name='X'); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2134/lib/python3.8/site-packages/scipy/spatial/distance.py"", line 2444, in is_valid_dm; raise ValueError(('Distance matrix \'%s\' diagonal must '; ValueError: Distance matrix 'X' diagonal must be zero.; ```. Some dendrogram issue. The RTD build is also flaky.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2134#issuecomment-1034839590:25,error,error,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2134#issuecomment-1034839590,1,['error'],['error']
Availability,"```; Warning, treated as error:; failed to reach any of the inventories with the following issues:; intersphinx inventory 'https://docs.scipy.org/doc/scipy/reference/objects.inv' not fetchable due to <class 'requests.exceptions.HTTPError'>: 404 Client Error: Not Found for url: https://docs.scipy.org/doc/scipy/reference/objects.inv; ```. Not my fault I guess",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1974#issuecomment-891043388:25,error,error,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1974#issuecomment-891043388,3,"['Error', 'error', 'fault']","['Error', 'error', 'fault']"
Availability,```; sc.__version__; '1.8.0.dev78+gc488909a'; ```. It seems to be working but I'm currently on a different dataset. What I noticed was that if I didn't have the same ID columns in my `adata.var` when setting adata.raw I couldn't use `gene_symbols`. After setting `adata.var` so it had the same IDs before setting `adata.raw` made it possible. ; In other words if adata.raw was missing the notation it failed for me (different error though). ; I will give an update when I get back to the dataset above. Just to make sure it's the same issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1758#issuecomment-816317537:426,error,error,426,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758#issuecomment-816317537,1,['error'],['error']
Availability,"```py; >>> from math import sqrt ; >>> sqrt(-1); ValueError: math domain error; ```. I assume it’s the square root throwing this. Assuming that it only happens when you pass a negative argument, the term inside can only become negative if `ns[imask] < 0` or `ns[imask] > n_cells`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/566#issuecomment-477933420:73,error,error,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/566#issuecomment-477933420,1,['error'],['error']
Availability,"```py; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; categories_order=['0','1','9','8','2','5','4','7','3','6','10']; sc.pl.tracksplot(adata,markers,groupby='louvain',vmax=3,categories_order=categories_order); ```. no mattet what the ""categories_order"" is, there is no work on the order of the label.Even the categories_order is error, such as categories_order = ['a','b','c','d'], the figure can not do anything on the order of the labels",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2250#issuecomment-1125580441:383,error,error,383,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250#issuecomment-1125580441,1,['error'],['error']
Availability,"```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <timed exec> in <module>. ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_pca.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size); 201 ); 202 ; --> 203 output = _pca_with_sparse(X, n_comps, solver=svd_solver); 204 # this is just a wrapper for the results; 205 X_pca = output['X_pca']. ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_pca.py in _pca_with_sparse(X, npcs, solver, mu, random_state); 293 return XHmat(x) - mhmat(ones(x)); 294 ; --> 295 XL = LinearOperator(; 296 matvec=matvec,; 297 dtype=X.dtype,. TypeError: __init__() got an unexpected keyword argument 'rmatmat'; ```. I got this error once with the new spare PCA. @atarashansky do we need to write an explicit scipy version as dependency? It might be something weird with my setup too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-636055632:827,error,error,827,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-636055632,1,['error'],['error']
Availability,"```pytb; Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : ; duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B; ---------------------------------------------------------------------------; RRuntimeError Traceback (most recent call last); File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:385, in RMagics.eval(self, code); 383 try:; 384 # Need the newline in case the last line in code is a comment.; --> 385 value, visible = ro.r(""withVisible({%s\n})"" % code); 386 except (ri.embedded.RRuntimeError, ValueError) as exception:; 387 # Otherwise next return seems to have copy of error. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/robjects/__init__.py:459, in R.__call__(self, string); 458 p = rinterface.parse(string); --> 459 res = self.eval(p); 460 return conversion.get_conversion().rpy2py(res). File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/robjects/functions.py:208, in SignatureTranslatedFunction.__call__(self, *args, **kwargs); 207 kwargs[r_k] = v; --> 208 return (super(SignatureTranslatedFunction, self); 209 .__call__(*args, **kwargs)). File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/robjects/functions.py:131, in Function.__call__(self, *args, **kwargs); 130 new_kwargs[k] = cv.py2rpy(v); --> 131 res = super(Function, self).__call__(*new_args, **new_kwargs); 132 res = cv.rpy2py(res). File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/rinterface_lib/conversion.py:45, in _cdata_res_to_rinterface.<locals>._(*args, **kwargs); 44 def _(*args, **kwargs):; ---> 45 cdata = function(*args, **kwargs); 46 # TODO: test cdata is of the expected CType. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/rinterface.py:817, in SexpClosure.__call__(self, *args,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277:9,Error,Error,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277,2,"['Error', 'error']","['Error', 'error']"
Availability,`gprofiler` functionality is being added to scanpy? I have a small wrapper for that as well... the main components being a try-catch wrapper around it as it can give an error when there are no results.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/467#issuecomment-463965367:169,error,error,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/467#issuecomment-463965367,1,['error'],['error']
Availability,"`logg.warning` vs. `logg.warn`. I liked the short and verbal `.warn` better. I know there is some confusion, because of how python's core warning and logging modules possible, but meanwhile, several other packages have adapted Scanpy's logging module. All of them now need to change each line from `logg.warn` to `logg.warning` and even I will tend to make a lot of errors being used to `logg.warn` (still most of the time using emacs without autosuggest...). So, as Isaac, I'd also like the equivalent `logg.warn` function but wouldn't even deprecate it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/676#issuecomment-499027754:366,error,errors,366,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/676#issuecomment-499027754,1,['error'],['errors']
Availability,"`paul15` is downloaded automatically, very practical.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/80#issuecomment-364331145:12,down,downloaded,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/80#issuecomment-364331145,1,['down'],['downloaded']
Availability,a.py::test_paga_pie - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[umap] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_gr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:2179,Error,Error,2179,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,a.py::test_paga_plots[continuous_obs-func2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_multiple-func3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_pie - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[umap] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_vi,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:1924,Error,Error,1924,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"a_30'); harmony_integrate(adata2, key='batch', basis='X_pca_30'); np.testing.assert_array_equal(adata1.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""]); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 567291 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 572730 (99.1%); Max absolute difference: 1.20792265e-12; Max relative difference: 4.37537551e-09; x: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; y: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; ```. The second test:. ```; sc.pp.neighbors(adata1, n_pcs=30, use_rep='X_pca_harmony'); sc.pp.neighbors(adata2, n_pcs=30, use_rep='X_pca_harmony'); np.testing.assert_array_equal(adata1.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 268636 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 434492 (61.8%); Max absolute difference: 0.99820393; Max relative difference: 810.4644; x: array([0.158963, 0.206843, 0.234457, ..., 0.095996, 0.179325, 1. ],; dtype=float32); y: array([0.158963, 0.206843, 0.234457, ..., 0.095996, 0.179324, 1. ],; dtype=float32); ```. This is my session_info:. ```; Click to view session information; -----; anndata 0.9.2; loguru 0.7.2; matplotlib 3.8.0; numpy 1.26.0; pandas 1.4.3; scanpy 1.9.6; seaborn 0.12.2; session_info 1.0.0; -----; Click to view modules imported as dependencies; PIL 9.4.0; argcomplete NA; asttokens NA; attr 23.1.0; awkward 2.4.2; awkward_cpp NA; backcall 0.2.0; cffi 1.15.1; comm 0.1.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; dot_parser NA; etils 1.4.1; exceptiongroup 1.1.3; executing 1.2.0; get_annotations NA; gmpy2 2.1.2; ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:2480,Error,Error,2480,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227,1,['Error'],['Error']
Availability,able_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4789,ERROR,ERROR,4789,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,"ace=True); sc.pp.normalize_per_cell(adata, counts_per_cell_after=10000); sc.pp.log1p(adata); return adata. def pca_update(tgt, src, inplace=True):; # TODO: Make sure we know the settings from src; if not inplace:; tgt = tgt.copy(); if sparse.issparse(tgt.X):; X = tgt.X.toarray(); else:; X = tgt.X.copy(); X -= np.asarray(tgt.X.mean(axis=0)); tgt_pca = np.dot(X, src.varm[""PCs""]); tgt.obsm[""X_pca""] = tgt_pca; return tgt. def simulate_doublets(adata, frac=.5):; """"""Simulate doublets from count data.; ; Params; ------; adata; The anndata object to sample from. Must have count data.; frac; Fraction of total cells to simulate.; """"""; m, n = adata.X.shape; n_doublets = int(np.round(m * frac)); pos_idx = np.array(list(chain.from_iterable(map(lambda x: repeat(x, 2), range(n_doublets))))); combos = np.random.randint(0, m, (n_doublets * 2)); pos = sparse.csr_matrix(; (np.ones_like(combos, dtype=adata.X.dtype), (pos_idx, combos)), ; shape=(n_doublets, m); ); dblX = pos * adata.X; # TODO: Downsample total counts; srcs = np.sort(combos.reshape(n_doublets, 2), axis=1); obs = pd.DataFrame(srcs, columns=[""src1"", ""src2""]); var = pd.DataFrame(index=adata.var_names); return sc.AnnData(dblX, obs=obs, var=var). # Load data. # http: // cf.10xgenomics.com/samples/cell-exp/3.0.0/pbmc_10k_v3/pbmc_10k_v3_filtered_feature_bc_matrix.h5; pbmc = sc.read_10x_h5(""./data/10x/pbmc_10k_v3_filtered_feature_bc_matrix.h5""); pbmc.var[""gene_symbols""] = pbmc.var.index; pbmc.var.set_index(""gene_ids"", inplace=True). dblt = simulate_doublets(pbmc); dblt.var[""gene_symbols""] = pbmc.var[""gene_symbols""]. pbmc.raw = pbmc; dblt.raw = dblt. pbmc = preprocess(pbmc); dblt = preprocess(dblt). sc.pp.pca(pbmc); pca_update(dblt, pbmc). umap = UMAP(); pbmc.obsm[""X_umap""] = umap.fit_transform(pbmc.obsm[""X_pca""]); dblt.obsm[""X_umap""] = umap.transform(dblt.obsm[""X_pca""]). sc.tl.embedding_density(pbmc, ""umap""); sc.tl.embedding_density(dblt, ""umap""); ```; </details>. <details> ; <summary> Getting setup for datashader plots (much sh",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/575#issuecomment-481184384:2035,Down,Downsample,2035,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/575#issuecomment-481184384,1,['Down'],['Downsample']
Availability,"add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right?. I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python; conda create -n scanpyenv python=3.8; https://github.com/theislab/scanpy.git; cd scanpy; pip install .; ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative.; >; > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python; for frame in traceback.extract_stack():; if frame.name == 'get_docstring_and_version_via_import':; re",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-783849659:1557,error,error,1557,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-783849659,1,['error'],['error']
Availability,"after I have used bbknn and ump these two steps, when I use the louvain, It gives me a System Error. ; Note: my dataset is too big. I want help!! thx!!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1980#issuecomment-899489219:94,Error,Error,94,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980#issuecomment-899489219,1,['Error'],['Error']
Availability,aga.py::test_paga_plots[continuous-func1] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_obs-func2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_multiple-func3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_pie - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[umap] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] -,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:1781,Error,Error,1781,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,age files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:3207,Error,Error,3207,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,age files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_mat,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:3832,Error,Error,3832,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"ah it seems a really minor tolerance thingy, try to increase it to 16 should be fine; ```; save_and_compare_images = image_comparer(ROOT, FIGS, tol=15); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2255#issuecomment-1143800266:27,toler,tolerance,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2255#issuecomment-1143800266,1,['toler'],['tolerance']
Availability,al' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_pie - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_paga.py::test_paga_plots[compare_pca-func6] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:42274,Error,Error,42274,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"al\Temp/ipykernel_11028/3052125001.py in <module>; ----> 1 from skmisc.loess import loess. ~\AppData\Roaming\Python\Python38\site-packages\skmisc\loess\__init__.py in <module>; 49 pp. 829--836. 1979.; 50 """"""; ---> 51 from ._loess import (loess, loess_model, loess_inputs, loess_control,; 52 loess_outputs, loess_prediction,; 53 loess_confidence_intervals, loess_anova). ImportError: DLL load failed while importing _loess: The specified module could not be found.; ```; Step5: run `import skmisc; print(skmisc.__file__)`; ```python; import skmisc; print(skmisc.__file__); C:\Users\Park_Lab\AppData\Roaming\Python\Python38\site-packages\skmisc\__init__.py; ```; Step6: due to Step4, I follow the solution (https://github.com/has2k1/scikit-misc/issues/4) to install Numpy with mkl.; ```python; (base) C:\Users\Park_Lab>conda activate Python38; (Python38) C:\Users\Park_Lab>cd Downloads/; (Python38) C:\Users\Park_Lab\Downloads>pip install numpy-1.21.5+mkl-cp38-cp38-win_amd64.whl; Processing c:\users\park_lab\downloads\numpy-1.21.5+mkl-cp38-cp38-win_amd64.whl; Installing collected packages: numpy; Attempting uninstall: numpy; Found existing installation: numpy 1.21.5; Uninstalling numpy-1.21.5:; Successfully uninstalled numpy-1.21.5; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.21.5+mkl which is incompatible.; Successfully installed numpy-1.21.5+mkl; ```; Step7: check anaconda Python38 environment, numpy-1.21.5+mkl is successfully installed; ![image](https://user-images.githubusercontent.com/75048821/147306587-eb94c188-5c18-40f0-add0-3a899872d786.png). Step8: Scanpy import error. Numpy>v1.20 is conflicted with Scanpy; ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342:4479,down,downloads,4479,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342,1,['down'],['downloads']
Availability,"ame, filemode=filemode); 673 ; 674 def _init_as_view(self, adata_ref: 'AnnData', oidx: Index, vidx: Index):. /opt/conda/lib/python3.7/site-packages/anndata/base.py in _init_as_actual(self, X, obs, var, uns, obsm, varm, raw, layers, dtype, shape, filename, filemode); 848 # annotations; 849 self._obs = _gen_dataframe(obs, self._n_obs,; --> 850 ['obs_names', 'row_names', 'smp_names']); 851 self._var = _gen_dataframe(var, self._n_vars, ['var_names', 'col_names']); 852 . /opt/conda/lib/python3.7/site-packages/anndata/base.py in _gen_dataframe(anno, length, index_names); 285 _anno = pd.DataFrame(; 286 anno, index=anno[index_name],; --> 287 columns=[k for k in anno.keys() if k != index_name]); 288 break; 289 else:. /opt/conda/lib/python3.7/site-packages/pandas/core/frame.py in __init__(self, data, index, columns, dtype, copy); 390 dtype=dtype, copy=copy); 391 elif isinstance(data, dict):; --> 392 mgr = init_dict(data, index, columns, dtype=dtype); 393 elif isinstance(data, ma.MaskedArray):; 394 import numpy.ma.mrecords as mrecords. /opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py in init_dict(data, index, columns, dtype); 210 arrays = [data[k] for k in keys]; 211 ; --> 212 return arrays_to_mgr(arrays, data_names, index, columns, dtype=dtype); 213 ; 214 . /opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py in arrays_to_mgr(arrays, arr_names, index, columns, dtype); 54 ; 55 # don't force copy because getting jammed in an ndarray anyway; ---> 56 arrays = _homogenize(arrays, index, dtype); 57 ; 58 # from BlockManager perspective. /opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py in _homogenize(data, index, dtype); 275 val = lib.fast_multiget(val, oindex.values, default=np.nan); 276 val = sanitize_array(val, index, dtype=dtype, copy=False,; --> 277 raise_cast_failure=False); 278 ; 279 homogenized.append(val). /opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py in sanitize_ar",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/598#issuecomment-487609885:1783,Mask,MaskedArray,1783,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/598#issuecomment-487609885,1,['Mask'],['MaskedArray']
Availability,ames to fa2.egg-info/top_level.txt; writing manifest file 'fa2.egg-info/SOURCES.txt'; reading manifest file 'fa2.egg-info/SOURCES.txt'; reading manifest template 'MANIFEST.in'; adding license file 'LICENSE'; writing manifest file 'fa2.egg-info/SOURCES.txt'; copying fa2/fa2util.c -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/fa2util.pxd -> build/lib.macosx-12.3-x86_64-3.10/fa2; running build_ext; skipping 'fa2/fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; creating build/temp.macosx-12.3-x86_64-3.10; creating build/temp.macosx-12.3-x86_64-3.10/fa2; clang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -I/Users/test/.pyenv/versions/3.10.3/include/python3.10 -c fa2/fa2util.c -o build/temp.macosx-12.3-x86_64-3.10/fa2/fa2util.o; fa2/fa2util.c:10939:33: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Node.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:10947:33: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Edge.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:10960:35: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Region.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:12133:22: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:261:7: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op) : \; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/ve,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:5742,error,error,5742,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,1,['error'],['error']
Availability,"ames); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/application.py"", line 343, in build; self.builder.build_update(); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/builders/__init__.py"", line 293, in build_update; self.build(to_build,; File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/builders/__init__.py"", line 307, in build; updated_docnames = set(self.read()); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/contextlib.py"", line 120, in __exit__; next(self.gen); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 213, in pending_warnings; memhandler.flushTo(logger); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 178, in flushTo; logger.handle(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 1587, in handle; self.callHandlers(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 1649, in callHandlers; hdlr.handle(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 946, in handle; rv = self.filter(record); File ""/home/docs/.pyenv/versions/3.8.6/lib/python3.8/logging/__init__.py"", line 807, in filter; result = f.filter(record); File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/2174/lib/python3.8/site-packages/sphinx/util/logging.py"", line 423, in filter; raise exc; sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/2174/scanpy/external/pp/_mnn_correct.py:docstring of scanpy.external.pp._mnn_correct.mnn_correct:76:Inline interpreted text or phrase reference start-string without end-string.; ```. Sigh, why are our jobs so flaky?....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2174#issuecomment-1066709010:1916,error,errors,1916,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2174#issuecomment-1066709010,1,['error'],['errors']
Availability,an...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_r,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62692,ERROR,ERROR,62692,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"anges from `rank_genes_groups`, only to discover the discrepancy in the fold change calculation. Here is an example of how confusing this inconsistency can be:. - I run `rank_genes_groups` and see that many marker genes have high log2 fold changes in `adata.uns['rank_genes_groups']['logfoldchanges'][<cluster_string>]`. For example, gene X has a fold change of -27.720167.; - Then, I run `filter_rank_genes_groups` -- and none of these genes with high negative fold changes are retained; - There are two issues here: one is that negative fold changes don't get retained at all. [This is the issue I notice first, and report in #1325]. I fix that in my fork of the repo (solution below), but STILL these genes are removed when filtering for a min absolute fold change of 1.5 (0.58 on log scale)... ?!; - This boils down to the inconsistency in fold change calculation. Mean expression of gene X within my cluster of interest is 0, and outside it is 0.1997576. `np.log2((0 + 1e-9)/(0.1997576 + 1e-9)) = -27.720167`, as reported originally by `rank_genes_groups`. As a user, I completely expect this gene to pass my threshold. `filter_rank_genes_groups`, however, calculates fold change as `np.log2(np.exp(0)/np.exp(0.199758)) = -0.288189`, which does NOT pass my fold change threshold, thus it gets filtered out. All this happens silently of course [the only number I have seen is a whopping fold change of -27] leaving me utterly confused. I'm not sure which is more correct (though -27 seems pretty inflated to me given the raw numbers), but it would make a lot more sense for it to at least be consistent, especially so that `filter_rank_genes_groups` could give expected results. p.s. Here is my fix to retain downregulated genes in `filter_rank_genes_groups`: update the third condition to `(np.absolute(np.log2(fold_change_matrix)) > np.log2(min_fold_change))` (similar to @gianasco's suggestion, but handles downregulated fold changes more appropriately). I noted this issue separately in #1325",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/863#issuecomment-661497061:1898,down,downregulated,1898,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/863#issuecomment-661497061,2,['down'],['downregulated']
Availability,annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61221,ERROR,ERROR,61221,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,anpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalizat,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68586,ERROR,ERROR,68586,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,anpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:70053,ERROR,ERROR,70053,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,anpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:71043,ERROR,ERROR,71043,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,anpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: ca,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65002,ERROR,ERROR,65002,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,anpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62368,ERROR,ERROR,62368,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,anpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preproce,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63680,ERROR,ERROR,63680,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,anpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metric,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:67940,ERROR,ERROR,67940,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"are kept. If they're not the same shape, then I would expect the same error as pandas throws. For 2. I think its okay if you return a dense 1-d array when I access a single column vector. I don't understand where the confusion is coming in with adata.X changing when you access a single column, but that's not been an issue for me. For the rest, I hope you can survey the community to figure out how rare my use-cases are. I would like scanpy / anndata to fit into my existing workflow that I picked up while learning matplotlib / pandas / numpy. I want slicing an AnnData to behave like slicing a DataFrame; I want clusters to be ints; I want to apply a transformation to a data-container and get the whole container returned with the transformation applied to the values. . I can come up with workarounds for all of the choices you've made here. That's not the issue. I raised this comment because these workarounds add overhead to getting my work done. I'm not going to change my work flow to match your design choices where they diverge from the apis for sklearn / numpy / pandas etc. I know I'm not the only one with these wants (e.g. @scottgigante has similar frustrations), but I don't know how prevalent these frustrations are. I think at the end of the day, my concern here boils down to what infrastructure you put in place to make sure the needs of the community are balanced with the intentions of the developers. I think the efforts be cellxgene are a great model for this, and I would happily get involved with figuring out the best way to incorporate community feedback into the development of scanpy / anndata. All this said, your tools do provide a bunch of amazing functionality that I rely on for my PhD. I really appreciate all the effort you've put in. I especially love how easy it is to run louvain / leiden, and how supportive you've been to people adding external tools to scanpy so they can be made accessible to the broader community of single cell users in Python. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-609066004:1714,down,down,1714,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-609066004,1,['down'],['down']
Availability,as2-0.3.5/examples/geometric_graph.png; x forceatlas2-0.3.5/examples/grid_graph.png; x forceatlas2-0.3.5/fa2/; x forceatlas2-0.3.5/fa2/__init__.py; x forceatlas2-0.3.5/fa2/fa2util.c; x forceatlas2-0.3.5/fa2/fa2util.pxd; x forceatlas2-0.3.5/fa2/fa2util.py; x forceatlas2-0.3.5/fa2/forceatlas2.py; x forceatlas2-0.3.5/setup.py; test@mac ~/PythonPackages$ cd forceatlas2-0.3.5/; test@mac ~/PythonPackages/forceatlas2-0.3.5$ pip3 install . --user; Processing /Users/test/PythonPackages/forceatlas2-0.3.5; Preparing metadata (setup.py) ... done; Requirement already satisfied: numpy in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (1.21.5); Requirement already satisfied: scipy in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (1.8.0); Requirement already satisfied: tqdm in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (4.63.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... error; error: subprocess-exited-with-error; ; × python setup.py bdist_wheel did not run successfully.; │ exit code: 1; ╰─> [214 lines of output]; Installing fa2 package (fastest forceatlas2 python implementation); ; >>>> Cython is installed?; Yes; ; >>>> Starting to install!; ; running bdist_wheel; running build; running build_py; creating build; creating build/lib.macosx-12.3-x86_64-3.10; creating build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/fa2util.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/__init__.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/forceatlas2.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; running egg_info; creating fa2.egg-info; writing fa2.egg-info/PKG-INFO; writing dependency_links to fa2.egg-info/dependency_links.txt; writing requirements to fa2.egg-info/requires.txt; writing top-level names to fa2.egg-info/top_level.txt; writing manifest file 'fa2.egg-info/SOURCES.txt'; reading manifest file 'fa2.egg-info/SOURCES.txt'; reading manifest template 'MANIFEST.in'; adding ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:3934,error,error,3934,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,3,['error'],['error']
Availability,atial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1371,ERROR,ERROR,1371,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,"b.py?line=130) self.gen.throw(type, value, traceback); [132](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=131) except StopIteration as exc:; [133](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=132) # Suppress StopIteration *unless* it's the same exception that; [134](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=133) # was passed to throw(). This prevents a StopIteration; [135](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=134) # raised inside the ""with"" statement from being suppressed.; [136](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=135) return exc is not value. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\errors.py:837, in new_error_context(fmt_, *args, **kwargs); [835](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=834) else:; [836](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=835) tb = None; --> [837](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=836) raise newerr.with_traceback(tb); [838](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=837) elif use_new_style_errors():; [839](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=838) raise e. LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x00000242239BD700> (trying to write member #1). File ""D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\umap\layouts.py"", line 53:; def rdist(x, y):; <source elided>; dim = x.shape[0]; for i in range(dim):; ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=Non",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:32744,error,errors,32744,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659,1,['error'],['errors']
Availability,"baforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_categorical - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_constants - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_constants_equivalent - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tools/_dendrogram.py::scanpy.tools._dendrogram.dendrogram; FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[umap_with_edges-fn17] - AssertionError: Error: Image files did not match.; ============================== 56 failed, 1236 passed, 96 skipped, 19 xfailed, 9 xpassed, 763 warnings in 595.02s (0:09:55) ==============================; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:7875,Error,Error,7875,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,4,['Error'],['Error']
Availability,"but when i run ; sc.pl.pca(adata, color='CST3'); it return the error,how could i fix it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2430#issuecomment-1442858802:63,error,error,63,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430#issuecomment-1442858802,1,['error'],['error']
Availability,"by calling the spatial function. this is addressed, embedding changes behaviour only if img is passed, but has nothing to do with spatial, there is a small trick, and has to do with `ax.invert_yaxis()`. See following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons; - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object; - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:; ```python; if img is _empty:; 	ax.invert_yaxis(); ```; This is the behviour; ```python; sc.pl.embedding(adata, color=""leiden"", basis=""spatial""); ```. <details>; <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python; sc.pl.spatial(adata, color=""leiden"", img_key=None); ```. <details>; <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. -------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1512#issuecomment-748455514:3012,down,down,3012,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512#issuecomment-748455514,1,['down'],['down']
Availability,c 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_mask-fn19] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_groups_and_size - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:55402,ERROR,ERROR,55402,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"can you link a doc build failure, please? Then I can check out why it fails. I assume they changed the documented location of the class. We have it in `qualname_overrides` and should probably just update the location there (or remove it that line if the new documented location now matches the qualified name). https://github.com/theislab/scanpy/blob/e5d246aacc71fb9ed71d49e2e7d5e26743fd4acb/docs/conf.py#L136-L140",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1241#issuecomment-635926781:25,failure,failure,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1241#issuecomment-635926781,1,['failure'],['failure']
Availability,can...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61545,ERROR,ERROR,61545,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"canpy/datasets/; [...]. ❯ du -a .pytest_cache/d/scanpy-data/ | reject directories files apparent; ╭───┬──────────────────────────────────────────────────────────────────────┬──────────╮; │ # │ path │ physical │; ├───┼──────────────────────────────────────────────────────────────────────┼──────────┤; │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data │ 199.6 MB │; ╰───┴──────────────────────────────────────────────────────────────────────┴──────────╯. ❯ du -a .pytest_cache/d/scanpy-data/* | reject directories files apparent; ╭───┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬──────────╮; │ # │ path │ physical │; ├───┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────┤; │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/E-MTAB-4888 │ 71.1 MB │; │ 1 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/Targeted_Visium_Human_Glioblastoma_Pan_Cancer │ 19.7 MB │; │ 2 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/V1_Breast_Cancer_Block_A_Section_1 │ 48.3 MB │; │ 3 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/burczynski06 │ 16.3 MB │; │ 4 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/moignard15 │ 3.4 MB │; │ 5 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/paul15 │ 10.3 MB │; │ 6 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_processed.h5ad │ 24.7 MB │; │ 7 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_raw.h5ad │ 5.9 MB │; ╰───┴────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴──────────╯; ```. > What was stopping this before? […] why wouldn't we want to download the data everytime?. someone implementing the caching, so nothing much really",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3060#issuecomment-2117262252:2127,down,download,2127,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060#issuecomment-2117262252,1,['down'],['download']
Availability,canpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_ra,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66125,ERROR,ERROR,66125,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,canpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:60571,ERROR,ERROR,60571,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,canpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/te,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64008,ERROR,ERROR,64008,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"cc: @Zethson @grst. Hey, . In principle this sounds good, but I'd like to hear a little bit more about the usecase. For context on our side, there are some other paths for speeding up DE available (probably some form of calculating statistics via https://github.com/scverse/anndata/pull/564). There're also increased momentum on more featureful DE in the scverse ecosystem. If you are specifically looking for faster scanpy DE, this makes sense, though there may be some easier paths forward (at least to me). If you need anything fancier or even just different, it could be good to check in with other efforts. E.g. . * https://github.com/theislab/pertpy/issues/189",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2390#issuecomment-1387422639:187,avail,available,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390#issuecomment-1387422639,1,['avail'],['available']
Availability,center-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-viridis] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-rgba] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:4971,Error,Error,4971,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"ception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper; return f(*args, **kwargs); File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed; backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',; File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read; **kwargs,; File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read; is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,); File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download; _download(backup_url, path); File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download; urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:; File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen; return opener.open(url, data, timeout); File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open; response = self._open(req, data); File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open; '_open', req); File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain; result = func(*args); File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open; context=self._context, check_hostname=self._check_hostname); File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open; raise URLError(err); urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)>; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1472#issuecomment-721326665:3520,error,error,3520,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472#issuecomment-721326665,2,['error'],['error']
Availability,cessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:71381,ERROR,ERROR,71381,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for 1-3 built-in commands. Other people are interested in creating those scripts (and did so already, but for the time being just call `scanpy-mycommand` with a dash in there). > I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. […] Generally, I think there should be a lon",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:1402,down,download,1402,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940,1,['down'],['download']
Availability,"cipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_categorical - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_constants - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_constants_equivalent - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tools/_dendrogram.py::scanpy.tools._dendrogram.dendrogram; FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[umap_with_edges-fn17] - AssertionError: Error: Image files did not match.; ============================== 56 failed, 1236 passed, 96 skipped, 19 xfailed, 9 xpassed, 763 warnings in 595.02s (0:09:55) ====",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:7742,Error,Error,7742,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"co.cross_plot is one high level possibility to construct complex heatmaps with the 'central data heatmap + annotation heatmaps' layout. Among other things, it can automatically cluster columns or rows based on the central data heatmap and apply the clustering to the annotation heatmaps. It can also plot dendrograms. This is an experimental function with some quirks, I did want to improve the concept soon-ish.; - co.heatmap is the base heatmap plotting function in codaplot. It provides a simple way to plot categorical heatmaps and add spacers within heatmaps. Both tasks are not trivial with matplotlib base plot functions. This would be helpful for adding categorical annotation heatmaps, even if you don't want to use co.cross_plot as it is right now.; - i have an alternative function to co.heatmap in my snippets library which is capable of creating heatmaps using rectangle or circle patches with size and color aesthetics, but i havent added it to codaplot yet. You can always create circle patch heatmaps with standard scatterplots, but this has drawbacks when you want to be able to add spacers within the plot or when you want full control of the circle patch sizes (so that they fit perfectly within the row at maximum size). From what I understand such a patch based function would be helpful, right?. I would be happy to contribute some base functionality for this issue by adding improvements to codaplot, ie provide the circle patch heatmap function and a better complex heatmap function than the currently available co.cross_plot. I do plan on maintaining codaplot for the foreseeable future and have been using it for my own projects for quite a while now. At the moment it's a relatively small library (when you subtract the experimental modules) and could be quickly refactored into a single scanpy module if something happens and I find myself unable to maintain and expand the library over the next years. . Does using codaplot for this issue sound at all interesting to you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103:1886,avail,available,1886,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2194#issuecomment-1145123103,1,['avail'],['available']
Availability,"conda/envs/rpy/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 604 pipeline = pipeline_class(typingctx, targetctx, library,; 605 args, return_type, flags, locals); --> 606 return pipeline.compile_extra(func); 607 ; 608 . ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(self, func); 351 self.state.lifted = (); 352 self.state.lifted_from = None; --> 353 return self._compile_bytecode(); 354 ; 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/compiler.py in _compile_bytecode(self); 413 """"""; 414 assert self.state.func_ir is None; --> 415 return self._compile_core(); 416 ; 417 def _compile_ir(self):. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/compiler.py in _compile_core(self); 393 self.state.status.fail_reason = e; 394 if is_final_pipeline:; --> 395 raise e; 396 else:; 397 raise CompilerError(""All available pipelines exhausted""). ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/compiler.py in _compile_core(self); 384 res = None; 385 try:; --> 386 pm.run(self.state); 387 if self.state.cr is not None:; 388 break. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/compiler_machinery.py in run(self, state); 337 (self.pipeline_name, pass_desc); 338 patched_exception = self._patch_error(msg, e); --> 339 raise patched_exception; 340 ; 341 def dependency_analysis(self):. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/compiler_machinery.py in run(self, state); 328 pass_inst = _pass_registry.get(pss).pass_inst; 329 if isinstance(pass_inst, CompilerPass):; --> 330 self._runPass(idx, pass_inst, state); 331 else:; 332 raise BaseException(""Legacy pass in use""). ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 33 def _acquire_compile_lock(*args, **kwargs):; 34 with self",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796:5866,avail,available,5866,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796,1,['avail'],['available']
Availability,"create -n test-2978 ""anndata==0.9.0"" ipython scanpy; [ ... ]; isaac@Mimir:~/tmp/genomic-features-docs; $ conda activate test-2978 ; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ ipython; from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help.; [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""); Out[4]: <Version('0.9.0')>. In [5]: quit(); (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ pip install -U anndata; Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0); Collecting anndata; Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB); [ ... ]; Downloading anndata-0.10.6-py3-none-any.whl (122 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00; Downloading array_api_compat-1.6-py3-none-any.whl (36 kB); Installing collected packages: array-api-compat, anndata; Attempting uninstall: anndata; Found existing installation: anndata 0.9.0; Uninstalling anndata-0.9.0:; Successfully uninstalled anndata-0.9.0; Successfully installed anndata-0.10.6 array-api-compat-1.6; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ conda list | grep anndata; anndata 0.10.6 pypi_0 pypi; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ ipython; imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""); Out[2]: <Version('0.10.6')>; ```. </details>. Interesting to see that this seems to work now!. I do think the recommended solution here is ""don't do this"", but I'm considering just using `anndata.__version__`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2978#issuecomment-2039433757:1188,Down,Downloading,1188,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978#issuecomment-2039433757,1,['Down'],['Downloading']
Availability,"cs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```; modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership); q = modularity_part.quality(); ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :); > ; > A couple follow up points on this and @LuckyMD's points; > ; > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores.; > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/819#issuecomment-529494088:2951,avail,available,2951,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819#issuecomment-529494088,1,['avail'],['available']
Availability,csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_res,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4113,ERROR,ERROR,4113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,d 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_gen,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:2486,Error,Error,2486,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"d'). adata_merge = adata.copy(); adata_merge.X = adata_merge.layers['counts']; sc.experimental.pp.highly_variable_genes(adata_merge, n_top_genes=3000, batch_key='batch'). adata_merge = adata_merge[:, adata_merge.var['highly_variable']].copy(); sc.experimental.pp.normalize_pearson_residuals(adata_merge); adata_merge.layers['apr'] = adata_merge.X.copy(); sc.tl.pca(adata_merge, svd_solver=""arpack""); adata_merge.obsm['X_pca_30'] = adata_merge.obsm['X_pca'][:, :30]. adata1 = adata_merge.copy(); adata2 = adata_merge.copy(); ```. The frist test:. ```; # scanpy 1.9.6 that changes of this PR won't have taken effect yet.; # I copy the harmony_integrate from https://github.com/scverse/scanpy/blob/75cb4e750efaccc1413cb204ffa49d21db017079/scanpy/external/pp/_harmony_integrate.py; harmony_integrate(adata1, key='batch', basis='X_pca_30'); harmony_integrate(adata2, key='batch', basis='X_pca_30'); np.testing.assert_array_equal(adata1.obsm[""X_pca_harmony""], adata2.obsm[""X_pca_harmony""]); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 567291 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 572730 (99.1%); Max absolute difference: 1.20792265e-12; Max relative difference: 4.37537551e-09; x: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; y: array([[-0.954048, -7.21621 , -1.601975, ..., 0.059509, -0.436056,; 0.564897],; [-1.145477, 10.185449, 4.414117, ..., -0.087394, -1.327791,...; ```. The second test:. ```; sc.pp.neighbors(adata1, n_pcs=30, use_rep='X_pca_harmony'); sc.pp.neighbors(adata2, n_pcs=30, use_rep='X_pca_harmony'); np.testing.assert_array_equal(adata1.obsp[""connectivities""].data, adata2.obsp[""connectivities""].data); ```. It raised the Error:. ```; AssertionError: ; Arrays are not equal. Mismatched elements: 268636 [/](https://vscode-remote+ssh-002dremote-002bnansha.vscode-resource.vscode-cdn.net/) 43",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:1652,Error,Error,1652,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227,1,['Error'],['Error']
Availability,"dFragment-->; </body>; </html>. Both tutorial adatas after a successful ingest:; ```. (AnnData object with n_obs × n_vars = 700 × 208; obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score', 'G2M_score', 'phase', 'louvain'; var: 'n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'; uns: 'bulk_labels_colors', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups', 'umap'; obsm: 'X_pca', 'X_umap', 'rep'; varm: 'PCs'; obsp: 'distances', 'connectivities',; AnnData object with n_obs × n_vars = 2638 × 208; obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'; var: 'n_cells'; uns: 'draw_graph', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups', 'umap'; obsm: 'X_pca', 'X_tsne', 'X_umap', 'X_draw_graph_fr'; varm: 'PCs'; obsp: 'distances', 'connectivities'); ```. Now my data, adata_ref:. <html><body>; <!--StartFragment--><div class=""lm-Widget p-Widget lm-Panel p-Panel jp-Cell-inputWrapper""><div class=""lm-Widget p-Widget jp-InputArea jp-Cell-inputArea"">.   | celltype | louvain; -- | -- | --; cell1 | hepatic stellate cells | 1; cell2 | cholangiocytes | 1; ... | ... | ... <p>8439 rows × 2 columns</p>; </div></div><!--EndFragment-->; </body>; </html>. and my adata that I wish to ingest:. <html><body>; <!--StartFragment-->.   | louvain; -- | --; cell1 | 0; cell2 | 0; ... <!--EndFragment-->; </body>; </html>. Both my adata files have the same 40 variables and pca/umaps, they look like this:. ```; (AnnData object with n_obs × n_vars = 8989 × 40; obs: 'louvain'; uns: 'pca', 'neighbors', 'umap', 'louvain', 'louvain_colors'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities',; AnnData object with n_obs × n_vars = 8439 × 40; obs: 'celltype', 'louvain'; uns: 'pca', 'neighbors', 'umap', 'louvain', 'louvain_colors'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities'); ```. I suspect the error stems from the Nearest Neighbours. Or maybe my number of variables (40) is too small?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2085#issuecomment-1104240383:3230,error,error,3230,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085#issuecomment-1104240383,1,['error'],['error']
Availability,"data[:, ['gene-0']]. site-packages/anndata/_core/anndata.py in __getitem__(self, index); 1085 def __getitem__(self, index: Index) -> ""AnnData"":; 1086 """"""Returns a sliced view of the object.""""""; -> 1087 oidx, vidx = self._normalize_indices(index); 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1089 . site-packages/anndata/_core/anndata.py in _normalize_indices(self, index); 1066 ; 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1068 return _normalize_indices(index, self.obs_names, self.var_names); 1069 ; 1070 # TODO: this is not quite complete... site-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1); 33 ax0, ax1 = unpack_index(index); 34 ax0 = _normalize_index(ax0, names0); ---> 35 ax1 = _normalize_index(ax1, names1); 36 return ax0, ax1; 37 . site-packages/anndata/_core/index.py in _normalize_index(indexer, index); 95 return positions # np.ndarray[int]; 96 else: # indexer should be string array; ---> 97 positions = index.get_indexer(indexer); 98 if np.any(positions < 0):; 99 not_found = indexer[positions < 0]. site-packages/pandas/core/indexes/base.py in get_indexer(self, target, method, limit, tolerance); 3169 ; 3170 if not self.is_unique:; -> 3171 raise InvalidIndexError(; 3172 ""Reindexing only valid with uniquely valued Index objects""; 3173 ). InvalidIndexError: Reindexing only valid with uniquely valued Index objects; ```; * `key` in both `adata.obs.columns` and `adata.var.index`: I changed this to raise a ValueError. I though about reverting back to the original implementation as you suggest but this will not work with `_anndata._prepare_dataframe` as I introduced some changes to work with this function. . The just added changes should mimic the response from 1.6 except for duplicate names in var_names which I think should respond similarly like when doing a slicing on the `AnnData` object. I added new tests based on your examples. I added checks to test for unique adata.obs.columns",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770217601:2220,toler,tolerance,2220,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770217601,1,['toler'],['tolerance']
Availability,"dataframe with all shared data; 533 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/anaconda3/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 310 @wraps(func); 311 def wrapper(*args, **kwargs) -> Callable[..., Any]:; --> 312 return func(*args, **kwargs); 313 ; 314 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs); 4174 kwargs.pop(""axis"", None); 4175 kwargs.pop(""labels"", None); -> 4176 return super().reindex(**kwargs); 4177 ; 4178 def drop(. ~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4810 # perform the reindex on the axes; 4811 return self._reindex_axes(; -> 4812 axes, level, limit, tolerance, method, fill_value, copy; 4813 ).__finalize__(self, method=""reindex""); 4814 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4021 if index is not None:; 4022 frame = frame._reindex_index(; -> 4023 index, method, copy, level, fill_value, limit, tolerance; 4024 ); 4025 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance); 4043 copy=copy,; 4044 fill_value=fill_value,; -> 4045 allow_dups=False,; 4046 ); 4047 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups); 4881 fill_value=fill_value,; 4882 allow_dups=allow_dups,; -> 4883 copy=copy,; 4884 ); 4885 # If we've made a copy once, no need to make another one. ~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice); 1299 # some axes don't allow reindexing with dups; 1300 if not allow_dups:; -> 1301 self.axes[axis]._can_reindex(indexer); 1302 ; 1303",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683:3021,toler,tolerance,3021,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683,1,['toler'],['tolerance']
Availability,default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residual,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1225,ERROR,ERROR,1225,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,do not `sc.pp.scale(adata)` before use `sc.pp.highly_variable_genes` will not show the error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/763#issuecomment-1309646072:87,error,error,87,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763#issuecomment-1309646072,1,['error'],['error']
Availability,"does the problem also happen in matrixplot or heatmap? seems to me like an; issue with the underlying seaborn violin plot. On Fri, Aug 31, 2018 at 6:25 PM a-munoz-rojas <notifications@github.com>; wrote:. > Thanks for all the work in developing this package, it's truly fantastic.; >; > I ran into what seems like a bug in the new plotting function; > sc.pl.rank_genes_groups_stacked_violin. It seems that when the ranked genes; > between 2 groups are similar (e.g. 'Tnf' is a highly ranked gene between; > two groups), then 'Tnf' is only plotted once on the first group, and any; > following groups with the same gene are truncated. You can see this in the; > toy example image I attached - when comparing groups M1 and M1+M2, 'Tnf'; > should be plotted for each group, but it is only plotted on group M1,; > therefore truncating group M2. When I plot the same data using; > rank_genes_groups_dotplot, this error doesn't happen and 'Tnf' is correctly; > plotted twice.; >; > I know this is a small bug that most people will probably not run across,; > but just in case you're comparing expression across similar groups this; > might be a useful fix. Thanks!; >; > [image: stacked_violin_global]; > <https://user-images.githubusercontent.com/37122760/44924265-bd353000-ad18-11e8-84d0-a0136083dbdd.png>; >; > [image: dotplot_global]; > <https://user-images.githubusercontent.com/37122760/44924244-aa226000-ad18-11e8-9351-4b28d11a7ee5.png>; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/252>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1Z1BA7WgQycvMb5E4fHkMuW1p1idks5uWWNxgaJpZM4WVgcM>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/252#issuecomment-417836666:908,error,error,908,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/252#issuecomment-417836666,1,['error'],['error']
Availability,dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_compare - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - Asser,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:47209,Error,Error,47209,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,duals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scan,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4674,ERROR,ERROR,4674,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,"e 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.18; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pygments 2.9.0; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.25.1; scanpy 1.7.2; scipy 1.5.3; seaborn 0.11.1; send2trash NA; setuptools_scm NA; sinfo 0.3.1; six 1.16.0; sklearn 0.24.2; sniffio 1.2.0; socks 1.7.1; sphinxcontrib NA; statsmodels 0.12.2; storemagic NA; tables 3.6.1; tblib 1.7.0; terminado 0.10.0; texttable 1.6.3; tlz 0.11.0; toolz 0.11.1; tornado 6.1; traitlets 5.0.5; typing_extensions NA; urllib3 1.26.4; wcwidth 0.2.5; websocket 0.57.0; yaml 5.4.1; zmq 22.0.3; zope NA; -----; IPython 7.23.1; jupyter_client 6.1.12; jupyter_core 4.7.1; jupyterlab 3.0.16; notebook 6.4.0; -----; Python 3.8.10 (default, May 19 2021, 18:05:58) [GCC 7.3.0]; Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.10; 4 logical CPU cores, x86_64; -----; Session information updated at 2021-05-25 15:50. </Details>. I'm still trying to update h5py in the old environment, which has quite some inconsistencies in it, considerably slowing everything down. At some point it looked like I had success with installing h5py 3.2.1 from conda-forge after running `conda update anaconda` and `conda update --all` (as per [here](https://stackoverflow.com/questions/56072846/how-to-resolve-inconsistent-package-warnings-in-conda)). But now this environment leads to an ImportError when importing scanpy: `ImportError: /home/karl/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/h5py/defs.cpython-38-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_ros3`; Can it be that pip version of scanpy doesn't see the updated conda version of h5py?. <Details>; <summary>Inconsistencies in the old environment</summary>. ```; The following packages are causing the inconsistency:. - defaults/linux-64::_anaconda_depends==2020.07=py38_0; - defaults/linux-64::anaconda==custom=py38_1; - defaults/linux-64::cairo==1.14.12=h8948797_3; - defaults/linux-64::graphviz==2.40.1=h21bd128_2; - defaults/linux-64",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310:2144,down,down,2144,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310,1,['down'],['down']
Availability,"e of those wheels are big, you need to clean that directory from time to time anyway if you have little space. > I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for 1-3 built-in commands. Other people are interested in creating those scripts (and did so already, but for the time being just call `scanpy-mycommand` with a dash in there). > I wa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:1145,down,downloaded,1145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940,1,['down'],['downloaded']
Availability,"e the way Anndata works means that its metadata must be computed eagerly after each operation in the Zheng17 recipe, rather than lazily for the whole computation (which is the way Dask works). Another option would be to see if you can swap out Anndata for Xarray. This is a big change obviously, and probably pretty disruptive to the existing codebase, but it would align you with many other software projects and scientific communities that are currently thinking about these exact same problems. My guess is that in the long run it would save you time, assuming that Xarray DataArrays meet your needs semantically. > Many operations work, however cupyx.scipy.sparse has a number of missing features that mean it can’t be used for Zheng17 yet. It would require significant work in CuPy to get it working:. I could imagine that these might be in scope for NVidia folks to work on in a few months (no promises though). If you wanted to raise these as issues there to track things that would be helpful. cc @jakirkham @pentschev. > However, when I tried NumPy 1.17 the Dask implementation slowed down significantly. I haven't been able to pinpoint the issue. I would be curious to know what's going on here if you find out. >> Any chance you did any profiling of these runs? I'd be interested in seeing the performance impact across the pipeline. > The closest I got to this was using the Dask web UI to watch tasks being run (see this part of the benchmark script: https://github.com/tomwhite/scanpy/blob/sparse-dask/benchmark.py#L54-L55). This is useful to see what operations are bottlenecks. The only timings I did were to run the complete recipe. +1 on profiling. I suggest that you first start with `compute(scheduler=""single-threaded"")` and the cProfile module. This will avoid any parallelism, and hopefully let you use profiling techniques that are more familiar to you. I personally like snakeviz. . If you want to get on a screenshare some time I'm happy to look at dashboard plots with you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/921#issuecomment-557191880:2209,down,down,2209,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/921#issuecomment-557191880,1,['down'],['down']
Availability,"e; 7 . ~\.conda\envs\NewPy38\lib\site-packages\numba\__init__.py in <module>; 198 ; 199 _ensure_llvm(); --> 200 _ensure_critical_deps(); 201 ; 202 # we know llvmlite is working as the above tests passed, import it now as SVML. ~\.conda\envs\NewPy38\lib\site-packages\numba\__init__.py in _ensure_critical_deps(); 138 raise ImportError(""Numba needs NumPy 1.18 or greater""); 139 elif numpy_version > (1, 21):; --> 140 raise ImportError(""Numba needs NumPy 1.21 or less""); 141 ; 142 try:. ImportError: Numba needs NumPy 1.21 or less; ```; Step5: I do` !pip uninstall Numpy`, then; ```python; !pip install numpy; Requirement already satisfied: numpy in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (1.21.5). import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). AttributeError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8308/1710492625.py in <module>; 1 import numpy as np; ----> 2 import pandas as pd; 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\pandas\__init__.py in <module>; 20 ; 21 # numpy compat; ---> 22 from pandas.compat import (; 23 np_version_under1p18 as _np_version_under1p18,; 24 is_numpy_dev as _is_numpy_dev,. ~\.conda\envs\NewPy38\lib\site-packages\pandas\compat\__init__.py in <module>; 12 import warnings; 13 ; ---> 14 from pandas._typing import F; 15 from pandas.compat.numpy import (; 16 is_numpy_dev,. ~\.conda\envs\NewPy38\lib\site-packages\pandas\_typing.py in <module>; 82 # array-like; 83 ; ---> 84 ArrayLike = Union[""ExtensionArray"", np.ndarray]; 85 AnyArrayLike = Union[ArrayLike, ""Index"", ""Series""]; 86 . AttributeError: module 'numpy' has no attribute 'ndarray'; ```; It looks like an endless error. What's wrong with the `!pip install scanpy[leiden]`? It installed so many incompatible packages which never happened before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:8491,error,error,8491,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841,1,['error'],['error']
Availability,"e; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output. note: This is an issue with the package mentioned above, not pip.; hint: See above for details.; Exception information:; Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper; status = run_func(*args); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/minic",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:4630,error,error,4630,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,2,['error'],['error']
Availability,"e_linked_requirement(self._ireq, parallel_builds=True); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 491, in prepare_linked_requirement; return self._prepare_linked_requirement(req, parallel_builds); ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 577, in _prepare_linked_requirement; dist = _get_prepared_distribution(; ^^^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/prepare.py"", line 69, in _get_prepared_distribution; abstract_dist.prepare_distribution_metadata(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/distributions/sdist.py"", line 61, in prepare_distribution_metadata; self.req.prepare_metadata(); File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/req/req_install.py"", line 541, in prepare_metadata; self.metadata_directory = generate_metadata_legacy(; ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 71, in generate_metadata; raise MetadataGenerationFailed(package_details=details) from error; pip._internal.exceptions.MetadataGenerationFailed: metadata generation failed; Remote version of pip: 22.3.1; Local version of pip: 22.3.1; Was pip installed by pip? False; Removed numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) from build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Removed build tracker: '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:10564,error,error,10564,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['error'],['error']
Availability,earson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_gene,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4226,ERROR,ERROR,4226,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,"ed graph is prohibitive computationally (memory and CPU time wise).; > Intuitively, I'd think having a more complete graph with weighted edges is more representative of the data than an arbitrary k neighbors. Even if you do use a hard cutoff on number of neighbors, I don't see how discounting all distance information would give a more accurate result. I would suspect using a weighted graph could perform better at identifying small subpopulations (where nearest neighbors from other cell types could be common), but that's just conjecture. That's just speculation to me. I never saw convincing benchmarks. No one claims that ""discounting all distance information gives a more accurate result"". It's just that it's computationally cheaper. I acknowledge that a ""non-fixed-degree knn graph"" varying say, between 5 and 100, would be computationally tractable and would carry information about the sampling density of the data in the given representation. This information is only indirectly available in the fixed-degree knn graph (more loops etc. in high-density regions). I never investigated this as I never saw fundamental results on such a non-fixed-degree knn graph. As it's also hard to benchmark this, I'd be afraid of getting into this if one doesn't have the time to get the fundamentals right. I want to note that even in the context of diffusion processes, we managed to obtain meaningful results with kNN graphs in practice. And this clearly contradicts the fundamental results found in all the Coifman papers. Having said that: if the code is simple, I don't mind at all to have the possibility that you suggest, @ivirshup. Please go ahead with a pull request and I'll see whether the changes are simple enough. The user will still use the default plain knn version, which is also what is done in Seurat. But my philosophy rests the same: rather than engineering the clustering or any other aspect of the manifold analysis, one should engineer the representation. Sorry that this got a b",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/240#issuecomment-416725777:1915,avail,available,1915,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/240#issuecomment-416725777,1,['avail'],['available']
Availability,ed_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncN,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49319,Error,Error,49319,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"elopment version:. ```; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); <ipython-input-36-2ee11f6b7699> in <module>; ----> 1 axs = sc.pl.pca(adata, color=['P36957'], gene_symbols='Accession', size=cellsize, wspace=wspace, hspace=hspace, ncols=3, show=False, use_raw=True). /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in pca(adata, **kwargs); 732 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 733 """"""; --> 734 return embedding(adata, 'pca', **kwargs); 735 ; 736 . /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 243 itertools.product(color, idx_components); 244 ):; --> 245 color_source_vector = _get_color_source_vector(; 246 adata,; 247 value_to_plot,. /mnt/c/Users/q/Downloads/scanpy/scanpy/plotting/_tools/scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups); 1016 ):; 1017 # We should probably just make an index for this, and share it over runs; -> 1018 value_to_plot = adata.var.index[adata.var[gene_symbols] == value_to_plot][; 1019 0; 1020 ] # TODO: Throw helpful error if this doesn't work. ~/miniconda3/envs/sc/lib/python3.8/site-packages/pandas/core/indexes/base.py in __getitem__(self, key); 4095 if is_scalar(key):; 4096 key = com.cast_scalar_indexer(key, warn_float=True); -> 4097 return getitem(key); 4098 ; 4099 if isinstance(key, slice):. IndexError: index 0 is out of bounds for axis 0 with size 0; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1277#issuecomment-703912344:1328,Down,Downloads,1328,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1277#issuecomment-703912344,2,"['Down', 'error']","['Downloads', 'error']"
Availability,envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:73005,ERROR,ERROR,73005,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"envs/py48/lib/site-packages/numba/core/dispatcher.py?line=151) cres = compiler.compile_extra(self.targetdescr.typing_context,; [153](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=152) self.targetdescr.target_context,; [154](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=153) impl,; [155](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=154) args=args, return_type=return_type,; [156](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=155) flags=flags, locals=self.locals,; [157](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=156) pipeline_class=self.pipeline_class); [158](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=157) # Check typing error if object mode is used; [159](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=158) if cres.typing_error is not None and not flags.enable_pyobject:. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); [669](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=668) """"""Compiler entry point; [670](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=669) ; [671](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=670) Parameter; (...); [689](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=688) compiler pipeline; [690](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=689) """"""; [691](file:///d%3A/Users/xiangrong1/Min",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:17829,error,error,17829,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659,1,['error'],['error']
Availability,epos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalizatio,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68427,ERROR,ERROR,68427,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,eprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cann,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:71713,ERROR,ERROR,71713,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,erplots[pca_with_fonts-fn1] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_markers_colors_with_dimensions-fn10] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[umap_with_edges-fn17] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_mask-fn19] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_groups_and_size - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:54899,ERROR,ERROR,54899,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"es/numba/core/decorators.py?line=218) disp.compile(sig); [220](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/decorators.py?line=219) disp.disable_compile(); [221](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/decorators.py?line=220) return disp. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\dispatcher.py:965, in Dispatcher.compile(self, sig); [963](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=962) with ev.trigger_event(""numba:compile"", data=ev_details):; [964](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=963) try:; --> [965](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=964) cres = self._compiler.compile(args, return_type); [966](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=965) except errors.ForceLiteralArg as e:; [967](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=966) def folded(args, kws):. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type); [124](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=123) def compile(self, args, return_type):; --> [125](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=124) status, retval = self._compile_cached(args, return_type); [126](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=125) if status:; [127](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=126) return retval. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\dispatcher.py:139, in _FunctionCompile",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:14657,error,errors,14657,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659,1,['error'],['errors']
Availability,"est.ini README.rst requirements.txt scanpy setup.py; >>> scanpy-master]$ git init; Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/; >>> scanpy-master]$ git tag v1.4.5.dev0; fatal: Failed to resolve 'HEAD' as a valid ref.; >>> scanpy-master]$ pip install -e .; Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master; Complete output from command python setup.py egg_info:; Traceback (most recent call last):; File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>; from setuptools_scm import get_version; ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>; from scanpy import __author__, __email__; File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>; __version__ = version(__name__); File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version; return version(package); File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version; return distribution(package).version; File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution; return Distribution.from_name(package); File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name; raise PackageNotFoundError(name); importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/838#issuecomment-533019090:1296,Down,Download,1296,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838#issuecomment-533019090,3,"['Down', 'error']","['Download', 'error']"
Availability,est/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbor,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:57076,ERROR,ERROR,57076,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,est_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: ca,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:73681,ERROR,ERROR,73681,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,est_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - I,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74011,ERROR,ERROR,74011,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - Imp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:67288,ERROR,ERROR,67288,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"even with scanpy 1.4.1 my very simple (copied from the tutorial) script; doesn't work. I'm getting the well-known ""TypeError: Categorical is not; ordered for operation max; you can use .as_ordered() to change the Categorical to an ordered one"". So; I downgraded anndata, which lead to another new error. I guess I'd also; have to downgrade pandas now. This makes me wonder if there is some testing; with a standard pipeline done before a release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/728#issuecomment-508769252:251,down,downgraded,251,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/728#issuecomment-508769252,3,"['down', 'error']","['downgrade', 'downgraded', 'error']"
Availability,"exactly! also this makes a lot of sense in the context of the reversed heatmap (where keys of the mapping are plotted as column annotation). ; This is also particularly useful if you have 2 annotations `cluster1=['1','2','3']` and `cluster2=['foo','bar']`, and you want to check for; ```python; markers={; 	""foo"":[""gene1"", ""gene2""],; 	""bar"":[""gene3""]; }; ```; but with respect to `cluster1`. I would have just thrown an error but this is a much more elegant solution!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1511#issuecomment-734861544:420,error,error,420,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511#issuecomment-734861544,1,['error'],['error']
Availability,"f_size=30):; <source elided>. left_node = make_euclidean_tree(data, left_indices, rng_state, leaf_size); ^. @numba.jit(); /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""make_euclidean_tree"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:; @numba.jit(); def make_euclidean_tree(data, indices, rng_state, leaf_size=30):; ^. self.func_ir.loc)); /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:; @numba.jit(); def make_euclidean_tree(data, indices, rng_state, leaf_size=30):; ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)); /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: ; The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:; @numba.njit(parallel=True); def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):; ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state; /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: ; The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/749#issuecomment-515138442:3210,error,errors,3210,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749#issuecomment-515138442,1,['error'],['errors']
Availability,fails these tests:. ```; scanpy/tests/test_embedding_plots.py::test_visium_circles FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_default FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_visium_empty_img_key FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_general FAILED [ 14%]; scanpy/tests/test_embedding_plots.py::test_spatial_external_img FAILED [ 14%]; ...; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1077,ERROR,ERROR,1077,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,"first try the following and check that you don't have any errors. ; ```; cd scanpy/scanpy/tests; py.test test_plotting.py; ```. If that is the case, you can go to this line: https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L36 and add a new test. I usually run the tests after adding the new test case which will fail the first time. But, it generates an image to compare. Then I copy the new image from `./figures/` to `./_images/` and add it to git. Off course you want to check that the image is what you expect. If you re-run the tests they should work now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1511#issuecomment-739930301:58,error,errors,58,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511#issuecomment-739930301,1,['error'],['errors']
Availability,"for very large data (`pp.log1p` and `pp.pca`), where it already gives remarkable memory use reduction in `memory` mode. Of course, this is considerably slower than feeding in the full data matrix. We'll use AnnData's chunked functionality in other tools, soon. We're also using it when working with tensorflow. At some point, when you open an AnnData in `backed` mode, the whole pipeline will run through by processing chunks and the user won't have to do a single change to his or her code. By that, code that has been written for data that fits into memory will automatically scale to many millions of observations. Also, there will be global settings that allow to manually determine whether the whole pipeline should run on chunks but still load the basic data matrix into memory, something we've found useful in several occasions.; - not returning `None` when modifying a reference inplace: the very first draft of Scanpy was written this way. then @flying-sheep remarked, that it shouldn't and I agreed with him right away: if you return the changed object, you'll allow two different variable names for the same reference. This is a dangerous source for bugs - this was one of the few instances where I produced more bugs than in C++, where one would always write inplace functions (taking pointers or references) that return `void`. In addition, returning `None` directly tells the user that the typical code for writing pipelines does not have to be redundant: `function(adata)` instead of `adata = function(adata)`. Finally: all of Scanpy is consistently written using these principles and it would cause a lot of trouble both changing it in a simple function and changing it everywhere. Why do you think that _it allows for a more functional style of writing a processing pipeline_?. Hence, I'm sorry that I tend to not merge your pull request as is. Either you restore everything else that was there and solely add the inplace `np.log1p` or I'd do that. :smile:. Have a good Sunday!; Alex",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/191#issuecomment-403240196:2327,redundant,redundant,2327,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191#issuecomment-403240196,1,['redundant'],['redundant']
Availability,fyi there is scranpy available i have been using it for a while,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3255#issuecomment-2368341703:21,avail,available,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3255#issuecomment-2368341703,1,['avail'],['available']
Availability,"g a good normalization technique anyway (this is argued by any more advanced normalization methods paper, e.g., the [scran pooling paper](http://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-0947-7)), there are a couple of things to consider here:; 1. Do we even want relative expression counts?; 2. What assumptions do downstream methods have on the distribution of expression values. For the first question: relative gene expression values ignore differences in cell sizes/number of molecules in the cell. There are some molecules whose numbers scale with the size of the cell, and others that don't (e.g., many housekeeping genes). Choosing relative over absolute expression values to compare gene expression across cells would be helpful to compare expression of those genes that scale with size, but not the others.... so there's not really a perfect answer here. Thus, removing all effects of total counts may not be the desirable outcome. Secondly, many downstream methods assume normally distributed expression data (e.g., DE methods like: t-tests, limma, MAST, or several batch correction/data integration methods). Log transformation is used as a variance stabilization to approximate a normal distribution (quite often poorly, but better than without). This leads to many methods performing better with log transformation. IMO, the ideal approach is probably something like scVI, GLMPCA, or scTransform, where you fit a model directly to the count data and use the residuals to describe the data. This would address both steps of normalization and variance stabilization at the same time. If we have a good model to describe the data, the residuals should quantify the biological variance + normally distributed noise. Overall, I would use other normalization approaches than CPM, and use log-transformation with anything that uses size factors that scale per-cell expression values. . Note also that the effect described in the second paper you mention (from Aaron Lun) will",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643:1296,down,downstream,1296,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643,1,['down'],['downstream']
Availability,g/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:56070,ERROR,ERROR,56070,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,g/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:60078,ERROR,ERROR,60078,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,g/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:58412,ERROR,ERROR,58412,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Ima,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48357,Error,Error,48357,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"ges/anndata/_core/merge.py in <listcomp>(.0); 529 dfs: Iterable[pd.DataFrame], new_index, merge_strategy=merge_unique; 530 ) -> pd.DataFrame:; --> 531 dfs = [df.reindex(index=new_index) for df in dfs]; 532 # New dataframe with all shared data; 533 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/anaconda3/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 310 @wraps(func); 311 def wrapper(*args, **kwargs) -> Callable[..., Any]:; --> 312 return func(*args, **kwargs); 313 ; 314 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs); 4174 kwargs.pop(""axis"", None); 4175 kwargs.pop(""labels"", None); -> 4176 return super().reindex(**kwargs); 4177 ; 4178 def drop(. ~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4810 # perform the reindex on the axes; 4811 return self._reindex_axes(; -> 4812 axes, level, limit, tolerance, method, fill_value, copy; 4813 ).__finalize__(self, method=""reindex""); 4814 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4021 if index is not None:; 4022 frame = frame._reindex_index(; -> 4023 index, method, copy, level, fill_value, limit, tolerance; 4024 ); 4025 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance); 4043 copy=copy,; 4044 fill_value=fill_value,; -> 4045 allow_dups=False,; 4046 ); 4047 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups); 4881 fill_value=fill_value,; 4882 allow_dups=allow_dups,; -> 4883 copy=copy,; 4884 ); 4885 # If we've made a copy once, no need to make another one. ~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, ne",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683:2828,toler,tolerance,2828,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683,1,['toler'],['tolerance']
Availability,"get_result_as_array(self); 1480 float_format = lambda value: self.float_format % value; 1481 ; -> 1482 formatted_values = format_values_with(float_format); 1483 ; 1484 if not self.fixed_width:. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in format_values_with(float_format); 1454 values = self.values; 1455 is_complex = is_complex_dtype(values); -> 1456 values = format_with_na_rep(values, formatter, na_rep); 1457 ; 1458 if self.fixed_width:. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in format_with_na_rep(values, formatter, na_rep); 1425 mask = isna(values); 1426 formatted = np.array(; -> 1427 [; 1428 formatter(val) if not m else na_rep; 1429 for val, m in zip(values.ravel(), mask.ravel()). ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in <listcomp>(.0); 1426 formatted = np.array(; 1427 [; -> 1428 formatter(val) if not m else na_rep; 1429 for val, m in zip(values.ravel(), mask.ravel()); 1430 ]. ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(). ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/IPython/core/formatters.py in __call__(self, obj); 343 method = get_real_method(obj, self.print_method); 344 if method is not None:; --> 345 return method(); 346 return None; 347 else:. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/core/frame.py in _repr_html_(self); 1045 decimal=""."",; 1046 ); -> 1047 return fmt.DataFrameRenderer(formatter).to_html(notebook=True); 1048 else:; 1049 return None. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in to_html(self, buf, encoding, classes, notebook, border, table_id, render_links); 1027 render_links=render_links,; 1028 ); -> 1029 string = html_formatter.to_string(); 1030 return save_to_buf",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2008#issuecomment-947943666:5917,mask,mask,5917,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008#issuecomment-947943666,1,['mask'],['mask']
Availability,"ggeration factor or the learning rate; might be too high. If the cost function gets stuck in a bad local; minimum increasing the learning rate helps sometimes. **random_state** : `int` or `None`, optional (default: 0). Change this to use different intial states for the optimization. If `None`,; the initial state is not reproducible. **use_fast_tsne** : `bool`, optional (default: `True`). Use the MulticoreTSNE package by D. Ulyanov if it is installed. **n_jobs** : `int` or `None` (default: `sc.settings.n_jobs`). Number of jobs. **copy** : `bool` (default: `False`). Return a copy instead of writing to adata. :Returns:. Depending on `copy`, returns or updates `adata` with the following fields. . **X_tsne** : `np.ndarray` (`adata.obs`, dtype `float`); ```. Now let's look at `pp.neighbors` where you're reading the type annotations from the signature.; - Obviously, the signature itself now is a mess for humans to read. But ok, that's fine if the docstring is easy to read.; - There is an error ` <class 'inspect._empty'>`; - The rest looks good to me, except for the superficial stylistic remarks above.; ```; Signature: sc.pp.neighbors(adata:anndata.base.AnnData, n_neighbors:int=15, n_pcs:Union[int, NoneType]=None, use_rep:Union[str, NoneType]=None, knn:bool=True, random_state:Union[int, mtrand.RandomState, NoneType]=0, method:str='umap', metric:Union[str, Callable[[numpy.ndarray, numpy.ndarray], float]]='euclidean', metric_kwds:Mapping[str, Any]={}, copy:bool=False) -> Union[anndata.base.AnnData, NoneType]; Docstring:; Compute a neighborhood graph of observations [McInnes18]_. The neighbor search efficiency of this heavily relies on UMAP [McInnes18]_,; which also provides a method for estimating connectivities of data points -; the connectivity of the manifold (`method=='umap'`). If `method=='diffmap'`,; connectivities are computed according to [Coifman05]_, in the adaption of; [Haghverdi16]_. :Parameters:. **adata** : AnnData, optional (default: <class 'inspect._empty'>). ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/192#issuecomment-404108999:3924,error,error,3924,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192#issuecomment-404108999,1,['error'],['error']
Availability,"github.com/theislab/scanpy.git ; ```; I got ouput as:; ```; Collecting git+https://github.com/theislab/scanpy.git; Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build; fatal: Unable to find remote helper for 'https'; Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None; ```. second, I tried; ```; pip install git+git://github.com/theislab/scanpy.git ; ```; I got ouput as:; ```; Collecting git+git://github.com/theislab/scanpy.git; Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build; ```; and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```; python setup.py build; ```. I got ouput as:. ```; importlib_metadata.PackageNotFoundError: scanpy; ```. after this, I tried . ```; pip install -e .; ```. I got ouput as:. ```; Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/; ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` ; pip install https://github.com/theislab/scanpy.git; ```. output:. ```; Collecting https://github.com/theislab/scanpy.git; Downloading https://github.com/theislab/scanpy.git; \ 143kB 442kB/s; Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format; Cannot determine archive format of /tmp/pip-xolhyav7-build; ```. and i also tried. ```; git clone --recursive git://github.com/theislab/scanpy.git; ```. output:. ```; Cloning into 'scanpy'...; remote: Enumerating objects: 122, done.; remote: Counting objects: 100% (122/122), done.; remote: Compressing objects: 100% (109/109), done.; Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s; fatal: The remote end hung up unexpectedly MiB | ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/838#issuecomment-532985027:1117,error,error,1117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838#issuecomment-532985027,2,"['Down', 'error']","['Download', 'error']"
Availability,good catch! Thank you for reporting this. ; Pinging @Koncopd since I believe you were involved in major refactoring of this. ; Thank you @rpeys,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1292#issuecomment-704767951:44,Ping,Pinging,44,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1292#issuecomment-704767951,1,['Ping'],['Pinging']
Availability,groups_and_size - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:55740,ERROR,ERROR,55740,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"hard to say what could cause that, there are a lot of changes between the two envs. but we might be able to pin it down with that, thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3116#issuecomment-2185889395:115,down,down,115,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116#issuecomment-2185889395,1,['down'],['down']
Availability,hbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - Impo,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:60243,ERROR,ERROR,60243,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,hbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:57905,ERROR,ERROR,57905,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,hbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:59241,ERROR,ERROR,59241,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,hbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:56569,ERROR,ERROR,56569,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,hbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:58074,ERROR,ERROR,58074,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"he functionalities and setup and it does look very nice!. - BCR makes sense to add, there seems to be generally less happening in this space in single-cell though right now, compared to TCR. Would be good to have somebody on board who actually works on this data.; - [tcellmatch](https://github.com/theislab/tcellmatch)'s primary purpose is specificity prediction, this could be easily added ontop of this, I will look into your data structure and will think about the necessary changes. I am in the process of making this code public anyway, hopefully next week or so.; - You mentioned distance metrics, this is definitely an interesting and relevant area, in [tcellmatch](https://github.com/theislab/tcellmatch), we implicitly use 1. manhatten distances, 2. euclidian distances in BLOSUM embedding and 3. learned embedding distances, 2. and maybe 3. could be potentially integrated, would be worth discussing in any case.; - Integration with epitope data bases: I have data loaders for IEDB and VDJdb downloads, can you be a bit more specific how you would integrate that with exploratorive single-cell studies? I can only imagine searching for similar TCRs? These anticipated use cases would determine how and whether this makes sense i think.; - Potentially additionally relevant: An integration with dextramer counts to ""stain"" TCR specificity? There is the purely numeric, standard multi-modal single-cell, nature to this data that can be covered by standard scanpy work flows. This data is especially useful in the context of clonotypes etc which then would require additional functionalities, which could be built on what you have here. I have been looking into this type of analysis a lot in context of tcellmatch. Would be to contribute but also happy to see what other people do here, too!. Could you add a brief summary of how you use anndata to store the TCR data in the docs? That would be very helpful to design extension or custom workflows. Great docs otherwise though!. Best,; David",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1163#issuecomment-613297254:1042,down,downloads,1042,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163#issuecomment-613297254,1,['down'],['downloads']
Availability,"heck_bool_indexer(self.index, key); 910 ; --> 911 return self._get_with(key); 912 ; 913 def _get_with(self, key):. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key); 951 return self.loc[key]; 952 ; --> 953 return self.reindex(key); 954 except Exception:; 955 # [slice(0, 5, None)] will break if you convert to ndarray,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs); 3732 @Appender(generic.NDFrame.reindex.__doc__); 3733 def reindex(self, index=None, **kwargs):; -> 3734 return super(Series, self).reindex(index=index, **kwargs); 3735 ; 3736 def drop(self, labels=None, axis=0, index=None, columns=None,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4354 # perform the reindex on the axes; 4355 return self._reindex_axes(axes, level, limit, tolerance, method,; -> 4356 fill_value, copy).__finalize__(self); 4357 ; 4358 def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4367 ax = self._get_axis(a); 4368 new_index, indexer = ax.reindex(labels, level=level, limit=limit,; -> 4369 tolerance=tolerance, method=method); 4370 ; 4371 axis = self._get_axis_number(a). ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance); 501 else:; 502 if not target.is_unique:; --> 503 raise ValueError(""cannot reindex with a non-unique indexer""); 504 ; 505 indexer, missing = self.get_indexer_non_unique(np.array(target)). ValueError: cannot reindex with a non-unique indexer; ```. These the [packages](https://gist.github.com/helios/a8c2f0f74cb9cc26097a0cdf1aed08e9) I have installed for this analysis both conda and pip",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264:1969,toler,tolerance,1969,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264,5,['toler'],['tolerance']
Availability,"hey, thanks for the interest and very good questions, my 2 cents:. > Can we infer from such an analysis how much a pathway is upregulated? (e.g. by calculating the FC of the mean?) . It would be great to conclude for example, that Pathway X is 30% more active, in condition Y. I think you could yes, maybe complementary to some standard approaches like hypergeometric test?. > How does in your opinion class-imbalance affect the analysis? For example, Condition A has 10 samples, while for Condition B,C.. I only have 3 each?. since you have densitieis, it should be ok (?). you could also try subsampling the condition where you have more samples n times. > I am happy to provide the code for the density distributions to visualise the results of the gene-set-score function. thanks, very much appreciated! Actually I don't think we have really a class/example of density/line plots in scanpy. Not sure if it can be of broad use/scope. . pinging @dawe (original author of the function).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1629#issuecomment-776883494:939,ping,pinging,939,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1629#issuecomment-776883494,1,['ping'],['pinging']
Availability,hi @Hrovatin ; so was it useful for your task? Curious to hear. Couple of questions:; - why having a tool redundant between two packages? ; - what is SEMITONES?; thank you!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1698#issuecomment-787484724:106,redundant,redundant,106,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1698#issuecomment-787484724,1,['redundant'],['redundant']
Availability,"hi @MertDemirdizen @sophieRAIBAUD ; sorry for late reply. This type of functionality is planned to be added to squidpy (there is an issue also there discussing the same). I'd close this here since the scanpy spatial plot will be deprecated, feel free to reopen/ping me in the squidpy repo directly",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2252#issuecomment-1249576288:261,ping,ping,261,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2252#issuecomment-1249576288,1,['ping'],['ping']
Availability,"hi @Tycooner, the same error happened to me recently when clustering using leiden, is there any idea what happened here and if you have any solution?. similar situation here: with large dataset and tried to set different resolution parameters when run sc.tl.leiden",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1980#issuecomment-1042669892:23,error,error,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980#issuecomment-1042669892,1,['error'],['error']
Availability,"hi @jlause ,. thanks again for moving the code over `experimental` and sorry for the delay. I give up with the docs, they keep failing on a very weird issue that I can't address (now it's request error from scipy, but before was some stupid indentation that I could not fix). . I realized that you forgot to copy over the `recipes`. Now it's there and working, I have a minor comment on copying over `X_pca` to `X_pearson_residuals_pca`. I think it should remain `X_pca` since the normalization is performed on `X`. Or am I missing something for such return to be chosen?. Meanwhile I'd also like to ping @ivirshup for taking a look at the experimental API and whether he agrees on the current structure as well as docs. remaining TOD:. - [ ] fix docs; - [ ] add tutorial to docs (should be done when tutorial has been reviewed)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-890768314:196,error,error,196,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-890768314,2,"['error', 'ping']","['error', 'ping']"
Availability,"hi @ktpolanski ,thank you for the heads up. > A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument spaceranger_image_path to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. > The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location. @LucaMarconato do we have any datasets that test for spaceranger 3.0.1 ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2992#issuecomment-2332223204:282,robust,robust,282,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992#issuecomment-2332223204,1,['robust'],['robust']
Availability,"hi, it is actually just one line code. here it is:; ad['leiden'] = rapids_scanpy_funcs.leiden(ad). rapids_scanpy_funcs.leiden can be downloaded from the link",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2358#issuecomment-1372935932:133,down,downloaded,133,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358#issuecomment-1372935932,1,['down'],['downloaded']
Availability,"hi,I wonder if this problem has been solved? This error also occurred recently when I used this code",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2286#issuecomment-1265013360:50,error,error,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2286#issuecomment-1265013360,1,['error'],['error']
Availability,"hi,I wonder if this problem has been solved? This error also occurred recently when I used this code, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2286#issuecomment-1973497725:50,error,error,50,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2286#issuecomment-1973497725,1,['error'],['error']
Availability,highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matrix-False] PASSED [ 83%]; ```. so maybe `test_recipe_plotting`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:5134,ERROR,ERROR,5134,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,"hon3.6/site-packages/umap/umap_.py"", line 467:; def fuzzy_simplicial_set(; <source elided>; if knn_indices is None or knn_dists is None:; knn_indices, knn_dists, _ = nearest_neighbors(; ^. @numba.jit(); /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:; @numba.jit(); def fuzzy_simplicial_set(; ^. self.func_ir.loc)); /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: ; Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:; @numba.jit(); def fuzzy_simplicial_set(; ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)); OrderedDict([('neighbors', {'params': {'n_neighbors': 100, 'method': 'umap', 'metric': 'euclidean'}, 'distances': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'; 	with 1803087 stored elements in Compressed Sparse Row format>, 'connectivities': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'; 	with 2667882 stored elements in Compressed Sparse Row format>}), ('iroot', 0)]); WARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters.; WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`); WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`); WARNING: detected group with only [] cells; ```. </details>; <details><summary>Traceback</summary>. ```pytb; ValueError Traceback (most recent call last); ~/dif",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/749#issuecomment-515138442:5664,error,errors,5664,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749#issuecomment-515138442,1,['error'],['errors']
Availability,"https://docs.python.org/3/library/warnings.html#temporarily-suppressing-warnings. ```py; import numba; import warnings. with warnings.catch_warnings():; warnings.simplefilter('ignore', numba.errors.NumbaDeprecationWarning):; do_thing(); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/688#issuecomment-504451555:191,error,errors,191,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/688#issuecomment-504451555,1,['error'],['errors']
Availability,"i encountered this error when using a new conda env in pycharm after install scannpy in cmd line according to scannpy manual. . I don;t know why but I didn't experience the error any longer if I set up new conda env and install scannpy in cmd line, and call spyder to run the same codes to import python packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-966679910:19,error,error,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-966679910,2,['error'],['error']
Availability,i met the same error when using sc.pl.dotplot. did you fix that?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2125#issuecomment-1036952400:15,error,error,15,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2125#issuecomment-1036952400,1,['error'],['error']
Availability,id not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[pca] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-float32-100n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[spatial] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_dimension_broadcasting - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_marker_broadcasting - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_compare - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionErro,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:46230,Error,Error,46230,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"ies.py in __getitem__(self, key); 909 key = check_bool_indexer(self.index, key); 910 ; --> 911 return self._get_with(key); 912 ; 913 def _get_with(self, key):. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in _get_with(self, key); 951 return self.loc[key]; 952 ; --> 953 return self.reindex(key); 954 except Exception:; 955 # [slice(0, 5, None)] will break if you convert to ndarray,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/series.py in reindex(self, index, **kwargs); 3732 @Appender(generic.NDFrame.reindex.__doc__); 3733 def reindex(self, index=None, **kwargs):; -> 3734 return super(Series, self).reindex(index=index, **kwargs); 3735 ; 3736 def drop(self, labels=None, axis=0, index=None, columns=None,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4354 # perform the reindex on the axes; 4355 return self._reindex_axes(axes, level, limit, tolerance, method,; -> 4356 fill_value, copy).__finalize__(self); 4357 ; 4358 def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,. ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/generic.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4367 ax = self._get_axis(a); 4368 new_index, indexer = ax.reindex(labels, level=level, limit=limit,; -> 4369 tolerance=tolerance, method=method); 4370 ; 4371 axis = self._get_axis_number(a). ~/jupyterminiconda3/envs/scanpy137/lib/python3.6/site-packages/pandas/core/indexes/category.py in reindex(self, target, method, level, limit, tolerance); 501 else:; 502 if not target.is_unique:; --> 503 raise ValueError(""cannot reindex with a non-unique indexer""); 504 ; 505 indexer, missing = self.get_indexer_non_unique(np.array(target)). ValueError: cannot reindex with a non-unique indexer; ```. These the [packages](https://gist.github.com/helios/a8c2f0f74cb9cc26097a0cdf1aed08e9) I have i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264:1847,toler,tolerance,1847,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/450#issuecomment-460303264,1,['toler'],['tolerance']
Availability,"ighbors=10, n_pcs=40, random_state=14); sc.write('test8_randomized.h5ad', adata); ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs; %env PYTHONHASHSEED=0; import numpy as np; import pandas as pd; import scanpy as sc; adata = sc.read_10x_mtx(; './data/filtered_gene_bc_matrices/hg19/', ; var_names='gene_symbols',; cache=True) . sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); adata = adata.copy(); sc.pp.scale(adata, max_value=10); sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5); adata = adata[:, adata.var.highly_variable]; sc.tl.pca(adata, svd_solver='arpack', random_state=14); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14); sc.write('test16.h5ad', adata); sc.tl.pca(adata, svd_solver='randomized', random_state=14); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14); sc.write('test16_randomized.h5ad', adata); ! echo $PYTHONHASHSEED. # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver; adata8 = sc.read('test8.h5ad'); adata16 = sc.read('test16.h5ad'); print((adata8.X != adata16.X).sum()); print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()); print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()); sc.tl.leiden(adata8, random_state=14); sc.tl.leiden(adata16, random_state=14); display(adata8.obs['leiden'].value_counts()); display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the randomized solver; adata8 = sc.read('test8_randomized.h5ad'); adata16 = sc.read('test16_randomized.h5ad'); print((adata8.X != adata16.X).sum()); print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()); print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()); sc.tl.leiden(adata",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1187#issuecomment-620841409:2074,echo,echo,2074,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187#issuecomment-620841409,1,['echo'],['echo']
Availability,iles did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-n,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:43318,Error,Error,43318,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"in <module>; 30 import umap.distances as dist; 31 ; ---> 32 import umap.sparse as sparse; 33 ; 34 from umap.utils import (. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/umap/sparse.py in <module>; 10 import numpy as np; 11 ; ---> 12 from umap.utils import norm; 13 ; 14 locale.setlocale(locale.LC_NUMERIC, ""C""). ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/umap/utils.py in <module>; 38 ; 39 @numba.njit(""i4(i8[:])""); ---> 40 def tau_rand_int(state):; 41 """"""A fast (pseudo)-random number generator.; 42 . ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func); 219 with typeinfer.register_dispatcher(disp):; 220 for sig in sigs:; --> 221 disp.compile(sig); 222 disp.disable_compile(); 223 return disp. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig); 907 with ev.trigger_event(""numba:compile"", data=ev_details):; 908 try:; --> 909 cres = self._compiler.compile(args, return_type); 910 except errors.ForceLiteralArg as e:; 911 def folded(args, kws):. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 77 ; 78 def compile(self, args, return_type):; ---> 79 status, retval = self._compile_cached(args, return_type); 80 if status:; 81 return retval. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 91 ; 92 try:; ---> 93 retval = self._compile_core(args, return_type); 94 except errors.TypingError as e:; 95 self._failed_cache[key] = e. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 104 ; 105 impl = self._get_implementation(args, {}); --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,; 107 self.targetdescr.target_context,; 108 impl,. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-846931466:2794,error,errors,2794,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-846931466,1,['error'],['errors']
Availability,"ing... done. # All requested packages already installed. Collecting package metadata (current_repodata.json): ...working... done; Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.; Collecting package metadata (repodata.json): ...working... done; Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve. PackagesNotFoundError: The following packages are not available from current channels:. - scanpy. Current channels:. - https://conda.anaconda.org/conda-forge/linux-64; - https://conda.anaconda.org/conda-forge/noarch; - https://repo.anaconda.com/pkgs/main/linux-64; - https://repo.anaconda.com/pkgs/main/noarch; - https://repo.anaconda.com/pkgs/r/linux-64; - https://repo.anaconda.com/pkgs/r/noarch. To search for alternate channels that may provide the conda package you're; looking for, navigate to. https://anaconda.org. and use the search bar at the top of the page. Error: one or more Python packages failed to install [error code 1]; ```. If I switch to the terminal and try `pip` or `conda` I get:. ```; pip install scanpy; ```. ```; Requirement already satisfied: scanpy in /home/tsundoku/anaconda3/lib/python3.7/site-packages (1.4.5.post2); Requirement already satisfied: setuptools-scm in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from scanpy) (3.3.3); Requirement already satisfied: scipy>=1.3 in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from scanpy) (1.3.2); Requirement already satisfied: pandas>=0.21 in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from scanpy) (0.25.3); Requirement already satisfied: packaging in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from scanpy) (19.2); Requirement already satisfied: natsort in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from scanpy) (7.0.0); Requirement already satisfied: statsmodels>=0.10.0rc2 in /home/tsundoku/anaconda3/lib/python3.7/site-packages (from scanpy) (0.10.1); Requirement alre",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990#issuecomment-575281452:1169,Error,Error,1169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990#issuecomment-575281452,2,"['Error', 'error']","['Error', 'error']"
Availability,ing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_n,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:59410,ERROR,ERROR,59410,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalizati,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:59909,ERROR,ERROR,59909,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:56738,ERROR,ERROR,56738,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbor,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:58243,ERROR,ERROR,58243,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"iniconda3/envs/py48/lib/contextlib.py?line=131) except StopIteration as exc:; [133](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=132) # Suppress StopIteration *unless* it's the same exception that; [134](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=133) # was passed to throw(). This prevents a StopIteration; [135](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=134) # raised inside the ""with"" statement from being suppressed.; [136](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=135) return exc is not value. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\errors.py:837, in new_error_context(fmt_, *args, **kwargs); [835](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=834) else:; [836](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=835) tb = None; --> [837](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=836) raise newerr.with_traceback(tb); [838](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=837) elif use_new_style_errors():; [839](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=838) raise e. LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x00000242239BD700> (trying to write member #1). File ""D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\umap\layouts.py"", line 53:; def rdist(x, y):; <source elided>; dim = x.shape[0]; for i in range(dim):; ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\umap\layouts.py (53); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:32865,error,errors,32865,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659,3,['error'],['errors']
Availability,"ion(self, fndesc); 188 # Init argument values; 189 self.extract_function_arguments(); --> 190 entry_block_tail = self.lower_function_body(); 191 ; 192 # Close tail of entry block. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/lowering.py in lower_function_body(self); 214 bb = self.blkmap[offset]; 215 self.builder.position_at_end(bb); --> 216 self.lower_block(block); 217 self.post_lower(); 218 return entry_block_tail. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/lowering.py in lower_block(self, block); 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; 229 loc=self.loc, errcls_=defaulterrcls):; --> 230 self.lower_inst(inst); 231 self.post_block(block); 232 . ~/.conda/envs/rpy/lib/python3.9/contextlib.py in __exit__(self, type, value, traceback); 133 value = type(); 134 try:; --> 135 self.gen.throw(type, value, traceback); 136 except StopIteration as exc:; 137 # Suppress StopIteration *unless* it's the same exception that. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs); 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)); 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None; --> 751 raise newerr.with_traceback(tb); 752 ; 753 . LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Storing i64 to ptr of i32 ('dim'). FE type int32. File ""../../../../../../../.conda/envs/rpy/lib/python3.9/site-packages/umap/layouts.py"", line 52:; def rdist(x, y):; <source elided>; result = 0.0; dim = x.shape[0]; ^. During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /public/home/ycxiang_zju/.conda/envs/rpy/lib/python3.9/site-packages/umap/layouts.py (52); ```; ​; sc.pp.filter_cells(unspliced, min_genes=200); dyn.pl.basic_stats(spliced)`; I am wondering how to solve this problem. Will I need to re-create a virtual environment with lower python verison?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796:9559,error,errors,9559,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796,1,['error'],['errors']
Availability,ions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_groups_and_size - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbor,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:55571,ERROR,ERROR,55571,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"it should definitely work. on a properly configured system (including docker images), the encoding should be UTF-8. you’re right, we should probably do it. the only reason we didn’t yet is that we open quite a few files in the codebase, and if one of those open calls expects UTF-8, it’ll break again, but this time deeper down and harder to reproduce.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/43#issuecomment-343484072:323,down,down,323,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/43#issuecomment-343484072,1,['down'],['down']
Availability,"it's not clear what the problem here sorry, can you copy the error and report a reproducible example? thank you!; I'll close this for now, feel free to reopen",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1220#issuecomment-702374437:61,error,error,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220#issuecomment-702374437,1,['error'],['error']
Availability,"itch the t-SNE implementation to openTSNE at the very least. For the recipes, there' already something similar in the preprocessing module. So I'd imagine calling standard t-SNE with `sc.tl.tsne` and the recipes like `sc.tl.tsne.recipe_multiscale`. > And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is very similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. I very much prefer option 1. If I understand option 2 correctly, we would normalize the 15 neighbors to essentially `perplexity=5`. I've never once found a case where that is useful, so having this as the default behaviour in scanpy seems like a really bad idea (I foresee a lot of issues in the style ""why is t-SNE not working?""). Using a uniform kernel produces results that are virtually indistinguishable from vanilla t-SNE, so that's fine IMO, and it's faster as well. It's still less than the default `perplexity=30`, but this seems like the best option. Whatever we agree on, the same can be applied to the ingest functionality, so adding that would also be straightforward. > Moreover, we could make the standard t-SNE available by extending sc.pp.neighors with method=""tsne"" (there are several methods there already). I don't understand this, why would this belong on `sc.pp.neighbors`? The graph weighing should go into the `sc.tl.tsne` call. Are the UMAP weights assigned to the graph in `sc.pp.neighbors`? That seems questionable. I would expect the output to be a directed, unweighted graph, and let each method take care of the graph. If anything, I'd expect it to weight it using the Jaccard index of shared nearest neighbors, which seems to me like pretty much the standard thing to do in single-cell analysis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1233#issuecomment-748670360:1452,avail,available,1452,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233#issuecomment-748670360,1,['avail'],['available']
Availability,"ith #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas?. Here is what I ran:. ```; sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); ```. And here is the resulting error:. ```; ValueError Traceback (most recent call last); <ipython-input-117-a5ba74ea872c> in <module>; ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds); 367 ; 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(; --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)); 370 scores[np.isnan(scores)] = 0; 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error; ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611:2064,error,error,2064,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530#issuecomment-505305611,1,['error'],['error']
Availability,"ith non-model species and the majority of gene names are non-informative like ""nbis-gene-11111"", but I am interested in some genes of actin that I deposited in GenBank. I would like to put GB accessions into the plot.) I created the column with following code: [""bob"" is the dataset name]. bob.var['GB_IDs'] = bob.var_names.copy(); ID_dict = {; ""nbis-gene-777"":""MT451954"",; ""nbis-gene-775"":""MT451955"",; ""nbis-gene-3785"":""MT451956"",; ""nbis-gene-3784"":""MT451957"",; ""nbis-gene-23114"":""MT451958"",; ""nbis-gene-25113"":""MT451959"",; ""nbis-gene-3783"":""MT518195""; }; bob.var['GB_IDs'].replace(ID_dict, inplace=True). After that GB_IDs column was present in the dataframe.; And then I tried to plot the dotplot:. dict = {; ""Actin 1"": [""nbis-gene-777""],; ""Actin 2"": [""nbis-gene-775""],; ""Actin 3"": [""nbis-gene-3785""],; ""Actin 4"": [""nbis-gene-3784""],; ""Actin 5"": [""nbis-gene-23114""],; ""Actin 6"": [""nbis-gene-25113""],; ""Actin 7"": [""nbis-gene-3783""]; }; dp=sc.pl.dotplot(bob, dict, ""scGate_multi"", dendrogram=False, return_fig=True, cmap='YlGnBu', gene_symbols='GB_IDs'). This results in an error: . ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); File ~/software/SAMap/lib/python3.9/site-packages/pandas/core/indexes/base.py:3791, in Index.get_loc(self, key); 3790 try:; -> 3791 return self._engine.get_loc(casted_key); 3792 except KeyError as err:. File index.pyx:152, in pandas._libs.index.IndexEngine.get_loc(). File index.pyx:181, in pandas._libs.index.IndexEngine.get_loc(). File pandas/_libs/hashtable_class_helper.pxi:7080, in pandas._libs.hashtable.PyObjectHashTable.get_item(). File pandas/_libs/hashtable_class_helper.pxi:7088, in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'GB_IDs'. If I correctly understand the docs (https://scanpy.readthedocs.io/en/latest/generated/scanpy.pl.dotplot.html), this code should work. I tried also to create such additional column in adata.raw.var, but that did not help as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1636#issuecomment-2048223788:1348,error,error,1348,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1636#issuecomment-2048223788,1,['error'],['error']
Availability,kends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighb,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:57245,ERROR,ERROR,57245,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"l last); <ipython-input-37-b22ada65a1cd> in <module>; 1 # Create Concatenated anndata object for all timepoints; 2 #alldays = e125.concatenate(e135, e145, e155, uns_merge=""unique""); ----> 3 alldays = e125.concatenate(e135). ~/miniconda3/envs/env4sc_velo_scannpy/lib/python3.8/site-packages/anndata/_core/anndata.py in concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas); 1696 all_adatas = (self,) + tuple(adatas); 1697 ; -> 1698 out = concat(; 1699 all_adatas,; 1700 axis=0,. ~/miniconda3/envs/env4sc_velo_scannpy/lib/python3.8/site-packages/anndata/_core/merge.py in concat(adatas, axis, join, merge, uns_merge, label, keys, index_unique, fill_value, pairwise); 799 [dim_indices(a, axis=1 - axis) for a in adatas], join=join; 800 ); --> 801 reindexers = [; 802 gen_reindexer(alt_indices, dim_indices(a, axis=1 - axis)) for a in adatas; 803 ]. ~/miniconda3/envs/env4sc_velo_scannpy/lib/python3.8/site-packages/anndata/_core/merge.py in <listcomp>(.0); 800 ); 801 reindexers = [; --> 802 gen_reindexer(alt_indices, dim_indices(a, axis=1 - axis)) for a in adatas; 803 ]; 804 . ~/miniconda3/envs/env4sc_velo_scannpy/lib/python3.8/site-packages/anndata/_core/merge.py in gen_reindexer(new_var, cur_var); 393 [1., 0., 0.]], dtype=float32); 394 """"""; --> 395 return Reindexer(cur_var, new_var); 396 ; 397 . ~/miniconda3/envs/env4sc_velo_scannpy/lib/python3.8/site-packages/anndata/_core/merge.py in __init__(self, old_idx, new_idx); 265 self.no_change = new_idx.equals(old_idx); 266 ; --> 267 new_pos = new_idx.get_indexer(old_idx); 268 old_pos = np.arange(len(new_pos)); 269 . ~/miniconda3/envs/env4sc_velo_scannpy/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_indexer(self, target, method, limit, tolerance); 2731 ; 2732 if not self.is_unique:; -> 2733 raise InvalidIndexError(; 2734 ""Reindexing only valid with uniquely valued Index objects""; 2735 ). InvalidIndexError: Reindexing only valid with uniquely valued Index objects; ```. Thanks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1409#issuecomment-693478875:3749,toler,tolerance,3749,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1409#issuecomment-693478875,1,['toler'],['tolerance']
Availability,lization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportErro,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:71552,ERROR,ERROR,71552,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"ls>=4.22.0 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (4.25.0); Requirement already satisfied: python-dateutil>=2.7 in c:\users\charles\anaconda3\lib\site-packages (from matplotlib>=3.1.2->scanpy) (2.8.2); Requirement already satisfied: llvmlite>=0.29.0 in c:\users\charles\anaconda3\lib\site-packages (from numba>=0.41.0->scanpy) (0.29.0); Requirement already satisfied: pytz>=2017.3 in c:\users\charles\anaconda3\lib\site-packages (from pandas>=0.21->scanpy) (2021.3); Requirement already satisfied: threadpoolctl>=2.0.0 in c:\users\charles\anaconda3\lib\site-packages (from scikit-learn>=0.21.2->scanpy) (2.2.0); Collecting numba>=0.41.0; Using cached numba-0.55.1-cp37-cp37m-win_amd64.whl (2.4 MB); Requirement already satisfied: pynndescent>=0.5 in c:\users\charles\anaconda3\lib\site-packages (from umap-learn>=0.3.10->scanpy) (0.5.2); Requirement already satisfied: setuptools in c:\users\charles\anaconda3\lib\site-packages (from numba>=0.41.0->scanpy) (58.0.4); Collecting llvmlite>=0.29.0; Using cached llvmlite-0.38.0-cp37-cp37m-win_amd64.whl (23.2 MB); Requirement already satisfied: get-version>=2.0.4 in c:\users\charles\anaconda3\lib\site-packages (from legacy-api-wrap->scanpy) (2.2); Requirement already satisfied: stdlib-list in c:\users\charles\anaconda3\lib\site-packages (from sinfo->scanpy) (0.8.0); Requirement already satisfied: numexpr>=2.6.2 in c:\users\charles\anaconda3\lib\site-packages (from tables->scanpy) (2.8.1); Requirement already satisfied: colorama in c:\users\charles\anaconda3\lib\site-packages (from tqdm->scanpy) (0.4.4); Installing collected packages: llvmlite, numba, xlrd; Attempting uninstall: llvmlite; Found existing installation: llvmlite 0.29.0; Note: you may need to restart the kernel to use updated packages.; ERROR: Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626:5492,ERROR,ERROR,5492,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626,1,['ERROR'],['ERROR']
Availability,"ly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My personal hell certainly includes dozens of libraries and applications putting all kinds of crap in unhidden directories in my home. All of them have a different way to configure that location or none at all. Chills me right to the core.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:1375,avail,available,1375,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890,1,['avail'],['available']
Availability,"m__(cls, name); 356 def __getitem__(cls, name):; --> 357 return cls._member_map_[name]; 358 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-20-38a594ec7d06> in <module>; ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 424 d[k] = read_dataframe(f[k]); 425 else: # Base case; --> 426 d[k] = read_attribute(f[k]); 427 ; 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 161 parent = _get_parent(elem); 162 raise AnnDataReadError(; --> 163 f""Above error raised while reading key {elem.name!r} of ""; 164 f""type {type(elem)} from {parent}.""; 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'); ```. <details>; <summary>Versions</summary>. Package Version; ----------------------- ------------; absl-py 1.1.0; aiohttp 3.8.1; aiosignal 1.2.0; anndata 0.7.5; anndata2ri 1.0.6; annoy 1.17.0; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; asn1crypto 1.4.0; async-timeout 4.0.2; asynctest 0.13.0; attrs 20.3.0; backcall 0.2.0; beautifulsoup4 4.11.1; bleach 5.0.0; boto3 1.17.66; botocore 1.20.66; brotlipy 0.7.0; cached-property 1.5.2; cachetools 5.2.0; certifi 2020.12.5; cffi 1.14.5; chardet 4.0.0; charset-normalizer 2.0.12; chex 0.1.3; click 8.1.3; colormath 3.0.0; commonmark 0.9.1; conda 4.6.14; conda-package-handling 1.7.3; cryptography 3.4.7; cycler 0.10.0; Cyth",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-1146346336:1734,error,error,1734,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-1146346336,1,['error'],['error']
Availability,mage files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-viridis] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); F,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:4386,Error,Error,4386,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"matrix'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last); <ipython-input-102-4378df4ffefd> in <module>; ----> 1 adpt.write_h5ad('../data/ra19_10_liverprimary_yubin_latest.h5ad.gz'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense); 1844 filename = self.filename; 1845 ; -> 1846 _write_h5ad(; 1847 Path(filename),; 1848 self,. ~/miniconda3/envs/scrna/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs); 90 elif not (adata.isbacked and Path(adata.filename) == Path(filepath)):; 91 # If adata.isbacked, X should already be up to date; ---> 92 write_attribute(f, ""X"", adata.X, dataset_kwargs=dataset_kwargs); 93 if ""raw/X"" in as_dense and isinstance(; 94 adata.raw.X, (sparse.spmatrix, SparseDataset). ~/miniconda3/envs/scrna/lib/python3.8/functools.py in wrapper(*args, **kw); 872 '1 positional argument'); 873 ; --> 874 return dispatch(args[0].__class__)(*args, **kw); 875 ; 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/envs/scrna/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 124 if key in f:; 125 del f[key]; --> 126 _write_method(type(value))(f, key, value, *args, **kwargs); 127 ; 128 . ~/miniconda3/envs/scrna/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 189 except Exception as e:; 190 parent = _get_parent(elem); --> 191 raise type(e)(; 192 f""{e}\n\n""; 193 f""Above error raised while writing key {key!r} of {type(elem)}"". NotImplementedError: Failed to write value for X, since a writer for type <class 'scipy.sparse.csr.csr_matrix'> has not been implemented yet. Above error raised while writing key 'X' of <class 'h5py._hl.files.File'> from /.; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1670#issuecomment-783799732:2496,error,error,2496,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670#issuecomment-783799732,2,['error'],['error']
Availability,"mba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:3275,error,error,3275,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['error'],['error']
Availability,mbedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:47923,Error,Error,47923,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,mmh true that should probably be 1-corr_matrix. I'll ping @flying-sheep he might have a better answer,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1288#issuecomment-702366534:53,ping,ping,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1288#issuecomment-702366534,1,['ping'],['ping']
Availability,"mmmm...; looks like there are some difficulties here.; The decorator sitting ontop of dotplot() causes a weird error for kwds; dictionary lookups. If I leave the decorator in place, then I get a; keywords error when, vmin is left out as a parameter. If I take the; decorator off the method, it works. error is coming from the. @doc_params(). decorator. But 1. it looks like this function only purpose in life it to; ensure that the __doc__ string starts with a '\' character. And in the case; of dotplot() it already does. When I comment out the decorator, the code; works. This error is too strange for me to understand. I don't often use; decorators, and it seems to be the problem here.; Tim. On Tue, Dec 4, 2018 at 11:39 PM Fidel Ramirez <notifications@github.com>; wrote:. > The change is quite useful. Please go ahead and add a PR.; >; > On Wed, Dec 5, 2018 at 3:52 AM Tim Rand <notifications@github.com> wrote:; >; > > Here is a patch that fixes the above problem...; > >; > > import matplotlib.colors; > >; > > #if user defined, then use the vmax, vmin keywords, else use data to; > generate them...; > > if ('vmax' in kwds) and ('vmin' in kwds):; > > _vmax = kwds['vmax']; > > _vmin = kwds['vmin']; > > else:; > > _vmax = max(mean_flat); > > _vmin = min(mean_flat); > >; > > #normalize = matplotlib.colors.Normalize(vmin=min(mean_flat),; > vmax=max(mean_flat)); > > normalize = matplotlib.colors.Normalize(vmin=_vmin, vmax=_vmax); > >; > > I'll submit a pull request.; > >; > > —; > > You are receiving this because you are subscribed to this thread.; > > Reply to this email directly, view it on GitHub; > > <https://github.com/theislab/scanpy/issues/388#issuecomment-444339817>,; > > or mute the thread; > > <; > https://github.com/notifications/unsubscribe-auth/AEu_1WglYAlmHO-3DyNHUCRJwBtAOfskks5u1zT6gaJpZM4ZB23Z; > >; > > .; > >; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/388#issuecomment-444632665:111,error,error,111,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/388#issuecomment-444632665,4,['error'],['error']
Availability,"move `*` if you think there should be some positional ones, especially for pearson residuals). > the ""is median rank a good way to do HVG selection across batches""-issue (see this code comment). thanks for the explanation @jlause , I think is clear and it makes sense that it's the same as Seurat V3. > the question what the final names of the functions should be (see @ivirshup's last post). for `normalize_pearson_residual`, i think it makes sense to keep `normalize` in, as it's not the same type of transformation compared to `log1p`. For the HVG genes, I understand that same API but different function is not nice, but I also think is not nice if the function name change after functions get outside experimental module. For instance, as it is now, it would be `sc.experimental.pp.highly_variable_genes` -> `sc.pp.highly_variable_genes`. Otherwise, it would be `sc.experimental.pp.pearson_deviant_genes ` -> `sc.pp.highly_variable_genes` , which I don't think it is a smooth transition. ; If/when we eventually refactor `highly_variable_genes`, it wouldn't matter (there would be changes in function name anyway), but then again we'd have to consider backward compatibility as well. Furthermore, as it is now, it is true that it's the same `highly_variable_genes` API, but it belongs to the experimental module. Therefore, users would/should not assume the same functionality. In my opinion it's clearer this way as `sc.experimental.pp.highly_variable_genes` provides method in the experiemntal module that do HVG selection (and for now, it happens that only pearson residuals are available). > docs consistency (see @ivirshup's last post); > A number of parameters are available in multiple functions. Would it make sense to use some of our tooling so there's only one place to edit these?. what do you have in mind @ivirshup ? happy to help out but don't think I know what you are referring to. . I will be on vacation until 14th of Sept, will have a look at remaining comments when I'm back!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-909055513:1841,avail,available,1841,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-909055513,2,['avail'],['available']
Availability,n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED sca,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:43947,Error,Error,43947,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,n...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69246,ERROR,ERROR,69246,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,n12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-viridis] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-rgba] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_ordinal - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_layer - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_view - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_categorical - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_r,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:6130,Error,Error,6130,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"nDataReadError Traceback (most recent call last); <ipython-input-20-38a594ec7d06> in <module>; ----> 1 adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'). /opt/conda/lib/python3.7/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 424 d[k] = read_dataframe(f[k]); 425 else: # Base case; --> 426 d[k] = read_attribute(f[k]); 427 ; 428 d[""raw""] = _read_raw(f, as_sparse, rdasp). /opt/conda/lib/python3.7/functools.py in wrapper(*args, **kw); 838 '1 positional argument'); 839 ; --> 840 return dispatch(args[0].__class__)(*args, **kw); 841 ; 842 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.7/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 161 parent = _get_parent(elem); 162 raise AnnDataReadError(; --> 163 f""Above error raised while reading key {elem.name!r} of ""; 164 f""type {type(elem)} from {parent}.""; 165 ). AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; adata_ast=sc.read_h5ad('../../data_processed/Leng_2020/adata_ast.h5ad'); ```. <details>; <summary>Versions</summary>. Package Version; ----------------------- ------------; absl-py 1.1.0; aiohttp 3.8.1; aiosignal 1.2.0; anndata 0.7.5; anndata2ri 1.0.6; annoy 1.17.0; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; asn1crypto 1.4.0; async-timeout 4.0.2; asynctest 0.13.0; attrs 20.3.0; backcall 0.2.0; beautifulsoup4 4.11.1; bleach 5.0.0; boto3 1.17.66; botocore 1.20.66; brotlipy 0.7.0; cached-property 1.5.2; cachetools 5.2.0; certifi 2020.12.5; cffi 1.14.5; chardet 4.0.0; charset-normalizer 2.0.12; chex 0.1.3; click 8.1.3; colormath 3.0.0; commonmark 0.9.1; conda 4.6.14; conda-package-handling 1.7.3; cryptography 3.4.7; cycler 0.10.0; Cython 0.29.30; decorator 5.0.7; defusedxml 0.7.1; dill 0.3.3; dm-tree 0.1.7; docrep 0.3.2; entrypoints 0.4; et-xmlfile 1.1.0; fa2 0.3.5; fastjsonschema 2.15.3; flatbuffers 2.0; flax 0.5.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-1146346336:1857,error,error,1857,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-1146346336,1,['error'],['error']
Availability,nd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_nor,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66785,ERROR,ERROR,66785,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,nes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:42759,Error,Error,42759,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,nes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionErro,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48626,Error,Error,48626,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,nked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image file,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49034,Error,Error,49034,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Imag,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:47661,Error,Error,47661,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,npy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR sc,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:70371,ERROR,ERROR,70371,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,npy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - Impo,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:72037,ERROR,ERROR,72037,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"ns=[""repeated_col"", ""repeated_col""],; index=[f""cell_{i}"" for i in range(M)],; ),; var=pd.DataFrame(; index=[f""gene_{i}"" for i in range(N)],; ), ; ); sc.get.obs_df(adata, [""repeated_col""]); ```. ### This pr (gets both columns). ```; repeated_col repeated_col; obs_index ; cell_0 0 1; cell_1 3 4; cell_2 6 7; cell_3 9 10; cell_4 12 13; ```. ### 1.6 (errors). ```pytb; ~/miniconda3/envs/scanpy-1.6/lib/python3.8/site-packages/pandas/core/internals/blocks.py in __init__(self, values, placement, ndim); 140 ; 141 if self._validate_ndim and self.ndim and len(self.mgr_locs) != len(self.values):; --> 142 raise ValueError(; 143 f""Wrong number of items passed {len(self.values)}, ""; 144 f""placement implies {len(self.mgr_locs)}"". ValueError: Wrong number of items passed 2, placement implies 1; ```. Not a great error, could definitley be improved. ## Key in adata.obs.columns and adata.var_names. In this case, the key is ambiguous (should it get the gene values or the column from obs?). I think this means it should error. I feel like this point has been discussed a number of times, but doesn't seem to have been discussed when this behaviour was changed. ```python; M, N = 5, 3; adata = sc.AnnData(; X=np.zeros((M, N)),; obs=pd.DataFrame(; np.arange(M),; columns=[""var_id""],; index=[f""cell_{i}"" for i in range(M)],; ),; var=pd.DataFrame(; index=[""var_id""] + [f""gene_{i}"" for i in range(N-1)],; ), ; ); sc.get.obs_df(adata, [""var_id""]); ```. ### This pr (warns). ```; /Users/isaac/github/scanpy/scanpy/get.py:177: UserWarning: The key `var_id` is found in both adata.obs and adata.var_names.Only the adata.obs key will be used.; warnings.warn(; Out[58]: ; var_id; obs_index ; cell_0 2; cell_1 5; cell_2 8; cell_3 11; cell_4 14; ```. ### 1.6 (errors). ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-16-69be169f6a4f> in <module>; ----> 1 sc.get.obs_df(adata, [""var_id""]). ~/miniconda3/envs/scanpy-1.6/lib/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421:2116,error,error,2116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421,1,['error'],['error']
Availability,"nse for integer valued numbers. At the time I couldn't see a reason to convert the output to a different type. I figure that `log1p` should be able to take an integer valued expression matrix. However, I tried to implement that and ended up adding a lot of flow control to an already flow control heavy function, which got ugly:. <details>; <summary> 🍝 </summary>. ```python; def log1p(data, copy=False, chunked=False, chunk_size=None):; """"""Logarithmize the data matrix. Computes `X = log(X + 1)`, where `log` denotes the natural logarithm. Parameters; ----------; data : :class:`~anndata.AnnData`, `np.ndarray`, `sp.sparse`; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; copy : `bool`, optional (default: `False`); If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""; if copy:; if not isinstance(data, AnnData):; data = data.astype(np.floating); data = data.copy(); elif not isinstance(data, AnnData) and np.issubdtype(data.dtype, np.integer):; raise TypeError(""Cannot perform inplace log1p on integer array""). def _log1p(X):; if issparse(X):; np.log1p(X.data, out=X.data); else:; np.log1p(X, out=X). return X. if isinstance(data, AnnData):; if not np.issubdtype(data.X.dtype, np.floating):; data.X = data.X.astype(np.floating, copy=False); if chunked:; for chunk, start, end in data.chunked_X(chunk_size):; data.X[start:end] = _log1p(chunk); else:; _log1p(data.X); else:; _log1p(data). return data if copy else None; ```. </details>. I'll give that another shot, and open a PR. On the return type of `downsample_counts`, I've noticed many functions in scanpy return `float32` matrices regardless of what was given to them. Is this a design that's meant to be propagated? Even if not, what should the return type of `downsample_counts` be? At the time I figured it didn't matter, since anything downstream should be able to deal with it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239:2279,down,downstream,2279,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239,1,['down'],['downstream']
Availability,"number of items passed 2, placement implies 1; ```. Not a great error, could definitley be improved. ## Key in adata.obs.columns and adata.var_names. In this case, the key is ambiguous (should it get the gene values or the column from obs?). I think this means it should error. I feel like this point has been discussed a number of times, but doesn't seem to have been discussed when this behaviour was changed. ```python; M, N = 5, 3; adata = sc.AnnData(; X=np.zeros((M, N)),; obs=pd.DataFrame(; np.arange(M),; columns=[""var_id""],; index=[f""cell_{i}"" for i in range(M)],; ),; var=pd.DataFrame(; index=[""var_id""] + [f""gene_{i}"" for i in range(N-1)],; ), ; ); sc.get.obs_df(adata, [""var_id""]); ```. ### This pr (warns). ```; /Users/isaac/github/scanpy/scanpy/get.py:177: UserWarning: The key `var_id` is found in both adata.obs and adata.var_names.Only the adata.obs key will be used.; warnings.warn(; Out[58]: ; var_id; obs_index ; cell_0 2; cell_1 5; cell_2 8; cell_3 11; cell_4 14; ```. ### 1.6 (errors). ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-16-69be169f6a4f> in <module>; ----> 1 sc.get.obs_df(adata, [""var_id""]). ~/miniconda3/envs/scanpy-1.6/lib/python3.8/site-packages/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 171 for k, l in zip(keys, lookup_keys):; 172 if not use_raw or k in adata.obs.columns:; --> 173 df[k] = adata.obs_vector(l, layer=layer); 174 else:; 175 df[k] = adata.raw.obs_vector(l). ~/miniconda3/envs/scanpy-1.6/lib/python3.8/site-packages/anndata/_core/anndata.py in obs_vector(self, k, layer); 1362 ); 1363 layer = None; -> 1364 return get_vector(self, k, ""obs"", ""var"", layer=layer); 1365 ; 1366 def var_vector(self, k, *, layer: Optional[str] = None) -> np.ndarray:. ~/miniconda3/envs/scanpy-1.6/lib/python3.8/site-packages/anndata/_core/index.py in get_vector(adata, k, coldim, idxdim, layer); 156 ; 157 if (in_col + in_idx) == 2:; ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421:2843,error,errors,2843,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421,1,['error'],['errors']
Availability,"ocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel); 281 percent_top=percent_top,; 282 inplace=inplace,; --> 283 X=X,; 284 ); 285 var_metrics = describe_var(. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel); 107 if percent_top:; 108 percent_top = sorted(percent_top); --> 109 proportions = top_segment_proportions(X, percent_top); 110 for i, n in enumerate(percent_top):; 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/scanpy/preprocessing/_qc.py in top_segment_proportions(mtx, ns); 364 mtx = csr_matrix(mtx); 365 return top_segment_proportions_sparse_csr(; --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int); 367 ); 368 else:. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/dispatcher.py in _compile_for_args(self, *args, **kws); 348 e.patch_message(msg); 349 ; --> 350 error_rewrite(e, 'typing'); 351 except errors.UnsupportedError as e:; 352 # Something unsupported is present in the user code, add help info. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/dispatcher.py in error_rewrite(e, issue_type); 315 raise e; 316 else:; --> 317 reraise(type(e), e, None); 318 ; 319 argtypes = []. ~/packages/anaconda3/envs/testscanpy145/lib/python3.6/site-packages/numba/six.py in reraise(tp, value, tb); 656 value = tp(); 657 if value.__traceback__ is not tb:; --> 658 raise value.with_traceback(tb); 659 raise value; 660 ; ```. I was also surprised since this should be the first few functions people run.; ```calculate_qc_metrics``` was there for a long time. But ```top_segment_proportions_sparse_csr``` seems to be a new version since 1.4.5- I checked the _qc.py in the tar.gz files. Sorry my previous description was not accurate.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/978#issuecomment-572708303:1929,error,errors,1929,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978#issuecomment-572708303,1,['error'],['errors']
Availability,ode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: I,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:43156,Error,Error,43156,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"odepath where zero-centering was done afterwards anyway due to the original bug. Therefore this is no code breaking change.; But I also moved this statement before the sparse check to have consistent handling of sparse and dense data. Before that the sparse path wrote infs in the values (unchecked divison by zero) - this is a potentially code breaking change, but it only leads to the behaviour already stated in the documentation. I personally think that code relying on this undocumented behaviour should be rewritten, anyway...; In the new test I explicitly check for this behaviour to make it well defined.; Similar for integer datatypes (resulted in an error), they are now converted to floating point for scaling and return a copy. BTW: In order to make the tests run in my conda environment, I had to remove every reference to compare_images from matplotlib.testing.compare. There seems to be a version conflict in the version checking... It always gave errors like the following:; `________________ ERROR collecting scanpy/tests/test_plotting.py ________________; scanpy/tests/test_plotting.py:16: in <module>; from matplotlib.testing.compare import compare_images; ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/testing/compare.py:240: in <module>; _update_converter(); ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/testing/compare.py:222: in _update_converter; mpl._get_executable_info(""gs""); ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/__init__.py:364: in _get_executable_info; return impl([e, ""--version""], ""(.*)"", ""9""); ~/.conda/envs/custom/lib/python3.8/site-packages/matplotlib/__init__.py:346: in impl; if min_ver is not None and version < min_ver:; ~/.conda/envs/custom/lib/python3.8/distutils/version.py:52: in __lt__; c = self._cmp(other); ~/.conda/envs/custom/lib/python3.8/distutils/version.py:337: in _cmp; if self.version < other.version:; E TypeError: '<' not supported between instances of 'str' and 'int''`; I have the current ma",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1160#issuecomment-615407330:1515,error,errors,1515,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1160#issuecomment-615407330,2,"['ERROR', 'error']","['ERROR', 'errors']"
Availability,"ok, I solved the error by uninstalling umap and installing umap-learn; it only worked with umap-learn v. 0.3.9, as was suggested here: https://github.com/theislab/scanpy/issues/1181",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1202#issuecomment-624926006:17,error,error,17,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202#issuecomment-624926006,1,['error'],['error']
Availability,"ok, finished also with tests (I took what you had already for gearys C that tested for different types and consistency). Had to change to float32 cause I was having reproducibility errors (possibly due to overflow). ready to review, thank you!; btw I took a fair bit of code from gearysc re design and tests, so if you think should add better acknowledgment or co-author this PR, please go ahead.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1740#issuecomment-800582076:181,error,errors,181,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1740#issuecomment-800582076,1,['error'],['errors']
Availability,"on); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-71-69d6424effb2> in <module>; 3 max_mean=variable_genes_max_mean,; 4 min_disp=variable_genes_min_disp,; ----> 5 flavor = 'seurat') . /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key); 255 n_top_genes=n_top_genes,; 256 n_bins=n_bins,; --> 257 flavor=flavor); 258 else:; 259 sanitize_anndata(adata). /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_single_batch(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor); 90 df['dispersions'] = dispersion; 91 if flavor == 'seurat':; ---> 92 df['mean_bin'] = pd.cut(df['means'], bins=n_bins); 93 disp_grouped = df.groupby('mean_bin')['dispersions']; 94 disp_mean_bin = disp_grouped.mean(). /usr/local/anaconda3/envs/pySCENIC/lib/python3.6/site-packages/pandas/core/reshape/tile.py in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates); 226 # GH 24314; 227 raise ValueError(; --> 228 ""cannot specify integer `bins` when input data contains infinity""; 229 ); 230 elif mn == mx: # adjust end points before binning. ValueError: cannot specify integer `bins` when input data contains infinity; ```. I am assuming its something wrong with the dataset (it's a publicly available one which I needed to convert from a Seurat Object), but I can't figure out what. . I have checked if there are any Inf values included in adata.X or adata.raw.X but there are not. Also both adata.X and adata.raw.X are sparse matrices. Any ideas would be greatly appreciated. . ![Screen Shot 2020-03-13 at 6 09 35 PM](https://user-images.githubusercontent.com/15019107/76643678-d6e24500-6555-11ea-88c0-c16f097432e3.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/391#issuecomment-598826026:3217,avail,available,3217,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/391#issuecomment-598826026,1,['avail'],['available']
Availability,onda-forge; libstdcxx-ng 13.1.0 hfd8a6a1_0 conda-forge; libuuid 2.38.1 h0b41bf4_0 conda-forge; libzlib 1.2.13 hd590300_5 conda-forge; lightning 2.0.5 pypi_0 pypi; lightning-cloud 0.5.37 pypi_0 pypi; lightning-utilities 0.9.0 pypi_0 pypi; lit 15.0.7 pypi_0 pypi; llvmlite 0.40.1 pypi_0 pypi; markdown-it-py 3.0.0 pypi_0 pypi; markupsafe 2.1.2 pypi_0 pypi; matplotlib 3.7.2 pypi_0 pypi; matplotlib-inline 0.1.6 pyhd8ed1ab_0 conda-forge; mdurl 0.1.2 pypi_0 pypi; ml-collections 0.1.1 pypi_0 pypi; ml-dtypes 0.2.0 pypi_0 pypi; mpmath 1.2.1 pypi_0 pypi; msgpack 1.0.5 pypi_0 pypi; mudata 0.2.3 pypi_0 pypi; multidict 6.0.4 pypi_0 pypi; multipledispatch 1.0.0 pypi_0 pypi; muon 0.1.5 pypi_0 pypi; natsort 8.4.0 pypi_0 pypi; ncurses 6.4 hcb278e6_0 conda-forge; nest-asyncio 1.5.6 pyhd8ed1ab_0 conda-forge; networkx 3.1 pypi_0 pypi; numba 0.57.1 pypi_0 pypi; numpy 1.24.4 pypi_0 pypi; numpyro 0.12.1 pypi_0 pypi; openssl 3.1.1 hd590300_1 conda-forge; opt-einsum 3.3.0 pypi_0 pypi; optax 0.1.5 pypi_0 pypi; orbax-checkpoint 0.2.7 pypi_0 pypi; ordered-set 4.1.0 pypi_0 pypi; packaging 23.1 pyhd8ed1ab_0 conda-forge; pandas 2.0.3 pypi_0 pypi; parasail 1.3.4 pypi_0 pypi; parso 0.8.3 pyhd8ed1ab_0 conda-forge; patsy 0.5.3 pypi_0 pypi; pexpect 4.8.0 pyh1a96a4e_2 conda-forge; pickleshare 0.7.5 py_1003 conda-forge; pillow 10.0.0 pypi_0 pypi; pip 23.2.1 pyhd8ed1ab_0 conda-forge; platformdirs 3.9.1 pyhd8ed1ab_0 conda-forge; pooch 1.7.0 pyha770c72_3 conda-forge; prompt-toolkit 3.0.39 pyha770c72_0 conda-forge; prompt_toolkit 3.0.39 hd8ed1ab_0 conda-forge; protobuf 4.23.4 pypi_0 pypi; psutil 5.9.5 py311h2582759_0 conda-forge; ptyprocess 0.7.0 pyhd3deb0d_0 conda-forge; pure_eval 0.2.2 pyhd8ed1ab_0 conda-forge; pydantic 1.10.11 pypi_0 pypi; pygments 2.15.1 pyhd8ed1ab_0 conda-forge; pyjwt 2.8.0 pypi_0 pypi; pynndescent 0.5.10 pypi_0 pypi; pyparsing 3.0.9 pypi_0 pypi; pyro-api 0.1.2 pypi_0 pypi; pyro-ppl 1.8.5 pypi_0 pypi; pysocks 1.7.1 pyha2e5f31_6 conda-forge; python 3.11.4 hab00c5b_0_cpython conda-forge; p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205:5147,checkpoint,checkpoint,5147,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480#issuecomment-1646783205,1,['checkpoint'],['checkpoint']
Availability,one-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-None-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-inf-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_norma,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:3840,ERROR,ERROR,3840,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,opying fa2/fa2util.pxd -> build/lib.macosx-12.3-x86_64-3.10/fa2; running build_ext; skipping 'fa2/fa2util.c' Cython extension (up-to-date); building 'fa2.fa2util' extension; creating build/temp.macosx-12.3-x86_64-3.10; creating build/temp.macosx-12.3-x86_64-3.10/fa2; clang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -I/Users/test/.pyenv/versions/3.10.3/include/python3.10 -c fa2/fa2util.c -o build/temp.macosx-12.3-x86_64-3.10/fa2/fa2util.o; fa2/fa2util.c:10939:33: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Node.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:10947:33: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Edge.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:10960:35: error: no member named 'tp_print' in 'struct _typeobject'; __pyx_type_3fa2_7fa2util_Region.tp_print = 0;; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^; fa2/fa2util.c:12133:22: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:261:7: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op) : \; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __att,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:6064,error,error,6064,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,2,['error'],['error']
Availability,or: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-float32-100n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[spatial] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_dimension_broadcasting - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_embedding_plots.py::test_marker_broadcasting - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_compare - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - A,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:46380,Error,Error,46380,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"orceatlas2; Preparing metadata (setup.py) ... done; Requirement already satisfied: numpy in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (1.21.5); Requirement already satisfied: scipy in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (1.8.0); Requirement already satisfied: tqdm in /Users/test/.local/lib/python3.10/site-packages (from fa2==0.3.5) (4.63.0); Building wheels for collected packages: fa2; Building wheel for fa2 (setup.py) ... done; Created wheel for fa2: filename=fa2-0.3.5-cp310-cp310-macosx_12_0_x86_64.whl size=155419 sha256=23d907bfec5df0e9d0d522865d1c288b1f8894134bd61b6c5a02467128dfd102; Stored in directory: /private/var/folders/0s/67yn6b6n3lx4882xx_86ps2m0000gp/T/pip-ephem-wheel-cache-i69s_t3j/wheels/51/1c/a5/5a9ef4f0bc9387d300190bc15adbb98dbda9d90c6da9c2da04; Successfully built fa2; Installing collected packages: fa2; Successfully installed fa2-0.3.5 ; test@mac ~/PythonPackages/forceatlas2$; ```. However, if you try to install the release version you get an error:. ```; test@mac ~/PythonPackages$ wget https://github.com/bhargavchippada/forceatlas2/archive/refs/tags/v0.3.5.tar.gz; --2022-03-24 02:54:21-- https://github.com/bhargavchippada/forceatlas2/archive/refs/tags/v0.3.5.tar.gz; Resolving github.com (github.com)... 140.82.114.3; Connecting to github.com (github.com)|140.82.114.3|:443... connected.; HTTP request sent, awaiting response... 302 Found; Location: https://codeload.github.com/bhargavchippada/forceatlas2/tar.gz/refs/tags/v0.3.5 [following]; --2022-03-24 02:54:21-- https://codeload.github.com/bhargavchippada/forceatlas2/tar.gz/refs/tags/v0.3.5; Resolving codeload.github.com (codeload.github.com)... 140.82.114.9; Connecting to codeload.github.com (codeload.github.com)|140.82.114.9|:443... connected.; HTTP request sent, awaiting response... 200 OK; Length: unspecified [application/x-gzip]; Saving to: ‘v0.3.5.tar.gz’. v0.3.5.tar.gz [ <=> ] 434.98K 1.03MB/s in 0.4s . 2022-03-24 02:54:22 (1.03 MB/s) - ‘v0",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:1669,error,error,1669,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,1,['error'],['error']
Availability,orkspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERRO,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:72838,ERROR,ERROR,72838,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"ormat.py in _format_strings(self); 1516 ; 1517 def _format_strings(self) -> list[str]:; -> 1518 return list(self.get_result_as_array()); 1519 ; 1520 . ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in get_result_as_array(self); 1480 float_format = lambda value: self.float_format % value; 1481 ; -> 1482 formatted_values = format_values_with(float_format); 1483 ; 1484 if not self.fixed_width:. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in format_values_with(float_format); 1454 values = self.values; 1455 is_complex = is_complex_dtype(values); -> 1456 values = format_with_na_rep(values, formatter, na_rep); 1457 ; 1458 if self.fixed_width:. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in format_with_na_rep(values, formatter, na_rep); 1425 mask = isna(values); 1426 formatted = np.array(; -> 1427 [; 1428 formatter(val) if not m else na_rep; 1429 for val, m in zip(values.ravel(), mask.ravel()). ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in <listcomp>(.0); 1426 formatted = np.array(; 1427 [; -> 1428 formatter(val) if not m else na_rep; 1429 for val, m in zip(values.ravel(), mask.ravel()); 1430 ]. ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(). ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/IPython/core/formatters.py in __call__(self, obj); 343 method = get_real_method(obj, self.print_method); 344 if method is not None:; --> 345 return method(); 346 return None; 347 else:. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/core/frame.py in _repr_html_(self); 1045 decimal=""."",; 1046 ); -> 1047 return fmt.DataFrameRenderer(formatter).to_html(notebook=True); 1048 else:; 1049 return None. ~/.miniconda3/envs/cellrank/lib/python3",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2008#issuecomment-947943666:5679,mask,mask,5679,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008#issuecomment-947943666,1,['mask'],['mask']
Availability,ors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:57740,ERROR,ERROR,57740,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/te,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:59076,ERROR,ERROR,59076,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:56404,ERROR,ERROR,56404,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_m,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:59579,ERROR,ERROR,59579,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,os/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:62849,ERROR,ERROR,62849,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,os/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/t,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66451,ERROR,ERROR,66451,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,os/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py -,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74810,ERROR,ERROR,74810,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,otplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm_ref - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_violin - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_binary_scatter - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plotting.py::test_color_cycler - TypeError: map() got an unexpe,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:50005,Error,Error,50005,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,otplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: E,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48907,Error,Error,48907,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"ouch, it’s pretty error prone to just guess! What if a column is in both `.var` and `.obs`? People will never figure out what they need to do in order to get what they want. I don’t like replicating that or that it ever went into any function. Explicit is better than implicit. We could throw a nice error if the column isn’t in `.obs` but is in `.var` instead, like. > You specified column “dropout_per_gene” which is not in `.obs`, but in `.var`. Did you mean to call `sc.pl.violin(adata.T, ...)`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/375#issuecomment-441214996:18,error,error,18,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375#issuecomment-441214996,2,['error'],['error']
Availability,"p\__init__.py in <module>; ----> 1 from .umap_ import UMAP; 2 ; 3 # Workaround: https://github.com/numba/numba/issues/3341; 4 import numba; 5 . C:\ProgramData\Anaconda3\lib\site-packages\umap\umap_.py in <module>; 52 from umap.spectral import spectral_layout; 53 from umap.utils import deheap_sort, submatrix; ---> 54 from umap.layouts import (; 55 optimize_layout_euclidean,; 56 optimize_layout_generic,. C:\ProgramData\Anaconda3\lib\site-packages\umap\layouts.py in <module>; 37 },; 38 ); ---> 39 def rdist(x, y):; 40 """"""Reduced Euclidean distance.; 41 . C:\ProgramData\Anaconda3\lib\site-packages\numba\core\decorators.py in wrapper(func); 217 with typeinfer.register_dispatcher(disp):; 218 for sig in sigs:; --> 219 disp.compile(sig); 220 disp.disable_compile(); 221 return disp. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig); 963 with ev.trigger_event(""numba:compile"", data=ev_details):; 964 try:; --> 965 cres = self._compiler.compile(args, return_type); 966 except errors.ForceLiteralArg as e:; 967 def folded(args, kws):. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type); 123 ; 124 def compile(self, args, return_type):; --> 125 status, retval = self._compile_cached(args, return_type); 126 if status:; 127 return retval. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type); 137 ; 138 try:; --> 139 retval = self._compile_core(args, return_type); 140 except errors.TypingError as e:; 141 self._failed_cache[key] = e. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type); 150 ; 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325:6060,error,errors,6060,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325,1,['error'],['errors']
Availability,p_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-viridis] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-rgba] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_ordinal - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_layer - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:5677,Error,Error,5677,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"ple who already have a working R installation etc. and use Scanpy along with R packages. As there are quite many of these people, this is definitely meaningful.; > . That'd make things a lot easier for many people (including myself 😃), I agree. However. 1) There are (and will be) so many R packages about single cell, so once we open the door, there might be so many requests about these packages so that it'd be difficult to decide what to include and what not to include. The decision might be a bit arbitrary. This is why I suggested a contrib repo, which will have everything users request (as soon as there is someone who is willing to maintain it), in a `use at your own risk` way... 2) There might be several bug reports about rpy2 itself or thin wrappers or R installation or R packages themselves. I was wondering whether this might introduce more maintenance burden, although supported packages will be limited. > The code would still look proper. Implementing tests for these wrappers is maybe not so important as these are only shallow interfaces. It would be easier to have this in the main scanpy repository than setting up a scanpy-contrib: I imagine less people will like to contribute and take the burden of maintaining another repository. PS: anndata is a different story. That's something that is meant to be so basic that it doesn't need a lot of maintenance an contributions.; > ; > What do you think?. Alternatively, we can just prepare jupyter notebooks with some Python 3 and some R cells in it (which is super easy via rpy2 magics anyway) for some R packages/functions like mnn or SIMLR and put those in scanpy_usage as a reference for the community. For example:. ![image](https://user-images.githubusercontent.com/1140359/38873972-4953977a-4257-11e8-8675-a238738eb558.png). Another question is other single cell Python packages like magic, ZIFA or DCA, for example. There will hopefully be more in the future. A contrib repo might include these, as well i.e. `sc.tl.magic`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/125#issuecomment-382002901:1721,mainten,maintenance,1721,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125#issuecomment-382002901,1,['mainten'],['maintenance']
Availability,plot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm_ref - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signa,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49599,Error,Error,49599,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,plot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_violin_without_raw - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:44117,Error,Error,44117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,pos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65807,ERROR,ERROR,65807,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ps[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48780,Error,Error,48780,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,py/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_norm,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:61378,ERROR,ERROR,61378,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,py/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63183,ERROR,ERROR,63183,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,py::test_paga_plots[-paga] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous-func1] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_obs-func2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_multiple-func3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_pie - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[umap] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED s,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:1677,Error,Error,1677,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,py::test_paga_plots[continuous_multiple-func3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_pie - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[umap] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py:,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:2035,Error,Error,2035,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"quick practical comment on this very interesting discussion.; @ivirshup shall we have this here or moved to the other package under development? We need to take a decision on this because we'll have to see how it works with rest of functions. Pinging @Koncopd as well.; Sorry to put pressure but we are on a tight schedule 😅 . re: networkx discussion, also agree with Isaac on having these operations external to networkx.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1383#issuecomment-707590491:243,Ping,Pinging,243,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1383#issuecomment-707590491,1,['Ping'],['Pinging']
Availability,"r, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right?. I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python; conda create -n scanpyenv python=3.8; https://github.com/theislab/scanpy.git; cd scanpy; pip install .; ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative.; >; > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python; for frame in traceback.extract_stack():; if frame.name == 'get_docstring_and_version_via_import':; return True; ```. I don't see why `flit` couldn't just change the name of a function that is called internally at any point. I also think that at the moment, you and I are the only contributors who would have any idea what was going on if this acts up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-783849659:2289,robust,robust,2289,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-783849659,1,['robust'],['robust']
Availability,r: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ra,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:3508,Error,Error,3508,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,r: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_compare - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_positions_reproducible - ImportError: cannot import name 'gcd' from 'fractions' (/mnt/workspace/mambaforge/envs/anndata-min-deps-test/lib/python...; FAILED scanpy/tests/test_embedding_plots.py::test_dimensions_same_as_components - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not m,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:47511,Error,Error,47511,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,r: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-viridis] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-rgba] - ValueError: The truth value of an array with more than one ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:4536,Error,Error,4536,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,racksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49452,Error,Error,49452,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_gr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:69896,ERROR,ERROR,69896,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"rings(); 1272 return _make_fixed_width(fmt_values, self.justify); 1273 . ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in _format_strings(self); 1516 ; 1517 def _format_strings(self) -> list[str]:; -> 1518 return list(self.get_result_as_array()); 1519 ; 1520 . ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in get_result_as_array(self); 1480 float_format = lambda value: self.float_format % value; 1481 ; -> 1482 formatted_values = format_values_with(float_format); 1483 ; 1484 if not self.fixed_width:. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in format_values_with(float_format); 1454 values = self.values; 1455 is_complex = is_complex_dtype(values); -> 1456 values = format_with_na_rep(values, formatter, na_rep); 1457 ; 1458 if self.fixed_width:. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in format_with_na_rep(values, formatter, na_rep); 1425 mask = isna(values); 1426 formatted = np.array(; -> 1427 [; 1428 formatter(val) if not m else na_rep; 1429 for val, m in zip(values.ravel(), mask.ravel()). ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/io/formats/format.py in <listcomp>(.0); 1426 formatted = np.array(; 1427 [; -> 1428 formatter(val) if not m else na_rep; 1429 for val, m in zip(values.ravel(), mask.ravel()); 1430 ]. ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(). ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/IPython/core/formatters.py in __call__(self, obj); 343 method = get_real_method(obj, self.print_method); 344 if method is not None:; --> 345 return method(); 346 return None; 347 else:. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/pandas/core/frame.py in _repr_html_(self); 1045 decimal=""."",; 10",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2008#issuecomment-947943666:5538,mask,mask,5538,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008#issuecomment-947943666,1,['mask'],['mask']
Availability,"rmagic.py:943, in RMagics.R(self, line, cell, local_ns); 941 if not e.stdout.endswith(e.err):; 942 print(e.err); --> 943 raise e; 944 finally:; 945 if self.device in DEVICES_STATIC:. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:923, in RMagics.R(self, line, cell, local_ns); 921 return_output = False; 922 else:; --> 923 text_result, result, visible = self.eval(code); 924 text_output += text_result; 925 if visible:. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:389, in RMagics.eval(self, code); 386 except (ri.embedded.RRuntimeError, ValueError) as exception:; 387 # Otherwise next return seems to have copy of error.; 388 warning_or_other_msg = self.flush(); --> 389 raise RInterpreterError(code, str(exception),; 390 warning_or_other_msg); 391 text_output = self.flush(); 392 return text_output, value, visible[0]. RInterpreterError: Failed to parse and evaluate line '\n# specify row and column names of data\nrownames(data) = genes\ncolnames(data) = cells\n# ensure correct sparse format for table of counts and table of droplets\ndata <- as(data, ""sparseMatrix"")\ndata_tod <- as(data_tod, ""sparseMatrix"")\n\n# Generate SoupChannel Object for SoupX \nsc = SoupChannel(data_tod, data, calcSoupProfile = FALSE)\n\n# Add extra meta data to the SoupChannel object\nsoupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data))\nsc = setSoupProfile(sc, soupProf)\n# Set cluster information in SoupChannel\nsc = setClusters(sc, soupx_groups)\n\n# Estimate contamination fraction\nsc = autoEstCont(sc, doPlot=FALSE)\n# Infer corrected table of counts and rount to integer\nout = adjustCounts(sc, roundToInt = TRUE)\n'.; R error message: 'Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : \n duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B'; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277:5794,error,error,5794,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277,2,"['Error', 'error']","['Error', 'error']"
Availability,rocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportErr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:73852,ERROR,ERROR,73852,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ror: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_gr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:3357,Error,Error,3357,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,roups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Ima,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:48464,Error,Error,48464,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,roups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm_ref - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_violin - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equa,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49732,Error,Error,49732,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,rror: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-viridis] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-rgba] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Er,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:4856,Error,Error,4856,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"rror: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:3702,error,error,3702,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,2,"['ERROR', 'error']","['ERROR', 'error']"
Availability,"rs/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output. note: This is an issue with the package mentioned above, not pip.; hint: See above for details.; Exception information:; Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper; status = run_func(*args); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper; return func(self, options, args); ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run; requirement_set = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve; result = self._result = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:5230,error,error,5230,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['error'],['error']
Availability,"rs/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=128) value = type(); [130](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=129) try:; --> [131](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=130) self.gen.throw(type, value, traceback); [132](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=131) except StopIteration as exc:; [133](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=132) # Suppress StopIteration *unless* it's the same exception that; [134](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=133) # was passed to throw(). This prevents a StopIteration; [135](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=134) # raised inside the ""with"" statement from being suppressed.; [136](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/contextlib.py?line=135) return exc is not value. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\errors.py:837, in new_error_context(fmt_, *args, **kwargs); [835](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=834) else:; [836](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=835) tb = None; --> [837](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=836) raise newerr.with_traceback(tb); [838](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=837) elif use_new_style_errors():; [839](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/errors.py?line=838) raise e. LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x00000242239BD700> (trying to write member #1). File ""D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\umap\layouts.p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:32485,error,errors,32485,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659,1,['error'],['errors']
Availability,rtionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-viridis] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-rgba] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - Asser,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:4694,Error,Error,4694,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"ry familiar with Scanpy (which seems like a fantastic library!), so please bear with me if some of the things I mention are not relevant to Scanpy. PyMDE (documentation here: https://pymde.org/) has a few benefits:; - as @adamgayoso mentioned, PyMDE supports computing embeddings on GPU. This makes it possible to compute very large embeddings quickly (often 4-10x faster than CPU).; - PyMDE is a very general embedding library. It is based on a general framework for embedding, and this framework includes many well-known methods --- such as UMAP, PCA, Laplacian embedding, multi-dimensional scaling, and more --- as special cases. This makes it easy to compare different methods using a single framework.; - PyMDE also supports creating entirely new types of embeddings, as custom instances of our framework.; - PyMDE provides ways to reason about how much an embedding distorts the original neighborhood graph. There are some comparisons to UMAP & openTSNE in the third part of our manuscript, which has been published in Foundations & Trends in Machine Learning and is available here: https://web.stanford.edu/~boyd/papers/pdf/min_dist_emb.pdf; - on CPU, UMAP and PyMDE are comparable in speed, with UMAP often having a slight edge; on GPU PyMDE can be much faster; - unlike UMAP/openTSNE, PyMDE allows users to fit constrained embeddings. Right now the supported constraints are standardization (zero mean, unit covariance; this forces embeddings to spread out, but not too much, and as a result standardized embeddings are typically similarly scaled), centering, and anchoring (pre-specifying the coordinates of a subset of the items); - PyMDE allows for more types of embeddings, in addition to UMAP-style embeddings. On the other hand, PyMDE is young software. If you do depend on it, I would recommend including it as an optional dependency, not a required one. Happy to chat more, to answer any questions, and to help with integration, if that is something you are ultimately interested in.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2154#issuecomment-1051103627:1197,avail,available,1197,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154#issuecomment-1051103627,1,['avail'],['available']
Availability,"s that aren't repeated. I think it's fine for this to work. I do think it should error if the key is one values that is duplicated in the index. ```python; adata = sc.AnnData(; X=np.ones((2, 3)),; obs=pd.DataFrame(index=[""cell-0"", ""cell-1""]),; var=pd.DataFrame(index=[""gene-0"", ""gene-0"", ""gene-1""]),; ); sc.get.obs_df(adata, [""gene-1""]); ``````. ### This PR (errors). ```pytb; ---------------------------------------------------------------------------; InvalidIndexError Traceback (most recent call last); <ipython-input-62-405d671e2970> in <module>; ----> 1 sc.get.obs_df(adata, [""a"", ""gene-1""]). ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 213 var_idx = adata.raw.var_names.get_indexer(var_names); 214 else:; --> 215 var_idx = adata.var_names.get_indexer(var_names); 216 ; 217 # for backed AnnData is important that the indices are ordered. /usr/local/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_indexer(self, target, method, limit, tolerance); 3169 ; 3170 if not self.is_unique:; -> 3171 raise InvalidIndexError(; 3172 ""Reindexing only valid with uniquely valued Index objects""; 3173 ). InvalidIndexError: Reindexing only valid with uniquely valued Index objects; ```. ### 1.6 (suceeds). ```python; gene-1; cell-0 1.0; cell-1 1.0; ```. 1.6 does error if I use `""gene-0""` as a key, but the error message could definitley be better. ## What should we do about this?. My current inclination is to revert most changes to `obs_df` and `var_df` from this PR and #1499. This should leave the use of indices as groupby untouched. Also, the loss of perfomance from reverting #1499 should be partially mitigated by improvements in pandas (see https://github.com/pandas-dev/pandas/issues/37954). We would keep all the user facing changes, and all the tests from both PRs. We can then make a release now, and can patch in performance boosts during the release cycle. Do you agree with this assessment? If not, could you propose an alternat",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421:5163,toler,tolerance,5163,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421,1,['toler'],['tolerance']
Availability,s.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches FAILED [ 34%]; ```. and then gets stuck after. ```; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[<lambda>-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-True] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csr_matrix-False] PASSED [ 83%]; scanpy/tests/test_preprocessing.py::test_scale_array[csc_matri,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4904,ERROR,ERROR,4904,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,s.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4338,ERROR,ERROR,4338,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,s/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR sca,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:56235,ERROR,ERROR,56235,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,s/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_gene,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74486,ERROR,ERROR,74486,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,s_keep_layer[seurat-10] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_keep_layer[cell_ranger-None] FAILED [ 19%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-100-30-False] ERROR [ 30%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100-inf-30-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-None-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-inf-False] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-100-30-True] ERROR [ 31%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:1663,ERROR,ERROR,1663,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,s_matrixplot_gene_names_symbol-fn11] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-viridis] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-rgba] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_ordinal - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_layer - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_view - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:5824,Error,Error,5824,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"same error in 1.4.4; ```; sc.pp.calculate_qc_metrics(adata, inplace=True, parallel=True); ```; Maybe because sc.pp.calculate_qc_metrics was running in non parallel by default in 1.4.4 and before. the parallel= option has been removed since 1.4.5 and calculate_qc_metrics is running in parallel by default. That's why the error wasn't reported. I don't know enough about numba.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/978#issuecomment-572718846:5,error,error,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/978#issuecomment-572718846,2,['error'],['error']
Availability,"same error, seconded -- is there an alternative approach built in?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/72#issuecomment-1322433329:5,error,error,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/72#issuecomment-1322433329,1,['error'],['error']
Availability,"same here, we are having CI failing in squidpy cause we use the dataset, pinging @falexwolf",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2124#issuecomment-1025527856:73,ping,pinging,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124#issuecomment-1025527856,1,['ping'],['pinging']
Availability,"sc.pp.highly_variable_genes(adata, flavor=""seurat_v3"", n_top_genes=3000); error:Please install skmisc package via `pip install --user scikit-misc; I have the same problem as the blogger, so how should I solve it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1518455042:74,error,error,74,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1518455042,2,['error'],['error']
Availability,"scTransform is easily usable if you use rpy2 and anndata2ri. I use directly; the vst R function at this address to make it work; https://github.com/ChristophH/sctransform/blob/master/R/vst.R. Den søn. 23. feb. 2020 kl. 00.44 skrev MalteDLuecken <; notifications@github.com>:. > Hi, It's not available in scanpy at the moment, but I wrote a wrapper for; > it via rpy2 and anndata2ri which is available here:; >; > https://github.com/normjam/benchmark/blob/master/normbench/methods/ad2seurat.py; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/1068?email_source=notifications&email_token=ACC66UMYH2ZHSMFFQS35FRLREG2ENA5CNFSM4KZJFJP2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEMVNJCY#issuecomment-590009483>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ACC66UJ2GVSPUTR4WLWM2V3REG2ENANCNFSM4KZJFJPQ>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-590049395:291,avail,available,291,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-590049395,2,['avail'],['available']
Availability,scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:72355,ERROR,ERROR,72355,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ============== 252 failed, 650 passed, 59 sk",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:74981,ERROR,ERROR,74981,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:72681,ERROR,ERROR,72681,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/test,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:70214,ERROR,ERROR,70214,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65332,ERROR,ERROR,65332,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalizat,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:67773,ERROR,ERROR,67773,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_util,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64501,ERROR,ERROR,64501,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - Imp,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64668,ERROR,ERROR,64668,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:64169,ERROR,ERROR,64169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py -,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:73343,ERROR,ERROR,73343,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"seems like you did something wrong. the commit you added (74540cc133ca9cfe0744ca9d3b250454a76a9c4d) reverts a lot of changes we made since. i assume you just copied all your code over the current master branch, and not the version of the master branch as it was when you made the changes. you need to find the version of scanpy that you downloaded before you made your changes and modify that one to have just the changes you want to commit. otherwise we have no idea what your actual changes are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/630#issuecomment-489194292:337,down,downloaded,337,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/630#issuecomment-489194292,1,['down'],['downloaded']
Availability,setting scipy==1.2 fixes several errors but there is another one maybe related to matplotlib.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/661#issuecomment-495629061:33,error,errors,33,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/661#issuecomment-495629061,1,['error'],['errors']
Availability,"should be gene_symbols in plural. On Thu, Mar 14, 2019 at 9:46 AM csijcs <notifications@github.com> wrote:. > Hello, I'm having a bit of trouble with this. I know the issues is closed,; > but I thought it might be better to continue this discussion rather than; > start a new one, though I can do that if you prefer. I have an AnnData; > object adata with ensembl ids as adata.var_name and mouse gene symbols; > under the column adata.var[“gene_name”]. When I call:; > sc.pl.umap(adata, color=['ENSMUSG00000074637']); > It plots no problem. However, when I call:; > sc.pl.umap(adata, color=['Sox2'], gene_symbol='gene_name'); > I get the following error:; >; > Traceback (most recent call last):; >; >; >; > File ""<ipython-input-559-05c51c5cc5d6>"", line 1, in <module>; >; > sc.pl.umap(adata, color=['Sox2'], gene_symbol='gene_name'); >; >; >; > File ""/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 29, in umap; >; > return plot_scatter(adata, basis='umap', **kwargs); >; >; >; > File ""/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 275, in plot_scatter; >; > use_raw=use_raw, gene_symbols=gene_symbols); >; >; >; > File ""/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 670, in _get_color_values; >; > .format(value_to_plot, adata.obs.columns)); >; >; >; > ValueError: The passed `color` Sox2 is not a valid observation annotation or variable name. Valid observation annotation keys are: Index(['timepoint', 'replicate_id', 'n_genes', 'percent_mito', 'n_counts',; >; > 'louvain'],; >; > dtype='object'); >; >; > Inspecting adata.var[""gene_name""] give:; >; > index; >; > ENSMUSG00000002459 Rgs20; >; > ENSMUSG00000033740 St18; >; > ENSMUSG00000067879 3110035E14Rik; >; > ENSMUSG00000025912 Mybl1; >; > ENSMUSG00000016918 Sulf1; >; > ENSMUSG00000025938 Slco5a1; >; > ENSMUSG00000025930 Msc; >; > ENSMUSG00000025921 Rdh10; >; > ENSMUSG00000025777 Gdap1; >; > ENSMUSG00000025776 Crispld1; >; ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/455#issuecomment-472840788:648,error,error,648,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/455#issuecomment-472840788,1,['error'],['error']
Availability,"slab/scanpy.git to /tmp/pip-_z2v8och-build; fatal: Unable to find remote helper for 'https'; Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None; ```. second, I tried; ```; pip install git+git://github.com/theislab/scanpy.git ; ```; I got ouput as:; ```; Collecting git+git://github.com/theislab/scanpy.git; Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build; ```; and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```; python setup.py build; ```. I got ouput as:. ```; importlib_metadata.PackageNotFoundError: scanpy; ```. after this, I tried . ```; pip install -e .; ```. I got ouput as:. ```; Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/; ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` ; pip install https://github.com/theislab/scanpy.git; ```. output:. ```; Collecting https://github.com/theislab/scanpy.git; Downloading https://github.com/theislab/scanpy.git; \ 143kB 442kB/s; Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format; Cannot determine archive format of /tmp/pip-xolhyav7-build; ```. and i also tried. ```; git clone --recursive git://github.com/theislab/scanpy.git; ```. output:. ```; Cloning into 'scanpy'...; remote: Enumerating objects: 122, done.; remote: Counting objects: 100% (122/122), done.; remote: Compressing objects: 100% (109/109), done.; Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s; fatal: The remote end hung up unexpectedly MiB | 28.00 KiB/s; fatal: early EOF; fatal: index-pack failed; ```. however, i can successfully install scanpy 1.4.4 with. ```; pip install scanpy; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/838#issuecomment-532985027:1464,Down,Downloading,1464,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838#issuecomment-532985027,2,"['Down', 'down']","['Downloading', 'downloaded']"
Availability,"so have been running into issues when trying to use the `gene_symbols` parameter with the `sc.pl.dotplot()` function despite the column with the proper `gene_symbols` being in my `adata.var` Data Frame. . ```; $ adata.var.columns; $ sc.pl.dotplot(adata, marker_genes, 'clusters', dendrogram=True, gene_symbols='alternate_gene_symbols'). ==============================================================================. Index(['gene_symbols', 'feature_types', 'n_cells', 'highly_variable', 'means',; 'dispersions', 'dispersions_norm', 'mean', 'std',; 'alternate_gene_symbols'],; dtype='object'). ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); File ~/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621, in Index.get_loc(self, key, method, tolerance); 3620 try:; -> 3621 return self._engine.get_loc(casted_key); 3622 except KeyError as err:. File ~/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/_libs/index.pyx:136, in pandas._libs.index.IndexEngine.get_loc(). File ~/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/_libs/index.pyx:163, in pandas._libs.index.IndexEngine.get_loc(). File pandas/_libs/hashtable_class_helper.pxi:5198, in pandas._libs.hashtable.PyObjectHashTable.get_item(). File pandas/_libs/hashtable_class_helper.pxi:5206, in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'alternate_gene_symbols'; ... ```. When I tried setting `adata.var['gene_symbols'] = adata.var['alternate_gene_symbols']` and trying to generate a `dotplot` with a random gene present in `alternate_gene_symbols`, I ran into the following error: . ```; ...; KeyError: ""Could not find keys '['KH.C1.159.']' in columns of `adata.obs` or in adata.raw.var['gene_symbols'].""; ```. It seems that `sc.pl.dotplot()` is expecting `gene_symbols` that are present in the `adata.raw.var` Data Frame versus the `adata.var` Data Frame. Is this the expected behavior for this parameter?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1636#issuecomment-1284430963:1679,error,error,1679,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1636#issuecomment-1284430963,1,['error'],['error']
Availability,space/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:65968,ERROR,ERROR,65968,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_n_genes_negative-fn12] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-viridis] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting_utils.py::test_validate_palette_no_mod[asarray-rgba] - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_tracksplot-fn15] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_ordinal - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_layer - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_view - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_categorical - ImportError: cannot import name '_centered' from ',MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:5986,Error,Error,5986,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"st(x, y):; 40 """"""Reduced Euclidean distance.; 41 . C:\ProgramData\Anaconda3\lib\site-packages\numba\core\decorators.py in wrapper(func); 217 with typeinfer.register_dispatcher(disp):; 218 for sig in sigs:; --> 219 disp.compile(sig); 220 disp.disable_compile(); 221 return disp. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, sig); 963 with ev.trigger_event(""numba:compile"", data=ev_details):; 964 try:; --> 965 cres = self._compiler.compile(args, return_type); 966 except errors.ForceLiteralArg as e:; 967 def folded(args, kws):. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\dispatcher.py in compile(self, args, return_type); 123 ; 124 def compile(self, args, return_type):; --> 125 status, retval = self._compile_cached(args, return_type); 126 if status:; 127 return retval. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_cached(self, args, return_type); 137 ; 138 try:; --> 139 retval = self._compile_core(args, return_type); 140 except errors.TypingError as e:; 141 self._failed_cache[key] = e. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type); 150 ; 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 150 ; 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 714 pipeline = pipeline_class(typingctx, targetctx, library,; 715 args, return_type, flags, locals); --> 716 return pipel",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325:6569,error,errors,6569,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325,1,['error'],['errors']
Availability,st_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError:,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:71880,ERROR,ERROR,71880,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,sting/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metri,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:59744,ERROR,ERROR,59744,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,sts/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_norma,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:63851,ERROR,ERROR,63851,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"sudo rm /media/ubuntu/d0b69706-4d42-40a3-b531-382041477d35/home/cns/biosoft/cellranger/cellranger-3.0.2/deng2_count_myself -fr. At 2019-07-27 18:48:50, ""Cristian"" <notifications@github.com> wrote:. Good day!. I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. This happens in the first loop to load all the datasets. If I run only one dataset the same error (unsupported operand type(s) for +: 'int' and 'str') showed up when I plot some data quality summary plots:. For instance:; p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac'); adata = adata[adata.obs['mt_frac'] < 0.2] print('Number of cells after MT filter: {:d}'.format(adata.n_obs)); sc.pp.filter_cells(adata, min_genes = 700) print('Number of cells after gene filter: {:d}'.format(adata.n_obs)). I am using data generated by 10x V3 and CellRanger v3.0.1. I really do not know where the problem is. I really appreciate any advice/help to solve this issue. Thanks in advance. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/751#issuecomment-515740613:553,error,error,553,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751#issuecomment-515740613,1,['error'],['error']
Availability,"sure, we’ll talk in 10 days or so, after my holidays 😄. except if you want to earlier, then we can skype or so. > One could think about renaming the ""data"" subdirectory to something like ""data_cache"" or so to make evident that this only stores cache files, which can simply be deleted, and everything else stores ""AnnData backing files"" = ""result files"" or exported files... definitely. > But I agree true cache files might be better placed in a tmp directory. no, as i said: cache directory, not temp directory. both have (overridable) standard locations on all OSs. e.g. on linux:. - `$TMPDIR` or `/tmp/`: temporary means that the files are only to be read during the same function/script execution, and deleted after. temp files forgotten by the application that created them are deleted after `$TMPTIME` and on reboot. (on linux now usually because `/tmp/` is a ramdisk and RAM contents don’t survive a reboot). ```py; # python gives you a context manager that deletes the file after its block; with tempfile.TemporaryFile() as fp:; use(fp); # fp and the file are gone now; ```. - `$XDG_CACHE_HOME` or `~/.cache/`: cache files are permanent until the user or OS cleans up or the application decides it no longer needs them (i think e.g. browsers clear out the parts of their cache periodically). since scanpy has a notion of a project directory, putting the cache there is OK as well. the advantage is visibility, but that only works if the user knows what the directory/ies are for. using `cache` in the name of the cache directory would certainly help to signify that the stuff can be safely deleted.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/50#issuecomment-346781457:815,reboot,reboot,815,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/50#issuecomment-346781457,2,['reboot'],['reboot']
Availability,symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm_ref - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_violin - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_binary_scatter - TypeError: map(),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49894,Error,Error,49894,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"t I meant is that a wheel cached by pip (such as scipy) ends up in ~/.cache. And since some of those wheels are big, you need to clean that directory from time to time anyway if you have little space. > I think I'd prefer printing on write, info logging on read. I'd put a higher precedence on changing stuff on disk rather than reading. My idea was that showing it every time would help people discover this. But the default scanpy log level is INFO anyway, right? So it would get shown by default if we info-log it?. > I like this model of having all the data in one place, makes it much easier to have multiple environments and uninstall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for 1-3 built-in commands. Other people are interested in creating those scripts (and did so",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:1070,down,downloaded,1070,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940,1,['down'],['downloaded']
Availability,"t aren't repeated. I think it's fine for this to work. I do think it should error if the key is one values that is duplicated in the index. ```python; adata = sc.AnnData(; X=np.ones((2, 3)),; obs=pd.DataFrame(index=[""cell-0"", ""cell-1""]),; var=pd.DataFrame(index=[""gene-0"", ""gene-0"", ""gene-1""]),; ); sc.get.obs_df(adata, [""gene-1""]); ``````. ### This PR (errors). ```pytb; ---------------------------------------------------------------------------; InvalidIndexError Traceback (most recent call last); <ipython-input-62-405d671e2970> in <module>; ----> 1 sc.get.obs_df(adata, [""a"", ""gene-1""]). ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 213 var_idx = adata.raw.var_names.get_indexer(var_names); 214 else:; --> 215 var_idx = adata.var_names.get_indexer(var_names); 216 ; 217 # for backed AnnData is important that the indices are ordered. /usr/local/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_indexer(self, target, method, limit, tolerance); 3169 ; 3170 if not self.is_unique:; -> 3171 raise InvalidIndexError(; 3172 ""Reindexing only valid with uniquely valued Index objects""; 3173 ). InvalidIndexError: Reindexing only valid with uniquely valued Index objects; ```. ### 1.6 (suceeds). ```python; gene-1; cell-0 1.0; cell-1 1.0; ```. 1.6 does error if I use `""gene-0""` as a key, but the error message could definitley be better. ## What should we do about this?. My current inclination is to revert most changes to `obs_df` and `var_df` from this PR and #1499. This should leave the use of indices as groupby untouched. Also, the loss of perfomance from reverting #1499 should be partially mitigated by improvements in pandas (see https://github.com/pandas-dev/pandas/issues/37954). We would keep all the user facing changes, and all the tests from both PRs. We can then make a release now, and can patch in performance boosts during the release cycle. Do you agree with this assessment? If not, could you propose an alternative?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421:5476,error,error,5476,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421,2,['error'],['error']
Availability,"t force. Didn't work. Proceed to Step2.; ```python; (base) C:\WINDOWS\system32>conda activate Python38; (Python38) C:\WINDOWS\system32>pip install scikit-misc; Requirement already satisfied: scikit-misc in c:\users\park_lab\appdata\roaming\python\python38\site-packages (0.1.4); Requirement already satisfied: numpy in c:\users\park_lab\anaconda3\envs\python38\lib\site-packages (from scikit-misc) (1.20.3); ```; Step2: force install.; ```python; (Python38) C:\WINDOWS\system32>pip install scikit-misc --force; Collecting scikit-misc; Using cached scikit_misc-0.1.4-cp38-cp38-win_amd64.whl (142 kB); Collecting numpy; Downloading numpy-1.21.5-cp38-cp38-win_amd64.whl (14.0 MB); |████████████████████████████████| 14.0 MB 3.3 MB/s; Installing collected packages: numpy, scikit-misc; Attempting uninstall: numpy; Found existing installation: numpy 1.20.3; Uninstalling numpy-1.20.3:; Successfully uninstalled numpy-1.20.3; ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\Users\\Park_Lab\\anaconda3\\envs\\Python38\\Lib\\site-packages\\~umpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll'; Consider using the `--user` option or check the permissions.; ```; Step3: same errors.; ```python; sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3'); sc.pl.highly_variable_genes(adata); ImportError Traceback (most recent call last); ~\anaconda3\envs\Python38\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 52 try:; ---> 53 from skmisc.loess import loess; 54 except ImportError:. ~\AppData\Roaming\Python\Python38\site-packages\skmisc\loess\__init__.py in <module>; 50 """"""; ---> 51 from ._loess import (loess, loess_model, loess_inputs, loess_control,; 52 loess_outputs, loess_prediction,. ImportError: DLL load failed while importing _loess: The specified module could not be found. During",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342:1082,ERROR,ERROR,1082,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342,1,['ERROR'],['ERROR']
Availability,"t_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; 12 warnings and 3 errors generated.; error: command '/usr/bin/clang' failed with exit code 1; [end of output]; ; note: This error originates from a subprocess, and is likely not a problem with pip.; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Attempting uninstall: fa2; Found existing installation: fa2 0.3.5; Uninstalling fa2-0.3.5:; Successfully uninstalled fa2-0.3.5; Running setup.py install for fa2 ... error; error: subprocess-exited-with-error; ; × Running setup.py install for fa2 did not run successfully.; │ exit code: 1; ╰─> [212 lines of output]; Installing fa2 package (fastest forceatlas2 python implementation); ; >>>> Cython is installed?; Yes; ; >>>> Starting to install!; ; running install; running build; running build_py; creating build; creating build/lib.macosx-12.3-x86_64-3.10; creating build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/fa2util.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/__init__.py -> build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/forceatlas2.py -> build/lib.macosx-12.3-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:16752,error,error,16752,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,2,['error'],['error']
Availability,"tall things. Me too: All cache data in ~/.cache, all configs in ~/.config, …. If you need to uninstall a thing that behaves correctly, you can just do `package-manager uninstall thing && rm -rf ~/.{cache,config,local/share}/thing/`. > If those datasets were being implicitly cleared from disk, I'd find that confusing. I guess I don't think of downloaded datasets being cached in the way you've defined before. If I've downloaded a dataset though sklearn or tensorflow , I expect it to stay on disk. As said: it doesn’t happen automatically on desktops, they show you a popup asking you to do it. I think the HPC servers don’t help you with your tiny $HOME, so everything you download manually or cache just stays there. On a well-configured system with little space in $HOME, you’d have $XDG_CACHE_DIR point to a separate disk that has more space and isn’t backupped. In an ideal world everyone would respect that and your $HOME would never be filled up with ephemeral files. > I'm not sure I'd want to support a command line interface just for configs, if there was more it could do, maybe. Also, there's gotta be a generic tool for this, right?. The idea we agreed on was to allow something similar as `jupyter`: Just delegate `scanpy foocmd` to `scanpy-foocmd` except for 1-3 built-in commands. Other people are interested in creating those scripts (and did so already, but for the time being just call `scanpy-mycommand` with a dash in there). > I was writing up how I'd like configuration to work when I realized the implementation could be getting complicated enough it might be worth just using a library. […] Generally, I think there should be a longer planning discussion about how configuration works. Agreed, probably in an extra issue. > I'm wondering if we couldn't cut down on the need to explain by adopting a convention of referencing relevant settings in any function that access them? For example, the docs for expression_atlas would have a reference to dataset_dir?. sounds great!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940:2510,down,down,2510,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-478230940,1,['down'],['down']
Availability,tch.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_correlation - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_gene_names-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange-fn8] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:3067,Error,Error,3067,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"te the ""full dataset"". This makes more sense now. In that case however I would say that having just raw counts in `adata.raw.X` is fine, no? In the end you are distributing a data file. You can have your version of the normalized data in a layer... and you would be distributing your analysis code as well, so it's always clear how people should use this data file that is being deposited, no?. > Might be important for integration?. Integration works better with HVGs typically, so I don't think these super lowly expressed genes are so relevant here... I would often go with `min_cells=20` or even `50` for larger datasets. In the end I reason that this value will be approximately related to the size of the smallest unique cellular identity you expect to find. > This does run into memory usage problems if want do a densifying transform on the data. Don't understand this entirely... and not sure what a block sparse matrix type is... but can't you subset sparse matrices based on masks? Should be fairly easy to just skip indices that are not in the mask... although i can imagine it might be slower than doing this on dense matrices. Based on above arguments the main issue I see is currently for the case @gokceneraslan mentioned about MT genes or non-coding genes being stored in `.raw`. In this case you might need these genes also during an analysis pipeline (and not just for data storage), so you would like to have them in a separate ""raw"" container that is otherwise not touched. This clashes with the way raw is used in current scanpy pipeline. I think we could deprecate the way `.raw` is used at the moment, and use a `.layer` for this instead (maybe a designated ""raw"" layer?), but then introduce a new `.frozenraw` or sth like that where just the raw data is stored and it's essentially read-only after assignment?. I would be a bit hesitant to not have a replacement for `.raw` as a version of the data that is used for DE analysis but not `.X`. This distinction is quite useful ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-820336449:1098,mask,masks,1098,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-820336449,2,['mask'],"['mask', 'masks']"
Availability,te-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_view - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_categorical - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_constants - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_preprocessing.py::test_regress_out_constants_equivalent - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tools/_dendrogram.py::scanpy.tools._dendrogram.dendrogram; FAILED scanpy/tests/notebooks/test_pbmc3k.py::test_pbmc3k - ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/mnt/workspace/mambaforge/envs/scanpy-min-deps-test/lib/python3.9/site-p...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[umap_with_edges-fn17] - AssertionError: Error: Image files did not match.; =,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:7615,Error,Error,7615,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['Error'],['Error']
Availability,"te-packages\numba\core\compiler_machinery.py"", line 269, in check; mangled = func(compiler_state); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass; lower.lower(); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower; self.lower_normal_function(self.fndesc); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function; entry_block_tail = self.lower_function_body(); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body; self.lower_block(block); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block; self.lower_inst(inst); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__; self.gen.throw(type, value, traceback); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context; raise newerr.with_traceback(tb); numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:; def rdist(x, y):; <source elided>; dim = x.shape[0]; for i in range(dim):; ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53). I am running scanpy using python v3.9 with numba v0.55. . _Originally posted by @gatocor in https://github.com/theislab/scanpy/issues/1652#issuecomment-779686831_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1652#issuecomment-1054106418:7539,error,errors,7539,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652#issuecomment-1054106418,2,['error'],['errors']
Availability,"te: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:59: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; 12 warnings and 3 errors generated.; error: command '/usr/bin/clang' failed with exit code 1; [end of output]; ; note: This error originates from a subprocess, and is likely not a problem with pip.; ERROR: Failed building wheel for fa2; Running setup.py clean for fa2; Failed to build fa2; Installing collected packages: fa2; Attempting uninstall: fa2; Found existing installation: fa2 0.3.5; Uninstalling fa2-0.3.5:; Successfully uninstalled fa2-0.3.5; Running setup.py install for fa2 ... error; error: subprocess-exited-with-error; ; × Running setup.py install for fa2 did not run successfully.; │ exit code: 1; ╰─> [212 lines of output]; Installing fa2 package (fastest forceatlas2 python implementation); ; >>>> Cython is installed?; Yes; ; >>>> Starting to install!; ; running install; running build; running build_py; creating build; creating build/lib.macosx-12.3-x86_64-3.10; creating build/lib.macosx-12.3-x86_64-3.10/fa2; copying fa2/fa2util.p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:16733,error,errors,16733,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,1,['error'],['errors']
Availability,"teresting that if I ran your PBMC tutorial without filtering out the non-HVG then I get this error. But I thought these filtering steps in the beginning already eliminated the empty rows and columns?; ```py; sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/230#issuecomment-596790394:93,error,error,93,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/230#issuecomment-596790394,1,['error'],['error']
Availability,test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportEr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:67455,ERROR,ERROR,67455,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,test_stacked_violin_obj - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_heatmap_swap_axes_vcenter-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot_logfoldchange_vcenter-fn9] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes-fn13] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[heatmap-heatmap] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[dotplot-dotplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:49178,Error,Error,49178,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"th repeated column values, but I do think it's reasonable. ```python; M, N = 5, 3; adata = sc.AnnData(; X=np.zeros((M, N)),; obs=pd.DataFrame(; np.arange(M * 2).reshape((M, 2)),; columns=[""repeated_col"", ""repeated_col""],; index=[f""cell_{i}"" for i in range(M)],; ),; var=pd.DataFrame(; index=[f""gene_{i}"" for i in range(N)],; ), ; ); sc.get.obs_df(adata, [""repeated_col""]); ```. ### This pr (gets both columns). ```; repeated_col repeated_col; obs_index ; cell_0 0 1; cell_1 3 4; cell_2 6 7; cell_3 9 10; cell_4 12 13; ```. ### 1.6 (errors). ```pytb; ~/miniconda3/envs/scanpy-1.6/lib/python3.8/site-packages/pandas/core/internals/blocks.py in __init__(self, values, placement, ndim); 140 ; 141 if self._validate_ndim and self.ndim and len(self.mgr_locs) != len(self.values):; --> 142 raise ValueError(; 143 f""Wrong number of items passed {len(self.values)}, ""; 144 f""placement implies {len(self.mgr_locs)}"". ValueError: Wrong number of items passed 2, placement implies 1; ```. Not a great error, could definitley be improved. ## Key in adata.obs.columns and adata.var_names. In this case, the key is ambiguous (should it get the gene values or the column from obs?). I think this means it should error. I feel like this point has been discussed a number of times, but doesn't seem to have been discussed when this behaviour was changed. ```python; M, N = 5, 3; adata = sc.AnnData(; X=np.zeros((M, N)),; obs=pd.DataFrame(; np.arange(M),; columns=[""var_id""],; index=[f""cell_{i}"" for i in range(M)],; ),; var=pd.DataFrame(; index=[""var_id""] + [f""gene_{i}"" for i in range(N-1)],; ), ; ); sc.get.obs_df(adata, [""var_id""]); ```. ### This pr (warns). ```; /Users/isaac/github/scanpy/scanpy/get.py:177: UserWarning: The key `var_id` is found in both adata.obs and adata.var_names.Only the adata.obs key will be used.; warnings.warn(; Out[58]: ; var_id; obs_index ; cell_0 2; cell_1 5; cell_2 8; cell_3 11; cell_4 14; ```. ### 1.6 (errors). ```pytb; ------------------------------------------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421:1909,error,error,1909,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-770167421,1,['error'],['error']
Availability,th signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[umap_with_edges-fn17] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatterplots[pca_mask-fn19] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_groups_and_size - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neig,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:55233,ERROR,ERROR,55233,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding?. indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image?. in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper).; It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042); For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1512#issuecomment-741689756:768,mask,mask,768,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512#issuecomment-741689756,1,['mask'],['mask']
Availability,"thank you very much! one thing that we could consider is renaming this to ""downsample_counts""; for some people, ""downsampling observations"" is an alias to ""subsampling observations"" and for these the function name is not descriptive enough. what do you think? can I make this change?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/100#issuecomment-371090054:113,down,downsampling,113,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/100#issuecomment-371090054,1,['down'],['downsampling']
Availability,"thanks for everyone's input. I tried to solve this problem by downgrading pandas to 1.1.5. the cause of this problem may be that in python 3.9 and above, pandas modifies the matrix function",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2008#issuecomment-981383663:62,down,downgrading,62,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008#issuecomment-981383663,1,['down'],['downgrading']
Availability,"thanks for getting this started!. since this new modality has different signal characteristics, I wanted to bring up for discussion:. ### normalization choice: for the incoming geometric normalization, any justification for choosing that one over others? . in your https://github.com/theislab/scanpy-tutorials/pull/14 (10x PBMC dataset of ~30 Totalseq antibodies), the antibody panel is similar to that used in mass cytometry datasets, but different papers seem to prefer different transforms -- which begs the question, now that similar panels are being used, which transform makes the most sense in terms of:; - preserving visual interpretation of absent/low/med/high (corresponding to expectations of cell subsets); - handling a variety of marker distribution shapes (unimodal/bimodal/trimodal, skewed shapes); - making it easier to spot nonspecific antibody staining / off-target effects; - not introducing more bias in downstream differential comparisons (fits with assumptions about variable distribution properties, based on the commonly used statistical testing methods). absent a convincing answer, it may be worth implementing multiple as options, leaving the choice to the user, and just documenting these use-cases through citations; eventually, someone can make a notebook that compares the behaviors, biological expectations, and/or impacts on statistical comparisons to inform which method should be the default. While the CITEseq paper applied CLR, it's not obvious that one is better than the ones used in more time-tested fields like mass cytometry and flow cytometry. ```python; def CLR_transform(df):; '''; implements the CLR transform used in CITEseq (need to confirm in Seurat's code); https://doi.org/10.1038/nmeth.4380; '''; logn1 = np.log(df + 1); T_clr = logn1.sub(logn1.mean(axis=1), axis=0); return T_clr. def asinh_transform(df, cofactor=5):; '''; implements the hyperbolic arcsin transform used in CyTOF/mass cytometry; https://doi.org/10.1038/nmeth.4380; '''; T_cytof = ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1117#issuecomment-635963691:924,down,downstream,924,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117#issuecomment-635963691,1,['down'],['downstream']
Availability,"that it's the devs responsibility to make it as easy as possible for the user. That's exactly my stance as well. > How about printing the absolute path of the data's destination on download?. I thought that too. Only we should do it not just on download, but on every use, e.g. “reading cached data from ~/.cache/scanpy/paul15.h5ad”. And put help on how to change the cache dir in the settings docs. > I thought the older ones would just be deleted, right?. Since those systems aren't configured well, probably not. On those systems, it would just be another directory. But on a laptop with a common Linux distribution, there would be a pop-up once your disk space gets low, which allows you to clear that directory with a click. > If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. You'd not notice it much, because datasets are just being re-downloaded on demand. That's a feature!. > [We don't have XDG_CACHE_HOME set]. Yes, because you only need it if you want your cache files to not be in `~/.cache`. > When I think about example datasets that are available through scientific computing packages I think of […]. I'm on mobile, so I don't want to check all of those, but. - miniconda is somewhere else for me by default, and it contains everything, not just data; - nltk pops up a window asking you to where to put stuff, and [recommends /use/local/share/nltk_data](https://www.nltk.org/data.html) for global installs, with no recommendation for per-user installs. I have a lot more stuff in my cache dir, not just applications. And as said: for good reason, because the OS often knows about this, which helps the user to delete the stuff with one click if needed. ---. My personal hell certainly includes dozens of libraries and applications putting all kinds of crap in unhidden directories in my home. All of them ha",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890:1165,down,downloaded,1165,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-477102890,1,['down'],['downloaded']
Availability,"this is not related to scanpy, but to sam (scanpy external). Please report the bug in the original repo: https://github.com/atarashansky/self-assembling-manifold; pinging @atarashansky who is possibly most helpful in this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1293#issuecomment-702362311:163,ping,pinging,163,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1293#issuecomment-702362311,1,['ping'],['pinging']
Availability,"this issue!! I just spent many hours digging into the source code to figure out why `filter_rank_genes_groups` was filtering out genes that reported really high fold changes from `rank_genes_groups`, only to discover the discrepancy in the fold change calculation. Here is an example of how confusing this inconsistency can be:. - I run `rank_genes_groups` and see that many marker genes have high log2 fold changes in `adata.uns['rank_genes_groups']['logfoldchanges'][<cluster_string>]`. For example, gene X has a fold change of -27.720167.; - Then, I run `filter_rank_genes_groups` -- and none of these genes with high negative fold changes are retained; - There are two issues here: one is that negative fold changes don't get retained at all. [This is the issue I notice first, and report in #1325]. I fix that in my fork of the repo (solution below), but STILL these genes are removed when filtering for a min absolute fold change of 1.5 (0.58 on log scale)... ?!; - This boils down to the inconsistency in fold change calculation. Mean expression of gene X within my cluster of interest is 0, and outside it is 0.1997576. `np.log2((0 + 1e-9)/(0.1997576 + 1e-9)) = -27.720167`, as reported originally by `rank_genes_groups`. As a user, I completely expect this gene to pass my threshold. `filter_rank_genes_groups`, however, calculates fold change as `np.log2(np.exp(0)/np.exp(0.199758)) = -0.288189`, which does NOT pass my fold change threshold, thus it gets filtered out. All this happens silently of course [the only number I have seen is a whopping fold change of -27] leaving me utterly confused. I'm not sure which is more correct (though -27 seems pretty inflated to me given the raw numbers), but it would make a lot more sense for it to at least be consistent, especially so that `filter_rank_genes_groups` could give expected results. p.s. Here is my fix to retain downregulated genes in `filter_rank_genes_groups`: update the third condition to `(np.absolute(np.log2(fold_change_matri",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/863#issuecomment-661497061:1000,down,down,1000,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/863#issuecomment-661497061,1,['down'],['down']
Availability,"tically. However, I'm wary of abandoning a critical discussion of imputation methods in this space because other portions of the typical workflow have issues as well. Further, I think there are important distinctions to be made between different classes of methodology that are (mis)used in this problem space. I. Methods that are fundamentally flawed by their assumptions or algorithm. These should obviously be avoided.; II. Methods that are fundamentally sound but are not sufficiently validated, e.g. the validation doesn't exist in this problem space, isn't sufficiently comprehensive/relevant, performs poorly against other fundamentally sound methodologies, or has such restrictive assumptions it isn't broadly useful/applicable.; III. Methods that are fundamentally sound in assumption/algorithm and can be used by a competent practitioner but still have the potential to be abused through applying it to data that violate those assumptions. I'd consider t-SNE and a great deal of the clustering algorithms to be in class III for the reasons you said; they're valid, functional tools but can be applied in assumption-violating or quasi-valid ways. I'm pretty sure that scImpute, for example, belongs in class I because its description of dropout and simulated test cases are inappropriate. I'd put MAGIC and several other currently available imputation methods in class II as they've got strong foundations but currently insufficient validation IMO. I'm not trying to pick on MAGIC or any specific imputation method. Instead I'd like to have an open discussion about the benefits, limitations, and relative performance of the various imputation methods available with the goal leading to something like @gokceneraslan suggested. Well, and since you brought it up, batch correction and multimodal integration methods are in definite need of the same open discussion, which I'd be happy to have, and I think they should have the same disclaimer regarding their limitations in the documentation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/189#issuecomment-417692893:1516,avail,available,1516,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189#issuecomment-417692893,2,['avail'],['available']
Availability,"top of a conda install:. <details>; <summary> me trying </summary>. ```python; isaac@Mimir:~/tmp/genomic-features-docs; $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy; [ ... ]; isaac@Mimir:~/tmp/genomic-features-docs; $ conda activate test-2978 ; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ ipython; from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help.; [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""); Out[4]: <Version('0.9.0')>. In [5]: quit(); (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ pip install -U anndata; Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0); Collecting anndata; Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB); [ ... ]; Downloading anndata-0.10.6-py3-none-any.whl (122 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00; Downloading array_api_compat-1.6-py3-none-any.whl (36 kB); Installing collected packages: array-api-compat, anndata; Attempting uninstall: anndata; Found existing installation: anndata 0.9.0; Uninstalling anndata-0.9.0:; Successfully uninstalled anndata-0.9.0; Successfully installed anndata-0.10.6 array-api-compat-1.6; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ conda list | grep anndata; anndata 0.10.6 pypi_0 pypi; (test-2978) isaac@Mimir:~/tmp/genomic-features-docs; $ ipython; imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""); Out[2]: <Version('0.10.6')>; ```. </details>. Interesting to see that this seem",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2978#issuecomment-2039433757:1056,Down,Downloading,1056,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978#issuecomment-2039433757,1,['Down'],['Downloading']
Availability,ts/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_pca.py - ImportError,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:73510,ERROR,ERROR,73510,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ts/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py -,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:71210,ERROR,ERROR,71210,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/tes,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:42613,Error,Error,42613,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"umap expects a list as group, so it will work if you do:. ```python; sc.pl.umap(adata, color='blobs', groups=['Zero']); ````. the improvement that I would consider is to automatically convert a string into a list to avoid the error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/231#issuecomment-414236960:226,error,error,226,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/231#issuecomment-414236960,1,['error'],['error']
Availability,"umba/core/dispatcher.py?line=124) status, retval = self._compile_cached(args, return_type); [126](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=125) if status:; [127](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=126) return retval. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type); [136](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=135) pass; [138](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=137) try:; --> [139](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=138) retval = self._compile_core(args, return_type); [140](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=139) except errors.TypingError as e:; [141](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=140) self._failed_cache[key] = e. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type); [149](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=148) flags = self._customize_flags(flags); [151](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=150) impl = self._get_implementation(args, {}); --> [152](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=151) cres = compiler.compile_extra(self.targetdescr.typing_context,; [153](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=152) self.targetdescr.target_context,; [154](file:///d%3A/Users/xiangrong1/Miniconda3/envs",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:16206,error,errors,16206,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659,1,['error'],['errors']
Availability,"up and it does look very nice. Well, I learned a lot from `scanpy` here ;) . > tcellmatch's primary purpose is specificity prediction, this could be easily added ontop of this,. Scirpy currently supports the construction of clonotype similarity networks based on Levenshtein distance and BLOSUM62 pairwise sequence alignments. With these networks, we, indeed, had in mind, that clonotypes forming a connected subgraph should recognize the same antigen. Supporting `tcellmatchs`'s learned embedding distances would be a great addition. Dou you think this could be implemented as a subclass of the `_DistanceCalculator` [here](https://github.com/icbi-lab/scirpy/blob/master/scirpy/_preprocessing/_tcr_dist.py#L20)? Feel free to open an issue in `scirpy` for that! . I'd also be curious how the BLOSUM embedding relates to our alignment distance. (How) does the embedding handle gaps?. > Integration with epitope data bases: I have data loaders for IEDB and VDJdb downloads, can you be a bit more specific how you would integrate that with exploratorive single-cell studies? I can only imagine searching for similar TCRs?. Exactly! I think it would be helpful if we could find a way to automatically annotate clonotypes with known epitopes (e.g. to identify clonotypes that are specific to common viral antigens which could represent ""bystander T-cells"" in cancer). I believe using our alignment-based approach or `tcellmatch` could improve over the existing database-queries that rely on Levenshtein distance. We can continue a more in-depth discussion in https://github.com/icbi-lab/scirpy/issues/54. > An integration with dextramer counts to ""stain"" TCR specificity? . Interesting! Do you have an example where this was used with single cells? . > Could you add a brief summary of how you use anndata to store the TCR data in the docs? That would be very helpful to design extension or custom workflows. Great docs otherwise though!. There's already some information [at the beginning of the tutorial]",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1163#issuecomment-613394910:1072,down,downloads,1072,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163#issuecomment-613394910,1,['down'],['downloads']
Availability,"update:. managed to get a confidence thresholding with this type of logic:. ```py; def _knn_classify(self, labels):; # ensure it's categorical; cat_array: pd.Series = self._adata_ref.obs[labels].astype(""category""); values = []; confidences = []. for inds in self._indices:; mode_value = cat_array.iloc[inds].mode()[0]; mode_count = (cat_array.iloc[inds] == mode_value).sum(); confidence = mode_count / len(inds); values.append(mode_value); confidences.append(confidence); ; # Create a DataFrame for better readability; classification_df = pd.DataFrame({; ""Mode Values"": values,; ""Confidences"": confidences; }); print(classification_df). return pd.Categorical(values=values, categories=cat_array.cat.categories), np.array(confidences). def map_labels(self, labels, method, confidence_threshold: float = 0.5):; """"""\; Map labels of `adata` to `adata_new`. This function infers `labels` for `adata_new.obs`; from existing labels in `adata.obs`.; `method` can be only 'knn'.; """"""; if method == ""knn"":; classified_labels, confidences = self._knn_classify(labels); mask = confidences >= confidence_threshold; ; filtered_labels = [; label if mask[idx] else np.nan ; for idx, label in enumerate(classified_labels); ]; ; classified_labels = pd.Categorical(; filtered_labels,; categories=classified_labels.categories; ); ; self._adata_new.obs[labels] = classified_labels; self._adata_new.obs[labels + '_confidence'] = confidences; else:; raise NotImplementedError(""Ingest supports knn labeling for now.""); ```; . would love to get input on whether or not this makes sense",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3160#issuecomment-2270570908:1058,mask,mask,1058,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3160#issuecomment-2270570908,2,['mask'],['mask']
Availability,ups[ranked_genes_matrixplot-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[stacked_violin-stacked_violin] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[matrixplot-matrixplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_stacked_violin-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_genes_symbols[tracksplot-tracksplot] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_matrixplot_swap_axes_vcenter-fn14] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_multiple_plots - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_rank_genes_groups[ranked_genes_dotplot-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_scatter_embedding_add_outline_vmin_vmax_norm_ref - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_violin - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_plotting.py::test_binary_scatter - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plotting.py::test_color_cycler - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_plotting.py::test_repeated_colors_w_missing_value - TypeError: ma,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:50145,Error,Error,50145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"use `cmap`. In general you can use any option available for; `matplotlib.pyplot.scatter` including vmin, vmax, etc. On Mon, Nov 26, 2018 at 11:01 PM aopisco <notifications@github.com> wrote:. > @falexwolf <https://github.com/falexwolf> @fidelram; > <https://github.com/fidelram> how to we change the color palette for; > numerical variables? currently setting palette = 'Oranges' only works for; > the categorical ones; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/issues/156#issuecomment-441815667>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEu_1RFS_19jC__9pOo04OZkjN_hVZvvks5uzGTBgaJpZM4UCLlA>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/156#issuecomment-441950074:46,avail,available,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156#issuecomment-441950074,1,['avail'],['available']
Availability,use_raw=False always create errors.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2029#issuecomment-976191715:28,error,errors,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2029#issuecomment-976191715,1,['error'],['errors']
Availability,"ut from being displayed; 2496 # when using magics with decorator @output_can_be_silenced; 2497 # when the last Python token in the expression is a ';'.; 2498 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False):. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:943, in RMagics.R(self, line, cell, local_ns); 941 if not e.stdout.endswith(e.err):; 942 print(e.err); --> 943 raise e; 944 finally:; 945 if self.device in DEVICES_STATIC:. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:923, in RMagics.R(self, line, cell, local_ns); 921 return_output = False; 922 else:; --> 923 text_result, result, visible = self.eval(code); 924 text_output += text_result; 925 if visible:. File /scratch/work/malonzm1/.conda_envs/R_for_scater/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:389, in RMagics.eval(self, code); 386 except (ri.embedded.RRuntimeError, ValueError) as exception:; 387 # Otherwise next return seems to have copy of error.; 388 warning_or_other_msg = self.flush(); --> 389 raise RInterpreterError(code, str(exception),; 390 warning_or_other_msg); 391 text_output = self.flush(); 392 return text_output, value, visible[0]. RInterpreterError: Failed to parse and evaluate line '\n# specify row and column names of data\nrownames(data) = genes\ncolnames(data) = cells\n# ensure correct sparse format for table of counts and table of droplets\ndata <- as(data, ""sparseMatrix"")\ndata_tod <- as(data_tod, ""sparseMatrix"")\n\n# Generate SoupChannel Object for SoupX \nsc = SoupChannel(data_tod, data, calcSoupProfile = FALSE)\n\n# Add extra meta data to the SoupChannel object\nsoupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data))\nsc = setSoupProfile(sc, soupProf)\n# Set cluster information in SoupChannel\nsc = setClusters(sc, soupx_groups)\n\n# Estimate contamination fraction\nsc = autoEstCont(sc, doPlot=FALSE)\n# Infer cor",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277:4743,error,error,4743,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685#issuecomment-1763978277,1,['error'],['error']
Availability,"version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console; $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no; Numba function called from a non-threadsafe context. Try installing `tbb`.; Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads.; - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):; File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper; File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _; File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper; File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func; File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task; File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get; File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__; File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task; File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task; File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks; File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run; File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3335#issuecomment-2457625478:1082,error,error,1082,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335#issuecomment-2457625478,1,['error'],['error']
Availability,"very interesting, also new to me. I think this boils down to issues in `pynndescent` not being able to handle such edge cases. I wonder if this happens with other metrics as well... @TiongSun can you update us on whether this is a similar issue for you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1696#issuecomment-802857928:53,down,down,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696#issuecomment-802857928,1,['down'],['down']
Availability,"vscode-cdn.net/data/LSY/venv/lib/python3.10/site-packages/scanpy/readwrite.py:123) if is_valid_filename(filename):; --> [124](https://vscode-remote+ssh-002dremote-002baws-005fcpu.vscode-resource.vscode-cdn.net/data/LSY/venv/lib/python3.10/site-packages/scanpy/readwrite.py:124) return _read(; [125](https://vscode-remote+ssh-002dremote-002baws-005fcpu.vscode-resource.vscode-cdn.net/data/LSY/venv/lib/python3.10/site-packages/scanpy/readwrite.py:125) filename,; [126](https://vscode-remote+ssh-002dremote-002baws-005fcpu.vscode-resource.vscode-cdn.net/data/LSY/venv/lib/python3.10/site-packages/scanpy/readwrite.py:126) backed=backed,; [127](https://vscode-remote+ssh-002dremote-002baws-005fcpu.vscode-resource.vscode-cdn.net/data/LSY/venv/lib/python3.10/site-packages/scanpy/readwrite.py:127) sheet=sheet,; [128](https://vscode-remote+ssh-002dremote-002baws-005fcpu.vscode-resource.vscode-cdn.net/data/LSY/venv/lib/python3.10/site-packages/scanpy/readwrite.py:128) ext=ext,; ...; [65](https://vscode-remote+ssh-002dremote-002baws-005fcpu.vscode-resource.vscode-cdn.net/data/LSY/venv/lib/python3.10/site-packages/anndata/_core/aligned_df.py:65) anno = anno.copy(deep=False); [66](https://vscode-remote+ssh-002dremote-002baws-005fcpu.vscode-resource.vscode-cdn.net/data/LSY/venv/lib/python3.10/site-packages/anndata/_core/aligned_df.py:66) if not is_string_dtype(anno.index):. ValueError: Observations annot. `var` must have as many rows as `X` has columns (1), but has 33538 rows.; Error raised while reading key '' of <class 'h5py._hl.files.File'> from /; Output is truncated. View as a [scrollable element](command:cellOutput.enableScrolling?21de049a-219f-41e8-9d9d-5aabf61d8031) or open in a [text editor](command:workbench.action.openLargeOutput?21de049a-219f-41e8-9d9d-5aabf61d8031). Adjust cell output [settings](command:workbench.action.openSettings?%5B%22%40tag%3AnotebookOutputLayout%22%5D)...; ```; This is my version:; ```; print(sc.__version__); print(ad.__version__); 1.10.0; 0.10.6; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/323#issuecomment-2041512845:4114,Error,Error,4114,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/323#issuecomment-2041512845,1,['Error'],['Error']
Availability,"we need to finally fix that CI failure in this job, I only look into the `minimum_versions` job anymore before I merge PRs",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3336#issuecomment-2454799672:31,failure,failure,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3336#issuecomment-2454799672,1,['failure'],['failure']
Availability,"what if i told you that we can have our cake and eat it too? as said before:. > We could throw a nice error if the column isn’t in `.obs` but is in `.var` instead, like; > ; > > You specified column “dropout_per_gene” which is not in `.obs`, but in `.var`. Did you mean to call `sc.pl.violin(adata.T, ...)`?. Near zero frustration, because people can just do what the error tells them.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/375#issuecomment-441263484:102,error,error,102,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/375#issuecomment-441263484,2,['error'],['error']
Availability,"with `umap-lean==0.5.0` and `numba=0.53.1` I get a different error. ```python; import scanpy as sc; adata = sc.datasets.pbmc3k_processed(); sc.pp.neighbors(adata); ```. <details>; <summary>Details</summary>. ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-4-5d47edb05ae7> in <module>; ----> 1 sc.pp.neighbors(adata). ~/Projects/scanpy/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,. ~/Projects/scanpy/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 806 # we need self._distances also for method == 'gauss' if we didn't; 807 # use dense distances; --> 808 self._distances, self._connectivities = _compute_connectivities_umap(; 809 knn_indices,; 810 knn_distances,. ~/Projects/scanpy/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 385 # umap 0.5.0; 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""); --> 387 from umap.umap_ import fuzzy_simplicial_set; 388 ; 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/umap/__init__.py in <module>; 1 from warnings import warn, catch_warnings, simplefilter; ----> 2 from .umap_ import UMAP; 3 ; 4 try:; 5 with catch_warnings():. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/umap/umap_.py in <module>; 30 import umap.distances as dist; 31 ; ---> 32 import umap.sparse as sparse; 33 ; 34 from umap.utils import (. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/umap/sparse.py in <module>; 10 import nump",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-846931466:61,error,error,61,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-846931466,1,['error'],['error']
Availability,"workx 2.5; numba 0.51.2; numexpr 2.7.1; numpy 1.19.2; packaging 20.4; pandas 1.0.1; parso 0.5.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.7; ptyprocess 0.6.0; pvectorc NA; pygments 2.7.0; pylab NA; pyparsing 2.4.7; pyrsistent NA; pytz 2020.1; requests 2.23.0; requests_cache 0.5.2; scanpy 1.6.0; scipy 1.5.2; seaborn 0.11.0; send2trash NA; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; socks 1.7.1; soupsieve 2.0.1; statsmodels 0.12.0; storemagic NA; tables 3.6.1; terminado 0.8.3; tornado 6.0.4; traitlets 5.0.4; urllib3 1.25.10; wcwidth 0.2.5; wrapt 1.12.1; xlsxwriter 1.3.3; zmq 19.0.2; -----; IPython 7.18.1; jupyter_client 6.1.7; jupyter_core 4.6.3; jupyterlab 2.2.8; notebook 6.1.4; -----; Python 3.8.5 | packaged by conda-forge | (default, Aug 29 2020, 01:22:49) [GCC 7.5.0]; Linux-4.4.0-142-generic-x86_64-with-glibc2.10; 64 logical CPU cores, x86_64; -----; Session information updated at 2020-09-16 11:03; ```. Here is the error message:. ```; ---------------------------------------------------------------------------; InvalidIndexError Traceback (most recent call last); <ipython-input-37-b22ada65a1cd> in <module>; 1 # Create Concatenated anndata object for all timepoints; 2 #alldays = e125.concatenate(e135, e145, e155, uns_merge=""unique""); ----> 3 alldays = e125.concatenate(e135). ~/miniconda3/envs/env4sc_velo_scannpy/lib/python3.8/site-packages/anndata/_core/anndata.py in concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas); 1696 all_adatas = (self,) + tuple(adatas); 1697 ; -> 1698 out = concat(; 1699 all_adatas,; 1700 axis=0,. ~/miniconda3/envs/env4sc_velo_scannpy/lib/python3.8/site-packages/anndata/_core/merge.py in concat(adatas, axis, join, merge, uns_merge, label, keys, index_unique, fill_value, pairwise); 799 [dim_indices(a, axis=1 - axis) for a in adatas], join=join; 800 ); --> 801 reindexers = [; 802 gen_reindexer(alt_indices, dim_indices(a, axis=1 -",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1409#issuecomment-693478875:1851,error,error,1851,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1409#issuecomment-693478875,1,['error'],['error']
Availability,"xception:. SystemError Traceback (most recent call last); /hps/scratch/lsf_tmpdir/hl-codon-13-02/ipykernel_2124423/1009160698.py in <module>; ----> 1 sc.pp.neighbors(adata_pbmc3k). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 806 # we need self._distances also for method == 'gauss' if we didn't; 807 # use dense distances; --> 808 self._distances, self._connectivities = _compute_connectivities_umap(; 809 knn_indices,; 810 knn_distances,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 388 ; 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)); --> 390 connectivities = fuzzy_simplicial_set(; 391 X,; 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose); 600 knn_dists = knn_dists.astype(np.float32); 601 ; --> 602 sigmas, rhos = smooth_knn_dist(; 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),; 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x150524c6cdc0>) returned a result with an error set. time: 3 s (started: 2021-08-23 11:59:12 +01:00); ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1983#issuecomment-903666863:2900,error,error,2900,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983#issuecomment-903666863,1,['error'],['error']
Availability,"xit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output. note: This is an issue with t",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:3777,avail,available,3777,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['avail'],['available']
Availability,"y in <module>; ----> 1 from .umap_ import UMAP; 2 ; 3 # Workaround: https://github.com/numba/numba/issues/3341; 4 import numba; 5 . ~/.conda/envs/rpy/lib/python3.9/site-packages/umap/umap_.py in <module>; 52 from umap.spectral import spectral_layout; 53 from umap.utils import deheap_sort, submatrix; ---> 54 from umap.layouts import (; 55 optimize_layout_euclidean,; 56 optimize_layout_generic,. ~/.conda/envs/rpy/lib/python3.9/site-packages/umap/layouts.py in <module>; 37 },; 38 ); ---> 39 def rdist(x, y):; 40 """"""Reduced Euclidean distance.; 41 . ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/decorators.py in wrapper(func); 219 with typeinfer.register_dispatcher(disp):; 220 for sig in sigs:; --> 221 disp.compile(sig); 222 disp.disable_compile(); 223 return disp. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/dispatcher.py in compile(self, sig); 907 with ev.trigger_event(""numba:compile"", data=ev_details):; 908 try:; --> 909 cres = self._compiler.compile(args, return_type); 910 except errors.ForceLiteralArg as e:; 911 def folded(args, kws):. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 77 ; 78 def compile(self, args, return_type):; ---> 79 status, retval = self._compile_cached(args, return_type); 80 if status:; 81 return retval. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 91 ; 92 try:; ---> 93 retval = self._compile_core(args, return_type); 94 except errors.TypingError as e:; 95 self._failed_cache[key] = e. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 104 ; 105 impl = self._get_implementation(args, {}); --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,; 107 self.targetdescr.target_context,; 108 impl,. ~/.conda/envs/rpy/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_typ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796:3974,error,errors,3974,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-803866796,1,['error'],['errors']
Availability,"y with mkl.; ```python; (base) C:\Users\Park_Lab>conda activate Python38; (Python38) C:\Users\Park_Lab>cd Downloads/; (Python38) C:\Users\Park_Lab\Downloads>pip install numpy-1.21.5+mkl-cp38-cp38-win_amd64.whl; Processing c:\users\park_lab\downloads\numpy-1.21.5+mkl-cp38-cp38-win_amd64.whl; Installing collected packages: numpy; Attempting uninstall: numpy; Found existing installation: numpy 1.21.5; Uninstalling numpy-1.21.5:; Successfully uninstalled numpy-1.21.5; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.21.5+mkl which is incompatible.; Successfully installed numpy-1.21.5+mkl; ```; Step7: check anaconda Python38 environment, numpy-1.21.5+mkl is successfully installed; ![image](https://user-images.githubusercontent.com/75048821/147306587-eb94c188-5c18-40f0-add0-3a899872d786.png). Step8: Scanpy import error. Numpy>v1.20 is conflicted with Scanpy; ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600); ; import scvelo as scv; scv.settings.verbosity = 3; scv.settings.presenter_view = True; scv.logging.print_versions(). import cellrank as cr; cr.settings.verbosity = 3; cr.logging.print_versions(). import matplotlib.pyplot as pl; from matplotlib import rcParams; ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_13940/2696797780.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\anaconda3\envs\Python38\lib\site-packages\scanpy\__init__.py in <module>; 4 ; 5 if not within_flit(): # see function docstring on why this is there; ----> 6 from ._utils import check_versions; 7 ; 8 check_versions(). ~\anaconda3\en",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342:5247,error,error,5247,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342,1,['error'],['error']
Availability,y/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:68266,ERROR,ERROR,68266,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,y/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/t,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:66618,ERROR,ERROR,66618,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,y/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200-inf-30-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100-False] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-True] ERROR [ 32%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-200-False] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_inputchecks[csr_matrix-int64] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] ERROR [ 33%]; scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] ERROR [ 33%]; scanpy/tests/test_highly_variable_genes.py::test_higly_variable_genes_compare_to_seurat FAILED [ 33%]; ...; scanpy/tests/test_highly_variable_genes.py::test_filter_genes_dispersion_compare_to_seurat FAILED [ 34%]; scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_batches,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316:4450,ERROR,ERROR,4450,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718#issuecomment-1782780316,1,['ERROR'],['ERROR']
Availability,y/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_pca.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/tests/test_normalization.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_preprocessing.py - ImportError: cannot import name 'ARRAY_TYPES_SUPPORTED' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scan...; ERROR scanpy/tests/test_metrics.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_utils.py - ImportError: cannot import name 'ARRAY_TYPES' from 'scanpy.testing._pytest.params' (/mnt/workspace/repos/scanpy/scanpy/...; ERROR scanpy/tests/test_rank_genes_groups.p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:67616,ERROR,ERROR,67616,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"y48/lib/site-packages/numba/core/compiler.py?line=495) assert self.state.func_ir is None; --> [497](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=496) return self._compile_core(). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:476, in CompilerBase._compile_core(self); [474](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=473) self.state.status.fail_reason = e; [475](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=474) if is_final_pipeline:; --> [476](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=475) raise e; [477](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=476) else:; [478](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=477) raise CompilerError(""All available pipelines exhausted""). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:463, in CompilerBase._compile_core(self); [461](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=460) res = None; [462](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=461) try:; --> [463](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=462) pm.run(self.state); [464](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=463) if self.state.cr is not None:; [465](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=464) break. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler_machinery.py:353, in PassManager.run(self, state); [350](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:21418,avail,available,21418,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659,1,['avail'],['available']
Availability,"y_variable""] (regardless of the value of the batch_key option), using adata.var[""highly_variable_intersection""] for filtering is not a good idea. If there is confusion between adata.var[""highly_variable""] and adata.var[""highly_variable_intersection""]:. If the user specifies n_top_genes, adata.var[""highly_variable""] contains top variable genes in the list of genes sorted by number of batches they are detected as variable (ties broken using dispersion). If mean/dispersion filters are provided, we apply these cutoffs to mean mean/dispersion across batches to construct a unified adata.var[""highly_variable""]. adata.var[""highly_variable_intersection""] is a very strict definition that I personally avoid using at all, but it also depends on the experimental setting and batch_key itself. Therefore, there is a mistake in the following code:. ```python; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""); adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(); sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below; ```. This possibly removes many genes that are identified as highly variable in adata.var.highly_variable because adata_hvg = adata[:, adata.var.highly_variable_intersection] keeps only a subset of highly variable genes (see the definitions above). If one wants to use the strict definition, correct usage would be:. ```python; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""); adata.var.highly_variable = adata.var.highly_variable_intersection; sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below; ```. which is what @LuckyMD proposes, IIUC. I think what we should do here is to print a more informative error in PCA, smt like `HVGs identified by sc.pp.highly_variable_genes cannot be found in adata.`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1032#issuecomment-616740607:1366,error,error,1366,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032#issuecomment-616740607,3,['error'],['error']
Availability,y_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[stacked_violin_std_scale_var_dict-fn10] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_dict-fn4] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_violin_without_raw - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_paga.py::test_paga_path - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_enumerated_palettes[pca] - TypeError: map() got an unexpected keyword argument 'na_action'; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-float32-100n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:44640,Error,Error,44640,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['Error'],['Error']
Availability,"yes very good point, the tutorial needs to be fixed for sure because now it would fail.; trowing error in the heatmap is also probably the best way to go.; Thank you for reporting this! I'll have a look as soon as I have time",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1479#issuecomment-723090290:97,error,error,97,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479#issuecomment-723090290,1,['error'],['error']
Availability,"yes, I know, that's non-ideal... the sparseness issue is circumvented by only returning top-scoring genes... I see that you make suggestions for how the user can get dataframes but I tend to say that he shouldn't have to do some extra work for this. i think we should continue to return a table with groups vs. top-scoring genes. this is also what all others (Seurat, Pagoda, ...) do and what, I guess, feels most intuitive. a sparse object is likely to confuse users. if we start changing this, we should also talk to @mbuttner, who has written a function for transforming the recarrays to a single dataframe to write them to a csv or xls file and send it out to collaborators... we should also talk to @tcallies, who worked a lot on `rank_genes_groups`; ; our current workflow often involves showing collaborators tables of marker genes for different cell groups. these can get quite long as, e.g., transcription factors are not much differentially expressed, hence not top-scoring and appear further down the tabular. the tabular therefore has to be easily inspectable. currently, you can quickly turn a single rearray into a dataframe as shown [here](https://github.com/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). `rank_genes_groups` returns a recarray for historical reasons: there is a simple hdf5-backing via the recarray. these days, since the hdf5-backing of categorical data types within anndata works well, we could think about returning a dataframe directly. i guess this would be the way to go requiring only minor modifactions in that the hdf5-backing also accepts dataframes in `.uns` and not only in `.obs` and `.var`. very generally: I think that it would be a decent convention to only allow strings to denote groups/categories. this was also the convetion before using dataframes for the annotation. now we use the category dtype of pandas, which - in contrast to R - allows arbitrary data types for denoting categories. I don't see much advantage of this flexibi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/61#issuecomment-355082458:1003,down,down,1003,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/61#issuecomment-355082458,1,['down'],['down']
Availability,"you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here?. Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks; -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good!. > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes.; > ...; > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway?. > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here?. No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-781992443:1793,avail,available,1793,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-781992443,2,"['avail', 'robust']","['available', 'robust']"
Availability,ytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/te,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:57410,ERROR,ERROR,57410,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,ytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/neighbors/_backends/rapids.py - ImportError: cannot import name 'check_is_fitted' from 'sklearn.base' (/mnt/workspace/mambaforge/envs/anndata-min-deps-...; ERROR scanpy/testing/_pytest/params.py - ImportError: cannot import name 'as_dense_dask_array' from 'anndata.tests.helpers' (/mnt/workspace/mambaforge/envs/annd...; ERROR scanpy/testin,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:58746,ERROR,ERROR,58746,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['ERROR'],['ERROR']
Availability,"ython3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 310 @wraps(func); 311 def wrapper(*args, **kwargs) -> Callable[..., Any]:; --> 312 return func(*args, **kwargs); 313 ; 314 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs); 4174 kwargs.pop(""axis"", None); 4175 kwargs.pop(""labels"", None); -> 4176 return super().reindex(**kwargs); 4177 ; 4178 def drop(. ~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4810 # perform the reindex on the axes; 4811 return self._reindex_axes(; -> 4812 axes, level, limit, tolerance, method, fill_value, copy; 4813 ).__finalize__(self, method=""reindex""); 4814 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4021 if index is not None:; 4022 frame = frame._reindex_index(; -> 4023 index, method, copy, level, fill_value, limit, tolerance; 4024 ); 4025 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance); 4043 copy=copy,; 4044 fill_value=fill_value,; -> 4045 allow_dups=False,; 4046 ); 4047 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups); 4881 fill_value=fill_value,; 4882 allow_dups=allow_dups,; -> 4883 copy=copy,; 4884 ); 4885 # If we've made a copy once, no need to make another one. ~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice); 1299 # some axes don't allow reindexing with dups; 1300 if not allow_dups:; -> 1301 self.axes[axis]._can_reindex(indexer); 1302 ; 1303 if axis >= self.ndim:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in _can_reindex(self, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683:3178,toler,tolerance,3178,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/267#issuecomment-1018908683,1,['toler'],['tolerance']
Availability,"ython; import scanpy as sc; import numpy as np; import pandas as pd; import matplotlib.pyplot as plt; import seaborn as sns; import anndata; import matplotlib as mpl; import scipy. sc.logging.print_versions(); # scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.3 scipy==1.3.1 ; # pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1. sp = sc.datasets.pbmc3k(); sc.pp.normalize_total(sp,target_sum=1e6,key_added='norm_factor'); sc.pp.log1p(sp); sp.raw=sp; sc.pp.highly_variable_genes(sp, n_top_genes=2000); sc.pl.highly_variable_genes(sp); sp = sp[:, sp.var['highly_variable']]; sc.pp.scale(sp, max_value=10); sc.tl.pca(sp, svd_solver='arpack'); sc.pl.pca_variance_ratio(sp, log=True); sc.pp.neighbors(sp, n_neighbors=10, n_pcs=30); sc.tl.diffmap(sp); sc.pp.neighbors(sp, n_neighbors=20, use_rep='X_diffmap'); sc.tl.louvain(sp,resolution=1); sc.tl.paga(sp); _, axs = plt.subplots(ncols=1, figsize=(24, 10), gridspec_kw={'wspace': 0.05, 'left': 0.12}); # Modified this call because pos_coord wasn't defined:; # sc.pl.paga(sp,color='louvain',layout='fa',pos=pos_coord,threshold=0.2,ax=axs) ; sc.pl.paga(sp,color='louvain',layout='fa',threshold=0.2,ax=axs); from scanpy.tools._utils import get_init_pos_from_paga as init; sc.tl.umap(sp,init_pos=init(sp)); sc.pl.umap(sp,color='louvain'); ```. The final plot looks normal enough:. ![image](https://user-images.githubusercontent.com/8238804/69206364-8c9d1880-0ba0-11ea-8180-3bbd0b8c825e.png). Right now, there are a lot of variables in this script. There's a few things to try:. * Check if `pos_coord` is causing the issue; * I noticed your scanpy version wasn't the same as the current release, could you update that?; * If you run the script with the dataset I used, does your plot still have those strange rectangular layouts?; * Can you cut down the number of commands you used, and potentially even the amount of data? This will limit the number of variables that could be causing the behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/918#issuecomment-555819868:2088,down,down,2088,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/918#issuecomment-555819868,1,['down'],['down']
Availability,yup! genes you filtered out are not available unless you use `use_raw`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2068#issuecomment-2268851567:36,avail,available,36,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2068#issuecomment-2268851567,1,['avail'],['available']
Availability,"z=2019.3=pypi_0; pyyaml=5.3.1=py37h8f50634_0; pyzmq=19.0.0=py37hac76be4_1; readline=8.0=h7b6447c_0; requests=2.23.0=pyh8c360ce_2; scanpy=1.4.6=pypi_0; scikit-learn=0.22.2.post1=pypi_0; scipy=1.4.1=pypi_0; seaborn=0.10.1=pypi_0; send2trash=1.5.0=py_0; setuptools=46.1.3=py37_0; setuptools-scm=3.5.0=pypi_0; six=1.14.0=py_1; sqlite=3.31.1=h62c20be_1; statsmodels=0.11.1=pypi_0; tables=3.6.1=pypi_0; tbb=2020.0.133=pypi_0; terminado=0.8.3=py37hc8dfbb8_1; testpath=0.4.4=py_0; texttable=1.6.2=py_0; tk=8.6.8=hbc83047_0; tornado=6.0.4=py37h8f50634_1; tqdm=4.45.0=pypi_0; traitlets=4.3.3=py37hc8dfbb8_1; umap-learn=0.4.1=pypi_0; urllib3=1.25.9=py_0; wcwidth=0.1.9=pyh9f0ad1d_0; webencodings=0.5.1=py_1; wheel=0.34.2=py37_0; xorg-kbproto=1.0.7=h14c3975_1002; xorg-libice=1.0.10=h516909a_0; xorg-libsm=1.2.3=h84519dc_1000; xorg-libx11=1.6.9=h516909a_0; xorg-libxau=1.0.9=h14c3975_0; xorg-libxdmcp=1.1.3=h516909a_0; xorg-libxext=1.3.4=h516909a_0; xorg-libxrender=0.9.10=h516909a_1002; xorg-renderproto=0.11.1=h14c3975_1002; xorg-xextproto=7.3.0=h14c3975_1002; xorg-xproto=7.0.31=h14c3975_1007; xz=5.2.5=h7b6447c_0; yaml=0.2.4=h516909a_0; zeromq=4.3.2=he1b5a44_2; zipp=3.1.0=py_0; zlib=1.2.11=h7b6447c_3; ```. </details>. I've recreated your environment, but cannot reproduce this error. Here's how I created the environment:. ```bash; # Where the output you pasted above is in scanpy_1183_env.txt; $ grep -v pypi_0 scanpy_1183_env.txt > scanpy_1183_env_nopip.txt; $ grep pypi_0 scanpy_1183_env.txt | sed 's/=pypi_0//' | sed 's/=/==/' > scanpy_1183_pip.txt; $ conda create -y --name scanpy1183 --file scanpy_1183_env_nopip.txt; $ conda activate scanpy1183; $ pip install -r scanpy_1183_pip.txt; ```. Then I tested this using:. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k(); sc.pp.normalize_total(adata, target_sum=1e4); ```. But did not get an error. ~Could you send a snippet that reproduces the error for you?~ Oops, forgot that you already did this in the notebook. Taking a look at that now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1183#issuecomment-620988575:4504,error,error,4504,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183#issuecomment-620988575,3,['error'],['error']
Availability,~~But it seems to throw an error if I combine it with `-k`:~~. ```; ValueError: limit_multithreading did not yield a value; ```. Fixed,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2843#issuecomment-1934363564:27,error,error,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2843#issuecomment-1934363564,1,['error'],['error']
Availability,"⠀⠂⠠⢠⡁⡄⡌⠀⠀⠠⢅⠀⠄⠀⢕⢐⠀⠄⡂⢀⠂⠀⠂⠈⡸⠂; ⠀⠀⠀⢐⡂⠀⢀⠐⠀⠰⡀⠑⡀⠀⠠⠀⠐⢀⠈⠆⠤⠄⢀⠀⣀⠢⡀⠀; ⠂⢀⢪⢘⠀⢀⠩⠅⢄⠄⠠⠠⠐⠀⠀⢀⠠⠂⠀⠁⡘⠀⠀⠐⠢⡐⠀⠀; ⢀⠌⡘⠘⠂⠄⢀⠀⢠⠔⠈⢀⠈⠀⠀⠠⡀⡂⠄⢀⠀⠀⠀⠁⠔⢈⢰⠀; ⠁⠐⡀⡠⠀⠐⠠⠈⠀⢀⠀⠘⠂⠀⠀⠀⠐⠰⠄⡡⠠⡀⠀⠀⠂⠠⠁⠐; ```. While this is one with blocks along the diagonal:. ```; ⠿⣧⣤⣤⣤⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀; ⠀⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀; ⠀⠿⠿⠿⠿⣧⣤⣤⣤⣤⣤⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠛⠛⠛⠛⠛⠛⣤⣤⣤⣤⣤⣤⣤⣤⣤⣤⡄⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠿⠿⠿⠿⠿⠿⠿⠿⠿⠿⣧⣤⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠛⢻⣶⣶⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⠛⢻⣶⡆⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠉⣿⣿; ```. When you have blocks of dense values, you can just store those dense blocks as regular arrays along with offsets. > but can't you subset sparse matrices based on masks? Should be fairly easy to just skip indices that are not in the mask. Yes, this should be fine. The issue I was thinking of is more when you want to do something like `scale`-ing your expression. > Or mito/ribo genes are filtered out sometimes, which might be needed later on e.g. to redo qc etc. > In this case you might need these genes also during an analysis pipeline (and not just for data storage), so you would like to have them in a separate ""raw"" container that is otherwise not touched. If don't want them to be used as features for any analyses on `X`, they could be stored in `obsm`. If you want to use them for some analyses, (like DE), then they can just be masked out for others. > I would be a bit hesitant to not have a replacement for .raw. I think `layers` satisfies this. It just doesn't allow you to have a different set of variables (that is, not just a subset) for DE than the rest of the object has. But, having the different set of variables is what makes `raw` difficult to work with. > introduce a new .frozenraw or sth like that where just the raw data is stored and it's essentially read-only after assignment?. I'd note that `.raw` is already supposed to be read-only.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-820902472:4105,mask,masked,4105,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-820902472,1,['mask'],['masked']
Availability,"⠈⢀⠌⠚⠀⠀⠃; ⠁⠂⡃⠈⠀⢀⠀⠙⢀⠥⠀⠀⠄⡁⠀⠠⠈⠀⠈⠃⠂⠠⣀⠀⠈⣁⠁⠆; ⡀⠐⠐⠠⠀⠐⢐⡄⣂⠀⠀⠘⠀⠀⠀⠠⠂⠀⡀⠨⠁⠀⠀⠀⠁⠁⠣⠤; ⠀⡐⢀⢢⠀⠁⠔⠀⠁⠀⠃⠀⢀⢀⠐⠃⠄⠀⡇⠊⠄⠀⡈⢀⠀⠀⣀⠆; ⠀⢐⣤⡄⠠⠂⠃⡈⠘⠀⠀⠀⡂⠰⢄⠊⡂⠀⠐⠂⠀⠄⠀⠀⢱⠩⠈⢀; ⢁⠀⠑⠚⠁⠂⠂⠐⠁⠀⠀⢀⠠⠀⠐⠈⠈⡨⠀⠂⠀⡈⠈⠁⡐⣀⢁⠂; ⠀⠀⠀⠁⠀⠠⠅⠁⡠⠇⢐⠀⠀⠖⢉⣀⠀⢀⠀⠠⡀⠀⡀⢰⠁⠂⢉⠂; ⠀⠀⠀⠂⠠⢠⡁⡄⡌⠀⠀⠠⢅⠀⠄⠀⢕⢐⠀⠄⡂⢀⠂⠀⠂⠈⡸⠂; ⠀⠀⠀⢐⡂⠀⢀⠐⠀⠰⡀⠑⡀⠀⠠⠀⠐⢀⠈⠆⠤⠄⢀⠀⣀⠢⡀⠀; ⠂⢀⢪⢘⠀⢀⠩⠅⢄⠄⠠⠠⠐⠀⠀⢀⠠⠂⠀⠁⡘⠀⠀⠐⠢⡐⠀⠀; ⢀⠌⡘⠘⠂⠄⢀⠀⢠⠔⠈⢀⠈⠀⠀⠠⡀⡂⠄⢀⠀⠀⠀⠁⠔⢈⢰⠀; ⠁⠐⡀⡠⠀⠐⠠⠈⠀⢀⠀⠘⠂⠀⠀⠀⠐⠰⠄⡡⠠⡀⠀⠀⠂⠠⠁⠐; ```. While this is one with blocks along the diagonal:. ```; ⠿⣧⣤⣤⣤⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀; ⠀⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀; ⠀⠿⠿⠿⠿⣧⣤⣤⣤⣤⣤⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠛⠛⠛⠛⠛⠛⣤⣤⣤⣤⣤⣤⣤⣤⣤⣤⡄⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠿⠿⠿⠿⠿⠿⠿⠿⠿⠿⣧⣤⠀⠀⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠛⢻⣶⣶⠀⠀⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⠛⢻⣶⡆⠀; ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠉⣿⣿; ```. When you have blocks of dense values, you can just store those dense blocks as regular arrays along with offsets. > but can't you subset sparse matrices based on masks? Should be fairly easy to just skip indices that are not in the mask. Yes, this should be fine. The issue I was thinking of is more when you want to do something like `scale`-ing your expression. > Or mito/ribo genes are filtered out sometimes, which might be needed later on e.g. to redo qc etc. > In this case you might need these genes also during an analysis pipeline (and not just for data storage), so you would like to have them in a separate ""raw"" container that is otherwise not touched. If don't want them to be used as features for any analyses on `X`, they could be stored in `obsm`. If you want to use them for some analyses, (like DE), then they can just be masked out for others. > I would be a bit hesitant to not have a replacement for .raw. I think `layers` satisfies this. It just doesn't allow you to have a different set of variables (that is, not just a subset) for DE than the rest of the object has. But, having the different set of variables is what makes `raw` difficult to work wi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-820902472:3427,mask,masks,3427,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-820902472,2,['mask'],"['mask', 'masks']"
Deployability," 5.4.1; zmq 22.0.3; zope NA; -----; IPython 7.23.1; jupyter_client 6.1.12; jupyter_core 4.7.1; jupyterlab 3.0.16; notebook 6.4.0; -----; Python 3.8.10 (default, May 19 2021, 18:05:58) [GCC 7.3.0]; Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.10; 4 logical CPU cores, x86_64; -----; Session information updated at 2021-05-25 15:50. </Details>. I'm still trying to update h5py in the old environment, which has quite some inconsistencies in it, considerably slowing everything down. At some point it looked like I had success with installing h5py 3.2.1 from conda-forge after running `conda update anaconda` and `conda update --all` (as per [here](https://stackoverflow.com/questions/56072846/how-to-resolve-inconsistent-package-warnings-in-conda)). But now this environment leads to an ImportError when importing scanpy: `ImportError: /home/karl/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/h5py/defs.cpython-38-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_ros3`; Can it be that pip version of scanpy doesn't see the updated conda version of h5py?. <Details>; <summary>Inconsistencies in the old environment</summary>. ```; The following packages are causing the inconsistency:. - defaults/linux-64::_anaconda_depends==2020.07=py38_0; - defaults/linux-64::anaconda==custom=py38_1; - defaults/linux-64::cairo==1.14.12=h8948797_3; - defaults/linux-64::graphviz==2.40.1=h21bd128_2; - defaults/linux-64::harfbuzz==1.8.8=hffaf4a1_0; - conda-forge/linux-64::leidenalg==0.8.2=py38habedc41_0; - defaults/linux-64::pango==1.42.4=h049681c_0; - defaults/linux-64::pycairo==1.19.1=py38h708ec4a_0; - conda-forge/linux-64::python-igraph==0.7.1.post7=py38h516909a_0; - r/linux-64::r==3.6.0=r36_0; - r/linux-64::r-base==3.6.1=haffb61f_2; - r/noarch::r-boot==1.3_20=r36h6115d3f_0; - r/linux-64::r-class==7.3_15=r36h96ca727_0; - r/linux-64::r-cluster==2.0.8=r36ha65eedd_0; - r/noarch::r-codetools==0.2_16=r36h6115d3f_0; - r/linux-64::r-foreign==0.8_71=r36h96ca727_0; - r/linux-64::r-kernsmooth==2.23_15=r",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310:2699,update,updated,2699,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310,1,['update'],['updated']
Deployability," E501 line too long (93 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:656:80: E501 line too long (80 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:693:80: E501 line too long (80 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:713:80: E501 line too long (88 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:735:80: E501 line too long (82 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:737:80: E501 line too long (83 > 79 characters); scanpy/preprocessing/_highly_variable_genes.py:742:80: E501 line too long (80 > 79 characters). ```. `git status` and `git diff` show the automatic changes pre-commit makes:. ```; jlause@8b38045532aa:~/libs/scanpy/scanpy/preprocessing$ git status; On branch pearson_residuals_1.7; Changes to be committed:; (use ""git reset HEAD <file>..."" to unstage). 	modified: _highly_variable_genes.py. Changes not staged for commit:; (use ""git add <file>..."" to update what will be committed); (use ""git checkout -- <file>..."" to discard changes in working directory). 	modified: _highly_variable_genes.py. Untracked files:; (use ""git add <file>..."" to include in what will be committed). 	../../.pre-commit-config.yaml. jlause@8b38045532aa:~/libs/scanpy/scanpy/preprocessing$ git diff _highly_variable_genes.py ; diff --git a/scanpy/preprocessing/_highly_variable_genes.py b/scanpy/preprocessing/_highly_variable_genes.py; index 03b01940..e2851f50 100644; --- a/scanpy/preprocessing/_highly_variable_genes.py; +++ b/scanpy/preprocessing/_highly_variable_genes.py; @@ -15,7 +15,8 @@ from ._utils import _get_mean_var; from ._distributed import materialize_as_ndarray; from ._simple import filter_genes; ; -#testedit; +# testedit; +; ; def _highly_variable_genes_seurat_v3(; adata: AnnData,; @@ -98,7 +99,9 @@ def _highly_variable_genes_seurat_v3(; else:; clip_val_broad = np.broadcast_to(clip_val, batch_counts.shape); np.putmask(; - batch_counts, batch_counts > clip_val_broad, clip_val_br",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-794148562:8412,update,update,8412,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-794148562,1,['update'],['update']
Deployability," NA; arrow 1.3.0; asttokens NA; attr 24.2.0; attrs 24.2.0; babel 2.16.0; certifi 2024.08.30; cffi 1.17.1; charset_normalizer 3.3.2; colorama 0.4.6; comm 0.2.2; cycler 0.12.1; cython_runtime NA; dateutil 2.9.0.post0; debugpy 1.8.5; decorator 5.1.1; defusedxml 0.7.1; exceptiongroup 1.2.2; executing 2.1.0; fastjsonschema NA; fqdn NA; h5py 3.11.0; idna 3.8; importlib_resources NA; ipykernel 6.29.5; isoduration NA; jedi 0.19.1; jinja2 3.1.4; joblib 1.4.2; json5 0.9.25; jsonpointer 3.0.0; jsonschema 4.23.0; jsonschema_specifications NA; jupyter_events 0.10.0; jupyter_server 2.14.2; jupyterlab_server 2.27.3; kiwisolver 1.4.7; lazy_loader 0.4; legacy_api_wrap NA; llvmlite 0.43.0; markupsafe 2.1.5; matplotlib 3.9.2; mpl_toolkits NA; natsort 8.4.0; nbformat 5.10.4; nt NA; numba 0.60.0; numpy 1.26.4; overrides NA; packaging 24.1; pandas 2.2.2; parso 0.8.4; platformdirs 4.3.2; pooch v1.8.2; prometheus_client NA; prompt_toolkit 3.0.47; psutil 6.0.0; pure_eval 0.2.3; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.18.0; pyparsing 3.1.4; pythoncom NA; pythonjsonlogger NA; pytz 2024.2; pywin32_bootstrap NA; pywin32_system32 NA; pywintypes NA; referencing NA; requests 2.32.3; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; rpds NA; scipy 1.13.1; send2trash NA; session_info 1.0.0; six 1.16.0; skimage 0.24.0; sklearn 1.5.2; sniffio 1.3.1; stack_data 0.6.3; threadpoolctl 3.5.0; tornado 6.4.1; tqdm 4.66.5; traitlets 5.14.3; typing_extensions NA; uri_template NA; urllib3 2.2.3; wcwidth 0.2.13; webcolors 24.8.0; websocket 1.8.0; win32api NA; win32com NA; win32con NA; win32trace NA; winerror NA; yaml 6.0.2; zipp NA; zmq 26.2.0; zoneinfo NA; -----; IPython 8.18.1; jupyter_client 8.6.2; jupyter_core 5.7.2; jupyterlab 4.2.5; notebook 7.2.2; -----; Python 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]; Windows-10-10.0.22621-SP0; -----; Session information updated at 2024-09-12 21:33; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3228#issuecomment-2348022832:2131,update,updated,2131,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228#issuecomment-2348022832,1,['update'],['updated']
Deployability," _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; ../../miniconda3/envs/scanpy/lib/python3.9/functools.py:888: in wrapper; return dispatch(args[0].__class__)(*args, **kw); scanpy/preprocessing/_simple.py:888: in scale_anndata; X, adata.var[""mean""], adata.var[""std""] = do_scale(; ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; error_rewrite(e, 'typing'); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); issue_type = 'typing'. def error_rewrite(e, issue_type):; """"""; Rewrite and raise Exception `e` with help supplied based on the; specified issue_type.; """"""; if config.SHOW_HELP:; help_msg = errors.error_extras[issue_type]; e.patch_message('\n'.join((str(e).rstrip(), help_msg))); if config.FULL_TRACEBACKS:; raise e; else:; > raise e.with_traceback(None); E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); E non-precise type pyobject; E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); E ; E File ""scanpy/preprocessing/_simple.py"", line 763:; E def do_scale(X, maxv, nthr):; E <source elided>; E # t0= time.time(); E s = np.zeros((nthr, X.shape[1])); E ^ ; E ; E This error may have been caused by the following argument(s):; E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>. ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; ```. When trying to use the new flavor with the existing test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183:2062,pipeline,pipeline,2062,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1533308183,1,['pipeline'],['pipeline']
Deployability," `from skmisc.loess import loess`; ```python; from skmisc.loess import loess; ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_11028/3052125001.py in <module>; ----> 1 from skmisc.loess import loess. ~\AppData\Roaming\Python\Python38\site-packages\skmisc\loess\__init__.py in <module>; 49 pp. 829--836. 1979.; 50 """"""; ---> 51 from ._loess import (loess, loess_model, loess_inputs, loess_control,; 52 loess_outputs, loess_prediction,; 53 loess_confidence_intervals, loess_anova). ImportError: DLL load failed while importing _loess: The specified module could not be found.; ```; Step5: run `import skmisc; print(skmisc.__file__)`; ```python; import skmisc; print(skmisc.__file__); C:\Users\Park_Lab\AppData\Roaming\Python\Python38\site-packages\skmisc\__init__.py; ```; Step6: due to Step4, I follow the solution (https://github.com/has2k1/scikit-misc/issues/4) to install Numpy with mkl.; ```python; (base) C:\Users\Park_Lab>conda activate Python38; (Python38) C:\Users\Park_Lab>cd Downloads/; (Python38) C:\Users\Park_Lab\Downloads>pip install numpy-1.21.5+mkl-cp38-cp38-win_amd64.whl; Processing c:\users\park_lab\downloads\numpy-1.21.5+mkl-cp38-cp38-win_amd64.whl; Installing collected packages: numpy; Attempting uninstall: numpy; Found existing installation: numpy 1.21.5; Uninstalling numpy-1.21.5:; Successfully uninstalled numpy-1.21.5; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.21.5+mkl which is incompatible.; Successfully installed numpy-1.21.5+mkl; ```; Step7: check anaconda Python38 environment, numpy-1.21.5+mkl is successfully installed; ![image](https://user-images.githubusercontent.com/75048821/147306587-eb94c188-5c18-40f0-add0-3a899872d786.png). Step8: Scanpy import error. Numpy>v1.20 is conflicted with Scanpy; ```python; import numpy as np; import pa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342:4400,install,install,4400,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342,1,['install'],['install']
Deployability," `mypy` allow partial typing these days? Also, I haven't found the numpy or pandas type stubs to always be great. Have you run into problems around this?. I think this would also need to wait at least until we can drop python 3.6 for `anndata`, since adding types there currently means circular dependencies. > `rstcheck` to check the syntax of .rst files. I would particularly like a linter for `rst`. I noticed you also had `doc8`, but you'd recommend `rstcheck` check over this? I'm a little worried, considering its last release was over a year ago. Spell check for prose in doc-strings could also be great, but I could see this being overzealous (is there a good way to notify about misspelled words, while not being annoying about technical terms?). I'm a little worried about some custom sphinx extensions we have, and conflicting with this, any experience here?. --------------------------------------------. @Koncopd, I think I agree with your concern, as I said above: it's the worst when you want to fix a bug, but instead have to learn about configuring a linter. I also think it's very easy to add new checks, so someone complaining about new ones is valuable. Per commit, this should always be an option with `git commit --no-verify`, though you could also just not install `pre-commit`. I would like to keep the required checks limited, ideally formatting tasks that can be automated as opposed ""this is poor style"" warnings. I also know these tools can be wrong (e.g. `black` when expression's have many operators, sometimes with chaining) so it would be good to document the escape hatches for this (`# fmt: off` for `black`). That said, we already do require that merged code goes through black before it gets merged, and a benefit of using this would be to not have commit messages like ""formatting"", ""remove unused import"", etc. The pre-commit checks would be a part of CI as well, so it would be *eventually* mandatory – just not on your machine. Does this address your concerns?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1563#issuecomment-754352635:1707,install,install,1707,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563#issuecomment-754352635,1,['install'],['install']
Deployability," a) numba was failing inference unless I was explicit about integers and b) downsampling counts only makes sense for integer valued numbers. At the time I couldn't see a reason to convert the output to a different type. I figure that `log1p` should be able to take an integer valued expression matrix. However, I tried to implement that and ended up adding a lot of flow control to an already flow control heavy function, which got ugly:. <details>; <summary> 🍝 </summary>. ```python; def log1p(data, copy=False, chunked=False, chunk_size=None):; """"""Logarithmize the data matrix. Computes `X = log(X + 1)`, where `log` denotes the natural logarithm. Parameters; ----------; data : :class:`~anndata.AnnData`, `np.ndarray`, `sp.sparse`; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; copy : `bool`, optional (default: `False`); If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""; if copy:; if not isinstance(data, AnnData):; data = data.astype(np.floating); data = data.copy(); elif not isinstance(data, AnnData) and np.issubdtype(data.dtype, np.integer):; raise TypeError(""Cannot perform inplace log1p on integer array""). def _log1p(X):; if issparse(X):; np.log1p(X.data, out=X.data); else:; np.log1p(X, out=X). return X. if isinstance(data, AnnData):; if not np.issubdtype(data.X.dtype, np.floating):; data.X = data.X.astype(np.floating, copy=False); if chunked:; for chunk, start, end in data.chunked_X(chunk_size):; data.X[start:end] = _log1p(chunk); else:; _log1p(data.X); else:; _log1p(data). return data if copy else None; ```. </details>. I'll give that another shot, and open a PR. On the return type of `downsample_counts`, I've noticed many functions in scanpy return `float32` matrices regardless of what was given to them. Is this a design that's meant to be propagated? Even if not, what should the return type of `downsample_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239:1209,update,updates,1209,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/435#issuecomment-475842239,1,['update'],['updates']
Deployability, did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.default-na_in_legend.False-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.default-na_in_legend.False-legend.on_right-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-inftheta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-200n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-inftheta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-200n-100theta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED s,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:14516,pipeline,pipeline,14516,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['pipeline'],['pipeline']
Deployability," error.; Running this with ```pip -vv install scanpy``` as you suggested indeed gives an error with numba, . ```; Collecting numba>=0.41.0; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-unpack-9g89heod; Looking up ""https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; Running command python setup.py egg_info; Traceback (most recent call last):; File ""<string>"", line 2, in <module>; File ""<pip-setuptools-caller>"", line 34, in <module>; File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for outpu",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:1822,install,install-,1822,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['install'],['install-']
Deployability," implement if python had generic functions. This is kinda something that's being worked on for numpy, but the assumptions a ufunc has about it's input data does not match with what an AnnData object is. I've worked on a side project of just wrapping the sklearn transformers so you can pass anndata objects, and could try and get that cleaned up for use if it'd be valuable. --------------------------------. I'm not really sure what you expect this line to do though:. ```python; adata[:, adata.var_names[0:3]] - adata[:, adata.var_names[3:6]]; ```. I would probably throw an error for that, since the var names wouldn't be the same. It's also not obvious to me which arrays would be subtracted (all of them? some of them?). If this is meant to do:. ```python; adata[:, adata.var_names[0:3]].X - adata[:, adata.var_names[3:6]].X; ```. I don't think that's so much more work. > I think it should return the whole AnnData object, like how DataFrames return themselves. I don't know if we think it should ""update"" the original AnnData. I'm also confused by how this results in a performance decrease?. If it should return the whole object, but not update the original, then all of the values from the original need to be copied to prevent unintentional modification. This is really expensive for large objects, which single cell datasets often are. For your example of `adata = np.sqrt(adata)` vs `adata_sq = np.sqrt(adata)`, there's no way for us to tell which of those statements was made while evaluating `np.sqrt`. That would require the ability to overload assignment, and for python to have different evaluation rules. ### 2. Requirement to use .var_vector or .obs_vector for single columns. Is what you're saying that you want: `adata[:, adata.var_names[0]].X` to be one dimensional?. This used to be the behaviour, but it got confusing quickly. Suddenly, `adata.X` could be a different shape from `adata`. I would recommend reading the issues that were opened about this on `anndata` for more c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-608231245:1117,update,update,1117,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-608231245,1,['update'],['update']
Deployability," it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand.; I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```; $ conda create -yn flit-deps python=3.8 flit; $ conda activate flit-deps; $ flit install -s --dep=develop # Make development install of scanpy; $ pip install scvelo # Install project that depends on scanty; ...; Attempting uninstall: scanpy; Found existing installation: scanpy 1.8.0.dev49-ge715cd98; Uninstalling scanpy-1.8.0.dev49-ge715cd98:; Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98; ...; # Development version of scanpy has now been uninstalled; ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-787407852:1318,install,install,1318,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-787407852,8,"['Install', 'install']","['Install', 'install', 'installation', 'installations']"
Deployability," methods paper, e.g., the [scran pooling paper](http://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-0947-7)), there are a couple of things to consider here:; 1. Do we even want relative expression counts?; 2. What assumptions do downstream methods have on the distribution of expression values. For the first question: relative gene expression values ignore differences in cell sizes/number of molecules in the cell. There are some molecules whose numbers scale with the size of the cell, and others that don't (e.g., many housekeeping genes). Choosing relative over absolute expression values to compare gene expression across cells would be helpful to compare expression of those genes that scale with size, but not the others.... so there's not really a perfect answer here. Thus, removing all effects of total counts may not be the desirable outcome. Secondly, many downstream methods assume normally distributed expression data (e.g., DE methods like: t-tests, limma, MAST, or several batch correction/data integration methods). Log transformation is used as a variance stabilization to approximate a normal distribution (quite often poorly, but better than without). This leads to many methods performing better with log transformation. IMO, the ideal approach is probably something like scVI, GLMPCA, or scTransform, where you fit a model directly to the count data and use the residuals to describe the data. This would address both steps of normalization and variance stabilization at the same time. If we have a good model to describe the data, the residuals should quantify the biological variance + normally distributed noise. Overall, I would use other normalization approaches than CPM, and use log-transformation with anything that uses size factors that scale per-cell expression values. . Note also that the effect described in the second paper you mention (from Aaron Lun) will mainly be relevant when you have biased distributions of sequencing depth between two samp",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643:1438,integrat,integration,1438,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1364#issuecomment-678119643,1,['integrat'],['integration']
Deployability," natsort 7.1.1; nbclient 0.6.4; nbconvert 6.5.0; nbformat 5.4.0; nest-asyncio 1.5.5; networkx 2.5; notebook 6.4.11; numba 0.52.0; numexpr 2.7.3; numpy 1.19.5; numpy-groupies 0.9.17; numpyro 0.9.2; oauthlib 3.2.0; openpyxl 3.0.10; opt-einsum 3.3.0; optax 0.1.2; packaging 20.9; pandas 1.2.0; pandocfilters 1.5.0; parso 0.8.2; pathos 0.2.7; patsy 0.5.1; pexpect 4.8.0; pickleshare 0.7.5; Pillow 9.1.1; pip 21.1.1; pox 0.2.9; ppft 1.6.6.3; prometheus-client 0.14.1; prompt-toolkit 3.0.18; protobuf 3.19.0; protobuf3-to-dict 0.1.5; ptyprocess 0.7.0; pyasn1 0.4.8; pyasn1-modules 0.2.8; pycosat 0.6.3; pycparser 2.20; pyDeprecate 0.3.1; Pygments 2.9.0; pyOpenSSL 20.0.1; pyparsing 2.4.7; pyro-api 0.1.2; pyro-ppl 1.8.1; pyrsistent 0.18.1; PySocks 1.7.1; python-dateutil 2.8.1; python-igraph 0.9.1; pytorch-lightning 1.5.10; pytz 2021.1; PyWavelets 1.3.0; PyYAML 6.0; pyzmq 22.0.3; requests 2.25.1; requests-oauthlib 1.3.1; rich 12.4.4; rpy2 3.4.2; rsa 4.8; ruamel-yaml-conda 0.15.80; ruamel.yaml 0.17.21; ruamel.yaml.clib 0.2.6; s3transfer 0.4.2; sagemaker 2.39.0.post0; scanpy 1.6.1; scikit-image 0.19.2; scikit-learn 0.24.2; scikit-misc 0.1.4; scipy 1.6.0; scrublet 0.2.3; scvi-tools 0.16.2; seaborn 0.11.1; Send2Trash 1.8.0; setuptools 59.5.0; setuptools-scm 6.0.1; sinfo 0.3.1; six 1.15.0; smdebug-rulesconfig 1.0.1; soupsieve 2.3.2.post1; spectra 0.0.11; statsmodels 0.12.2; stdlib-list 0.8.0; tables 3.6.1; tensorboard 2.9.0; tensorboard-data-server 0.6.1; tensorboard-plugin-wit 1.8.1; terminado 0.15.0; texttable 1.6.3; threadpoolctl 2.1.0; tifffile 2021.11.2; tinycss2 1.1.1; toolz 0.11.2; torch 1.11.0; torchmetrics 0.9.0; tornado 6.1; tqdm 4.60.0; traitlets 5.2.2.post1; typing-extensions 4.2.0; tzlocal 2.1; umap-learn 0.4.6; urllib3 1.26.4; wcwidth 0.2.5; webencodings 0.5.1; Werkzeug 2.1.2; wheel 0.36.2; widgetsnbextension 3.6.0; yarl 1.7.2; zipp 3.4.1; Note: you may need to restart the kernel to use updated packages."". </details>. Has anyone found any solution to work around this issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-1146346336:5580,update,updated,5580,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-1146346336,1,['update'],['updated']
Deployability," no? In the end you are distributing a data file. You can have your version of the normalized data in a layer... and you would be distributing your analysis code as well, so it's always clear how people should use this data file that is being deposited, no?. > Might be important for integration?. Integration works better with HVGs typically, so I don't think these super lowly expressed genes are so relevant here... I would often go with `min_cells=20` or even `50` for larger datasets. In the end I reason that this value will be approximately related to the size of the smallest unique cellular identity you expect to find. > This does run into memory usage problems if want do a densifying transform on the data. Don't understand this entirely... and not sure what a block sparse matrix type is... but can't you subset sparse matrices based on masks? Should be fairly easy to just skip indices that are not in the mask... although i can imagine it might be slower than doing this on dense matrices. Based on above arguments the main issue I see is currently for the case @gokceneraslan mentioned about MT genes or non-coding genes being stored in `.raw`. In this case you might need these genes also during an analysis pipeline (and not just for data storage), so you would like to have them in a separate ""raw"" container that is otherwise not touched. This clashes with the way raw is used in current scanpy pipeline. I think we could deprecate the way `.raw` is used at the moment, and use a `.layer` for this instead (maybe a designated ""raw"" layer?), but then introduce a new `.frozenraw` or sth like that where just the raw data is stored and it's essentially read-only after assignment?. I would be a bit hesitant to not have a replacement for `.raw` as a version of the data that is used for DE analysis but not `.X`. This distinction is quite useful as it is becoming more frequent that you have 1 version of the data for further embedding-based analysis, and one for moecular analysis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-820336449:1473,pipeline,pipeline,1473,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-820336449,2,['pipeline'],['pipeline']
Deployability," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-801745797:2179,patch,patching,2179,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-801745797,1,['patch'],['patching']
Deployability," pipeline.compile_extra(func). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:429, in CompilerBase.compile_extra(self, func); [427](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=426) self.state.lifted = (); [428](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=427) self.state.lifted_from = None; --> [429](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=428) return self._compile_bytecode(). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:497, in CompilerBase._compile_bytecode(self); [493](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=492) """"""; [494](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=493) Populate and run pipeline for bytecode input; [495](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=494) """"""; [496](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=495) assert self.state.func_ir is None; --> [497](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=496) return self._compile_core(). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:476, in CompilerBase._compile_core(self); [474](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=473) self.state.status.fail_reason = e; [475](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=474) if is_final_pipeline:; --> [476](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=475) raise e; [477](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:20220,pipeline,pipeline,20220,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659,1,['pipeline'],['pipeline']
Deployability," remeber thinking about this as a possibility. IIRC I decided against this because I just as frequently wanted some other column, like `""gene_symbols""` as the index. I could see adding this as an option via a keyword argument now. But maybe you just want to use `sc.get.obs_df`?. ### 4. Clusters as categories creates confusing scatterplots. Well, there is no order to the categories, so I guess I see why `matplotlib` wouldn't plot those in sorted order, but agree it's a little counter intuitive. Seems like more of a matplotlib issue to me though. ### 5. Cannot pass clusters to c parameter in plt.scatter. Use one of these?. ```python; sc.pl.scatter(pbmc, x=pbmc.var_names[0], y=pbmc.var_names[1], color=""leiden"") . import seaborn as sns; sns.scatterplot(pbmc.X[:, 0], pbmc.X[:, 0], hue=pbmc.obs[""leiden""]); ```. Categorical values for scatter plots are a known issue for matplotlib, as I linked to above. Their current behaviour if you pass a numeric valued categorical (regardless of whether it's ordered) is to use a continuous color palette, which in my opinion is easily misleading. ### 6. Clusters as categories frustrate subclustering. We've used a different convention for subclustering, which is actually the reason we use strings. We're assuming you're breaking a cluster or set of clusters into smaller ones, so the new id is appended to the old one. I believe there's a tutorial with this somewhere. Do you know where this was @LuckyMD?. Basically, I'd say do something more like:. ```python; from collections.abc import Iterable; import numpy as np; import pandas as pd; from sklearn import cluster. def kmeans_subcluster(adata, orig_key, orig_clusters, key_added):; if isinstance(orig_clusters, str) or not isinstance(orig_clusters, Iterable):; orig_clusters = [orig_clusters]. subset = adata[adata.obs[orig_key].isin(orig_clusters)]; sub_clustering = cluster.KMeans(n_clusters=2).fit_predict(subset.X). # Make new clustering; ; new_clustering = adata.obs[orig_key].copy(); # Make n",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-608231245:3448,continuous,continuous,3448,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-608231245,1,['continuous'],['continuous']
Deployability," the early exaggeration factor or the learning rate might be too high. **learning_rate** : `float`, optional (default: 1000). Note that the R-package ""Rtsne"" uses a default of 200.; The learning rate can be a critical parameter. It should be; between 100 and 1000. If the cost function increases during initial; optimization, the early exaggeration factor or the learning rate; might be too high. If the cost function gets stuck in a bad local; minimum increasing the learning rate helps sometimes. **random_state** : `int` or `None`, optional (default: 0). Change this to use different intial states for the optimization. If `None`,; the initial state is not reproducible. **use_fast_tsne** : `bool`, optional (default: `True`). Use the MulticoreTSNE package by D. Ulyanov if it is installed. **n_jobs** : `int` or `None` (default: `sc.settings.n_jobs`). Number of jobs. **copy** : `bool` (default: `False`). Return a copy instead of writing to adata. :Returns:. Depending on `copy`, returns or updates `adata` with the following fields. . **X_tsne** : `np.ndarray` (`adata.obs`, dtype `float`); ```. Now let's look at `pp.neighbors` where you're reading the type annotations from the signature.; - Obviously, the signature itself now is a mess for humans to read. But ok, that's fine if the docstring is easy to read.; - There is an error ` <class 'inspect._empty'>`; - The rest looks good to me, except for the superficial stylistic remarks above.; ```; Signature: sc.pp.neighbors(adata:anndata.base.AnnData, n_neighbors:int=15, n_pcs:Union[int, NoneType]=None, use_rep:Union[str, NoneType]=None, knn:bool=True, random_state:Union[int, mtrand.RandomState, NoneType]=0, method:str='umap', metric:Union[str, Callable[[numpy.ndarray, numpy.ndarray], float]]='euclidean', metric_kwds:Mapping[str, Any]={}, copy:bool=False) -> Union[anndata.base.AnnData, NoneType]; Docstring:; Compute a neighborhood graph of observations [McInnes18]_. The neighbor search efficiency of this heavily relies on UMAP [McI",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/192#issuecomment-404108999:3585,update,updates,3585,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192#issuecomment-404108999,1,['update'],['updates']
Deployability," the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handling setup.cfg-only projects.; import os, sys, tokenize; ; try:; import setuptools; except ImportError as error:; print(; ""ERROR: Can not execute `setup.py` since setuptools is not available in ""; ""the build environment."",; file=sys.stderr,; ); sys.exit(1); ; __file__ = %r; sys.argv[0] = __file__; ; if os.path.exists(__file__):; filename = __file__; with tokenize.open(__file__) as f:; setup_py_code = f.read(); else:; filename = ""<auto-generated setuptools caller>""; setup_py_code = ""from setuptools import setup; setup()""; ; exec(compile(setup_py_code, filename, ""exec"")); '""'""''""'""''""'""' % ('""'""'/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output. note: This is an issue with the package mentioned above, not pip.; hint: See above for details.; Exception information:; Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:4538,install,install-,4538,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['install'],['install-']
Deployability," this can quickly get out of bounds, I'd thus suggest to; ; - constrain this discussion to `matplotlib`/`seaborn` (as this is what scanpy and afaik most of the ecosystem projects are using); - only focus on the low-level use-cases. . In brief all that is required to implement a plotting API that behaves like scanpy's. . ---. > I'd be interested in hearing specific thoughts on this. I've personally been thinking it would be nice to lean on seaborn plotting classes more heavily here, potentially contributing features upstream. Here's one example mwaskom/seaborn#2487 of a feature which could fit the AnnData data model nicely. I was mostly referring to @fidelram's idea how to make plot styling more ""modular"" instead of having a vast amount of arguments for a single plotting function (#956). If this idea was to be implemented for all scanpy plotting functions, I thought that maybe an abstract base-class could provide the method signatures to ensure consistency within scanpy and ecosystem packages. Even with the current ""keyword approach"" it would be great if there was some way to ensure that common keywords are always named consistently. . What would be an example of a plot object you would like to ""move"" to seaborn? Something like a multi-panel UMAP plot? . ---. > I'd like to move towards stabilizing this. I'm not sure how much we'd want to provide plotting library specific code, vs. more generic helpers. Right now the most obvious addition is _set_color_for_categorical_obs, which I'd also like to make accessible through sc.get. Adding groupby support to anndata would help a lot here too (theislab/anndata#556). that sounds great! . ---. Finally, in terms of ""reusable building blocks"" I was thinking of, for instance, . - the ""dot size legend"" ; ![image](https://user-images.githubusercontent.com/7051479/118252952-a378ae80-b4a9-11eb-8a11-72bf46cdae20.png). - Setting up axes for a scatter plot together with the appropriate legend (continuous color bar or categorical legend)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1832#issuecomment-841139143:2011,continuous,continuous,2011,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832#issuecomment-841139143,1,['continuous'],['continuous']
Deployability," to start a flame war. Scanpy is an excellent piece of software, and I greatly appreciate at the work that goes into it. Responding to @LuckyMD, I again would just point out that returning cluster labels as ints is the standard for sklearn, and I would urge that scanpy serve as an access point to single cell analysis both for biologists and also for data science / machine learning researchers. Biologists will likely stick to using scanpy's plotting functions where you can handle default color maps for things that appear to be labels. We do this kind of checking in scprep: https://github.com/KrishnaswamyLab/scprep/blob/09de1bf41c4b42d331b29a4493c436110b641e07/scprep/plot/scatter.py#L206-L253. However, for machine learning researchers who likely have their own preferred plotting tools in matplotib or seaborn, might be trying to use the results from clustering in scanpy to compare to results from `sklearn.cluster`, or otherwise want to fit scanpy into their analysis pipelines, turning arrays of numerics into arrays of strings causes headaches that make the tools less accessible. The argument about the default colormap in matplotlib is continuous seems less important than making scanpy compatible with the larger ecosystem of data science tools in Python. Finally, I will note that in Python, strings are also defined ordinally, even if you might not think of them that way. Although in some respects the question, ""Is `'1'` less than `'a'`?"" is nonsensical, this is a well defined test in Python. ```python; In [1]: '1' < 'a'; Out[1]: True; ```. Again, I want to emphasize that I really love what has been done with scanpy / anndata so far. We use it in various places in our single cell workshop (https://krishnaswamylab.org/workshop), and I rely on the implementations of louvain / paga / dpt for my research. I bring up these issues here because I think changing some of these conventions could result in greater widespread adoption that I would love to see for scanpy and anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-582988545:2108,pipeline,pipelines,2108,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-582988545,2,"['continuous', 'pipeline']","['continuous', 'pipelines']"
Deployability," ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. I've pasted the output of scanpy.logging.print_versions() details below as requested, which includes a verification of used scanpy version (latest version, 1.9.3). It may not be important, but I also had to install `leidenalg` manually in the middle of the tutorial. That's the only deviation I made from the original tutorial. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 10.0.0; appnope 0.1.3; asttokens NA; backcall 0.2.0; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; h5py 3.9.0; igraph 0.10.6; ipykernel 6.25.0; jedi 0.18.2; joblib 1.3.1; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.40.1; matplotlib 3.7.2; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numpy 1.24.4; packaging 23.1; pandas 2.0.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.9.1; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pyparsing 3.0.9; pytz 2023.3; scipy 1.11.1; session_info 1.0.0; sitecustomize NA; six 1.16.0; sklearn 1.3.0; stack_data 0.6.2; texttable 1.6.7; threadpoolctl 3.2.0; tornado 6.3.2; traitlets 5.9.0; wcwidth 0.2.6; zmq 25.1.0; -----; IPython 8.14.0; jupyter_client 8.3.0; jupyter_core 5.3.1; -----; Python 3.11.4 (main, Jun 20 2023, 17:23:00) [Clang 14.0.3 (clang-1403.0.22.14.1)]; macOS-13.5-arm64-i386-64bit; -----; Session information updated at 2023-07-26 10:47; ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453:3519,update,updated,3519,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453,1,['update'],['updated']
Deployability,""", ""louvain""],; obsm_keys=[(""X_umap"", 0), (""X_umap"", 1)]; ); louvain_colors = dict(; zip(; adata.obs[""louvain""].cat.categories, ; adata.uns[""louvain_colors""]; ); ); pts = (; ds.Canvas(1000, 1000); .points(df, ""X_umap-0"", ""X_umap-1"", agg=ds.count_cat(""louvain"")); ). # Make images; pts_ncats = (pts != 0).sum(axis=2); overlap_idx = pts_ncats == 1; zebra_source = xr.DataArray(; diagonal_bands_like(overlap_idx, 13),; coords=overlap_idx.coords; ). color_by_cluster = tf.shade(pts, color_key=louvain_colors); tf.Images(; color_by_cluster,; tf.stack(; tf.Image(xr.where(pts_ncats == 1, color_by_cluster, 0)),; tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")); ),; tf.stack(; color_by_cluster,; tf.Image(tf.shade(xr.where(pts_ncats > 1, zebra_source, False), cmap=""black"")); ),; ); ```. </details>. > I do think that randomization would result in sth similar to the datashader example you show though, except that it wouldn't change alphas by density. I wonder how either of these are effected by number of points. Say you have two cell types (A and B) in an overlapping region. ; A has 10x the representation of B in this region, but it's only 10% of the A in this dataset, while this region has all of B. What the fair way to color this? If it were random, or purely by count this would look mostly like A. > I'm not sure if doing that is so helpful as it can lead to hardly being able to see small clusters in less dense regions of the plot. I think bin size would be helpful here. Additionally [datashader has methods](https://pyviz-dev.github.io/datashader/api.html#datashader.transfer_functions.dynspread) for exaggerating points in less dense regions so they are visible. This could be worth looking into. Update: Turns out `dynspread` uses global density, not local. The spread operators could still be of help here. Also, minimum alpha values can be set. Overall, I do like that there is a sense of density with the alpha levels, and wouldn't want to miss out on it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1263#issuecomment-760657953:2817,Update,Update,2817,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263#issuecomment-760657953,1,['Update'],['Update']
Deployability,"## Xarray and anndata. Theoretically, `AnnData` objects are kind of like a special case of `xarray.Dataset`s. While `AnnData` objects have an `obs` and a `var` dimension `xarray.Dataset` can have any number of dimensions. `AnnData` objects are just specializing to the the 2d case. I think it would make a lot of sense to eventually have `anndata` and `scanpy` be based on `xarray`, or something like it. In practice there are a number of difficulties here. The biggest one is support for sparse data, and I'll briefly point out a couple others. ### Sparse arrays. I could probably rant about this for a while, since it's always a problem. Efficient processing of scRNA-seq data needs sparse matrices. The only fully featured sparse array library in python right now is `scipy.sparse`. All of it's sparse arrays only follow the `np.matrix` interface, which is deprecated. This means that they only kind-of work like arrays, and need to be special cased pretty frequently. `xarray` seems to work pretty well with a number of different array types, as long as they act like `np.ndarray`s. They have explicit support for `pydata/sparse`, but that library isn't well supported by the rest of the ecosystem, probably because it doesn't have CSR or CSC matrices yet. This leaves `xarray` with a level of sparse array support that isn't usable for us. ### Pairwise arrays and other weird behaviour. * Having an array where multiple axes have the same name doesn't work well with `xarray`. This is a problem if you're frequently using adjacency matrices like we do.; * `xarray.DataArray`s do not necessarily have the same behaviour as numpy arrays. For example, they have specific behaviour for matrix multiplication. Any transition would be much easier if `DataArrays` could be used as drop-in replacements for numpy arrays (plus some errors for misaligned data). We need to map this out more before we could make any attempt at integrating the libraries.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1030#issuecomment-608238154:1922,integrat,integrating,1922,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030#issuecomment-608238154,1,['integrat'],['integrating']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2684?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `83.33333%` with `1 line` in your changes missing coverage. Please review.; > Project coverage is 71.83%. Comparing base [(`42e3c2a`)](https://app.codecov.io/gh/scverse/scanpy/commit/42e3c2a04e2bee8431da4e831abd16d198bc8323?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`7b6a875`)](https://app.codecov.io/gh/scverse/scanpy/commit/7b6a875a75529e41e4a53993a0e04a4ad04a9d78?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 223 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/2684?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [scanpy/tools/\_umap.py](https://app.codecov.io/gh/scverse/scanpy/pull/2684?src=pr&el=tree&filepath=scanpy%2Ftools%2F_umap.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL191bWFwLnB5) | 83.33% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/2684?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2684 +/- ##; ==========================================; - Coverage 71.98% 71.83% -0.16% ; ==========================================; Files 108 108 ; Lines 11920 11921 +1 ; ==========================================; - Hits 8581 8563 -18 ; - Misses 3339 3358 +19 ; ```. | [Files with missing lines](https://a,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2684#issuecomment-1763195554:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2684#issuecomment-1763195554,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2769?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `54.23729%` with `27 lines` in your changes are missing coverage. Please review.; > Project coverage is 75.12%. Comparing base [(`6542113`)](https://app.codecov.io/gh/scverse/scanpy/commit/6542113d9e7f6a9e1a287aa940ec5564b60a247d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`1c4740e`)](https://app.codecov.io/gh/scverse/scanpy/pull/2769?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2769 +/- ##; ==========================================; - Coverage 75.24% 75.12% -0.13% ; ==========================================; Files 116 116 ; Lines 12802 12847 +45 ; ==========================================; + Hits 9633 9651 +18 ; - Misses 3169 3196 +27 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2769?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19hbm5kYXRhLnB5) | `84.98% <100.00%> (ø)` | |; | [scanpy/plotting/\_docs.py](https://app.codecov.io/gh/scverse/scanpy/pull/2769?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19kb2NzLnB5) | `100.00% <ø> (ø)` | |; | [scanpy/plotting/\_tools/\_\_init\_\_.py](https://app.codecov.i,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2769#issuecomment-1830133314:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2769#issuecomment-1830133314,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2772?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `88.88889%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 72.47%. Comparing base [(`bc349b9`)](https://app.codecov.io/gh/scverse/scanpy/commit/bc349b999be62196aa51b59db6e2daa37f428322?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`a0670c7`)](https://app.codecov.io/gh/scverse/scanpy/commit/a0670c7d3ba4db77d4016365484b79b9a6a2d522?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 143 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2772 +/- ##; ==========================================; + Coverage 72.46% 72.47% +0.01% ; ==========================================; Files 111 111 ; Lines 12418 12430 +12 ; ==========================================; + Hits 8999 9009 +10 ; - Misses 3419 3421 +2 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2772?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/2772?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_simple.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3NpbXBsZS5weQ==) | `82.29% <88.88%> (+0.02%)` | :arrow_up: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2772#issuecomment-1833851711:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2772#issuecomment-1833851711,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2856?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `96.71053%` with `5 lines` in your changes are missing coverage. Please review.; > Project coverage is 75.47%. Comparing base [(`921fcca`)](https://app.codecov.io/gh/scverse/scanpy/commit/921fccaca86ce86974ad91348498991714452bc6?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`937c6db`)](https://app.codecov.io/gh/scverse/scanpy/pull/2856?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). > :exclamation: Current head 937c6db differs from pull request most recent head b3581ea. Consider uploading reports for the commit b3581ea to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2856 +/- ##; ==========================================; + Coverage 75.25% 75.47% +0.22% ; ==========================================; Files 116 116 ; Lines 12788 12896 +108 ; ==========================================; + Hits 9623 9733 +110 ; + Misses 3165 3163 -2 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2856?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_distributed.py](https://app.codecov.io/gh/scverse/scanpy/pull/2856?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2Rpc3RyaWJ1dGVkLnB5) | `95.23% <100.00%> (-4.77%)` | :arrow_down: |; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2856?src=pr&el=tr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2856#issuecomment-1946002253:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2856#issuecomment-1946002253,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2873?src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `85.71429%` with `12 lines` in your changes are missing coverage. Please review.; > Project coverage is 74.76%. Comparing base [(`14555ba`)](https://app.codecov.io/gh/scverse/scanpy/commit/14555ba48537995acaa381b8b6ad5fc41e612510?el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`626d389`)](https://app.codecov.io/gh/scverse/scanpy/pull/2873?src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2873 +/- ##; ==========================================; - Coverage 74.82% 74.76% -0.07% ; ==========================================; Files 116 117 +1 ; Lines 12809 12893 +84 ; ==========================================; + Hits 9584 9639 +55 ; - Misses 3225 3254 +29 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2873?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2873?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19faW5pdF9fLnB5) | `100.00% <100.00%> (ø)` | |; | [scanpy/plotting/\_stacked\_barplot.py](https://app.codecov.io/gh/scverse/scanpy/pull/2873?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19zdGFja2VkX2JhcnBsb3QucHk=) | `85.54% <85.54%> (ø)` | |. ... and [8 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/287,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2873#issuecomment-1954774755:197,Patch,Patch,197,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2873#issuecomment-1954774755,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2875?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `86.66667%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.50%. Comparing base [(`4b090c0`)](https://app.codecov.io/gh/scverse/scanpy/commit/4b090c0201bdc5e79c271d988890e3ddabda7c66?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`97e4024`)](https://app.codecov.io/gh/scverse/scanpy/commit/97e402493c3ec9ecfe7bcb94071a4052871583e7?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2875 +/- ##; =======================================; Coverage 76.50% 76.50% ; =======================================; Files 109 109 ; Lines 12474 12485 +11 ; =======================================; + Hits 9543 9552 +9 ; - Misses 2931 2933 +2 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2875?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/2875?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_simple.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19zaW1wbGUucHk=) | `87.95% <ø> (ø)` | |; | [src/scanpy/tools/\_score\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2875?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_score_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#d,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2875#issuecomment-1957267440:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2875#issuecomment-1957267440,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2889?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `50.00000%` with `2 lines` in your changes are missing coverage. Please review.; > Project coverage is 73.22%. Comparing base [(`360e350`)](https://app.codecov.io/gh/scverse/scanpy/commit/360e3501460824906b0fef88c36f1d78364e6994?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`4bc1c48`)](https://app.codecov.io/gh/scverse/scanpy/pull/2889?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2889 +/- ##; ==========================================; - Coverage 74.92% 73.22% -1.71% ; ==========================================; Files 116 116 ; Lines 12802 12765 -37 ; ==========================================; - Hits 9592 9347 -245 ; - Misses 3210 3418 +208 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2889?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_leiden.py](https://app.codecov.io/gh/scverse/scanpy/pull/2889?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19sZWlkZW4ucHk=) | `88.40% <100.00%> (ø)` | |; | [scanpy/tools/\_louvain.py](https://app.codecov.io/gh/scverse/scanpy/pull/2889?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19sb3V2YWluLnB5) | `21.42% <0.00%> (ø)` | |. ... and [26 files with indirect coverage changes](https://app.codecov,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2889#issuecomment-1961959634:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2889#issuecomment-1961959634,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2907?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `82.35294%` with `3 lines` in your changes are missing coverage. Please review.; > Project coverage is 73.21%. Comparing base [(`1fee6a1`)](https://app.codecov.io/gh/scverse/scanpy/commit/1fee6a1033669db8f0d1e4ade477b861174b5722?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`45796d4`)](https://app.codecov.io/gh/scverse/scanpy/pull/2907?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2907 +/- ##; ==========================================; - Coverage 74.82% 73.21% -1.62% ; ==========================================; Files 116 116 ; Lines 12811 12763 -48 ; ==========================================; - Hits 9586 9344 -242 ; - Misses 3225 3419 +194 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2907?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2907?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L19faW5pdF9fLnB5) | `89.28% <ø> (ø)` | |; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2907?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `67.26% <ø> (-1.54%)` | :arrow_down: |; | [scanpy/\_utils/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2907#issuecomment-1992590092:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2907#issuecomment-1992590092,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2919?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `82.35294%` with `3 lines` in your changes are missing coverage. Please review.; > Project coverage is 73.22%. Comparing base [(`545b0a6`)](https://app.codecov.io/gh/scverse/scanpy/commit/545b0a6c167c9968233d16526380256ae5bd06ab?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`cc8d153`)](https://app.codecov.io/gh/scverse/scanpy/pull/2919?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on 1.10.x. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2919 +/- ##; ==========================================; - Coverage 74.82% 73.22% -1.61% ; ==========================================; Files 116 116 ; Lines 12811 12765 -46 ; ==========================================; - Hits 9586 9347 -239 ; - Misses 3225 3418 +193 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2919?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2919?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L19faW5pdF9fLnB5) | `89.28% <ø> (ø)` | |; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2919?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `67.26% <ø> (-1.54%)` | :arrow_down: |; | [scanpy/\_ut,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2919#issuecomment-1997461129:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2919#issuecomment-1997461129,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2923?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `78.57143%` with `3 lines` in your changes are missing coverage. Please review.; > Project coverage is 74.92%. Comparing base [(`b132f11`)](https://app.codecov.io/gh/scverse/scanpy/commit/b132f115385f1a917f3201dfcbf1f36dfa03235b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`2632d44`)](https://app.codecov.io/gh/scverse/scanpy/pull/2923?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2923 +/- ##; ==========================================; - Coverage 74.92% 74.92% -0.01% ; ==========================================; Files 116 116 ; Lines 12802 12812 +10 ; ==========================================; + Hits 9592 9599 +7 ; - Misses 3210 3213 +3 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2923?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_normalization.py](https://app.codecov.io/gh/scverse/scanpy/pull/2923?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX25vcm1hbGl6YXRpb24ucHk=) | `86.95% <78.57%> (-2.07%)` | :arrow_down: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2923#issuecomment-2003898907:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2923#issuecomment-2003898907,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2942?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `87.70492%` with `15 lines` in your changes are missing coverage. Please review.; > Project coverage is 75.51%. Comparing base [(`c68557c`)](https://app.codecov.io/gh/scverse/scanpy/commit/c68557c5ba05484b1c2fc0c0fe9489affecdc318?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`35dd438`)](https://app.codecov.io/gh/scverse/scanpy/pull/2942?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2942 +/- ##; ==========================================; + Coverage 75.49% 75.51% +0.02% ; ==========================================; Files 116 117 +1 ; Lines 12911 12955 +44 ; ==========================================; + Hits 9747 9783 +36 ; - Misses 3164 3172 +8 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2942?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2942?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX19pbml0X18ucHk=) | `100.00% <100.00%> (ø)` | |; | [scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/2942?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_simple.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campai,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2942#issuecomment-2014865366:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2942#issuecomment-2014865366,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2943?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `25.00000%` with `3 lines` in your changes are missing coverage. Please review.; > Project coverage is 75.25%. Comparing base [(`6542113`)](https://app.codecov.io/gh/scverse/scanpy/commit/6542113d9e7f6a9e1a287aa940ec5564b60a247d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`e5d904e`)](https://app.codecov.io/gh/scverse/scanpy/pull/2943?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2943 +/- ##; =======================================; Coverage 75.24% 75.25% ; =======================================; Files 116 116 ; Lines 12802 12788 -14 ; =======================================; - Hits 9633 9623 -10 ; + Misses 3169 3165 -4 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2943?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2943?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `68.70% <ø> (-0.10%)` | :arrow_down: |; | [scanpy/tools/\_paga.py](https://app.codecov.io/gh/scverse/scanpy/pull/2943?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19wYWdhLnB5) | `33.33% <25.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2943#issuecomment-2015047081:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2943#issuecomment-2015047081,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2944?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `25.00000%` with `3 lines` in your changes are missing coverage. Please review.; > Project coverage is 75.25%. Comparing base [(`7c1e4cc`)](https://app.codecov.io/gh/scverse/scanpy/commit/7c1e4cc6c1a076d5eaaee7702d5172425b30d7be?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`d9b42b3`)](https://app.codecov.io/gh/scverse/scanpy/pull/2944?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2944 +/- ##; =======================================; Coverage 75.24% 75.25% ; =======================================; Files 116 116 ; Lines 12802 12788 -14 ; =======================================; - Hits 9633 9623 -10 ; + Misses 3169 3165 -4 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2944?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2944?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `68.70% <ø> (-0.10%)` | :arrow_down: |; | [scanpy/tools/\_paga.py](https://app.codecov.io/gh/scverse/scanpy/pull/2944?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19wYWdhLnB5) | `33.33% <25.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2944#issuecomment-2015166004:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2944#issuecomment-2015166004,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2947?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `96.71053%` with `5 lines` in your changes are missing coverage. Please review.; > Project coverage is 75.46%. Comparing base [(`7c1e4cc`)](https://app.codecov.io/gh/scverse/scanpy/commit/7c1e4cc6c1a076d5eaaee7702d5172425b30d7be?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`6f32147`)](https://app.codecov.io/gh/scverse/scanpy/pull/2947?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2947 +/- ##; ==========================================; + Coverage 75.24% 75.46% +0.22% ; ==========================================; Files 116 116 ; Lines 12802 12910 +108 ; ==========================================; + Hits 9633 9743 +110 ; + Misses 3169 3167 -2 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2947?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_distributed.py](https://app.codecov.io/gh/scverse/scanpy/pull/2947?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2Rpc3RyaWJ1dGVkLnB5) | `95.23% <100.00%> (-4.77%)` | :arrow_down: |; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/2947?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2hpZ2hseV92YXJpYWJsZV9nZW5lcy5,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2947#issuecomment-2015480720:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2947#issuecomment-2015480720,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2950?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `90.00000%` with `1 lines` in your changes are missing coverage. Please review.; > Project coverage is 73.14%. Comparing base [(`e6c7251`)](https://app.codecov.io/gh/scverse/scanpy/commit/e6c7251d66eae3983baad37575a6b0bba8fe1318?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`3633712`)](https://app.codecov.io/gh/scverse/scanpy/pull/2950?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2950 +/- ##; ==========================================; - Coverage 75.48% 73.14% -2.35% ; ==========================================; Files 116 116 ; Lines 12904 12872 -32 ; ==========================================; - Hits 9741 9415 -326 ; - Misses 3163 3457 +294 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2950?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/get/\_aggregated.py](https://app.codecov.io/gh/scverse/scanpy/pull/2950?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2dldC9fYWdncmVnYXRlZC5weQ==) | `94.73% <90.00%> (-0.62%)` | :arrow_down: |. ... and [27 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2950/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2950#issuecomment-2017705266:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2950#issuecomment-2017705266,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2952?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `90.00000%` with `1 lines` in your changes are missing coverage. Please review.; > Project coverage is 75.29%. Comparing base [(`60a0042`)](https://app.codecov.io/gh/scverse/scanpy/commit/60a0042a0d372273d47446aad463332f7664ebe4?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`9322058`)](https://app.codecov.io/gh/scverse/scanpy/pull/2952?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2952 +/- ##; ==========================================; - Coverage 75.48% 75.29% -0.20% ; ==========================================; Files 116 116 ; Lines 12904 12908 +4 ; ==========================================; - Hits 9741 9719 -22 ; - Misses 3163 3189 +26 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2952?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/get/\_aggregated.py](https://app.codecov.io/gh/scverse/scanpy/pull/2952?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2dldC9fYWdncmVnYXRlZC5weQ==) | `94.73% <90.00%> (-0.62%)` | :arrow_down: |. ... and [10 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/2952/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2952#issuecomment-2017783436:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2952#issuecomment-2017783436,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2977?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `85.71429%` with `1 lines` in your changes are missing coverage. Please review.; > Project coverage is 75.53%. Comparing base [(`4f6e690`)](https://app.codecov.io/gh/scverse/scanpy/commit/4f6e69005547647da24f8e212474f27f54f5da89?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`7378b49`)](https://app.codecov.io/gh/scverse/scanpy/pull/2977?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2977 +/- ##; ==========================================; + Coverage 75.52% 75.53% +0.01% ; ==========================================; Files 117 117 ; Lines 12951 12950 -1 ; ==========================================; + Hits 9781 9782 +1 ; + Misses 3170 3168 -2 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2977?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_leiden.py](https://app.codecov.io/gh/scverse/scanpy/pull/2977?src=pr&el=tree&filepath=scanpy%2Ftools%2F_leiden.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19sZWlkZW4ucHk=) | `89.55% <100.00%> (+0.98%)` | :arrow_up: |; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2977?src=pr&el=tree&filepath=scanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) |,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2977#issuecomment-2035081129:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2977#issuecomment-2035081129,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2980?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `97.56098%` with `1 line` in your changes missing coverage. Please review.; > Project coverage is 75.54%. Comparing base [(`896e249`)](https://app.codecov.io/gh/scverse/scanpy/commit/896e24906edd8a6f03c97c590838ca20b3f1d127?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`7eb31ff`)](https://app.codecov.io/gh/scverse/scanpy/commit/7eb31ffaa94b8d997d77312378e4cc31ecdbc23f?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). > :exclamation: **Current head 7eb31ff differs from pull request most recent head d58e083**; > ; > Please [upload](https://docs.codecov.com/docs/codecov-uploader) reports for the commit d58e083 to get more accurate results. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2980 +/- ##; ==========================================; - Coverage 76.31% 75.54% -0.77% ; ==========================================; Files 109 117 +8 ; Lines 12513 12971 +458 ; ==========================================; + Hits 9549 9799 +250 ; - Misses 2964 3172 +208 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2980?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2980?src=pr&el=tree&filepath=scanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `74.84% <100.00%> (ø)` | |; | [scanpy/experimental/pp/\_n,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2980#issuecomment-2039521442:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2980#issuecomment-2039521442,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2985?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `81.96721%` with `22 lines` in your changes are missing coverage. Please review.; > Project coverage is 73.17%. Comparing base [(`99cc32f`)](https://app.codecov.io/gh/scverse/scanpy/commit/99cc32fb75a22fa708ba24a5a410683df9a45c35?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`4042018`)](https://app.codecov.io/gh/scverse/scanpy/pull/2985?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #2985 +/- ##; ==========================================; - Coverage 75.49% 73.17% -2.32% ; ==========================================; Files 116 117 +1 ; Lines 12911 12919 +8 ; ==========================================; - Hits 9747 9454 -293 ; - Misses 3164 3465 +301 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2985?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/2985?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX19pbml0X18ucHk=) | `100.00% <100.00%> (ø)` | |; | [scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/2985?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_simple.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2N,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2985#issuecomment-2042583820:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2985#issuecomment-2042583820,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2992?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `40.00000%` with `3 lines` in your changes are missing coverage. Please review.; > Project coverage is 75.49%. Comparing base [(`9c8c095`)](https://app.codecov.io/gh/scverse/scanpy/commit/9c8c095daa6e411e73845ccca99d2c5171b3f059?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`8e23732`)](https://app.codecov.io/gh/scverse/scanpy/pull/2992?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2992 +/- ##; ==========================================; - Coverage 75.51% 75.49% -0.02% ; ==========================================; Files 117 117 ; Lines 12955 12959 +4 ; ==========================================; + Hits 9783 9784 +1 ; - Misses 3172 3175 +3 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2992?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/readwrite.py](https://app.codecov.io/gh/scverse/scanpy/pull/2992?src=pr&el=tree&filepath=scanpy%2Freadwrite.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3JlYWR3cml0ZS5weQ==) | `67.72% <40.00%> (-0.43%)` | :arrow_down: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2992#issuecomment-2045167705:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992#issuecomment-2045167705,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/2998?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `48.71795%` with `20 lines` in your changes are missing coverage. Please review.; > Project coverage is 75.43%. Comparing base [(`10f4ebc`)](https://app.codecov.io/gh/scverse/scanpy/commit/10f4ebc7c0ee834897ce8586ffe717e80f78ba58?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`06c93dc`)](https://app.codecov.io/gh/scverse/scanpy/pull/2998?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #2998 +/- ##; ==========================================; - Coverage 75.52% 75.43% -0.09% ; ==========================================; Files 117 117 ; Lines 12951 12986 +35 ; ==========================================; + Hits 9781 9796 +15 ; - Misses 3170 3190 +20 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/2998?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_tools/scatterplots.py](https://app.codecov.io/gh/scverse/scanpy/pull/2998?src=pr&el=tree&filepath=scanpy%2Fplotting%2F_tools%2Fscatterplots.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL190b29scy9zY2F0dGVycGxvdHMucHk=) | `83.29% <48.71%> (-3.19%)` | :arrow_down: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2998#issuecomment-2047370580:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998#issuecomment-2047370580,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3017?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `85.71429%` with `1 line` in your changes missing coverage. Please review.; > Project coverage is 75.86%. Comparing base [(`3ba3f46`)](https://app.codecov.io/gh/scverse/scanpy/commit/3ba3f46b4e6e77e8c6f0551db9663822097b486a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`277c1bf`)](https://app.codecov.io/gh/scverse/scanpy/commit/277c1bfb0885234aa757d0fdaeaa9103eb8568e2?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 47 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3017?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3017?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_highly_variable_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2hpZ2hseV92YXJpYWJsZV9nZW5lcy5weQ==) | 85.71% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3017?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3017 +/- ##; ==========================================; - Coverage 75.87% 75.86% -0.01% ; ==========================================; Files 110 110 ; Lines 12533 12533 ; ==========================================; - Hits ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3017#issuecomment-2069245430:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017#issuecomment-2069245430,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3031?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `69.23077%` with `4 lines` in your changes are missing coverage. Please review.; > Project coverage is 76.27%. Comparing base [(`d2a5368`)](https://app.codecov.io/gh/scverse/scanpy/commit/d2a53680e312835b998077b4e25b254e98bcb5ba?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`69f9781`)](https://app.codecov.io/gh/scverse/scanpy/pull/3031?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3031 +/- ##; ==========================================; - Coverage 76.27% 76.27% -0.01% ; ==========================================; Files 117 117 ; Lines 12799 12803 +4 ; ==========================================; + Hits 9763 9766 +3 ; - Misses 3036 3037 +1 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3031?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3031?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_highly_variable_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2hpZ2hseV92YXJpYWJsZV9nZW5lcy5weQ==) | `95.60% <100.00%> (ø)` | |; | [scanpy/preprocessing/\_scrublet/core.py](https://app.codecov.io/gh/scverse/scanpy/pull/3031?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_scrublet%2Fcore.py&utm_medium=referral&utm_source=github&utm_content=commen,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3031#issuecomment-2079044440:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3031#issuecomment-2079044440,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3038?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `0%` with `3 lines` in your changes are missing coverage. Please review.; > Project coverage is 73.90%. Comparing base [(`a008ab8`)](https://app.codecov.io/gh/scverse/scanpy/commit/a008ab812602abe805740c394e8f802ab56f101a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`3b0e501`)](https://app.codecov.io/gh/scverse/scanpy/pull/3038?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3038 +/- ##; ==========================================; - Coverage 76.27% 73.90% -2.38% ; ==========================================; Files 117 117 ; Lines 12795 12759 -36 ; ==========================================; - Hits 9760 9430 -330 ; - Misses 3035 3329 +294 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3038?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_scrublet.py](https://app.codecov.io/gh/scverse/scanpy/pull/3038?src=pr&el=tree&filepath=scanpy%2Fplotting%2F_scrublet.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19zY3J1YmxldC5weQ==) | `23.52% <0.00%> (-70.59%)` | :arrow_down: |; | [scanpy/external/exporting.py](https://app.codecov.io/gh/scverse/scanpy/pull/3038?src=pr&el=tree&filepath=scanpy%2Fexternal%2Fexporting.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3038#issuecomment-2083379495:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3038#issuecomment-2083379495,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3039?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `33.33333%` with `2 lines` in your changes are missing coverage. Please review.; > Project coverage is 76.27%. Comparing base [(`cf99920`)](https://app.codecov.io/gh/scverse/scanpy/commit/cf999200f7dab9983d2c52821534def4b7ed6ea1?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`d228a87`)](https://app.codecov.io/gh/scverse/scanpy/pull/3039?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3039 +/- ##; =======================================; Coverage 76.27% 76.27% ; =======================================; Files 117 117 ; Lines 12795 12795 ; =======================================; Hits 9760 9760 ; Misses 3035 3035 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3039?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_scrublet.py](https://app.codecov.io/gh/scverse/scanpy/pull/3039?src=pr&el=tree&filepath=scanpy%2Fplotting%2F_scrublet.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19zY3J1YmxldC5weQ==) | `94.11% <100.00%> (ø)` | |; | [scanpy/external/exporting.py](https://app.codecov.io/gh/scverse/scanpy/pull/3039?src=pr&el=tree&filepath=scanpy%2Fexternal%2Fexporting.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL2V4cG9ydGluZy5weQ==) | `13.44% <0.00%> (ø)` ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3039#issuecomment-2084689348:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3039#issuecomment-2084689348,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3043?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `47.72727%` with `23 lines` in your changes are missing coverage. Please review.; > Project coverage is 76.18%. Comparing base [(`0d4554b`)](https://app.codecov.io/gh/scverse/scanpy/commit/0d4554b44e301c9c1e78e80e21b5e4a6642e156a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`efcf8df`)](https://app.codecov.io/gh/scverse/scanpy/pull/3043?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3043 +/- ##; ==========================================; - Coverage 76.27% 76.18% -0.10% ; ==========================================; Files 117 117 ; Lines 12795 12838 +43 ; ==========================================; + Hits 9760 9780 +20 ; - Misses 3035 3058 +23 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3043?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/plotting/\_baseplot\_class.py](https://app.codecov.io/gh/scverse/scanpy/pull/3043?src=pr&el=tree&filepath=scanpy%2Fplotting%2F_baseplot_class.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Bsb3R0aW5nL19iYXNlcGxvdF9jbGFzcy5weQ==) | `85.21% <47.72%> (-4.68%)` | :arrow_down: |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3043#issuecomment-2091092171:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3043#issuecomment-2091092171,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3044?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `89.47368%` with `2 lines` in your changes are missing coverage. Please review.; > Project coverage is 76.28%. Comparing base [(`c26480e`)](https://app.codecov.io/gh/scverse/scanpy/commit/c26480ed0dc2f7d27b796e0e355b29a8305886c6?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`57732d0`)](https://app.codecov.io/gh/scverse/scanpy/pull/3044?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3044 +/- ##; =======================================; Coverage 76.27% 76.28% ; =======================================; Files 117 117 ; Lines 12803 12802 -1 ; =======================================; Hits 9766 9766 ; + Misses 3037 3036 -1 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3044?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_scrublet/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3044?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_scrublet%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3NjcnVibGV0L19faW5pdF9fLnB5) | `96.80% <100.00%> (+0.10%)` | :arrow_up: |; | [scanpy/preprocessing/\_scrublet/pipeline.py](https://app.codecov.io/gh/scverse/scanpy/pull/3044?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_scrublet%2Fpipeline.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campa,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3044#issuecomment-2096282888:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044#issuecomment-2096282888,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3047?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `76.47059%` with `8 lines` in your changes are missing coverage. Please review.; > Project coverage is 73.90%. Comparing base [(`9714250`)](https://app.codecov.io/gh/scverse/scanpy/commit/971425046f3f0411ea77a13939be208526e0c9eb?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`d314182`)](https://app.codecov.io/gh/scverse/scanpy/pull/3047?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3047 +/- ##; ==========================================; - Coverage 73.98% 73.90% -0.08% ; ==========================================; Files 117 117 ; Lines 12795 12763 -32 ; ==========================================; - Hits 9466 9433 -33 ; - Misses 3329 3330 +1 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3047?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3047?src=pr&el=tree&filepath=scanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `66.66% <100.00%> (ø)` | |; | [scanpy/datasets/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3047?src=pr&el=tree&filepath=scanpy%2Fdatasets%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2RhdGFzZXRzL191dGlscy5weQ==) | `100.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3047#issuecomment-2097731381:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3047#issuecomment-2097731381,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3050?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `82.35294%` with `6 lines` in your changes are missing coverage. Please review.; > Project coverage is 76.27%. Comparing base [(`6b00ea3`)](https://app.codecov.io/gh/scverse/scanpy/commit/6b00ea3b8c436b84ff64662054226381473850a5?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`7e0aae1`)](https://app.codecov.io/gh/scverse/scanpy/pull/3050?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3050 +/- ##; ==========================================; - Coverage 76.27% 76.27% -0.01% ; ==========================================; Files 117 117 ; Lines 12795 12799 +4 ; ==========================================; + Hits 9760 9763 +3 ; - Misses 3035 3036 +1 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3050?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3050?src=pr&el=tree&filepath=scanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L191dGlscy9fX2luaXRfXy5weQ==) | `74.94% <100.00%> (ø)` | |; | [scanpy/datasets/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3050?src=pr&el=tree&filepath=scanpy%2Fdatasets%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2RhdGFzZXRzL191dGlscy5weQ==) | `100.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3050#issuecomment-2104675113:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3050#issuecomment-2104675113,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3056?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `69.23077%` with `4 lines` in your changes are missing coverage. Please review.; > Project coverage is 76.27%. Comparing base [(`19a0bb8`)](https://app.codecov.io/gh/scverse/scanpy/commit/19a0bb8fd3601c3b39e242ff6419fb73e59cf67a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`0e14441`)](https://app.codecov.io/gh/scverse/scanpy/pull/3056?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3056 +/- ##; ==========================================; - Coverage 76.27% 76.27% -0.01% ; ==========================================; Files 117 117 ; Lines 12799 12803 +4 ; ==========================================; + Hits 9763 9766 +3 ; - Misses 3036 3037 +1 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3056?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3056?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_highly_variable_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2hpZ2hseV92YXJpYWJsZV9nZW5lcy5weQ==) | `95.60% <100.00%> (ø)` | |; | [scanpy/preprocessing/\_scrublet/core.py](https://app.codecov.io/gh/scverse/scanpy/pull/3056?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_scrublet%2Fcore.py&utm_medium=referral&utm_source=github&utm_content=comm,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3056#issuecomment-2109792074:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3056#issuecomment-2109792074,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3058?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `89.47368%` with `2 lines` in your changes are missing coverage. Please review.; > Project coverage is 76.08%. Comparing base [(`dea050f`)](https://app.codecov.io/gh/scverse/scanpy/commit/dea050f63f252d73f4716145e8a166f6ffc043dd?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`968b5f1`)](https://app.codecov.io/gh/scverse/scanpy/pull/3058?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3058 +/- ##; ==========================================; - Coverage 76.27% 76.08% -0.20% ; ==========================================; Files 117 117 ; Lines 12803 12802 -1 ; ==========================================; - Hits 9766 9740 -26 ; - Misses 3037 3062 +25 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3058?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/preprocessing/\_scrublet/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3058?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_scrublet%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX3NjcnVibGV0L19faW5pdF9fLnB5) | `96.80% <100.00%> (+0.10%)` | :arrow_up: |; | [scanpy/preprocessing/\_scrublet/pipeline.py](https://app.codecov.io/gh/scverse/scanpy/pull/3058?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_scrublet%2Fpipeline.py&utm_medium=referral&utm_source=github&ut,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3058#issuecomment-2110286934:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3058#issuecomment-2110286934,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3061?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `66.66667%` with `1 lines` in your changes are missing coverage. Please review.; > Project coverage is 75.19%. Comparing base [(`3ba3f46`)](https://app.codecov.io/gh/scverse/scanpy/commit/3ba3f46b4e6e77e8c6f0551db9663822097b486a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`d8d4763`)](https://app.codecov.io/gh/scverse/scanpy/pull/3061?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3061 +/- ##; ==========================================; - Coverage 75.87% 75.19% -0.68% ; ==========================================; Files 110 110 ; Lines 12533 12536 +3 ; ==========================================; - Hits 9509 9427 -82 ; - Misses 3024 3109 +85 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3061?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [scanpy/tools/\_tsne.py](https://app.codecov.io/gh/scverse/scanpy/pull/3061?src=pr&el=tree&filepath=scanpy%2Ftools%2F_tsne.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL190c25lLnB5) | `68.08% <66.66%> (-25.10%)` | :arrow_down: |. ... and [5 files with indirect coverage changes](https://app.codecov.io/gh/scverse/scanpy/pull/3061/indirect-changes?src=pr&el=tree-more&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3061#issuecomment-2110890545:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061#issuecomment-2110890545,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3082?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `85.71429%` with `1 line` in your changes missing coverage. Please review.; > Project coverage is 75.80%. Comparing base [(`b3b9d05`)](https://app.codecov.io/gh/scverse/scanpy/commit/b3b9d0576897a8da5a4ae765b4b0b5609cebc890?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`2709e08`)](https://app.codecov.io/gh/scverse/scanpy/commit/2709e08fe39d3440c904b3cfcb1913611d9bc672?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 39 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3082?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3082?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_highly_variable_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2hpZ2hseV92YXJpYWJsZV9nZW5lcy5weQ==) | 85.71% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3082?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3082 +/- ##; =======================================; Coverage 75.80% 75.80% ; =======================================; Files 110 110 ; Lines 12500 12501 +1 ; =======================================; + Hits 9475 9476 +,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3082#issuecomment-2141612509:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3082#issuecomment-2141612509,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3084?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `62.50000%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 75.85%. Comparing base [(`5dc489d`)](https://app.codecov.io/gh/scverse/scanpy/commit/5dc489d5c71fa91fd0cabe6adb363172119ce5eb?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`6ba3676`)](https://app.codecov.io/gh/scverse/scanpy/commit/6ba36767cbb6fe59524c1ac54347b3a36de41a28?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 46 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3084?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [scanpy/external/exporting.py](https://app.codecov.io/gh/scverse/scanpy/pull/3084?src=pr&el=tree&filepath=scanpy%2Fexternal%2Fexporting.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL2V4cG9ydGluZy5weQ==) | 0.00% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3084?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [scanpy/preprocessing/\_combat.py](https://app.codecov.io/gh/scverse/scanpy/pull/3084?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_combat.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2NvbWJhdC5weQ==) | 0.00% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3084?src=pr&e,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3084#issuecomment-2141838152:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3084#issuecomment-2141838152,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3088?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `66.66667%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 78.58%. Comparing base [(`698313b`)](https://app.codecov.io/gh/scverse/scanpy/commit/698313b5f38ed726c5b8093c155482d1bfdaf4bc?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`63253ab`)](https://app.codecov.io/gh/scverse/scanpy/commit/63253ab59f2799350c43631bf4033362d3f913bb?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 42 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3088?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [scanpy/external/exporting.py](https://app.codecov.io/gh/scverse/scanpy/pull/3088?src=pr&el=tree&filepath=scanpy%2Fexternal%2Fexporting.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL2V4cG9ydGluZy5weQ==) | 0.00% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3088?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [scanpy/preprocessing/\_combat.py](https://app.codecov.io/gh/scverse/scanpy/pull/3088?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_combat.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2NvbWJhdC5weQ==) | 0.00% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3088?src=pr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3088#issuecomment-2144755688:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3088#issuecomment-2144755688,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3097?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `79.16667%` with `5 lines` in your changes missing coverage. Please review.; > Project coverage is 76.35%. Comparing base [(`4f40d68`)](https://app.codecov.io/gh/scverse/scanpy/commit/4f40d68c8958ef74fd8abe5f97601c40ffee9337?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`e89ebac`)](https://app.codecov.io/gh/scverse/scanpy/commit/e89ebaceddc37589fe22bfe32b1e8a9f1b5746f9?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 41 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3097?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [scanpy/tools/\_score\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3097?src=pr&el=tree&filepath=scanpy%2Ftools%2F_score_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19zY29yZV9nZW5lcy5weQ==) | 82.35% | [3 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3097?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [scanpy/get/get.py](https://app.codecov.io/gh/scverse/scanpy/pull/3097?src=pr&el=tree&filepath=scanpy%2Fget%2Fget.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2dldC9nZXQucHk=) | 66.66% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3097?src=pr&el=tree&utm_medium=referral&utm_source=github&,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3097#issuecomment-2147774048:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3097#issuecomment-2147774048,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3098?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `79.16667%` with `5 lines` in your changes missing coverage. Please review.; > Project coverage is 76.35%. Comparing base [(`d34e575`)](https://app.codecov.io/gh/scverse/scanpy/commit/d34e5756aa6a6f763e06d48c060efdd0a94fa468?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`a01cf79`)](https://app.codecov.io/gh/scverse/scanpy/commit/a01cf79bf6dc5809357d037d17bece02d92616f5?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 35 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3098?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [scanpy/tools/\_score\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3098?src=pr&el=tree&filepath=scanpy%2Ftools%2F_score_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3Rvb2xzL19zY29yZV9nZW5lcy5weQ==) | 82.35% | [3 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3098?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [scanpy/get/get.py](https://app.codecov.io/gh/scverse/scanpy/pull/3098?src=pr&el=tree&filepath=scanpy%2Fget%2Fget.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2dldC9nZXQucHk=) | 66.66% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3098?src=pr&el=tree&utm_medium=referral&utm_source=githu,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3098#issuecomment-2147840847:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3098#issuecomment-2147840847,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3115?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `57.14286%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 76.50%. Comparing base [(`8d9a5f0`)](https://app.codecov.io/gh/scverse/scanpy/commit/8d9a5f0d2b303abeb42f7e4c9252d505000fd05c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`8fb2a0e`)](https://app.codecov.io/gh/scverse/scanpy/commit/8fb2a0eac8778931a22d70c16e76b9f516f9ef78?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 48 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3115?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/\_utils/compute/is\_constant.py](https://app.codecov.io/gh/scverse/scanpy/pull/3115?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2Fcompute%2Fis_constant.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvY29tcHV0ZS9pc19jb25zdGFudC5weQ==) | 25.00% | [3 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3115?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3115 +/- ##; ==========================================; + Coverage 76.31% 76.50% +0.18% ; ==========================================; Files 109 109 ; Lines 12515 12474 -41 ; ==========================================; - Hits 9551 9543 -8,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3115#issuecomment-2181074546:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115#issuecomment-2181074546,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3134?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `57.14286%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 76.50%. Comparing base [(`a5eadd5`)](https://app.codecov.io/gh/scverse/scanpy/commit/a5eadd5b723799105d724b5e9f80b711e0be87ca?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`25f0c97`)](https://app.codecov.io/gh/scverse/scanpy/commit/25f0c97e81e9143bece1ded7c4838964ed7d3866?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 43 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3134?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/\_utils/compute/is\_constant.py](https://app.codecov.io/gh/scverse/scanpy/pull/3134?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2Fcompute%2Fis_constant.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvY29tcHV0ZS9pc19jb25zdGFudC5weQ==) | 25.00% | [3 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3134?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3134 +/- ##; ==========================================; + Coverage 76.31% 76.50% +0.18% ; ==========================================; Files 109 109 ; Lines 12515 12474 -41 ; ==========================================; - Hits 9551 954,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3134#issuecomment-2202709708:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3134#issuecomment-2202709708,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3138?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `0%` with `1 line` in your changes missing coverage. Please review.; > Project coverage is 76.52%. Comparing base [(`208115d`)](https://app.codecov.io/gh/scverse/scanpy/commit/208115dd78046af3258da3a756f36dda34e5aba8?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`4ed4477`)](https://app.codecov.io/gh/scverse/scanpy/commit/4ed4477c4f000703aa42f22e4c8f5930e21eab9b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3138 +/- ##; =======================================; Coverage 76.52% 76.52% ; =======================================; Files 109 109 ; Lines 12483 12483 ; =======================================; Hits 9553 9553 ; Misses 2930 2930 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3138?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/tools/\_score\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3138?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_score_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fc2NvcmVfZ2VuZXMucHk=) | `85.10% <0.00%> (ø)` | |. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3138#issuecomment-2204452117:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3138#issuecomment-2204452117,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3142?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `86.66667%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.50%. Comparing base [(`e6e5328`)](https://app.codecov.io/gh/scverse/scanpy/commit/e6e532804a9c087ea37808f26395aa9ed038d6cb?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`a37840f`)](https://app.codecov.io/gh/scverse/scanpy/commit/a37840f6d72e7b3ad980c6603c310f2e5e2305c0?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 43 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3142?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/tools/\_score\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3142?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_score_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fc2NvcmVfZ2VuZXMucHk=) | 86.66% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3142?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3142 +/- ##; =======================================; Coverage 76.50% 76.50% ; =======================================; Files 109 109 ; Lines 12474 12485 +11 ; =======================================; + Hits 9543 9552 +9 ; - Misses 2931 2933 +2 ; ```. | [Files wit,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3142#issuecomment-2209117430:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3142#issuecomment-2209117430,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3181?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `50.00000%` with `1 line` in your changes missing coverage. Please review.; > Project coverage is 76.54%. Comparing base [(`d3de744`)](https://app.codecov.io/gh/scverse/scanpy/commit/d3de7442615eb89999abb741ad28825688199de3?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`d6be2f5`)](https://app.codecov.io/gh/scverse/scanpy/commit/d6be2f5157d48deaefff8f1d97ca4715bba466b4?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3181 +/- ##; =======================================; Coverage 76.54% 76.54% ; =======================================; Files 109 109 ; Lines 12490 12490 ; =======================================; Hits 9560 9560 ; Misses 2930 2930 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3181?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Coverage Δ | |; |---|---|---|; | [src/scanpy/plotting/\_tools/scatterplots.py](https://app.codecov.io/gh/scverse/scanpy/pull/3181?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_tools%2Fscatterplots.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fdG9vbHMvc2NhdHRlcnBsb3RzLnB5) | `86.99% <ø> (ø)` | |; | [src/scanpy/plotting/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3181?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3181#issuecomment-2261315786:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3181#issuecomment-2261315786,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3182?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `94.33962%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 76.58%. Comparing base [(`d3de744`)](https://app.codecov.io/gh/scverse/scanpy/commit/d3de7442615eb89999abb741ad28825688199de3?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`6c895e8`)](https://app.codecov.io/gh/scverse/scanpy/commit/6c895e8b0e3ecef999924d1c3998b19affe10d8d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 52 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3182?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/tools/\_umap.py](https://app.codecov.io/gh/scverse/scanpy/pull/3182?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_umap.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fdW1hcC5weQ==) | 66.66% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3182?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3182?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvX19pbml0X18ucHk=) | 93.33% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3182?src=pr&el=tree&,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3182#issuecomment-2446491018:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3182#issuecomment-2446491018,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3185?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `94.33962%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 74.06%. Comparing base [(`bcae3fe`)](https://app.codecov.io/gh/scverse/scanpy/commit/bcae3fe77aabcd7f8eb334d868786620cef6fbd8?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`17c5c11`)](https://app.codecov.io/gh/scverse/scanpy/commit/17c5c1110bb6d7fdafed36e452558179ee84d957?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3185?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/tools/\_umap.py](https://app.codecov.io/gh/scverse/scanpy/pull/3185?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_umap.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fdW1hcC5weQ==) | 66.66% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3185?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3185?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvX19pbml0X18ucHk=) | 93.33% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3185?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_ca,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3185#issuecomment-2262723609:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3185#issuecomment-2262723609,2,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3191?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `66.66667%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.61%. Comparing base [(`243a46e`)](https://app.codecov.io/gh/scverse/scanpy/commit/243a46e674f97f04c835893320dfd21543f89827?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`deb9f38`)](https://app.codecov.io/gh/scverse/scanpy/commit/deb9f3876ec6848562b1f5f3e5ce9f9a8551eead?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 49 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3191?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/get/get.py](https://app.codecov.io/gh/scverse/scanpy/pull/3191?src=pr&el=tree&filepath=src%2Fscanpy%2Fget%2Fget.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9nZXQvZ2V0LnB5) | 0.00% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3191?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3191 +/- ##; ==========================================; - Coverage 76.61% 76.61% -0.01% ; ==========================================; Files 109 109 ; Lines 12529 12532 +3 ; ==========================================; + Hits 9599 9601 +2 ; - Misses 2930 2931 +1 ; ```. | [Files with missing lines](https://app,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3191#issuecomment-2263391738:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3191#issuecomment-2263391738,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3192?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `66.66667%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.61%. Comparing base [(`a60a96f`)](https://app.codecov.io/gh/scverse/scanpy/commit/a60a96fb7790e35abe8d007abd6f5a17b1573d7d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`fca69e6`)](https://app.codecov.io/gh/scverse/scanpy/commit/fca69e6d08e90f86c01a033fa4c8749cc2cb4ea3?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 43 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3192?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/get/get.py](https://app.codecov.io/gh/scverse/scanpy/pull/3192?src=pr&el=tree&filepath=src%2Fscanpy%2Fget%2Fget.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9nZXQvZ2V0LnB5) | 0.00% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3192?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3192 +/- ##; ==========================================; - Coverage 76.61% 76.61% -0.01% ; ==========================================; Files 109 109 ; Lines 12529 12532 +3 ; ==========================================; + Hits 9599 9601 +2 ; - Misses 2930 2931 +1 ; ```. | [Files with missing lines](https:/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3192#issuecomment-2263491216:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3192#issuecomment-2263491216,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3204?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `86.66667%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 74.10%. Comparing base [(`c6766d7`)](https://app.codecov.io/gh/scverse/scanpy/commit/c6766d758b83410e9167578d22054f712d5bca4b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`3a9b3f6`)](https://app.codecov.io/gh/scverse/scanpy/commit/3a9b3f6f3d463704495aca6ed6353bbf5eca87a1?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3204?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/tools/\_dendrogram.py](https://app.codecov.io/gh/scverse/scanpy/pull/3204?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_dendrogram.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fZGVuZHJvZ3JhbS5weQ==) | 83.33% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3204?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3204 +/- ##; ==========================================; - Coverage 76.63% 74.10% -2.54% ; ==========================================; Files 109 109 ; Lines 12533 12537 +4 ; ==========================================; - Hits 9605 9290 -315 ; - Misses 2928 3247 +319 ; ```. | [Files](https://app.codecov.io/gh/scverse/scanpy/pull/3204?d,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3204#issuecomment-2277865200:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3204#issuecomment-2277865200,2,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3209?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `95.08197%` with `12 lines` in your changes missing coverage. Please review.; > Project coverage is 76.69%. Comparing base [(`7ae1216`)](https://app.codecov.io/gh/scverse/scanpy/commit/7ae12167f582935a8c6f9c06fff9cda99a4eedc6?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`297ed30`)](https://app.codecov.io/gh/scverse/scanpy/commit/297ed3070eaa2d67e0a1ceeed9b9b3cf74345061?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3209?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/plotting/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3209?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fdXRpbHMucHk=) | 86.48% | [5 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3209?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/plotting/\_baseplot\_class.py](https://app.codecov.io/gh/scverse/scanpy/pull/3209?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_baseplot_class.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fYmFzZXBsb3RfY2xhc3MucHk=) | 95.50% | [4 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3209?src=pr&el=tree&utm_m,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3209#issuecomment-2286226902:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3209#issuecomment-2286226902,2,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3220?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `33.33333%` with `30 lines` in your changes missing coverage. Please review.; > Project coverage is 76.73%. Comparing base [(`d4e1fb4`)](https://app.codecov.io/gh/scverse/scanpy/commit/d4e1fb4cb290d9835710fba2b5b9594d97176601?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`403dd30`)](https://app.codecov.io/gh/scverse/scanpy/commit/403dd30f9e523ae84eba4ac239c6fb72fb439585?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3220?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/plotting/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3220?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fdXRpbHMucHk=) | 25.00% | [15 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3220?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/tools/\_draw\_graph.py](https://app.codecov.io/gh/scverse/scanpy/pull/3220?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_draw_graph.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fZHJhd19ncmFwaC5weQ==) | 31.57% | [13 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3220#issuecomment-2323386009:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3220#issuecomment-2323386009,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3227?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `50.00000%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.62%. Comparing base [(`bec794c`)](https://app.codecov.io/gh/scverse/scanpy/commit/bec794c7e7e28393e7cb6ae6624ecdbd187868ac?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`8d1cb04`)](https://app.codecov.io/gh/scverse/scanpy/commit/8d1cb04fbff869dd70d1b452477b83c151237e4a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 35 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3227?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/preprocessing/\_pca.py](https://app.codecov.io/gh/scverse/scanpy/pull/3227?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_pca.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19wY2EucHk=) | 50.00% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3227?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3227 +/- ##; ==========================================; - Coverage 76.63% 76.62% -0.02% ; ==========================================; Files 109 109 ; Lines 12533 12536 +3 ; ==========================================; + Hits 9605 9606 +1 ; - Misses 2928 2930 +2 ; ```. ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3227#issuecomment-2346840063:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3227#issuecomment-2346840063,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3230?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `33.33333%` with `30 lines` in your changes missing coverage. Please review.; > Project coverage is 76.72%. Comparing base [(`0f6acdf`)](https://app.codecov.io/gh/scverse/scanpy/commit/0f6acdf5dda52b698fbf3e675d018ef75806115c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`a98157b`)](https://app.codecov.io/gh/scverse/scanpy/commit/a98157b52c1b8fa5108a348a5dcf33bd123cc5e6?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3230?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/plotting/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3230?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fdXRpbHMucHk=) | 25.00% | [15 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3230?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/tools/\_draw\_graph.py](https://app.codecov.io/gh/scverse/scanpy/pull/3230?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_draw_graph.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fZHJhd19ncmFwaC5weQ==) | 31.57% | [13 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3230#issuecomment-2348590448:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3230#issuecomment-2348590448,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3243?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `25.00000%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 76.75%. Comparing base [(`bd75839`)](https://app.codecov.io/gh/scverse/scanpy/commit/bd758395a669c31a6c9eaa9239750fde368d3ca7?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`c06bbc8`)](https://app.codecov.io/gh/scverse/scanpy/commit/c06bbc83218ee426fa54e681ab39c8006e1668c0?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3243?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/plotting/\_stacked\_violin.py](https://app.codecov.io/gh/scverse/scanpy/pull/3243?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_stacked_violin.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fc3RhY2tlZF92aW9saW4ucHk=) | 25.00% | [3 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3243?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3243 +/- ##; ==========================================; + Coverage 76.49% 76.75% +0.25% ; ==========================================; Files 109 109 ; Lines 12544 12548 +4 ; ==========================================; + Hits 9596 9631 +35 ; + Misses,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3243#issuecomment-2363207170:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3243#issuecomment-2363207170,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3246?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `25.00000%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 76.71%. Comparing base [(`2553c67`)](https://app.codecov.io/gh/scverse/scanpy/commit/2553c67af6e47992abde5cb13e4c9deb82a3adbc?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`2e3ca25`)](https://app.codecov.io/gh/scverse/scanpy/commit/2e3ca25422b317736d49b2b14a61683cb9bfa98b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3246?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/plotting/\_stacked\_violin.py](https://app.codecov.io/gh/scverse/scanpy/pull/3246?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_stacked_violin.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fc3RhY2tlZF92aW9saW4ucHk=) | 25.00% | [3 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3246?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3246 +/- ##; ==========================================; - Coverage 76.76% 76.71% -0.05% ; ==========================================; Files 109 109 ; Lines 12529 12533 +4 ; ==========================================; - Hits 9618 9615 -3 ; - Mis,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3246#issuecomment-2363411554:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3246#issuecomment-2363411554,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3248?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `87.87879%` with `4 lines` in your changes missing coverage. Please review.; > Project coverage is 76.75%. Comparing base [(`b0597a9`)](https://app.codecov.io/gh/scverse/scanpy/commit/b0597a9f6f114a1aee6737e0acae6b1ca403e1b8?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`3cce3f2`)](https://app.codecov.io/gh/scverse/scanpy/commit/3cce3f28e94d29dc907f94056bd6995f197d9f93?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3248?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/external/tl/\_wishbone.py](https://app.codecov.io/gh/scverse/scanpy/pull/3248?src=pr&el=tree&filepath=src%2Fscanpy%2Fexternal%2Ftl%2F_wishbone.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9leHRlcm5hbC90bC9fd2lzaGJvbmUucHk=) | 50.00% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3248?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/3248?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_anndata.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fYW5uZGF0YS5weQ==) | 75.00% | [1 Missing :warning: ](https://app.codecov.io/gh/scv,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3248#issuecomment-2363527588:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3248#issuecomment-2363527588,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3249?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `94.59459%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.75%. Comparing base [(`1650aed`)](https://app.codecov.io/gh/scverse/scanpy/commit/1650aed30fd0141a97c01a6a6b19c2735e058c77?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`b3fa09b`)](https://app.codecov.io/gh/scverse/scanpy/commit/b3fa09ba950806f9e2a2c5060b32d3d768f0f14e?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3249?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/3249?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_anndata.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fYW5uZGF0YS5weQ==) | 93.10% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3249?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3249 +/- ##; ==========================================; - Coverage 76.75% 76.75% -0.01% ; ==========================================; Files 109 109 ; Lines 12551 12556 +5 ; ==========================================; + Hits 9634 9637 +3 ; - Misses 2917 2919 +2 ; ```. | [,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3249#issuecomment-2363632936:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3249#issuecomment-2363632936,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3250?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `87.87879%` with `4 lines` in your changes missing coverage. Please review.; > Project coverage is 76.71%. Comparing base [(`ffebf12`)](https://app.codecov.io/gh/scverse/scanpy/commit/ffebf124f8a7da65a85622a07c7037ca477bfbef?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`2b269f7`)](https://app.codecov.io/gh/scverse/scanpy/commit/2b269f7a7e579f2ab5af52f240a1e86f93c118b2?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3250?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/external/tl/\_wishbone.py](https://app.codecov.io/gh/scverse/scanpy/pull/3250?src=pr&el=tree&filepath=src%2Fscanpy%2Fexternal%2Ftl%2F_wishbone.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9leHRlcm5hbC90bC9fd2lzaGJvbmUucHk=) | 50.00% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3250?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/3250?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_anndata.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fYW5uZGF0YS5weQ==) | 75.00% | [1 Missing :warning: ](https://app.codecov.io/gh/s,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3250#issuecomment-2363580091:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3250#issuecomment-2363580091,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3251?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `94.59459%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.71%. Comparing base [(`b325b50`)](https://app.codecov.io/gh/scverse/scanpy/commit/b325b50f942ba75d77e1a4caa181d67f83d0a057?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`408a7b5`)](https://app.codecov.io/gh/scverse/scanpy/commit/408a7b58758a609147276eea01e9f86ae16855ee?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3251?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/3251?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_anndata.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fYW5uZGF0YS5weQ==) | 93.10% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3251?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3251 +/- ##; ==========================================; - Coverage 76.72% 76.71% -0.01% ; ==========================================; Files 109 109 ; Lines 12536 12541 +5 ; ==========================================; + Hits 9618 9621 +3 ; - Misses 2918 2920 +2 ; ```.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3251#issuecomment-2363756462:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3251#issuecomment-2363756462,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3252?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `33.33333%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.74%. Comparing base [(`e27e257`)](https://app.codecov.io/gh/scverse/scanpy/commit/e27e257964c358acb3a9a83e4289cccfdfa425ae?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`0744da6`)](https://app.codecov.io/gh/scverse/scanpy/commit/0744da68e4f3593a81bed752d387bd2ca12a5e09?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3252?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/plotting/\_stacked\_violin.py](https://app.codecov.io/gh/scverse/scanpy/pull/3252?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_stacked_violin.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fc3RhY2tlZF92aW9saW4ucHk=) | 33.33% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3252?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3252 +/- ##; ==========================================; - Coverage 76.75% 76.74% -0.02% ; ==========================================; Files 109 109 ; Lines 12556 12559 +3 ; ==========================================; + Hits 9637 9638 +1 ; - Misses ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3252#issuecomment-2363846754:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3252#issuecomment-2363846754,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3258?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `79.24528%` with `22 lines` in your changes missing coverage. Please review.; > Project coverage is 76.96%. Comparing base [(`8b2088d`)](https://app.codecov.io/gh/scverse/scanpy/commit/8b2088de18452ff11e555bac0c147eaf15cf27f4?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`1b1fbc9`)](https://app.codecov.io/gh/scverse/scanpy/commit/1b1fbc93200bdbf7b69d0dd87f01a5c0ede2bdc1?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3258?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/plotting/\_tools/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3258?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_tools%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fdG9vbHMvX19pbml0X18ucHk=) | 44.44% | [5 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3258?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/tools/\_sim.py](https://app.codecov.io/gh/scverse/scanpy/pull/3258?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_sim.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fc2ltLnB5) | 58.33% | [5 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3258#issuecomment-2371725350:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3258#issuecomment-2371725350,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3264?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `92.00000%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.95%. Comparing base [(`d998742`)](https://app.codecov.io/gh/scverse/scanpy/commit/d9987426be03f9ef1bdab065f50959d046734ea4?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`9d0ffa5`)](https://app.codecov.io/gh/scverse/scanpy/commit/9d0ffa5b52b7311999bd52f7c856096a2b3d7653?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3264?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/\_compat.py](https://app.codecov.io/gh/scverse/scanpy/pull/3264?src=pr&el=tree&filepath=src%2Fscanpy%2F_compat.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fY29tcGF0LnB5) | 81.81% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3264?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3264 +/- ##; ==========================================; - Coverage 76.96% 76.95% -0.02% ; ==========================================; Files 109 109 ; Lines 12469 12466 -3 ; ==========================================; - Hits 9597 9593 -4 ; - Misses 2872 2873 +1 ; ```. | [Flag](https://app.codecov.io/gh/scvers,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3264#issuecomment-2376822003:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3264#issuecomment-2376822003,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3265?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `92.00000%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.91%. Comparing base [(`7ccf96d`)](https://app.codecov.io/gh/scverse/scanpy/commit/7ccf96d4b6ac10f0a718010578f725e3de2902f7?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`bd99e6d`)](https://app.codecov.io/gh/scverse/scanpy/commit/bd99e6de4235131acaf426f62649a929db32c699?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3265?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/\_compat.py](https://app.codecov.io/gh/scverse/scanpy/pull/3265?src=pr&el=tree&filepath=src%2Fscanpy%2F_compat.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fY29tcGF0LnB5) | 81.81% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3265?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3265 +/- ##; ==========================================; - Coverage 76.93% 76.91% -0.02% ; ==========================================; Files 109 109 ; Lines 12454 12451 -3 ; ==========================================; - Hits 9581 9577 -4 ; - Misses 2873 2874 +1 ; ```. | [Flag](https://app.codecov.io/gh/sc,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3265#issuecomment-2377150033:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3265#issuecomment-2377150033,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3267?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `95.16129%` with `6 lines` in your changes missing coverage. Please review.; > Project coverage is 77.03%. Comparing base [(`bbcd4b1`)](https://app.codecov.io/gh/scverse/scanpy/commit/bbcd4b173aabebb8b4793cf2cdd6ea8b31e31005?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`7516acc`)](https://app.codecov.io/gh/scverse/scanpy/commit/7516acc4474f54b86cc7a880e3508a20b8a40169?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3267?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/preprocessing/\_pca/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3267?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_pca%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19wY2EvX19pbml0X18ucHk=) | 93.18% | [6 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3267?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3267 +/- ##; ==========================================; + Coverage 76.95% 77.03% +0.08% ; ==========================================; Files 109 110 +1 ; Lines 12465 12492 +27 ; ==========================================; + Hits 9592 ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3267#issuecomment-2378904712:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3267#issuecomment-2378904712,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3275?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `88.88889%` with `1 line` in your changes missing coverage. Please review.; > Project coverage is 77.23%. Comparing base [(`502f738`)](https://app.codecov.io/gh/scverse/scanpy/commit/502f738b78e9ef78506fafd751e05b993d6001b3?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`af65f75`)](https://app.codecov.io/gh/scverse/scanpy/commit/af65f75e459e061460b8cda5d0ef68065e2809d3?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3275?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/3275?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_simple.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19zaW1wbGUucHk=) | 88.88% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3275?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3275 +/- ##; =======================================; Coverage 77.22% 77.23% ; =======================================; Files 111 111 ; Lines 12600 12605 +5 ; =======================================; + Hits 9730 9735 +5 ; Misses 2870 2870 ; ```. | [Files with m,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3275#issuecomment-2399522678:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3275#issuecomment-2399522678,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3283?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `87.50000%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 76.94%. Comparing base [(`be99b23`)](https://app.codecov.io/gh/scverse/scanpy/commit/be99b230fa84e077f5167979bc9f6dacc4ad0d41?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`8268e54`)](https://app.codecov.io/gh/scverse/scanpy/commit/8268e543090721ae9b056355c0cbb8d2ac742d13?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3283?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/external/pl.py](https://app.codecov.io/gh/scverse/scanpy/pull/3283?src=pr&el=tree&filepath=src%2Fscanpy%2Fexternal%2Fpl.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9leHRlcm5hbC9wbC5weQ==) | 0.00% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3283?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/plotting/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3283?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fdXRpbHMucHk=) | 83.33% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3283?src=pr&el=tree&utm_med,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3283#issuecomment-2411417242:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3283#issuecomment-2411417242,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3284?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `90.62500%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 77.22%. Comparing base [(`60d30a4`)](https://app.codecov.io/gh/scverse/scanpy/commit/60d30a40de65b4e9dacb9578f074f9e8565621dc?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`9cd667d`)](https://app.codecov.io/gh/scverse/scanpy/commit/9cd667d7a99c9d4554b88edc258127bc043ccc83?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3284?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/preprocessing/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3284?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL191dGlscy5weQ==) | 62.50% | [3 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3284?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3284 +/- ##; ==========================================; + Coverage 77.21% 77.22% +0.01% ; ==========================================; Files 111 111 ; Lines 12597 12621 +24 ; ==========================================; + Hits 9727 9747 +20 ; - Misses 2870 2874 +4 ; ```. | [Files with missing lines](https:,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3284#issuecomment-2413061647:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3284#issuecomment-2413061647,2,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3303?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `87.50000%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 76.91%. Comparing base [(`388aae5`)](https://app.codecov.io/gh/scverse/scanpy/commit/388aae5fe140ee09c1b3f8c4a84f14667823f31b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`81f4aa3`)](https://app.codecov.io/gh/scverse/scanpy/commit/81f4aa39a45739c2f832b0f452ad07b717bcecc6?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3303?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/external/pl.py](https://app.codecov.io/gh/scverse/scanpy/pull/3303?src=pr&el=tree&filepath=src%2Fscanpy%2Fexternal%2Fpl.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9leHRlcm5hbC9wbC5weQ==) | 0.00% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3303?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/plotting/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3303?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fdXRpbHMucHk=) | 83.33% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3303?src=pr&el=tree&utm_m,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3303#issuecomment-2427060248:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3303#issuecomment-2427060248,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3307?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `95.45455%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 77.23%. Comparing base [(`2f0afac`)](https://app.codecov.io/gh/scverse/scanpy/commit/2f0afac72be3644624cf996323197239580f14f9?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`65c74cf`)](https://app.codecov.io/gh/scverse/scanpy/commit/65c74cfa67b2f9d9493b9cd2384685245ecacc2c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3307?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/preprocessing/\_qc.py](https://app.codecov.io/gh/scverse/scanpy/pull/3307?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_qc.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19xYy5weQ==) | 94.28% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3307?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3307 +/- ##; ==========================================; + Coverage 77.21% 77.23% +0.02% ; ==========================================; Files 111 111 ; Lines 12597 12618 +21 ; ==========================================; + Hits 9727 9746 +19 ; - Misses 2870 2872 +2 ; ```. |,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3307#issuecomment-2429279414:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3307#issuecomment-2429279414,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3314?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `88.88889%` with `1 line` in your changes missing coverage. Please review.; > Project coverage is 76.95%. Comparing base [(`947afa1`)](https://app.codecov.io/gh/scverse/scanpy/commit/947afa157474130bd94b5130dd2de433692e06ff?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`ca18a68`)](https://app.codecov.io/gh/scverse/scanpy/commit/ca18a68e60d72a0b16263ea43d5b950fcf9b0c44?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3314?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/3314?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_simple.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19zaW1wbGUucHk=) | 88.88% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3314?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3314 +/- ##; =======================================; Coverage 76.94% 76.95% ; =======================================; Files 109 109 ; Lines 12462 12467 +5 ; =======================================; + Hits 9589 9594 +5 ; Misses 2873 2873 ; ```. | [Files wi,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3314#issuecomment-2434892685:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3314#issuecomment-2434892685,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3316?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `85.71429%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 77.21%. Comparing base [(`3d220a9`)](https://app.codecov.io/gh/scverse/scanpy/commit/3d220a93c83fdd60ee3220c94db3dd8d5533c60d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`f5f2775`)](https://app.codecov.io/gh/scverse/scanpy/commit/f5f27756930da430c3f6d803800076e8501952e6?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3316?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/3316?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_simple.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19zaW1wbGUucHk=) | 85.71% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3316?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3316 +/- ##; ==========================================; - Coverage 77.23% 77.21% -0.02% ; ==========================================; Files 111 111 ; Lines 12605 12597 -8 ; ==========================================; - Hits 9735 9727 -8 ; Misses 2870 2870 ; `,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3316#issuecomment-2435332939:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3316#issuecomment-2435332939,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3317?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `91.66667%` with `1 line` in your changes missing coverage. Please review.; > Project coverage is 77.22%. Comparing base [(`3d220a9`)](https://app.codecov.io/gh/scverse/scanpy/commit/3d220a93c83fdd60ee3220c94db3dd8d5533c60d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`7fdeda1`)](https://app.codecov.io/gh/scverse/scanpy/commit/7fdeda1f70297e30c1990232a35a53bbfd33940c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3317?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/preprocessing/\_scale.py](https://app.codecov.io/gh/scverse/scanpy/pull/3317?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_scale.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19zY2FsZS5weQ==) | 91.66% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3317?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3317 +/- ##; ==========================================; - Coverage 77.23% 77.22% -0.01% ; ==========================================; Files 111 111 ; Lines 12605 12604 -1 ; ==========================================; - Hits 9735 9734 -1 ; Misses 2870 2870 ; ```. | [Files with missing lines](https://app.co,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3317#issuecomment-2435647972:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3317#issuecomment-2435647972,2,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3325?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `58.82353%` with `7 lines` in your changes missing coverage. Please review.; > Project coverage is 77.20%. Comparing base [(`9a9f17e`)](https://app.codecov.io/gh/scverse/scanpy/commit/9a9f17e4d4afdd3c2e1395dfe9aec5cce5489248?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`d5e994e`)](https://app.codecov.io/gh/scverse/scanpy/commit/d5e994ef08ebfc8c2c683b5ea07de37c8158d638?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3325?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/external/exporting.py](https://app.codecov.io/gh/scverse/scanpy/pull/3325?src=pr&el=tree&filepath=src%2Fscanpy%2Fexternal%2Fexporting.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9leHRlcm5hbC9leHBvcnRpbmcucHk=) | 0.00% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3325?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/external/tl/\_phenograph.py](https://app.codecov.io/gh/scverse/scanpy/pull/3325?src=pr&el=tree&filepath=src%2Fscanpy%2Fexternal%2Ftl%2F_phenograph.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9leHRlcm5hbC90bC9fcGhlbm9ncmFwaC5weQ==) | 0.00% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3325?src=pr&el=tree&,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3325#issuecomment-2438028067:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3325#issuecomment-2438028067,2,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3330?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `22.44898%` with `38 lines` in your changes missing coverage. Please review.; > Project coverage is 72.25%. Comparing base [(`a70582e`)](https://app.codecov.io/gh/scverse/scanpy/commit/a70582ee03556cf6821eb45148560cb259a5fb34?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`25e7cd4`)](https://app.codecov.io/gh/scverse/scanpy/commit/25e7cd418ac258329944ced2b4ba443d5d06865b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 103 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3330?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/3330?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_simple.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19zaW1wbGUucHk=) | 22.44% | [38 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3330?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3330 +/- ##; ==========================================; - Coverage 76.27% 72.25% -4.03% ; ==========================================; Files 117 111 -6 ; Lines 12795 12639 -156 ; ==========================================; - Hits 9760 9132 -628 ; - Misses ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3330#issuecomment-2443557729:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3330#issuecomment-2443557729,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3333?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `90.00000%` with `4 lines` in your changes missing coverage. Please review.; > Project coverage is 77.23%. Comparing base [(`6440515`)](https://app.codecov.io/gh/scverse/scanpy/commit/6440515ebce6e38b62bac5bce6d656f71fbeaa5b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`bbb9469`)](https://app.codecov.io/gh/scverse/scanpy/commit/bbb94697549e9980eb039d3a5c174b2cc72a51ac?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3333?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3333?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvX19pbml0X18ucHk=) | 83.33% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3333?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/get/\_aggregated.py](https://app.codecov.io/gh/scverse/scanpy/pull/3333?src=pr&el=tree&filepath=src%2Fscanpy%2Fget%2F_aggregated.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9nZXQvX2FnZ3JlZ2F0ZWQucHk=) | 75.00% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3333?src=,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3333#issuecomment-2449625873:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3333#issuecomment-2449625873,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3335?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `90.54054%` with `7 lines` in your changes missing coverage. Please review.; > Project coverage is 76.56%. Comparing base [(`6440515`)](https://app.codecov.io/gh/scverse/scanpy/commit/6440515ebce6e38b62bac5bce6d656f71fbeaa5b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`b426035`)](https://app.codecov.io/gh/scverse/scanpy/commit/b4260358866324a1097cdce17315ceebfe0cef0b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3335?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/\_compat.py](https://app.codecov.io/gh/scverse/scanpy/pull/3335?src=pr&el=tree&filepath=src%2Fscanpy%2F_compat.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fY29tcGF0LnB5) | 87.23% | [6 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3335?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/\_utils/compute/is\_constant.py](https://app.codecov.io/gh/scverse/scanpy/pull/3335?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2Fcompute%2Fis_constant.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvY29tcHV0ZS9pc19jb25zdGFudC5weQ==) | 87.50% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/33,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3335#issuecomment-2450235904:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335#issuecomment-2450235904,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3336?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `90.00000%` with `4 lines` in your changes missing coverage. Please review.; > Project coverage is 77.22%. Comparing base [(`dda1f6e`)](https://app.codecov.io/gh/scverse/scanpy/commit/dda1f6eafad19e1a53947c54401ac4573b0a1cc3?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`c4a1e0a`)](https://app.codecov.io/gh/scverse/scanpy/commit/c4a1e0a829f553e14a91be9c1e441345e6b9a66c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 5 commits behind head on ig/fix_pca_args. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3336?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3336?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvX19pbml0X18ucHk=) | 83.33% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3336?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/get/\_aggregated.py](https://app.codecov.io/gh/scverse/scanpy/pull/3336?src=pr&el=tree&filepath=src%2Fscanpy%2Fget%2F_aggregated.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9nZXQvX2FnZ3JlZ2F0ZWQucHk=) | 75.00% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pul,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3336#issuecomment-2450270276:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3336#issuecomment-2450270276,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3339?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `76.92308%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 77.24%. Comparing base [(`0d04447`)](https://app.codecov.io/gh/scverse/scanpy/commit/0d04447448747337e2d3adb15ecdfdbfa1ad91c7?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`41666cf`)](https://app.codecov.io/gh/scverse/scanpy/commit/41666cffcc228a2ebe0c1837e87c074c5d097367?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3339?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3339?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvX19pbml0X18ucHk=) | 62.50% | [3 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3339?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3339 +/- ##; =======================================; Coverage 77.23% 77.24% ; =======================================; Files 111 111 ; Lines 12608 12609 +1 ; =======================================; + Hits 9738 9740 +2 ; + Misses 2870 2869 -1 ; ```. | [Files with missing lin,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3339#issuecomment-2456762349:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3339#issuecomment-2456762349,1,['Patch'],['Patch']
Deployability,## [Codecov](https://app.codecov.io/gh/scverse/scanpy/pull/3340?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `96.29630%` with `1 line` in your changes missing coverage. Please review.; > Project coverage is 77.26%. Comparing base [(`6440515`)](https://app.codecov.io/gh/scverse/scanpy/commit/6440515ebce6e38b62bac5bce6d656f71fbeaa5b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`11a711e`)](https://app.codecov.io/gh/scverse/scanpy/commit/11a711e97b84c01dcd73d5b17b8e68c6b6d047c6?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse). | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3340?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/preprocessing/\_highly\_variable\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3340?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_highly_variable_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19oaWdobHlfdmFyaWFibGVfZ2VuZXMucHk=) | 96.29% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3340?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3340 +/- ##; ==========================================; + Coverage 77.22% 77.26% +0.03% ; ==========================================; Files 111 111 ; Lines 12601 12618 +17 ; ==========================================; + Hits 9731 9749 +18 ; + Misses 28,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3340#issuecomment-2456911184:215,Patch,Patch,215,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3340#issuecomment-2456911184,2,['Patch'],['Patch']
Deployability,"### Test failures as of d36b977fa0c85d67b96799da4cb86b8582868048. Significantly improved!. 56 failed, 1236 passed, 96 skipped, 19 xfailed, 9 xpassed, 763 warnings in 595.02s (0:09:55). Remaining errors include:. * A lot of `AssertionError: Error: Image files did not match.`; * Some missing function from scipy; * Missing pynndescent; * 3 or 4 more unique ones. <details>; <summary> </summary>. ```python; FAILED scanpy/get/get.py::scanpy.get.get.obs_df; FAILED scanpy/plotting/_baseplot_class.py::scanpy.plotting._baseplot_class.BasePlot.add_totals; FAILED scanpy/tests/test_metrics.py::test_consistency[morans_i-allclose] - AssertionError: ; FAILED scanpy/tests/test_paga.py::test_paga_plots[-paga] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous-func1] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_obs-func2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_plots[continuous_multiple-func3] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_paga.py::test_paga_pie - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[umap] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_euclidean[gauss] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_neighbors.py::test_distances_all[pynndescent] - ModuleNotFoundError: No module named 'pynndescent'; FAILED scanpy/tests/test_plotting.py::test_tracksplot - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot-fn0] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456:804,continuous,continuous-,804,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1896079456,1,['continuous'],['continuous-']
Deployability,"### symlink installs being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip?. Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR; * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right?. I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python; conda create -n scanpyenv python=3.8; https://github.com/theislab/scanpy.git; cd scanpy; pip install .; ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-783849659:12,install,installs,12,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-783849659,6,"['install', 'update']","['install', 'installation', 'installs', 'update']"
Deployability,"#2064 should do it. There seems to be some issues with recent builds of pytables. I've been having periodic trouble installing it, but had trouble reproducing the error when I tried. IIRC, the errors made me think it was some incompatibility between new versions of `pip`/ `setuptools` and old builds of `pytables` – but that wasn't on windows. @MxMstrmn has also mentioned seeing some issues with pytables installing on windows.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013006816:116,install,installing,116,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1013006816,2,['install'],['installing']
Deployability,"(= 0.40.0-2),; debconf (= 1.5.79),; debhelper (= 13.5.2),; debianutils (= 5.5-1),; dh-autoreconf (= 20),; dh-python (= 5.20211105),; dh-strip-nondeterminism (= 1.12.0-2),; diffutils (= 1:3.7-5),; dmsetup (= 2:1.02.175-2.1),; docutils-common (= 0.17.1+dfsg-2),; dpkg (= 1.20.9),; dpkg-dev (= 1.20.9),; dwz (= 0.14-1),; file (= 1:5.39-3),; findutils (= 4.8.0-1),; flit (= 3.0.0-1),; fontconfig (= 2.13.1-4.2),; fontconfig-config (= 2.13.1-4.2),; fonts-font-awesome (= 5.0.10+really4.7.0~dfsg-4.1),; fonts-lato (= 2.0-2.1),; fonts-lyx (= 2.3.6-1),; g++ (= 4:11.2.0-2),; g++-11 (= 11.2.0-10),; gcc (= 4:11.2.0-2),; gcc-11 (= 11.2.0-10),; gcc-11-base (= 11.2.0-10),; gettext (= 0.21-4),; gettext-base (= 0.21-4),; gir1.2-atk-1.0 (= 2.36.0-2),; gir1.2-freedesktop (= 1.70.0-2),; gir1.2-gdkpixbuf-2.0 (= 2.42.6+dfsg-2),; gir1.2-glib-2.0 (= 1.70.0-2),; gir1.2-gtk-3.0 (= 3.24.30-3),; gir1.2-harfbuzz-0.0 (= 2.7.4-1),; gir1.2-pango-1.0 (= 1.48.10+ds1-1),; grep (= 3.7-1),; groff-base (= 1.22.4-7),; gtk-update-icon-cache (= 3.24.30-3),; gzip (= 1.10-4),; hicolor-icon-theme (= 0.17-2),; hostname (= 3.23),; imagemagick (= 8:6.9.11.60+dfsg-1.3),; imagemagick-6-common (= 8:6.9.11.60+dfsg-1.3),; imagemagick-6.q16 (= 8:6.9.11.60+dfsg-1.3),; init-system-helpers (= 1.60),; intltool-debian (= 0.35.0+20060710.5),; libacl1 (= 2.3.1-1),; libaec0 (= 1.0.6-1),; libamd2 (= 1:5.10.1+dfsg-2),; libaom3 (= 3.2.0-1),; libapparmor1 (= 3.0.3-5),; libarchive-zip-perl (= 1.68-1),; libargon2-1 (= 0~20171227-0.2),; libarpack2 (= 3.8.0-1),; libasan6 (= 11.2.0-10),; libatk-bridge2.0-0 (= 2.38.0-2),; libatk1.0-0 (= 2.36.0-2),; libatk1.0-data (= 2.36.0-2),; libatlas3-base (= 3.10.3-11),; libatomic1 (= 11.2.0-10),; libatspi2.0-0 (= 2.42.0-2),; libattr1 (= 1:2.5.1-1),; libaudit-common (= 1:3.0.6-1),; libaudit1 (= 1:3.0.6-1),; libavahi-client3 (= 0.8-5),; libavahi-common-data (= 0.8-5),; libavahi-common3 (= 0.8-5),; libbinutils (= 2.37-8),; libblas3 (= 3.10.0-1),; libblkid1 (= 2.37.2-4),; libblosc1 (= 1.21.1+ds1-1),; libbr",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2048#issuecomment-969885616:2851,update,update-icon-cache,2851,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048#issuecomment-969885616,1,['update'],['update-icon-cache']
Deployability,"(Py_UNICODE *) PyUnicode_AsUnicode(; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; fa2/fa2util.c:12149:59: warning: '_PyUnicode_get_wstr_length' is deprecated [-Wdeprecated-declarations]; (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :; ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:264:8: note: expanded from macro 'PyUnicode_GET_SIZE'; PyUnicode_WSTR_LENGTH(op))); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:451:35: note: expanded from macro 'PyUnicode_WSTR_LENGTH'; #define PyUnicode_WSTR_LENGTH(op) _PyUnicode_get_wstr_length((PyObject*)op); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/cpython/unicodeobject.h:445:1: note: '_PyUnicode_get_wstr_length' has been explicitly marked deprecated here; Py_DEPRECATED(3.3); ^; /Users/test/.pyenv/versions/3.10.3/include/python3.10/pyport.h:513:54: note: expanded from macro 'Py_DEPRECATED'; #define Py_DEPRECATED(VERSION_UNUSED) __attribute__((__deprecated__)); ^; 12 warnings and 3 errors generated.; error: command '/usr/bin/clang' failed with exit code 1; [end of output]; ; note: This error originates from a subprocess, and is likely not a problem with pip.; WARNING: No metadata found in /Users/test/.local/lib/python3.10/site-packages; Rolling back uninstall of fa2; Moving to /Users/test/.local/lib/python3.10/site-packages/fa2-0.3.5.dist-info/; from /Users/test/.local/lib/python3.10/site-packages/~a2-0.3.5.dist-info; Moving to /Users/test/.local/lib/python3.10/site-packages/fa2/; from /Users/test/.local/lib/python3.10/site-packages/~a2; error: legacy-install-failure. × Encountered error while trying to install package.; ╰─> fa2. note: This is an issue with the package mentioned above, not pip.; hint: See above for output from the failure.; test@mac ~/PythonPackages/forceatlas2-0.3.5$; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096:30193,Rolling,Rolling,30193,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067#issuecomment-1077457096,3,"['Rolling', 'install']","['Rolling', 'install', 'install-failure']"
Deployability,"(and fingers crossed for a release soon, I currently have a nasty patch in place for our pipelines)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1965#issuecomment-1076139906:27,release,release,27,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1965#issuecomment-1076139906,3,"['patch', 'pipeline', 'release']","['patch', 'pipelines', 'release']"
Deployability,"(self, index):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _getitem_view(self, index); 1303 def _getitem_view(self, index):; 1304 oidx, vidx = self._normalize_indices(index); -> 1305 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1306 ; 1307 def _remove_unused_categories(self, df_full, df_sub, uns):. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in __init__(self, X, obs, var, uns, obsm, varm, layers, raw, dtype, shape, filename, filemode, asview, oidx, vidx); 662 if not isinstance(X, AnnData):; 663 raise ValueError('`X` has to be an AnnData object.'); --> 664 self._init_as_view(X, oidx, vidx); 665 else:; 666 self._init_as_actual(. ~/anaconda3/lib/python3.6/site-packages/anndata/base.py in _init_as_view(self, adata_ref, oidx, vidx); 691 self._varm = ArrayView(adata_ref.varm[vidx_normalized], view_args=(self, 'varm')); 692 # hackish solution here, no copy should be necessary; --> 693 uns_new = deepcopy(self._adata_ref._uns); 694 # need to do the slicing before setting the updated self._n_obs, self._n_vars; 695 self._n_obs = self._adata_ref.n_obs # use the original n_obs here. ~/anaconda3/lib/python3.6/copy.py in deepcopy(x, memo, _nil); 178 y = x; 179 else:; --> 180 y = _reconstruct(x, memo, *rv); 181 ; 182 # If is its own copy, don't memoize. ~/anaconda3/lib/python3.6/copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy); 278 if state is not None:; 279 if deep:; --> 280 state = deepcopy(state, memo); 281 if hasattr(y, '__setstate__'):; 282 y.__setstate__(state). ~/anaconda3/lib/python3.6/copy.py in deepcopy(x, memo, _nil); 148 copier = _deepcopy_dispatch.get(cls); 149 if copier:; --> 150 y = copier(x, memo); 151 else:; 152 try:. ~/anaconda3/lib/python3.6/copy.py in _deepcopy_dict(x, memo, deepcopy); 238 memo[id(x)] = y; 239 for key, value in x.items():; --> 240 y[deepcopy(key, memo)] = deepcopy(value, memo); 241 return y; 242 d[dict] = _deepcopy_dict. ~/anaconda3/lib/python3.6/copy.py in deepcopy(x, memo",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/363#issuecomment-442366170:2240,update,updated,2240,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/363#issuecomment-442366170,1,['update'],['updated']
Deployability,"* I think it fits the standard tutorial, I calculate these things all the time. All the tutorials are in the [`scanpy_usage`](https://github.com/theislab/scanpy_usage) repo, right?; * Do you mean the `top_segment_proportions` and/ or `top_proportions` functions?. ## Sparse matrix support. I took the easy way out for calculations on other sparse matrices types – just converted them to a `CSR` – so there's room for improvement. I'm considering writing a more involved implementation, but I'd have to benchmark it against conversion. . I'd probably try an online sort (insertion?) for each cell, keeping only the top `max(ns)` expression values, while iterating through the `COO` or `CSC` matrix. ## Numba. This currently throws a lot of warnings about `np.partition` not being implemented in `numba`. This should change with their next release, and give some speedup here. ## `cell_controls`. I'm trying to decide on including this. I haven't used data with control wells, so I don't know how common it is. It could be nice to implement it a bit differently, and have able to get something like`.var[""mean_counts_in_sampletype-CD8""]`, but I'm already returning a lot of values. Any thoughts?. ## f-strings. Just noticed this is why my builds are failing. This might get ugly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/316#issuecomment-432531663:838,release,release,838,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/316#issuecomment-432531663,1,['release'],['release']
Deployability,"* Release note, yeah, a new PR.; * Backport, up to you. Docs should be fine to backport. [Instructions here](https://scanpy.readthedocs.io/en/latest/dev/versioning.html), but you basically just need to write a comment with the right format and a backport PR will be opened.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1680#issuecomment-787580560:2,Release,Release,2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1680#issuecomment-787580560,1,['Release'],['Release']
Deployability,"**I installed the newest versions of JAVA and VC+++, didn't work.; Here also attaches the information of install scapy[leiden]:**; Collecting scanpy[leiden]; Using cached scanpy-1.7.2-py3-none-any.whl (10.3 MB); Collecting h5py>=2.10.0; Using cached h5py-3.1.0-cp36-cp36m-win_amd64.whl (2.7 MB); Collecting tables; Using cached tables-3.6.1-2-cp36-cp36m-win_amd64.whl (3.2 MB); Collecting numpy>=1.17.0; Using cached numpy-1.19.5-cp36-cp36m-win_amd64.whl (13.2 MB); Collecting joblib; Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB); Collecting pandas>=0.21; Using cached pandas-1.1.5-cp36-cp36m-win_amd64.whl (8.7 MB); Collecting tqdm; Using cached tqdm-4.62.3-py2.py3-none-any.whl (76 kB); Collecting matplotlib>=3.1.2; Using cached matplotlib-3.3.4-cp36-cp36m-win_amd64.whl (8.5 MB); Collecting networkx>=2.3; Using cached networkx-2.5.1-py3-none-any.whl (1.6 MB); Collecting sinfo; Using cached sinfo-0.3.4-py3-none-any.whl; Requirement already satisfied: importlib-metadata>=0.7 in c:\users\yuanjian\.conda\envs\py363636\lib\site-packages (from scanpy[leiden]) (4.8.1); Collecting scikit-learn>=0.21.2; Using cached scikit_learn-0.24.2-cp36-cp36m-win_amd64.whl (6.8 MB); Collecting scipy>=1.4; Using cached scipy-1.5.4-cp36-cp36m-win_amd64.whl (31.2 MB); Collecting numba>=0.41.0; Using cached numba-0.53.1-cp36-cp36m-win_amd64.whl (2.3 MB); Collecting patsy; Using cached patsy-0.5.2-py2.py3-none-any.whl (233 kB); Collecting natsort; Using cached natsort-8.0.0-py3-none-any.whl (37 kB); Collecting seaborn; Using cached seaborn-0.11.2-py3-none-any.whl (292 kB); Requirement already satisfied: packaging in c:\users\yuanjian\.conda\envs\py363636\lib\site-packages (from scanpy[leiden]) (21.0); Collecting statsmodels>=0.10.0rc2; Using cached statsmodels-0.12.2-cp36-none-win_amd64.whl (9.3 MB); Collecting umap-learn>=0.3.10; Using cached umap_learn-0.5.2-py3-none-any.whl; Collecting anndata>=0.7.4; Using cached anndata-0.7.6-py3-none-any.whl (127 kB); Collecting legacy-api-wrap; Usin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2045#issuecomment-962562955:4,install,installed,4,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2045#issuecomment-962562955,2,['install'],"['install', 'installed']"
Deployability,"**solution please :** ; scanpy ; During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, varkwarg=None, target=None)"" at C:\ProgramData\Anaconda3\lib\site-packages\umap\layouts.py. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); computing neighbors; using 'X_pca' with n_pcs = 40; ; LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x000001FF1D57B970> (trying to write member #1). File ""C:\ProgramData\Anaconda3\lib\site-packages\umap\layouts.py"", line 53:; def rdist(x, y):; <source elided>; dim = x.shape[0]; for i in range(dim):; ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, varkwarg=None, target=None)"" at C:\ProgramData\Anaconda3\lib\site-packages\umap\layouts.py (53). TypeError Traceback (most recent call last); C:\ProgramData\Anaconda3\lib\site-packages\numba\core\errors.py in new_error_context(fmt_, *args, **kwargs); 822 try:; --> 823 yield; 824 except NumbaError as e:. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower_block(self, block); 264 loc=self.loc, errcls_=defaulterrcls):; --> 265 self.lower_inst(inst); 266 self.post_block(block). C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower_inst(self, inst); 438 ty = self.typeof(inst.target.name); --> 439 val = self.lower_assign(ty, inst); 440 argidx = None. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower_assign(self, ty, inst); 625 elif isinstance(value, ir.Expr):; --> 626 return self.lower_expr(ty, value); 627 . C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lowering.py in lower_expr(self, resty, expr); 1161 elif expr.op == 'call':; -> 1162 res = self.lower_call(resty, expr); 1163 return res. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\lo",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325:410,pipeline,pipeline,410,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325,1,['pipeline'],['pipeline']
Deployability,", cholesterol tags, etc.) we've been doing. However, most of the time I'll just load the tags matrix in as a pandas dataframe and run them through a demuxing function that'll modify `adata.obs`. A couple challenges/ideas to consider:. * at our facility, we're typically building the same Illumina i7 index (`ATTACTCG`) into all tag libraries. This leads to some tricky situations when using a NovaSeq for sequencing since the multiple tag libraries (with disjoint sets of tags) may be run on the same sequencing flowcell lane. This results in a single set of FASTQ files and thus a single barcode-tag matrix for all tag libraries on that lane. Therefore, the mapping between transcriptome AnnData objects <-> tag library matrices is not always 1-to-1.; * in my experience, HTO libraries have a large variance in quality, so for the most part I've been using the transcriptome as my ""ground truth"" as to what is a cell. However, I imagine others use HTOs to ""rescue"" cells that were not called by their pipeline of choice (and I hope to do this once I build enough trust in the data). In that case, one would want to intersect the HTO classifications with the raw cell-gene matrix.; * not all tags are antibody based, so I'd vote for naming all related functions `*hashtags()`. I'd therefore vote for something like the following design:; ```{python}; # htos is a AnnData object; htos = sc.read_hashtags(filename) . # classify_hashtags adds a classification to the hto AnnData object; # kwargs might involve things like `use_tags=[""tag1"", ""tag2"", ""tag3""]`; sc.pp.classify_hashtags(htos, **kwargs); print(htos.obs.classification) . # demuxing cell-gene matrix(es) could then be done like; rna1 = sc.read_10x_h5(...); rna2 = sc.read_10x_h5(...); # sc.pp.demux_by_hashtag(adata_hto, *adata_rna, tag_groups=None, ...); sc.pp.demux_by_hashtag(; htos, ; rna1, rna2, ; tag_groups=[(""tag1"", ""tag3"", ""tag5""), (""tag2"", ""tag4"", ""tag6"")]; ); ```; @gokceneraslan This is more complex than what you suggested, but I ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/351#issuecomment-543387900:1567,pipeline,pipeline,1567,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/351#issuecomment-543387900,1,['pipeline'],['pipeline']
Deployability,", our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right?. I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python; conda create -n scanpyenv python=3.8; https://github.com/theislab/scanpy.git; cd scanpy; pip install .; ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative.; >; > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python; for frame in traceback.extract_stack():; if frame.name == 'get_docstring_and_version_via_import':; return True; ```. I don't see why `flit` couldn't just change the name of a function that is called internally at any point. I also think that at the moment, you and I are the only contributors who would have any idea what was going on if this acts up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-783849659:1870,install,install,1870,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-783849659,2,['install'],['install']
Deployability,- Either upgrade Scanpy to 1.10 (this PR has the fix for your problem): https://github.com/scverse/scanpy/pull/2414; - or upgrade Matplotlib to 3.8,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3029#issuecomment-2077206877:9,upgrade,upgrade,9,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029#issuecomment-2077206877,2,['upgrade'],['upgrade']
Deployability,"-----------------------------------------------; ImportError Traceback (most recent call last); <ipython-input-2-0074c9bc0b31> in <module>; ----> 1 import scanpy as sc. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/__init__.py in <module>; 3 from ._metadata import __version__, __author__, __email__; 4 ; ----> 5 from ._utils import check_versions; 6 ; 7 check_versions(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/_utils.py in <module>; 16 from numpy import random; 17 from scipy import sparse; ---> 18 from anndata import AnnData, __version__ as anndata_version; 19 from textwrap import dedent; 20 from packaging import version. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/anndata/__init__.py in <module>; 5 if not within_flit():; 6 del within_flit; ----> 7 from ._core.anndata import AnnData, ImplicitModificationWarning; 8 from ._core.merge import concat; 9 from ._core.raw import Raw. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/anndata/_core/anndata.py in <module>; 15 from typing import Tuple, List # Generic; 16 ; ---> 17 import h5py; 18 from natsort import natsorted; 19 import numpy as np. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/h5py/__init__.py in <module>; 31 raise; 32 ; ---> 33 from . import version; 34 ; 35 if version.hdf5_version_tuple != version.hdf5_built_version_tuple:. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/h5py/version.py in <module>; 13 ; 14 from collections import namedtuple; ---> 15 from . import h5 as _h5; 16 import sys; 17 import numpy. h5py/h5.pyx in init h5py.h5(). ImportError: /home/karl/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/h5py/defs.cpython-38-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_ros3; ```. </Details>. Before, when I was trying to update `h5py` and getting lots of conflicts, I let conda try to figure out all of them, printing out a huge list that reached the output limit of my console (~6000 lines). Let me know if I should post the list.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310:20564,update,update,20564,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310,1,['update'],['update']
Deployability,-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-inftheta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.on_data-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-100theta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode p,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:37084,pipeline,pipeline,37084,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['pipeline'],['pipeline']
Deployability,"-4-5d47edb05ae7> in <module>; ----> 1 sc.pp.neighbors(adata). ~/Projects/scanpy/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,. ~/Projects/scanpy/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 806 # we need self._distances also for method == 'gauss' if we didn't; 807 # use dense distances; --> 808 self._distances, self._connectivities = _compute_connectivities_umap(; 809 knn_indices,; 810 knn_distances,. ~/Projects/scanpy/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 385 # umap 0.5.0; 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""); --> 387 from umap.umap_ import fuzzy_simplicial_set; 388 ; 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/umap/__init__.py in <module>; 1 from warnings import warn, catch_warnings, simplefilter; ----> 2 from .umap_ import UMAP; 3 ; 4 try:; 5 with catch_warnings():. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/umap/umap_.py in <module>; 30 import umap.distances as dist; 31 ; ---> 32 import umap.sparse as sparse; 33 ; 34 from umap.utils import (. ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/umap/sparse.py in <module>; 10 import numpy as np; 11 ; ---> 12 from umap.utils import norm; 13 ; 14 locale.setlocale(locale.LC_NUMERIC, ""C""). ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-packages/umap/utils.py in <module>; 38 ; 39 @numba.njit(""i4(i8[:])""); ---> 40 def tau_rand_int(state):; 41 """"""A fast (pseudo)-random number generator.; 42 . ~/miniconda3/envs/scanpy_dev/lib/python3.8/site-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-846931466:1364,install,installed,1364,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-846931466,1,['install'],['installed']
Deployability,"-packages/anndata/compat.py in pkg_version(package); 56 try:; ---> 57 from importlib.metadata import version as v; 58 except ImportError:. ModuleNotFoundError: No module named 'importlib.metadata'. During handling of the above exception, another exception occurred:. ModuleNotFoundError Traceback (most recent call last); <ipython-input-11-495a6d84c058> in <module>; 1 import os; ----> 2 import scanpy as sc; 3 import numpy as np; 4 import pandas as pd; 5 import loompy as lp. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/__init__.py in <module>; 1 # some technical stuff; 2 import sys; ----> 3 from .utils import check_versions, annotate_doc_types; 4 from ._version import get_versions # version generated by versioneer; 5 . ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/utils.py in <module>; 17 from pandas.api.types import CategoricalDtype; 18 ; ---> 19 from ._settings import settings; 20 from . import logging as logg; 21 import warnings. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/_settings.py in <module>; 7 from typing import Tuple, Union, Any, List, Iterable, TextIO, Optional; 8 ; ----> 9 from . import logging; 10 from .logging import _set_log_level, _set_log_file, RootLogger; 11 . ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/logging.py in <module>; 7 from typing import Optional; 8 ; ----> 9 import anndata.logging; 10 ; 11 . ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/__init__.py in <module>; 93 from .compat import pkg_version; 94 ; ---> 95 __version__ = pkg_version(__name__); 96 del pkg_version. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/anndata/compat.py in pkg_version(package); 57 from importlib.metadata import version as v; 58 except ImportError:; ---> 59 from importlib_metadata import version as v; 60 return version.parse(v(package)); 61 . ModuleNotFoundError: No module named 'importlib_metadata'. And, when I try to install the module, it says that I already installed it. Thank you",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1154#issuecomment-611202845:3719,install,install,3719,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154#issuecomment-611202845,2,['install'],"['install', 'installed']"
Deployability,". It can definitely make the transition from R to Python more difficult (I can attest, as I'm going through it right now :P). R packages just tend to come with very thorough vignettes, documenting how the package is supposed to be used end-to-end, highlighting special use-cases, etc. I think [Seurat](http://satijalab.org/seurat/get_started.html), [Monocle](http://cole-trapnell-lab.github.io/monocle-release/), or really any Bioconductor package (eg. [Scater](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-intro.html)) are great examples. Jupyter notebooks are fantastic for helping get an idea of how to use a package, but sometimes the documentation within them is lacking, making it hard to understand what's going on at each step without having to dive into source code. I find Scanpy's straight forward to follow though. I really appreciate the modular design of Scanpy. At least if you're familiar with single-cell analysis, you can recognize the steps quite easily and just string together the appropriate functions for your analysis pipeline. Some other packages are bit trickier. For example, I found Velocyto (which I love btw) incredibly hard to navigate. There are functions that are used in some analysis notebooks but not all of them, so it becomes unclear what the standard analysis pipeline with it should be. Obviously you can dive into the paper, understand the statistical guts of the method, go through all the source code and see what's there, but then it starts becoming a barrier to newer users adapting it. . Anyway, this is just a general thing I also noticed moving from R to Python. Not saying that it's something that necessarily needs changing, but it does create a little bit of friction to newer users, so it may be worth thinking about as a community. I suspect this will improve as the genomics user-base of Python increases, and as all these packages have more time to develop. Also, I understand that this is more of a ""communit",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/74#issuecomment-363820657:1241,pipeline,pipeline,1241,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/74#issuecomment-363820657,1,['pipeline'],['pipeline']
Deployability,.2 py38h06a4308_0 ; boto 2.49.0 py38_0 ; bottleneck 1.3.2 py38heb32a55_1 ; brotlipy 0.7.0 py38h27cfd23_1003 ; bwidget 1.9.11 1 ; bzip2 1.0.8 h7b6447c_0 ; c-ares 1.17.1 h27cfd23_0 ; ca-certificates 2021.4.13 h06a4308_1 ; cached-property 1.5.2 py_0 ; cachetools 4.2.2 pypi_0 pypi; cairo 1.14.12 h8948797_3 ; capital 1.0.0 pypi_0 pypi; cellrank 1.2.0 pypi_0 pypi; certifi 2020.12.5 py38h06a4308_0 ; cffi 1.14.0 py38h2e261b9_0 ; chardet 4.0.0 py38h06a4308_1003 ; click 8.0.0 pypi_0 pypi; cloudpickle 1.6.0 py_0 ; clyent 1.2.2 py38_1 ; cmake 3.18.4.post1 pypi_0 pypi; colorama 0.4.4 pyhd3eb1b0_0 ; conda-pack 0.6.0 pyhd3eb1b0_0 ; contextlib2 0.6.0.post1 py_0 ; cryptography 3.4.7 py38hd23ed53_0 ; curl 7.69.1 hbc83047_0 ; cycler 0.10.0 py38_0 ; cython 0.29.22 pypi_0 pypi; cytoolz 0.11.0 py38h7b6447c_0 ; dask 2021.4.0 pyhd3eb1b0_0 ; dask-core 2021.4.0 pyhd3eb1b0_0 ; dbus 1.13.18 hb2f20db_0 ; decorator 5.0.9 pyhd3eb1b0_0 ; defusedxml 0.7.1 pyhd3eb1b0_0 ; deprecated 1.2.11 pypi_0 pypi; diff-match-patch 20200713 py_0 ; distributed 2021.5.0 py38h06a4308_0 ; docrep 0.3.2 pyh44b312d_0 conda-forge; docutils 0.17.1 py38h06a4308_1 ; dorothea-py 1.0.3 pypi_0 pypi; entrypoints 0.3 py38_0 ; et_xmlfile 1.1.0 py38h06a4308_0 ; expat 2.4.1 h2531618_2 ; fa2 0.3.5 pypi_0 pypi; fastcache 1.1.0 py38h7b6447c_0 ; fbpca 1.0 pypi_0 pypi; fcsparser 0.2.1 pypi_0 pypi; filelock 3.0.12 pyhd3eb1b0_1 ; flake8 3.9.0 pyhd3eb1b0_0 ; flask 1.1.2 pyhd3eb1b0_0 ; fontconfig 2.13.1 h6c09931_0 ; freetype 2.10.4 h5ab3b9f_0 ; fribidi 1.0.10 h7b6447c_0 ; fsspec 0.9.0 pyhd3eb1b0_0 ; funcargparse 0.2.3 pypi_0 pypi; future 0.18.2 py38_1 ; future_fstrings 1.2.0 py38h32f6830_2 conda-forge; gcc_impl_linux-64 7.3.0 habb00fd_1 ; gcc_linux-64 7.3.0 h553295d_15 ; geosketch 1.2 pypi_0 pypi; get_terminal_size 1.0.0 haa9412d_0 ; get_version 2.1 py_1 conda-forge; gevent 21.1.2 py38h27cfd23_1 ; gfortran_impl_linux-64 7.3.0 hdf63c60_1 ; gfortran_linux-64 7.3.0 h553295d_15 ; glib 2.63.1 h5a9c865_0 ; glob2 0.7 pyhd3eb1b0_0 ; gmp 6.2.1 h2531,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310:6569,patch,patch,6569,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310,1,['patch'],['patch']
Deployability,.io/gh/scverse/scanpy/pull/3182?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `94.33962%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 76.58%. Comparing base [(`d3de744`)](https://app.codecov.io/gh/scverse/scanpy/commit/d3de7442615eb89999abb741ad28825688199de3?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`6c895e8`)](https://app.codecov.io/gh/scverse/scanpy/commit/6c895e8b0e3ecef999924d1c3998b19affe10d8d?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 52 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3182?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/tools/\_umap.py](https://app.codecov.io/gh/scverse/scanpy/pull/3182?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_umap.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fdW1hcC5weQ==) | 66.66% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3182?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3182?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvX19pbml0X18ucHk=) | 93.33% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3182?src=pr&el=tree&utm_medium=referral&utm_source=,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3182#issuecomment-2446491018:1085,Patch,Patch,1085,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3182#issuecomment-2446491018,1,['Patch'],['Patch']
Deployability,.io/gh/scverse/scanpy/pull/3303?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `87.50000%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 76.91%. Comparing base [(`388aae5`)](https://app.codecov.io/gh/scverse/scanpy/commit/388aae5fe140ee09c1b3f8c4a84f14667823f31b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`81f4aa3`)](https://app.codecov.io/gh/scverse/scanpy/commit/81f4aa39a45739c2f832b0f452ad07b717bcecc6?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3303?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/external/pl.py](https://app.codecov.io/gh/scverse/scanpy/pull/3303?src=pr&el=tree&filepath=src%2Fscanpy%2Fexternal%2Fpl.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9leHRlcm5hbC9wbC5weQ==) | 0.00% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3303?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/plotting/\_utils.py](https://app.codecov.io/gh/scverse/scanpy/pull/3303?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_utils.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fdXRpbHMucHk=) | 83.33% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3303?src=pr&el=tree&utm_medium=referral&utm_source=github,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3303#issuecomment-2427060248:1086,Patch,Patch,1086,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3303#issuecomment-2427060248,1,['Patch'],['Patch']
Deployability,.off-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-200n-100theta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-200n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-200n-inftheta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-200n-100theta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-100n-inftheta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-200n-inftheta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILE,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:16896,pipeline,pipeline,16896,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['pipeline'],['pipeline']
Deployability,".py in _compile_cached(self, args, return_type); 137 ; 138 try:; --> 139 retval = self._compile_core(args, return_type); 140 except errors.TypingError as e:; 141 self._failed_cache[key] = e. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\dispatcher.py in _compile_core(self, args, return_type); 150 ; 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 150 ; 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 714 pipeline = pipeline_class(typingctx, targetctx, library,; 715 args, return_type, flags, locals); --> 716 return pipeline.compile_extra(func); 717 ; 718 . C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func); 450 self.state.lifted = (); 451 self.state.lifted_from = None; --> 452 return self._compile_bytecode(); 453 ; 454 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self); 518 """"""; 519 assert self.state.func_ir is None; --> 520 return self._compile_core(); 521 ; 522 def _compile_ir(self):. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 497 self.state.status.fail_reason = e; 498 if is_final_pipeline:; --> 499 raise e; 500 else:; 501 raise CompilerError(""All available pipelines exhausted""). C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 484 res = None; 485 try:; --> 4",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325:7433,pipeline,pipeline,7433,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325,2,['pipeline'],['pipeline']
Deployability,/gh/scverse/scanpy/pull/3088?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `66.66667%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 78.58%. Comparing base [(`698313b`)](https://app.codecov.io/gh/scverse/scanpy/commit/698313b5f38ed726c5b8093c155482d1bfdaf4bc?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`63253ab`)](https://app.codecov.io/gh/scverse/scanpy/commit/63253ab59f2799350c43631bf4033362d3f913bb?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 42 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3088?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [scanpy/external/exporting.py](https://app.codecov.io/gh/scverse/scanpy/pull/3088?src=pr&el=tree&filepath=scanpy%2Fexternal%2Fexporting.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L2V4dGVybmFsL2V4cG9ydGluZy5weQ==) | 0.00% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3088?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [scanpy/preprocessing/\_combat.py](https://app.codecov.io/gh/scverse/scanpy/pull/3088?src=pr&el=tree&filepath=scanpy%2Fpreprocessing%2F_combat.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c2NhbnB5L3ByZXByb2Nlc3NpbmcvX2NvbWJhdC5weQ==) | 0.00% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3088?src=pr&el=tree&utm_medium=referral&utm_s,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3088#issuecomment-2144755688:1087,Patch,Patch,1087,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3088#issuecomment-2144755688,1,['Patch'],['Patch']
Deployability,/gh/scverse/scanpy/pull/3227?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `50.00000%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.62%. Comparing base [(`bec794c`)](https://app.codecov.io/gh/scverse/scanpy/commit/bec794c7e7e28393e7cb6ae6624ecdbd187868ac?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`8d1cb04`)](https://app.codecov.io/gh/scverse/scanpy/commit/8d1cb04fbff869dd70d1b452477b83c151237e4a?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 35 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3227?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/preprocessing/\_pca.py](https://app.codecov.io/gh/scverse/scanpy/pull/3227?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_pca.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19wY2EucHk=) | 50.00% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3227?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3227 +/- ##; ==========================================; - Coverage 76.63% 76.62% -0.02% ; ==========================================; Files 109 109 ; Lines 12533 12536 +3 ; ==========================================; + Hits 9605 9606 +1 ; - Misses 2928 2930 +2 ; ```. | [Files with missing lines](https:,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3227#issuecomment-2346840063:1085,Patch,Patch,1085,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3227#issuecomment-2346840063,1,['Patch'],['Patch']
Deployability,/gh/scverse/scanpy/pull/3275?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `88.88889%` with `1 line` in your changes missing coverage. Please review.; > Project coverage is 77.23%. Comparing base [(`502f738`)](https://app.codecov.io/gh/scverse/scanpy/commit/502f738b78e9ef78506fafd751e05b993d6001b3?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`af65f75`)](https://app.codecov.io/gh/scverse/scanpy/commit/af65f75e459e061460b8cda5d0ef68065e2809d3?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3275?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/preprocessing/\_simple.py](https://app.codecov.io/gh/scverse/scanpy/pull/3275?src=pr&el=tree&filepath=src%2Fscanpy%2Fpreprocessing%2F_simple.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wcmVwcm9jZXNzaW5nL19zaW1wbGUucHk=) | 88.88% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3275?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3275 +/- ##; =======================================; Coverage 77.22% 77.23% ; =======================================; Files 111 111 ; Lines 12600 12605 +5 ; =======================================; + Hits 9730 9735 +5 ; Misses 2870 2870 ; ```. | [Files with missing lines](https://app.codecov.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3275#issuecomment-2399522678:1083,Patch,Patch,1083,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3275#issuecomment-2399522678,1,['Patch'],['Patch']
Deployability,/gh/scverse/scanpy/pull/3333?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `90.00000%` with `4 lines` in your changes missing coverage. Please review.; > Project coverage is 77.23%. Comparing base [(`6440515`)](https://app.codecov.io/gh/scverse/scanpy/commit/6440515ebce6e38b62bac5bce6d656f71fbeaa5b?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`bbb9469`)](https://app.codecov.io/gh/scverse/scanpy/commit/bbb94697549e9980eb039d3a5c174b2cc72a51ac?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3333?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3333?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvX19pbml0X18ucHk=) | 83.33% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3333?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/get/\_aggregated.py](https://app.codecov.io/gh/scverse/scanpy/pull/3333?src=pr&el=tree&filepath=src%2Fscanpy%2Fget%2F_aggregated.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9nZXQvX2FnZ3JlZ2F0ZWQucHk=) | 75.00% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3333?src=pr&el=tree&utm_medium=referral&utm,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3333#issuecomment-2449625873:1084,Patch,Patch,1084,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3333#issuecomment-2449625873,1,['Patch'],['Patch']
Deployability,/gh/scverse/scanpy/pull/3339?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `76.92308%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 77.24%. Comparing base [(`0d04447`)](https://app.codecov.io/gh/scverse/scanpy/commit/0d04447448747337e2d3adb15ecdfdbfa1ad91c7?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`41666cf`)](https://app.codecov.io/gh/scverse/scanpy/commit/41666cffcc228a2ebe0c1837e87c074c5d097367?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3339?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3339?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvX19pbml0X18ucHk=) | 62.50% | [3 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3339?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3339 +/- ##; =======================================; Coverage 77.23% 77.24% ; =======================================; Files 111 111 ; Lines 12608 12609 +1 ; =======================================; + Hits 9738 9740 +2 ; + Misses 2870 2869 -1 ; ```. | [Files with missing lines](https://app.codecov.io/gh/scve,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3339#issuecomment-2456762349:1084,Patch,Patch,1084,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3339#issuecomment-2456762349,1,['Patch'],['Patch']
Deployability,/preprocessing/_simple.py::scanpy.preprocessing._simple.filter_cells; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-200n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/plotting/_baseplot_class.py::scanpy.plotting._baseplot_class.BasePlot.add_totals; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-200n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-100theta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-inftheta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILE,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:27535,pipeline,pipeline,27535,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['pipeline'],['pipeline']
Deployability,/scanpy/pull/3336?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `90.00000%` with `4 lines` in your changes missing coverage. Please review.; > Project coverage is 77.22%. Comparing base [(`dda1f6e`)](https://app.codecov.io/gh/scverse/scanpy/commit/dda1f6eafad19e1a53947c54401ac4573b0a1cc3?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`c4a1e0a`)](https://app.codecov.io/gh/scverse/scanpy/commit/c4a1e0a829f553e14a91be9c1e441345e6b9a66c?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 5 commits behind head on ig/fix_pca_args. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3336?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/\_utils/\_\_init\_\_.py](https://app.codecov.io/gh/scverse/scanpy/pull/3336?src=pr&el=tree&filepath=src%2Fscanpy%2F_utils%2F__init__.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9fdXRpbHMvX19pbml0X18ucHk=) | 83.33% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3336?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/get/\_aggregated.py](https://app.codecov.io/gh/scverse/scanpy/pull/3336?src=pr&el=tree&filepath=src%2Fscanpy%2Fget%2F_aggregated.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9nZXQvX2FnZ3JlZ2F0ZWQucHk=) | 75.00% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3336?src=pr&el=tree&utm_medium=referral&utm,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3336#issuecomment-2450270276:1095,Patch,Patch,1095,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3336#issuecomment-2450270276,1,['Patch'],['Patch']
Deployability,/scverse/scanpy/pull/3142?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `86.66667%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.50%. Comparing base [(`e6e5328`)](https://app.codecov.io/gh/scverse/scanpy/commit/e6e532804a9c087ea37808f26395aa9ed038d6cb?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`a37840f`)](https://app.codecov.io/gh/scverse/scanpy/commit/a37840f6d72e7b3ad980c6603c310f2e5e2305c0?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 43 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3142?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/tools/\_score\_genes.py](https://app.codecov.io/gh/scverse/scanpy/pull/3142?src=pr&el=tree&filepath=src%2Fscanpy%2Ftools%2F_score_genes.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS90b29scy9fc2NvcmVfZ2VuZXMucHk=) | 86.66% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3142?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## 1.10.x #3142 +/- ##; =======================================; Coverage 76.50% 76.50% ; =======================================; Files 109 109 ; Lines 12474 12485 +11 ; =======================================; + Hits 9543 9552 +9 ; - Misses 2931 2933 +2 ; ```. | [Files with missing lines](https://app.codecov.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3142#issuecomment-2209117430:1087,Patch,Patch,1087,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3142#issuecomment-2209117430,1,['Patch'],['Patch']
Deployability,/scverse/scanpy/pull/3243?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `25.00000%` with `3 lines` in your changes missing coverage. Please review.; > Project coverage is 76.75%. Comparing base [(`bd75839`)](https://app.codecov.io/gh/scverse/scanpy/commit/bd758395a669c31a6c9eaa9239750fde368d3ca7?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`c06bbc8`)](https://app.codecov.io/gh/scverse/scanpy/commit/c06bbc83218ee426fa54e681ab39c8006e1668c0?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3243?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/plotting/\_stacked\_violin.py](https://app.codecov.io/gh/scverse/scanpy/pull/3243?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_stacked_violin.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fc3RhY2tlZF92aW9saW4ucHk=) | 25.00% | [3 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3243?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3243 +/- ##; ==========================================; + Coverage 76.49% 76.75% +0.25% ; ==========================================; Files 109 109 ; Lines 12544 12548 +4 ; ==========================================; + Hits 9596 9631 +35 ; + Misses 2948 2917 -31 ; ```. | [Files with m,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3243#issuecomment-2363207170:1084,Patch,Patch,1084,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3243#issuecomment-2363207170,1,['Patch'],['Patch']
Deployability,/scverse/scanpy/pull/3250?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `87.87879%` with `4 lines` in your changes missing coverage. Please review.; > Project coverage is 76.71%. Comparing base [(`ffebf12`)](https://app.codecov.io/gh/scverse/scanpy/commit/ffebf124f8a7da65a85622a07c7037ca477bfbef?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`2b269f7`)](https://app.codecov.io/gh/scverse/scanpy/commit/2b269f7a7e579f2ab5af52f240a1e86f93c118b2?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 2 commits behind head on 1.10.x. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3250?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/external/tl/\_wishbone.py](https://app.codecov.io/gh/scverse/scanpy/pull/3250?src=pr&el=tree&filepath=src%2Fscanpy%2Fexternal%2Ftl%2F_wishbone.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9leHRlcm5hbC90bC9fd2lzaGJvbmUucHk=) | 50.00% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3250?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |; | [src/scanpy/plotting/\_anndata.py](https://app.codecov.io/gh/scverse/scanpy/pull/3250?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_anndata.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fYW5uZGF0YS5weQ==) | 75.00% | [1 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3250?src=pr&el=tre,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3250#issuecomment-2363580091:1086,Patch,Patch,1086,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3250#issuecomment-2363580091,1,['Patch'],['Patch']
Deployability,/scverse/scanpy/pull/3252?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) Report; Attention: Patch coverage is `33.33333%` with `2 lines` in your changes missing coverage. Please review.; > Project coverage is 76.74%. Comparing base [(`e27e257`)](https://app.codecov.io/gh/scverse/scanpy/commit/e27e257964c358acb3a9a83e4289cccfdfa425ae?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) to head [(`0744da6`)](https://app.codecov.io/gh/scverse/scanpy/commit/0744da68e4f3593a81bed752d387bd2ca12a5e09?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse).; > Report is 1 commits behind head on main. | [Files with missing lines](https://app.codecov.io/gh/scverse/scanpy/pull/3252?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) | Patch % | Lines |; |---|---|---|; | [src/scanpy/plotting/\_stacked\_violin.py](https://app.codecov.io/gh/scverse/scanpy/pull/3252?src=pr&el=tree&filepath=src%2Fscanpy%2Fplotting%2F_stacked_violin.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse#diff-c3JjL3NjYW5weS9wbG90dGluZy9fc3RhY2tlZF92aW9saW4ucHk=) | 33.33% | [2 Missing :warning: ](https://app.codecov.io/gh/scverse/scanpy/pull/3252?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=scverse) |. <details><summary>Additional details and impacted files</summary>. ```diff; @@ Coverage Diff @@; ## main #3252 +/- ##; ==========================================; - Coverage 76.75% 76.74% -0.02% ; ==========================================; Files 109 109 ; Lines 12556 12559 +3 ; ==========================================; + Hits 9637 9638 +1 ; - Misses 2919 2921 +2 ; ```. | [Flag](https://,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3252#issuecomment-2363846754:1084,Patch,Patch,1084,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3252#issuecomment-2363846754,1,['Patch'],['Patch']
Deployability,/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot3-fn2] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_heatmap - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot-fn5] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_var_dict-fn6] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[matrixplot_std_scale_group-fn7] - AssertionError: Error: Image files did not match.; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_plotting.py::test_dotplot_matrixplot_stacked_violin[dotplot_std_scale_group-fn3] - AssertionError: Erro,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:42989,pipeline,pipeline,42989,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['pipeline'],['pipeline']
Deployability,"0); Requirement already satisfied: packaging in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (21.3); Requirement already satisfied: numpy>=1.19.0 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (1.21.5); Requirement already satisfied: numexpr>=2.6.2 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from tables) (2.8.1); Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\users\hyjfo\.conda\envs\newpy38\lib\site-packages (from packaging->tables) (3.0.4). import tables. ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_8256/574719567.py in <module>; ----> 1 import tables. ~\.conda\envs\NewPy38\lib\site-packages\tables\__init__.py in <module>; 43 ; 44 # Necessary imports to get versions stored on the cython extension; ---> 45 from .utilsextension import get_hdf5_version as _get_hdf5_version; 46 ; 47 . ImportError: DLL load failed while importing utilsextension; ```; Step 3: As you recommend, I do `!pip uninstall tables` and `conda install -c conda-forge pytables`, then; ```python; import tables # pass. import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_15024/1710492625.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\NewPy38\lib\site-packages\scanpy\__init__.py in <module>; 4 ; 5 if not within_flit(): # see function docstring on why this is there; ----> 6 from ._utils import check_versions; 7 ; 8 check_versions(). ~\.conda\envs\NewPy38\lib\site-packages\scanpy\_utils\__init__.py in <module>; 19 from numpy import random; 20 from scipy import sparse; ---> 21 from anndata import AnnData, __version__ as anndata_version; 22 from textwrap import dedent; 23 f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841:3591,install,install,3591,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108#issuecomment-1012790841,1,['install'],['install']
Deployability,"0.0 is not a release, it's just a dummy tag. if you upgrade now, the version will be `0.0+216.g2d10bdd`, where `0.0` marks the initial commit, `+216` one is 216 commits later, and `g2d10bdd` marks the installed commit",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/15#issuecomment-298314807:13,release,release,13,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/15#issuecomment-298314807,3,"['install', 'release', 'upgrade']","['installed', 'release', 'upgrade']"
Deployability,00n-inftheta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-100theta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-100n-100theta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-100n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:38267,pipeline,pipeline,38267,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['pipeline'],['pipeline']
Deployability,00theta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.True-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-int64-100n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-100theta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.True-legend.on_right-groups.all] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-100n-100theta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-100theta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-100theta-30clip-subset] - NotImplementedError: Failed in,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:31998,pipeline,pipeline,31998,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['pipeline'],['pipeline']
Deployability,"0].__class__)(*args, **kw); > scanpy/preprocessing/_simple.py:888: in scale_anndata; > X, adata.var[""mean""], adata.var[""std""] = do_scale(; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:468: in _compile_for_args; > error_rewrite(e, 'typing'); > _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; > ; > e = TypingError('Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of ...y the following argument(s):\n- argument 0: Cannot determine Numba type of <class \'scipy.sparse._csr.csr_matrix\'>\n'); > issue_type = 'typing'; > ; > def error_rewrite(e, issue_type):; > """"""; > Rewrite and raise Exception `e` with help supplied based on the; > specified issue_type.; > """"""; > if config.SHOW_HELP:; > help_msg = errors.error_extras[issue_type]; > e.patch_message('\n'.join((str(e).rstrip(), help_msg))); > if config.FULL_TRACEBACKS:; > raise e; > else:; > > raise e.with_traceback(None); > E numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); > E non-precise type pyobject; > E During: typing of argument at /home/zeth/PycharmProjects/scanpy/scanpy/preprocessing/_simple.py (763); > E ; > E File ""scanpy/preprocessing/_simple.py"", line 763:; > E def do_scale(X, maxv, nthr):; > E <source elided>; > E # t0= time.time(); > E s = np.zeros((nthr, X.shape[1])); > E ^ ; > E ; > E This error may have been caused by the following argument(s):; > E - argument 0: Cannot determine Numba type of <class 'scipy.sparse._csr.csr_matrix'>; > ; > ../../miniconda3/envs/scanpy/lib/python3.9/site-packages/numba/core/dispatcher.py:409: TypingError; > ```; > ; > When trying to use the new flavor with the existing test. Hi @Zethson ,; We are not able to see this issue with the latest commit. Can you please retry with the latest commit in scale branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717:2160,pipeline,pipeline,2160,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457#issuecomment-1540006717,1,['pipeline'],['pipeline']
Deployability,0n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-int64-200n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/preprocessing/_simple.py::scanpy.preprocessing._simple.filter_cells; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-200n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/plotting/_baseplot_class.py::scanpy.plotting._baseplot_class.BasePlot.add_totals; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-200n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-100theta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-inftheta-noclip-subset] - NotImpl,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:26992,pipeline,pipeline,26992,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['pipeline'],['pipeline']
Deployability,"1. How do we xfail stuff from `dev`? https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=108 It looks like the UMAP package via `pynndescent` is using something that has been removed (`np.infty`) in an upcoming release of numpy; 2. Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3048#issuecomment-2112257384:314,release,release,314,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048#issuecomment-2112257384,1,['release'],['release']
Deployability,"1. No, I have sampled cells with weights, out of those 1000 rows most; having weight=1, e.g. 1 row has weight 125, then in gene ranking the; expression all genes will multiplied with that specific weight of cell, so; I updated code by calculated weighted mean and variance. Before updating; this I was getting wrong marker genes. Same for plotting points in dotplot,; stacked_violin and heatmap. 2. I suggest that scanpy should support weighted data, I mean PCA should; also be computed for data with weighted observations (PCA in matlab support; weighted observations). Currently my input is weighted PCA data for; clustering, so I don't need to update PCA code, but in future it will be a; good thing to support scanpy for weighted sampled data as well. Thanks,; Khalid. On Tue, May 21, 2019 at 3:00 AM MalteDLuecken <notifications@github.com>; wrote:. > So you want to e.g., downweight the likelihood of sampling cells with a; > particular feature (like a common cell type), and upweight others. What do; > you want to use this weighting for now in the sc.tl.rank_genes_groups; > function? Or in the visualization functions you changed?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/theislab/scanpy/pull/644?email_source=notifications&email_token=ABREGOHR7Q62WL6MCWX7UWTPWLYOLA5CNFSM4HMZ5G72YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODVZYS3I#issuecomment-494111085>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABREGOHHMFZBUTLM4VIJCTLPWLYOLANCNFSM4HMZ5G7Q>; > .; >",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/644#issuecomment-494119134:219,update,updated,219,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/644#issuecomment-494119134,2,['update'],"['update', 'updated']"
Deployability,"2); ```. This is my session_info:. ```; Click to view session information; -----; anndata 0.9.2; loguru 0.7.2; matplotlib 3.8.0; numpy 1.26.0; pandas 1.4.3; scanpy 1.9.6; seaborn 0.12.2; session_info 1.0.0; -----; Click to view modules imported as dependencies; PIL 9.4.0; argcomplete NA; asttokens NA; attr 23.1.0; awkward 2.4.2; awkward_cpp NA; backcall 0.2.0; cffi 1.15.1; comm 0.1.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; dot_parser NA; etils 1.4.1; exceptiongroup 1.1.3; executing 1.2.0; get_annotations NA; gmpy2 2.1.2; h5py 3.9.0; harmonypy NA; igraph 0.10.8; importlib_metadata NA; importlib_resources NA; ipykernel 6.25.2; ipywidgets 8.1.1; jax 0.4.20; jaxlib 0.4.20; jedi 0.19.0; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.41.1; ml_dtypes 0.2.0; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; numba 0.58.1; nvfuser NA; opt_einsum v3.0.0; packaging 23.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.10.0; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 13.0.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydot 1.4.2; pygments 2.16.1; pynndescent 0.5.5; pyparsing 3.0.9; pytz 2023.3.post1; rich NA; scipy 1.10.1; setuptools 68.0.0; six 1.16.0; sklearn 1.3.2; sparse 0.14.0; stack_data 0.6.2; statsmodels 0.13.1; sympy 1.11.1; texttable 1.6.7; threadpoolctl 3.2.0; torch 2.0.1; tornado 6.3.3; tqdm 4.66.1; traitlets 5.10.0; typing_extensions NA; umap 0.5.3; wcwidth 0.2.6; yaml 6.0; zipp NA; zmq 25.1.1; -----; IPython 8.15.0; jupyter_client 8.3.1; jupyter_core 5.3.1; -----; Python 3.9.18 (main, Sep 11 2023, 13:41:44) [GCC 11.2.0]; Linux-6.2.0-36-generic-x86_64-with-glibc2.35; -----; Session information updated at 2023-11-23 00:08; ```. I uploaded the ipynb file as attachment. 👇. [harmony_test.ipynb.zip](https://github.com/scverse/scanpy/files/13441924/harmony_test.ipynb.zip)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227:4731,update,updated,4731,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655#issuecomment-1823084227,1,['update'],['updated']
Deployability,"3.1.0; babel 2.12.1; backcall 0.2.0; certifi 2023.05.07; cffi 1.15.1; charset_normalizer 3.1.0; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.6.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; fastjsonschema NA; google NA; h5py 3.9.0; idna 3.4; igraph 0.10.4; importlib_resources NA; ipykernel 6.23.3; ipython_genutils 0.2.0; ipywidgets 8.0.6; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.6.0; jupyterlab_server 2.23.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.0; louvain 0.8.0; markupsafe 2.1.3; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.4.0; nbformat 5.9.0; numba 0.57.0; numexpr 2.8.4; numpy 1.24.3; objc 9.2; overrides NA; packaging 23.1; pandas 2.0.2; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.8.0; prometheus_client NA; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pvectorc NA; pydev_jupyter_utils NA; pydev_jupyter_vars NA; pydevconsole NA; pydevd_file_utils NA; pydevd_plugins NA; pygments 2.15.1; pyparsing 3.1.0; pyrsistent NA; pythonjsonlogger NA; pytz 2023.3; requests 2.31.0; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; scipy 1.11.0; seaborn 0.12.2; send2trash NA; session_info 1.0.0; setuptools 68.0.0; six 1.16.0; sklearn 1.2.2; sniffio 1.3.0; socks 1.7.1; stack_data 0.6.2; statsmodels 0.14.0; texttable 1.6.7; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; torch 1.12.1; tornado 6.3.2; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; urllib3 2.0.3; wcwidth 0.2.6; websocket 1.6.1; yaml 6.0; zipp NA; zmq 25.1.0; zoneinfo NA; -----; IPython 8.14.0; jupyter_client 8.3.0; jupyter_core 5.3.1; jupyterlab 4.0.2; notebook 6.5.4; -----; Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:42:20) [Clang 14.0.6 ]; macOS-12.6.6-x86_64-i386-64bit; -----; Session information updated at 2023-06-26 14:43. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2531#issuecomment-1608050519:2314,update,updated,2314,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531#issuecomment-1608050519,1,['update'],['updated']
Deployability,"4 impl,. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 714 pipeline = pipeline_class(typingctx, targetctx, library,; 715 args, return_type, flags, locals); --> 716 return pipeline.compile_extra(func); 717 ; 718 . C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in compile_extra(self, func); 450 self.state.lifted = (); 451 self.state.lifted_from = None; --> 452 return self._compile_bytecode(); 453 ; 454 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in _compile_bytecode(self); 518 """"""; 519 assert self.state.func_ir is None; --> 520 return self._compile_core(); 521 ; 522 def _compile_ir(self):. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 497 self.state.status.fail_reason = e; 498 if is_final_pipeline:; --> 499 raise e; 500 else:; 501 raise CompilerError(""All available pipelines exhausted""). C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler.py in _compile_core(self); 484 res = None; 485 try:; --> 486 pm.run(self.state); 487 if self.state.cr is not None:; 488 break. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 366 (self.pipeline_name, pass_desc); 367 patched_exception = self._patch_error(msg, e); --> 368 raise patched_exception; 369 ; 370 def dependency_analysis(self):. C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler_machinery.py in run(self, state); 354 pass_inst = _pass_registry.get(pss).pass_inst; 355 if isinstance(pass_inst, CompilerPass):; --> 356 self._runPass(idx, pass_inst, state); 357 else:; 358 raise BaseException(""Legacy pass in use""). C:\ProgramData\Anaconda3\lib\site-packages\numba\core\compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 33 def _acquire_compile_lock(*args, **kwargs):; 34 with self:; ---> 35 r",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325:8294,pipeline,pipelines,8294,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1756#issuecomment-1319286325,1,['pipeline'],['pipelines']
Deployability,4-100n-100theta-infclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_embedding_plots.py::test_missing_values_categorical[pca-na_color.black_tup-na_in_legend.False-legend.on_right-groups.3] - numpy.core._exceptions._UFuncNoLoopError: ufunc 'equal' did not contain a loop with signature matching types (<class 'n...; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-100n-100theta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-100n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-200n-inftheta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-int64-100n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-inftheta-infclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED sca,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:38503,pipeline,pipeline,38503,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['pipeline'],['pipeline']
Deployability,4-200n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-100n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-int64-200n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/preprocessing/_simple.py::scanpy.preprocessing._simple.filter_cells; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-200n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/plotting/_baseplot_class.py::scanpy.plotting._baseplot_class.BasePlot.add_totals; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-100n-100theta-noclip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-200n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-100theta-infclip-subset] - NotImplementedError: ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:26777,pipeline,pipeline,26777,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['pipeline'],['pipeline']
Deployability,"48/lib/site-packages/numba/core/dispatcher.py?line=157) # Check typing error if object mode is used; [159](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/dispatcher.py?line=158) if cres.typing_error is not None and not flags.enable_pyobject:. File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); [669](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=668) """"""Compiler entry point; [670](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=669) ; [671](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=670) Parameter; (...); [689](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=688) compiler pipeline; [690](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=689) """"""; [691](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=690) pipeline = pipeline_class(typingctx, targetctx, library,; [692](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=691) args, return_type, flags, locals); --> [693](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=692) return pipeline.compile_extra(func). File D:\Users\xiangrong1\Miniconda3\envs\py48\lib\site-packages\numba\core\compiler.py:429, in CompilerBase.compile_extra(self, func); [427](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=426) self.state.lifted = (); [428](file:///d%3A/Users/xiangrong1/Miniconda3/envs/py48/lib/site-packages/numba/core/compiler.py?line=427) self.state.lifted_from = None; --> [429](file:///d%3A/Users/xiangrong1/Miniconda3/envs",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659:18717,pipeline,pipeline,18717,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160#issuecomment-1107838659,1,['pipeline'],['pipeline']
Deployability,"4f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; Running command python setup.py egg_info; Traceback (most recent call last):; File ""<string>"", line 2, in <module>; File ""<pip-setuptools-caller>"", line 34, in <module>; File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:; # manifest_maker: standard file '""'""'-c'""'""' not found"".; # - It generates a shim setup.py, for handl",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:2610,install,install,2610,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['install'],['install']
Deployability,"51d9588484449eb116f16ee1b89979/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; cwd: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/; Preparing metadata (setup.py) ... error; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output. note: This is an issue with the package mentioned above, not pip.; hint: See above for details.; Exception information:; Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/operations/build/metadata_legacy.py"", line 64, in generate_metadata; call_subprocess(; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/utils/subprocess.py"", line 224, in call_subprocess; raise error; pip._internal.exceptions.InstallationSubprocessError: python setup.py egg_info exited with 1. The above exception was the direct cause of the following exception:. Traceback (most recent call last):; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/base_command.py"", line 160, in exc_logging_wrapper; status = run_func(*args); ^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/cli/req_command.py"", line 247, in wrapper; return func(self, options, args); ^^^^^^^^^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/commands/install.py"", line 400, in run; requirement_set = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py"", line 92, in resolve; result = self._result = resolver.resolve(; ^^^^^^^^^^^^^^^^^; File ""/Users/dang/opt/miniconda3/envs2/test/lib/python3.11/site-packages/pip/_ve",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:5262,Install,InstallationSubprocessError,5262,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['Install'],['InstallationSubprocessError']
Deployability,"52 loess_outputs, loess_prediction,; 53 loess_confidence_intervals, loess_anova). ImportError: DLL load failed while importing _loess: The specified module could not be found.; ```; Step5: run `import skmisc; print(skmisc.__file__)`; ```python; import skmisc; print(skmisc.__file__); C:\Users\Park_Lab\AppData\Roaming\Python\Python38\site-packages\skmisc\__init__.py; ```; Step6: due to Step4, I follow the solution (https://github.com/has2k1/scikit-misc/issues/4) to install Numpy with mkl.; ```python; (base) C:\Users\Park_Lab>conda activate Python38; (Python38) C:\Users\Park_Lab>cd Downloads/; (Python38) C:\Users\Park_Lab\Downloads>pip install numpy-1.21.5+mkl-cp38-cp38-win_amd64.whl; Processing c:\users\park_lab\downloads\numpy-1.21.5+mkl-cp38-cp38-win_amd64.whl; Installing collected packages: numpy; Attempting uninstall: numpy; Found existing installation: numpy 1.21.5; Uninstalling numpy-1.21.5:; Successfully uninstalled numpy-1.21.5; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.21.5+mkl which is incompatible.; Successfully installed numpy-1.21.5+mkl; ```; Step7: check anaconda Python38 environment, numpy-1.21.5+mkl is successfully installed; ![image](https://user-images.githubusercontent.com/75048821/147306587-eb94c188-5c18-40f0-add0-3a899872d786.png). Step8: Scanpy import error. Numpy>v1.20 is conflicted with Scanpy; ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600); ; import scvelo as scv; scv.settings.verbosity = 3; scv.settings.presenter_view = True; scv.logging.print_versions(). import cellrank as cr; cr.settings.verbosity = 3; cr.logging.print_versions(). import matplotlib.pyplot as pl; from matplotlib impor",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342:4804,install,installed,4804,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1000601342,1,['install'],['installed']
Deployability,"6.4.tar.gz"" in the cache; Current age based on date: 1302943; Ignoring unknown cache-control directive: immutable; Freshness lifetime from max-age: 365000000; The response is ""fresh"", returning cached response; 365000000 > 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; Running command python setup.py egg_info; Traceback (most recent call last):; File ""<string>"", line 2, in <module>; File ""<pip-setuptools-caller>"", line 34, in <module>; File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:2266,install,install-,2266,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['install'],['install-']
Deployability,"8 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/Desktop/data/env/lib/python3.11/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. I've pasted the output of scanpy.logging.print_versions() details below as requested, which includes a verification of used scanpy version (latest version, 1.9.3). It may not be important, but I also had to install `leidenalg` manually in the middle of the tutorial. That's the only deviation I made from the original tutorial. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 10.0.0; appnope 0.1.3; asttokens NA; backcall 0.2.0; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; h5py 3.9.0; igraph 0.10.6; ipykernel 6.25.0; jedi 0.18.2; joblib 1.3.1; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.40.1; matplotlib 3.7.2; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numpy 1.24.4; packaging 23.1; pandas 2.0.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.9.1; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pyparsing 3.0.9; pytz 2023.3; scipy 1.11.1; session_info 1.0.0; sitecustomize NA; six 1.16.0; sklearn 1.3.0; stack_data 0.6.2; texttable 1.6.7; ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453:2220,install,install,2220,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440#issuecomment-1652367453,1,['install'],['install']
Deployability,"99 (= 3.5-2),; libxau6 (= 1:1.0.9-1),; libxcb-render0 (= 1.14-3),; libxcb-shm0 (= 1.14-3),; libxcb1 (= 1.14-3),; libxcomposite1 (= 1:0.4.5-1),; libxcursor1 (= 1:1.2.0-2),; libxdamage1 (= 1:1.1.5-2),; libxdmcp6 (= 1:1.1.2-3),; libxext6 (= 2:1.3.4-1),; libxfixes3 (= 1:5.0.3-2),; libxft2 (= 2.3.2-2),; libxi6 (= 2:1.8-1),; libxinerama1 (= 2:1.1.4-2),; libxkbcommon0 (= 1.3.1-1),; libxml2 (= 2.9.12+dfsg-5),; libxrandr2 (= 2:1.5.2-1),; libxrender1 (= 1:0.9.10-1),; libxss1 (= 1:1.2.3-1),; libz3-4 (= 4.8.12-1+b1),; libzstd1 (= 1.4.8+dfsg-3),; linux-libc-dev (= 5.14.16-1),; llvm-11 (= 1:11.1.0-4),; llvm-11-linker-tools (= 1:11.1.0-4),; llvm-11-runtime (= 1:11.1.0-4),; login (= 1:4.8.1-2),; lsb-base (= 11.1.0),; m4 (= 1.4.18-5),; mailcap (= 3.70),; make (= 4.3-4.1),; man-db (= 2.9.4-2),; mawk (= 1.3.4.20200120-2),; media-types (= 4.0.0),; mime-support (= 3.66),; mount (= 2.37.2-4),; ncurses-base (= 6.2+20210905-1),; ncurses-bin (= 6.2+20210905-1),; openssl (= 1.1.1l-1),; passwd (= 1:4.8.1-2),; patch (= 2.7.6-7),; perl (= 5.32.1-6),; perl-base (= 5.32.1-6),; perl-modules-5.32 (= 5.32.1-6),; po-debconf (= 1.0.21+nmu1),; procps (= 2:3.3.17-5),; python-matplotlib-data (= 3.3.4-2),; python-tables-data (= 3.6.1-5),; python3 (= 3.9.7-1),; python3-all (= 3.9.7-1),; python3-anndata (= 0.7.5+ds-3),; python3-asciitree (= 0.3.3-3),; python3-attr (= 20.3.0-1),; python3-certifi (= 2020.6.20-1),; python3-cffi-backend (= 1.15.0-1),; python3-chardet (= 4.0.0-1),; python3-cov-core (= 1.15.0-3),; python3-coverage (= 5.1+dfsg.1-2+b2),; python3-cryptography (= 3.3.2-1),; python3-cycler (= 0.11.0-1),; python3-dateutil (= 2.8.1-6),; python3-decorator (= 4.4.2-2),; python3-distutils (= 3.9.8-1),; python3-docutils (= 0.17.1+dfsg-2),; python3-fasteners (= 0.14.1-2),; python3-gi (= 3.42.0-1+b1),; python3-h5py (= 3.3.0-5),; python3-h5py-serial (= 3.3.0-5),; python3-harmony (= 0.7.1-1),; python3-idna (= 2.10-1),; python3-igraph (= 0.9.6-1),; python3-importlib-metadata (= 4.6.4-1),; python3-iniconfig (= 1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2048#issuecomment-969885616:10418,patch,patch,10418,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048#issuecomment-969885616,1,['patch'],['patch']
Deployability,:test_highly_variable_genes_pearson_residuals_general[csr_matrix-float32-100n-inftheta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-30clip-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[csr_matrix-float32-200n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-int64-200n-subset] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-100n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-int64-200n-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[toarray-float32-100n-100theta-noclip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/preprocessing/_simple.py::scanpy.preprocessing._simple.filter_cells; FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_general[csr_matrix-int64-200n-100theta-30clip-full] - NotImplementedError: Failed in nopython mode pipeline (step: analyzing bytecode); FAILED scanpy/tests/test_highly_variable_genes.py::test_highly_variable_genes_pearson_residuals_batch[toarray-float32-200n-subset] - NotImplementedError: Failed in nopython mode pipeli,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515:26020,pipeline,pipeline,26020,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2816#issuecomment-1895708515,1,['pipeline'],['pipeline']
Deployability,"; Package matplotlib conflicts for:; scanpy -> matplotlib[version='3.0.*|>=2.2']; Package scikit-learn conflicts for:; scanpy -> scikit-learn[version='>=0.21.2']; Package natsort conflicts for:; scanpy -> natsort; Package openssl conflicts for:; python=3.7 -> openssl[version='>=1.0.2o,<1.0.3a|>=1.0.2p,<1.0.3a|>=1.1.1a,<1.1.2a|>=1.1.1b,<1.1.2a|>=1.1.1c,<1.1.2a|>=1.1.1d,<1.1.2a']; Package importlib_metadata conflicts for:; scanpy -> importlib_metadata[version='>=0.7']; ```. I can import `scanpy` by opening Python 3 interpreter from the terminal by running `python`. ```; Python 3.7.5 (default, Oct 25 2019, 15:51:11); [GCC 7.3.0] :: Anaconda, Inc. on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import scanpy as sc # this works; ```. Check the `PATH`:. ```; ['', '/home/tsundoku/anaconda3/lib/python37.zip', '/home/tsundoku/anaconda3/lib/python3.7', '/home/tsundoku/anaconda3/lib/python3.7/lib-dynload', '/home/tsundoku/.local/lib/python3.7/site-packages', '/home/tsundoku/anaconda3/lib/python3.7/site-packages']; ```. But it fails to load from `reticulate`. ```; library(reticulate); repl_python(); ```. ```; import pandas as pd; import scanpy as sc; ```. ```; ModuleNotFoundError: No module named 'scanpy'; ```. Check the `PATH`:. ```; import sys; sys.path; ```. ```; ['', '/home/tsundoku/.local/share/r-miniconda/envs/r-reticulate/bin', '/home/tsundoku/.local/share/r-miniconda/envs/r-reticulate/lib/python36.zip', '/home/tsundoku/.local/share/r-miniconda/envs/r-reticulate/lib/python3.6', '/home/tsundoku/.local/share/r-miniconda/envs/r-reticulate/lib/python3.6/lib-dynload', '/home/tsundoku/.local/share/r-miniconda/envs/r-reticulate/lib/python3.6/site-packages', '/home/tsundoku/R/x86_64-pc-linux-gnu-library/3.6/reticulate/python']; ```. Okay so `scanpy` is installed but the `PATH` are different. Not sure why `py_install()` doesn't work. I guess the alternative is including the those paths for reticulate but not sure at the moment how to do that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990#issuecomment-575281452:15253,install,installed,15253,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990#issuecomment-575281452,1,['install'],['installed']
Deployability,"; pvectorc NA; pygments 2.9.0; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.25.1; scanpy 1.7.2; scipy 1.5.3; seaborn 0.11.1; send2trash NA; setuptools_scm NA; sinfo 0.3.1; six 1.16.0; sklearn 0.24.2; sniffio 1.2.0; socks 1.7.1; sphinxcontrib NA; statsmodels 0.12.2; storemagic NA; tables 3.6.1; tblib 1.7.0; terminado 0.10.0; texttable 1.6.3; tlz 0.11.0; toolz 0.11.1; tornado 6.1; traitlets 5.0.5; typing_extensions NA; urllib3 1.26.4; wcwidth 0.2.5; websocket 0.57.0; yaml 5.4.1; zmq 22.0.3; zope NA; -----; IPython 7.23.1; jupyter_client 6.1.12; jupyter_core 4.7.1; jupyterlab 3.0.16; notebook 6.4.0; -----; Python 3.8.10 (default, May 19 2021, 18:05:58) [GCC 7.3.0]; Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.10; 4 logical CPU cores, x86_64; -----; Session information updated at 2021-05-25 15:50. </Details>. I'm still trying to update h5py in the old environment, which has quite some inconsistencies in it, considerably slowing everything down. At some point it looked like I had success with installing h5py 3.2.1 from conda-forge after running `conda update anaconda` and `conda update --all` (as per [here](https://stackoverflow.com/questions/56072846/how-to-resolve-inconsistent-package-warnings-in-conda)). But now this environment leads to an ImportError when importing scanpy: `ImportError: /home/karl/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/h5py/defs.cpython-38-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_ros3`; Can it be that pip version of scanpy doesn't see the updated conda version of h5py?. <Details>; <summary>Inconsistencies in the old environment</summary>. ```; The following packages are causing the inconsistency:. - defaults/linux-64::_anaconda_depends==2020.07=py38_0; - defaults/linux-64::anaconda==custom=py38_1; - defaults/linux-64::cairo==1.14.12=h8948797_3; - defaults/linux-64::graphviz==2.40.1=h21bd128_2; - defaults/linux-64::harfbuzz==1.8.8=hffaf4a1_0; - conda-forge/linux-64::leidenalg==0.8.2=py38habedc41_0; - defaults/linux",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310:2198,install,installing,2198,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-847928310,1,['install'],['installing']
Deployability,<details>; <summary>Installed scanpy on jupyter notebook/ anaconda: </summary>. ```; pip install scanpy. Requirement already satisfied: scanpy in c:\users\charles\anaconda3\lib\site-packages (1.7.2); Requirement already satisfied: numba>=0.41.0 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.44.1); Requirement already satisfied: tables in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (3.7.0); Requirement already satisfied: anndata>=0.7.4 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.7.6); Requirement already satisfied: legacy-api-wrap in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.2); Requirement already satisfied: packaging in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (21.3); Requirement already satisfied: pandas>=0.21 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.3.4); Requirement already satisfied: scipy>=1.4 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.7.3); Requirement already satisfied: umap-learn>=0.3.10 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.5.1); Requirement already satisfied: h5py>=2.10.0 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (2.10.0); Requirement already satisfied: scikit-learn>=0.21.2 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.0.2); Requirement already satisfied: statsmodels>=0.10.0rc2 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.13.0); Requirement already satisfied: matplotlib>=3.1.2 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (3.5.1); Requirement already satisfied: numpy>=1.17.0 in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (1.21.5); Requirement already satisfied: seaborn in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (0.11.2); Requirement already satisfied: tqdm in c:\users\charles\anaconda3\lib\site-packages (from scanpy) (4.62.3); Requirement already satisfied: natsort in c:\users\charles\an,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626:20,Install,Installed,20,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063704626,2,"['Install', 'install']","['Installed', 'install']"
Deployability,<details>; <summary>pip list</summary>. ```; anndata 0.7.8; asttokens 2.0.5; bcrypt 3.2.0; Bottleneck 1.3.2; brotlipy 0.7.0; cached-property 1.5.2; certifi 2021.10.8; cffi 1.15.0; charset-normalizer 2.0.12; chart-studio 1.1.0; click 8.0.4; cmake 3.22.2; colorama 0.4.4; conda 4.11.0; conda-package-handling 1.7.3; cryptography 36.0.1; cycler 0.11.0; Cython 0.29.20; devtools 0.8.0; dunamai 1.9.0; executing 0.8.2; fa2 0.3.5; Fabric 1.6.1; fonttools 4.29.1; get_version 3.5.4; h5py 3.6.0; idna 3.3; igraph 0.9.9; install 1.3.5; joblib 1.1.0; kiwisolver 1.3.2; legacy-api-wrap 1.2; llvmlite 0.38.0; loom 0.0.18; loompy 3.0.6; mamba 0.15.3; matplotlib 3.5.1; mkl-fft 1.3.1; mkl-random 1.2.2; mkl-service 2.4.0; MulticoreTSNE 0.1; natsort 8.1.0; networkx 2.6.3; numba 0.55.1; numexpr 2.8.1; numpy 1.21.2; numpy-groupies 0.9.14; opt-einsum 3.3.0; packaging 21.3; pandas 1.4.1; paramiko 2.9.2; patsy 0.5.2; Pillow 9.0.1; pip 21.2.4; plotly 5.6.0; pycosat 0.6.3; pycparser 2.21; PyNaCl 1.5.0; pynndescent 0.5.6; pyOpenSSL 22.0.0; pyparsing 3.0.7; PyQt5 5.12.3; PyQt5_sip 4.19.18; PyQtChart 5.12; PyQtWebEngine 5.12.1; pyro-api 0.1.2; pyro-ppl 1.8.0; pysam 0.18.0; PySocks 1.7.1; python-dateutil 2.8.2; pytz 2021.3; requests 2.27.1; retrying 1.3.3; ruamel-yaml-conda 0.15.80; scanpy 1.7.0rc1; scikit-learn 1.0.2; scipy 1.7.3; seaborn 0.11.2; setuptools 58.0.4; sinfo 0.3.4; six 1.16.0; statsmodels 0.13.2; stdlib-list 0.8.0; tables 3.7.0; tenacity 8.0.1; texttable 1.6.4; threadpoolctl 3.1.0; torch 1.10.2; tornado 6.1; tqdm 4.62.3; umap-learn 0.4.6; unicodedata2 14.0.0; urllib3 1.26.8; velocyto 0.17.17; wheel 0.37.1; xlrd 1.2.0; ```. </details>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2169#issuecomment-1062402318:512,install,install,512,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169#issuecomment-1062402318,1,['install'],['install']
Deployability,"<samp>; <b>Supported commands</b><br>; <ul type=""none""><li><b>help:</b></li><ul type=""none""><li>Get descriptions, examples and documentation about supported commands</li><li><b>Example: </b>help ""command_name""</li></ul><li><b>list:</b></li><ul type=""none""><li>List all pipelines for this repository using a comment.</li><li><b>Example: </b>""list""</li></ul><li><b>run:</b></li><ul type=""none""><li>Run all pipelines or specific pipelines for this repository using a comment. Use this command by itself to trigger all related pipelines, or specify specific pipelines to run.</li><li><b>Example: </b>""run"" or ""run pipeline_name, pipeline_name, pipeline_name""</li></ul><li><b>where:</b></li><ul type=""none""><li>Report back the Azure DevOps orgs that are related to this repository and org</li><li><b>Example: </b>""where""</li></ul></ul><br>; See <a href=""https://go.microsoft.com/fwlink/?linkid=2056279"">additional documentation.</a>; </samp>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1398#issuecomment-738558280:269,pipeline,pipelines,269,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1398#issuecomment-738558280,5,['pipeline'],['pipelines']
Deployability,<samp>; Azure Pipelines successfully started running 1 pipeline(s).<br>. </samp>,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1398#issuecomment-738554080:14,Pipeline,Pipelines,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1398#issuecomment-738554080,30,"['Pipeline', 'pipeline']","['Pipelines', 'pipeline']"
Deployability,> * Either upgrade Scanpy to 1.10 (this PR has the fix for your problem): [matplotlib 3.7 compat #2414](https://github.com/scverse/scanpy/pull/2414); > * or upgrade Matplotlib to 3.8. My Anaconda prompts that I can't install Scanpy above 1.10 or Matplotlib above 3.8.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/3029#issuecomment-2077224770:11,upgrade,upgrade,11,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029#issuecomment-2077224770,3,"['install', 'upgrade']","['install', 'upgrade']"
Deployability,"> * Shouldn't `var_df` should get similar updates to `obs_df`?. I would suggest a different PR to address this. . > * Could we get tests for `get.obs_df`/ `get.var_df` for the issues you addressed here (repeated indices)?. Sure, I added new tests to `get.obs_df` to check duplicated keys.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1583#issuecomment-765255875:42,update,updates,42,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583#issuecomment-765255875,1,['update'],['updates']
Deployability,"> . No spesific reason, I just use the one come pre-installed. Thank you anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2208#issuecomment-1089099688:52,install,installed,52,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208#issuecomment-1089099688,1,['install'],['installed']
Deployability,> 1. Release note please. I'll do so. > 2. Why do we have `N_PCS` in the settings? Wasn't aware of that actually. I don't know I just came across this while working on RSC and thought the behavior was not what I expected. I hope that this is more in line with what the user intended.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2610#issuecomment-1677075979:5,Release,Release,5,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2610#issuecomment-1677075979,1,['Release'],['Release']
Deployability,"> 1302943; Using cached numba-0.56.4.tar.gz (2.4 MB); Added numba>=0.41.0 from https://files.pythonhosted.org/packages/e2/1e/de917b683bb5f0b6078fb1397293eab84c4eaa825fbf94d73d6488eb354f/numba-0.56.4.tar.gz (from scanpy) to build tracker '/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-build-tracker-740xp5sy'; Running setup.py (path:/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py) egg_info for package numba; Created temporary directory: /private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-pip-egg-info-tlduu_0q; Running command python setup.py egg_info; Traceback (most recent call last):; File ""<string>"", line 2, in <module>; File ""<pip-setuptools-caller>"", line 34, in <module>; File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 51, in <module>; _guard_py_ver(); File ""/private/var/folders/8z/k5cyvf4j5kl0mzc9vn1gf_2h0000gq/T/pip-install-3aknwjnh/numba_c251d9588484449eb116f16ee1b89979/setup.py"", line 48, in _guard_py_ver; raise RuntimeError(msg.format(cur_py, min_py, max_py)); RuntimeError: Cannot install on Python version 3.11.0; only versions >=3.7,<3.11 are supported.; error: subprocess-exited-with-error; ; × python setup.py egg_info did not run successfully.; │ exit code: 1; ╰─> See above for output.; ; note: This error originates from a subprocess, and is likely not a problem with pip.; full command: /Users/dang/opt/miniconda3/envs2/test/bin/python3.11 -c '; exec(compile('""'""''""'""''""'""'; # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py; #; # - It imports setuptools before invoking setup.py, to enable projects that directly; # import from `distutils.core` to work with newer packaging standards.; # - It provides a clear error message when setuptools is not installed.; # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so; # setu",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209:2439,install,install-,2439,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369#issuecomment-1332434209,1,['install'],['install-']
Deployability,"> 2. Have the info in notebook. I think I'd be happy to recommend calling `session_info` directly for this. IIRC, we have these functions at all because a package which did a good job of displaying the imported packages and dependencies didn't really exist. . > and leave print_versions unchanged?. With the update to use `session_info`?. I'd even be fine to deprecate the `file` argument, since it's not super useful. Plus `session_info` provides this, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2089#issuecomment-998063447:308,update,update,308,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2089#issuecomment-998063447,1,['update'],['update']
Deployability,"> 4\. Small differences in the edge weights of the nearest neighbor graph CAN lead to huge differences in the UMAP projection if the graph has no inherent structure. Exactly this! We have come across the difficulty of exactly reproducing the umap and clustering results in our [single-cell tutorial/best practices](www.github.com/theislab/single-cell-tutorial), however it was always due to the difficulty of defining boundaries in a continuous phenotype. Essentially, that means that the biological interpretations should not rely on this moving boundary anyway. On another note, you may have more luck with reproducibility by setting `PYTHONHASHSEED` as well. Check out the discussion here: #313.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1009#issuecomment-578344362:434,continuous,continuous,434,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009#issuecomment-578344362,1,['continuous'],['continuous']
Deployability,"> ; > ; > I had a same issue; > ; > My environment is; > ; > ```; > windows10; > python3.8.8 (conda env); > ```; > ; > scanpy installation; > `conda install -c conda-forge -c bioconda scanpy`; > ; > It looks work well on command prompt, but it wasn't work on jupyterlab(3.0); > ; > To solve this, I just installed all packages using pip, not conda.; > here is my install procedure; > ; > ```; > conda create -n test python=3.8; > pip install ipykernel; > pip install jupyterlab; > pip install scanpy; > pip install python-igraph; > pip install leidenalg; > pip install fa2; > ```; > ; > I tired a lot of install and environment combination, but always there was a problem with conda. Thanks! my scanpy was working but stopped reinstalling everything in a new environment again with pip got it working as you suggested",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/454#issuecomment-814972872:126,install,installation,126,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/454#issuecomment-814972872,11,['install'],"['install', 'installation', 'installed']"
Deployability,"> ; > ; > Seen this recently exactly on a windows laptop. Not sure but sound like something messed up with the environment, are you working on the base env? Try creating a fresh conda environment and installing scanpy there. Thanks for the suggestion, @giovp. Was doing it in the base env earlier. Made a new env and tried it again, but ran into the same exact error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1147#issuecomment-609495323:200,install,installing,200,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147#issuecomment-609495323,1,['install'],['installing']
Deployability,"> > @giovp looking at this again, it seems you drop the mixed up columns anyway ([scverse/squidpy@`fb069de`/squidpy/read/_read.py#L100](https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100)) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release.; > ; > Hi @stephenwilliams22 ,; > ; > we drop it from obs since we don't want to save spatial coordinates there, cause they should be only in obsm.; > ; > So the only changes between space rangers version is the name of the tissue position file correct? but the order of the columns remains the same?. Yes, this is correct.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2296#issuecomment-1273309536:397,release,release,397,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296#issuecomment-1273309536,1,['release'],['release']
Deployability,"> > Sorry for late reply, I think this was fixed in #1138. Could you update your scanpy and try again? For me it seems to work; > > ```python; > > fig, ax = plt.subplots(1,3, figsize=(20,6)); > > sc.pl.spatial(adata, img_key=""hires"", color=""array_row"", size=1.5, ax=ax[0], show=False); > > sc.pl.spatial(bdata, img_key=""hires"", color=""array_row"", size=1.5, ax=ax[1], show=False); > > sc.pl.spatial(cdata, img_key=""hires"", color=""array_row"", size=1.5, ax=ax[2], show=False); > > plt.tight_layout(pad=3.0); > > plt.show(); > > ```; > > ; > > ; > > ; > > ; > > ; > > ; > > ; > > ; > > ; > > ; > > ; > > ![image](https://user-images.githubusercontent.com/25887487/79438766-41165b80-7fd4-11ea-8ed7-f297b22da7c0.png); > ; > Hello, I have a problem, that is why some plots show colorbar but other plots show legend? It seems using same code. I've got the reason: if the data type is category, sc.pl.spetial would append lengend, in others conditon it would append colorbar.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1158#issuecomment-1454702754:69,update,update,69,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1158#issuecomment-1454702754,1,['update'],['update']
Deployability,> > Why have separate package registries for biology vs everything else?; >; > probably because bioconda predates conda-forge?. That would make sense! I think things like bioconda and the bioconductor registry were good things to start and have been very important. I just think some of the initial design decisions are now outdated. > The only downside of this is that we need to update that file manually for every release of scanpy/ anndata. Seems github action-able?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160598574:381,update,update,381,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281#issuecomment-1160598574,2,"['release', 'update']","['release', 'update']"
Deployability,"> > what about `X_coords` ?; > ; > Ha, I was mostly just trying to get rid of the `X_`! . ah right, anyway good for me!; > ; > > What about re-open the theislab/spatial branch and merge this PR there? I could then work on how to handle the new uns structure in the plotting functions and have a definitive version of multiple slices support in anndata.; > ; > I'd like to merge the changes currently in this PR to master since it fixes a bug with dataset reading. The changes to uns structure could go in another PR, but I'm waiting for an email back from 10x to make sure using the `library_id` as a key makes sense. Either way, the logic of getting the transformed coordinates etc. should be abstracted into a function so it's easy to change.; > . What do you mean by transformed coordinates? Also, to understand the inputs for anndata (output of spaceranger) you might have a look at this, if you are not already familiar with https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview. ; Also, ok for having `uns` changes in another PR, I can work on that as soon as this is merged.; > Update: heard back, the `library_id` should be fine, at least for this version.; > . good !. > > support for multiple slices should be first; > ; > I'm not sure I'm convinced of this. I've also already got some code ready to go for the connectivities and some examples of what can be done with it.; > ; > I'd like to hear what kind of stuff you want to be able to do with multiple slices. Are you interested in stitching together slides or holding arbitrary slides in an AnnData? I think I'd like to see a more fleshed out idea of what kinds of analysis could be done here before deciding on what kind of an API this should have, and cases we should be ready to handle.; > . support for multiple slices and concatenation of anndata objects is by far the priority to me. It's a really useful functionality since:; * most people don't work with one slide; * having the same ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1088#issuecomment-596965855:995,pipeline,pipelines,995,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1088#issuecomment-596965855,1,['pipeline'],['pipelines']
Deployability,> @Zethson See my comment above. You have a version mismatch between igraph and leidenalg. Use the latest of both. I know. The issue is that `poetry update` defaults to this combination in my environment for pertpy. I'll probably have to set minimum requirements. Thanks nevertheless!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2341#issuecomment-1641903565:149,update,update,149,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341#issuecomment-1641903565,1,['update'],['update']
Deployability,"> @Zethson re your comment ([#2028 (comment)](https://github.com/theislab/scanpy/pull/2028#issuecomment-956365435)), what were you thinking for a patch?; > ; > Disallowing `0.5.2`? Or make a fix for that version?. Well, I'd accept the [PR](https://github.com/theislab/scanpy/pull/2028) that fixes this. It's targeted enough and I am happy to see people contributing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2026#issuecomment-959063737:146,patch,patch,146,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2026#issuecomment-959063737,1,['patch'],['patch']
Deployability,"> @awnimo , for me test_phenograph.py fails with `E TypeError: Expected list, got numpy.ndarray`.; > Could you check please?; > This is certainly related to scipy 1.5. With scipy 1.4 the test works fine. Indeed, this error is related to scipy, and we have fixed that in Phenograph new release [1.5.7](https://github.com/dpeerlab/PhenoGraph#version-157). The `test_phenograph.py` does not fail with the new Phenograph release (`pip install -U phenograph`)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1080#issuecomment-703773746:285,release,release,285,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080#issuecomment-703773746,3,"['install', 'release']","['install', 'release']"
Deployability,"> @flying-sheep mentioned this was known and already fixed though?. I meant the other breakage due to the scipy update, sorry. > We could have blacklisted sklearn versions 0.21.0 and 0.21.1 if it was known, no?. We should do that now. We can do `sklearn >= 0.19.1, != 0.21.0, != 0.21.1` I think.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/654#issuecomment-494706587:112,update,update,112,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/654#issuecomment-494706587,1,['update'],['update']
Deployability,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory?. There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/558#issuecomment-476797878:159,install,install,159,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558#issuecomment-476797878,2,['install'],"['install', 'installing']"
Deployability,"> @giovp feel free to approve and merge. One request first:; > ; > Can this get a release note?. for sure, @LLehner could you? think he's is on holiday until next week",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2424#issuecomment-1450549756:82,release,release,82,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2424#issuecomment-1450549756,1,['release'],['release']
Deployability,"> @giovp looking at this again, it seems you drop the mixed up columns anyway ([scverse/squidpy@`fb069de`/squidpy/read/_read.py#L100](https://github.com/scverse/squidpy/blob/fb069ded7515e8a1386224d32344a8657cbecd2e/squidpy/read/_read.py#L100)) so I'd suggest having one code path with the correct column names. Please let me know if you need more clarity and help getting this over the hump for release. Hi @stephenwilliams22 ,. we drop it from obs since we don't want to save spatial coordinates there, cause they should be only in obsm. . So the only changes between space rangers version is the name of the tissue position file correct? but the order of the columns remains the same?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2296#issuecomment-1272277275:395,release,release,395,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296#issuecomment-1272277275,1,['release'],['release']
Deployability,"> @giovp, should this change happen in scanpy or squidpy?. I would make it happen in both and deprecate this function from the next release (as well as all the other spatial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2296#issuecomment-1272576192:132,release,release,132,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296#issuecomment-1272576192,1,['release'],['release']
Deployability,"> @hurleyLi, would you mind opening an issue over on umap that you're unable to get a `__version__` from it? It would be nice to have that fixed/ at least tracked down upstream. Figure it out. In my case it's because I have both `umap` and `umap-learn` installed, see here: https://github.com/theislab/scanpy/issues/2045#issuecomment-963533994",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1978#issuecomment-963537478:253,install,installed,253,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978#issuecomment-963537478,1,['install'],['installed']
Deployability,"> @ktpolanski I re-created a new conda env and installed scanpy so now it's working. I'm still not sure where the problem lies, though I did realize it starts jumping error after I install another package called stereopy, I'm guessing maybe that package updated something which got in conflict with normal scanpy setting. https://github.com/BGIResearch/stereopy/blob/6345d2732772a58d60351e790058bd5da1301fb5/requirements.txt#L26",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2297#issuecomment-1452144253:47,install,installed,47,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297#issuecomment-1452144253,3,"['install', 'update']","['install', 'installed', 'updated']"
Deployability,"> @macros29 try `pip install anndata --force-reinstall` then import your packages again and try saving. That indeed solved it! Thanks alot, @shayanhoss ! Although I still don't know what caused the issue in the first place exactly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/515#issuecomment-469502578:21,install,install,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515#issuecomment-469502578,1,['install'],['install']
Deployability,"> @pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:; > You'll need to add a scrublet entry to `extras_require` here:. Ahh, I see- thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1476#issuecomment-734715153:77,install,installed,77,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476#issuecomment-734715153,1,['install'],['installed']
Deployability,"> After #1156 I will update the function. Wait, does it use OR logic now?? Doesn't AND logic make more sense???",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1213#issuecomment-696776848:21,update,update,21,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213#issuecomment-696776848,1,['update'],['update']
Deployability,"> Ah I think I see the issue! Feature branches should be based off `master` and directing the pull request there! I think what's happening is that a pre-commit hook was installed, but the config only exists on the `master` branch.; > ; > I think this should largely be manageable by rebasing onto master (e.g. `git rebase --onto master 1.7.x`) and changing the branch the PR is targeting via the github interface:. Thanks a lot, I rebased and changed the PR target to `master` so I hope everything is on track now! ; The pre-commit style checks were working as expected now (auto-edits only in the files / parts I edited). > Side note: We're considering separating the highly_variable_genes interface into multiple functions, since the arguments to the different methods don't always overlap in meaningful or intuitive ways. There's nothing you need to do about this right now, but just a heads up to keep the logic for this method separate from the main function. Sounds good!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1715#issuecomment-795469189:169,install,installed,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715#issuecomment-795469189,1,['install'],['installed']
Deployability,> Any update?. I tried that but it's still giving me exactly the same tree : (,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/637#issuecomment-496025833:6,update,update,6,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/637#issuecomment-496025833,1,['update'],['update']
Deployability,"> As you can see, it's a pretty trivial wrapper anyway. Yes, makes sense. > Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. Yes, I like this. > I added exaggeration=None, as is the default in openTSNE. But setting it to 1 instead of None is better, and I should change that in the next release. Ah, right, I somehow overlooked that you did add the exaggeration parameter. That's fine then!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1561#issuecomment-753621515:392,release,release,392,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561#issuecomment-753621515,1,['release'],['release']
Deployability,"> Awesome, Gokcen, thank you! 😁; >. Thank you!; ; > Also, adding an export utility for Gephi was on the list already before. Cool that you found a simple solution for this.; > . Ah ok, didn't know that. Here is what I used so far for gephi:. ```python; # python-igraph from master branch is required; # see https://github.com/igraph/python-igraph/issues/115; from igraph.remote.gephi import GephiConnection, GephiGraphStreamer. sc.tl.draw_graph(adata); # would be also nice have access to igraph object right after sc.tl.draw_graph; g = sc.utils.get_igraph_from_adjacency(adata.uns['data_graph_norm_weights']). # then install latest Gephi and the streaming plugin:; # https://gephi.org/plugins/#/plugin/graphstreaming; # and start the Gephi master server; streamer = GephiGraphStreamer(); conn = GephiConnection(workspace=1). # igraph cannot serialize numpy float32 to json, so it must be converted to float64; g.es['weight'] = [float(x) for x in g.es['weight']]; g.vs['groups'] = adata.obs['louvain_groups'].tolist(); streamer.post(g, conn); ```. Here is the Yifan Hu layout for 3K PBMC:. ![image](https://user-images.githubusercontent.com/1140359/34961174-384c5658-fa0c-11e7-8597-db4e77cbf4e3.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/68#issuecomment-357787075:618,install,install,618,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/68#issuecomment-357787075,1,['install'],['install']
Deployability,"> Bumping matplotlib needs updating of google Colab's default matplotlib. As Colab imports matplotlib on start-up this means you have to restart the runtime after installing scanpy. For production I think it's fine, tutorials would require to restart after installing scanpy. You can see this behavior in scverse tutorials using Colab, e.g. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Noted!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2208#issuecomment-1089886547:163,install,installing,163,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208#issuecomment-1089886547,2,['install'],['installing']
Deployability,"> But I actually don't see any docs there, I don't know why it doesn't find the original docstring... That’s because on readthedocs, bbknn isn’t installed, so it uses the dummy version. > We'd like to have the reference to @ktpolanski preprint in the docstring in the first line together with a short summary of what it does and how it does it, just as for any other function. We could do that either by adding a docstring to the dummy version that links to https://bbknn.rtfd.io or by installing bbknn on rtd, and modifying the docstring programmatically. something like:. ```py; try:; from bbknn import bbknn; first_para, rest = bbknn.__doc__.split('\n\n', 1); bbknn.__doc__ =; '{}\n\nFor a graphical explanation, visit '; '`The bbknn project <https://github.com/Teichlab/bbknn>`__-\n\n{}'; .format(first_para, rest); except ImportError:; ...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/361#issuecomment-439855867:145,install,installed,145,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/361#issuecomment-439855867,2,['install'],"['installed', 'installing']"
Deployability,"> CCA does not have code in python, which will make it difficult to integrate, pySCENIC is probably easier but I would rather ask the developers.; > ; > @falexwolf We should consider a way to facilitate scanpy 'plugins'. A quick search shows me that this could be possible: https://packaging.python.org/guides/creating-and-discovering-plugins/ but honestly I don't know how it works. Nevertheless, given the number of tools that continue to appear we should consider a scheme that facilitate how developers can take advantage of scanpy preprocessing, storing, analysis and visualization tools. Pyscenic has been integrated into scanpy now! Here is the hyper link:; https://github.com/aertslab/pySCENIC/blob/master/notebooks/pySCENIC%20-%20Integration%20with%20scanpy.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/265#issuecomment-509063881:68,integrat,integrate,68,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/265#issuecomment-509063881,2,['integrat'],"['integrate', 'integrated']"
Deployability,"> Can we call this epi_sc_expression_atlas instead of expression_atlas?. Definitely agree it's good to specify it's from EBI. Would `ebi_expression_atlas` be alright? `ebi_sc_expression_atlas` feels a little verbose for me. I think it's implied it's single cell, plus it's explicit in the doc-string. > For the time being, can we make this settings.datasetsdir instead of settings.dataset_dir and add it here:. Changed the name. It looks like the main docs aren't being generated from `scanpy/scanpy/api/__init__.py`, but from `docs/api/index.rst` instead. Which is correct?. > Can we point it to the home directory by default, I'd say ~/scanpy-datasets/?. Changed. Does this mean config changes should also happen in this PR? I think this may cause trouble (HPC environments with small `~` allocations) without allowing default configuration at the same time. I had previously figured that setting up a config file could be factored out to a separate PR. To be able to put off adding the config for now, we could temporarily special case a `SCANPY_DATASETDIR` environment variable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/573#issuecomment-478414057:829,configurat,configuration,829,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/573#issuecomment-478414057,1,['configurat'],['configuration']
Deployability,"> Can we keep the docs on what exactly is happening + how to troubleshoot somewhere in this doc? This means things like: How to tag + build locally, twine check, list contents of distributed file etc. Sure, as we agreed on in person, I’ll just add a section to the end of the document.; If the build process or package structure aren’t touched, doing things manually isn’t necessary. > We should also automate some checks to avoid broken releases. As we agreed in person: Let’s postpone this. E.g. don't allow this except on specific branches + probably turn on merge queue so we know only commits that pass tests + doc builds get to those branches. This PR automatically does `twine check`, which is enough improvement over “trust the person doing the release to do that” to be worth the change, even if it wasn’t for the added convenience!. /edit: all addressed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2720#issuecomment-1785549678:438,release,releases,438,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2720#issuecomment-1785549678,2,['release'],"['release', 'releases']"
Deployability,> Can you elaborate? You can use `sc.pl.violin` independently. OK I just updated my question and attached a sample image. What I want to do is split-violinplot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1448#issuecomment-706060383:73,update,updated,73,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448#issuecomment-706060383,1,['update'],['updated']
Deployability,"> Completely agree, Gökcen!; > ; > How I just thought about dealing with this in the past couple of minutes: could we not make a submodule rtools? We could show the contained wrapper functions on an extra page of the API. All of the dependencies of this would be optional. In effect, this would be a very shallow wrapper that is only interesting for people who already have a working R installation etc. and use Scanpy along with R packages. As there are quite many of these people, this is definitely meaningful.; > . That'd make things a lot easier for many people (including myself 😃), I agree. However. 1) There are (and will be) so many R packages about single cell, so once we open the door, there might be so many requests about these packages so that it'd be difficult to decide what to include and what not to include. The decision might be a bit arbitrary. This is why I suggested a contrib repo, which will have everything users request (as soon as there is someone who is willing to maintain it), in a `use at your own risk` way... 2) There might be several bug reports about rpy2 itself or thin wrappers or R installation or R packages themselves. I was wondering whether this might introduce more maintenance burden, although supported packages will be limited. > The code would still look proper. Implementing tests for these wrappers is maybe not so important as these are only shallow interfaces. It would be easier to have this in the main scanpy repository than setting up a scanpy-contrib: I imagine less people will like to contribute and take the burden of maintaining another repository. PS: anndata is a different story. That's something that is meant to be so basic that it doesn't need a lot of maintenance an contributions.; > ; > What do you think?. Alternatively, we can just prepare jupyter notebooks with some Python 3 and some R cells in it (which is super easy via rpy2 magics anyway) for some R packages/functions like mnn or SIMLR and put those in scanpy_usage as a ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/125#issuecomment-382002901:386,install,installation,386,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125#issuecomment-382002901,1,['install'],['installation']
Deployability,"> Could any noqas added in this PR get something searchable added to them (like # noqa: {rule} TODO: fix me) so we know why it was added?. The noqas already state what they are ignoring. I for now would not try to differentiate between noqas that we want to keep and noqas that we want to get rid of. We want to get rid of all of them in the follow up issue and only when examining all of them we will figure out which ones we want to keep. > Document how to turn off these checks in dev docs. What do you mean? How to ignore a single line? How to fully ignore whole checks? I would always refer to the flake8 documentation, because it will certainly maintained better than the dev documentation. > Add autopep8 to precommit. If things can be fixed automatically, they should be. autopep8 should be able to get it's rules from the flake8 config. I wish it were that easy. autopep8 does not take its configuration from the flake8 config file nor can it fix all pep8 violations nor do Black and autopep8 always work nicely together. Black is an **opiniated** formatter. It formats consistently, but not necessarily compatible with other tools. I would not add autopep8, since I do not see any further benefit to the Black & flake8 combination, only more potential for issues and confused developers. I agree with your other comments and will take care of them as soon as I got your answers :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1689#issuecomment-787424021:899,configurat,configuration,899,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689#issuecomment-787424021,1,['configurat'],['configuration']
Deployability,> Could you please add a release note?. Sure; I added it.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3220#issuecomment-2324834604:25,release,release,25,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3220#issuecomment-2324834604,1,['release'],['release']
Deployability,"> Do you think you could make a PR with this to sklearn? I'd like to see the response it gets, and judge based on that. My preference would be for this to go there, but I'm very open to having this in our codebase until it's in a `sklearn` release. I'll try and do that soon. For now, I'll focus on providing you with the benchmarks you requested!. > * Datasets size (one small, one large (>50k cells)); > * Implicit centering, densifying centering, no centering; > * single threaded, multi-threaded <---------. I could not find a `n_jobs` argument in `scanpy.pp.pca`. Can you elaborate a little on the single threaded, multi-threaded bit?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1066#issuecomment-589512273:240,release,release,240,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066#issuecomment-589512273,1,['release'],['release']
Deployability,> Do you want to add a release note entry?. Added. I believe I got the format right.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2733#issuecomment-1799724990:23,release,release,23,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2733#issuecomment-1799724990,1,['release'],['release']
Deployability,"> Except if you plan to not update the scanpy.api module and docs section. Yes, that's the plan. `scanpy.api` is completely phased out an simply there for backwards compatibility.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/406#issuecomment-450877926:28,update,update,28,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406#issuecomment-450877926,1,['update'],['update']
Deployability,"> First, thanks for adding more tests!. Sure thing. Thanks for all the great feedback!. > 1. Is the file `scanpy/tests/_images/scatter_filtered_genes_raw.png` meant to be here?. No, thanks for catching that. > 2. Could the tests be broken up by what they are asserting? I would prefer to break up what is being tested by test case ; rather than values of parameters. Yes, I've broken both of the tests down into multiple tests. > 3. Could we cut down on the number of reference images generated since those cause manual maintenance burden on some matplotlib updates. These reference based tests are not great for confirming the correct plot is output, only that their output is consistent across commits.; > I think some of these cases could instead be tested with `check_same_image`, e.g. where it doesn't matter whether raw is `True` or `None`. Also testing for checking cases where `use_raw=True` would be equivalent to passing `pbmc.raw.to_adata()`. I've cut the number of reference images down to two. I couldn't figure out a clever way to use `check_same_image()` instead of `save_and_compare_images()` for these as you did for the others. See below for comments about individual suggestions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2027#issuecomment-966240677:558,update,updates,558,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027#issuecomment-966240677,1,['update'],['updates']
Deployability,"> From my error log it seems the only non-noarch dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py). That’s surprising! I think numba is our most complex dependency, and umap’s dependency PyNNDescent is also compiled. I think if this isn’t a mistake and it’s really just about h5py, we can think about it. Trying to install scanpy and following JupyterLite’s debug instructions gives:. ![image](https://github.com/scverse/scanpy/assets/291575/07a30013-e78d-46af-80fd-fb48af71d45b). ```pytb; ValueError: Can't find a pure Python 3 wheel for: 'umap-learn>=0.3.10', 'session-info', 'numba>=0.41.0'; See: https://pyodide.org/en/stable/usage/faq.html#why-can-t-micropip-find-a-pure-python-wheel-for-a-package; ```. (session-info isn’t a problem, it’s just an old package that doesn’t publish wheels)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731:344,install,install,344,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667#issuecomment-1803434731,1,['install'],['install']
Deployability,"> Given the file sizes nowadays and the number of ""groups"", this is getting fairly computationally intensive. It's one of those simple things your biologists will love (""this is so fast now!""). I agree it doesn't harm to have `rank_genes_groups` parallelized (given that it should be straightforward to implement). ; What @ivirshup was referring to though, is that `rank_genes_groups` on single cells in general isn't seen anymore as best practice for DE analysis because it doesn't account for pseudoreplication bias. Please take a look at @Zethson's [book chapter](https://www.sc-best-practices.org/conditions/differential_gene_expression.html). . > RE: pertpy; >; > Could does this relate to @davidsebfischer and diffxpy?. Diffxpy is currently being reimplemented. Once it is released, it would likely be included in pertpy as an additional method. I.e. pertpy is more general and strives to provide a consistent interface to multiple methods.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2390#issuecomment-1396521226:779,release,released,779,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2390#issuecomment-1396521226,1,['release'],['released']
Deployability,"> Great, thank you!. hi, did you find the ""merge"" or ""integrate"" commond in scanpy?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/702#issuecomment-527330223:54,integrat,integrate,54,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/702#issuecomment-527330223,1,['integrat'],['integrate']
Deployability,"> Had this problem, followed the `scikit-misc` package [issue](https://github.com/has2k1/scikit-misc/issues/12) on a related problem and installed the recommended patch with; > ; > ```; > pip install -i https://test.pypi.org/simple/ ""scikit-misc==0.2.0rc1""; > ```; > ; > Seems to work now for me. Thank you. It just worked for me, in July 2024.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-2231704559:137,install,installed,137,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-2231704559,3,"['install', 'patch']","['install', 'installed', 'patch']"
Deployability,"> Hey @ywen1407!; > ; > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though.; > ; > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1431#issuecomment-699114229:1053,integrat,integration,1053,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431#issuecomment-699114229,2,['integrat'],['integration']
Deployability,"> Hey, sorry about the late response!. No worries!. > Would you mind separating out the bug fix and feature addition? That was the bug fix can be released more quickly. OK, will do- see https://github.com/theislab/scanpy/pull/2023, https://github.com/theislab/scanpy/pull/2025. > Question about the main idea here: what kind of batches are you expecting to handle here?; > ; > If they were from completely separate sequencing experiments, would you want to have variable expected doublet rates between batches?; > ; > If the batches are multiple samples that were barcoded and multiplexed, would you want to allow for the possibility of multiplets across batches?. So, really, I just want to be able to follow best practice as per the [Scrublet docs](https://github.com/swolock/scrublet#best-practices), to be able to run Scrublet on cells from different samples separately, perhaps batches is the wrong term. Do you have a preferred alternative, or should I just clarify the help text?. > Could you also merge master into this? CI should be fixed now. Done",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1965#issuecomment-953614277:146,release,released,146,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1965#issuecomment-953614277,1,['release'],['released']
Deployability,"> Hi @ChineseBest, installing the following versions in google colab worked for me: `scanpy==1.7.1 pynndescent==0.4.8 numba==0.51.2`. Ok, thanks. In fact I have already changed to local machine to run it. Thx again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1951#issuecomment-908462363:19,install,installing,19,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951#issuecomment-908462363,1,['install'],['installing']
Deployability,"> Hi @JackieMium, I remember you said something similar in another issue.; > ; > If there’s things bugging you, how about making a PR that fixes it?. Not sure what you're referring to but I don't think I ever reported color pallette issue before. ; I hope I could help fix things but I am familiar with R/Seurat and Python/scanpy is a whole new universe to me. I am starting to learning the scanpy pipeline. How things work under the hood with scanpy or basically Python plotting are really beyond my capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1438#issuecomment-1640521040:398,pipeline,pipeline,398,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438#issuecomment-1640521040,1,['pipeline'],['pipeline']
Deployability,"> Hi @KabitaBaral1 ,; > You can update it using:; > ; > ```; > pip install --upgrade scanpy; > ```; in conda; ```; conda install -c bioconda scanpy=1.4.6; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1154#issuecomment-613413914:32,update,update,32,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154#issuecomment-613413914,4,"['install', 'update', 'upgrade']","['install', 'update', 'upgrade']"
Deployability,"> Hi @grimwoo,; > ; > The data integration methods MNN and BBKNN are implemented in scanpy externals, which you can find [here](https://scanpy.readthedocs.io/en/stable/external/index.html#batch-effect-correction). You can also use combat correction, which is a simpler, linear batch effect correction approach implemented as `sc.pp.combat()`. Thanks you so much~",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/702#issuecomment-527391920:31,integrat,integration,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/702#issuecomment-527391920,1,['integrat'],['integration']
Deployability,"> Hi @grimwoo,; > ; > The data integration methods MNN and BBKNN are implemented in scanpy externals, which you can find [here](https://scanpy.readthedocs.io/en/stable/external/index.html#batch-effect-correction). You can also use combat correction, which is a simpler, linear batch effect correction approach implemented as `sc.pp.combat()`. sorry to bother you again. ; I want to merge adata001, adata002, and adata003 into adata.combined, with mark ""001"", ""002"", and ""003"" respectively. I looked into the help-information of ""help(combat)"", but still don't know how to do so. In Seurat (R), it can be done like: ; adata001$Sample <- ""001""; adata002$Sample <- ""002""; adata002$Sample <- ""003""; adata.anchors <- FindIntegrationAnchors(object.list = list(adata001, adata002, adata003), dims = 1:11); adata.combined <- IntegrateData(anchorset = adata.anchors, dims = 1:11)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/702#issuecomment-527731457:31,integrat,integration,31,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/702#issuecomment-527731457,2,"['Integrat', 'integrat']","['IntegrateData', 'integration']"
Deployability,"> Hi @ivirshup, I've been meaning to get back to this. I've just started on an AnnData-compatible version of Scrublet which should be easy to hook up to Scanpy. Will keep you posted. Any updates on this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/173#issuecomment-492312537:187,update,updates,187,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173#issuecomment-492312537,1,['update'],['updates']
Deployability,"> Hi @rbf22 ,; > what's the issue here?. I’ve updated the issue. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1486#issuecomment-723136057:46,update,updated,46,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486#issuecomment-723136057,1,['update'],['updated']
Deployability,"> Hi @sygongcode,; > ; > Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy). Yes, that is what I want to do. Thank you so much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/821#issuecomment-529218989:206,integrat,integrated,206,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821#issuecomment-529218989,1,['integrat'],['integrated']
Deployability,"> Hi, Just wanted to comment that I had this issue. Converted from Seurat to h5ad using SeuratDisk. `adata.raw.var_names` is different than `adata.var_names`. As a result, I couldn't plot since none of my features were found (keys). Using `use_raw=False` worked. Yep, I have the same problem, if you worked on a Seurat-converted h5ad adata.; Any solutions or updates on this? Or we have to use useRaw=False????",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1406#issuecomment-850250397:359,update,updates,359,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1406#issuecomment-850250397,1,['update'],['updates']
Deployability,"> Hi,; > ; > all things that are not transcriptomics should ideally live in our sister packages such as https://github.com/scverse/muon . If you remove all things related to ATAC-seq in this PR we could consider it, but honestly I think that this might better live outside of scanpy external and much rather in the [scverse ecosystem](https://scverse.org/packages/#ecosystem). Hi,; Thank you for your reply. I could remove the ATAC in the PR, actually, this commit [7f74d8c](https://github.com/scverse/scanpy/pull/2355/commits/7f74d8c47005dd630f691ab5926095f0ff277ce8) is the version without ATAC. Please let me know if this does not work, I will commit another PR.; I think scalex is very suitable to be included in pp.external since it was developed based-on scanpy system, which could provide more choices for scanpy users to do single-cell integration.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2355#issuecomment-1376280885:844,integrat,integration,844,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355#issuecomment-1376280885,1,['integrat'],['integration']
Deployability,> How did you install scanpy? What conda command did you use?. And I'd appreciate an answer here. Just want to rule out that you used bioconda.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063428175:14,install,install,14,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173#issuecomment-1063428175,1,['install'],['install']
Deployability,"> How do we xfail stuff from dev?. [`pytest.mark.xfail`](https://docs.pytest.org/en/6.2.x/reference.html#pytest-mark-xfail) takes a condition:. ```py; xfail_if_dev_tests = pytest.mark.xfail(; os.environ.get(""DEPENDENCIES_VERSION"", ""latest"") == ""pre-release"",; reason=""..."",; ). @xfail_if_dev_tests; def test_xzy(): ...; ```. You probably need to change the tests so it makes the CI variable visible as an env variable, I’m not an Azure expert so I don’t know if it already is. > Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test. Yeah, maybe, let’s see once everything passes. I’m also OK with lowering the percentage, I just set it to 75% to have some indication if codecov is broken or working. (Before it would report 20% for a PR and there would be no visual indication that that’s a problem)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/3048#issuecomment-2114691148:249,release,release,249,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048#issuecomment-2114691148,1,['release'],['release']
Deployability,"> Huh. This is really weird, since it looks like it's almost entirely due to scipy sparse indexing. Must have something to do with versions. Two things:; > ; > * If you upgrade scipy, do you still run into this error?; > * Could you get the version info from an environment where you've only imported scanpy and run this command?. I will try to update scipy. Here is the output from only import scanpy:; BTW, everything works fine until I updated scanpy to 1.7.0. ```; anndata 0.7.4; scanpy 1.7.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.4; backcall 0.2.0; cairo 1.19.1; cffi 1.14.4; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; future_fstrings NA; get_version 2.1; h5py 2.10.0; igraph 0.8.2; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.7.0; matplotlib 3.3.1; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.8; pandas 1.2.1; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.6; psutil 5.7.2; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 2.4.7; pytz 2020.1; scanpy 1.7.0; scipy 1.4.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; storemagic NA; tables 3.6.1; texttable 1.6.2; tornado 6.0.4; traitlets 4.3.3; wcwidth 0.2.5; zmq 19.0.2; zope NA; -----; IPython 7.17.0; jupyter_client 6.1.6; jupyter_core 4.6.3; notebook 6.1.3; -----; Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]; Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10; 64 logical CPU cores, x86_64; -----; Session information updated at 2021-02-21 23:42; ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1670#issuecomment-783075376:169,upgrade,upgrade,169,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670#issuecomment-783075376,4,"['update', 'upgrade']","['update', 'updated', 'upgrade']"
Deployability,> I am not sure what --add does or -c . The following is probably a cleaner way to install. It should not have any unforeseen 'channels' related side effects.; > ; > This worked for me on MacOS Catalina; > ; > ```; > $ conda create --name SCA python=3.8.2; > (base) $ conda activate SCA; > (SCA) $ conda install scanpy --channel conda-forge --channel bioconda; > ```. That's the only way it worked for me. Thanks! Without creating a virtualenv it just did not move forward.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990#issuecomment-614315370:83,install,install,83,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990#issuecomment-614315370,2,['install'],['install']
Deployability,"> I created a new environment (see below for package details) and there everything works as it should. Can you use this new environment to do your analysis?. I expect that the previous environment managed to get into a messy state, which can lead to very strange errors. Because of this, I generally avoid trying to update old environments much and instead opt for creating fresh ones frequently.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1850#issuecomment-848441096:316,update,update,316,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850#issuecomment-848441096,1,['update'],['update']
Deployability,"> I didn't keep perfect track of the steps that I took to solve this or the exact versions of everything that I used but I'll try outlining what I did.; > ; > First I tried to upgrade numba and umap as suggested by the other individuals in the thread:; > ; > ```shell; > pip install --upgrade numba; > pip install --upgrade umap-learn; > ```; > ; > Then I essentially reinstalled scanpy using the steps in their installation docs.; > ; > ```shell; > conda install seaborn scikit-learn statsmodels numba pytables; > conda install -c conda-forge python-igraph leidenalg; > pip install scanpy; > ```; > ; > I think I then ended up with a version of numpy that was incompatible with numba so I ran; > ; > ```shell; > pip install numpy==1.20; > ```; > ; > After each step, you should be able to run the code from above to check if your installations worked, which I used to pinpoint what still needed work in my environment:; > ; > ```shell; > python3 -c ""import numpy as np; import umap; umap.UMAP().fit_transform(np.random.randn(10_000, 20))""; > ```; > ; > This seemed to fix my problems; I hope it's able to help others!. I followed your instruction but it still threw errors:. <frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject. Segmentation fault",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1567#issuecomment-1063184606:176,upgrade,upgrade,176,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1567#issuecomment-1063184606,11,"['install', 'upgrade']","['install', 'installation', 'installations', 'upgrade']"
Deployability,"> I for now would not try to differentiate between noqas that we want to keep and noqas that we want to get rid of. We want to get rid of all of them in the follow up issue and only when examining all of them we will figure out which ones we want to keep. After this merges new ignore messages can be added for reasons like ""this rule is generally good, but not in this specific case"". Each of these will go through PR review, so will be vetted. The ones added here largely have not been vetted, and are just being added so we don't get a failure. I would like to be able to distinguish between these cases. Once more `noqa` cases are added, it gets more complicated to find cases that haven't been vetted if they don't have some associated label. --------------------------. > What do you mean? How to ignore a single line? How to fully ignore whole checks?. How to disable flake8 errors for a line or file. > I would always refer to the flake8 documentation, because it will certainly maintained better than the dev documentation. A link to the section of the flake8 docs on this would be great. -------------------------. > I wish it were that easy. autopep8 does not take its configuration from the flake8 config file . `autopep8` says it does this: https://github.com/hhatto/autopep8#configuration. > It formats consistently, but not necessarily compatible with other tools. I would like changes that are automatically applicable to be automatically applied. I'm thinking of things like white space in docstrings. Is there another way to automate these you can suggest?. ---------. BTW, I've added a few more points to the checklist above. I would recommend trying to build the package and build the docs in the directory you're working in to see what files get generated so they can be added to the `ignore`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1689#issuecomment-787426782:1180,configurat,configuration,1180,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1689#issuecomment-787426782,2,['configurat'],['configuration']
Deployability,"> I found a workaround that does not require downloading the `.whl` file for `numpy=1.19.5`. By default, MKL is included when you install numpy with conda. It's good to do this in a new environment.; > ; > ```; > conda create -n scanpy_env; > conda activate scanpy_env; > conda install numpy=1.19; > conda install seaborn scikit-learn statsmodels numba pytables; > conda install -c conda-forge python-igraph leidenalg; > pip install scanpy; > ```; > ; > Now I can run `sc.pp.highly_variable_genes()` with no problem. Update: this workaround does not seem to work anymore, at least for scanpy 1.8.2 (you'll need to `pip install scanpy==1.8.1`). ; During `pip install scanpy`, a newer version of numpy is installed and version 1.19 is overwritten. This newer version does not have MKL, leading us back to square one. It's also not possible to `conda install numpy 1.19` as the very last step, because this leads to another error (it's related to the fact that scanpy needs to be compiled with the same version of numpy).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/2073#issuecomment-1058514241:130,install,install,130,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073#issuecomment-1058514241,10,"['Update', 'install']","['Update', 'install', 'installed']"
Deployability,"> I had the exact same issue and error message at that step in the tutorial. I installed scanpy using pip, because installing with conda was not working. Same here. I assume there is some issue with the implementation of the setter of adata.X, which prevents `adata.X = adata.X.toarray()` from updating X to its densified version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1010#issuecomment-578596689:79,install,installed,79,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010#issuecomment-578596689,2,['install'],"['installed', 'installing']"
Deployability,"> I had the same issue, and it turns out setting up channels solves the problem as follows:; > ; > ```; > conda config --add channels defaults; > conda config --add channels bioconda; > conda config --add channels conda-forge; > ```; > ; > Ref:; > https://bioconda.github.io/recipes/scanpy/README.html; > https://bioconda.github.io/user/install.html#set-up-channels. Thanks, this also worked for me!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/990#issuecomment-762368917:337,install,install,337,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990#issuecomment-762368917,1,['install'],['install']
Deployability,"> I have got what I want with the following code adapted from dotplot():; > ; > gene_ids = adata.raw.var.index.values clusters = adata.obs['louvain'].cat.categories obs = adata.raw[:,gene_ids].X.toarray() obs = pd.DataFrame(obs,columns=gene_ids,index=adata.obs['louvain']) average_obs = obs.groupby(level=0).mean() obs_bool = obs.astype(bool) fraction_obs = obs_bool.groupby(level=0).sum()/obs_bool.groupby(level=0).count() average_obs.T.to_csv(""average.csv"") fraction_obs.T.to_csv(""fraction.csv""). Love this! Thanks a lot!! ; Just one question, is there a way to get the average expression in different cell types (cluster label 1 ) in different sample (cluster label 2 ) from an integrated object?? ; to get something roughly like this:. Gene 1 Gene 2 ; sample1 sample2 sample3 sample1 sample2 sample3 ..... ....... ....; T-cell; B-cell ; .....; ..... I am not sure if this makes sense, but I have been trying to do this for a while and nothing worked!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/336#issuecomment-1334674713:681,integrat,integrated,681,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/336#issuecomment-1334674713,1,['integrat'],['integrated']
Deployability,"> I know exactly that in PCA I can interpret a component based on its rank (and/or variance contribution). Ah, I meant more specifically that it may be easier to biologically interpret an ICA. > That would say I should try as many decompositions as possible to see when I get a good result. I'm a little unsure of your meaning here. Do you mean decompositions like decomposition techniques? If so, I don't think this is the right conclusion. I think it means: probably PCA for clustering, probably NMF for finding gene modules. I would also suspect something which finds sparser variable loadings like ICA or NMF could be more robust for cross dataset classification. If you mean, if the results are unstable how do we know which to trust – I did ask that question. I think it's the usual: have a validation dataset, maybe some ensemble/ robustness method, or do some sort of enrichment. It's an open question, but a lot of our analysis pipeline is.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/941#issuecomment-560313033:937,pipeline,pipeline,937,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/941#issuecomment-560313033,1,['pipeline'],['pipeline']
Deployability,"> I know that this will cause a little more headache, but could we consider renaming to `rank_genes`?. Would you not maybe do this in stages with a `DeprecationWarning` first for a couple of releases? This change would break nearly everyone's pipelines and published notebooks. It's not a lot of work to change... but it might warrant a longer warning time.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1156#issuecomment-616525603:191,release,releases,191,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1156#issuecomment-616525603,2,"['pipeline', 'release']","['pipelines', 'releases']"
Deployability,"> I sent you an invitation for readthedocs.com about 2 months ago already - I just resent it. :). Well, doesn’t seem like it worked in the past: What I got now was not an invitation that I needed to click, but simply a notification that I’m now member of the team on rtd.com (which I wasn’t before). The changes look good! I would however prefer to do things via `.. include::` instead of duplicating code for the `scanpy` and `scanpy.api` sections. Except if you plan to not update the `scanpy.api` module and docs section.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/406#issuecomment-450818246:476,update,update,476,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/406#issuecomment-450818246,1,['update'],['update']
Deployability,"> I think we should have a 'cookbook' where we can keep this and other information. I've been trying to be organized about keeping notebooks around for this ([here](https://github.com/ivirshup/notebooks/tree/master/plotting)). Of course, I rarely get the notebooks clean enough to push 😆. > > In the end it's about showing which cells are represented per pixel/pixel bin.; >; > I would argue that this would be fair. In the end it's about showing which cells are represented per pixel/pixel bin. Is it fair if coloring by batch and one dataset had fewer samples? Wouldn't you want to know that multiple batches were showing up in this region? I'm fairly convinced there is no good way to show this in one plot, other than telling users some information is hidden. > We could do a quick fix based on random order for now. I'm trying to think of the simplest way to implement this. I would like to keep the behaviour of `sort_order=False` just using the order from the anndata object. Some options:. * `sort_order=""random""`, this would make the order random, but we might need to add a seed argument. Also, do we still plot over null values?; * `sort_order=order_array` where `order_array: np.ndarray[1, int]`. Basically, the user can pass whatever order they like. For random order it would be `np.random.choice(adata.n_obs, adata.n_obs, repeat=False)`. This is pretty flexible since it allows whatever order you want to be used without sorting the object. > larger update that would have to do with updating scanpy plotting to larger cell numbers?. I think this might be worth a separate package, at least to start out. At least with how I'm handling it now, there would be a large number of dependencies. Plus, I think overplottting like this is an unsolved problem, so freedom to experiment in important.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1263#issuecomment-761745895:1465,update,update,1465,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1263#issuecomment-761745895,1,['update'],['update']
Deployability,"> I want the h5ad file to include absolutely everything, so that it can be simply used as a single file distribute the ""full dataset"". This makes more sense now. In that case however I would say that having just raw counts in `adata.raw.X` is fine, no? In the end you are distributing a data file. You can have your version of the normalized data in a layer... and you would be distributing your analysis code as well, so it's always clear how people should use this data file that is being deposited, no?. > Might be important for integration?. Integration works better with HVGs typically, so I don't think these super lowly expressed genes are so relevant here... I would often go with `min_cells=20` or even `50` for larger datasets. In the end I reason that this value will be approximately related to the size of the smallest unique cellular identity you expect to find. > This does run into memory usage problems if want do a densifying transform on the data. Don't understand this entirely... and not sure what a block sparse matrix type is... but can't you subset sparse matrices based on masks? Should be fairly easy to just skip indices that are not in the mask... although i can imagine it might be slower than doing this on dense matrices. Based on above arguments the main issue I see is currently for the case @gokceneraslan mentioned about MT genes or non-coding genes being stored in `.raw`. In this case you might need these genes also during an analysis pipeline (and not just for data storage), so you would like to have them in a separate ""raw"" container that is otherwise not touched. This clashes with the way raw is used in current scanpy pipeline. I think we could deprecate the way `.raw` is used at the moment, and use a `.layer` for this instead (maybe a designated ""raw"" layer?), but then introduce a new `.frozenraw` or sth like that where just the raw data is stored and it's essentially read-only after assignment?. I would be a bit hesitant to not have a replacement f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1798#issuecomment-820336449:532,integrat,integration,532,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798#issuecomment-820336449,2,"['Integrat', 'integrat']","['Integration', 'integration']"
Deployability,> I was facing this issue in 0.7.8. Upgrading to 0.8.0 solved the problem. how did you update? pip says that 0.7.8 is the latest version,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1351#issuecomment-1378202005:87,update,update,87,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1351#issuecomment-1378202005,1,['update'],['update']
Deployability,"> I wasn't really expecting this feature PR to also include such a large refactor. It would have been necessary for the Dask Dataframe version. Now I 1. did the work and 2. improved readability, so it would be counter productive to undo it. > I'm still not 100% convinced the behaviour here is exactly the same as before. I have done a few tests, which have been okay, but I haven't tried much parameterization. I'm ~80% convinced the results should be the same. If you have any specific things in mind, you should probably make a PR that adds tests for the properties you think we should preserve. We can then merge that one, update this one, and see if it actually breaks something. I can’t check for speculative differences if I have no idea where those could be. > I would note that the dataframe returned when inplace=False has a different index than it did previously. Yup, now it actually matches instead of discarding the original Index and replacing it with a RangeIndex for no reason. > Apart from the comments, can we get a regression test for ""cell_ranger"" (e.g. generate results with an older version)? I don't think we have one in the test suite. Sure! That’s a concrete thing I can do. I’ll do that on thursday, I did the rest of what you asked today",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/2809#issuecomment-1930104931:627,update,update,627,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2809#issuecomment-1930104931,1,['update'],['update']
Deployability,"> I wonder why the tests are not working now?. Sorry, I forgot to update `violin.png` after the latest changes to `_anndata.py`. Let's see if the tests pass now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1422#issuecomment-696705252:66,update,update,66,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422#issuecomment-696705252,1,['update'],['update']
Deployability,"> I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with.; > Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. thank you, I really appreciate this :heart: . > The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand.; > I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. Totally understood. My motivation to use flit is that it’s simpler and therefore better both for first-time contributors (to get started) and experienced people (to debug), whereas CLI, metadata, and code of setuptools/pip is very complex and a nightmare to debug. I know that due to flit being used less, there needs to be someone who understands the packaging ecosystem to fix things when they’re broken instead of cargo-culting one of the million answers around setuptools on StackOverflow. > Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have pip install -e listed, and there has to be a note saying flit -s installations will be overridden due to a bug in pip. This stuff can be removed once this is fixed upstream. OK, will do! Can you link me tp the upstream discussion of this problem please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/pull/1527#issuecomment-787454064:1458,install,installation,1458,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527#issuecomment-787454064,3,['install'],"['install', 'installation', 'installations']"
Deployability,"> I would recommend creating fresh conda environments frequently, especially if you mix `conda` and `pip` installation. Upgrading them in finicky, and often results in a broken state. Creating a new environment and reinstalling everything worked for me. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1567#issuecomment-1063371834:106,install,installation,106,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1567#issuecomment-1063371834,1,['install'],['installation']
Deployability,"> I'd really like to have scanpy and anndata work better with dask, but am wary of a high code overhead. Could you provide examples of where you were running into issues with arrays being materialized?. You can see where the materialization occurs by looking for references to `materialize_as_ndarray` in the existing code. For example, in `filter_genes`: https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/_simple.py#L215, where the gene subset of materialized as an ndarray, then used to subset the anndata. Contrast this to the optimized version where the materialize step is not needed, and the data remains a dask array throughout the `filter_genes` method: https://github.com/tomwhite/scanpy/blob/sparse-dask/scanpy/preprocessing/_dask_optimized.py#L18. > I think this can be worked around in AnnData side in many cases. That would be great. > Any chance you did any profiling of these runs? I'd be interested in seeing the performance impact across the pipeline. The closest I got to this was using the Dask web UI to watch tasks being run (see this part of the benchmark script: https://github.com/tomwhite/scanpy/blob/sparse-dask/benchmark.py#L54-L55). This is useful to see what operations are bottlenecks. The only timings I did were to run the complete recipe. On the GPU questions, these all sound like promising avenues, but I haven't looked into any of them.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/921#issuecomment-555940037:977,pipeline,pipeline,977,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/921#issuecomment-555940037,1,['pipeline'],['pipeline']
Deployability,"> I'll definitely talk to the admin, but I am not sure he would update. An admin that doesn’t take security risks seriously isn’t doing their job properly. ---. > Jupyter Notebook requires JavaScript. that probably means that Jupyter notebook tries to run lynx or www or sone other text-only browser. `jupyter notebook --no-browser` is correct and the tokens aren’t machine-specific. [I set up stuff differently](https://jupyter-notebook.readthedocs.io/en/stable/public_server.html#automatic-password-setup), but @ivirshup’s setup should work perfectly as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/561#issuecomment-477525477:64,update,update,64,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/561#issuecomment-477525477,1,['update'],['update']
Deployability,"> I'm not keen to create and maintain a conda R package. That's fair. Might be worth asking the `conos` developers in this case?. Also, does using `install.packages` within a conda environment work for you? I recall that not working well for me in the past. > I'm guessing this is not what already happens in rpy2?. Nah, `rpy2` even copies the data in a particularly slow way by default.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-593263880:148,install,install,148,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-593263880,1,['install'],['install']
Deployability,"> I'm not sure how you could get any python setup to install R dependencies for you. Maybe a conda package could include dependencies? I think getting a working environment would alleviate a large pain point for this stuff (for example, I currently have no working Seurat install.). Plus making sure packages are up to date for the wrapped functionality. > you'd have to have a a separate data structure that can move been languages. Sort of. The idea is that you could move arrays to R from python without making any copies, they'd just point to the same memory. This is already possible when passing data from R to python. The main idea is making these wrappers faster and take less memory.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1068#issuecomment-590215132:53,install,install,53,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068#issuecomment-590215132,2,['install'],['install']
Deployability,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this?. > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function?. > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/issues/1233#issuecomment-631235395:257,install,installed,257,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233#issuecomment-631235395,1,['install'],['installed']
